[01/28 17:28:00] detectron2 INFO: Rank of current process: 0. World size: 4
[01/28 17:28:07] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 17:28:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32'], resume=False)
[01/28 17:28:07] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/28 17:28:07] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/28 17:28:07] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/config.yaml
[01/28 17:28:07] d2.utils.env INFO: Using a generated random seed 7945526
[01/28 17:28:10] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[01/28 17:28:10] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/28 17:28:14] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 17:28:14] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/28 17:28:15] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/28 17:28:15] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/28 17:28:15] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/28 17:28:15] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/28 17:28:15] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[01/28 17:28:15] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/28 17:28:15] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 17:28:27] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 619, in forward
    if self.deep_supervision:
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'MaskFormerStereo' object has no attribute 'deep_supervision'
[01/28 17:28:27] d2.engine.hooks INFO: Total training time: 0:00:12 (0:00:00 on hooks)
[01/28 17:28:27] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 10349M
[01/28 17:30:14] detectron2 INFO: Rank of current process: 0. World size: 4
[01/28 17:30:19] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 17:30:19] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32'], resume=False)
[01/28 17:30:19] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/28 17:30:19] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/28 17:30:20] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/config.yaml
[01/28 17:30:20] d2.utils.env INFO: Using a generated random seed 20264634
[01/28 17:30:21] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[01/28 17:30:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/28 17:30:26] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 17:30:27] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/28 17:30:27] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/28 17:30:28] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/28 17:30:28] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/28 17:30:28] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/28 17:30:28] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[01/28 17:30:28] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/28 17:30:28] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 17:31:55] d2.utils.events INFO:  eta: 2 days, 5:13:09  iter: 19  total_loss: 1.442e+05  loss_mask: 1.424e+04  loss_mask_0: 1.46e+04  loss_mask_1: 1.454e+04  loss_mask_2: 1.433e+04  loss_mask_3: 1.45e+04  loss_mask_4: 1.407e+04  loss_mask_5: 1.442e+04  loss_mask_6: 1.461e+04  loss_mask_7: 1.454e+04  loss_mask_8: 1.433e+04  time: 3.3493  data_time: 0.4739  lr: 9.9971e-05  max_mem: 27533M
[01/28 17:32:39] d2.engine.hooks INFO: Overall training speed: 31 iterations in 0:01:43 (3.3425 s / it)
[01/28 17:32:39] d2.engine.hooks INFO: Total training time: 0:01:43 (0:00:00 on hooks)
[01/28 17:32:39] d2.utils.events INFO:  eta: 2 days, 4:21:20  iter: 33  total_loss: 1.439e+04  loss_mask: 1286  loss_mask_0: 2028  loss_mask_1: 1610  loss_mask_2: 1437  loss_mask_3: 1469  loss_mask_4: 1410  loss_mask_5: 1289  loss_mask_6: 1366  loss_mask_7: 1246  loss_mask_8: 1247  time: 3.2452  data_time: 0.0637  lr: 9.9952e-05  max_mem: 27536M
[01/28 17:33:17] detectron2 INFO: Rank of current process: 0. World size: 4
[01/28 17:33:21] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 17:33:21] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32'], resume=False)
[01/28 17:33:21] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/28 17:33:21] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/28 17:33:21] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/config.yaml
[01/28 17:33:21] d2.utils.env INFO: Using a generated random seed 21759538
[01/28 17:33:22] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[01/28 17:33:22] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/28 17:33:27] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 17:33:27] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/28 17:33:27] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/28 17:33:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/28 17:33:27] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/28 17:33:27] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/28 17:33:27] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[01/28 17:33:27] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/28 17:33:27] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 17:34:51] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 17:34:51] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 17:34:51] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 17:45:15] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 151.62780516075225, 'error_1pix': 0.9988840955397478, 'error_3pix': 0.9984628228775367, 'mIoU': nan, 'fwIoU': 0.0, 'IoU-0': nan, 'IoU-1': nan, 'IoU-2': nan, 'IoU-3': nan, 'IoU-4': nan, 'IoU-5': nan, 'IoU-6': nan, 'IoU-7': nan, 'IoU-8': nan, 'IoU-9': nan, 'IoU-10': nan, 'IoU-11': nan, 'IoU-12': nan, 'IoU-13': nan, 'IoU-14': nan, 'IoU-15': nan, 'IoU-16': nan, 'IoU-17': nan, 'IoU-18': nan, 'IoU-19': nan, 'IoU-20': nan, 'IoU-21': nan, 'IoU-22': nan, 'IoU-23': nan, 'IoU-24': nan, 'IoU-25': nan, 'IoU-26': nan, 'IoU-27': nan, 'IoU-28': nan, 'IoU-29': nan, 'IoU-30': nan, 'IoU-31': nan, 'IoU-32': nan, 'IoU-33': nan, 'IoU-34': nan, 'IoU-35': nan, 'IoU-36': nan, 'IoU-37': nan, 'IoU-38': nan, 'IoU-39': nan, 'IoU-40': nan, 'IoU-41': nan, 'IoU-42': nan, 'IoU-43': nan, 'IoU-44': nan, 'IoU-45': nan, 'IoU-46': nan, 'IoU-47': nan, 'IoU-48': nan, 'IoU-49': nan, 'IoU-50': nan, 'IoU-51': nan, 'IoU-52': nan, 'IoU-53': nan, 'IoU-54': nan, 'IoU-55': nan, 'IoU-56': nan, 'IoU-57': nan, 'IoU-58': nan, 'IoU-59': nan, 'IoU-60': nan, 'IoU-61': nan, 'IoU-62': nan, 'IoU-63': nan, 'IoU-64': nan, 'IoU-65': nan, 'IoU-66': nan, 'IoU-67': nan, 'IoU-68': nan, 'IoU-69': nan, 'IoU-70': nan, 'IoU-71': nan, 'IoU-72': nan, 'IoU-73': nan, 'IoU-74': nan, 'IoU-75': nan, 'IoU-76': nan, 'IoU-77': nan, 'IoU-78': nan, 'IoU-79': nan, 'IoU-80': nan, 'IoU-81': nan, 'IoU-82': nan, 'IoU-83': nan, 'IoU-84': nan, 'IoU-85': nan, 'IoU-86': nan, 'IoU-87': nan, 'IoU-88': nan, 'IoU-89': nan, 'IoU-90': nan, 'IoU-91': nan, 'IoU-92': nan, 'IoU-93': nan, 'IoU-94': nan, 'IoU-95': nan, 'IoU-96': nan, 'IoU-97': nan, 'IoU-98': nan, 'IoU-99': nan, 'IoU-100': nan, 'IoU-101': nan, 'IoU-102': nan, 'IoU-103': nan, 'IoU-104': nan, 'IoU-105': nan, 'IoU-106': nan, 'IoU-107': nan, 'IoU-108': nan, 'IoU-109': nan, 'IoU-110': nan, 'IoU-111': nan, 'IoU-112': nan, 'IoU-113': nan, 'IoU-114': nan, 'IoU-115': nan, 'IoU-116': nan, 'IoU-117': nan, 'IoU-118': nan, 'IoU-119': nan, 'IoU-120': nan, 'IoU-121': nan, 'IoU-122': nan, 'IoU-123': nan, 'IoU-124': nan, 'IoU-125': nan, 'IoU-126': nan, 'IoU-127': nan, 'IoU-128': nan, 'IoU-129': nan, 'IoU-130': nan, 'IoU-131': nan, 'IoU-132': nan, 'IoU-133': nan, 'IoU-134': nan, 'IoU-135': nan, 'IoU-136': nan, 'IoU-137': nan, 'IoU-138': nan, 'IoU-139': nan, 'IoU-140': nan, 'IoU-141': nan, 'IoU-142': nan, 'IoU-143': nan, 'IoU-144': nan, 'IoU-145': nan, 'IoU-146': nan, 'IoU-147': nan, 'IoU-148': nan, 'IoU-149': nan, 'IoU-150': nan, 'IoU-151': nan, 'IoU-152': nan, 'IoU-153': nan, 'IoU-154': nan, 'IoU-155': nan, 'IoU-156': nan, 'IoU-157': nan, 'IoU-158': nan, 'IoU-159': nan, 'IoU-160': nan, 'IoU-161': nan, 'IoU-162': nan, 'IoU-163': nan, 'IoU-164': nan, 'IoU-165': nan, 'IoU-166': nan, 'IoU-167': nan, 'IoU-168': nan, 'IoU-169': nan, 'IoU-170': nan, 'IoU-171': nan, 'IoU-172': nan, 'IoU-173': nan, 'IoU-174': nan, 'IoU-175': nan, 'IoU-176': nan, 'IoU-177': nan, 'IoU-178': nan, 'IoU-179': nan, 'IoU-180': nan, 'IoU-181': nan, 'IoU-182': nan, 'IoU-183': nan, 'IoU-184': nan, 'IoU-185': nan, 'IoU-186': nan, 'IoU-187': nan, 'IoU-188': nan, 'IoU-189': nan, 'IoU-190': nan, 'IoU-191': nan, 'IoU-192': nan, 'mACC': nan, 'pACC': nan, 'ACC-0': nan, 'ACC-1': nan, 'ACC-2': nan, 'ACC-3': nan, 'ACC-4': nan, 'ACC-5': nan, 'ACC-6': nan, 'ACC-7': nan, 'ACC-8': nan, 'ACC-9': nan, 'ACC-10': nan, 'ACC-11': nan, 'ACC-12': nan, 'ACC-13': nan, 'ACC-14': nan, 'ACC-15': nan, 'ACC-16': nan, 'ACC-17': nan, 'ACC-18': nan, 'ACC-19': nan, 'ACC-20': nan, 'ACC-21': nan, 'ACC-22': nan, 'ACC-23': nan, 'ACC-24': nan, 'ACC-25': nan, 'ACC-26': nan, 'ACC-27': nan, 'ACC-28': nan, 'ACC-29': nan, 'ACC-30': nan, 'ACC-31': nan, 'ACC-32': nan, 'ACC-33': nan, 'ACC-34': nan, 'ACC-35': nan, 'ACC-36': nan, 'ACC-37': nan, 'ACC-38': nan, 'ACC-39': nan, 'ACC-40': nan, 'ACC-41': nan, 'ACC-42': nan, 'ACC-43': nan, 'ACC-44': nan, 'ACC-45': nan, 'ACC-46': nan, 'ACC-47': nan, 'ACC-48': nan, 'ACC-49': nan, 'ACC-50': nan, 'ACC-51': nan, 'ACC-52': nan, 'ACC-53': nan, 'ACC-54': nan, 'ACC-55': nan, 'ACC-56': nan, 'ACC-57': nan, 'ACC-58': nan, 'ACC-59': nan, 'ACC-60': nan, 'ACC-61': nan, 'ACC-62': nan, 'ACC-63': nan, 'ACC-64': nan, 'ACC-65': nan, 'ACC-66': nan, 'ACC-67': nan, 'ACC-68': nan, 'ACC-69': nan, 'ACC-70': nan, 'ACC-71': nan, 'ACC-72': nan, 'ACC-73': nan, 'ACC-74': nan, 'ACC-75': nan, 'ACC-76': nan, 'ACC-77': nan, 'ACC-78': nan, 'ACC-79': nan, 'ACC-80': nan, 'ACC-81': nan, 'ACC-82': nan, 'ACC-83': nan, 'ACC-84': nan, 'ACC-85': nan, 'ACC-86': nan, 'ACC-87': nan, 'ACC-88': nan, 'ACC-89': nan, 'ACC-90': nan, 'ACC-91': nan, 'ACC-92': nan, 'ACC-93': nan, 'ACC-94': nan, 'ACC-95': nan, 'ACC-96': nan, 'ACC-97': nan, 'ACC-98': nan, 'ACC-99': nan, 'ACC-100': nan, 'ACC-101': nan, 'ACC-102': nan, 'ACC-103': nan, 'ACC-104': nan, 'ACC-105': nan, 'ACC-106': nan, 'ACC-107': nan, 'ACC-108': nan, 'ACC-109': nan, 'ACC-110': nan, 'ACC-111': nan, 'ACC-112': nan, 'ACC-113': nan, 'ACC-114': nan, 'ACC-115': nan, 'ACC-116': nan, 'ACC-117': nan, 'ACC-118': nan, 'ACC-119': nan, 'ACC-120': nan, 'ACC-121': nan, 'ACC-122': nan, 'ACC-123': nan, 'ACC-124': nan, 'ACC-125': nan, 'ACC-126': nan, 'ACC-127': nan, 'ACC-128': nan, 'ACC-129': nan, 'ACC-130': nan, 'ACC-131': nan, 'ACC-132': nan, 'ACC-133': nan, 'ACC-134': nan, 'ACC-135': nan, 'ACC-136': nan, 'ACC-137': nan, 'ACC-138': nan, 'ACC-139': nan, 'ACC-140': nan, 'ACC-141': nan, 'ACC-142': nan, 'ACC-143': nan, 'ACC-144': nan, 'ACC-145': nan, 'ACC-146': nan, 'ACC-147': nan, 'ACC-148': nan, 'ACC-149': nan, 'ACC-150': nan, 'ACC-151': nan, 'ACC-152': nan, 'ACC-153': nan, 'ACC-154': nan, 'ACC-155': nan, 'ACC-156': nan, 'ACC-157': nan, 'ACC-158': nan, 'ACC-159': nan, 'ACC-160': nan, 'ACC-161': nan, 'ACC-162': nan, 'ACC-163': nan, 'ACC-164': nan, 'ACC-165': nan, 'ACC-166': nan, 'ACC-167': nan, 'ACC-168': nan, 'ACC-169': nan, 'ACC-170': nan, 'ACC-171': nan, 'ACC-172': nan, 'ACC-173': nan, 'ACC-174': nan, 'ACC-175': nan, 'ACC-176': nan, 'ACC-177': nan, 'ACC-178': nan, 'ACC-179': nan, 'ACC-180': nan, 'ACC-181': nan, 'ACC-182': nan, 'ACC-183': nan, 'ACC-184': nan, 'ACC-185': nan, 'ACC-186': nan, 'ACC-187': nan, 'ACC-188': nan, 'ACC-189': nan, 'ACC-190': nan, 'ACC-191': nan, 'ACC-192': nan})])
[01/28 17:45:15] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 17:45:15] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 17:45:15] d2.evaluation.testing INFO: copypaste: 151.6278,0.9989,0.9985,nan,0.0000,nan,nan
[01/28 17:45:15] d2.utils.events INFO:  eta: 2 days, 5:21:20  iter: 19  total_loss: 1.451e+05  loss_mask: 1.479e+04  loss_mask_0: 1.424e+04  loss_mask_1: 1.415e+04  loss_mask_2: 1.415e+04  loss_mask_3: 1.474e+04  loss_mask_4: 1.411e+04  loss_mask_5: 1.492e+04  loss_mask_6: 1.457e+04  loss_mask_7: 1.444e+04  loss_mask_8: 1.495e+04  time: 3.3347  data_time: 0.4501  lr: 9.9971e-05  max_mem: 27502M
[01/28 17:46:17] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 17:46:18] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 17:46:18] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 17:48:46] d2.engine.hooks INFO: Overall training speed: 37 iterations in 0:02:02 (3.2993 s / it)
[01/28 17:48:46] d2.engine.hooks INFO: Total training time: 0:14:54 (0:12:52 on hooks)
[01/28 17:48:46] d2.utils.events INFO:  eta: 2 days, 4:04:08  iter: 39  total_loss: 2075  loss_mask: 118.2  loss_mask_0: 590.4  loss_mask_1: 306  loss_mask_2: 206.8  loss_mask_3: 182.2  loss_mask_4: 214.4  loss_mask_5: 122.9  loss_mask_6: 110.1  loss_mask_7: 110.5  loss_mask_8: 113.5  time: 3.2124  data_time: 0.0597  lr: 9.9941e-05  max_mem: 27586M
[01/28 17:50:55] detectron2 INFO: Rank of current process: 0. World size: 4
[01/28 17:51:00] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 17:51:00] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32'], resume=False)
[01/28 17:51:00] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/28 17:51:00] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/28 17:51:00] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/config.yaml
[01/28 17:51:00] d2.utils.env INFO: Using a generated random seed 1060566
[01/28 17:51:02] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[01/28 17:51:02] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/28 17:51:07] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 17:51:07] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/28 17:51:07] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/28 17:51:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/28 17:51:07] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/28 17:51:08] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/28 17:51:08] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[01/28 17:51:08] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/28 17:51:08] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 17:52:34] d2.utils.events INFO:  eta: 2 days, 5:12:16  iter: 19  total_loss: 1.472e+05  loss_mask: 1.4e+04  loss_mask_0: 1.42e+04  loss_mask_1: 1.483e+04  loss_mask_2: 1.493e+04  loss_mask_3: 1.49e+04  loss_mask_4: 1.476e+04  loss_mask_5: 1.506e+04  loss_mask_6: 1.464e+04  loss_mask_7: 1.493e+04  loss_mask_8: 1.491e+04  time: 3.4000  data_time: 0.4562  lr: 9.9971e-05  max_mem: 27555M
[01/28 17:53:37] d2.utils.events INFO:  eta: 2 days, 4:06:46  iter: 39  total_loss: 2856  loss_mask: 45.86  loss_mask_0: 991  loss_mask_1: 566.6  loss_mask_2: 257.4  loss_mask_3: 77.28  loss_mask_4: 85.43  loss_mask_5: 152.3  loss_mask_6: 390.3  loss_mask_7: 219.9  loss_mask_8: 86.43  time: 3.2484  data_time: 0.0652  lr: 9.9941e-05  max_mem: 27555M
[01/28 17:54:40] d2.utils.events INFO:  eta: 2 days, 4:15:10  iter: 59  total_loss: 313.3  loss_mask: 34.62  loss_mask_0: 34.07  loss_mask_1: 29.08  loss_mask_2: 31.16  loss_mask_3: 35.49  loss_mask_4: 30.89  loss_mask_5: 31.52  loss_mask_6: 28.3  loss_mask_7: 30.01  loss_mask_8: 32.65  time: 3.2131  data_time: 0.0606  lr: 9.9911e-05  max_mem: 27610M
[01/28 17:55:42] d2.utils.events INFO:  eta: 2 days, 4:20:09  iter: 79  total_loss: 275.9  loss_mask: 27.85  loss_mask_0: 27.13  loss_mask_1: 26.54  loss_mask_2: 27.58  loss_mask_3: 27.48  loss_mask_4: 28  loss_mask_5: 27.74  loss_mask_6: 26.87  loss_mask_7: 27.36  loss_mask_8: 28.06  time: 3.1938  data_time: 0.0628  lr: 9.9881e-05  max_mem: 27610M
[01/28 17:56:45] d2.utils.events INFO:  eta: 2 days, 4:06:36  iter: 99  total_loss: 285.3  loss_mask: 28.45  loss_mask_0: 26.77  loss_mask_1: 26.97  loss_mask_2: 28.71  loss_mask_3: 28.74  loss_mask_4: 29.34  loss_mask_5: 29.66  loss_mask_6: 27.61  loss_mask_7: 29.04  loss_mask_8: 29.22  time: 3.1763  data_time: 0.0677  lr: 9.9851e-05  max_mem: 27610M
[01/28 17:57:47] d2.utils.events INFO:  eta: 2 days, 4:05:08  iter: 119  total_loss: 283.6  loss_mask: 28.46  loss_mask_0: 26.34  loss_mask_1: 28.55  loss_mask_2: 28.54  loss_mask_3: 28.56  loss_mask_4: 28.61  loss_mask_5: 28.51  loss_mask_6: 28.48  loss_mask_7: 28.5  loss_mask_8: 28.51  time: 3.1675  data_time: 0.0653  lr: 9.9821e-05  max_mem: 27610M
[01/28 17:58:49] d2.utils.events INFO:  eta: 2 days, 4:01:30  iter: 139  total_loss: 263.5  loss_mask: 26.73  loss_mask_0: 29.42  loss_mask_1: 26.3  loss_mask_2: 26.34  loss_mask_3: 26.05  loss_mask_4: 26.38  loss_mask_5: 26.49  loss_mask_6: 26.31  loss_mask_7: 26.47  loss_mask_8: 26.34  time: 3.1566  data_time: 0.0707  lr: 9.9791e-05  max_mem: 27610M
[01/28 17:59:51] d2.utils.events INFO:  eta: 2 days, 3:44:50  iter: 159  total_loss: 246.6  loss_mask: 23.35  loss_mask_0: 30.56  loss_mask_1: 24.31  loss_mask_2: 24.53  loss_mask_3: 23.7  loss_mask_4: 24.51  loss_mask_5: 24.74  loss_mask_6: 24.9  loss_mask_7: 24.71  loss_mask_8: 24  time: 3.1477  data_time: 0.0643  lr: 9.9761e-05  max_mem: 27610M
[01/28 18:00:52] d2.utils.events INFO:  eta: 2 days, 3:40:03  iter: 179  total_loss: 238.9  loss_mask: 24.02  loss_mask_0: 22.8  loss_mask_1: 24.65  loss_mask_2: 24.46  loss_mask_3: 24.28  loss_mask_4: 23.99  loss_mask_5: 24.24  loss_mask_6: 24.04  loss_mask_7: 23.82  loss_mask_8: 23.8  time: 3.1403  data_time: 0.0584  lr: 9.9731e-05  max_mem: 27610M
[01/28 18:01:55] d2.utils.events INFO:  eta: 2 days, 3:52:57  iter: 199  total_loss: 252  loss_mask: 25.23  loss_mask_0: 22.45  loss_mask_1: 25.51  loss_mask_2: 25.01  loss_mask_3: 25.48  loss_mask_4: 25.33  loss_mask_5: 25.08  loss_mask_6: 25.63  loss_mask_7: 25.32  loss_mask_8: 25.21  time: 3.1405  data_time: 0.0730  lr: 9.9701e-05  max_mem: 27611M
[01/28 18:02:58] d2.utils.events INFO:  eta: 2 days, 3:39:49  iter: 219  total_loss: 231.3  loss_mask: 23.67  loss_mask_0: 19.68  loss_mask_1: 23.11  loss_mask_2: 23.14  loss_mask_3: 23.61  loss_mask_4: 23.39  loss_mask_5: 23.26  loss_mask_6: 23.06  loss_mask_7: 23.09  loss_mask_8: 23.34  time: 3.1372  data_time: 0.0561  lr: 9.9671e-05  max_mem: 27611M
[01/28 18:03:59] d2.utils.events INFO:  eta: 2 days, 3:38:26  iter: 239  total_loss: 217.9  loss_mask: 22.12  loss_mask_0: 19.78  loss_mask_1: 21.07  loss_mask_2: 22.05  loss_mask_3: 22.19  loss_mask_4: 22.06  loss_mask_5: 22.11  loss_mask_6: 21.85  loss_mask_7: 22.03  loss_mask_8: 22.06  time: 3.1335  data_time: 0.0685  lr: 9.9641e-05  max_mem: 27611M
[01/28 18:05:02] d2.utils.events INFO:  eta: 2 days, 3:39:39  iter: 259  total_loss: 206.7  loss_mask: 20.87  loss_mask_0: 19.62  loss_mask_1: 19.83  loss_mask_2: 19.95  loss_mask_3: 20.39  loss_mask_4: 20.86  loss_mask_5: 21.08  loss_mask_6: 20.78  loss_mask_7: 20.83  loss_mask_8: 20.92  time: 3.1328  data_time: 0.0688  lr: 9.9611e-05  max_mem: 27611M
[01/28 18:06:03] d2.utils.events INFO:  eta: 2 days, 3:35:19  iter: 279  total_loss: 205.7  loss_mask: 20.26  loss_mask_0: 19.96  loss_mask_1: 20.45  loss_mask_2: 20.07  loss_mask_3: 20.44  loss_mask_4: 20.26  loss_mask_5: 20.47  loss_mask_6: 20.58  loss_mask_7: 20.7  loss_mask_8: 20.81  time: 3.1284  data_time: 0.0693  lr: 9.9581e-05  max_mem: 27611M
[01/28 18:07:05] d2.utils.events INFO:  eta: 2 days, 3:33:50  iter: 299  total_loss: 193.8  loss_mask: 20.07  loss_mask_0: 19.12  loss_mask_1: 19.7  loss_mask_2: 19.12  loss_mask_3: 19.25  loss_mask_4: 19.62  loss_mask_5: 19.44  loss_mask_6: 19.1  loss_mask_7: 19.46  loss_mask_8: 19.47  time: 3.1263  data_time: 0.0581  lr: 9.9551e-05  max_mem: 27611M
[01/28 18:08:07] d2.utils.events INFO:  eta: 2 days, 3:31:47  iter: 319  total_loss: 213.9  loss_mask: 22.06  loss_mask_0: 21.61  loss_mask_1: 20.64  loss_mask_2: 21.48  loss_mask_3: 21.3  loss_mask_4: 21.16  loss_mask_5: 22.29  loss_mask_6: 21.64  loss_mask_7: 20.77  loss_mask_8: 21.73  time: 3.1227  data_time: 0.0671  lr: 9.9521e-05  max_mem: 27611M
[01/28 18:09:09] d2.utils.events INFO:  eta: 2 days, 3:27:52  iter: 339  total_loss: 176.2  loss_mask: 18.03  loss_mask_0: 18.13  loss_mask_1: 17.45  loss_mask_2: 17.45  loss_mask_3: 17.54  loss_mask_4: 17.89  loss_mask_5: 17.82  loss_mask_6: 18.07  loss_mask_7: 17.99  loss_mask_8: 18.13  time: 3.1206  data_time: 0.0637  lr: 9.9491e-05  max_mem: 27611M
[01/28 18:10:10] d2.utils.events INFO:  eta: 2 days, 3:24:28  iter: 359  total_loss: 192.4  loss_mask: 19.68  loss_mask_0: 20.18  loss_mask_1: 18.04  loss_mask_2: 18.53  loss_mask_3: 19.72  loss_mask_4: 19.72  loss_mask_5: 19.26  loss_mask_6: 18.54  loss_mask_7: 19.01  loss_mask_8: 19.2  time: 3.1162  data_time: 0.0653  lr: 9.9461e-05  max_mem: 27611M
[01/28 18:11:12] d2.utils.events INFO:  eta: 2 days, 3:25:15  iter: 379  total_loss: 201  loss_mask: 20.46  loss_mask_0: 19.94  loss_mask_1: 19.66  loss_mask_2: 19.76  loss_mask_3: 19.75  loss_mask_4: 19.95  loss_mask_5: 20.15  loss_mask_6: 20.84  loss_mask_7: 20.15  loss_mask_8: 20.27  time: 3.1177  data_time: 0.0692  lr: 9.9431e-05  max_mem: 27611M
[01/28 18:12:15] d2.utils.events INFO:  eta: 2 days, 3:24:46  iter: 399  total_loss: 176.4  loss_mask: 18.35  loss_mask_0: 18.17  loss_mask_1: 17.36  loss_mask_2: 17.01  loss_mask_3: 16.83  loss_mask_4: 17.37  loss_mask_5: 17.74  loss_mask_6: 18.47  loss_mask_7: 18.19  loss_mask_8: 17.87  time: 3.1181  data_time: 0.0679  lr: 9.9401e-05  max_mem: 27611M
[01/28 18:13:16] d2.utils.events INFO:  eta: 2 days, 3:21:07  iter: 419  total_loss: 161.1  loss_mask: 16.23  loss_mask_0: 16.37  loss_mask_1: 15.72  loss_mask_2: 15.67  loss_mask_3: 15.69  loss_mask_4: 15.9  loss_mask_5: 15.82  loss_mask_6: 16.11  loss_mask_7: 15.88  loss_mask_8: 16.07  time: 3.1146  data_time: 0.0671  lr: 9.9371e-05  max_mem: 27611M
[01/28 18:14:18] d2.utils.events INFO:  eta: 2 days, 3:19:39  iter: 439  total_loss: 164.7  loss_mask: 16.65  loss_mask_0: 16.65  loss_mask_1: 15.99  loss_mask_2: 16.3  loss_mask_3: 16.74  loss_mask_4: 16.45  loss_mask_5: 16.85  loss_mask_6: 16.64  loss_mask_7: 16.34  loss_mask_8: 16.25  time: 3.1132  data_time: 0.0588  lr: 9.9341e-05  max_mem: 27611M
[01/28 18:15:20] d2.utils.events INFO:  eta: 2 days, 3:18:26  iter: 459  total_loss: 166.1  loss_mask: 16.85  loss_mask_0: 17.06  loss_mask_1: 16.41  loss_mask_2: 16.16  loss_mask_3: 16.38  loss_mask_4: 16.32  loss_mask_5: 16.37  loss_mask_6: 16.63  loss_mask_7: 16.53  loss_mask_8: 16.77  time: 3.1127  data_time: 0.0836  lr: 9.9311e-05  max_mem: 27611M
[01/28 18:16:22] d2.utils.events INFO:  eta: 2 days, 3:17:35  iter: 479  total_loss: 188.7  loss_mask: 19.59  loss_mask_0: 18.33  loss_mask_1: 18.02  loss_mask_2: 18.22  loss_mask_3: 19.53  loss_mask_4: 18.98  loss_mask_5: 19.61  loss_mask_6: 19.85  loss_mask_7: 18.98  loss_mask_8: 18.75  time: 3.1118  data_time: 0.0631  lr: 9.9281e-05  max_mem: 27611M
[01/28 18:17:24] d2.utils.events INFO:  eta: 2 days, 3:17:07  iter: 499  total_loss: 214.8  loss_mask: 20.54  loss_mask_0: 20.78  loss_mask_1: 19.99  loss_mask_2: 18.85  loss_mask_3: 20.8  loss_mask_4: 22.72  loss_mask_5: 22.17  loss_mask_6: 21.95  loss_mask_7: 20.63  loss_mask_8: 21.63  time: 3.1126  data_time: 0.0663  lr: 9.9251e-05  max_mem: 27611M
[01/28 18:18:25] d2.utils.events INFO:  eta: 2 days, 3:15:20  iter: 519  total_loss: 215.8  loss_mask: 22.19  loss_mask_0: 20.1  loss_mask_1: 21.25  loss_mask_2: 20.73  loss_mask_3: 20.47  loss_mask_4: 22.74  loss_mask_5: 23.48  loss_mask_6: 22.24  loss_mask_7: 21.48  loss_mask_8: 22.43  time: 3.1104  data_time: 0.0606  lr: 9.9221e-05  max_mem: 27611M
[01/28 18:19:27] d2.utils.events INFO:  eta: 2 days, 3:14:05  iter: 539  total_loss: 161.7  loss_mask: 16.34  loss_mask_0: 16.91  loss_mask_1: 16.73  loss_mask_2: 16.04  loss_mask_3: 15.97  loss_mask_4: 16.12  loss_mask_5: 16.55  loss_mask_6: 16.4  loss_mask_7: 16.1  loss_mask_8: 15.78  time: 3.1094  data_time: 0.0692  lr: 9.9191e-05  max_mem: 27611M
[01/28 18:20:29] d2.utils.events INFO:  eta: 2 days, 3:11:41  iter: 559  total_loss: 175.8  loss_mask: 18.1  loss_mask_0: 18.33  loss_mask_1: 17.55  loss_mask_2: 16.8  loss_mask_3: 17.11  loss_mask_4: 17.49  loss_mask_5: 17.23  loss_mask_6: 16.86  loss_mask_7: 16.6  loss_mask_8: 17.65  time: 3.1084  data_time: 0.0575  lr: 9.9161e-05  max_mem: 27611M
[01/28 18:21:30] d2.utils.events INFO:  eta: 2 days, 3:10:22  iter: 579  total_loss: 190.5  loss_mask: 18.32  loss_mask_0: 18.64  loss_mask_1: 18.88  loss_mask_2: 20.45  loss_mask_3: 19.06  loss_mask_4: 18.52  loss_mask_5: 18.99  loss_mask_6: 18.67  loss_mask_7: 19.95  loss_mask_8: 18.56  time: 3.1073  data_time: 0.0638  lr: 9.9131e-05  max_mem: 27611M
[01/28 18:22:32] d2.utils.events INFO:  eta: 2 days, 3:09:03  iter: 599  total_loss: 180.4  loss_mask: 16.94  loss_mask_0: 19.98  loss_mask_1: 17.38  loss_mask_2: 16.73  loss_mask_3: 17.02  loss_mask_4: 17.07  loss_mask_5: 17.66  loss_mask_6: 17.2  loss_mask_7: 18.31  loss_mask_8: 17.42  time: 3.1067  data_time: 0.0615  lr: 9.9101e-05  max_mem: 27611M
[01/28 18:23:34] d2.utils.events INFO:  eta: 2 days, 3:07:28  iter: 619  total_loss: 158.7  loss_mask: 16.64  loss_mask_0: 16.28  loss_mask_1: 15.77  loss_mask_2: 14.76  loss_mask_3: 15.14  loss_mask_4: 15.79  loss_mask_5: 16.04  loss_mask_6: 15.73  loss_mask_7: 16.03  loss_mask_8: 15.9  time: 3.1055  data_time: 0.0714  lr: 9.9071e-05  max_mem: 27611M
[01/28 18:24:36] d2.utils.events INFO:  eta: 2 days, 3:07:11  iter: 639  total_loss: 139.9  loss_mask: 14.26  loss_mask_0: 13.89  loss_mask_1: 13.6  loss_mask_2: 13.9  loss_mask_3: 14.02  loss_mask_4: 14.04  loss_mask_5: 13.97  loss_mask_6: 14  loss_mask_7: 14.04  loss_mask_8: 13.64  time: 3.1060  data_time: 0.0633  lr: 9.9041e-05  max_mem: 27611M
[01/28 18:25:38] d2.utils.events INFO:  eta: 2 days, 3:05:57  iter: 659  total_loss: 164.3  loss_mask: 16.2  loss_mask_0: 16.51  loss_mask_1: 16.09  loss_mask_2: 16.27  loss_mask_3: 16.14  loss_mask_4: 16.72  loss_mask_5: 16.37  loss_mask_6: 16.5  loss_mask_7: 16.61  loss_mask_8: 16.36  time: 3.1060  data_time: 0.0715  lr: 9.9011e-05  max_mem: 27611M
[01/28 18:26:40] d2.utils.events INFO:  eta: 2 days, 3:04:22  iter: 679  total_loss: 143.1  loss_mask: 14.45  loss_mask_0: 14.69  loss_mask_1: 14.38  loss_mask_2: 14.21  loss_mask_3: 14.28  loss_mask_4: 14.21  loss_mask_5: 14.18  loss_mask_6: 14.49  loss_mask_7: 14.44  loss_mask_8: 14.33  time: 3.1056  data_time: 0.0725  lr: 9.8981e-05  max_mem: 27611M
[01/28 18:27:42] d2.utils.events INFO:  eta: 2 days, 3:03:04  iter: 699  total_loss: 141.7  loss_mask: 14.09  loss_mask_0: 14.51  loss_mask_1: 14.14  loss_mask_2: 14.15  loss_mask_3: 14.07  loss_mask_4: 14.17  loss_mask_5: 14.15  loss_mask_6: 14.25  loss_mask_7: 13.94  loss_mask_8: 14.01  time: 3.1048  data_time: 0.0648  lr: 9.8951e-05  max_mem: 27611M
[01/28 18:28:44] d2.utils.events INFO:  eta: 2 days, 3:01:29  iter: 719  total_loss: 147.4  loss_mask: 15.02  loss_mask_0: 15.29  loss_mask_1: 14.7  loss_mask_2: 14.73  loss_mask_3: 14.73  loss_mask_4: 14.7  loss_mask_5: 14.8  loss_mask_6: 14.78  loss_mask_7: 14.62  loss_mask_8: 14.65  time: 3.1044  data_time: 0.0735  lr: 9.8921e-05  max_mem: 27611M
[01/28 18:29:45] d2.utils.events INFO:  eta: 2 days, 2:59:58  iter: 739  total_loss: 138.6  loss_mask: 13.76  loss_mask_0: 14.26  loss_mask_1: 13.86  loss_mask_2: 13.81  loss_mask_3: 13.87  loss_mask_4: 13.88  loss_mask_5: 13.85  loss_mask_6: 13.74  loss_mask_7: 13.82  loss_mask_8: 13.8  time: 3.1038  data_time: 0.0671  lr: 9.8891e-05  max_mem: 27611M
[01/28 18:30:47] d2.utils.events INFO:  eta: 2 days, 2:58:48  iter: 759  total_loss: 147.9  loss_mask: 14.66  loss_mask_0: 15.75  loss_mask_1: 14.63  loss_mask_2: 14.69  loss_mask_3: 14.74  loss_mask_4: 14.74  loss_mask_5: 14.82  loss_mask_6: 14.91  loss_mask_7: 14.71  loss_mask_8: 14.91  time: 3.1030  data_time: 0.0676  lr: 9.8861e-05  max_mem: 27611M
[01/28 18:31:49] d2.utils.events INFO:  eta: 2 days, 2:57:54  iter: 779  total_loss: 139.2  loss_mask: 13.91  loss_mask_0: 14.07  loss_mask_1: 13.8  loss_mask_2: 13.98  loss_mask_3: 13.89  loss_mask_4: 13.83  loss_mask_5: 14.03  loss_mask_6: 13.83  loss_mask_7: 13.83  loss_mask_8: 13.83  time: 3.1034  data_time: 0.0756  lr: 9.8831e-05  max_mem: 27611M
[01/28 18:32:51] d2.utils.events INFO:  eta: 2 days, 2:56:15  iter: 799  total_loss: 135  loss_mask: 13.56  loss_mask_0: 13.73  loss_mask_1: 13.29  loss_mask_2: 13.62  loss_mask_3: 13.56  loss_mask_4: 13.55  loss_mask_5: 13.5  loss_mask_6: 13.42  loss_mask_7: 13.22  loss_mask_8: 13.37  time: 3.1026  data_time: 0.0690  lr: 9.8801e-05  max_mem: 27611M
[01/28 18:33:53] d2.utils.events INFO:  eta: 2 days, 2:55:37  iter: 819  total_loss: 137.5  loss_mask: 13.65  loss_mask_0: 14.05  loss_mask_1: 13.88  loss_mask_2: 13.79  loss_mask_3: 13.89  loss_mask_4: 13.84  loss_mask_5: 13.78  loss_mask_6: 13.59  loss_mask_7: 13.71  loss_mask_8: 13.85  time: 3.1025  data_time: 0.0742  lr: 9.8771e-05  max_mem: 27611M
[01/28 18:34:55] d2.utils.events INFO:  eta: 2 days, 2:54:35  iter: 839  total_loss: 141.4  loss_mask: 13.82  loss_mask_0: 15.01  loss_mask_1: 13.83  loss_mask_2: 13.97  loss_mask_3: 13.99  loss_mask_4: 14.1  loss_mask_5: 13.99  loss_mask_6: 13.98  loss_mask_7: 13.91  loss_mask_8: 13.98  time: 3.1028  data_time: 0.0725  lr: 9.8741e-05  max_mem: 27611M
[01/28 18:35:57] d2.utils.events INFO:  eta: 2 days, 2:53:33  iter: 859  total_loss: 135.3  loss_mask: 13.44  loss_mask_0: 15.15  loss_mask_1: 13.3  loss_mask_2: 13.32  loss_mask_3: 13.48  loss_mask_4: 13.43  loss_mask_5: 13.47  loss_mask_6: 13.48  loss_mask_7: 13.54  loss_mask_8: 13.53  time: 3.1031  data_time: 0.0816  lr: 9.8711e-05  max_mem: 27611M
[01/28 18:36:59] d2.utils.events INFO:  eta: 2 days, 2:52:10  iter: 879  total_loss: 135.6  loss_mask: 13.4  loss_mask_0: 13.92  loss_mask_1: 13.37  loss_mask_2: 13.39  loss_mask_3: 13.48  loss_mask_4: 13.47  loss_mask_5: 13.53  loss_mask_6: 13.53  loss_mask_7: 13.42  loss_mask_8: 13.48  time: 3.1030  data_time: 0.0633  lr: 9.8681e-05  max_mem: 27611M
[01/28 18:38:01] d2.utils.events INFO:  eta: 2 days, 2:50:40  iter: 899  total_loss: 140.1  loss_mask: 13.92  loss_mask_0: 14.47  loss_mask_1: 13.65  loss_mask_2: 13.76  loss_mask_3: 13.79  loss_mask_4: 13.88  loss_mask_5: 13.87  loss_mask_6: 14.22  loss_mask_7: 14.03  loss_mask_8: 13.98  time: 3.1027  data_time: 0.0591  lr: 9.865e-05  max_mem: 27611M
[01/28 18:39:03] d2.utils.events INFO:  eta: 2 days, 2:49:18  iter: 919  total_loss: 127.1  loss_mask: 12.51  loss_mask_0: 14.54  loss_mask_1: 12.52  loss_mask_2: 12.98  loss_mask_3: 12.77  loss_mask_4: 12.74  loss_mask_5: 12.82  loss_mask_6: 12.88  loss_mask_7: 12.55  loss_mask_8: 12.54  time: 3.1024  data_time: 0.0536  lr: 9.862e-05  max_mem: 27611M
[01/28 18:40:05] d2.utils.events INFO:  eta: 2 days, 2:45:48  iter: 939  total_loss: 122.6  loss_mask: 12.14  loss_mask_0: 13.04  loss_mask_1: 12.28  loss_mask_2: 12.11  loss_mask_3: 12.24  loss_mask_4: 12.24  loss_mask_5: 12.15  loss_mask_6: 12.1  loss_mask_7: 12.24  loss_mask_8: 12.16  time: 3.1018  data_time: 0.0617  lr: 9.859e-05  max_mem: 27611M
[01/28 18:41:06] d2.utils.events INFO:  eta: 2 days, 2:43:35  iter: 959  total_loss: 160.5  loss_mask: 15.93  loss_mask_0: 15.24  loss_mask_1: 15.17  loss_mask_2: 15.18  loss_mask_3: 16.07  loss_mask_4: 15.56  loss_mask_5: 15.79  loss_mask_6: 15.52  loss_mask_7: 15.53  loss_mask_8: 15.75  time: 3.1007  data_time: 0.0606  lr: 9.856e-05  max_mem: 27611M
[01/28 18:42:07] d2.utils.events INFO:  eta: 2 days, 2:41:03  iter: 979  total_loss: 166  loss_mask: 16.95  loss_mask_0: 16.55  loss_mask_1: 15.5  loss_mask_2: 16.15  loss_mask_3: 16.35  loss_mask_4: 16.86  loss_mask_5: 17.75  loss_mask_6: 16.61  loss_mask_7: 16.79  loss_mask_8: 16.66  time: 3.0997  data_time: 0.0654  lr: 9.853e-05  max_mem: 27611M
[01/28 18:43:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 18:43:08] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 18:43:08] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 18:56:34] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 14.316387573575373, 'error_1pix': 0.8413682338008281, 'error_3pix': 0.7453572170015768, 'mIoU': 0.49865137351070826, 'fwIoU': 1.6779408889765897, 'IoU-0': 0.0008793803822343293, 'IoU-1': 5.784797034992387, 'IoU-2': 0.866269557804948, 'IoU-3': 0.31120723938453715, 'IoU-4': 0.2270951518842846, 'IoU-5': 0.1824025029005696, 'IoU-6': 0.1433568259237053, 'IoU-7': 0.11218221239470251, 'IoU-8': 0.2930935725694139, 'IoU-9': 0.9829518235800605, 'IoU-10': 1.7129527148087527, 'IoU-11': 2.720484716181608, 'IoU-12': 3.194274837083059, 'IoU-13': 3.148466414775498, 'IoU-14': 2.9877094875664505, 'IoU-15': 2.564719183084592, 'IoU-16': 2.5571446251698133, 'IoU-17': 2.284928410558209, 'IoU-18': 2.0552401183771987, 'IoU-19': 1.7701228118715784, 'IoU-20': 1.8608574161159321, 'IoU-21': 1.8547763384900402, 'IoU-22': 1.8329097850605065, 'IoU-23': 1.6852947276350554, 'IoU-24': 1.499409545227671, 'IoU-25': 1.3639118373965011, 'IoU-26': 1.40968970684383, 'IoU-27': 1.39478647236344, 'IoU-28': 1.313927278915724, 'IoU-29': 1.2849315538526962, 'IoU-30': 1.3024583227844528, 'IoU-31': 1.3733658435536296, 'IoU-32': 1.3557013169850107, 'IoU-33': 1.2523573265179433, 'IoU-34': 1.157591841391138, 'IoU-35': 1.149998038798779, 'IoU-36': 1.0897535935594642, 'IoU-37': 1.1215343841332759, 'IoU-38': 1.1010309467257968, 'IoU-39': 1.125196551071549, 'IoU-40': 1.0601937953974798, 'IoU-41': 1.0470854373487537, 'IoU-42': 0.9829996903941495, 'IoU-43': 0.8457836755796535, 'IoU-44': 0.8151331846492499, 'IoU-45': 0.7731196794979283, 'IoU-46': 0.730539781488726, 'IoU-47': 0.7341696324594522, 'IoU-48': 0.7000280678137053, 'IoU-49': 0.6879876791151905, 'IoU-50': 0.667914742338062, 'IoU-51': 0.6486366867378457, 'IoU-52': 0.6580252751228244, 'IoU-53': 0.6261967622966025, 'IoU-54': 0.57283338220784, 'IoU-55': 0.5266573867706726, 'IoU-56': 0.5303264762183011, 'IoU-57': 0.6115389123208664, 'IoU-58': 0.5717519179663064, 'IoU-59': 0.5516557680172711, 'IoU-60': 0.5510882365701729, 'IoU-61': 0.5841855074794168, 'IoU-62': 0.6797848467573981, 'IoU-63': 0.6862116357078774, 'IoU-64': 0.7832355192710319, 'IoU-65': 0.7472322915690053, 'IoU-66': 0.7821288477474174, 'IoU-67': 0.9544485740995057, 'IoU-68': 1.0214314286792365, 'IoU-69': 0.9074248706245196, 'IoU-70': 1.0796955943493858, 'IoU-71': 0.9761981528588143, 'IoU-72': 0.8819538264095573, 'IoU-73': 0.9218766070107456, 'IoU-74': 1.0935219596795538, 'IoU-75': 0.9874045498319072, 'IoU-76': 0.8840890746324082, 'IoU-77': 0.9920971159577111, 'IoU-78': 0.7490088725988806, 'IoU-79': 0.6718493999002997, 'IoU-80': 0.5321442126640126, 'IoU-81': 0.704030777678007, 'IoU-82': 0.7310938064558437, 'IoU-83': 0.29058064791593174, 'IoU-84': 0.44986384665391477, 'IoU-85': 0.147106226050833, 'IoU-86': 0.13798619601233045, 'IoU-87': 0.09491321302108298, 'IoU-88': 0.04276159339635959, 'IoU-89': 0.1420508212878147, 'IoU-90': 0.11739241410995967, 'IoU-91': 0.08566171015354579, 'IoU-92': 0.001748028889328605, 'IoU-93': 0.00947114302999642, 'IoU-94': 0.003361460306526606, 'IoU-95': 0.021927010737643974, 'IoU-96': 0.020290450962710496, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 1.7741899713911868e-05, 'IoU-100': 2.0236074039747695e-05, 'IoU-101': 2.144194047845975e-05, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 2.5632869130617666e-05, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 4.018126572594288e-05, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.230814114666577, 'pACC': 2.911052456461891, 'ACC-0': 0.007626490994498303, 'ACC-1': 6.122200574882528, 'ACC-2': 3.917852219342776, 'ACC-3': 6.480054349961064, 'ACC-4': 5.444814995098808, 'ACC-5': 5.433343381052107, 'ACC-6': 5.218018167174568, 'ACC-7': 4.934713091292283, 'ACC-8': 4.664561326364391, 'ACC-9': 5.5860154176218515, 'ACC-10': 5.340865876755387, 'ACC-11': 5.413216847409072, 'ACC-12': 5.838187047972577, 'ACC-13': 5.767940532310025, 'ACC-14': 5.738227840404626, 'ACC-15': 5.378430724569401, 'ACC-16': 5.652271851192817, 'ACC-17': 5.601967076317966, 'ACC-18': 4.9244748834869405, 'ACC-19': 4.30537164762218, 'ACC-20': 4.582451048592746, 'ACC-21': 4.488510034481689, 'ACC-22': 4.240048169113397, 'ACC-23': 4.101498136062273, 'ACC-24': 3.6933786371482404, 'ACC-25': 3.3386443746905234, 'ACC-26': 3.3780228117803848, 'ACC-27': 3.161911464223414, 'ACC-28': 2.975329519533961, 'ACC-29': 2.7483272992642176, 'ACC-30': 2.744048829627971, 'ACC-31': 2.752749068975687, 'ACC-32': 2.688534002868493, 'ACC-33': 2.4796642961733943, 'ACC-34': 2.228026137430692, 'ACC-35': 2.1020151406904484, 'ACC-36': 1.9152313342480705, 'ACC-37': 1.932001154243213, 'ACC-38': 1.8371611367126877, 'ACC-39': 1.8378712913582629, 'ACC-40': 1.6954880637717413, 'ACC-41': 1.686399054825543, 'ACC-42': 1.5581184943398656, 'ACC-43': 1.3146925156697429, 'ACC-44': 1.2244612174896174, 'ACC-45': 1.1527176214933896, 'ACC-46': 1.0922693574704578, 'ACC-47': 1.0829451989114274, 'ACC-48': 1.0216132078827262, 'ACC-49': 0.991625797843855, 'ACC-50': 0.9564246761409323, 'ACC-51': 0.9351931513455616, 'ACC-52': 0.9473479566943372, 'ACC-53': 0.900116262523117, 'ACC-54': 0.8233030127036536, 'ACC-55': 0.7672111994502954, 'ACC-56': 0.7842502012438403, 'ACC-57': 0.9100543964538577, 'ACC-58': 0.8692485205444762, 'ACC-59': 0.8643245248258866, 'ACC-60': 0.8943764056775559, 'ACC-61': 0.9946672400529938, 'ACC-62': 1.21482443675987, 'ACC-63': 1.3496121020364815, 'ACC-64': 1.6069822022575078, 'ACC-65': 1.6484996441443067, 'ACC-66': 1.8606673423190465, 'ACC-67': 2.4868258811365744, 'ACC-68': 2.812050681095859, 'ACC-69': 2.5907847642616453, 'ACC-70': 3.403890608512284, 'ACC-71': 3.422468737371872, 'ACC-72': 3.1168620879204094, 'ACC-73': 3.59615552056092, 'ACC-74': 4.1184660130995905, 'ACC-75': 3.588751816838641, 'ACC-76': 2.832041054682387, 'ACC-77': 2.8253258110371307, 'ACC-78': 2.027730766389523, 'ACC-79': 1.805564698139357, 'ACC-80': 1.3052746302731844, 'ACC-81': 1.5951832486257878, 'ACC-82': 1.5227985487812865, 'ACC-83': 0.5089994200384883, 'ACC-84': 0.7596563598125579, 'ACC-85': 0.20798297252245432, 'ACC-86': 0.18289006140803885, 'ACC-87': 0.12372894295622248, 'ACC-88': 0.053642040679971935, 'ACC-89': 0.2023286955289471, 'ACC-90': 0.14978187964925666, 'ACC-91': 0.10314606380740698, 'ACC-92': 0.0020903250796776465, 'ACC-93': 0.009575847414616957, 'ACC-94': 0.0037100019219026346, 'ACC-95': 0.023562261347503218, 'ACC-96': 0.022714900191827665, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 1.9284067426356074e-05, 'ACC-100': 2.0273333187365333e-05, 'ACC-101': 2.1493506381851916e-05, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 2.6222375710528048e-05, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 4.018236363913987e-05, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/28 18:56:34] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 18:56:34] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 18:56:34] d2.evaluation.testing INFO: copypaste: 14.3164,0.8414,0.7454,0.4987,1.6779,1.2308,2.9111
[01/28 18:56:34] d2.utils.events INFO:  eta: 2 days, 2:38:39  iter: 999  total_loss: 159.7  loss_mask: 15.2  loss_mask_0: 15.89  loss_mask_1: 16.04  loss_mask_2: 15.68  loss_mask_3: 17.21  loss_mask_4: 15.83  loss_mask_5: 15.89  loss_mask_6: 15.44  loss_mask_7: 15.02  loss_mask_8: 15.28  time: 3.0980  data_time: 0.0542  lr: 9.85e-05  max_mem: 27611M
[01/28 18:57:36] d2.utils.events INFO:  eta: 2 days, 2:37:00  iter: 1019  total_loss: 133.5  loss_mask: 13.46  loss_mask_0: 14.44  loss_mask_1: 12.85  loss_mask_2: 13.18  loss_mask_3: 13.95  loss_mask_4: 13.37  loss_mask_5: 13.12  loss_mask_6: 13.28  loss_mask_7: 13.16  loss_mask_8: 13.3  time: 3.0980  data_time: 0.0640  lr: 9.847e-05  max_mem: 27611M
[01/28 18:58:37] d2.utils.events INFO:  eta: 2 days, 2:35:22  iter: 1039  total_loss: 135.3  loss_mask: 13.19  loss_mask_0: 14.35  loss_mask_1: 13.15  loss_mask_2: 13.22  loss_mask_3: 13.65  loss_mask_4: 13.45  loss_mask_5: 13.34  loss_mask_6: 13.31  loss_mask_7: 13.18  loss_mask_8: 13.17  time: 3.0968  data_time: 0.0657  lr: 9.844e-05  max_mem: 27611M
[01/28 18:59:38] d2.utils.events INFO:  eta: 2 days, 2:33:11  iter: 1059  total_loss: 137.3  loss_mask: 13.5  loss_mask_0: 13.64  loss_mask_1: 13.44  loss_mask_2: 13.74  loss_mask_3: 13.68  loss_mask_4: 13.58  loss_mask_5: 13.52  loss_mask_6: 13.67  loss_mask_7: 13.49  loss_mask_8: 13.39  time: 3.0960  data_time: 0.0569  lr: 9.841e-05  max_mem: 27611M
[01/28 19:00:39] d2.utils.events INFO:  eta: 2 days, 2:29:54  iter: 1079  total_loss: 138.9  loss_mask: 13.59  loss_mask_0: 14.65  loss_mask_1: 13.17  loss_mask_2: 13.29  loss_mask_3: 14.1  loss_mask_4: 14.05  loss_mask_5: 13.8  loss_mask_6: 13.93  loss_mask_7: 13.4  loss_mask_8: 13.63  time: 3.0950  data_time: 0.0632  lr: 9.838e-05  max_mem: 27611M
[01/28 19:01:39] d2.utils.events INFO:  eta: 2 days, 2:27:23  iter: 1099  total_loss: 132.6  loss_mask: 13.13  loss_mask_0: 13.58  loss_mask_1: 12.91  loss_mask_2: 13.25  loss_mask_3: 13.61  loss_mask_4: 13.53  loss_mask_5: 13.06  loss_mask_6: 13.19  loss_mask_7: 13.15  loss_mask_8: 12.81  time: 3.0936  data_time: 0.0667  lr: 9.835e-05  max_mem: 27611M
[01/28 19:02:40] d2.utils.events INFO:  eta: 2 days, 2:24:14  iter: 1119  total_loss: 133.5  loss_mask: 13.27  loss_mask_0: 13.77  loss_mask_1: 13.17  loss_mask_2: 13.29  loss_mask_3: 13.11  loss_mask_4: 13.32  loss_mask_5: 13.51  loss_mask_6: 13.39  loss_mask_7: 13.27  loss_mask_8: 13.4  time: 3.0928  data_time: 0.0708  lr: 9.832e-05  max_mem: 27611M
[01/28 19:03:43] d2.utils.events INFO:  eta: 2 days, 2:24:39  iter: 1139  total_loss: 125.9  loss_mask: 12.54  loss_mask_0: 12.97  loss_mask_1: 12.48  loss_mask_2: 12.7  loss_mask_3: 12.73  loss_mask_4: 12.67  loss_mask_5: 12.54  loss_mask_6: 12.82  loss_mask_7: 12.7  loss_mask_8: 12.71  time: 3.0934  data_time: 0.0621  lr: 9.829e-05  max_mem: 27611M
[01/28 19:04:44] d2.utils.events INFO:  eta: 2 days, 2:23:38  iter: 1159  total_loss: 141.3  loss_mask: 14.2  loss_mask_0: 15.68  loss_mask_1: 13.85  loss_mask_2: 13.81  loss_mask_3: 13.73  loss_mask_4: 13.97  loss_mask_5: 13.92  loss_mask_6: 14.16  loss_mask_7: 13.91  loss_mask_8: 13.82  time: 3.0929  data_time: 0.0763  lr: 9.826e-05  max_mem: 27611M
[01/28 19:05:46] d2.utils.events INFO:  eta: 2 days, 2:21:42  iter: 1179  total_loss: 126.8  loss_mask: 12.56  loss_mask_0: 14.6  loss_mask_1: 12.6  loss_mask_2: 12.42  loss_mask_3: 12.63  loss_mask_4: 12.64  loss_mask_5: 12.62  loss_mask_6: 12.52  loss_mask_7: 12.45  loss_mask_8: 12.56  time: 3.0927  data_time: 0.0643  lr: 9.823e-05  max_mem: 27632M
[01/28 19:06:46] d2.utils.events INFO:  eta: 2 days, 2:18:37  iter: 1199  total_loss: 126.4  loss_mask: 12.44  loss_mask_0: 13.47  loss_mask_1: 12.69  loss_mask_2: 12.69  loss_mask_3: 12.69  loss_mask_4: 12.51  loss_mask_5: 12.58  loss_mask_6: 12.6  loss_mask_7: 12.52  loss_mask_8: 12.63  time: 3.0916  data_time: 0.0713  lr: 9.82e-05  max_mem: 27632M
[01/28 19:07:47] d2.utils.events INFO:  eta: 2 days, 2:15:45  iter: 1219  total_loss: 119.3  loss_mask: 11.83  loss_mask_0: 13.06  loss_mask_1: 11.95  loss_mask_2: 11.75  loss_mask_3: 11.88  loss_mask_4: 12.05  loss_mask_5: 11.87  loss_mask_6: 11.68  loss_mask_7: 11.78  loss_mask_8: 11.9  time: 3.0904  data_time: 0.0594  lr: 9.817e-05  max_mem: 27632M
[01/28 19:08:47] d2.utils.events INFO:  eta: 2 days, 2:12:57  iter: 1239  total_loss: 123.1  loss_mask: 12.24  loss_mask_0: 13.61  loss_mask_1: 12.24  loss_mask_2: 12.39  loss_mask_3: 12.32  loss_mask_4: 12.23  loss_mask_5: 12.25  loss_mask_6: 12.23  loss_mask_7: 12.21  loss_mask_8: 12.21  time: 3.0892  data_time: 0.0623  lr: 9.814e-05  max_mem: 27632M
[01/28 19:09:49] d2.utils.events INFO:  eta: 2 days, 2:11:02  iter: 1259  total_loss: 126.2  loss_mask: 12.89  loss_mask_0: 13.14  loss_mask_1: 12.04  loss_mask_2: 12.4  loss_mask_3: 12.59  loss_mask_4: 12.81  loss_mask_5: 12.65  loss_mask_6: 12.48  loss_mask_7: 12.42  loss_mask_8: 12.64  time: 3.0891  data_time: 0.0637  lr: 9.811e-05  max_mem: 27632M
[01/28 19:10:50] d2.utils.events INFO:  eta: 2 days, 2:06:48  iter: 1279  total_loss: 127.3  loss_mask: 12.45  loss_mask_0: 14.46  loss_mask_1: 12.5  loss_mask_2: 13.08  loss_mask_3: 13.23  loss_mask_4: 12.81  loss_mask_5: 12.24  loss_mask_6: 11.8  loss_mask_7: 12.02  loss_mask_8: 12.23  time: 3.0883  data_time: 0.0691  lr: 9.8079e-05  max_mem: 27632M
[01/28 19:11:50] d2.utils.events INFO:  eta: 2 days, 2:02:51  iter: 1299  total_loss: 128.9  loss_mask: 11.76  loss_mask_0: 15.02  loss_mask_1: 12.65  loss_mask_2: 12.75  loss_mask_3: 12.98  loss_mask_4: 12.6  loss_mask_5: 12.13  loss_mask_6: 11.66  loss_mask_7: 11.71  loss_mask_8: 11.84  time: 3.0873  data_time: 0.0679  lr: 9.8049e-05  max_mem: 27632M
[01/28 19:12:52] d2.utils.events INFO:  eta: 2 days, 2:01:40  iter: 1319  total_loss: 119.6  loss_mask: 11.41  loss_mask_0: 13.14  loss_mask_1: 11.51  loss_mask_2: 12.03  loss_mask_3: 12.09  loss_mask_4: 11.75  loss_mask_5: 11.78  loss_mask_6: 11.55  loss_mask_7: 11.16  loss_mask_8: 11.35  time: 3.0873  data_time: 0.0639  lr: 9.8019e-05  max_mem: 27632M
[01/28 19:13:52] d2.utils.events INFO:  eta: 2 days, 1:59:38  iter: 1339  total_loss: 113.2  loss_mask: 10.93  loss_mask_0: 12.51  loss_mask_1: 11.02  loss_mask_2: 11.04  loss_mask_3: 11.48  loss_mask_4: 11.01  loss_mask_5: 10.91  loss_mask_6: 11.18  loss_mask_7: 10.89  loss_mask_8: 11  time: 3.0863  data_time: 0.0641  lr: 9.7989e-05  max_mem: 27632M
[01/28 19:14:53] d2.utils.events INFO:  eta: 2 days, 1:58:14  iter: 1359  total_loss: 108.2  loss_mask: 10.72  loss_mask_0: 11.94  loss_mask_1: 10.73  loss_mask_2: 10.75  loss_mask_3: 10.82  loss_mask_4: 10.7  loss_mask_5: 10.75  loss_mask_6: 10.76  loss_mask_7: 10.71  loss_mask_8: 10.7  time: 3.0857  data_time: 0.0652  lr: 9.7959e-05  max_mem: 27632M
[01/28 19:15:54] d2.utils.events INFO:  eta: 2 days, 1:54:00  iter: 1379  total_loss: 121.7  loss_mask: 11.74  loss_mask_0: 13.22  loss_mask_1: 11.76  loss_mask_2: 12.28  loss_mask_3: 11.93  loss_mask_4: 11.94  loss_mask_5: 11.94  loss_mask_6: 12.2  loss_mask_7: 11.8  loss_mask_8: 11.87  time: 3.0852  data_time: 0.0615  lr: 9.7929e-05  max_mem: 27632M
[01/28 19:16:56] d2.utils.events INFO:  eta: 2 days, 1:52:38  iter: 1399  total_loss: 114.8  loss_mask: 11.26  loss_mask_0: 11.81  loss_mask_1: 11.27  loss_mask_2: 11.52  loss_mask_3: 11.41  loss_mask_4: 11.54  loss_mask_5: 11.5  loss_mask_6: 11.38  loss_mask_7: 11.7  loss_mask_8: 11.66  time: 3.0850  data_time: 0.0624  lr: 9.7899e-05  max_mem: 27632M
[01/28 19:17:57] d2.utils.events INFO:  eta: 2 days, 1:51:37  iter: 1419  total_loss: 118.1  loss_mask: 11.55  loss_mask_0: 13.61  loss_mask_1: 11.41  loss_mask_2: 12.04  loss_mask_3: 11.56  loss_mask_4: 11.54  loss_mask_5: 11.64  loss_mask_6: 11.52  loss_mask_7: 11.92  loss_mask_8: 11.81  time: 3.0843  data_time: 0.0674  lr: 9.7869e-05  max_mem: 27632M
[01/28 19:18:58] d2.utils.events INFO:  eta: 2 days, 1:50:36  iter: 1439  total_loss: 116.1  loss_mask: 11.45  loss_mask_0: 12.79  loss_mask_1: 11.61  loss_mask_2: 11.53  loss_mask_3: 11.51  loss_mask_4: 11.56  loss_mask_5: 11.5  loss_mask_6: 11.52  loss_mask_7: 11.43  loss_mask_8: 11.5  time: 3.0840  data_time: 0.0566  lr: 9.7839e-05  max_mem: 27632M
[01/28 19:19:58] d2.utils.events INFO:  eta: 2 days, 1:47:19  iter: 1459  total_loss: 111.3  loss_mask: 11.05  loss_mask_0: 12.12  loss_mask_1: 10.92  loss_mask_2: 10.91  loss_mask_3: 10.99  loss_mask_4: 10.98  loss_mask_5: 10.94  loss_mask_6: 11.16  loss_mask_7: 10.94  loss_mask_8: 10.87  time: 3.0832  data_time: 0.0524  lr: 9.7809e-05  max_mem: 27632M
[01/28 19:20:59] d2.utils.events INFO:  eta: 2 days, 1:44:33  iter: 1479  total_loss: 113.1  loss_mask: 11.24  loss_mask_0: 12.19  loss_mask_1: 11.05  loss_mask_2: 11.23  loss_mask_3: 11.35  loss_mask_4: 11.14  loss_mask_5: 11.14  loss_mask_6: 11.29  loss_mask_7: 11.18  loss_mask_8: 11.11  time: 3.0823  data_time: 0.0517  lr: 9.7779e-05  max_mem: 27632M
[01/28 19:21:59] d2.utils.events INFO:  eta: 2 days, 1:41:08  iter: 1499  total_loss: 106.3  loss_mask: 10.29  loss_mask_0: 11.55  loss_mask_1: 10.44  loss_mask_2: 10.42  loss_mask_3: 10.52  loss_mask_4: 10.61  loss_mask_5: 10.55  loss_mask_6: 10.5  loss_mask_7: 10.51  loss_mask_8: 10.53  time: 3.0815  data_time: 0.0572  lr: 9.7749e-05  max_mem: 27632M
[01/28 19:23:00] d2.utils.events INFO:  eta: 2 days, 1:40:07  iter: 1519  total_loss: 103.7  loss_mask: 10.24  loss_mask_0: 11.34  loss_mask_1: 10.4  loss_mask_2: 10.32  loss_mask_3: 10.35  loss_mask_4: 10.25  loss_mask_5: 10.23  loss_mask_6: 10.29  loss_mask_7: 10.23  loss_mask_8: 10.19  time: 3.0809  data_time: 0.0513  lr: 9.7719e-05  max_mem: 27632M
[01/28 19:24:01] d2.utils.events INFO:  eta: 2 days, 1:38:51  iter: 1539  total_loss: 115.4  loss_mask: 11.42  loss_mask_0: 12.37  loss_mask_1: 11.51  loss_mask_2: 11.6  loss_mask_3: 11.5  loss_mask_4: 11.43  loss_mask_5: 11.37  loss_mask_6: 11.48  loss_mask_7: 11.28  loss_mask_8: 11.32  time: 3.0804  data_time: 0.0561  lr: 9.7689e-05  max_mem: 27632M
[01/28 19:25:01] d2.utils.events INFO:  eta: 2 days, 1:37:38  iter: 1559  total_loss: 110.2  loss_mask: 10.84  loss_mask_0: 12.06  loss_mask_1: 10.8  loss_mask_2: 10.87  loss_mask_3: 10.87  loss_mask_4: 10.79  loss_mask_5: 10.93  loss_mask_6: 11.1  loss_mask_7: 10.94  loss_mask_8: 10.89  time: 3.0797  data_time: 0.0509  lr: 9.7658e-05  max_mem: 27632M
[01/28 19:26:02] d2.utils.events INFO:  eta: 2 days, 1:35:16  iter: 1579  total_loss: 120.5  loss_mask: 12.48  loss_mask_0: 12.42  loss_mask_1: 11.64  loss_mask_2: 11.86  loss_mask_3: 11.98  loss_mask_4: 11.8  loss_mask_5: 11.77  loss_mask_6: 11.93  loss_mask_7: 11.57  loss_mask_8: 11.87  time: 3.0791  data_time: 0.0545  lr: 9.7628e-05  max_mem: 27632M
[01/28 19:27:03] d2.utils.events INFO:  eta: 2 days, 1:32:30  iter: 1599  total_loss: 120.4  loss_mask: 13.35  loss_mask_0: 12.74  loss_mask_1: 11.44  loss_mask_2: 11.47  loss_mask_3: 12.19  loss_mask_4: 11.54  loss_mask_5: 11.44  loss_mask_6: 11.59  loss_mask_7: 11.69  loss_mask_8: 12.22  time: 3.0788  data_time: 0.0555  lr: 9.7598e-05  max_mem: 27632M
[01/28 19:28:04] d2.utils.events INFO:  eta: 2 days, 1:30:02  iter: 1619  total_loss: 119.1  loss_mask: 12.41  loss_mask_0: 12.05  loss_mask_1: 11.35  loss_mask_2: 11.59  loss_mask_3: 11.71  loss_mask_4: 11.52  loss_mask_5: 11.65  loss_mask_6: 11.95  loss_mask_7: 11.8  loss_mask_8: 12.31  time: 3.0780  data_time: 0.0435  lr: 9.7568e-05  max_mem: 27632M
[01/28 19:29:04] d2.utils.events INFO:  eta: 2 days, 1:27:46  iter: 1639  total_loss: 106.2  loss_mask: 11.34  loss_mask_0: 11.67  loss_mask_1: 10.58  loss_mask_2: 10.9  loss_mask_3: 10.49  loss_mask_4: 10.7  loss_mask_5: 10.3  loss_mask_6: 10.34  loss_mask_7: 10.67  loss_mask_8: 10.67  time: 3.0773  data_time: 0.0506  lr: 9.7538e-05  max_mem: 27632M
[01/28 19:30:05] d2.utils.events INFO:  eta: 2 days, 1:26:08  iter: 1659  total_loss: 93.76  loss_mask: 9.388  loss_mask_0: 10.47  loss_mask_1: 9.275  loss_mask_2: 9.51  loss_mask_3: 9.174  loss_mask_4: 9.2  loss_mask_5: 9.255  loss_mask_6: 9.247  loss_mask_7: 9.326  loss_mask_8: 9.29  time: 3.0768  data_time: 0.0512  lr: 9.7508e-05  max_mem: 27632M
[01/28 19:31:05] d2.utils.events INFO:  eta: 2 days, 1:23:53  iter: 1679  total_loss: 99.75  loss_mask: 9.909  loss_mask_0: 10.74  loss_mask_1: 9.988  loss_mask_2: 10.12  loss_mask_3: 10.06  loss_mask_4: 10.01  loss_mask_5: 9.903  loss_mask_6: 9.926  loss_mask_7: 9.901  loss_mask_8: 9.975  time: 3.0759  data_time: 0.0482  lr: 9.7478e-05  max_mem: 27632M
[01/28 19:32:05] d2.utils.events INFO:  eta: 2 days, 1:21:20  iter: 1699  total_loss: 100.5  loss_mask: 10.19  loss_mask_0: 11.03  loss_mask_1: 9.995  loss_mask_2: 10.23  loss_mask_3: 10.03  loss_mask_4: 10.05  loss_mask_5: 9.968  loss_mask_6: 10.06  loss_mask_7: 9.91  loss_mask_8: 10.01  time: 3.0752  data_time: 0.0479  lr: 9.7448e-05  max_mem: 27632M
[01/28 19:33:05] d2.utils.events INFO:  eta: 2 days, 1:17:24  iter: 1719  total_loss: 100.3  loss_mask: 9.947  loss_mask_0: 10.49  loss_mask_1: 9.759  loss_mask_2: 9.94  loss_mask_3: 10.06  loss_mask_4: 10.01  loss_mask_5: 10.02  loss_mask_6: 10.17  loss_mask_7: 10.04  loss_mask_8: 9.928  time: 3.0745  data_time: 0.0494  lr: 9.7418e-05  max_mem: 27632M
[01/28 19:34:06] d2.utils.events INFO:  eta: 2 days, 1:14:31  iter: 1739  total_loss: 98.35  loss_mask: 9.896  loss_mask_0: 10.62  loss_mask_1: 9.696  loss_mask_2: 9.833  loss_mask_3: 9.885  loss_mask_4: 9.794  loss_mask_5: 9.699  loss_mask_6: 9.67  loss_mask_7: 9.746  loss_mask_8: 9.798  time: 3.0739  data_time: 0.0469  lr: 9.7388e-05  max_mem: 27632M
[01/28 19:35:06] d2.utils.events INFO:  eta: 2 days, 1:12:03  iter: 1759  total_loss: 103.7  loss_mask: 10.35  loss_mask_0: 11.42  loss_mask_1: 10.18  loss_mask_2: 10.53  loss_mask_3: 10.57  loss_mask_4: 10.39  loss_mask_5: 10.52  loss_mask_6: 10.32  loss_mask_7: 10.07  loss_mask_8: 10.15  time: 3.0731  data_time: 0.0481  lr: 9.7358e-05  max_mem: 27632M
[01/28 19:36:06] d2.utils.events INFO:  eta: 2 days, 1:08:23  iter: 1779  total_loss: 129.5  loss_mask: 12.95  loss_mask_0: 13.66  loss_mask_1: 12.57  loss_mask_2: 13.26  loss_mask_3: 13.23  loss_mask_4: 12.71  loss_mask_5: 12.97  loss_mask_6: 13.02  loss_mask_7: 12.94  loss_mask_8: 12.62  time: 3.0724  data_time: 0.0522  lr: 9.7328e-05  max_mem: 27632M
[01/28 19:37:07] d2.utils.events INFO:  eta: 2 days, 1:06:46  iter: 1799  total_loss: 116.3  loss_mask: 11.64  loss_mask_0: 13.78  loss_mask_1: 11.42  loss_mask_2: 11.5  loss_mask_3: 11.28  loss_mask_4: 11.32  loss_mask_5: 11.41  loss_mask_6: 11.55  loss_mask_7: 11.52  loss_mask_8: 11.32  time: 3.0717  data_time: 0.0458  lr: 9.7297e-05  max_mem: 27632M
[01/28 19:38:07] d2.utils.events INFO:  eta: 2 days, 1:03:32  iter: 1819  total_loss: 114.8  loss_mask: 11.48  loss_mask_0: 12.42  loss_mask_1: 11.56  loss_mask_2: 11.35  loss_mask_3: 11.51  loss_mask_4: 11.37  loss_mask_5: 11.18  loss_mask_6: 11.26  loss_mask_7: 11.32  loss_mask_8: 11.24  time: 3.0710  data_time: 0.0533  lr: 9.7267e-05  max_mem: 27632M
[01/28 19:39:08] d2.utils.events INFO:  eta: 2 days, 1:01:07  iter: 1839  total_loss: 106.5  loss_mask: 10.79  loss_mask_0: 11.75  loss_mask_1: 10.47  loss_mask_2: 10.7  loss_mask_3: 10.81  loss_mask_4: 10.52  loss_mask_5: 10.2  loss_mask_6: 10.55  loss_mask_7: 10.39  loss_mask_8: 10.42  time: 3.0709  data_time: 0.0520  lr: 9.7237e-05  max_mem: 27632M
[01/28 19:40:09] d2.utils.events INFO:  eta: 2 days, 0:59:17  iter: 1859  total_loss: 95.72  loss_mask: 9.51  loss_mask_0: 10.89  loss_mask_1: 9.406  loss_mask_2: 9.316  loss_mask_3: 9.569  loss_mask_4: 9.498  loss_mask_5: 9.352  loss_mask_6: 9.463  loss_mask_7: 9.444  loss_mask_8: 9.633  time: 3.0705  data_time: 0.0449  lr: 9.7207e-05  max_mem: 27632M
[01/28 19:41:10] d2.utils.events INFO:  eta: 2 days, 0:56:34  iter: 1879  total_loss: 103.3  loss_mask: 10.2  loss_mask_0: 11.51  loss_mask_1: 9.904  loss_mask_2: 10.31  loss_mask_3: 10.59  loss_mask_4: 10.16  loss_mask_5: 9.889  loss_mask_6: 10.17  loss_mask_7: 9.905  loss_mask_8: 10.47  time: 3.0702  data_time: 0.0472  lr: 9.7177e-05  max_mem: 27632M
[01/28 19:42:11] d2.utils.events INFO:  eta: 2 days, 0:54:39  iter: 1899  total_loss: 98.64  loss_mask: 9.799  loss_mask_0: 10.97  loss_mask_1: 9.413  loss_mask_2: 9.722  loss_mask_3: 9.833  loss_mask_4: 9.737  loss_mask_5: 9.689  loss_mask_6: 9.884  loss_mask_7: 9.57  loss_mask_8: 9.793  time: 3.0701  data_time: 0.0482  lr: 9.7147e-05  max_mem: 27632M
[01/28 19:43:12] d2.utils.events INFO:  eta: 2 days, 0:53:26  iter: 1919  total_loss: 120.4  loss_mask: 11.07  loss_mask_0: 13.25  loss_mask_1: 11.37  loss_mask_2: 12.21  loss_mask_3: 12.53  loss_mask_4: 11.81  loss_mask_5: 11.37  loss_mask_6: 12.22  loss_mask_7: 11.14  loss_mask_8: 11.29  time: 3.0700  data_time: 0.0528  lr: 9.7117e-05  max_mem: 27632M
[01/28 19:44:14] d2.utils.events INFO:  eta: 2 days, 0:52:17  iter: 1939  total_loss: 103.4  loss_mask: 10.27  loss_mask_0: 10.88  loss_mask_1: 10.01  loss_mask_2: 10.1  loss_mask_3: 10.2  loss_mask_4: 10.19  loss_mask_5: 10  loss_mask_6: 10.09  loss_mask_7: 10.19  loss_mask_8: 10.64  time: 3.0700  data_time: 0.0528  lr: 9.7087e-05  max_mem: 27632M
[01/28 19:45:15] d2.utils.events INFO:  eta: 2 days, 0:51:25  iter: 1959  total_loss: 102.9  loss_mask: 10.41  loss_mask_0: 10.65  loss_mask_1: 9.747  loss_mask_2: 9.984  loss_mask_3: 10.28  loss_mask_4: 10.3  loss_mask_5: 10.23  loss_mask_6: 10.31  loss_mask_7: 10.45  loss_mask_8: 10.5  time: 3.0697  data_time: 0.0570  lr: 9.7057e-05  max_mem: 27632M
[01/28 19:46:16] d2.utils.events INFO:  eta: 2 days, 0:51:12  iter: 1979  total_loss: 99.84  loss_mask: 9.963  loss_mask_0: 10.96  loss_mask_1: 9.907  loss_mask_2: 9.944  loss_mask_3: 9.84  loss_mask_4: 9.876  loss_mask_5: 9.891  loss_mask_6: 9.906  loss_mask_7: 9.942  loss_mask_8: 9.901  time: 3.0700  data_time: 0.0599  lr: 9.7027e-05  max_mem: 27632M
[01/28 19:47:17] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 19:47:18] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 19:47:18] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 20:00:28] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 10.190605363717083, 'error_1pix': 0.8508548478140346, 'error_3pix': 0.7229301165271242, 'mIoU': 0.9496549241811814, 'fwIoU': 4.700689733231946, 'IoU-0': 0.0, 'IoU-1': 33.47758580697717, 'IoU-2': 1.913478685857248, 'IoU-3': 0.22436671230994507, 'IoU-4': 0.21171587326009722, 'IoU-5': 0.21100746040399626, 'IoU-6': 0.17309477192816058, 'IoU-7': 0.1320410894757612, 'IoU-8': 0.6082155680568512, 'IoU-9': 0.7407769475248152, 'IoU-10': 1.1962505098231098, 'IoU-11': 1.2735203992784836, 'IoU-12': 1.1143236446997733, 'IoU-13': 0.8428304153072661, 'IoU-14': 0.7347037095745561, 'IoU-15': 0.6067523854245263, 'IoU-16': 0.5025478669714739, 'IoU-17': 0.46984381753011645, 'IoU-18': 0.6240240600641329, 'IoU-19': 0.742022124936634, 'IoU-20': 0.9282497591138664, 'IoU-21': 1.0358774614997768, 'IoU-22': 1.1400605200928011, 'IoU-23': 1.1716185699106438, 'IoU-24': 1.329945749482679, 'IoU-25': 1.4090229368183735, 'IoU-26': 1.4565040475012034, 'IoU-27': 1.5913388347653004, 'IoU-28': 1.6120991027802865, 'IoU-29': 1.8838685008021698, 'IoU-30': 2.0625462948593594, 'IoU-31': 2.0533952394849053, 'IoU-32': 2.1573239593658258, 'IoU-33': 2.090939166857099, 'IoU-34': 2.053885095833623, 'IoU-35': 2.1104338295027967, 'IoU-36': 2.339970127010892, 'IoU-37': 2.377250759508832, 'IoU-38': 2.4084181712072494, 'IoU-39': 2.348443077907179, 'IoU-40': 2.4120147013886615, 'IoU-41': 2.236752461111498, 'IoU-42': 2.215336977925332, 'IoU-43': 2.2410927103669924, 'IoU-44': 2.375464805088969, 'IoU-45': 2.2943579435328236, 'IoU-46': 2.1373222100299056, 'IoU-47': 2.1829642808175156, 'IoU-48': 2.1133089517169594, 'IoU-49': 2.032474948215253, 'IoU-50': 2.0464905933281754, 'IoU-51': 1.8922073172991105, 'IoU-52': 1.7987362793184494, 'IoU-53': 1.6927674577121208, 'IoU-54': 1.6941741491780047, 'IoU-55': 1.7042921784508158, 'IoU-56': 1.6810925728748496, 'IoU-57': 1.6753373754298941, 'IoU-58': 1.4995151350439142, 'IoU-59': 1.3692610533244471, 'IoU-60': 1.3202305589757803, 'IoU-61': 1.2477866774194049, 'IoU-62': 1.219630147542677, 'IoU-63': 1.1660510760236444, 'IoU-64': 1.18134769381577, 'IoU-65': 1.0867284218033402, 'IoU-66': 1.1732311936422621, 'IoU-67': 1.1490278756676664, 'IoU-68': 1.1225566940910991, 'IoU-69': 1.1778684234282717, 'IoU-70': 1.2432060550648032, 'IoU-71': 1.2577527106983741, 'IoU-72': 1.3679104921087653, 'IoU-73': 1.353233036635622, 'IoU-74': 1.3578683381285401, 'IoU-75': 1.3597546502599531, 'IoU-76': 1.4723528676949789, 'IoU-77': 1.5217782214837314, 'IoU-78': 1.6036351589442384, 'IoU-79': 1.4346383197705668, 'IoU-80': 1.4623354462558737, 'IoU-81': 1.2608206868176957, 'IoU-82': 1.332244188173569, 'IoU-83': 1.3935978517698913, 'IoU-84': 1.4508237861522084, 'IoU-85': 1.526783216698343, 'IoU-86': 1.5081873445881362, 'IoU-87': 1.4570457738811902, 'IoU-88': 1.3369203243742158, 'IoU-89': 1.477959569954779, 'IoU-90': 1.2624320277687173, 'IoU-91': 1.034049122314406, 'IoU-92': 0.9601212431096813, 'IoU-93': 0.8953720770080449, 'IoU-94': 1.1209309284106126, 'IoU-95': 0.9175806287865341, 'IoU-96': 0.7966535387914787, 'IoU-97': 0.6887723670824136, 'IoU-98': 0.548621893945231, 'IoU-99': 0.6299126516012779, 'IoU-100': 0.6625572087210578, 'IoU-101': 0.7857062333029506, 'IoU-102': 0.6061597698473056, 'IoU-103': 0.3976609321987302, 'IoU-104': 0.7664265606576138, 'IoU-105': 0.5492421074301104, 'IoU-106': 0.4952783641028557, 'IoU-107': 0.5295827760608443, 'IoU-108': 0.41718290666615376, 'IoU-109': 0.506932426087133, 'IoU-110': 0.547006436126894, 'IoU-111': 0.6757566029817164, 'IoU-112': 0.5789142264825777, 'IoU-113': 0.2431698830614199, 'IoU-114': 0.33557226833156567, 'IoU-115': 0.2766084867994995, 'IoU-116': 0.469369769917803, 'IoU-117': 0.23075971361970635, 'IoU-118': 0.3703119611614145, 'IoU-119': 0.2066994816049667, 'IoU-120': 0.19237552701104052, 'IoU-121': 0.5067500953031956, 'IoU-122': 1.1579575180281882, 'IoU-123': 0.29836430031005146, 'IoU-124': 0.33168597510578574, 'IoU-125': 0.17858368140058076, 'IoU-126': 0.07496213952063782, 'IoU-127': 0.1031480566750185, 'IoU-128': 0.1778669392819563, 'IoU-129': 0.16306633257851416, 'IoU-130': 0.04050831854837658, 'IoU-131': 0.08735619239616489, 'IoU-132': 0.02822486549023346, 'IoU-133': 0.08208773389122745, 'IoU-134': 0.6283158411518369, 'IoU-135': 0.022658185093447424, 'IoU-136': 0.02117952715986853, 'IoU-137': 0.0033607303678300075, 'IoU-138': 0.0010398559452897125, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.9912318914797258, 'pACC': 6.257278468161144, 'ACC-0': 0.0, 'ACC-1': 33.752856634131554, 'ACC-2': 18.145926520879925, 'ACC-3': 6.329852501785091, 'ACC-4': 4.485629652276875, 'ACC-5': 3.837807724538896, 'ACC-6': 2.731974675641603, 'ACC-7': 1.856875635822659, 'ACC-8': 2.711402927266933, 'ACC-9': 1.376222589985032, 'ACC-10': 1.5723145364705353, 'ACC-11': 1.433472290615055, 'ACC-12': 1.2246248896734333, 'ACC-13': 0.9277583592540465, 'ACC-14': 0.8205597900311019, 'ACC-15': 0.6996162318417122, 'ACC-16': 0.600688182779414, 'ACC-17': 0.6033773769034175, 'ACC-18': 0.8417772873518208, 'ACC-19': 1.092456965845946, 'ACC-20': 1.5188158203302053, 'ACC-21': 1.8576275338223098, 'ACC-22': 2.181477407612632, 'ACC-23': 2.559322376920797, 'ACC-24': 3.143723100652028, 'ACC-25': 3.426424934787611, 'ACC-26': 3.5559008737445574, 'ACC-27': 3.73863712297494, 'ACC-28': 3.837850921757841, 'ACC-29': 4.303957936058564, 'ACC-30': 4.763577279799841, 'ACC-31': 4.634403031244385, 'ACC-32': 4.944079114230883, 'ACC-33': 4.938576052403006, 'ACC-34': 4.875216782913912, 'ACC-35': 4.88723191774233, 'ACC-36': 5.350969823546679, 'ACC-37': 5.502865037163896, 'ACC-38': 5.551127012995298, 'ACC-39': 5.491777685370535, 'ACC-40': 5.707472801157463, 'ACC-41': 5.554714869245664, 'ACC-42': 5.532661526106565, 'ACC-43': 5.581377754854197, 'ACC-44': 5.705608627890529, 'ACC-45': 5.550610863599017, 'ACC-46': 5.284100238476876, 'ACC-47': 5.3208861652750805, 'ACC-48': 5.076452104224588, 'ACC-49': 4.773231211257062, 'ACC-50': 4.710158885135699, 'ACC-51': 4.344145569302042, 'ACC-52': 4.0346742145674765, 'ACC-53': 3.714654274763196, 'ACC-54': 3.6265440397511255, 'ACC-55': 3.5942761510594132, 'ACC-56': 3.5378800603242, 'ACC-57': 3.409506596342652, 'ACC-58': 2.9954835704867495, 'ACC-59': 2.7094860303434203, 'ACC-60': 2.58659668393501, 'ACC-61': 2.421811562459934, 'ACC-62': 2.3391578684675958, 'ACC-63': 2.2405086126371803, 'ACC-64': 2.2658760954265498, 'ACC-65': 2.06077787729977, 'ACC-66': 2.2414270301562, 'ACC-67': 2.1828419361780784, 'ACC-68': 2.175888735195837, 'ACC-69': 2.299672737290885, 'ACC-70': 2.412980866783385, 'ACC-71': 2.495883195775748, 'ACC-72': 2.7787949007837343, 'ACC-73': 2.839935489260217, 'ACC-74': 2.763976768918009, 'ACC-75': 2.7682123399789678, 'ACC-76': 3.0245696040641223, 'ACC-77': 3.212131241814198, 'ACC-78': 3.5398743459353432, 'ACC-79': 3.121896278435617, 'ACC-80': 3.1350078307189104, 'ACC-81': 2.7204362909507522, 'ACC-82': 2.885155656325882, 'ACC-83': 3.086561620660208, 'ACC-84': 3.0977951376503587, 'ACC-85': 3.3483268086950124, 'ACC-86': 3.3568976874599414, 'ACC-87': 3.3492824137286394, 'ACC-88': 3.1756641093272044, 'ACC-89': 3.555724059586704, 'ACC-90': 2.761963270742276, 'ACC-91': 2.132783003270465, 'ACC-92': 1.8856723004482538, 'ACC-93': 1.8413028691743307, 'ACC-94': 2.3354005950599803, 'ACC-95': 2.0641453840318067, 'ACC-96': 1.5673114600834754, 'ACC-97': 1.3399296572455726, 'ACC-98': 1.1376374093077357, 'ACC-99': 1.3311213222390808, 'ACC-100': 1.3918859633117544, 'ACC-101': 1.5459419400210808, 'ACC-102': 1.4184186678749433, 'ACC-103': 0.8129309530556343, 'ACC-104': 1.548535451661297, 'ACC-105': 1.148829372928612, 'ACC-106': 0.9706212369251958, 'ACC-107': 0.9523941621085336, 'ACC-108': 0.7372816972679012, 'ACC-109': 0.9846020386033398, 'ACC-110': 1.010999440257331, 'ACC-111': 1.3049060745292602, 'ACC-112': 1.034974732055689, 'ACC-113': 0.4911043258585743, 'ACC-114': 0.6160721021196451, 'ACC-115': 0.5291446784839055, 'ACC-116': 0.8128160907794638, 'ACC-117': 0.423441748029256, 'ACC-118': 0.7128110754642594, 'ACC-119': 0.3123261608115162, 'ACC-120': 0.3521454650235261, 'ACC-121': 0.8054497878160106, 'ACC-122': 2.1359223300970873, 'ACC-123': 0.5592901874793997, 'ACC-124': 0.45751400697138833, 'ACC-125': 0.2661081640222632, 'ACC-126': 0.0927831765316624, 'ACC-127': 0.13135577381341756, 'ACC-128': 0.253692259092977, 'ACC-129': 0.322422953903809, 'ACC-130': 0.060106850891155, 'ACC-131': 0.1464066569505281, 'ACC-132': 0.04604357048788089, 'ACC-133': 0.13295501711268518, 'ACC-134': 0.9572425678586816, 'ACC-135': 0.03441936035573799, 'ACC-136': 0.03217596906448006, 'ACC-137': 0.006640121445531542, 'ACC-138': 0.001427773688351905, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/28 20:00:28] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 20:00:28] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 20:00:28] d2.evaluation.testing INFO: copypaste: 10.1906,0.8509,0.7229,0.9497,4.7007,1.9912,6.2573
[01/28 20:00:28] d2.utils.events INFO:  eta: 2 days, 0:51:50  iter: 1999  total_loss: 108.5  loss_mask: 10.92  loss_mask_0: 11.67  loss_mask_1: 10.74  loss_mask_2: 10.89  loss_mask_3: 10.94  loss_mask_4: 10.82  loss_mask_5: 10.77  loss_mask_6: 10.86  loss_mask_7: 10.84  loss_mask_8: 10.78  time: 3.0696  data_time: 0.0562  lr: 9.6996e-05  max_mem: 27632M
[01/28 20:01:29] d2.utils.events INFO:  eta: 2 days, 0:48:35  iter: 2019  total_loss: 109  loss_mask: 10.94  loss_mask_0: 11.81  loss_mask_1: 10.3  loss_mask_2: 10.63  loss_mask_3: 10.9  loss_mask_4: 10.65  loss_mask_5: 10.61  loss_mask_6: 10.87  loss_mask_7: 10.4  loss_mask_8: 11.29  time: 3.0694  data_time: 0.0579  lr: 9.6966e-05  max_mem: 27632M
[01/28 20:02:30] d2.utils.events INFO:  eta: 2 days, 0:47:35  iter: 2039  total_loss: 115.2  loss_mask: 11.49  loss_mask_0: 11.68  loss_mask_1: 10.79  loss_mask_2: 11.19  loss_mask_3: 11.66  loss_mask_4: 12.54  loss_mask_5: 11.48  loss_mask_6: 11.32  loss_mask_7: 10.99  loss_mask_8: 10.43  time: 3.0690  data_time: 0.0462  lr: 9.6936e-05  max_mem: 27632M
[01/28 20:03:31] d2.utils.events INFO:  eta: 2 days, 0:46:01  iter: 2059  total_loss: 97.88  loss_mask: 9.585  loss_mask_0: 10.5  loss_mask_1: 9.56  loss_mask_2: 9.621  loss_mask_3: 9.654  loss_mask_4: 10.28  loss_mask_5: 9.603  loss_mask_6: 9.585  loss_mask_7: 9.664  loss_mask_8: 9.616  time: 3.0687  data_time: 0.0465  lr: 9.6906e-05  max_mem: 27632M
[01/28 20:04:32] d2.utils.events INFO:  eta: 2 days, 0:44:55  iter: 2079  total_loss: 105.2  loss_mask: 10.43  loss_mask_0: 11.28  loss_mask_1: 10.11  loss_mask_2: 10.29  loss_mask_3: 10.24  loss_mask_4: 10.56  loss_mask_5: 10.16  loss_mask_6: 10.3  loss_mask_7: 10.55  loss_mask_8: 11.28  time: 3.0684  data_time: 0.0497  lr: 9.6876e-05  max_mem: 27632M
[01/28 20:05:32] d2.utils.events INFO:  eta: 2 days, 0:43:20  iter: 2099  total_loss: 103.9  loss_mask: 10.33  loss_mask_0: 10.41  loss_mask_1: 10.4  loss_mask_2: 10.37  loss_mask_3: 10.3  loss_mask_4: 10.31  loss_mask_5: 10.33  loss_mask_6: 10.27  loss_mask_7: 10.19  loss_mask_8: 10.46  time: 3.0678  data_time: 0.0526  lr: 9.6846e-05  max_mem: 27632M
[01/28 20:06:32] d2.utils.events INFO:  eta: 2 days, 0:41:05  iter: 2119  total_loss: 121.4  loss_mask: 11.77  loss_mask_0: 11.88  loss_mask_1: 11.21  loss_mask_2: 11.04  loss_mask_3: 11.39  loss_mask_4: 11.97  loss_mask_5: 11.84  loss_mask_6: 11.9  loss_mask_7: 11.88  loss_mask_8: 12  time: 3.0673  data_time: 0.0495  lr: 9.6816e-05  max_mem: 27632M
[01/28 20:07:33] d2.utils.events INFO:  eta: 2 days, 0:37:51  iter: 2139  total_loss: 105.3  loss_mask: 10.31  loss_mask_0: 11.46  loss_mask_1: 10.11  loss_mask_2: 10.64  loss_mask_3: 10.56  loss_mask_4: 10.57  loss_mask_5: 10.36  loss_mask_6: 10.27  loss_mask_7: 10.32  loss_mask_8: 10.72  time: 3.0670  data_time: 0.0470  lr: 9.6786e-05  max_mem: 27632M
[01/28 20:08:34] d2.utils.events INFO:  eta: 2 days, 0:36:27  iter: 2159  total_loss: 103.2  loss_mask: 9.985  loss_mask_0: 11.83  loss_mask_1: 10.24  loss_mask_2: 10.71  loss_mask_3: 11.35  loss_mask_4: 9.836  loss_mask_5: 9.666  loss_mask_6: 9.671  loss_mask_7: 9.729  loss_mask_8: 10.08  time: 3.0670  data_time: 0.0536  lr: 9.6756e-05  max_mem: 27632M
[01/28 20:09:35] d2.utils.events INFO:  eta: 2 days, 0:34:28  iter: 2179  total_loss: 91.11  loss_mask: 9.291  loss_mask_0: 9.499  loss_mask_1: 9.093  loss_mask_2: 9.229  loss_mask_3: 9.429  loss_mask_4: 8.974  loss_mask_5: 9.28  loss_mask_6: 8.728  loss_mask_7: 9.231  loss_mask_8: 8.727  time: 3.0668  data_time: 0.0547  lr: 9.6725e-05  max_mem: 27632M
[01/28 20:10:36] d2.utils.events INFO:  eta: 2 days, 0:34:26  iter: 2199  total_loss: 94.14  loss_mask: 9.365  loss_mask_0: 9.744  loss_mask_1: 9.443  loss_mask_2: 9.442  loss_mask_3: 9.684  loss_mask_4: 9.361  loss_mask_5: 9.309  loss_mask_6: 9.393  loss_mask_7: 9.329  loss_mask_8: 9.584  time: 3.0664  data_time: 0.0554  lr: 9.6695e-05  max_mem: 27632M
[01/28 20:11:37] d2.utils.events INFO:  eta: 2 days, 0:33:56  iter: 2219  total_loss: 105.6  loss_mask: 10.63  loss_mask_0: 10.85  loss_mask_1: 10.48  loss_mask_2: 10.68  loss_mask_3: 10.67  loss_mask_4: 10.58  loss_mask_5: 10.54  loss_mask_6: 10.57  loss_mask_7: 10.58  loss_mask_8: 10.62  time: 3.0662  data_time: 0.0498  lr: 9.6665e-05  max_mem: 27632M
[01/28 20:12:38] d2.utils.events INFO:  eta: 2 days, 0:32:58  iter: 2239  total_loss: 104.4  loss_mask: 10.09  loss_mask_0: 11.5  loss_mask_1: 9.916  loss_mask_2: 10.38  loss_mask_3: 10.2  loss_mask_4: 10.17  loss_mask_5: 10.12  loss_mask_6: 10.06  loss_mask_7: 9.974  loss_mask_8: 10.11  time: 3.0661  data_time: 0.0538  lr: 9.6635e-05  max_mem: 27632M
[01/28 20:13:38] d2.utils.events INFO:  eta: 2 days, 0:30:26  iter: 2259  total_loss: 90.78  loss_mask: 9.059  loss_mask_0: 9.716  loss_mask_1: 8.83  loss_mask_2: 8.946  loss_mask_3: 8.948  loss_mask_4: 8.998  loss_mask_5: 9.333  loss_mask_6: 9.113  loss_mask_7: 8.91  loss_mask_8: 8.885  time: 3.0658  data_time: 0.0489  lr: 9.6605e-05  max_mem: 27632M
[01/28 20:14:39] d2.utils.events INFO:  eta: 2 days, 0:30:16  iter: 2279  total_loss: 87.37  loss_mask: 8.488  loss_mask_0: 10.04  loss_mask_1: 8.237  loss_mask_2: 8.259  loss_mask_3: 8.55  loss_mask_4: 8.798  loss_mask_5: 9.062  loss_mask_6: 8.72  loss_mask_7: 8.479  loss_mask_8: 8.558  time: 3.0656  data_time: 0.0513  lr: 9.6575e-05  max_mem: 27632M
[01/28 20:15:40] d2.utils.events INFO:  eta: 2 days, 0:30:05  iter: 2299  total_loss: 93.48  loss_mask: 9.285  loss_mask_0: 9.878  loss_mask_1: 9.327  loss_mask_2: 9.2  loss_mask_3: 9.247  loss_mask_4: 9.459  loss_mask_5: 9.227  loss_mask_6: 9.242  loss_mask_7: 9.246  loss_mask_8: 9.277  time: 3.0653  data_time: 0.0497  lr: 9.6545e-05  max_mem: 27632M
[01/28 20:16:41] d2.utils.events INFO:  eta: 2 days, 0:28:53  iter: 2319  total_loss: 90.22  loss_mask: 8.727  loss_mask_0: 9.883  loss_mask_1: 8.722  loss_mask_2: 8.859  loss_mask_3: 8.995  loss_mask_4: 9.323  loss_mask_5: 9.86  loss_mask_6: 8.694  loss_mask_7: 8.739  loss_mask_8: 8.819  time: 3.0651  data_time: 0.0550  lr: 9.6515e-05  max_mem: 27632M
[01/28 20:17:42] d2.utils.events INFO:  eta: 2 days, 0:29:01  iter: 2339  total_loss: 84.9  loss_mask: 8.604  loss_mask_0: 9.03  loss_mask_1: 8.369  loss_mask_2: 8.489  loss_mask_3: 8.468  loss_mask_4: 8.398  loss_mask_5: 8.272  loss_mask_6: 8.307  loss_mask_7: 8.486  loss_mask_8: 8.517  time: 3.0651  data_time: 0.0579  lr: 9.6485e-05  max_mem: 27632M
[01/28 20:18:43] d2.utils.events INFO:  eta: 2 days, 0:27:49  iter: 2359  total_loss: 97.01  loss_mask: 9.489  loss_mask_0: 10.72  loss_mask_1: 9.586  loss_mask_2: 9.77  loss_mask_3: 9.628  loss_mask_4: 9.672  loss_mask_5: 9.849  loss_mask_6: 9.651  loss_mask_7: 9.673  loss_mask_8: 9.631  time: 3.0650  data_time: 0.0557  lr: 9.6454e-05  max_mem: 27632M
[01/28 20:19:44] d2.utils.events INFO:  eta: 2 days, 0:26:48  iter: 2379  total_loss: 104.8  loss_mask: 10.46  loss_mask_0: 11.9  loss_mask_1: 10.15  loss_mask_2: 10.61  loss_mask_3: 10.23  loss_mask_4: 10.08  loss_mask_5: 10.26  loss_mask_6: 10.44  loss_mask_7: 10.92  loss_mask_8: 10.79  time: 3.0648  data_time: 0.0455  lr: 9.6424e-05  max_mem: 27632M
[01/28 20:20:45] d2.utils.events INFO:  eta: 2 days, 0:24:51  iter: 2399  total_loss: 97.94  loss_mask: 9.689  loss_mask_0: 10.48  loss_mask_1: 9.556  loss_mask_2: 9.67  loss_mask_3: 9.67  loss_mask_4: 9.612  loss_mask_5: 9.778  loss_mask_6: 9.633  loss_mask_7: 9.542  loss_mask_8: 9.602  time: 3.0644  data_time: 0.0510  lr: 9.6394e-05  max_mem: 27632M
[01/28 20:21:45] d2.utils.events INFO:  eta: 2 days, 0:24:07  iter: 2419  total_loss: 91.32  loss_mask: 8.954  loss_mask_0: 9.549  loss_mask_1: 9.01  loss_mask_2: 9.029  loss_mask_3: 8.864  loss_mask_4: 9.05  loss_mask_5: 9.041  loss_mask_6: 9.013  loss_mask_7: 9.149  loss_mask_8: 9.129  time: 3.0642  data_time: 0.0523  lr: 9.6364e-05  max_mem: 27632M
[01/28 20:22:46] d2.utils.events INFO:  eta: 2 days, 0:22:12  iter: 2439  total_loss: 102.9  loss_mask: 10.42  loss_mask_0: 12.16  loss_mask_1: 9.813  loss_mask_2: 10.15  loss_mask_3: 10.22  loss_mask_4: 10.1  loss_mask_5: 10.33  loss_mask_6: 10.31  loss_mask_7: 10.32  loss_mask_8: 10.17  time: 3.0638  data_time: 0.0530  lr: 9.6334e-05  max_mem: 27632M
[01/28 20:23:46] d2.utils.events INFO:  eta: 2 days, 0:22:28  iter: 2459  total_loss: 94.88  loss_mask: 9.348  loss_mask_0: 10.63  loss_mask_1: 9.225  loss_mask_2: 9.27  loss_mask_3: 9.423  loss_mask_4: 9.53  loss_mask_5: 9.464  loss_mask_6: 9.284  loss_mask_7: 9.247  loss_mask_8: 9.532  time: 3.0636  data_time: 0.0465  lr: 9.6304e-05  max_mem: 27632M
[01/28 20:24:47] d2.utils.events INFO:  eta: 2 days, 0:21:51  iter: 2479  total_loss: 86.85  loss_mask: 8.669  loss_mask_0: 9.25  loss_mask_1: 8.607  loss_mask_2: 8.76  loss_mask_3: 8.864  loss_mask_4: 8.828  loss_mask_5: 8.675  loss_mask_6: 8.584  loss_mask_7: 8.402  loss_mask_8: 8.624  time: 3.0632  data_time: 0.0569  lr: 9.6274e-05  max_mem: 27632M
[01/28 20:25:48] d2.utils.events INFO:  eta: 2 days, 0:21:20  iter: 2499  total_loss: 86.89  loss_mask: 8.749  loss_mask_0: 9.401  loss_mask_1: 8.549  loss_mask_2: 8.614  loss_mask_3: 8.588  loss_mask_4: 8.637  loss_mask_5: 8.736  loss_mask_6: 8.571  loss_mask_7: 8.81  loss_mask_8: 8.554  time: 3.0630  data_time: 0.0531  lr: 9.6244e-05  max_mem: 27632M
[01/28 20:26:48] d2.utils.events INFO:  eta: 2 days, 0:20:00  iter: 2519  total_loss: 91.41  loss_mask: 9.011  loss_mask_0: 9.91  loss_mask_1: 8.937  loss_mask_2: 9.133  loss_mask_3: 9.055  loss_mask_4: 8.99  loss_mask_5: 9.063  loss_mask_6: 8.996  loss_mask_7: 8.98  loss_mask_8: 9.12  time: 3.0626  data_time: 0.0536  lr: 9.6213e-05  max_mem: 27632M
[01/28 20:27:49] d2.utils.events INFO:  eta: 2 days, 0:18:50  iter: 2539  total_loss: 95.04  loss_mask: 9.578  loss_mask_0: 10.27  loss_mask_1: 9.27  loss_mask_2: 9.48  loss_mask_3: 9.445  loss_mask_4: 9.352  loss_mask_5: 9.43  loss_mask_6: 9.387  loss_mask_7: 9.292  loss_mask_8: 9.337  time: 3.0625  data_time: 0.0503  lr: 9.6183e-05  max_mem: 27632M
[01/28 20:28:50] d2.utils.events INFO:  eta: 2 days, 0:17:43  iter: 2559  total_loss: 98.75  loss_mask: 9.863  loss_mask_0: 11.05  loss_mask_1: 9.773  loss_mask_2: 9.847  loss_mask_3: 9.924  loss_mask_4: 9.867  loss_mask_5: 9.82  loss_mask_6: 9.705  loss_mask_7: 9.64  loss_mask_8: 9.879  time: 3.0623  data_time: 0.0554  lr: 9.6153e-05  max_mem: 27632M
[01/28 20:29:51] d2.utils.events INFO:  eta: 2 days, 0:17:09  iter: 2579  total_loss: 109.3  loss_mask: 10.62  loss_mask_0: 11.28  loss_mask_1: 10.68  loss_mask_2: 10.74  loss_mask_3: 10.86  loss_mask_4: 10.58  loss_mask_5: 10.67  loss_mask_6: 10.72  loss_mask_7: 10.59  loss_mask_8: 10.79  time: 3.0622  data_time: 0.0505  lr: 9.6123e-05  max_mem: 27632M
[01/28 20:30:52] d2.utils.events INFO:  eta: 2 days, 0:15:56  iter: 2599  total_loss: 93.48  loss_mask: 9.422  loss_mask_0: 10.28  loss_mask_1: 9.285  loss_mask_2: 9.176  loss_mask_3: 9.065  loss_mask_4: 9.166  loss_mask_5: 9.288  loss_mask_6: 9.284  loss_mask_7: 9.664  loss_mask_8: 9.258  time: 3.0621  data_time: 0.0564  lr: 9.6093e-05  max_mem: 27632M
[01/28 20:31:53] d2.utils.events INFO:  eta: 2 days, 0:15:36  iter: 2619  total_loss: 85.8  loss_mask: 8.591  loss_mask_0: 8.738  loss_mask_1: 8.52  loss_mask_2: 8.422  loss_mask_3: 8.661  loss_mask_4: 8.481  loss_mask_5: 8.55  loss_mask_6: 8.418  loss_mask_7: 8.677  loss_mask_8: 8.741  time: 3.0620  data_time: 0.0562  lr: 9.6063e-05  max_mem: 27632M
[01/28 20:32:54] d2.utils.events INFO:  eta: 2 days, 0:16:45  iter: 2639  total_loss: 106.5  loss_mask: 11.38  loss_mask_0: 11.58  loss_mask_1: 10.67  loss_mask_2: 9.695  loss_mask_3: 10.44  loss_mask_4: 10.62  loss_mask_5: 10.05  loss_mask_6: 10.42  loss_mask_7: 11.56  loss_mask_8: 11.31  time: 3.0619  data_time: 0.0572  lr: 9.6033e-05  max_mem: 27632M
[01/28 20:33:55] d2.utils.events INFO:  eta: 2 days, 0:15:57  iter: 2659  total_loss: 95.58  loss_mask: 9.472  loss_mask_0: 9.669  loss_mask_1: 9.305  loss_mask_2: 9.597  loss_mask_3: 9.855  loss_mask_4: 9.602  loss_mask_5: 9.622  loss_mask_6: 9.458  loss_mask_7: 9.565  loss_mask_8: 9.491  time: 3.0619  data_time: 0.0519  lr: 9.6003e-05  max_mem: 27632M
[01/28 20:34:56] d2.utils.events INFO:  eta: 2 days, 0:15:00  iter: 2679  total_loss: 86.98  loss_mask: 8.541  loss_mask_0: 9.284  loss_mask_1: 8.606  loss_mask_2: 8.556  loss_mask_3: 8.651  loss_mask_4: 8.757  loss_mask_5: 8.597  loss_mask_6: 8.667  loss_mask_7: 8.68  loss_mask_8: 8.615  time: 3.0616  data_time: 0.0521  lr: 9.5972e-05  max_mem: 27632M
[01/28 20:35:56] d2.utils.events INFO:  eta: 2 days, 0:14:57  iter: 2699  total_loss: 78.39  loss_mask: 7.717  loss_mask_0: 8.443  loss_mask_1: 7.602  loss_mask_2: 7.713  loss_mask_3: 7.913  loss_mask_4: 7.638  loss_mask_5: 7.757  loss_mask_6: 7.675  loss_mask_7: 7.838  loss_mask_8: 7.745  time: 3.0614  data_time: 0.0556  lr: 9.5942e-05  max_mem: 27632M
[01/28 20:36:57] d2.utils.events INFO:  eta: 2 days, 0:14:05  iter: 2719  total_loss: 80.93  loss_mask: 7.88  loss_mask_0: 8.557  loss_mask_1: 7.984  loss_mask_2: 8.109  loss_mask_3: 8.018  loss_mask_4: 8.174  loss_mask_5: 8.209  loss_mask_6: 8.068  loss_mask_7: 7.925  loss_mask_8: 7.827  time: 3.0612  data_time: 0.0490  lr: 9.5912e-05  max_mem: 27632M
[01/28 20:37:59] d2.utils.events INFO:  eta: 2 days, 0:13:59  iter: 2739  total_loss: 86.99  loss_mask: 8.64  loss_mask_0: 9.398  loss_mask_1: 8.571  loss_mask_2: 8.674  loss_mask_3: 8.641  loss_mask_4: 8.729  loss_mask_5: 8.725  loss_mask_6: 8.681  loss_mask_7: 8.656  loss_mask_8: 8.669  time: 3.0613  data_time: 0.0569  lr: 9.5882e-05  max_mem: 27632M
[01/28 20:39:00] d2.utils.events INFO:  eta: 2 days, 0:13:42  iter: 2759  total_loss: 84.76  loss_mask: 8.443  loss_mask_0: 9.112  loss_mask_1: 8.42  loss_mask_2: 8.462  loss_mask_3: 8.56  loss_mask_4: 8.619  loss_mask_5: 8.535  loss_mask_6: 8.289  loss_mask_7: 8.323  loss_mask_8: 8.329  time: 3.0613  data_time: 0.0498  lr: 9.5852e-05  max_mem: 27632M
[01/28 20:40:01] d2.utils.events INFO:  eta: 2 days, 0:13:02  iter: 2779  total_loss: 89.07  loss_mask: 8.819  loss_mask_0: 10.06  loss_mask_1: 8.488  loss_mask_2: 8.68  loss_mask_3: 8.688  loss_mask_4: 8.589  loss_mask_5: 8.959  loss_mask_6: 8.939  loss_mask_7: 8.64  loss_mask_8: 8.839  time: 3.0612  data_time: 0.0600  lr: 9.5822e-05  max_mem: 27632M
[01/28 20:41:01] d2.utils.events INFO:  eta: 2 days, 0:11:44  iter: 2799  total_loss: 89.55  loss_mask: 8.924  loss_mask_0: 10.04  loss_mask_1: 8.634  loss_mask_2: 8.723  loss_mask_3: 8.879  loss_mask_4: 8.822  loss_mask_5: 8.952  loss_mask_6: 8.841  loss_mask_7: 8.935  loss_mask_8: 8.861  time: 3.0609  data_time: 0.0482  lr: 9.5792e-05  max_mem: 27632M
[01/28 20:42:02] d2.utils.events INFO:  eta: 2 days, 0:12:20  iter: 2819  total_loss: 79.63  loss_mask: 7.864  loss_mask_0: 8.496  loss_mask_1: 7.874  loss_mask_2: 7.799  loss_mask_3: 7.827  loss_mask_4: 7.782  loss_mask_5: 8.041  loss_mask_6: 7.776  loss_mask_7: 8.007  loss_mask_8: 7.886  time: 3.0608  data_time: 0.0537  lr: 9.5761e-05  max_mem: 27632M
[01/28 20:43:03] d2.utils.events INFO:  eta: 2 days, 0:11:31  iter: 2839  total_loss: 102.3  loss_mask: 10.02  loss_mask_0: 10.85  loss_mask_1: 9.827  loss_mask_2: 10.1  loss_mask_3: 10.1  loss_mask_4: 9.896  loss_mask_5: 10.04  loss_mask_6: 9.925  loss_mask_7: 10.02  loss_mask_8: 10.01  time: 3.0608  data_time: 0.0555  lr: 9.5731e-05  max_mem: 27632M
[01/28 20:44:04] d2.utils.events INFO:  eta: 2 days, 0:10:47  iter: 2859  total_loss: 81.17  loss_mask: 8.242  loss_mask_0: 8.47  loss_mask_1: 8.008  loss_mask_2: 8.455  loss_mask_3: 7.95  loss_mask_4: 8.024  loss_mask_5: 8.193  loss_mask_6: 8.254  loss_mask_7: 8.053  loss_mask_8: 8.133  time: 3.0606  data_time: 0.0518  lr: 9.5701e-05  max_mem: 27632M
[01/28 20:45:06] d2.utils.events INFO:  eta: 2 days, 0:10:02  iter: 2879  total_loss: 80.94  loss_mask: 8.116  loss_mask_0: 8.499  loss_mask_1: 7.824  loss_mask_2: 8.09  loss_mask_3: 8.034  loss_mask_4: 8.078  loss_mask_5: 8.187  loss_mask_6: 7.965  loss_mask_7: 8.114  loss_mask_8: 8.037  time: 3.0607  data_time: 0.0592  lr: 9.5671e-05  max_mem: 27632M
[01/28 20:46:07] d2.utils.events INFO:  eta: 2 days, 0:09:02  iter: 2899  total_loss: 83.42  loss_mask: 8.226  loss_mask_0: 9.112  loss_mask_1: 8.163  loss_mask_2: 8.457  loss_mask_3: 8.176  loss_mask_4: 8.107  loss_mask_5: 8.264  loss_mask_6: 8.179  loss_mask_7: 8.367  loss_mask_8: 8.136  time: 3.0606  data_time: 0.0583  lr: 9.5641e-05  max_mem: 27632M
[01/28 20:47:07] d2.utils.events INFO:  eta: 2 days, 0:07:37  iter: 2919  total_loss: 81.05  loss_mask: 8.048  loss_mask_0: 8.477  loss_mask_1: 8.082  loss_mask_2: 7.945  loss_mask_3: 8.098  loss_mask_4: 8.153  loss_mask_5: 8.157  loss_mask_6: 7.976  loss_mask_7: 8.07  loss_mask_8: 8.095  time: 3.0604  data_time: 0.0514  lr: 9.5611e-05  max_mem: 27632M
[01/28 20:48:08] d2.utils.events INFO:  eta: 2 days, 0:06:25  iter: 2939  total_loss: 81.98  loss_mask: 8.073  loss_mask_0: 8.489  loss_mask_1: 8.087  loss_mask_2: 8.059  loss_mask_3: 8.097  loss_mask_4: 8.095  loss_mask_5: 8.098  loss_mask_6: 8.037  loss_mask_7: 8.067  loss_mask_8: 8.027  time: 3.0603  data_time: 0.0577  lr: 9.5581e-05  max_mem: 27632M
[01/28 20:49:09] d2.utils.events INFO:  eta: 2 days, 0:05:00  iter: 2959  total_loss: 91.12  loss_mask: 9.172  loss_mask_0: 9.756  loss_mask_1: 8.991  loss_mask_2: 8.994  loss_mask_3: 9.026  loss_mask_4: 8.971  loss_mask_5: 9.134  loss_mask_6: 8.993  loss_mask_7: 8.963  loss_mask_8: 8.947  time: 3.0601  data_time: 0.0473  lr: 9.555e-05  max_mem: 27632M
[01/28 20:50:09] d2.utils.events INFO:  eta: 2 days, 0:02:13  iter: 2979  total_loss: 93.16  loss_mask: 9.157  loss_mask_0: 10.18  loss_mask_1: 9.185  loss_mask_2: 9.268  loss_mask_3: 9.249  loss_mask_4: 9.142  loss_mask_5: 9.458  loss_mask_6: 9.038  loss_mask_7: 9.097  loss_mask_8: 9.221  time: 3.0597  data_time: 0.0516  lr: 9.552e-05  max_mem: 27632M
[01/28 20:51:11] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 20:51:12] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 20:51:12] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 21:04:55] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 8.099260779326958, 'error_1pix': 0.8150137042261142, 'error_3pix': 0.6395327312661931, 'mIoU': 1.2908695229329539, 'fwIoU': 5.12241723884581, 'IoU-0': 0.0, 'IoU-1': 31.646247331458277, 'IoU-2': 2.1024773745002756, 'IoU-3': 0.12037821382350287, 'IoU-4': 0.19549536043781565, 'IoU-5': 0.21871764424365553, 'IoU-6': 0.21850776540099617, 'IoU-7': 0.19043856603501588, 'IoU-8': 0.4026419904035566, 'IoU-9': 0.42466951572473643, 'IoU-10': 0.6102214839308516, 'IoU-11': 0.6019550972532648, 'IoU-12': 0.5065870745310734, 'IoU-13': 0.5838285434288106, 'IoU-14': 0.8734752155232735, 'IoU-15': 1.319636799649284, 'IoU-16': 1.3367891062526143, 'IoU-17': 1.4177319385871605, 'IoU-18': 1.9719175774538091, 'IoU-19': 2.9407530902578607, 'IoU-20': 2.9311430967174394, 'IoU-21': 3.069204417568497, 'IoU-22': 3.1789774331499294, 'IoU-23': 2.8673993567011706, 'IoU-24': 2.9720888372437444, 'IoU-25': 2.912734828547323, 'IoU-26': 2.741886855958241, 'IoU-27': 2.8172890883314508, 'IoU-28': 2.8976486172490086, 'IoU-29': 3.175194186935922, 'IoU-30': 3.019756469669281, 'IoU-31': 2.9744963584205926, 'IoU-32': 3.079687458583387, 'IoU-33': 3.04402603822502, 'IoU-34': 2.9077396837005427, 'IoU-35': 2.8503216413945496, 'IoU-36': 2.957753348380026, 'IoU-37': 2.986013273766356, 'IoU-38': 2.883877176484452, 'IoU-39': 3.076119585109994, 'IoU-40': 3.018588621316481, 'IoU-41': 2.7830225204361048, 'IoU-42': 2.7972554839681414, 'IoU-43': 2.7870284923758204, 'IoU-44': 2.903308600018109, 'IoU-45': 2.6749168760572437, 'IoU-46': 2.583996904768659, 'IoU-47': 2.4926017174569717, 'IoU-48': 2.4833003312022877, 'IoU-49': 2.4069083580871, 'IoU-50': 2.3022510237152187, 'IoU-51': 2.188288311531283, 'IoU-52': 2.133526480174196, 'IoU-53': 2.0563961624117693, 'IoU-54': 2.0575409821219806, 'IoU-55': 2.020113132903187, 'IoU-56': 1.9697156711019248, 'IoU-57': 1.9267388485376562, 'IoU-58': 1.8804773431974275, 'IoU-59': 1.8170775793301717, 'IoU-60': 1.8469377719043198, 'IoU-61': 1.8029441527568308, 'IoU-62': 1.6525833455120726, 'IoU-63': 1.566767365077994, 'IoU-64': 1.574407640033513, 'IoU-65': 1.6260081057372047, 'IoU-66': 1.6293508832937225, 'IoU-67': 1.5353773002441864, 'IoU-68': 1.474862176008247, 'IoU-69': 1.5751198931567008, 'IoU-70': 1.5691308150987908, 'IoU-71': 1.6275780087328964, 'IoU-72': 1.6478378973080687, 'IoU-73': 1.7059531852801149, 'IoU-74': 1.740476513959469, 'IoU-75': 1.7707756652330968, 'IoU-76': 1.8882059844902999, 'IoU-77': 1.942100538826873, 'IoU-78': 2.033547167845566, 'IoU-79': 1.9767612621323978, 'IoU-80': 2.083817032849018, 'IoU-81': 2.1274502536616886, 'IoU-82': 2.3649324729841603, 'IoU-83': 2.468738635613022, 'IoU-84': 2.584401147485512, 'IoU-85': 2.443490311244175, 'IoU-86': 2.411698464835924, 'IoU-87': 2.4190064160458418, 'IoU-88': 2.504931310593554, 'IoU-89': 2.4778377943264753, 'IoU-90': 2.5411173795257946, 'IoU-91': 2.2712006456386504, 'IoU-92': 1.9131474367682841, 'IoU-93': 1.9045942580724722, 'IoU-94': 1.6611782478255632, 'IoU-95': 1.4828898139369122, 'IoU-96': 1.503592329467807, 'IoU-97': 1.3366523488459938, 'IoU-98': 1.0799327658928124, 'IoU-99': 1.1426973775365354, 'IoU-100': 1.1722878788914248, 'IoU-101': 1.0009846452626783, 'IoU-102': 0.8008505340665164, 'IoU-103': 0.8438008706211544, 'IoU-104': 0.7222383017003855, 'IoU-105': 0.7428955813626382, 'IoU-106': 0.8415441478176682, 'IoU-107': 0.7113198605088739, 'IoU-108': 0.7172217008736724, 'IoU-109': 0.5348917654813488, 'IoU-110': 0.439156653366721, 'IoU-111': 0.503258145053431, 'IoU-112': 0.42710219644745506, 'IoU-113': 0.4288122557866982, 'IoU-114': 0.5997983446959728, 'IoU-115': 0.6022543493599397, 'IoU-116': 0.4443499116602916, 'IoU-117': 0.48204563868959915, 'IoU-118': 0.3695698650819898, 'IoU-119': 0.4665496715767574, 'IoU-120': 0.47146670067177804, 'IoU-121': 0.7222471296180639, 'IoU-122': 0.534605968980458, 'IoU-123': 0.4501282070401148, 'IoU-124': 0.7100704419691015, 'IoU-125': 0.3588777486678839, 'IoU-126': 0.3147289819098311, 'IoU-127': 0.3619005747354442, 'IoU-128': 0.31845492331860403, 'IoU-129': 0.309512021903733, 'IoU-130': 0.3061582305148357, 'IoU-131': 0.5471361018429354, 'IoU-132': 0.37854981654501946, 'IoU-133': 0.13199782591816137, 'IoU-134': 0.1092232175737004, 'IoU-135': 0.18439796880502574, 'IoU-136': 0.16302960488917204, 'IoU-137': 0.144628399494164, 'IoU-138': 0.21039492514981084, 'IoU-139': 0.017436465501741837, 'IoU-140': 0.029924491561293377, 'IoU-141': 0.07889207245592131, 'IoU-142': 0.0545934271337311, 'IoU-143': 0.09899210672015815, 'IoU-144': 0.060625257307133466, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.7653593263563505, 'pACC': 7.2519441972483545, 'ACC-0': 0.0, 'ACC-1': 31.856432057046728, 'ACC-2': 26.182723768445214, 'ACC-3': 4.355160357803911, 'ACC-4': 3.9292672886017455, 'ACC-5': 3.146093304905128, 'ACC-6': 2.4139542664576426, 'ACC-7': 1.7629835442714885, 'ACC-8': 1.2538767243303386, 'ACC-9': 0.6462823936540529, 'ACC-10': 0.7287124811883829, 'ACC-11': 0.650172682715325, 'ACC-12': 0.5409564816207162, 'ACC-13': 0.631737573617097, 'ACC-14': 1.0022293887518314, 'ACC-15': 1.7431550523395112, 'ACC-16': 2.177804835541593, 'ACC-17': 3.0102924596189142, 'ACC-18': 4.588097662485892, 'ACC-19': 7.1478550847210105, 'ACC-20': 7.2861682960811285, 'ACC-21': 7.301001766047706, 'ACC-22': 6.971222196019141, 'ACC-23': 6.368132852181333, 'ACC-24': 6.507662628035135, 'ACC-25': 6.265889426449483, 'ACC-26': 5.758175057569222, 'ACC-27': 5.618407515393684, 'ACC-28': 5.801848181512358, 'ACC-29': 6.130397186145382, 'ACC-30': 5.904451506687167, 'ACC-31': 5.719915302849414, 'ACC-32': 6.025737937466682, 'ACC-33': 6.103186313275715, 'ACC-34': 5.8341269753507925, 'ACC-35': 5.58024245166103, 'ACC-36': 5.7181461210017615, 'ACC-37': 5.871622372199536, 'ACC-38': 5.718672475560719, 'ACC-39': 6.197688650718185, 'ACC-40': 6.1709147107973354, 'ACC-41': 5.994870304826685, 'ACC-42': 6.092617540723439, 'ACC-43': 6.060758419152043, 'ACC-44': 6.115590742507269, 'ACC-45': 5.68836134968761, 'ACC-46': 5.626272373925156, 'ACC-47': 5.396693309004616, 'ACC-48': 5.333477909795967, 'ACC-49': 5.07964465883377, 'ACC-50': 4.795135480780379, 'ACC-51': 4.571474424334862, 'ACC-52': 4.413525598546722, 'ACC-53': 4.221366238375449, 'ACC-54': 4.161787626530147, 'ACC-55': 4.091552422005748, 'ACC-56': 4.0439236057911945, 'ACC-57': 3.909355570670361, 'ACC-58': 3.86178828000256, 'ACC-59': 3.805599536958102, 'ACC-60': 3.911876509085536, 'ACC-61': 3.8623361975939146, 'ACC-62': 3.5750124603669198, 'ACC-63': 3.4130978046739773, 'ACC-64': 3.417537798438567, 'ACC-65': 3.5439666014965225, 'ACC-66': 3.553838851592641, 'ACC-67': 3.367830201515402, 'ACC-68': 3.229179352815734, 'ACC-69': 3.3743743670585404, 'ACC-70': 3.330807202565046, 'ACC-71': 3.5083937599887975, 'ACC-72': 3.5419267012161826, 'ACC-73': 3.6336018923621776, 'ACC-74': 3.6713993799975966, 'ACC-75': 3.752761430931739, 'ACC-76': 3.957198273798706, 'ACC-77': 4.187539393918223, 'ACC-78': 4.4772108089737435, 'ACC-79': 4.409368852076484, 'ACC-80': 4.664627056413797, 'ACC-81': 4.839997473731797, 'ACC-82': 5.471356927301125, 'ACC-83': 5.677879960766066, 'ACC-84': 6.025555366653084, 'ACC-85': 5.837352501281088, 'ACC-86': 5.864482531882435, 'ACC-87': 6.045944509532744, 'ACC-88': 6.279612781887793, 'ACC-89': 6.1527732202961145, 'ACC-90': 6.429730439513028, 'ACC-91': 5.873651242746777, 'ACC-92': 4.9001770235164415, 'ACC-93': 4.796276792668613, 'ACC-94': 4.173311219289091, 'ACC-95': 3.6563529963578443, 'ACC-96': 3.742379725519408, 'ACC-97': 3.1782303505204488, 'ACC-98': 2.520924054181841, 'ACC-99': 2.667102229469603, 'ACC-100': 2.6777626673867756, 'ACC-101': 2.260837455787857, 'ACC-102': 1.8744676030811056, 'ACC-103': 1.881080570511004, 'ACC-104': 1.6060598608002754, 'ACC-105': 1.6119315008283637, 'ACC-106': 1.793584276224408, 'ACC-107': 1.504183909246374, 'ACC-108': 1.431008557033208, 'ACC-109': 1.169128100889745, 'ACC-110': 0.9311781484170183, 'ACC-111': 1.0201571290186002, 'ACC-112': 0.8599042133704895, 'ACC-113': 0.9116397134935786, 'ACC-114': 1.2732156777139334, 'ACC-115': 1.2091997053207644, 'ACC-116': 0.8892202530769968, 'ACC-117': 0.9744223182491419, 'ACC-118': 0.7352320635244534, 'ACC-119': 0.8718283261213525, 'ACC-120': 0.935423453054885, 'ACC-121': 1.5153793081207672, 'ACC-122': 1.1922688631624634, 'ACC-123': 1.0127420465826802, 'ACC-124': 1.5530863816065303, 'ACC-125': 0.7064674127629674, 'ACC-126': 0.6106612992832358, 'ACC-127': 0.6500037380033455, 'ACC-128': 0.6367919638098235, 'ACC-129': 0.6139716195007527, 'ACC-130': 0.642472584310822, 'ACC-131': 1.0463124861684587, 'ACC-132': 0.747621584850526, 'ACC-133': 0.267202841454204, 'ACC-134': 0.18626454114605775, 'ACC-135': 0.28917963628071375, 'ACC-136': 0.2766259783824077, 'ACC-137': 0.21263653272702154, 'ACC-138': 0.2946766251237404, 'ACC-139': 0.023693321516733305, 'ACC-140': 0.04016982310369446, 'ACC-141': 0.0957688352388919, 'ACC-142': 0.08366366507985164, 'ACC-143': 0.12274756863664832, 'ACC-144': 0.07030685920577617, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/28 21:04:55] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 21:04:55] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 21:04:55] d2.evaluation.testing INFO: copypaste: 8.0993,0.8150,0.6395,1.2909,5.1224,2.7654,7.2519
[01/28 21:04:56] d2.utils.events INFO:  eta: 2 days, 0:01:13  iter: 2999  total_loss: 77.58  loss_mask: 7.635  loss_mask_0: 8.361  loss_mask_1: 7.483  loss_mask_2: 7.604  loss_mask_3: 7.769  loss_mask_4: 7.674  loss_mask_5: 7.625  loss_mask_6: 7.672  loss_mask_7: 8.173  loss_mask_8: 7.814  time: 3.0599  data_time: 0.0610  lr: 9.549e-05  max_mem: 27632M
[01/28 21:05:57] d2.utils.events INFO:  eta: 2 days, 0:00:43  iter: 3019  total_loss: 86.83  loss_mask: 8.633  loss_mask_0: 8.74  loss_mask_1: 8.496  loss_mask_2: 8.621  loss_mask_3: 8.478  loss_mask_4: 8.646  loss_mask_5: 8.581  loss_mask_6: 8.647  loss_mask_7: 7.967  loss_mask_8: 8.178  time: 3.0599  data_time: 0.0779  lr: 9.546e-05  max_mem: 27632M
[01/28 21:06:59] d2.utils.events INFO:  eta: 2 days, 0:00:06  iter: 3039  total_loss: 82.4  loss_mask: 8.206  loss_mask_0: 8.57  loss_mask_1: 8.244  loss_mask_2: 8.21  loss_mask_3: 8.13  loss_mask_4: 8.219  loss_mask_5: 8.254  loss_mask_6: 8.166  loss_mask_7: 8.148  loss_mask_8: 8.193  time: 3.0600  data_time: 0.0612  lr: 9.543e-05  max_mem: 27632M
[01/28 21:08:00] d2.utils.events INFO:  eta: 1 day, 23:59:44  iter: 3059  total_loss: 82.82  loss_mask: 8.327  loss_mask_0: 8.437  loss_mask_1: 8.308  loss_mask_2: 8.29  loss_mask_3: 8.14  loss_mask_4: 8.173  loss_mask_5: 8.305  loss_mask_6: 8.34  loss_mask_7: 8.111  loss_mask_8: 8.147  time: 3.0601  data_time: 0.0629  lr: 9.54e-05  max_mem: 27632M
[01/28 21:09:02] d2.utils.events INFO:  eta: 1 day, 23:59:39  iter: 3079  total_loss: 96.66  loss_mask: 9.63  loss_mask_0: 10.67  loss_mask_1: 9.534  loss_mask_2: 9.572  loss_mask_3: 9.495  loss_mask_4: 9.655  loss_mask_5: 9.519  loss_mask_6: 9.5  loss_mask_7: 9.315  loss_mask_8: 9.368  time: 3.0603  data_time: 0.0737  lr: 9.5369e-05  max_mem: 27632M
[01/28 21:10:03] d2.utils.events INFO:  eta: 1 day, 23:59:30  iter: 3099  total_loss: 102.1  loss_mask: 10.46  loss_mask_0: 9.843  loss_mask_1: 9.954  loss_mask_2: 10.63  loss_mask_3: 9.835  loss_mask_4: 10.19  loss_mask_5: 10.37  loss_mask_6: 10.26  loss_mask_7: 10.02  loss_mask_8: 10.18  time: 3.0603  data_time: 0.0606  lr: 9.5339e-05  max_mem: 27632M
[01/28 21:11:05] d2.utils.events INFO:  eta: 1 day, 23:59:52  iter: 3119  total_loss: 88.81  loss_mask: 8.658  loss_mask_0: 9.833  loss_mask_1: 8.708  loss_mask_2: 8.715  loss_mask_3: 8.761  loss_mask_4: 8.604  loss_mask_5: 8.633  loss_mask_6: 8.769  loss_mask_7: 8.676  loss_mask_8: 8.67  time: 3.0604  data_time: 0.0639  lr: 9.5309e-05  max_mem: 27632M
[01/28 21:12:06] d2.utils.events INFO:  eta: 1 day, 23:58:59  iter: 3139  total_loss: 70.45  loss_mask: 6.972  loss_mask_0: 7.549  loss_mask_1: 6.949  loss_mask_2: 6.912  loss_mask_3: 7.058  loss_mask_4: 6.908  loss_mask_5: 6.945  loss_mask_6: 7.002  loss_mask_7: 7.019  loss_mask_8: 6.953  time: 3.0602  data_time: 0.0621  lr: 9.5279e-05  max_mem: 27632M
[01/28 21:13:07] d2.utils.events INFO:  eta: 1 day, 23:58:58  iter: 3159  total_loss: 80.4  loss_mask: 8.086  loss_mask_0: 9.284  loss_mask_1: 7.873  loss_mask_2: 7.923  loss_mask_3: 7.938  loss_mask_4: 7.93  loss_mask_5: 8.052  loss_mask_6: 8.006  loss_mask_7: 8.021  loss_mask_8: 7.969  time: 3.0602  data_time: 0.0636  lr: 9.5249e-05  max_mem: 27632M
[01/28 21:14:08] d2.utils.events INFO:  eta: 1 day, 23:57:49  iter: 3179  total_loss: 75.48  loss_mask: 7.512  loss_mask_0: 7.946  loss_mask_1: 7.526  loss_mask_2: 7.542  loss_mask_3: 7.529  loss_mask_4: 7.521  loss_mask_5: 7.522  loss_mask_6: 7.445  loss_mask_7: 7.503  loss_mask_8: 7.566  time: 3.0602  data_time: 0.0644  lr: 9.5219e-05  max_mem: 27632M
[01/28 21:15:09] d2.utils.events INFO:  eta: 1 day, 23:57:07  iter: 3199  total_loss: 82.57  loss_mask: 8.25  loss_mask_0: 8.262  loss_mask_1: 8.296  loss_mask_2: 8.226  loss_mask_3: 8.185  loss_mask_4: 8.21  loss_mask_5: 8.338  loss_mask_6: 8.161  loss_mask_7: 8.17  loss_mask_8: 8.219  time: 3.0601  data_time: 0.0566  lr: 9.5188e-05  max_mem: 27632M
[01/28 21:16:10] d2.utils.events INFO:  eta: 1 day, 23:56:34  iter: 3219  total_loss: 82.37  loss_mask: 8.271  loss_mask_0: 8.881  loss_mask_1: 8.325  loss_mask_2: 8.036  loss_mask_3: 8.154  loss_mask_4: 8.184  loss_mask_5: 8.225  loss_mask_6: 8.115  loss_mask_7: 8.258  loss_mask_8: 8.123  time: 3.0600  data_time: 0.0646  lr: 9.5158e-05  max_mem: 27632M
[01/28 21:17:11] d2.utils.events INFO:  eta: 1 day, 23:55:54  iter: 3239  total_loss: 77.04  loss_mask: 7.654  loss_mask_0: 8.375  loss_mask_1: 7.529  loss_mask_2: 7.616  loss_mask_3: 7.653  loss_mask_4: 7.537  loss_mask_5: 7.69  loss_mask_6: 7.591  loss_mask_7: 7.629  loss_mask_8: 7.634  time: 3.0600  data_time: 0.0584  lr: 9.5128e-05  max_mem: 27632M
[01/28 21:18:12] d2.utils.events INFO:  eta: 1 day, 23:55:15  iter: 3259  total_loss: 69.59  loss_mask: 6.971  loss_mask_0: 7.309  loss_mask_1: 6.86  loss_mask_2: 6.923  loss_mask_3: 6.924  loss_mask_4: 6.889  loss_mask_5: 6.903  loss_mask_6: 6.936  loss_mask_7: 6.894  loss_mask_8: 6.9  time: 3.0600  data_time: 0.0585  lr: 9.5098e-05  max_mem: 27632M
[01/28 21:19:13] d2.utils.events INFO:  eta: 1 day, 23:53:58  iter: 3279  total_loss: 76.92  loss_mask: 7.701  loss_mask_0: 7.64  loss_mask_1: 7.657  loss_mask_2: 7.648  loss_mask_3: 7.676  loss_mask_4: 7.568  loss_mask_5: 7.663  loss_mask_6: 7.511  loss_mask_7: 7.574  loss_mask_8: 7.572  time: 3.0599  data_time: 0.0574  lr: 9.5068e-05  max_mem: 27632M
[01/28 21:20:14] d2.utils.events INFO:  eta: 1 day, 23:52:52  iter: 3299  total_loss: 71.28  loss_mask: 7.066  loss_mask_0: 8.37  loss_mask_1: 7.103  loss_mask_2: 7.182  loss_mask_3: 7.106  loss_mask_4: 7.065  loss_mask_5: 7.079  loss_mask_6: 7.103  loss_mask_7: 7.013  loss_mask_8: 7.163  time: 3.0597  data_time: 0.0675  lr: 9.5038e-05  max_mem: 27632M
[01/28 21:21:15] d2.utils.events INFO:  eta: 1 day, 23:51:55  iter: 3319  total_loss: 70.61  loss_mask: 6.998  loss_mask_0: 7.788  loss_mask_1: 6.994  loss_mask_2: 7.048  loss_mask_3: 6.881  loss_mask_4: 7.012  loss_mask_5: 7.033  loss_mask_6: 6.97  loss_mask_7: 6.957  loss_mask_8: 6.908  time: 3.0597  data_time: 0.0608  lr: 9.5007e-05  max_mem: 27632M
[01/28 21:22:16] d2.utils.events INFO:  eta: 1 day, 23:50:04  iter: 3339  total_loss: 70.47  loss_mask: 6.996  loss_mask_0: 7.153  loss_mask_1: 7.053  loss_mask_2: 6.978  loss_mask_3: 7.038  loss_mask_4: 7.067  loss_mask_5: 6.93  loss_mask_6: 6.893  loss_mask_7: 7.054  loss_mask_8: 6.915  time: 3.0596  data_time: 0.0584  lr: 9.4977e-05  max_mem: 27632M
[01/28 21:23:17] d2.utils.events INFO:  eta: 1 day, 23:48:51  iter: 3359  total_loss: 72.53  loss_mask: 7.224  loss_mask_0: 7.494  loss_mask_1: 7.092  loss_mask_2: 7.282  loss_mask_3: 7.23  loss_mask_4: 7.226  loss_mask_5: 7.162  loss_mask_6: 7.146  loss_mask_7: 7.145  loss_mask_8: 7.174  time: 3.0595  data_time: 0.0627  lr: 9.4947e-05  max_mem: 27632M
[01/28 21:24:18] d2.utils.events INFO:  eta: 1 day, 23:48:19  iter: 3379  total_loss: 69.74  loss_mask: 6.961  loss_mask_0: 7.394  loss_mask_1: 6.879  loss_mask_2: 6.839  loss_mask_3: 6.963  loss_mask_4: 6.792  loss_mask_5: 6.868  loss_mask_6: 6.915  loss_mask_7: 6.812  loss_mask_8: 6.875  time: 3.0594  data_time: 0.0613  lr: 9.4917e-05  max_mem: 27632M
[01/28 21:25:19] d2.utils.events INFO:  eta: 1 day, 23:47:53  iter: 3399  total_loss: 67.32  loss_mask: 6.749  loss_mask_0: 7.266  loss_mask_1: 6.594  loss_mask_2: 6.691  loss_mask_3: 6.68  loss_mask_4: 6.655  loss_mask_5: 6.679  loss_mask_6: 6.692  loss_mask_7: 6.731  loss_mask_8: 6.707  time: 3.0594  data_time: 0.0646  lr: 9.4887e-05  max_mem: 27632M
[01/28 21:26:21] d2.utils.events INFO:  eta: 1 day, 23:48:09  iter: 3419  total_loss: 75.25  loss_mask: 7.411  loss_mask_0: 7.759  loss_mask_1: 7.41  loss_mask_2: 7.546  loss_mask_3: 7.481  loss_mask_4: 7.429  loss_mask_5: 7.591  loss_mask_6: 7.432  loss_mask_7: 7.433  loss_mask_8: 7.468  time: 3.0597  data_time: 0.0765  lr: 9.4857e-05  max_mem: 27632M
[01/28 21:27:23] d2.utils.events INFO:  eta: 1 day, 23:47:54  iter: 3439  total_loss: 67.12  loss_mask: 6.627  loss_mask_0: 7.543  loss_mask_1: 6.634  loss_mask_2: 6.627  loss_mask_3: 6.644  loss_mask_4: 6.674  loss_mask_5: 6.743  loss_mask_6: 6.675  loss_mask_7: 6.672  loss_mask_8: 6.583  time: 3.0597  data_time: 0.0608  lr: 9.4826e-05  max_mem: 27632M
[01/28 21:28:25] d2.utils.events INFO:  eta: 1 day, 23:48:03  iter: 3459  total_loss: 76.26  loss_mask: 7.843  loss_mask_0: 8.408  loss_mask_1: 7.649  loss_mask_2: 7.574  loss_mask_3: 7.659  loss_mask_4: 7.749  loss_mask_5: 7.406  loss_mask_6: 7.64  loss_mask_7: 7.597  loss_mask_8: 7.345  time: 3.0600  data_time: 0.0685  lr: 9.4796e-05  max_mem: 27632M
[01/28 21:29:26] d2.utils.events INFO:  eta: 1 day, 23:47:03  iter: 3479  total_loss: 68.59  loss_mask: 6.877  loss_mask_0: 7.537  loss_mask_1: 6.803  loss_mask_2: 6.894  loss_mask_3: 6.825  loss_mask_4: 6.758  loss_mask_5: 6.889  loss_mask_6: 6.892  loss_mask_7: 6.741  loss_mask_8: 6.829  time: 3.0600  data_time: 0.0662  lr: 9.4766e-05  max_mem: 27632M
[01/28 21:30:27] d2.utils.events INFO:  eta: 1 day, 23:45:28  iter: 3499  total_loss: 74.4  loss_mask: 7.353  loss_mask_0: 7.572  loss_mask_1: 7.312  loss_mask_2: 7.325  loss_mask_3: 7.357  loss_mask_4: 7.376  loss_mask_5: 7.285  loss_mask_6: 7.436  loss_mask_7: 7.3  loss_mask_8: 7.323  time: 3.0598  data_time: 0.0544  lr: 9.4736e-05  max_mem: 27632M
[01/28 21:31:28] d2.utils.events INFO:  eta: 1 day, 23:45:02  iter: 3519  total_loss: 65.06  loss_mask: 6.546  loss_mask_0: 6.705  loss_mask_1: 6.446  loss_mask_2: 6.482  loss_mask_3: 6.43  loss_mask_4: 6.492  loss_mask_5: 6.469  loss_mask_6: 6.497  loss_mask_7: 6.481  loss_mask_8: 6.448  time: 3.0598  data_time: 0.0694  lr: 9.4706e-05  max_mem: 27632M
[01/28 21:32:29] d2.utils.events INFO:  eta: 1 day, 23:44:01  iter: 3539  total_loss: 72.92  loss_mask: 7.413  loss_mask_0: 8.323  loss_mask_1: 7.189  loss_mask_2: 7.219  loss_mask_3: 7.185  loss_mask_4: 7.218  loss_mask_5: 7.153  loss_mask_6: 7.169  loss_mask_7: 7.086  loss_mask_8: 7.172  time: 3.0597  data_time: 0.0633  lr: 9.4675e-05  max_mem: 27632M
[01/28 21:33:30] d2.utils.events INFO:  eta: 1 day, 23:43:30  iter: 3559  total_loss: 76.17  loss_mask: 7.598  loss_mask_0: 7.844  loss_mask_1: 7.585  loss_mask_2: 7.739  loss_mask_3: 7.668  loss_mask_4: 7.572  loss_mask_5: 7.574  loss_mask_6: 7.664  loss_mask_7: 7.842  loss_mask_8: 7.718  time: 3.0597  data_time: 0.0618  lr: 9.4645e-05  max_mem: 27632M
[01/28 21:34:32] d2.utils.events INFO:  eta: 1 day, 23:44:14  iter: 3579  total_loss: 94  loss_mask: 9.381  loss_mask_0: 10.68  loss_mask_1: 8.535  loss_mask_2: 8.637  loss_mask_3: 8.645  loss_mask_4: 8.673  loss_mask_5: 8.688  loss_mask_6: 9.036  loss_mask_7: 11.53  loss_mask_8: 9  time: 3.0600  data_time: 0.0657  lr: 9.4615e-05  max_mem: 27632M
[01/28 21:35:34] d2.utils.events INFO:  eta: 1 day, 23:44:15  iter: 3599  total_loss: 94.84  loss_mask: 9.266  loss_mask_0: 9.779  loss_mask_1: 8.469  loss_mask_2: 8.416  loss_mask_3: 8.344  loss_mask_4: 8.541  loss_mask_5: 8.898  loss_mask_6: 9.613  loss_mask_7: 11.02  loss_mask_8: 9.644  time: 3.0603  data_time: 0.0765  lr: 9.4585e-05  max_mem: 27632M
[01/28 21:36:36] d2.utils.events INFO:  eta: 1 day, 23:44:21  iter: 3619  total_loss: 80.23  loss_mask: 7.86  loss_mask_0: 8.448  loss_mask_1: 7.725  loss_mask_2: 8.042  loss_mask_3: 7.834  loss_mask_4: 7.734  loss_mask_5: 7.788  loss_mask_6: 7.659  loss_mask_7: 8.215  loss_mask_8: 7.981  time: 3.0604  data_time: 0.0683  lr: 9.4555e-05  max_mem: 27632M
[01/28 21:37:37] d2.utils.events INFO:  eta: 1 day, 23:42:25  iter: 3639  total_loss: 66.01  loss_mask: 6.529  loss_mask_0: 6.881  loss_mask_1: 6.656  loss_mask_2: 6.386  loss_mask_3: 6.492  loss_mask_4: 6.581  loss_mask_5: 6.511  loss_mask_6: 6.565  loss_mask_7: 6.845  loss_mask_8: 6.626  time: 3.0604  data_time: 0.0752  lr: 9.4525e-05  max_mem: 27632M
[01/28 21:38:40] d2.utils.events INFO:  eta: 1 day, 23:42:19  iter: 3659  total_loss: 77.17  loss_mask: 7.709  loss_mask_0: 7.997  loss_mask_1: 7.437  loss_mask_2: 7.474  loss_mask_3: 7.768  loss_mask_4: 7.553  loss_mask_5: 7.704  loss_mask_6: 7.661  loss_mask_7: 7.892  loss_mask_8: 7.7  time: 3.0607  data_time: 0.0771  lr: 9.4494e-05  max_mem: 27632M
[01/28 21:39:41] d2.utils.events INFO:  eta: 1 day, 23:43:19  iter: 3679  total_loss: 65.77  loss_mask: 6.477  loss_mask_0: 6.924  loss_mask_1: 6.454  loss_mask_2: 6.483  loss_mask_3: 6.436  loss_mask_4: 6.483  loss_mask_5: 6.43  loss_mask_6: 6.574  loss_mask_7: 7.108  loss_mask_8: 6.443  time: 3.0608  data_time: 0.0796  lr: 9.4464e-05  max_mem: 27632M
[01/28 21:40:43] d2.utils.events INFO:  eta: 1 day, 23:43:30  iter: 3699  total_loss: 74.78  loss_mask: 7.281  loss_mask_0: 7.803  loss_mask_1: 7.343  loss_mask_2: 7.402  loss_mask_3: 7.391  loss_mask_4: 7.22  loss_mask_5: 7.4  loss_mask_6: 7.464  loss_mask_7: 7.878  loss_mask_8: 7.334  time: 3.0610  data_time: 0.0820  lr: 9.4434e-05  max_mem: 27632M
[01/28 21:41:45] d2.utils.events INFO:  eta: 1 day, 23:43:25  iter: 3719  total_loss: 74.82  loss_mask: 7.286  loss_mask_0: 8.646  loss_mask_1: 7.093  loss_mask_2: 7.171  loss_mask_3: 7.234  loss_mask_4: 7.416  loss_mask_5: 7.31  loss_mask_6: 7.306  loss_mask_7: 7.485  loss_mask_8: 7.332  time: 3.0611  data_time: 0.0639  lr: 9.4404e-05  max_mem: 27632M
[01/28 21:42:47] d2.utils.events INFO:  eta: 1 day, 23:42:32  iter: 3739  total_loss: 76.04  loss_mask: 7.546  loss_mask_0: 7.886  loss_mask_1: 7.461  loss_mask_2: 7.6  loss_mask_3: 7.531  loss_mask_4: 7.557  loss_mask_5: 7.559  loss_mask_6: 7.585  loss_mask_7: 7.616  loss_mask_8: 7.615  time: 3.0612  data_time: 0.0695  lr: 9.4374e-05  max_mem: 27632M
[01/28 21:43:49] d2.utils.events INFO:  eta: 1 day, 23:42:38  iter: 3759  total_loss: 69.11  loss_mask: 6.751  loss_mask_0: 8.123  loss_mask_1: 6.673  loss_mask_2: 6.765  loss_mask_3: 6.71  loss_mask_4: 6.801  loss_mask_5: 6.768  loss_mask_6: 6.774  loss_mask_7: 6.906  loss_mask_8: 6.769  time: 3.0615  data_time: 0.0748  lr: 9.4343e-05  max_mem: 27632M
[01/28 21:44:51] d2.utils.events INFO:  eta: 1 day, 23:42:41  iter: 3779  total_loss: 66.44  loss_mask: 6.422  loss_mask_0: 7.224  loss_mask_1: 6.484  loss_mask_2: 6.643  loss_mask_3: 6.459  loss_mask_4: 6.562  loss_mask_5: 6.403  loss_mask_6: 6.587  loss_mask_7: 6.758  loss_mask_8: 6.576  time: 3.0616  data_time: 0.0653  lr: 9.4313e-05  max_mem: 27632M
[01/28 21:45:52] d2.utils.events INFO:  eta: 1 day, 23:42:44  iter: 3799  total_loss: 69.01  loss_mask: 6.815  loss_mask_0: 7.404  loss_mask_1: 6.76  loss_mask_2: 6.819  loss_mask_3: 6.835  loss_mask_4: 6.785  loss_mask_5: 6.833  loss_mask_6: 6.842  loss_mask_7: 7.008  loss_mask_8: 6.837  time: 3.0616  data_time: 0.0606  lr: 9.4283e-05  max_mem: 27632M
[01/28 21:46:53] d2.utils.events INFO:  eta: 1 day, 23:42:30  iter: 3819  total_loss: 63.68  loss_mask: 6.32  loss_mask_0: 6.806  loss_mask_1: 6.188  loss_mask_2: 6.119  loss_mask_3: 6.234  loss_mask_4: 6.31  loss_mask_5: 6.308  loss_mask_6: 6.288  loss_mask_7: 6.379  loss_mask_8: 6.292  time: 3.0615  data_time: 0.0623  lr: 9.4253e-05  max_mem: 27632M
[01/28 21:47:54] d2.utils.events INFO:  eta: 1 day, 23:41:29  iter: 3839  total_loss: 58.6  loss_mask: 5.822  loss_mask_0: 6.107  loss_mask_1: 5.837  loss_mask_2: 5.86  loss_mask_3: 5.829  loss_mask_4: 5.808  loss_mask_5: 5.797  loss_mask_6: 5.859  loss_mask_7: 5.92  loss_mask_8: 5.86  time: 3.0615  data_time: 0.0751  lr: 9.4223e-05  max_mem: 27632M
[01/28 21:48:55] d2.utils.events INFO:  eta: 1 day, 23:39:54  iter: 3859  total_loss: 59.03  loss_mask: 5.927  loss_mask_0: 6.276  loss_mask_1: 5.837  loss_mask_2: 5.835  loss_mask_3: 5.915  loss_mask_4: 5.822  loss_mask_5: 5.88  loss_mask_6: 5.907  loss_mask_7: 5.863  loss_mask_8: 5.861  time: 3.0615  data_time: 0.0777  lr: 9.4192e-05  max_mem: 27632M
[01/28 21:49:57] d2.utils.events INFO:  eta: 1 day, 23:38:44  iter: 3879  total_loss: 70.11  loss_mask: 7.099  loss_mask_0: 7.322  loss_mask_1: 6.943  loss_mask_2: 6.9  loss_mask_3: 7.03  loss_mask_4: 6.938  loss_mask_5: 6.929  loss_mask_6: 6.905  loss_mask_7: 7.013  loss_mask_8: 6.978  time: 3.0615  data_time: 0.0663  lr: 9.4162e-05  max_mem: 27632M
[01/28 21:50:57] d2.utils.events INFO:  eta: 1 day, 23:37:43  iter: 3899  total_loss: 66.84  loss_mask: 6.518  loss_mask_0: 7.315  loss_mask_1: 6.568  loss_mask_2: 6.484  loss_mask_3: 6.69  loss_mask_4: 6.564  loss_mask_5: 6.618  loss_mask_6: 6.593  loss_mask_7: 6.585  loss_mask_8: 6.482  time: 3.0614  data_time: 0.0666  lr: 9.4132e-05  max_mem: 27632M
[01/28 21:51:58] d2.utils.events INFO:  eta: 1 day, 23:37:24  iter: 3919  total_loss: 72.36  loss_mask: 7.076  loss_mask_0: 7.388  loss_mask_1: 6.705  loss_mask_2: 7.27  loss_mask_3: 7.659  loss_mask_4: 7.731  loss_mask_5: 7.132  loss_mask_6: 7.22  loss_mask_7: 7.474  loss_mask_8: 7.127  time: 3.0613  data_time: 0.0666  lr: 9.4102e-05  max_mem: 27632M
[01/28 21:53:00] d2.utils.events INFO:  eta: 1 day, 23:36:09  iter: 3939  total_loss: 69.52  loss_mask: 6.962  loss_mask_0: 7.349  loss_mask_1: 6.946  loss_mask_2: 6.841  loss_mask_3: 6.682  loss_mask_4: 6.879  loss_mask_5: 6.81  loss_mask_6: 7.368  loss_mask_7: 6.874  loss_mask_8: 6.833  time: 3.0614  data_time: 0.0718  lr: 9.4072e-05  max_mem: 27632M
[01/28 21:54:01] d2.utils.events INFO:  eta: 1 day, 23:35:46  iter: 3959  total_loss: 76.52  loss_mask: 7.623  loss_mask_0: 8.042  loss_mask_1: 6.968  loss_mask_2: 7.141  loss_mask_3: 7.92  loss_mask_4: 7.749  loss_mask_5: 7.558  loss_mask_6: 8.713  loss_mask_7: 7.955  loss_mask_8: 7.492  time: 3.0614  data_time: 0.0668  lr: 9.4041e-05  max_mem: 27632M
[01/28 21:55:02] d2.utils.events INFO:  eta: 1 day, 23:35:19  iter: 3979  total_loss: 83.36  loss_mask: 8.499  loss_mask_0: 8.997  loss_mask_1: 8.212  loss_mask_2: 8.193  loss_mask_3: 8.282  loss_mask_4: 8.108  loss_mask_5: 8.202  loss_mask_6: 8.616  loss_mask_7: 8.233  loss_mask_8: 8.39  time: 3.0613  data_time: 0.0581  lr: 9.4011e-05  max_mem: 27632M
[01/28 21:56:03] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 21:56:04] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 21:56:04] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 22:10:14] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 9.0167798736004, 'error_1pix': 0.8275856130238701, 'error_3pix': 0.7083427887877703, 'mIoU': 0.9400460974741861, 'fwIoU': 1.8293561706009036, 'IoU-0': 0.0003950521843753546, 'IoU-1': 4.3397467645122605, 'IoU-2': 1.008718266114219, 'IoU-3': 0.7149718476830459, 'IoU-4': 0.5967255245803031, 'IoU-5': 0.3324197534504728, 'IoU-6': 0.13001837693242402, 'IoU-7': 0.09072570755711272, 'IoU-8': 0.22469556228627047, 'IoU-9': 0.3914957346916662, 'IoU-10': 0.8041044495606059, 'IoU-11': 1.1438577737624005, 'IoU-12': 1.2678636868272455, 'IoU-13': 1.225394389798879, 'IoU-14': 1.1508054269183672, 'IoU-15': 1.0746846814575832, 'IoU-16': 1.1687627104082667, 'IoU-17': 1.164787128568662, 'IoU-18': 0.9681367004888719, 'IoU-19': 0.9342381405236655, 'IoU-20': 0.9672886822398076, 'IoU-21': 0.9092290277443013, 'IoU-22': 1.04386881560356, 'IoU-23': 0.9965587926430155, 'IoU-24': 1.0069690748356792, 'IoU-25': 1.0394186193195434, 'IoU-26': 1.3107696599475724, 'IoU-27': 1.3793276806478194, 'IoU-28': 1.47761423404583, 'IoU-29': 1.5765560284242819, 'IoU-30': 1.664179999522615, 'IoU-31': 1.9023896043702737, 'IoU-32': 2.0035289636430798, 'IoU-33': 2.100879372091534, 'IoU-34': 2.2698813637059625, 'IoU-35': 2.5043178686926924, 'IoU-36': 2.663146547635665, 'IoU-37': 2.7982756314653483, 'IoU-38': 3.087790305419133, 'IoU-39': 3.2384015771789696, 'IoU-40': 3.289469684033017, 'IoU-41': 3.2749764225564997, 'IoU-42': 3.331203622057562, 'IoU-43': 3.2750916528561, 'IoU-44': 3.3357474027734346, 'IoU-45': 3.1564587561504744, 'IoU-46': 2.976995587094702, 'IoU-47': 2.8766326567009757, 'IoU-48': 2.7411877622900667, 'IoU-49': 2.5441823402002335, 'IoU-50': 2.355354264654983, 'IoU-51': 2.0632544901515386, 'IoU-52': 1.9177244182099558, 'IoU-53': 1.752081372677282, 'IoU-54': 1.6994505983998647, 'IoU-55': 1.4624149799964479, 'IoU-56': 1.3256672369092264, 'IoU-57': 1.257720866470986, 'IoU-58': 1.1588971765402436, 'IoU-59': 1.000301296320371, 'IoU-60': 0.967076660621953, 'IoU-61': 0.9024375299374616, 'IoU-62': 0.81058058053119, 'IoU-63': 0.7197920734241913, 'IoU-64': 0.6536824354039317, 'IoU-65': 0.5908506939253747, 'IoU-66': 0.5722732565977992, 'IoU-67': 0.5652968853664949, 'IoU-68': 0.5188520775772963, 'IoU-69': 0.5294598079412355, 'IoU-70': 0.5228737524707869, 'IoU-71': 0.5053005596513006, 'IoU-72': 0.42993303305678116, 'IoU-73': 0.44232042610193817, 'IoU-74': 0.4295721519503022, 'IoU-75': 0.4748868466421752, 'IoU-76': 0.48091568663626105, 'IoU-77': 0.4594965810556835, 'IoU-78': 0.45784200581016377, 'IoU-79': 0.5035923130898818, 'IoU-80': 0.4969570885455643, 'IoU-81': 0.5074304092148524, 'IoU-82': 0.4730883565552678, 'IoU-83': 0.5101558927516546, 'IoU-84': 0.5541219283612793, 'IoU-85': 0.5648724436369236, 'IoU-86': 0.6457436055199086, 'IoU-87': 0.6982555562244038, 'IoU-88': 0.6881314433702943, 'IoU-89': 0.6723237692723596, 'IoU-90': 0.7409003633071131, 'IoU-91': 0.7326753764089717, 'IoU-92': 0.7635068489091148, 'IoU-93': 0.759446244918604, 'IoU-94': 0.8492110242599983, 'IoU-95': 0.8395739439072425, 'IoU-96': 0.9064118712172741, 'IoU-97': 0.9266931379931155, 'IoU-98': 0.7999288974503307, 'IoU-99': 0.950593484082561, 'IoU-100': 0.9873858758407376, 'IoU-101': 1.163075444485751, 'IoU-102': 1.0498815723273693, 'IoU-103': 1.1322537886871031, 'IoU-104': 1.1040538538058557, 'IoU-105': 0.9834042803270968, 'IoU-106': 1.261768850669233, 'IoU-107': 1.0083891091518224, 'IoU-108': 1.0661131111634965, 'IoU-109': 1.1448830982694067, 'IoU-110': 1.2385239987899408, 'IoU-111': 1.1877059096043099, 'IoU-112': 1.290949082234473, 'IoU-113': 1.3715658190379925, 'IoU-114': 1.7126229198288292, 'IoU-115': 1.2726423964455007, 'IoU-116': 1.1914658986582158, 'IoU-117': 1.405419795986997, 'IoU-118': 1.2311871259139937, 'IoU-119': 1.3460978631454295, 'IoU-120': 1.2231341380202532, 'IoU-121': 1.3444828777222388, 'IoU-122': 1.4448924946636856, 'IoU-123': 1.0490412793902038, 'IoU-124': 0.8561392644644717, 'IoU-125': 1.0363278989165114, 'IoU-126': 1.2133173150630707, 'IoU-127': 1.2016206203884174, 'IoU-128': 1.2102757078680164, 'IoU-129': 1.3370792899897228, 'IoU-130': 1.405284278715697, 'IoU-131': 1.1958342156428667, 'IoU-132': 1.0046437065512703, 'IoU-133': 0.9769240015196681, 'IoU-134': 0.9102314343376992, 'IoU-135': 0.924147603696352, 'IoU-136': 1.0601483921052857, 'IoU-137': 1.2219320879945574, 'IoU-138': 1.0419429140518108, 'IoU-139': 0.7407977442113378, 'IoU-140': 1.201851101257859, 'IoU-141': 0.9518077861842997, 'IoU-142': 1.1470446835078785, 'IoU-143': 0.7156844767886985, 'IoU-144': 0.4925484801645792, 'IoU-145': 0.8586534353727481, 'IoU-146': 0.5036995259226873, 'IoU-147': 0.6533066818509288, 'IoU-148': 0.36547930853850186, 'IoU-149': 0.13441068468105544, 'IoU-150': 0.2620522939587444, 'IoU-151': 0.36578862374846965, 'IoU-152': 0.13666025924944283, 'IoU-153': 0.007513253378960487, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.2355992594938576, 'pACC': 2.9207912658558635, 'ACC-0': 0.0035670420513159323, 'ACC-1': 4.3892393695235405, 'ACC-2': 2.150080762540381, 'ACC-3': 4.81154289649244, 'ACC-4': 5.1535594988581765, 'ACC-5': 6.902782797253343, 'ACC-6': 8.266633553912566, 'ACC-7': 9.981367433482466, 'ACC-8': 8.316593879189444, 'ACC-9': 4.159771113981556, 'ACC-10': 3.544102410006596, 'ACC-11': 2.616455690277825, 'ACC-12': 2.401741721731095, 'ACC-13': 2.160473155284746, 'ACC-14': 2.008789953384729, 'ACC-15': 1.930413828229047, 'ACC-16': 2.121617515804388, 'ACC-17': 2.2381634370392596, 'ACC-18': 1.7929244050405695, 'ACC-19': 1.7279877548307847, 'ACC-20': 1.792831126512981, 'ACC-21': 1.6554467384746858, 'ACC-22': 1.8304870133387041, 'ACC-23': 1.8137289983161955, 'ACC-24': 1.8456198224343312, 'ACC-25': 1.8987809256811043, 'ACC-26': 2.3581721686548227, 'ACC-27': 2.3887579238101844, 'ACC-28': 2.5614309497130483, 'ACC-29': 2.634921353507557, 'ACC-30': 2.7772142072483694, 'ACC-31': 3.0996836429413714, 'ACC-32': 3.278684752763427, 'ACC-33': 3.477117346801051, 'ACC-34': 3.7310850572297682, 'ACC-35': 4.002157735667289, 'ACC-36': 4.1892510154873195, 'ACC-37': 4.4054895415971815, 'ACC-38': 4.798742855862051, 'ACC-39': 5.007179523693528, 'ACC-40': 5.065025941444971, 'ACC-41': 5.1721598961207444, 'ACC-42': 5.262963649169128, 'ACC-43': 5.157077518211146, 'ACC-44': 5.149063742060422, 'ACC-45': 4.9130943637562625, 'ACC-46': 4.73831535326059, 'ACC-47': 4.589921266645143, 'ACC-48': 4.398756571637284, 'ACC-49': 4.0730950078280985, 'ACC-50': 3.7781383720756097, 'ACC-51': 3.3674233602859935, 'ACC-52': 3.144222950161696, 'ACC-53': 2.8917670189369424, 'ACC-54': 2.8082264985991383, 'ACC-55': 2.4465571210286274, 'ACC-56': 2.2690235029664314, 'ACC-57': 2.1524041459948524, 'ACC-58': 2.02853515686149, 'ACC-59': 1.7965432975295843, 'ACC-60': 1.772475921728211, 'ACC-61': 1.6842416476131459, 'ACC-62': 1.5402836126722106, 'ACC-63': 1.3916680316438605, 'ACC-64': 1.2763275846608284, 'ACC-65': 1.1709259716294729, 'ACC-66': 1.1487896105977398, 'ACC-67': 1.1504011115289172, 'ACC-68': 1.060561163140578, 'ACC-69': 1.0678697545895108, 'ACC-70': 1.0483195582250548, 'ACC-71': 1.0325667192419457, 'ACC-72': 0.8815226910491096, 'ACC-73': 0.9011437883220357, 'ACC-74': 0.8660513554750522, 'ACC-75': 0.9529571198780439, 'ACC-76': 0.9496691249826841, 'ACC-77': 0.9216457559145731, 'ACC-78': 0.9251796840701605, 'ACC-79': 1.020323490418331, 'ACC-80': 1.0028716506301785, 'ACC-81': 1.0252770861933902, 'ACC-82': 0.9686005073369893, 'ACC-83': 1.0465906866261276, 'ACC-84': 1.155561412918411, 'ACC-85': 1.196399714295369, 'ACC-86': 1.3938919249347945, 'ACC-87': 1.5511569567647299, 'ACC-88': 1.5469721028710557, 'ACC-89': 1.5419699109259162, 'ACC-90': 1.7315321990658237, 'ACC-91': 1.7804126441289343, 'ACC-92': 1.9343896727133942, 'ACC-93': 1.9708861828035167, 'ACC-94': 2.2433043588265202, 'ACC-95': 2.251856492134895, 'ACC-96': 2.4802372874412413, 'ACC-97': 2.5809521216936844, 'ACC-98': 2.2910171669225097, 'ACC-99': 2.8100935894360335, 'ACC-100': 2.927327398923243, 'ACC-101': 3.5780455008932703, 'ACC-102': 3.1736067059356596, 'ACC-103': 3.4831396996316237, 'ACC-104': 3.3330710016969576, 'ACC-105': 2.987242408539692, 'ACC-106': 3.968809008539841, 'ACC-107': 3.1240617208203334, 'ACC-108': 3.218387437414103, 'ACC-109': 3.3560553549837486, 'ACC-110': 3.6316128447543625, 'ACC-111': 3.4885976631532167, 'ACC-112': 3.7840523336396314, 'ACC-113': 4.097957315328718, 'ACC-114': 5.120668863705026, 'ACC-115': 3.700141325755867, 'ACC-116': 3.4990276548481267, 'ACC-117': 4.030371437733008, 'ACC-118': 3.600625940243448, 'ACC-119': 3.8851624486336696, 'ACC-120': 3.5030501410865953, 'ACC-121': 3.9905033868134794, 'ACC-122': 4.2523139630332025, 'ACC-123': 2.984640860206565, 'ACC-124': 2.415799682595662, 'ACC-125': 3.1765472397736256, 'ACC-126': 4.040849643439376, 'ACC-127': 3.624519900195311, 'ACC-128': 3.948634635579608, 'ACC-129': 3.7367301744083528, 'ACC-130': 5.077416592070539, 'ACC-131': 3.9219439188735663, 'ACC-132': 3.277806261791544, 'ACC-133': 3.4398198234977917, 'ACC-134': 2.7938302455838, 'ACC-135': 3.3140926971096287, 'ACC-136': 3.44559494968319, 'ACC-137': 4.346989849772977, 'ACC-138': 3.209952534456938, 'ACC-139': 2.0914070307677046, 'ACC-140': 3.6470058159277903, 'ACC-141': 3.013267938983975, 'ACC-142': 3.4567590722241, 'ACC-143': 2.1008165498947298, 'ACC-144': 1.4503610108303249, 'ACC-145': 2.1250027952324517, 'ACC-146': 1.1328048251125176, 'ACC-147': 1.381730259437707, 'ACC-148': 0.6631807773577516, 'ACC-149': 0.21114141099659356, 'ACC-150': 0.3751267707515773, 'ACC-151': 0.4671298531466519, 'ACC-152': 0.16353091914491874, 'ACC-153': 0.008588468092123344, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/28 22:10:14] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 22:10:14] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 22:10:14] d2.evaluation.testing INFO: copypaste: 9.0168,0.8276,0.7083,0.9400,1.8294,2.2356,2.9208
[01/28 22:10:15] d2.utils.events INFO:  eta: 1 day, 23:33:33  iter: 3999  total_loss: 75.55  loss_mask: 8.012  loss_mask_0: 7.567  loss_mask_1: 7.343  loss_mask_2: 7.762  loss_mask_3: 7.212  loss_mask_4: 7.407  loss_mask_5: 7.463  loss_mask_6: 7.605  loss_mask_7: 7.512  loss_mask_8: 7.091  time: 3.0612  data_time: 0.0573  lr: 9.3981e-05  max_mem: 27632M
[01/28 22:11:16] d2.utils.events INFO:  eta: 1 day, 23:32:56  iter: 4019  total_loss: 74.41  loss_mask: 7.251  loss_mask_0: 7.689  loss_mask_1: 7.276  loss_mask_2: 7.162  loss_mask_3: 7.557  loss_mask_4: 7.03  loss_mask_5: 7.105  loss_mask_6: 7.714  loss_mask_7: 7.25  loss_mask_8: 7.186  time: 3.0613  data_time: 0.0625  lr: 9.3951e-05  max_mem: 27632M
[01/28 22:12:17] d2.utils.events INFO:  eta: 1 day, 23:31:30  iter: 4039  total_loss: 75.33  loss_mask: 7.423  loss_mask_0: 7.899  loss_mask_1: 7.336  loss_mask_2: 7.528  loss_mask_3: 7.208  loss_mask_4: 7.208  loss_mask_5: 7.457  loss_mask_6: 7.604  loss_mask_7: 7.34  loss_mask_8: 7.317  time: 3.0613  data_time: 0.0656  lr: 9.3921e-05  max_mem: 27632M
[01/28 22:13:19] d2.utils.events INFO:  eta: 1 day, 23:30:54  iter: 4059  total_loss: 65.88  loss_mask: 6.386  loss_mask_0: 6.932  loss_mask_1: 6.603  loss_mask_2: 6.762  loss_mask_3: 6.404  loss_mask_4: 6.436  loss_mask_5: 6.553  loss_mask_6: 6.708  loss_mask_7: 6.577  loss_mask_8: 6.407  time: 3.0614  data_time: 0.0698  lr: 9.389e-05  max_mem: 27632M
[01/28 22:14:21] d2.utils.events INFO:  eta: 1 day, 23:29:18  iter: 4079  total_loss: 60.59  loss_mask: 6.168  loss_mask_0: 6.395  loss_mask_1: 5.846  loss_mask_2: 5.998  loss_mask_3: 6.131  loss_mask_4: 5.925  loss_mask_5: 5.846  loss_mask_6: 6.278  loss_mask_7: 6.336  loss_mask_8: 5.946  time: 3.0614  data_time: 0.0739  lr: 9.386e-05  max_mem: 27632M
[01/28 22:15:22] d2.utils.events INFO:  eta: 1 day, 23:28:17  iter: 4099  total_loss: 60.97  loss_mask: 5.979  loss_mask_0: 6.32  loss_mask_1: 6  loss_mask_2: 6.164  loss_mask_3: 6.056  loss_mask_4: 6.092  loss_mask_5: 6.097  loss_mask_6: 6.148  loss_mask_7: 6.342  loss_mask_8: 5.984  time: 3.0614  data_time: 0.0654  lr: 9.383e-05  max_mem: 27632M
[01/28 22:16:24] d2.utils.events INFO:  eta: 1 day, 23:27:16  iter: 4119  total_loss: 75.19  loss_mask: 7.401  loss_mask_0: 7.755  loss_mask_1: 7.289  loss_mask_2: 7.363  loss_mask_3: 7.333  loss_mask_4: 7.263  loss_mask_5: 7.409  loss_mask_6: 7.513  loss_mask_7: 7.908  loss_mask_8: 7.397  time: 3.0616  data_time: 0.0711  lr: 9.38e-05  max_mem: 27632M
[01/28 22:17:25] d2.utils.events INFO:  eta: 1 day, 23:26:57  iter: 4139  total_loss: 66.13  loss_mask: 6.48  loss_mask_0: 6.976  loss_mask_1: 6.485  loss_mask_2: 6.477  loss_mask_3: 6.505  loss_mask_4: 6.487  loss_mask_5: 6.483  loss_mask_6: 6.591  loss_mask_7: 6.849  loss_mask_8: 6.423  time: 3.0616  data_time: 0.0663  lr: 9.377e-05  max_mem: 27632M
[01/28 22:18:27] d2.utils.events INFO:  eta: 1 day, 23:26:25  iter: 4159  total_loss: 57.31  loss_mask: 5.664  loss_mask_0: 6.022  loss_mask_1: 5.643  loss_mask_2: 5.733  loss_mask_3: 5.648  loss_mask_4: 5.719  loss_mask_5: 5.65  loss_mask_6: 5.728  loss_mask_7: 5.815  loss_mask_8: 5.652  time: 3.0617  data_time: 0.0631  lr: 9.3739e-05  max_mem: 27632M
[01/28 22:19:28] d2.utils.events INFO:  eta: 1 day, 23:26:11  iter: 4179  total_loss: 59.56  loss_mask: 5.973  loss_mask_0: 6.556  loss_mask_1: 5.862  loss_mask_2: 5.955  loss_mask_3: 5.915  loss_mask_4: 5.873  loss_mask_5: 5.983  loss_mask_6: 5.968  loss_mask_7: 5.976  loss_mask_8: 5.949  time: 3.0616  data_time: 0.0713  lr: 9.3709e-05  max_mem: 27632M
[01/28 22:20:28] d2.utils.events INFO:  eta: 1 day, 23:24:34  iter: 4199  total_loss: 68.85  loss_mask: 6.696  loss_mask_0: 7.852  loss_mask_1: 6.639  loss_mask_2: 6.611  loss_mask_3: 6.695  loss_mask_4: 6.712  loss_mask_5: 6.713  loss_mask_6: 6.874  loss_mask_7: 7.464  loss_mask_8: 6.709  time: 3.0615  data_time: 0.0586  lr: 9.3679e-05  max_mem: 27632M
[01/28 22:21:29] d2.utils.events INFO:  eta: 1 day, 23:22:20  iter: 4219  total_loss: 61.08  loss_mask: 6.11  loss_mask_0: 6.568  loss_mask_1: 5.972  loss_mask_2: 5.973  loss_mask_3: 6.035  loss_mask_4: 6.04  loss_mask_5: 5.963  loss_mask_6: 6.136  loss_mask_7: 6.218  loss_mask_8: 5.94  time: 3.0613  data_time: 0.0623  lr: 9.3649e-05  max_mem: 27632M
[01/28 22:22:30] d2.utils.events INFO:  eta: 1 day, 23:21:06  iter: 4239  total_loss: 69.15  loss_mask: 6.799  loss_mask_0: 7.135  loss_mask_1: 6.793  loss_mask_2: 6.935  loss_mask_3: 6.816  loss_mask_4: 6.804  loss_mask_5: 6.805  loss_mask_6: 6.902  loss_mask_7: 7.044  loss_mask_8: 6.873  time: 3.0613  data_time: 0.0579  lr: 9.3618e-05  max_mem: 27632M
[01/28 22:23:31] d2.utils.events INFO:  eta: 1 day, 23:19:51  iter: 4259  total_loss: 76.75  loss_mask: 7.771  loss_mask_0: 8.123  loss_mask_1: 7.49  loss_mask_2: 7.479  loss_mask_3: 7.679  loss_mask_4: 7.604  loss_mask_5: 7.679  loss_mask_6: 7.501  loss_mask_7: 7.788  loss_mask_8: 7.437  time: 3.0613  data_time: 0.0597  lr: 9.3588e-05  max_mem: 27632M
[01/28 22:24:32] d2.utils.events INFO:  eta: 1 day, 23:19:16  iter: 4279  total_loss: 68.97  loss_mask: 6.849  loss_mask_0: 7.688  loss_mask_1: 6.462  loss_mask_2: 6.476  loss_mask_3: 6.508  loss_mask_4: 7.631  loss_mask_5: 6.583  loss_mask_6: 6.5  loss_mask_7: 6.635  loss_mask_8: 6.383  time: 3.0612  data_time: 0.0694  lr: 9.3558e-05  max_mem: 27632M
[01/28 22:25:34] d2.utils.events INFO:  eta: 1 day, 23:20:40  iter: 4299  total_loss: 59.94  loss_mask: 6.016  loss_mask_0: 6.489  loss_mask_1: 5.866  loss_mask_2: 5.898  loss_mask_3: 5.821  loss_mask_4: 6.659  loss_mask_5: 6.023  loss_mask_6: 5.842  loss_mask_7: 5.75  loss_mask_8: 5.674  time: 3.0613  data_time: 0.0716  lr: 9.3528e-05  max_mem: 27632M
[01/28 22:26:35] d2.utils.events INFO:  eta: 1 day, 23:19:55  iter: 4319  total_loss: 65.44  loss_mask: 6.373  loss_mask_0: 7.387  loss_mask_1: 6.589  loss_mask_2: 6.458  loss_mask_3: 6.439  loss_mask_4: 6.694  loss_mask_5: 6.379  loss_mask_6: 6.377  loss_mask_7: 6.309  loss_mask_8: 6.395  time: 3.0613  data_time: 0.0720  lr: 9.3498e-05  max_mem: 27632M
[01/28 22:27:37] d2.utils.events INFO:  eta: 1 day, 23:20:07  iter: 4339  total_loss: 66.93  loss_mask: 6.62  loss_mask_0: 7.337  loss_mask_1: 6.675  loss_mask_2: 6.578  loss_mask_3: 6.542  loss_mask_4: 7.104  loss_mask_5: 6.679  loss_mask_6: 6.5  loss_mask_7: 6.487  loss_mask_8: 6.553  time: 3.0613  data_time: 0.0582  lr: 9.3467e-05  max_mem: 27632M
[01/28 22:28:39] d2.utils.events INFO:  eta: 1 day, 23:19:40  iter: 4359  total_loss: 64.28  loss_mask: 6.364  loss_mask_0: 6.644  loss_mask_1: 6.348  loss_mask_2: 6.383  loss_mask_3: 6.399  loss_mask_4: 6.737  loss_mask_5: 6.57  loss_mask_6: 6.364  loss_mask_7: 6.449  loss_mask_8: 6.424  time: 3.0615  data_time: 0.0748  lr: 9.3437e-05  max_mem: 27632M
[01/28 22:29:40] d2.utils.events INFO:  eta: 1 day, 23:18:16  iter: 4379  total_loss: 66.7  loss_mask: 6.535  loss_mask_0: 6.976  loss_mask_1: 6.425  loss_mask_2: 6.423  loss_mask_3: 6.59  loss_mask_4: 6.801  loss_mask_5: 6.443  loss_mask_6: 6.629  loss_mask_7: 6.618  loss_mask_8: 6.592  time: 3.0616  data_time: 0.0615  lr: 9.3407e-05  max_mem: 27632M
[01/28 22:30:42] d2.utils.events INFO:  eta: 1 day, 23:18:38  iter: 4399  total_loss: 53.83  loss_mask: 5.321  loss_mask_0: 5.848  loss_mask_1: 5.329  loss_mask_2: 5.354  loss_mask_3: 5.352  loss_mask_4: 5.456  loss_mask_5: 5.355  loss_mask_6: 5.329  loss_mask_7: 5.3  loss_mask_8: 5.304  time: 3.0618  data_time: 0.0786  lr: 9.3377e-05  max_mem: 27632M
[01/28 22:31:44] d2.utils.events INFO:  eta: 1 day, 23:17:37  iter: 4419  total_loss: 64.89  loss_mask: 6.397  loss_mask_0: 6.568  loss_mask_1: 6.488  loss_mask_2: 6.515  loss_mask_3: 6.506  loss_mask_4: 6.667  loss_mask_5: 6.44  loss_mask_6: 6.435  loss_mask_7: 6.58  loss_mask_8: 6.475  time: 3.0619  data_time: 0.0661  lr: 9.3346e-05  max_mem: 27632M
[01/28 22:32:46] d2.utils.events INFO:  eta: 1 day, 23:17:07  iter: 4439  total_loss: 57.89  loss_mask: 5.727  loss_mask_0: 6.122  loss_mask_1: 5.599  loss_mask_2: 5.678  loss_mask_3: 5.779  loss_mask_4: 5.805  loss_mask_5: 5.688  loss_mask_6: 5.773  loss_mask_7: 5.701  loss_mask_8: 5.677  time: 3.0620  data_time: 0.0673  lr: 9.3316e-05  max_mem: 27632M
[01/28 22:33:49] d2.utils.events INFO:  eta: 1 day, 23:16:35  iter: 4459  total_loss: 57.79  loss_mask: 5.804  loss_mask_0: 6.114  loss_mask_1: 5.63  loss_mask_2: 5.706  loss_mask_3: 5.92  loss_mask_4: 6.226  loss_mask_5: 5.708  loss_mask_6: 5.749  loss_mask_7: 5.79  loss_mask_8: 5.567  time: 3.0623  data_time: 0.0832  lr: 9.3286e-05  max_mem: 27632M
[01/28 22:34:51] d2.utils.events INFO:  eta: 1 day, 23:15:53  iter: 4479  total_loss: 56.47  loss_mask: 5.565  loss_mask_0: 5.791  loss_mask_1: 5.51  loss_mask_2: 5.581  loss_mask_3: 5.483  loss_mask_4: 5.709  loss_mask_5: 5.659  loss_mask_6: 5.553  loss_mask_7: 5.582  loss_mask_8: 5.588  time: 3.0624  data_time: 0.0703  lr: 9.3256e-05  max_mem: 27632M
[01/28 22:35:53] d2.utils.events INFO:  eta: 1 day, 23:15:31  iter: 4499  total_loss: 62.59  loss_mask: 6.217  loss_mask_0: 6.45  loss_mask_1: 6.134  loss_mask_2: 6.173  loss_mask_3: 6.185  loss_mask_4: 6.212  loss_mask_5: 6.149  loss_mask_6: 6.193  loss_mask_7: 6.18  loss_mask_8: 6.174  time: 3.0627  data_time: 0.0835  lr: 9.3225e-05  max_mem: 27632M
[01/28 22:36:55] d2.utils.events INFO:  eta: 1 day, 23:15:06  iter: 4519  total_loss: 62.21  loss_mask: 6.089  loss_mask_0: 6.499  loss_mask_1: 6.151  loss_mask_2: 6.057  loss_mask_3: 6.045  loss_mask_4: 6.098  loss_mask_5: 6.057  loss_mask_6: 6.138  loss_mask_7: 6.163  loss_mask_8: 6.102  time: 3.0628  data_time: 0.0686  lr: 9.3195e-05  max_mem: 27632M
[01/28 22:37:57] d2.utils.events INFO:  eta: 1 day, 23:15:46  iter: 4539  total_loss: 62.52  loss_mask: 6.262  loss_mask_0: 6.663  loss_mask_1: 6.046  loss_mask_2: 6.052  loss_mask_3: 6.118  loss_mask_4: 6.183  loss_mask_5: 6.26  loss_mask_6: 6.09  loss_mask_7: 6.169  loss_mask_8: 6.032  time: 3.0629  data_time: 0.0775  lr: 9.3165e-05  max_mem: 27632M
[01/28 22:38:58] d2.utils.events INFO:  eta: 1 day, 23:14:12  iter: 4559  total_loss: 57.73  loss_mask: 5.8  loss_mask_0: 6.454  loss_mask_1: 5.645  loss_mask_2: 5.674  loss_mask_3: 5.924  loss_mask_4: 5.748  loss_mask_5: 5.924  loss_mask_6: 5.783  loss_mask_7: 5.764  loss_mask_8: 5.676  time: 3.0629  data_time: 0.0641  lr: 9.3135e-05  max_mem: 27632M
[01/28 22:40:00] d2.utils.events INFO:  eta: 1 day, 23:12:02  iter: 4579  total_loss: 58.56  loss_mask: 5.722  loss_mask_0: 6.574  loss_mask_1: 5.657  loss_mask_2: 5.876  loss_mask_3: 5.943  loss_mask_4: 5.869  loss_mask_5: 5.938  loss_mask_6: 5.735  loss_mask_7: 5.758  loss_mask_8: 5.781  time: 3.0630  data_time: 0.0725  lr: 9.3105e-05  max_mem: 27632M
[01/28 22:41:01] d2.utils.events INFO:  eta: 1 day, 23:10:00  iter: 4599  total_loss: 57.04  loss_mask: 5.758  loss_mask_0: 6.184  loss_mask_1: 5.581  loss_mask_2: 5.645  loss_mask_3: 5.801  loss_mask_4: 5.537  loss_mask_5: 5.676  loss_mask_6: 5.807  loss_mask_7: 5.693  loss_mask_8: 5.661  time: 3.0630  data_time: 0.0662  lr: 9.3074e-05  max_mem: 27632M
[01/28 22:42:02] d2.utils.events INFO:  eta: 1 day, 23:08:53  iter: 4619  total_loss: 63.83  loss_mask: 6.261  loss_mask_0: 7.015  loss_mask_1: 6.275  loss_mask_2: 6.478  loss_mask_3: 6.199  loss_mask_4: 6.5  loss_mask_5: 6.353  loss_mask_6: 6.233  loss_mask_7: 6.267  loss_mask_8: 6.226  time: 3.0630  data_time: 0.0656  lr: 9.3044e-05  max_mem: 27632M
[01/28 22:43:03] d2.utils.events INFO:  eta: 1 day, 23:07:23  iter: 4639  total_loss: 58.56  loss_mask: 5.843  loss_mask_0: 6.18  loss_mask_1: 5.722  loss_mask_2: 5.825  loss_mask_3: 5.862  loss_mask_4: 5.818  loss_mask_5: 5.859  loss_mask_6: 5.852  loss_mask_7: 5.804  loss_mask_8: 5.793  time: 3.0629  data_time: 0.0614  lr: 9.3014e-05  max_mem: 27632M
[01/28 22:44:05] d2.utils.events INFO:  eta: 1 day, 23:06:01  iter: 4659  total_loss: 69.16  loss_mask: 6.998  loss_mask_0: 6.887  loss_mask_1: 7.061  loss_mask_2: 6.969  loss_mask_3: 6.855  loss_mask_4: 6.884  loss_mask_5: 6.835  loss_mask_6: 6.829  loss_mask_7: 7.02  loss_mask_8: 6.867  time: 3.0630  data_time: 0.0657  lr: 9.2984e-05  max_mem: 27632M
[01/28 22:45:05] d2.utils.events INFO:  eta: 1 day, 23:03:32  iter: 4679  total_loss: 62.54  loss_mask: 6.205  loss_mask_0: 6.431  loss_mask_1: 6.188  loss_mask_2: 6.212  loss_mask_3: 6.262  loss_mask_4: 6.256  loss_mask_5: 6.221  loss_mask_6: 6.232  loss_mask_7: 6.265  loss_mask_8: 6.144  time: 3.0629  data_time: 0.0673  lr: 9.2953e-05  max_mem: 27632M
[01/28 22:46:06] d2.utils.events INFO:  eta: 1 day, 23:01:23  iter: 4699  total_loss: 61.61  loss_mask: 6.066  loss_mask_0: 6.406  loss_mask_1: 6.064  loss_mask_2: 6.07  loss_mask_3: 6.127  loss_mask_4: 6.203  loss_mask_5: 6.123  loss_mask_6: 6.111  loss_mask_7: 6.105  loss_mask_8: 6.118  time: 3.0626  data_time: 0.0694  lr: 9.2923e-05  max_mem: 27632M
[01/28 22:47:06] d2.utils.events INFO:  eta: 1 day, 22:59:36  iter: 4719  total_loss: 53.74  loss_mask: 5.404  loss_mask_0: 5.732  loss_mask_1: 5.338  loss_mask_2: 5.442  loss_mask_3: 5.499  loss_mask_4: 5.325  loss_mask_5: 5.272  loss_mask_6: 5.313  loss_mask_7: 5.241  loss_mask_8: 5.299  time: 3.0625  data_time: 0.0712  lr: 9.2893e-05  max_mem: 27632M
[01/28 22:48:07] d2.utils.events INFO:  eta: 1 day, 22:56:42  iter: 4739  total_loss: 53.23  loss_mask: 5.261  loss_mask_0: 5.588  loss_mask_1: 5.16  loss_mask_2: 5.516  loss_mask_3: 5.312  loss_mask_4: 5.49  loss_mask_5: 5.224  loss_mask_6: 5.249  loss_mask_7: 5.299  loss_mask_8: 5.285  time: 3.0624  data_time: 0.0664  lr: 9.2863e-05  max_mem: 27632M
[01/28 22:49:08] d2.utils.events INFO:  eta: 1 day, 22:54:39  iter: 4759  total_loss: 56.28  loss_mask: 5.625  loss_mask_0: 6.321  loss_mask_1: 5.506  loss_mask_2: 5.512  loss_mask_3: 5.507  loss_mask_4: 5.533  loss_mask_5: 5.545  loss_mask_6: 5.54  loss_mask_7: 5.49  loss_mask_8: 5.508  time: 3.0623  data_time: 0.0588  lr: 9.2832e-05  max_mem: 27632M
[01/28 22:50:09] d2.utils.events INFO:  eta: 1 day, 22:52:59  iter: 4779  total_loss: 57.57  loss_mask: 5.751  loss_mask_0: 6.489  loss_mask_1: 5.724  loss_mask_2: 5.651  loss_mask_3: 5.704  loss_mask_4: 5.728  loss_mask_5: 5.656  loss_mask_6: 5.654  loss_mask_7: 5.764  loss_mask_8: 5.701  time: 3.0623  data_time: 0.0643  lr: 9.2802e-05  max_mem: 27632M
[01/28 22:51:11] d2.utils.events INFO:  eta: 1 day, 22:52:03  iter: 4799  total_loss: 52.86  loss_mask: 5.244  loss_mask_0: 5.577  loss_mask_1: 5.169  loss_mask_2: 5.255  loss_mask_3: 5.272  loss_mask_4: 5.3  loss_mask_5: 5.249  loss_mask_6: 5.26  loss_mask_7: 5.221  loss_mask_8: 5.279  time: 3.0624  data_time: 0.0651  lr: 9.2772e-05  max_mem: 27632M
[01/28 22:52:13] d2.utils.events INFO:  eta: 1 day, 22:51:48  iter: 4819  total_loss: 58.54  loss_mask: 5.974  loss_mask_0: 6.415  loss_mask_1: 5.681  loss_mask_2: 5.771  loss_mask_3: 5.83  loss_mask_4: 5.813  loss_mask_5: 5.8  loss_mask_6: 5.873  loss_mask_7: 5.808  loss_mask_8: 5.852  time: 3.0625  data_time: 0.0610  lr: 9.2742e-05  max_mem: 27632M
[01/28 22:53:14] d2.utils.events INFO:  eta: 1 day, 22:50:58  iter: 4839  total_loss: 59.34  loss_mask: 6.011  loss_mask_0: 6.651  loss_mask_1: 5.713  loss_mask_2: 5.807  loss_mask_3: 5.776  loss_mask_4: 5.689  loss_mask_5: 5.757  loss_mask_6: 5.788  loss_mask_7: 5.751  loss_mask_8: 5.704  time: 3.0625  data_time: 0.0593  lr: 9.2711e-05  max_mem: 27632M
[01/28 22:54:15] d2.utils.events INFO:  eta: 1 day, 22:50:06  iter: 4859  total_loss: 56.13  loss_mask: 5.46  loss_mask_0: 6.072  loss_mask_1: 5.544  loss_mask_2: 5.559  loss_mask_3: 5.471  loss_mask_4: 5.585  loss_mask_5: 5.508  loss_mask_6: 5.451  loss_mask_7: 5.554  loss_mask_8: 5.526  time: 3.0624  data_time: 0.0645  lr: 9.2681e-05  max_mem: 27632M
[01/28 22:55:16] d2.utils.events INFO:  eta: 1 day, 22:49:01  iter: 4879  total_loss: 54.64  loss_mask: 5.531  loss_mask_0: 5.769  loss_mask_1: 5.36  loss_mask_2: 5.384  loss_mask_3: 5.506  loss_mask_4: 5.411  loss_mask_5: 5.445  loss_mask_6: 5.499  loss_mask_7: 5.401  loss_mask_8: 5.401  time: 3.0624  data_time: 0.0664  lr: 9.2651e-05  max_mem: 27632M
[01/28 22:56:17] d2.utils.events INFO:  eta: 1 day, 22:50:02  iter: 4899  total_loss: 58.15  loss_mask: 5.826  loss_mask_0: 6.191  loss_mask_1: 5.758  loss_mask_2: 5.803  loss_mask_3: 5.74  loss_mask_4: 5.816  loss_mask_5: 5.788  loss_mask_6: 5.799  loss_mask_7: 5.865  loss_mask_8: 5.702  time: 3.0624  data_time: 0.0672  lr: 9.2621e-05  max_mem: 27632M
[01/28 22:57:18] d2.utils.events INFO:  eta: 1 day, 22:48:52  iter: 4919  total_loss: 61.26  loss_mask: 6.122  loss_mask_0: 7.015  loss_mask_1: 6.042  loss_mask_2: 6.166  loss_mask_3: 6.178  loss_mask_4: 6.105  loss_mask_5: 6.134  loss_mask_6: 6.014  loss_mask_7: 6.204  loss_mask_8: 6.084  time: 3.0623  data_time: 0.0662  lr: 9.259e-05  max_mem: 27632M
[01/28 22:58:19] d2.utils.events INFO:  eta: 1 day, 22:46:54  iter: 4939  total_loss: 54.8  loss_mask: 5.444  loss_mask_0: 5.768  loss_mask_1: 5.44  loss_mask_2: 5.454  loss_mask_3: 5.469  loss_mask_4: 5.493  loss_mask_5: 5.476  loss_mask_6: 5.423  loss_mask_7: 5.463  loss_mask_8: 5.386  time: 3.0623  data_time: 0.0659  lr: 9.256e-05  max_mem: 27632M
[01/28 22:59:21] d2.utils.events INFO:  eta: 1 day, 22:45:53  iter: 4959  total_loss: 49.22  loss_mask: 4.901  loss_mask_0: 5.362  loss_mask_1: 4.858  loss_mask_2: 4.892  loss_mask_3: 4.865  loss_mask_4: 4.864  loss_mask_5: 4.879  loss_mask_6: 4.903  loss_mask_7: 4.856  loss_mask_8: 4.875  time: 3.0624  data_time: 0.0732  lr: 9.253e-05  max_mem: 27632M
[01/28 23:00:22] d2.utils.events INFO:  eta: 1 day, 22:45:16  iter: 4979  total_loss: 52.86  loss_mask: 5.232  loss_mask_0: 5.718  loss_mask_1: 5.123  loss_mask_2: 5.231  loss_mask_3: 5.286  loss_mask_4: 5.264  loss_mask_5: 5.171  loss_mask_6: 5.125  loss_mask_7: 5.247  loss_mask_8: 5.232  time: 3.0623  data_time: 0.0617  lr: 9.25e-05  max_mem: 27632M
[01/28 23:01:22] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/model_0004999.pth
[01/28 23:01:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 23:01:24] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 23:01:24] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 23:15:45] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 6.730395210827506, 'error_1pix': 0.7683433598313754, 'error_3pix': 0.5755496939270014, 'mIoU': 1.4917949043110303, 'fwIoU': 3.8300066507271286, 'IoU-0': 0.00018092018922004574, 'IoU-1': 14.476255450170013, 'IoU-2': 1.2953896338740138, 'IoU-3': 0.4846240312403848, 'IoU-4': 0.392394349970385, 'IoU-5': 0.3179224106965713, 'IoU-6': 0.20793944047956237, 'IoU-7': 0.17608327199568694, 'IoU-8': 0.6149871175428662, 'IoU-9': 1.9157129138124391, 'IoU-10': 2.7358903707530504, 'IoU-11': 3.8577061958796484, 'IoU-12': 3.579705753753008, 'IoU-13': 3.535321865101743, 'IoU-14': 2.7722585797599555, 'IoU-15': 2.5984844956747124, 'IoU-16': 2.352226647078441, 'IoU-17': 2.288429242914002, 'IoU-18': 2.190253217632014, 'IoU-19': 1.8672698884052774, 'IoU-20': 1.9873932317379968, 'IoU-21': 2.0062433941962987, 'IoU-22': 2.3796957056666166, 'IoU-23': 2.5442411487236147, 'IoU-24': 2.2875950808742465, 'IoU-25': 2.220485672597726, 'IoU-26': 2.5730348198612965, 'IoU-27': 2.831288575344337, 'IoU-28': 2.901923211735725, 'IoU-29': 3.1885005749137267, 'IoU-30': 3.2022692072030496, 'IoU-31': 3.7982191529580356, 'IoU-32': 4.129798295846453, 'IoU-33': 4.063917184256059, 'IoU-34': 4.215152028699356, 'IoU-35': 4.590695920795128, 'IoU-36': 4.936153850088926, 'IoU-37': 5.134126602736854, 'IoU-38': 5.216107040977798, 'IoU-39': 5.116072830585053, 'IoU-40': 5.094990044411128, 'IoU-41': 4.753267040329725, 'IoU-42': 4.569198615943889, 'IoU-43': 4.352538328318075, 'IoU-44': 4.192598884153028, 'IoU-45': 3.839088570286882, 'IoU-46': 3.4269104939352326, 'IoU-47': 3.239968696993252, 'IoU-48': 2.9686931967561376, 'IoU-49': 2.7436541647564265, 'IoU-50': 2.5027703258047307, 'IoU-51': 2.3197554780900638, 'IoU-52': 2.1202357735067565, 'IoU-53': 1.9734679431860678, 'IoU-54': 1.939299671286498, 'IoU-55': 1.7321744555532408, 'IoU-56': 1.5519710677475935, 'IoU-57': 1.52167031046083, 'IoU-58': 1.4258060374962236, 'IoU-59': 1.3116346455479342, 'IoU-60': 1.2325989118453669, 'IoU-61': 1.2192168644825474, 'IoU-62': 1.1472431790729594, 'IoU-63': 1.0341790572285632, 'IoU-64': 0.9640769044783368, 'IoU-65': 0.9047193885126373, 'IoU-66': 0.8734073672885787, 'IoU-67': 0.8560591005313863, 'IoU-68': 0.8350407193469247, 'IoU-69': 0.8189864021927507, 'IoU-70': 0.8286838524666589, 'IoU-71': 0.7326892419487718, 'IoU-72': 0.6637048470044784, 'IoU-73': 0.6936963087211144, 'IoU-74': 0.7058774271580518, 'IoU-75': 0.7414084436370035, 'IoU-76': 0.7219193174077737, 'IoU-77': 0.7002271233569045, 'IoU-78': 0.7185050735400492, 'IoU-79': 0.7286080059143843, 'IoU-80': 0.6690447385752373, 'IoU-81': 0.6591272230841464, 'IoU-82': 0.6340020453861539, 'IoU-83': 0.6589573123395858, 'IoU-84': 0.6419939510894502, 'IoU-85': 0.7046373915923776, 'IoU-86': 0.7065978837407388, 'IoU-87': 0.7302823904622929, 'IoU-88': 0.7314972628007506, 'IoU-89': 0.7440839970489731, 'IoU-90': 0.7758035827656125, 'IoU-91': 0.7841689153297838, 'IoU-92': 0.789444919881228, 'IoU-93': 0.7590469353334539, 'IoU-94': 0.7968092609256062, 'IoU-95': 0.88746951836185, 'IoU-96': 0.8683266360651443, 'IoU-97': 0.9906468138716237, 'IoU-98': 0.9475456655253521, 'IoU-99': 0.8962268500673349, 'IoU-100': 0.9794764157577018, 'IoU-101': 0.9447464421905614, 'IoU-102': 1.056068940426934, 'IoU-103': 1.0923707351495842, 'IoU-104': 1.0514720965383555, 'IoU-105': 1.059190594532958, 'IoU-106': 1.216715610828604, 'IoU-107': 1.244178790164061, 'IoU-108': 1.478655364957145, 'IoU-109': 1.4705597994259167, 'IoU-110': 1.5256393197231861, 'IoU-111': 1.441268540805842, 'IoU-112': 1.3356349595724217, 'IoU-113': 1.6872296870468035, 'IoU-114': 1.2352267569399589, 'IoU-115': 1.4959073333632924, 'IoU-116': 1.3449003000599755, 'IoU-117': 1.5183926967549632, 'IoU-118': 1.319630930135368, 'IoU-119': 1.2529049259154346, 'IoU-120': 1.2886670433287575, 'IoU-121': 1.277760971713824, 'IoU-122': 1.2452019903411022, 'IoU-123': 1.2372729409136674, 'IoU-124': 1.2227710607138669, 'IoU-125': 1.2317809779809519, 'IoU-126': 1.1047040273630189, 'IoU-127': 0.8896554341207399, 'IoU-128': 1.0640296603720834, 'IoU-129': 1.1813158627563058, 'IoU-130': 0.8981787579475492, 'IoU-131': 0.8165373680382606, 'IoU-132': 1.2739711960567863, 'IoU-133': 1.1394889590607433, 'IoU-134': 0.9831442352051023, 'IoU-135': 0.7381777905588087, 'IoU-136': 0.6367791870330907, 'IoU-137': 0.9785824695901023, 'IoU-138': 0.9622066868275966, 'IoU-139': 1.0068684359396907, 'IoU-140': 1.0873912226000992, 'IoU-141': 1.1978313144671544, 'IoU-142': 1.017048668458329, 'IoU-143': 1.2632335873710174, 'IoU-144': 0.9007852132809047, 'IoU-145': 0.8452688424512796, 'IoU-146': 0.6921031473552764, 'IoU-147': 0.7871216541533517, 'IoU-148': 0.9357291566385475, 'IoU-149': 1.231171198167559, 'IoU-150': 1.4376744958772427, 'IoU-151': 1.2790798982710376, 'IoU-152': 2.0977119943171147, 'IoU-153': 0.5754749683098637, 'IoU-154': 0.5744310901789768, 'IoU-155': 1.0169068563229147, 'IoU-156': 0.9119250134623589, 'IoU-157': 0.8359243415431933, 'IoU-158': 1.3424810383917212, 'IoU-159': 1.2853806833467851, 'IoU-160': 0.8020226065338847, 'IoU-161': 1.3035986208979404, 'IoU-162': 0.570343911545089, 'IoU-163': 0.8467933365455473, 'IoU-164': 1.0757006605536894, 'IoU-165': 0.9892478058309256, 'IoU-166': 1.0561889066979704, 'IoU-167': 1.1847213374321546, 'IoU-168': 0.9473665674690521, 'IoU-169': 1.016809610973007, 'IoU-170': 0.9181111831931684, 'IoU-171': 1.1894961458874147, 'IoU-172': 0.6791551536625764, 'IoU-173': 0.0367171020236959, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 3.309980029588627, 'pACC': 5.847051656920078, 'ACC-0': 0.0014733434559783198, 'ACC-1': 14.781665134811513, 'ACC-2': 3.247715425941047, 'ACC-3': 3.9835840933931985, 'ACC-4': 3.5623819121218334, 'ACC-5': 3.8692134214376237, 'ACC-6': 4.085803424065729, 'ACC-7': 6.181928233625402, 'ACC-8': 10.510267420414028, 'ACC-9': 13.072253655029012, 'ACC-10': 10.274191396591903, 'ACC-11': 8.858413755052897, 'ACC-12': 7.216040198383851, 'ACC-13': 6.683154144701123, 'ACC-14': 5.14041423854267, 'ACC-15': 4.860042283876961, 'ACC-16': 4.384401137368847, 'ACC-17': 4.493191100026643, 'ACC-18': 4.116580365394864, 'ACC-19': 3.5063842735783273, 'ACC-20': 3.7633488162193904, 'ACC-21': 3.748107314306088, 'ACC-22': 4.273045671411317, 'ACC-23': 4.734308560605072, 'ACC-24': 4.304372739422691, 'ACC-25': 4.187197039530773, 'ACC-26': 4.787156190677473, 'ACC-27': 5.051944782077775, 'ACC-28': 5.196630423727937, 'ACC-29': 5.48324804521592, 'ACC-30': 5.480459042070928, 'ACC-31': 6.319917188733519, 'ACC-32': 6.883795505573087, 'ACC-33': 6.873955356701883, 'ACC-34': 7.100173172918585, 'ACC-35': 7.511308857647972, 'ACC-36': 7.932417069175024, 'ACC-37': 8.274006921080682, 'ACC-38': 8.331177651639347, 'ACC-39': 8.189206711888101, 'ACC-40': 8.158393757103314, 'ACC-41': 7.882672893065254, 'ACC-42': 7.653019722896754, 'ACC-43': 7.3296070095769466, 'ACC-44': 6.965791766643359, 'ACC-45': 6.477428737310167, 'ACC-46': 5.960707899777984, 'ACC-47': 5.675085938548033, 'ACC-48': 5.241255114812646, 'ACC-49': 4.871010372100649, 'ACC-50': 4.480391476306816, 'ACC-51': 4.209789515049205, 'ACC-52': 3.8652018220320383, 'ACC-53': 3.6190431101871057, 'ACC-54': 3.555621505688591, 'ACC-55': 3.224082382788641, 'ACC-56': 2.9572831579344876, 'ACC-57': 2.8853743007044885, 'ACC-58': 2.7587180444117876, 'ACC-59': 2.6155851361406612, 'ACC-60': 2.515908252019929, 'ACC-61': 2.536533345442113, 'ACC-62': 2.417784360995231, 'ACC-63': 2.20156064851911, 'ACC-64': 2.056235818780501, 'ACC-65': 1.9438277213316077, 'ACC-66': 1.8804442789155167, 'ACC-67': 1.8344522755469352, 'ACC-68': 1.7671956222254752, 'ACC-69': 1.6848887076941426, 'ACC-70': 1.6735051525866296, 'ACC-71': 1.4898007450216577, 'ACC-72': 1.340475318656471, 'ACC-73': 1.3836926078276508, 'ACC-74': 1.3883552878030936, 'ACC-75': 1.445728531819656, 'ACC-76': 1.3700568382319611, 'ACC-77': 1.33970433192827, 'ACC-78': 1.3865715953309983, 'ACC-79': 1.4059493215348893, 'ACC-80': 1.2780387894547867, 'ACC-81': 1.2604748719414705, 'ACC-82': 1.2229215688877717, 'ACC-83': 1.2649749657181646, 'ACC-84': 1.2471457170359168, 'ACC-85': 1.3838065837049298, 'ACC-86': 1.4058332004219172, 'ACC-87': 1.4886501665379583, 'ACC-88': 1.5269883060854055, 'ACC-89': 1.5685695165188547, 'ACC-90': 1.6563155898211894, 'ACC-91': 1.719953810158445, 'ACC-92': 1.7757240452369099, 'ACC-93': 1.7490800925350967, 'ACC-94': 1.8681532218629806, 'ACC-95': 2.112513339356374, 'ACC-96': 2.1280897218573793, 'ACC-97': 2.4566718183326373, 'ACC-98': 2.4004012132440087, 'ACC-99': 2.3427634994257205, 'ACC-100': 2.5938310679910828, 'ACC-101': 2.517899792114806, 'ACC-102': 2.857430901676484, 'ACC-103': 2.9828327193728157, 'ACC-104': 2.832665207446939, 'ACC-105': 2.8420265755700793, 'ACC-106': 3.212083690285423, 'ACC-107': 3.3292592979387226, 'ACC-108': 3.8653260104459757, 'ACC-109': 3.816137313018173, 'ACC-110': 4.011569420285448, 'ACC-111': 3.7665459789945155, 'ACC-112': 3.461705034036485, 'ACC-113': 4.466164188084426, 'ACC-114': 3.1597702184076732, 'ACC-115': 3.89115661599988, 'ACC-116': 3.484760828246273, 'ACC-117': 3.87607116135871, 'ACC-118': 3.3701600161565475, 'ACC-119': 3.113096639684466, 'ACC-120': 3.260057910512796, 'ACC-121': 3.3267215563762615, 'ACC-122': 3.129676281053337, 'ACC-123': 3.099163359116109, 'ACC-124': 3.0432033225702826, 'ACC-125': 2.9824454540807057, 'ACC-126': 2.6812061129882787, 'ACC-127': 2.0676415067891485, 'ACC-128': 2.6179089659479127, 'ACC-129': 2.9841380206192554, 'ACC-130': 2.157848845458321, 'ACC-131': 1.9697443964397197, 'ACC-132': 3.1928903901639676, 'ACC-133': 2.7173447100369468, 'ACC-134': 2.2859112451529513, 'ACC-135': 1.6755743686220854, 'ACC-136': 1.4628418514722326, 'ACC-137': 2.5034021082003974, 'ACC-138': 2.489720029443866, 'ACC-139': 2.6848878420467095, 'ACC-140': 2.941093646210702, 'ACC-141': 3.250922763865022, 'ACC-142': 3.0164331856556115, 'ACC-143': 3.6560084755129383, 'ACC-144': 2.4057761732851985, 'ACC-145': 2.1864531854469016, 'ACC-146': 1.8431381508304585, 'ACC-147': 2.2696737088700565, 'ACC-148': 2.4206050847344853, 'ACC-149': 3.6499474174728137, 'ACC-150': 3.88749740725801, 'ACC-151': 3.614367946557702, 'ACC-152': 5.96793023804707, 'ACC-153': 1.545580717858517, 'ACC-154': 1.5392166187019105, 'ACC-155': 3.415396523715498, 'ACC-156': 2.95112696904471, 'ACC-157': 2.982988378091089, 'ACC-158': 4.577934404157217, 'ACC-159': 4.233357055973143, 'ACC-160': 2.577987151065466, 'ACC-161': 3.8911527562858597, 'ACC-162': 1.701720613744083, 'ACC-163': 2.922953924609465, 'ACC-164': 4.688307611325506, 'ACC-165': 3.6932982241040317, 'ACC-166': 3.927273337754237, 'ACC-167': 4.777935855277443, 'ACC-168': 3.5944862507911948, 'ACC-169': 4.464346815981245, 'ACC-170': 4.1238979513607905, 'ACC-171': 4.397796509609503, 'ACC-172': 1.3092195429121756, 'ACC-173': 0.05681967842319748, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/28 23:15:45] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 23:15:45] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 23:15:45] d2.evaluation.testing INFO: copypaste: 6.7304,0.7683,0.5755,1.4918,3.8300,3.3100,5.8471
[01/28 23:15:45] d2.utils.events INFO:  eta: 1 day, 22:44:15  iter: 4999  total_loss: 58.02  loss_mask: 5.779  loss_mask_0: 6.227  loss_mask_1: 5.709  loss_mask_2: 5.707  loss_mask_3: 5.838  loss_mask_4: 5.69  loss_mask_5: 5.742  loss_mask_6: 5.778  loss_mask_7: 5.747  loss_mask_8: 5.74  time: 3.0621  data_time: 0.0601  lr: 9.2469e-05  max_mem: 27632M
[01/28 23:16:46] d2.utils.events INFO:  eta: 1 day, 22:41:57  iter: 5019  total_loss: 64.92  loss_mask: 6.388  loss_mask_0: 6.755  loss_mask_1: 6.418  loss_mask_2: 6.464  loss_mask_3: 6.444  loss_mask_4: 6.49  loss_mask_5: 6.307  loss_mask_6: 6.359  loss_mask_7: 6.32  loss_mask_8: 6.39  time: 3.0619  data_time: 0.0705  lr: 9.2439e-05  max_mem: 27632M
[01/28 23:17:48] d2.utils.events INFO:  eta: 1 day, 22:41:00  iter: 5039  total_loss: 52.57  loss_mask: 5.263  loss_mask_0: 5.552  loss_mask_1: 5.126  loss_mask_2: 5.187  loss_mask_3: 5.198  loss_mask_4: 5.241  loss_mask_5: 5.177  loss_mask_6: 5.144  loss_mask_7: 5.251  loss_mask_8: 5.186  time: 3.0620  data_time: 0.0740  lr: 9.2409e-05  max_mem: 27632M
[01/28 23:18:49] d2.utils.events INFO:  eta: 1 day, 22:39:46  iter: 5059  total_loss: 49.05  loss_mask: 4.889  loss_mask_0: 5.337  loss_mask_1: 4.804  loss_mask_2: 4.838  loss_mask_3: 4.885  loss_mask_4: 4.804  loss_mask_5: 4.889  loss_mask_6: 4.861  loss_mask_7: 4.892  loss_mask_8: 4.85  time: 3.0620  data_time: 0.0713  lr: 9.2378e-05  max_mem: 27632M
[01/28 23:19:50] d2.utils.events INFO:  eta: 1 day, 22:38:33  iter: 5079  total_loss: 56.23  loss_mask: 5.55  loss_mask_0: 6.15  loss_mask_1: 5.519  loss_mask_2: 5.585  loss_mask_3: 5.485  loss_mask_4: 5.616  loss_mask_5: 5.556  loss_mask_6: 5.445  loss_mask_7: 5.66  loss_mask_8: 5.432  time: 3.0620  data_time: 0.0623  lr: 9.2348e-05  max_mem: 27632M
[01/28 23:20:50] d2.utils.events INFO:  eta: 1 day, 22:37:32  iter: 5099  total_loss: 61.88  loss_mask: 6.227  loss_mask_0: 6.313  loss_mask_1: 6.064  loss_mask_2: 6.133  loss_mask_3: 6.213  loss_mask_4: 6.188  loss_mask_5: 6.216  loss_mask_6: 6.12  loss_mask_7: 6.068  loss_mask_8: 6.178  time: 3.0618  data_time: 0.0618  lr: 9.2318e-05  max_mem: 27632M
[01/28 23:21:52] d2.utils.events INFO:  eta: 1 day, 22:36:31  iter: 5119  total_loss: 54.65  loss_mask: 5.442  loss_mask_0: 5.756  loss_mask_1: 5.385  loss_mask_2: 5.372  loss_mask_3: 5.442  loss_mask_4: 5.385  loss_mask_5: 5.424  loss_mask_6: 5.392  loss_mask_7: 5.405  loss_mask_8: 5.61  time: 3.0618  data_time: 0.0608  lr: 9.2288e-05  max_mem: 27632M
[01/28 23:22:54] d2.utils.events INFO:  eta: 1 day, 22:35:22  iter: 5139  total_loss: 56.26  loss_mask: 5.598  loss_mask_0: 5.655  loss_mask_1: 5.456  loss_mask_2: 5.545  loss_mask_3: 5.491  loss_mask_4: 5.503  loss_mask_5: 5.68  loss_mask_6: 5.651  loss_mask_7: 5.579  loss_mask_8: 5.608  time: 3.0619  data_time: 0.0722  lr: 9.2257e-05  max_mem: 27632M
[01/28 23:23:56] d2.utils.events INFO:  eta: 1 day, 22:34:40  iter: 5159  total_loss: 52.43  loss_mask: 5.221  loss_mask_0: 5.806  loss_mask_1: 5.235  loss_mask_2: 5.254  loss_mask_3: 5.179  loss_mask_4: 5.195  loss_mask_5: 5.238  loss_mask_6: 5.176  loss_mask_7: 5.227  loss_mask_8: 5.292  time: 3.0621  data_time: 0.0834  lr: 9.2227e-05  max_mem: 27632M
[01/28 23:24:58] d2.utils.events INFO:  eta: 1 day, 22:33:48  iter: 5179  total_loss: 52.14  loss_mask: 5.212  loss_mask_0: 5.548  loss_mask_1: 5.129  loss_mask_2: 5.302  loss_mask_3: 5.283  loss_mask_4: 5.157  loss_mask_5: 5.22  loss_mask_6: 5.243  loss_mask_7: 5.221  loss_mask_8: 5.229  time: 3.0622  data_time: 0.0725  lr: 9.2197e-05  max_mem: 27632M
[01/28 23:26:00] d2.utils.events INFO:  eta: 1 day, 22:34:48  iter: 5199  total_loss: 47.71  loss_mask: 4.718  loss_mask_0: 4.992  loss_mask_1: 4.696  loss_mask_2: 4.816  loss_mask_3: 4.761  loss_mask_4: 4.757  loss_mask_5: 4.714  loss_mask_6: 4.806  loss_mask_7: 4.745  loss_mask_8: 4.745  time: 3.0624  data_time: 0.0716  lr: 9.2167e-05  max_mem: 27632M
[01/28 23:27:02] d2.utils.events INFO:  eta: 1 day, 22:34:41  iter: 5219  total_loss: 51.7  loss_mask: 5.146  loss_mask_0: 5.359  loss_mask_1: 5.124  loss_mask_2: 5.14  loss_mask_3: 5.138  loss_mask_4: 5.171  loss_mask_5: 5.199  loss_mask_6: 5.157  loss_mask_7: 5.136  loss_mask_8: 5.178  time: 3.0624  data_time: 0.0688  lr: 9.2136e-05  max_mem: 27632M
[01/28 23:28:03] d2.utils.events INFO:  eta: 1 day, 22:33:08  iter: 5239  total_loss: 52.71  loss_mask: 5.295  loss_mask_0: 5.36  loss_mask_1: 5.178  loss_mask_2: 5.216  loss_mask_3: 5.262  loss_mask_4: 5.214  loss_mask_5: 5.274  loss_mask_6: 5.262  loss_mask_7: 5.271  loss_mask_8: 5.318  time: 3.0624  data_time: 0.0593  lr: 9.2106e-05  max_mem: 27632M
[01/28 23:29:04] d2.utils.events INFO:  eta: 1 day, 22:32:00  iter: 5259  total_loss: 52.02  loss_mask: 5.177  loss_mask_0: 5.398  loss_mask_1: 5.169  loss_mask_2: 5.129  loss_mask_3: 5.192  loss_mask_4: 5.261  loss_mask_5: 5.135  loss_mask_6: 5.204  loss_mask_7: 5.223  loss_mask_8: 5.21  time: 3.0624  data_time: 0.0805  lr: 9.2076e-05  max_mem: 27632M
[01/28 23:30:05] d2.utils.events INFO:  eta: 1 day, 22:31:02  iter: 5279  total_loss: 54.98  loss_mask: 5.474  loss_mask_0: 5.917  loss_mask_1: 5.457  loss_mask_2: 5.491  loss_mask_3: 5.513  loss_mask_4: 5.482  loss_mask_5: 5.461  loss_mask_6: 5.409  loss_mask_7: 5.449  loss_mask_8: 5.413  time: 3.0624  data_time: 0.0757  lr: 9.2045e-05  max_mem: 27632M
[01/28 23:31:07] d2.utils.events INFO:  eta: 1 day, 22:30:36  iter: 5299  total_loss: 52.51  loss_mask: 5.275  loss_mask_0: 5.419  loss_mask_1: 5.193  loss_mask_2: 5.27  loss_mask_3: 5.285  loss_mask_4: 5.281  loss_mask_5: 5.26  loss_mask_6: 5.253  loss_mask_7: 5.184  loss_mask_8: 5.185  time: 3.0625  data_time: 0.0761  lr: 9.2015e-05  max_mem: 27632M
[01/28 23:32:08] d2.utils.events INFO:  eta: 1 day, 22:29:04  iter: 5319  total_loss: 52.66  loss_mask: 5.264  loss_mask_0: 5.584  loss_mask_1: 5.267  loss_mask_2: 5.212  loss_mask_3: 5.216  loss_mask_4: 5.224  loss_mask_5: 5.238  loss_mask_6: 5.284  loss_mask_7: 5.319  loss_mask_8: 5.236  time: 3.0624  data_time: 0.0597  lr: 9.1985e-05  max_mem: 27632M
[01/28 23:33:09] d2.utils.events INFO:  eta: 1 day, 22:27:47  iter: 5339  total_loss: 56.42  loss_mask: 5.626  loss_mask_0: 5.77  loss_mask_1: 5.618  loss_mask_2: 5.646  loss_mask_3: 5.667  loss_mask_4: 5.744  loss_mask_5: 5.587  loss_mask_6: 5.626  loss_mask_7: 5.572  loss_mask_8: 5.599  time: 3.0624  data_time: 0.0546  lr: 9.1955e-05  max_mem: 27632M
[01/28 23:34:09] d2.utils.events INFO:  eta: 1 day, 22:25:51  iter: 5359  total_loss: 52.11  loss_mask: 5.125  loss_mask_0: 5.61  loss_mask_1: 5.084  loss_mask_2: 5.127  loss_mask_3: 5.205  loss_mask_4: 5.045  loss_mask_5: 5.167  loss_mask_6: 5.115  loss_mask_7: 5.209  loss_mask_8: 5.159  time: 3.0622  data_time: 0.0589  lr: 9.1924e-05  max_mem: 27632M
[01/28 23:35:11] d2.utils.events INFO:  eta: 1 day, 22:24:05  iter: 5379  total_loss: 57.53  loss_mask: 5.827  loss_mask_0: 5.925  loss_mask_1: 5.657  loss_mask_2: 5.73  loss_mask_3: 5.847  loss_mask_4: 5.674  loss_mask_5: 5.682  loss_mask_6: 5.86  loss_mask_7: 5.679  loss_mask_8: 5.751  time: 3.0622  data_time: 0.0769  lr: 9.1894e-05  max_mem: 27632M
[01/28 23:36:11] d2.utils.events INFO:  eta: 1 day, 22:22:15  iter: 5399  total_loss: 65.18  loss_mask: 6.458  loss_mask_0: 6.713  loss_mask_1: 6.392  loss_mask_2: 6.492  loss_mask_3: 6.399  loss_mask_4: 6.414  loss_mask_5: 6.487  loss_mask_6: 6.416  loss_mask_7: 6.483  loss_mask_8: 6.508  time: 3.0621  data_time: 0.0665  lr: 9.1864e-05  max_mem: 27632M
[01/28 23:37:11] d2.utils.events INFO:  eta: 1 day, 22:20:17  iter: 5419  total_loss: 53.86  loss_mask: 5.302  loss_mask_0: 5.338  loss_mask_1: 5.328  loss_mask_2: 5.236  loss_mask_3: 5.747  loss_mask_4: 5.393  loss_mask_5: 5.493  loss_mask_6: 5.495  loss_mask_7: 5.389  loss_mask_8: 5.448  time: 3.0618  data_time: 0.0508  lr: 9.1834e-05  max_mem: 27632M
[01/28 23:38:12] d2.utils.events INFO:  eta: 1 day, 22:17:28  iter: 5439  total_loss: 50.02  loss_mask: 5.014  loss_mask_0: 5.182  loss_mask_1: 4.826  loss_mask_2: 4.882  loss_mask_3: 5.029  loss_mask_4: 4.927  loss_mask_5: 4.939  loss_mask_6: 4.882  loss_mask_7: 4.774  loss_mask_8: 5.15  time: 3.0618  data_time: 0.0557  lr: 9.1803e-05  max_mem: 27632M
[01/28 23:39:13] d2.utils.events INFO:  eta: 1 day, 22:15:24  iter: 5459  total_loss: 53.18  loss_mask: 5.363  loss_mask_0: 5.465  loss_mask_1: 5.305  loss_mask_2: 5.385  loss_mask_3: 5.372  loss_mask_4: 5.304  loss_mask_5: 5.258  loss_mask_6: 5.279  loss_mask_7: 5.33  loss_mask_8: 5.31  time: 3.0617  data_time: 0.0690  lr: 9.1773e-05  max_mem: 27632M
[01/28 23:40:13] d2.utils.events INFO:  eta: 1 day, 22:12:42  iter: 5479  total_loss: 51.75  loss_mask: 5.212  loss_mask_0: 5.492  loss_mask_1: 5.051  loss_mask_2: 5.113  loss_mask_3: 5.141  loss_mask_4: 5.124  loss_mask_5: 5.122  loss_mask_6: 5.171  loss_mask_7: 5.188  loss_mask_8: 5.127  time: 3.0615  data_time: 0.0620  lr: 9.1743e-05  max_mem: 27632M
[01/28 23:41:14] d2.utils.events INFO:  eta: 1 day, 22:10:41  iter: 5499  total_loss: 51.95  loss_mask: 5.175  loss_mask_0: 5.587  loss_mask_1: 5.142  loss_mask_2: 5.169  loss_mask_3: 5.166  loss_mask_4: 5.205  loss_mask_5: 5.188  loss_mask_6: 5.198  loss_mask_7: 5.133  loss_mask_8: 5.157  time: 3.0615  data_time: 0.0684  lr: 9.1712e-05  max_mem: 27632M
[01/28 23:42:15] d2.utils.events INFO:  eta: 1 day, 22:08:38  iter: 5519  total_loss: 51.38  loss_mask: 5.062  loss_mask_0: 5.472  loss_mask_1: 4.997  loss_mask_2: 5.08  loss_mask_3: 5.015  loss_mask_4: 5.058  loss_mask_5: 5.035  loss_mask_6: 5.021  loss_mask_7: 5.129  loss_mask_8: 5.128  time: 3.0614  data_time: 0.0706  lr: 9.1682e-05  max_mem: 27632M
[01/28 23:43:16] d2.utils.events INFO:  eta: 1 day, 22:06:21  iter: 5539  total_loss: 52.93  loss_mask: 5.285  loss_mask_0: 5.445  loss_mask_1: 5.037  loss_mask_2: 5.16  loss_mask_3: 5.29  loss_mask_4: 5.301  loss_mask_5: 5.176  loss_mask_6: 5.231  loss_mask_7: 5.233  loss_mask_8: 5.354  time: 3.0613  data_time: 0.0685  lr: 9.1652e-05  max_mem: 27632M
[01/28 23:44:17] d2.utils.events INFO:  eta: 1 day, 22:05:37  iter: 5559  total_loss: 52  loss_mask: 5.035  loss_mask_0: 5.34  loss_mask_1: 5.161  loss_mask_2: 5.32  loss_mask_3: 5.368  loss_mask_4: 5.118  loss_mask_5: 5.09  loss_mask_6: 5.064  loss_mask_7: 5.075  loss_mask_8: 5.084  time: 3.0613  data_time: 0.0612  lr: 9.1621e-05  max_mem: 27632M
[01/28 23:45:18] d2.utils.events INFO:  eta: 1 day, 22:03:07  iter: 5579  total_loss: 54.63  loss_mask: 5.286  loss_mask_0: 5.672  loss_mask_1: 5.604  loss_mask_2: 5.807  loss_mask_3: 5.442  loss_mask_4: 5.371  loss_mask_5: 5.423  loss_mask_6: 5.396  loss_mask_7: 5.33  loss_mask_8: 5.389  time: 3.0612  data_time: 0.0619  lr: 9.1591e-05  max_mem: 27632M
[01/28 23:46:19] d2.utils.events INFO:  eta: 1 day, 22:01:44  iter: 5599  total_loss: 53.04  loss_mask: 5.237  loss_mask_0: 5.468  loss_mask_1: 5.138  loss_mask_2: 5.447  loss_mask_3: 5.239  loss_mask_4: 5.271  loss_mask_5: 5.252  loss_mask_6: 5.231  loss_mask_7: 5.22  loss_mask_8: 5.114  time: 3.0611  data_time: 0.0703  lr: 9.1561e-05  max_mem: 27632M
[01/28 23:47:19] d2.utils.events INFO:  eta: 1 day, 21:59:06  iter: 5619  total_loss: 51.72  loss_mask: 5.16  loss_mask_0: 5.391  loss_mask_1: 5.117  loss_mask_2: 5.154  loss_mask_3: 5.11  loss_mask_4: 5.163  loss_mask_5: 5.148  loss_mask_6: 5.222  loss_mask_7: 5.223  loss_mask_8: 5.223  time: 3.0609  data_time: 0.0729  lr: 9.1531e-05  max_mem: 27632M
[01/28 23:48:19] d2.utils.events INFO:  eta: 1 day, 21:58:15  iter: 5639  total_loss: 49.78  loss_mask: 5.016  loss_mask_0: 5.219  loss_mask_1: 4.935  loss_mask_2: 5.045  loss_mask_3: 4.935  loss_mask_4: 4.973  loss_mask_5: 4.924  loss_mask_6: 4.868  loss_mask_7: 5.009  loss_mask_8: 4.922  time: 3.0608  data_time: 0.0630  lr: 9.15e-05  max_mem: 27632M
[01/28 23:49:21] d2.utils.events INFO:  eta: 1 day, 21:56:23  iter: 5659  total_loss: 58.66  loss_mask: 6.105  loss_mask_0: 6.217  loss_mask_1: 5.753  loss_mask_2: 5.659  loss_mask_3: 5.728  loss_mask_4: 5.696  loss_mask_5: 5.633  loss_mask_6: 5.584  loss_mask_7: 5.68  loss_mask_8: 5.688  time: 3.0609  data_time: 0.0753  lr: 9.147e-05  max_mem: 27632M
[01/28 23:50:23] d2.utils.events INFO:  eta: 1 day, 21:56:19  iter: 5679  total_loss: 60.16  loss_mask: 6.486  loss_mask_0: 6.056  loss_mask_1: 6.181  loss_mask_2: 5.959  loss_mask_3: 5.947  loss_mask_4: 5.892  loss_mask_5: 5.908  loss_mask_6: 5.839  loss_mask_7: 6.095  loss_mask_8: 6.058  time: 3.0610  data_time: 0.0711  lr: 9.144e-05  max_mem: 27632M
[01/28 23:51:24] d2.utils.events INFO:  eta: 1 day, 21:56:10  iter: 5699  total_loss: 57.9  loss_mask: 6.612  loss_mask_0: 5.862  loss_mask_1: 5.575  loss_mask_2: 5.792  loss_mask_3: 5.735  loss_mask_4: 5.586  loss_mask_5: 5.645  loss_mask_6: 5.661  loss_mask_7: 5.525  loss_mask_8: 5.848  time: 3.0610  data_time: 0.0681  lr: 9.1409e-05  max_mem: 27632M
[01/28 23:52:25] d2.utils.events INFO:  eta: 1 day, 21:55:10  iter: 5719  total_loss: 52.25  loss_mask: 5.78  loss_mask_0: 5.426  loss_mask_1: 5.124  loss_mask_2: 5.203  loss_mask_3: 5.077  loss_mask_4: 5.09  loss_mask_5: 5.014  loss_mask_6: 5.04  loss_mask_7: 5.131  loss_mask_8: 5.243  time: 3.0610  data_time: 0.0607  lr: 9.1379e-05  max_mem: 27632M
[01/28 23:53:27] d2.utils.events INFO:  eta: 1 day, 21:54:22  iter: 5739  total_loss: 50.48  loss_mask: 5.431  loss_mask_0: 5.305  loss_mask_1: 4.985  loss_mask_2: 4.956  loss_mask_3: 5.039  loss_mask_4: 5.003  loss_mask_5: 5.051  loss_mask_6: 5.029  loss_mask_7: 4.996  loss_mask_8: 5.031  time: 3.0610  data_time: 0.0703  lr: 9.1349e-05  max_mem: 27632M
[01/28 23:54:28] d2.utils.events INFO:  eta: 1 day, 21:53:50  iter: 5759  total_loss: 49.78  loss_mask: 5.452  loss_mask_0: 5.028  loss_mask_1: 4.875  loss_mask_2: 4.947  loss_mask_3: 4.964  loss_mask_4: 4.855  loss_mask_5: 4.815  loss_mask_6: 4.921  loss_mask_7: 4.867  loss_mask_8: 4.999  time: 3.0610  data_time: 0.0772  lr: 9.1319e-05  max_mem: 27632M
[01/28 23:55:30] d2.utils.events INFO:  eta: 1 day, 21:53:01  iter: 5779  total_loss: 52.31  loss_mask: 5.19  loss_mask_0: 5.337  loss_mask_1: 5.175  loss_mask_2: 5.291  loss_mask_3: 5.089  loss_mask_4: 5.136  loss_mask_5: 5.101  loss_mask_6: 5.13  loss_mask_7: 5.108  loss_mask_8: 5.13  time: 3.0611  data_time: 0.0723  lr: 9.1288e-05  max_mem: 27632M
[01/28 23:56:32] d2.utils.events INFO:  eta: 1 day, 21:52:18  iter: 5799  total_loss: 54.09  loss_mask: 5.889  loss_mask_0: 5.874  loss_mask_1: 5.26  loss_mask_2: 5.407  loss_mask_3: 5.155  loss_mask_4: 5.233  loss_mask_5: 5.252  loss_mask_6: 5.197  loss_mask_7: 5.241  loss_mask_8: 5.376  time: 3.0612  data_time: 0.0699  lr: 9.1258e-05  max_mem: 27632M
[01/28 23:57:33] d2.utils.events INFO:  eta: 1 day, 21:51:04  iter: 5819  total_loss: 52.59  loss_mask: 5.392  loss_mask_0: 5.156  loss_mask_1: 5.249  loss_mask_2: 5.197  loss_mask_3: 5.344  loss_mask_4: 5.216  loss_mask_5: 5.264  loss_mask_6: 5.293  loss_mask_7: 5.214  loss_mask_8: 5.243  time: 3.0612  data_time: 0.0659  lr: 9.1228e-05  max_mem: 27632M
[01/28 23:58:33] d2.utils.events INFO:  eta: 1 day, 21:49:04  iter: 5839  total_loss: 47.49  loss_mask: 5.021  loss_mask_0: 5.041  loss_mask_1: 4.632  loss_mask_2: 4.582  loss_mask_3: 4.608  loss_mask_4: 4.65  loss_mask_5: 4.684  loss_mask_6: 4.612  loss_mask_7: 4.567  loss_mask_8: 4.567  time: 3.0611  data_time: 0.0630  lr: 9.1197e-05  max_mem: 27632M
[01/28 23:59:35] d2.utils.events INFO:  eta: 1 day, 21:48:32  iter: 5859  total_loss: 47.65  loss_mask: 4.84  loss_mask_0: 5.021  loss_mask_1: 4.667  loss_mask_2: 4.758  loss_mask_3: 4.714  loss_mask_4: 4.663  loss_mask_5: 4.781  loss_mask_6: 4.792  loss_mask_7: 4.683  loss_mask_8: 4.819  time: 3.0611  data_time: 0.0632  lr: 9.1167e-05  max_mem: 27632M
[01/29 00:00:36] d2.utils.events INFO:  eta: 1 day, 21:47:15  iter: 5879  total_loss: 52.15  loss_mask: 5.267  loss_mask_0: 5.415  loss_mask_1: 5.124  loss_mask_2: 5.263  loss_mask_3: 5.183  loss_mask_4: 5.189  loss_mask_5: 5.166  loss_mask_6: 5.267  loss_mask_7: 5.21  loss_mask_8: 5.121  time: 3.0611  data_time: 0.0663  lr: 9.1137e-05  max_mem: 27632M
[01/29 00:01:37] d2.utils.events INFO:  eta: 1 day, 21:45:09  iter: 5899  total_loss: 53.18  loss_mask: 5.433  loss_mask_0: 5.378  loss_mask_1: 5.265  loss_mask_2: 5.217  loss_mask_3: 5.285  loss_mask_4: 5.285  loss_mask_5: 5.361  loss_mask_6: 5.289  loss_mask_7: 5.284  loss_mask_8: 5.285  time: 3.0611  data_time: 0.0745  lr: 9.1106e-05  max_mem: 27632M
[01/29 00:02:38] d2.utils.events INFO:  eta: 1 day, 21:43:23  iter: 5919  total_loss: 48.48  loss_mask: 4.91  loss_mask_0: 4.93  loss_mask_1: 4.819  loss_mask_2: 4.846  loss_mask_3: 4.812  loss_mask_4: 4.766  loss_mask_5: 4.647  loss_mask_6: 4.866  loss_mask_7: 4.801  loss_mask_8: 4.875  time: 3.0610  data_time: 0.0620  lr: 9.1076e-05  max_mem: 27632M
[01/29 00:03:39] d2.utils.events INFO:  eta: 1 day, 21:42:24  iter: 5939  total_loss: 45.12  loss_mask: 4.612  loss_mask_0: 4.66  loss_mask_1: 4.438  loss_mask_2: 4.461  loss_mask_3: 4.487  loss_mask_4: 4.739  loss_mask_5: 4.572  loss_mask_6: 4.605  loss_mask_7: 4.588  loss_mask_8: 4.417  time: 3.0609  data_time: 0.0659  lr: 9.1046e-05  max_mem: 27632M
[01/29 00:04:40] d2.utils.events INFO:  eta: 1 day, 21:42:01  iter: 5959  total_loss: 47.48  loss_mask: 4.744  loss_mask_0: 4.84  loss_mask_1: 4.7  loss_mask_2: 4.709  loss_mask_3: 4.717  loss_mask_4: 4.823  loss_mask_5: 4.754  loss_mask_6: 4.747  loss_mask_7: 4.749  loss_mask_8: 4.711  time: 3.0609  data_time: 0.0622  lr: 9.1015e-05  max_mem: 27632M
[01/29 00:05:42] d2.utils.events INFO:  eta: 1 day, 21:41:11  iter: 5979  total_loss: 48.42  loss_mask: 4.866  loss_mask_0: 4.801  loss_mask_1: 4.79  loss_mask_2: 4.831  loss_mask_3: 4.8  loss_mask_4: 4.857  loss_mask_5: 4.766  loss_mask_6: 4.794  loss_mask_7: 4.845  loss_mask_8: 4.786  time: 3.0610  data_time: 0.0705  lr: 9.0985e-05  max_mem: 27632M
[01/29 00:06:42] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 00:06:43] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 00:06:43] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 00:20:57] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.4075250919695765, 'error_1pix': 0.6164235774804268, 'error_3pix': 0.34186694265565326, 'mIoU': 3.3945766069951735, 'fwIoU': 11.740865749180612, 'IoU-0': 0.0, 'IoU-1': 63.49001412297849, 'IoU-2': 3.1342413729565144, 'IoU-3': 1.6782433620785255, 'IoU-4': 1.2988507178764763, 'IoU-5': 1.0503370565636494, 'IoU-6': 1.011511504971061, 'IoU-7': 0.7861864860235726, 'IoU-8': 1.3572884451079903, 'IoU-9': 1.995063841463238, 'IoU-10': 3.776071661921137, 'IoU-11': 5.99756449163151, 'IoU-12': 6.987978700057829, 'IoU-13': 8.020877359158565, 'IoU-14': 8.653544902379961, 'IoU-15': 8.180862370285395, 'IoU-16': 8.073434830002133, 'IoU-17': 7.647747378294064, 'IoU-18': 7.566963570941976, 'IoU-19': 7.242503890672264, 'IoU-20': 7.7819216854083395, 'IoU-21': 7.224822225816715, 'IoU-22': 8.022514435166192, 'IoU-23': 6.996274329339963, 'IoU-24': 6.767542405265966, 'IoU-25': 7.123247551147804, 'IoU-26': 6.904646242898351, 'IoU-27': 7.5761684035205015, 'IoU-28': 7.435930077661792, 'IoU-29': 7.2450301655375675, 'IoU-30': 7.523487715886508, 'IoU-31': 7.729856504062564, 'IoU-32': 7.2758940651240485, 'IoU-33': 6.854328610980136, 'IoU-34': 6.434535020189287, 'IoU-35': 6.807518456419152, 'IoU-36': 6.975840414045388, 'IoU-37': 6.8323232772727565, 'IoU-38': 6.691825057937725, 'IoU-39': 6.538439223115961, 'IoU-40': 6.528248102135918, 'IoU-41': 6.201293439445246, 'IoU-42': 6.225467017196151, 'IoU-43': 6.364913041369431, 'IoU-44': 6.538353928869635, 'IoU-45': 6.43835004084882, 'IoU-46': 5.940630400674535, 'IoU-47': 5.926126181445014, 'IoU-48': 5.915838795132506, 'IoU-49': 5.804865682104653, 'IoU-50': 5.591106322083025, 'IoU-51': 5.355896765844936, 'IoU-52': 5.506599054893316, 'IoU-53': 5.395201310477734, 'IoU-54': 5.2609605968661715, 'IoU-55': 5.252787551158565, 'IoU-56': 4.983775018326857, 'IoU-57': 4.972829841404468, 'IoU-58': 4.897731135442349, 'IoU-59': 4.702989388835256, 'IoU-60': 4.7031358351493475, 'IoU-61': 4.48055353905775, 'IoU-62': 4.427264791626829, 'IoU-63': 4.523840321900981, 'IoU-64': 4.5408189901524505, 'IoU-65': 4.278064820594784, 'IoU-66': 4.2096558996969975, 'IoU-67': 4.039834474286569, 'IoU-68': 3.9818279232340132, 'IoU-69': 4.047004145082877, 'IoU-70': 3.9934800099726644, 'IoU-71': 4.097534965784724, 'IoU-72': 3.947402954396647, 'IoU-73': 3.701361995989326, 'IoU-74': 3.7549375077366722, 'IoU-75': 3.9150629060042306, 'IoU-76': 3.9363390811471977, 'IoU-77': 3.923139762072276, 'IoU-78': 3.9236508823712968, 'IoU-79': 3.930618248793271, 'IoU-80': 3.895847485397802, 'IoU-81': 3.9707809145706303, 'IoU-82': 3.972554985741192, 'IoU-83': 4.094735086527877, 'IoU-84': 3.963815970741865, 'IoU-85': 3.8957118009180918, 'IoU-86': 3.7945254837239117, 'IoU-87': 3.760651822637499, 'IoU-88': 3.750073814414856, 'IoU-89': 3.736548445345081, 'IoU-90': 3.77317523805102, 'IoU-91': 3.5976302055693625, 'IoU-92': 3.552568481864262, 'IoU-93': 3.606456390221619, 'IoU-94': 3.5433489671370992, 'IoU-95': 3.4997732907025183, 'IoU-96': 3.4153997806870784, 'IoU-97': 3.432319939626661, 'IoU-98': 3.5894311891903214, 'IoU-99': 3.3786190587116516, 'IoU-100': 3.190764627978316, 'IoU-101': 2.847396356796766, 'IoU-102': 2.784099862028678, 'IoU-103': 2.9356208449496033, 'IoU-104': 2.640098356908306, 'IoU-105': 2.624080447068481, 'IoU-106': 2.540479034623329, 'IoU-107': 2.631329857756213, 'IoU-108': 2.6653026263652966, 'IoU-109': 2.732104997342321, 'IoU-110': 2.4407951563759633, 'IoU-111': 2.1506417703218683, 'IoU-112': 1.9878114847257746, 'IoU-113': 2.1512169946392303, 'IoU-114': 2.040875528245804, 'IoU-115': 1.9929441787347073, 'IoU-116': 2.1113107427195184, 'IoU-117': 1.9857514310477842, 'IoU-118': 1.8130685471801318, 'IoU-119': 2.028526665209158, 'IoU-120': 1.7906989106744358, 'IoU-121': 1.6709102267470848, 'IoU-122': 1.592119021286885, 'IoU-123': 1.4694421290966777, 'IoU-124': 1.372940423655141, 'IoU-125': 1.458549402471222, 'IoU-126': 1.4244987615086226, 'IoU-127': 1.3379571829937165, 'IoU-128': 1.240899195594573, 'IoU-129': 1.0401302563027781, 'IoU-130': 1.19076189373712, 'IoU-131': 1.1558623768374732, 'IoU-132': 1.2974683841754664, 'IoU-133': 1.1176334061853277, 'IoU-134': 1.2086830721725232, 'IoU-135': 1.4309959867426498, 'IoU-136': 1.1338805545797435, 'IoU-137': 1.1297297409876057, 'IoU-138': 1.0084521704239273, 'IoU-139': 0.8608207661333125, 'IoU-140': 0.9517103538062363, 'IoU-141': 0.8507462859513306, 'IoU-142': 0.8979566286750257, 'IoU-143': 0.8923180925776365, 'IoU-144': 0.7827058475437243, 'IoU-145': 0.861794467460026, 'IoU-146': 0.658929470469823, 'IoU-147': 0.9701002842294751, 'IoU-148': 1.18690335215561, 'IoU-149': 1.1658711663840942, 'IoU-150': 0.8954766486549824, 'IoU-151': 0.8732314085118055, 'IoU-152': 0.807168929026124, 'IoU-153': 0.6878826894645179, 'IoU-154': 0.7218604312022349, 'IoU-155': 0.842264221903379, 'IoU-156': 0.5690974829813343, 'IoU-157': 0.6338698017730092, 'IoU-158': 0.5648995213539539, 'IoU-159': 0.43884535424845056, 'IoU-160': 0.45613746423571483, 'IoU-161': 0.3746509072211375, 'IoU-162': 0.4619901397787913, 'IoU-163': 0.6753289122837837, 'IoU-164': 0.2878660180266491, 'IoU-165': 0.40749463835325117, 'IoU-166': 0.2454856474273897, 'IoU-167': 0.4792464225791555, 'IoU-168': 0.06404245099608884, 'IoU-169': 0.13284665269340232, 'IoU-170': 0.013017131229810602, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 6.506124405678204, 'pACC': 16.642983515552164, 'ACC-0': 0.0, 'ACC-1': 64.45467789000973, 'ACC-2': 18.41735373992687, 'ACC-3': 14.89701930209289, 'ACC-4': 8.250361722698486, 'ACC-5': 6.104857151424382, 'ACC-6': 5.606748103346285, 'ACC-7': 4.318124637649452, 'ACC-8': 3.2616673717780023, 'ACC-9': 2.870140604411795, 'ACC-10': 4.656765137507154, 'ACC-11': 7.164385401014493, 'ACC-12': 9.53161582612516, 'ACC-13': 13.079255559804873, 'ACC-14': 16.401565731856323, 'ACC-15': 17.03104130977636, 'ACC-16': 17.16364121903047, 'ACC-17': 17.444810367311028, 'ACC-18': 15.954199760593998, 'ACC-19': 14.82202398564608, 'ACC-20': 15.526660559236326, 'ACC-21': 14.006670299090732, 'ACC-22': 14.84049995921954, 'ACC-23': 13.612883962820485, 'ACC-24': 13.361000127934188, 'ACC-25': 14.147980268717458, 'ACC-26': 13.787645025403442, 'ACC-27': 14.570351367041404, 'ACC-28': 14.625102030800182, 'ACC-29': 13.840237972638803, 'ACC-30': 14.434039296666532, 'ACC-31': 14.425727335732946, 'ACC-32': 13.798546437551758, 'ACC-33': 13.280900010663348, 'ACC-34': 12.409986711967615, 'ACC-35': 12.765004847752353, 'ACC-36': 13.040799473343034, 'ACC-37': 12.938990785530516, 'ACC-38': 12.476531997145937, 'ACC-39': 12.139836242254624, 'ACC-40': 12.053093797682093, 'ACC-41': 11.912240204933175, 'ACC-42': 12.00295012874732, 'ACC-43': 12.187672331126828, 'ACC-44': 12.20523606354072, 'ACC-45': 12.19735278250268, 'ACC-46': 11.529247882206004, 'ACC-47': 11.454278366472991, 'ACC-48': 11.388325123266034, 'ACC-49': 11.048877185496593, 'ACC-50': 10.592132026239703, 'ACC-51': 10.284806880831916, 'ACC-52': 10.549625078653001, 'ACC-53': 10.33497918402918, 'ACC-54': 10.065325361956438, 'ACC-55': 9.857462380892699, 'ACC-56': 9.448453922185546, 'ACC-57': 9.246159665299638, 'ACC-58': 9.175824343280782, 'ACC-59': 8.897898933988088, 'ACC-60': 8.936959653837446, 'ACC-61': 8.622154993268943, 'ACC-62': 8.581714069804693, 'ACC-63': 8.886268993473195, 'ACC-64': 8.825003620635732, 'ACC-65': 8.334887162338944, 'ACC-66': 8.192506554495834, 'ACC-67': 7.877406790847492, 'ACC-68': 7.744295992753618, 'ACC-69': 7.752970832977176, 'ACC-70': 7.616464300858363, 'ACC-71': 7.932589708292652, 'ACC-72': 7.637799379391633, 'ACC-73': 7.101761316450459, 'ACC-74': 7.140473930716981, 'ACC-75': 7.45748515679686, 'ACC-76': 7.3853693129466365, 'ACC-77': 7.480963745259903, 'ACC-78': 7.587016915004371, 'ACC-79': 7.642524342198985, 'ACC-80': 7.56711843366602, 'ACC-81': 7.699821720809691, 'ACC-82': 7.791547188798171, 'ACC-83': 7.9433803531387985, 'ACC-84': 7.750334495367082, 'ACC-85': 7.657446535692479, 'ACC-86': 7.486681683186222, 'ACC-87': 7.46161503158006, 'ACC-88': 7.502696555723498, 'ACC-89': 7.515362361327453, 'ACC-90': 7.558800265120961, 'ACC-91': 7.283119071652767, 'ACC-92': 7.181404240572811, 'ACC-93': 7.248297745801323, 'ACC-94': 7.090558714125497, 'ACC-95': 7.020829857493177, 'ACC-96': 6.892806487535365, 'ACC-97': 6.858598325682879, 'ACC-98': 7.208912335519992, 'ACC-99': 6.860924077083817, 'ACC-100': 6.463523813462628, 'ACC-101': 5.835379515140886, 'ACC-102': 5.74415496148618, 'ACC-103': 6.060852932842165, 'ACC-104': 5.464917242566587, 'ACC-105': 5.4339223266406185, 'ACC-106': 5.218226544019371, 'ACC-107': 5.420860366652307, 'ACC-108': 5.472792459264758, 'ACC-109': 5.556165067053352, 'ACC-110': 5.052227092328033, 'ACC-111': 4.447079035539088, 'ACC-112': 4.125818547265036, 'ACC-113': 4.480867495114792, 'ACC-114': 4.307366225254619, 'ACC-115': 4.2251514741479115, 'ACC-116': 4.521051233235497, 'ACC-117': 4.188810497562136, 'ACC-118': 3.7563132505940096, 'ACC-119': 4.166607692693704, 'ACC-120': 3.6251172793303748, 'ACC-121': 3.3700531470589703, 'ACC-122': 3.2367648862596354, 'ACC-123': 2.9444765714894734, 'ACC-124': 2.8689985248529513, 'ACC-125': 2.9966400649145113, 'ACC-126': 2.949480414211423, 'ACC-127': 2.7622092534272817, 'ACC-128': 2.545582278619963, 'ACC-129': 2.1551131774851138, 'ACC-130': 2.447935342570355, 'ACC-131': 2.409030825147387, 'ACC-132': 2.7754152801654084, 'ACC-133': 2.3591010226785603, 'ACC-134': 2.5537268418785004, 'ACC-135': 3.134014594378884, 'ACC-136': 2.4648102636973537, 'ACC-137': 2.4840160065088455, 'ACC-138': 2.2806305048607762, 'ACC-139': 1.9945021656023803, 'ACC-140': 2.1493754213690206, 'ACC-141': 1.8536066476026654, 'ACC-142': 1.9793705313516048, 'ACC-143': 1.91912139339158, 'ACC-144': 1.6736462093862818, 'ACC-145': 1.8277689572664864, 'ACC-146': 1.4280688126841972, 'ACC-147': 2.0000315696719446, 'ACC-148': 2.369371827031199, 'ACC-149': 2.5586444761979132, 'ACC-150': 1.863960000375231, 'ACC-151': 1.9136017598102066, 'ACC-152': 1.817700957583114, 'ACC-153': 1.592531010095458, 'ACC-154': 1.6738936697089355, 'ACC-155': 2.1641115901622774, 'ACC-156': 1.3627049842605699, 'ACC-157': 1.4738687387118858, 'ACC-158': 1.378164733378402, 'ACC-159': 1.0767337610969498, 'ACC-160': 0.917154911098041, 'ACC-161': 0.782695877577041, 'ACC-162': 1.116628632464646, 'ACC-163': 1.6454513908527943, 'ACC-164': 0.8079680617962385, 'ACC-165': 0.6822794741238839, 'ACC-166': 0.3015168176209383, 'ACC-167': 0.6147651333149199, 'ACC-168': 0.068921865110064, 'ACC-169': 0.14669420399969818, 'ACC-170': 0.013487229723014893, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 00:20:57] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 00:20:57] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 00:20:57] d2.evaluation.testing INFO: copypaste: 4.4075,0.6164,0.3419,3.3946,11.7409,6.5061,16.6430
[01/29 00:20:57] d2.utils.events INFO:  eta: 1 day, 21:41:18  iter: 5999  total_loss: 46.59  loss_mask: 4.76  loss_mask_0: 4.885  loss_mask_1: 4.556  loss_mask_2: 4.628  loss_mask_3: 4.593  loss_mask_4: 4.573  loss_mask_5: 4.552  loss_mask_6: 4.645  loss_mask_7: 4.531  loss_mask_8: 4.603  time: 3.0609  data_time: 0.0661  lr: 9.0955e-05  max_mem: 27632M
[01/29 00:21:59] d2.utils.events INFO:  eta: 1 day, 21:41:37  iter: 6019  total_loss: 45.23  loss_mask: 4.585  loss_mask_0: 4.663  loss_mask_1: 4.445  loss_mask_2: 4.466  loss_mask_3: 4.612  loss_mask_4: 4.461  loss_mask_5: 4.509  loss_mask_6: 4.479  loss_mask_7: 4.47  loss_mask_8: 4.458  time: 3.0609  data_time: 0.0790  lr: 9.0924e-05  max_mem: 27632M
[01/29 00:23:00] d2.utils.events INFO:  eta: 1 day, 21:40:36  iter: 6039  total_loss: 51.84  loss_mask: 5.202  loss_mask_0: 5.297  loss_mask_1: 5.227  loss_mask_2: 5.282  loss_mask_3: 5.271  loss_mask_4: 5.232  loss_mask_5: 5.143  loss_mask_6: 5.182  loss_mask_7: 5.156  loss_mask_8: 5.221  time: 3.0609  data_time: 0.0773  lr: 9.0894e-05  max_mem: 27632M
[01/29 00:24:01] d2.utils.events INFO:  eta: 1 day, 21:39:22  iter: 6059  total_loss: 48.9  loss_mask: 4.895  loss_mask_0: 5.093  loss_mask_1: 4.865  loss_mask_2: 4.867  loss_mask_3: 4.949  loss_mask_4: 4.886  loss_mask_5: 4.882  loss_mask_6: 4.834  loss_mask_7: 4.894  loss_mask_8: 4.893  time: 3.0609  data_time: 0.0776  lr: 9.0864e-05  max_mem: 27632M
[01/29 00:25:03] d2.utils.events INFO:  eta: 1 day, 21:39:14  iter: 6079  total_loss: 51.1  loss_mask: 5.153  loss_mask_0: 5.33  loss_mask_1: 5.061  loss_mask_2: 5.131  loss_mask_3: 5.026  loss_mask_4: 5.054  loss_mask_5: 5.072  loss_mask_6: 5.068  loss_mask_7: 5.025  loss_mask_8: 5.088  time: 3.0610  data_time: 0.0777  lr: 9.0833e-05  max_mem: 27632M
[01/29 00:26:04] d2.utils.events INFO:  eta: 1 day, 21:37:59  iter: 6099  total_loss: 49.33  loss_mask: 4.998  loss_mask_0: 5.106  loss_mask_1: 4.934  loss_mask_2: 4.884  loss_mask_3: 4.838  loss_mask_4: 4.979  loss_mask_5: 4.853  loss_mask_6: 5.021  loss_mask_7: 4.898  loss_mask_8: 4.885  time: 3.0609  data_time: 0.0746  lr: 9.0803e-05  max_mem: 27632M
[01/29 00:27:04] d2.utils.events INFO:  eta: 1 day, 21:35:44  iter: 6119  total_loss: 47.38  loss_mask: 4.78  loss_mask_0: 4.98  loss_mask_1: 4.669  loss_mask_2: 4.663  loss_mask_3: 4.706  loss_mask_4: 4.756  loss_mask_5: 4.731  loss_mask_6: 4.696  loss_mask_7: 4.747  loss_mask_8: 4.737  time: 3.0608  data_time: 0.0684  lr: 9.0773e-05  max_mem: 27632M
[01/29 00:28:05] d2.utils.events INFO:  eta: 1 day, 21:33:32  iter: 6139  total_loss: 52.3  loss_mask: 5.389  loss_mask_0: 5.583  loss_mask_1: 5.265  loss_mask_2: 5.23  loss_mask_3: 5.261  loss_mask_4: 5.276  loss_mask_5: 5.233  loss_mask_6: 5.126  loss_mask_7: 5.192  loss_mask_8: 5.155  time: 3.0607  data_time: 0.0680  lr: 9.0743e-05  max_mem: 27632M
[01/29 00:29:06] d2.utils.events INFO:  eta: 1 day, 21:29:44  iter: 6159  total_loss: 61.07  loss_mask: 6.155  loss_mask_0: 6.432  loss_mask_1: 6.014  loss_mask_2: 6.059  loss_mask_3: 5.909  loss_mask_4: 5.923  loss_mask_5: 6.192  loss_mask_6: 6.053  loss_mask_7: 5.947  loss_mask_8: 5.912  time: 3.0607  data_time: 0.0739  lr: 9.0712e-05  max_mem: 27632M
[01/29 00:30:06] d2.utils.events INFO:  eta: 1 day, 21:27:53  iter: 6179  total_loss: 50.17  loss_mask: 4.852  loss_mask_0: 5.016  loss_mask_1: 4.706  loss_mask_2: 4.801  loss_mask_3: 4.813  loss_mask_4: 5.051  loss_mask_5: 5.601  loss_mask_6: 5.195  loss_mask_7: 4.623  loss_mask_8: 4.832  time: 3.0605  data_time: 0.0605  lr: 9.0682e-05  max_mem: 27632M
[01/29 00:31:08] d2.utils.events INFO:  eta: 1 day, 21:26:21  iter: 6199  total_loss: 47.99  loss_mask: 4.772  loss_mask_0: 4.982  loss_mask_1: 4.729  loss_mask_2: 4.791  loss_mask_3: 4.706  loss_mask_4: 4.728  loss_mask_5: 5.209  loss_mask_6: 4.886  loss_mask_7: 4.75  loss_mask_8: 4.584  time: 3.0606  data_time: 0.0624  lr: 9.0652e-05  max_mem: 27632M
[01/29 00:32:09] d2.utils.events INFO:  eta: 1 day, 21:23:28  iter: 6219  total_loss: 51.09  loss_mask: 5.009  loss_mask_0: 5.172  loss_mask_1: 4.951  loss_mask_2: 4.998  loss_mask_3: 4.925  loss_mask_4: 5.038  loss_mask_5: 5.411  loss_mask_6: 5.126  loss_mask_7: 4.985  loss_mask_8: 4.897  time: 3.0606  data_time: 0.0708  lr: 9.0621e-05  max_mem: 27632M
[01/29 00:33:11] d2.utils.events INFO:  eta: 1 day, 21:22:44  iter: 6239  total_loss: 48.61  loss_mask: 4.952  loss_mask_0: 5.266  loss_mask_1: 4.825  loss_mask_2: 4.881  loss_mask_3: 4.89  loss_mask_4: 4.741  loss_mask_5: 5.328  loss_mask_6: 4.898  loss_mask_7: 4.854  loss_mask_8: 4.794  time: 3.0606  data_time: 0.0560  lr: 9.0591e-05  max_mem: 27632M
[01/29 00:34:11] d2.utils.events INFO:  eta: 1 day, 21:21:43  iter: 6259  total_loss: 48.13  loss_mask: 4.79  loss_mask_0: 5.186  loss_mask_1: 4.758  loss_mask_2: 4.76  loss_mask_3: 4.805  loss_mask_4: 4.728  loss_mask_5: 5.382  loss_mask_6: 4.829  loss_mask_7: 4.769  loss_mask_8: 4.647  time: 3.0605  data_time: 0.0648  lr: 9.0561e-05  max_mem: 27632M
[01/29 00:35:13] d2.utils.events INFO:  eta: 1 day, 21:20:42  iter: 6279  total_loss: 48.25  loss_mask: 4.904  loss_mask_0: 4.909  loss_mask_1: 4.783  loss_mask_2: 4.79  loss_mask_3: 4.829  loss_mask_4: 4.828  loss_mask_5: 4.957  loss_mask_6: 4.87  loss_mask_7: 4.821  loss_mask_8: 4.796  time: 3.0605  data_time: 0.0742  lr: 9.053e-05  max_mem: 27632M
[01/29 00:36:14] d2.utils.events INFO:  eta: 1 day, 21:18:01  iter: 6299  total_loss: 45.65  loss_mask: 4.625  loss_mask_0: 4.616  loss_mask_1: 4.402  loss_mask_2: 4.523  loss_mask_3: 4.448  loss_mask_4: 4.565  loss_mask_5: 5.186  loss_mask_6: 4.501  loss_mask_7: 4.511  loss_mask_8: 4.534  time: 3.0605  data_time: 0.0756  lr: 9.05e-05  max_mem: 27632M
[01/29 00:37:15] d2.utils.events INFO:  eta: 1 day, 21:17:17  iter: 6319  total_loss: 44.61  loss_mask: 4.386  loss_mask_0: 4.566  loss_mask_1: 4.363  loss_mask_2: 4.539  loss_mask_3: 4.344  loss_mask_4: 4.434  loss_mask_5: 4.794  loss_mask_6: 4.24  loss_mask_7: 4.496  loss_mask_8: 4.623  time: 3.0605  data_time: 0.0732  lr: 9.047e-05  max_mem: 27632M
[01/29 00:38:16] d2.utils.events INFO:  eta: 1 day, 21:17:09  iter: 6339  total_loss: 49.99  loss_mask: 4.978  loss_mask_0: 5.145  loss_mask_1: 4.832  loss_mask_2: 4.918  loss_mask_3: 5.043  loss_mask_4: 4.997  loss_mask_5: 5.064  loss_mask_6: 5.029  loss_mask_7: 4.881  loss_mask_8: 4.887  time: 3.0605  data_time: 0.0708  lr: 9.0439e-05  max_mem: 27632M
[01/29 00:39:16] d2.utils.events INFO:  eta: 1 day, 21:15:42  iter: 6359  total_loss: 46.02  loss_mask: 4.613  loss_mask_0: 5.105  loss_mask_1: 4.473  loss_mask_2: 4.766  loss_mask_3: 4.906  loss_mask_4: 4.652  loss_mask_5: 4.637  loss_mask_6: 4.656  loss_mask_7: 4.629  loss_mask_8: 4.499  time: 3.0604  data_time: 0.0593  lr: 9.0409e-05  max_mem: 27632M
[01/29 00:40:17] d2.utils.events INFO:  eta: 1 day, 21:15:08  iter: 6379  total_loss: 52.61  loss_mask: 5.272  loss_mask_0: 5.227  loss_mask_1: 5.189  loss_mask_2: 5.303  loss_mask_3: 5.483  loss_mask_4: 5.25  loss_mask_5: 5.317  loss_mask_6: 5.16  loss_mask_7: 5.239  loss_mask_8: 5.183  time: 3.0603  data_time: 0.0637  lr: 9.0379e-05  max_mem: 27632M
[01/29 00:41:18] d2.utils.events INFO:  eta: 1 day, 21:14:37  iter: 6399  total_loss: 47.47  loss_mask: 4.654  loss_mask_0: 4.819  loss_mask_1: 4.636  loss_mask_2: 4.935  loss_mask_3: 4.882  loss_mask_4: 4.734  loss_mask_5: 4.796  loss_mask_6: 4.635  loss_mask_7: 4.66  loss_mask_8: 4.588  time: 3.0603  data_time: 0.0735  lr: 9.0348e-05  max_mem: 27632M
[01/29 00:42:19] d2.utils.events INFO:  eta: 1 day, 21:14:05  iter: 6419  total_loss: 46.2  loss_mask: 4.431  loss_mask_0: 4.573  loss_mask_1: 4.54  loss_mask_2: 4.52  loss_mask_3: 4.595  loss_mask_4: 4.637  loss_mask_5: 4.88  loss_mask_6: 4.654  loss_mask_7: 4.458  loss_mask_8: 4.577  time: 3.0601  data_time: 0.0569  lr: 9.0318e-05  max_mem: 27632M
[01/29 00:43:20] d2.utils.events INFO:  eta: 1 day, 21:14:11  iter: 6439  total_loss: 48.29  loss_mask: 4.768  loss_mask_0: 4.882  loss_mask_1: 4.849  loss_mask_2: 4.826  loss_mask_3: 4.783  loss_mask_4: 4.904  loss_mask_5: 5.008  loss_mask_6: 4.781  loss_mask_7: 4.849  loss_mask_8: 4.698  time: 3.0601  data_time: 0.0650  lr: 9.0288e-05  max_mem: 27632M
[01/29 00:44:21] d2.utils.events INFO:  eta: 1 day, 21:13:10  iter: 6459  total_loss: 48.54  loss_mask: 4.775  loss_mask_0: 5.057  loss_mask_1: 4.564  loss_mask_2: 4.677  loss_mask_3: 4.697  loss_mask_4: 4.93  loss_mask_5: 5.214  loss_mask_6: 4.943  loss_mask_7: 4.728  loss_mask_8: 4.751  time: 3.0601  data_time: 0.0712  lr: 9.0257e-05  max_mem: 27632M
[01/29 00:45:22] d2.utils.events INFO:  eta: 1 day, 21:12:31  iter: 6479  total_loss: 52.7  loss_mask: 5.018  loss_mask_0: 5.817  loss_mask_1: 4.874  loss_mask_2: 5.041  loss_mask_3: 5.012  loss_mask_4: 5.138  loss_mask_5: 5.461  loss_mask_6: 5.091  loss_mask_7: 4.975  loss_mask_8: 5.137  time: 3.0601  data_time: 0.0640  lr: 9.0227e-05  max_mem: 27632M
[01/29 00:46:23] d2.utils.events INFO:  eta: 1 day, 21:11:30  iter: 6499  total_loss: 46.32  loss_mask: 4.622  loss_mask_0: 4.697  loss_mask_1: 4.522  loss_mask_2: 4.606  loss_mask_3: 4.595  loss_mask_4: 4.582  loss_mask_5: 4.657  loss_mask_6: 4.579  loss_mask_7: 4.657  loss_mask_8: 4.591  time: 3.0600  data_time: 0.0569  lr: 9.0196e-05  max_mem: 27632M
[01/29 00:47:24] d2.utils.events INFO:  eta: 1 day, 21:10:51  iter: 6519  total_loss: 46.83  loss_mask: 4.705  loss_mask_0: 4.774  loss_mask_1: 4.592  loss_mask_2: 4.682  loss_mask_3: 4.64  loss_mask_4: 4.623  loss_mask_5: 4.918  loss_mask_6: 4.699  loss_mask_7: 4.727  loss_mask_8: 4.724  time: 3.0600  data_time: 0.0652  lr: 9.0166e-05  max_mem: 27632M
[01/29 00:48:25] d2.utils.events INFO:  eta: 1 day, 21:10:03  iter: 6539  total_loss: 51.66  loss_mask: 5.135  loss_mask_0: 4.993  loss_mask_1: 4.899  loss_mask_2: 4.946  loss_mask_3: 4.917  loss_mask_4: 4.927  loss_mask_5: 5.02  loss_mask_6: 4.982  loss_mask_7: 5.233  loss_mask_8: 5.232  time: 3.0600  data_time: 0.0678  lr: 9.0136e-05  max_mem: 27632M
[01/29 00:49:26] d2.utils.events INFO:  eta: 1 day, 21:08:46  iter: 6559  total_loss: 43.8  loss_mask: 4.397  loss_mask_0: 4.347  loss_mask_1: 4.16  loss_mask_2: 4.204  loss_mask_3: 4.243  loss_mask_4: 4.26  loss_mask_5: 4.261  loss_mask_6: 4.313  loss_mask_7: 4.747  loss_mask_8: 4.354  time: 3.0599  data_time: 0.0577  lr: 9.0105e-05  max_mem: 27632M
[01/29 00:50:27] d2.utils.events INFO:  eta: 1 day, 21:08:27  iter: 6579  total_loss: 49.2  loss_mask: 4.954  loss_mask_0: 5.096  loss_mask_1: 4.832  loss_mask_2: 4.874  loss_mask_3: 4.856  loss_mask_4: 4.856  loss_mask_5: 4.871  loss_mask_6: 5.076  loss_mask_7: 4.983  loss_mask_8: 5.057  time: 3.0599  data_time: 0.0697  lr: 9.0075e-05  max_mem: 27632M
[01/29 00:51:28] d2.utils.events INFO:  eta: 1 day, 21:08:18  iter: 6599  total_loss: 52.6  loss_mask: 5.408  loss_mask_0: 5.789  loss_mask_1: 5.246  loss_mask_2: 5.186  loss_mask_3: 5.147  loss_mask_4: 5.16  loss_mask_5: 5.303  loss_mask_6: 5.204  loss_mask_7: 5.412  loss_mask_8: 5.352  time: 3.0599  data_time: 0.0766  lr: 9.0045e-05  max_mem: 27632M
[01/29 00:52:29] d2.utils.events INFO:  eta: 1 day, 21:09:13  iter: 6619  total_loss: 45.2  loss_mask: 4.533  loss_mask_0: 4.681  loss_mask_1: 4.508  loss_mask_2: 4.535  loss_mask_3: 4.471  loss_mask_4: 4.557  loss_mask_5: 4.565  loss_mask_6: 4.536  loss_mask_7: 4.544  loss_mask_8: 4.499  time: 3.0599  data_time: 0.0716  lr: 9.0014e-05  max_mem: 27632M
[01/29 00:53:30] d2.utils.events INFO:  eta: 1 day, 21:08:50  iter: 6639  total_loss: 51.4  loss_mask: 5.207  loss_mask_0: 5.41  loss_mask_1: 5.041  loss_mask_2: 5.123  loss_mask_3: 5.068  loss_mask_4: 5.094  loss_mask_5: 5.191  loss_mask_6: 5.199  loss_mask_7: 5.233  loss_mask_8: 5.096  time: 3.0598  data_time: 0.0700  lr: 8.9984e-05  max_mem: 27632M
[01/29 00:54:30] d2.utils.events INFO:  eta: 1 day, 21:05:30  iter: 6659  total_loss: 47.21  loss_mask: 4.772  loss_mask_0: 4.929  loss_mask_1: 4.626  loss_mask_2: 4.701  loss_mask_3: 4.714  loss_mask_4: 4.77  loss_mask_5: 4.71  loss_mask_6: 4.71  loss_mask_7: 4.799  loss_mask_8: 4.625  time: 3.0596  data_time: 0.0596  lr: 8.9954e-05  max_mem: 27632M
[01/29 00:55:31] d2.utils.events INFO:  eta: 1 day, 21:04:15  iter: 6679  total_loss: 46.76  loss_mask: 4.671  loss_mask_0: 4.907  loss_mask_1: 4.505  loss_mask_2: 4.58  loss_mask_3: 4.627  loss_mask_4: 4.652  loss_mask_5: 4.535  loss_mask_6: 4.625  loss_mask_7: 4.743  loss_mask_8: 4.561  time: 3.0596  data_time: 0.0656  lr: 8.9923e-05  max_mem: 27632M
[01/29 00:56:32] d2.utils.events INFO:  eta: 1 day, 21:03:14  iter: 6699  total_loss: 48.19  loss_mask: 4.79  loss_mask_0: 4.949  loss_mask_1: 4.767  loss_mask_2: 4.773  loss_mask_3: 4.74  loss_mask_4: 4.738  loss_mask_5: 4.899  loss_mask_6: 4.739  loss_mask_7: 4.844  loss_mask_8: 4.723  time: 3.0595  data_time: 0.0590  lr: 8.9893e-05  max_mem: 27632M
[01/29 00:57:32] d2.utils.events INFO:  eta: 1 day, 21:00:50  iter: 6719  total_loss: 53.2  loss_mask: 5.25  loss_mask_0: 5.521  loss_mask_1: 5.189  loss_mask_2: 5.259  loss_mask_3: 5.195  loss_mask_4: 5.299  loss_mask_5: 5.431  loss_mask_6: 5.223  loss_mask_7: 5.339  loss_mask_8: 5.172  time: 3.0593  data_time: 0.0670  lr: 8.9863e-05  max_mem: 27632M
[01/29 00:58:33] d2.utils.events INFO:  eta: 1 day, 20:59:38  iter: 6739  total_loss: 45.67  loss_mask: 4.558  loss_mask_0: 4.799  loss_mask_1: 4.488  loss_mask_2: 4.568  loss_mask_3: 4.517  loss_mask_4: 4.571  loss_mask_5: 4.585  loss_mask_6: 4.542  loss_mask_7: 4.614  loss_mask_8: 4.549  time: 3.0592  data_time: 0.0761  lr: 8.9832e-05  max_mem: 27632M
[01/29 00:59:33] d2.utils.events INFO:  eta: 1 day, 20:58:03  iter: 6759  total_loss: 47.75  loss_mask: 4.728  loss_mask_0: 5.53  loss_mask_1: 4.668  loss_mask_2: 4.794  loss_mask_3: 4.694  loss_mask_4: 4.75  loss_mask_5: 4.781  loss_mask_6: 4.64  loss_mask_7: 4.695  loss_mask_8: 4.604  time: 3.0591  data_time: 0.0570  lr: 8.9802e-05  max_mem: 27632M
[01/29 01:00:34] d2.utils.events INFO:  eta: 1 day, 20:56:40  iter: 6779  total_loss: 49.63  loss_mask: 4.937  loss_mask_0: 5.141  loss_mask_1: 4.988  loss_mask_2: 4.865  loss_mask_3: 4.846  loss_mask_4: 4.732  loss_mask_5: 5.197  loss_mask_6: 4.975  loss_mask_7: 4.946  loss_mask_8: 4.976  time: 3.0590  data_time: 0.0636  lr: 8.9772e-05  max_mem: 27632M
[01/29 01:01:35] d2.utils.events INFO:  eta: 1 day, 20:54:45  iter: 6799  total_loss: 48.15  loss_mask: 4.852  loss_mask_0: 4.895  loss_mask_1: 4.801  loss_mask_2: 4.801  loss_mask_3: 4.784  loss_mask_4: 4.885  loss_mask_5: 4.921  loss_mask_6: 4.806  loss_mask_7: 4.793  loss_mask_8: 4.85  time: 3.0590  data_time: 0.0624  lr: 8.9741e-05  max_mem: 27632M
[01/29 01:02:36] d2.utils.events INFO:  eta: 1 day, 20:52:17  iter: 6819  total_loss: 43.88  loss_mask: 4.406  loss_mask_0: 4.413  loss_mask_1: 4.277  loss_mask_2: 4.337  loss_mask_3: 4.356  loss_mask_4: 4.383  loss_mask_5: 4.308  loss_mask_6: 4.347  loss_mask_7: 4.421  loss_mask_8: 4.29  time: 3.0590  data_time: 0.0758  lr: 8.9711e-05  max_mem: 27632M
[01/29 01:03:37] d2.utils.events INFO:  eta: 1 day, 20:51:45  iter: 6839  total_loss: 44.59  loss_mask: 4.465  loss_mask_0: 4.623  loss_mask_1: 4.47  loss_mask_2: 4.452  loss_mask_3: 4.442  loss_mask_4: 4.444  loss_mask_5: 4.434  loss_mask_6: 4.474  loss_mask_7: 4.468  loss_mask_8: 4.418  time: 3.0590  data_time: 0.0659  lr: 8.968e-05  max_mem: 27632M
[01/29 01:04:38] d2.utils.events INFO:  eta: 1 day, 20:50:28  iter: 6859  total_loss: 44.24  loss_mask: 4.276  loss_mask_0: 4.487  loss_mask_1: 4.252  loss_mask_2: 4.25  loss_mask_3: 4.346  loss_mask_4: 5.008  loss_mask_5: 4.45  loss_mask_6: 4.284  loss_mask_7: 4.236  loss_mask_8: 4.29  time: 3.0589  data_time: 0.0734  lr: 8.965e-05  max_mem: 27632M
[01/29 01:05:39] d2.utils.events INFO:  eta: 1 day, 20:50:12  iter: 6879  total_loss: 47.32  loss_mask: 4.716  loss_mask_0: 5.049  loss_mask_1: 4.443  loss_mask_2: 4.404  loss_mask_3: 4.683  loss_mask_4: 5.485  loss_mask_5: 4.834  loss_mask_6: 4.581  loss_mask_7: 4.493  loss_mask_8: 4.479  time: 3.0590  data_time: 0.0628  lr: 8.962e-05  max_mem: 27632M
[01/29 01:06:40] d2.utils.events INFO:  eta: 1 day, 20:47:44  iter: 6899  total_loss: 45.97  loss_mask: 4.582  loss_mask_0: 4.946  loss_mask_1: 4.591  loss_mask_2: 4.552  loss_mask_3: 4.596  loss_mask_4: 4.765  loss_mask_5: 4.66  loss_mask_6: 4.605  loss_mask_7: 4.517  loss_mask_8: 4.535  time: 3.0589  data_time: 0.0674  lr: 8.9589e-05  max_mem: 27632M
[01/29 01:07:41] d2.utils.events INFO:  eta: 1 day, 20:47:02  iter: 6919  total_loss: 45.76  loss_mask: 4.59  loss_mask_0: 4.783  loss_mask_1: 4.552  loss_mask_2: 4.545  loss_mask_3: 4.508  loss_mask_4: 4.736  loss_mask_5: 4.543  loss_mask_6: 4.516  loss_mask_7: 4.515  loss_mask_8: 4.514  time: 3.0589  data_time: 0.0732  lr: 8.9559e-05  max_mem: 27632M
[01/29 01:08:42] d2.utils.events INFO:  eta: 1 day, 20:45:55  iter: 6939  total_loss: 44  loss_mask: 4.469  loss_mask_0: 4.415  loss_mask_1: 4.362  loss_mask_2: 4.378  loss_mask_3: 4.385  loss_mask_4: 4.492  loss_mask_5: 4.37  loss_mask_6: 4.354  loss_mask_7: 4.354  loss_mask_8: 4.29  time: 3.0588  data_time: 0.0680  lr: 8.9529e-05  max_mem: 27632M
[01/29 01:09:43] d2.utils.events INFO:  eta: 1 day, 20:44:29  iter: 6959  total_loss: 44.14  loss_mask: 4.332  loss_mask_0: 4.468  loss_mask_1: 4.332  loss_mask_2: 4.387  loss_mask_3: 4.419  loss_mask_4: 4.516  loss_mask_5: 4.415  loss_mask_6: 4.358  loss_mask_7: 4.384  loss_mask_8: 4.353  time: 3.0588  data_time: 0.0693  lr: 8.9498e-05  max_mem: 27632M
[01/29 01:10:44] d2.utils.events INFO:  eta: 1 day, 20:43:41  iter: 6979  total_loss: 48.09  loss_mask: 4.811  loss_mask_0: 5.177  loss_mask_1: 4.703  loss_mask_2: 4.702  loss_mask_3: 4.643  loss_mask_4: 4.778  loss_mask_5: 4.679  loss_mask_6: 4.731  loss_mask_7: 4.794  loss_mask_8: 4.745  time: 3.0588  data_time: 0.0662  lr: 8.9468e-05  max_mem: 27632M
[01/29 01:11:46] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 01:11:46] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 01:11:46] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 01:25:53] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.247812766776914, 'error_1pix': 0.6012778978661828, 'error_3pix': 0.3251455338244705, 'mIoU': 3.287071574306911, 'fwIoU': 8.703009329906882, 'IoU-0': 5.650586573721444e-05, 'IoU-1': 30.551155492729638, 'IoU-2': 2.6745954773393237, 'IoU-3': 1.659645554909936, 'IoU-4': 1.3106559612415212, 'IoU-5': 1.11056265849592, 'IoU-6': 0.9710974773490427, 'IoU-7': 0.8051343219249458, 'IoU-8': 2.8495105713301343, 'IoU-9': 5.942829805883895, 'IoU-10': 8.927657278161869, 'IoU-11': 14.527217261364628, 'IoU-12': 15.583574666248417, 'IoU-13': 12.432906039555638, 'IoU-14': 11.215861287882909, 'IoU-15': 9.371677083060899, 'IoU-16': 8.28266395280393, 'IoU-17': 6.8600723065134, 'IoU-18': 7.233660144301073, 'IoU-19': 5.781040566013433, 'IoU-20': 5.99230622287341, 'IoU-21': 6.399500436358757, 'IoU-22': 7.156626688054879, 'IoU-23': 6.509436531203446, 'IoU-24': 6.145969133929218, 'IoU-25': 6.007169636373231, 'IoU-26': 6.022158719359086, 'IoU-27': 6.428987392900888, 'IoU-28': 6.035112207956398, 'IoU-29': 5.988146455743422, 'IoU-30': 6.339342306632882, 'IoU-31': 6.6555188271442525, 'IoU-32': 6.703443341620989, 'IoU-33': 6.524402043340029, 'IoU-34': 6.554188123756055, 'IoU-35': 6.851384641999511, 'IoU-36': 6.879726694139003, 'IoU-37': 6.86320644817595, 'IoU-38': 7.006947134045165, 'IoU-39': 6.7911827382343555, 'IoU-40': 6.840209234241278, 'IoU-41': 6.780097409717674, 'IoU-42': 7.043151838691074, 'IoU-43': 6.976098658063249, 'IoU-44': 7.061946175813951, 'IoU-45': 6.847116712670644, 'IoU-46': 6.471008397307807, 'IoU-47': 6.250068452909699, 'IoU-48': 6.260993008034377, 'IoU-49': 6.008311149753459, 'IoU-50': 6.084736278089118, 'IoU-51': 5.721949844307329, 'IoU-52': 5.556617173381419, 'IoU-53': 5.375250976347258, 'IoU-54': 5.306763512014689, 'IoU-55': 4.824681617026202, 'IoU-56': 4.591290772632663, 'IoU-57': 4.539300043716186, 'IoU-58': 4.261101448890633, 'IoU-59': 4.1842112014943025, 'IoU-60': 4.152202638049033, 'IoU-61': 3.8995995855433785, 'IoU-62': 3.8902026003144874, 'IoU-63': 3.841197595576732, 'IoU-64': 3.8303471766585653, 'IoU-65': 3.841648483021063, 'IoU-66': 3.7750332461129124, 'IoU-67': 3.537186081588447, 'IoU-68': 3.554680499315143, 'IoU-69': 3.6804436807621923, 'IoU-70': 3.618655050972914, 'IoU-71': 3.60802479869661, 'IoU-72': 3.587617134922306, 'IoU-73': 3.578787185321336, 'IoU-74': 3.5956515860083123, 'IoU-75': 3.6139180721631963, 'IoU-76': 3.7050671437314713, 'IoU-77': 3.823418877467394, 'IoU-78': 3.776900958983326, 'IoU-79': 3.6198216617564, 'IoU-80': 3.737499743885241, 'IoU-81': 3.814619292907246, 'IoU-82': 3.8038985166399497, 'IoU-83': 3.90633735964523, 'IoU-84': 3.945421136876468, 'IoU-85': 3.878643826923942, 'IoU-86': 3.9023846839616114, 'IoU-87': 3.987805359183161, 'IoU-88': 3.7905227579317287, 'IoU-89': 3.778653857829025, 'IoU-90': 3.8130967303003187, 'IoU-91': 3.7378912620883, 'IoU-92': 3.6540738570334343, 'IoU-93': 3.7445499697480775, 'IoU-94': 3.496704421813046, 'IoU-95': 3.470770503952632, 'IoU-96': 3.4451469960011263, 'IoU-97': 3.326952699761888, 'IoU-98': 3.4958730554384436, 'IoU-99': 3.1808600289828446, 'IoU-100': 3.062468889203252, 'IoU-101': 2.945985030799461, 'IoU-102': 2.811885023666404, 'IoU-103': 2.7697643896359008, 'IoU-104': 2.791699124589396, 'IoU-105': 2.782391823284419, 'IoU-106': 2.827638237925463, 'IoU-107': 2.6641320094034184, 'IoU-108': 2.5827478835351725, 'IoU-109': 2.688854986060167, 'IoU-110': 2.344948597260238, 'IoU-111': 2.146611769365065, 'IoU-112': 2.0793184546076455, 'IoU-113': 1.9469696930674691, 'IoU-114': 1.9518502566183988, 'IoU-115': 1.831745380642515, 'IoU-116': 1.9586910188012243, 'IoU-117': 1.8836594283912624, 'IoU-118': 1.9829857906520798, 'IoU-119': 2.0213991593949348, 'IoU-120': 1.933399532751199, 'IoU-121': 1.8496227171875979, 'IoU-122': 1.8477956406225196, 'IoU-123': 1.5842254866877932, 'IoU-124': 1.438806391343272, 'IoU-125': 1.3357048018396889, 'IoU-126': 1.4823780743094546, 'IoU-127': 1.3817612717567567, 'IoU-128': 1.2210345916464986, 'IoU-129': 1.2665443172306066, 'IoU-130': 1.3379511259710886, 'IoU-131': 1.4340595018636382, 'IoU-132': 1.3468228793615062, 'IoU-133': 1.1931330692107527, 'IoU-134': 1.317571833023396, 'IoU-135': 1.0968889401866613, 'IoU-136': 0.9527372538063085, 'IoU-137': 0.8627037285947812, 'IoU-138': 1.030038826565425, 'IoU-139': 1.0479637968714484, 'IoU-140': 0.6952641581315414, 'IoU-141': 0.7420252342567238, 'IoU-142': 0.8103820274513343, 'IoU-143': 0.8160063262142503, 'IoU-144': 0.662014372967725, 'IoU-145': 0.7440453931262123, 'IoU-146': 0.7368857485898886, 'IoU-147': 0.7433064706382763, 'IoU-148': 1.1020031510039863, 'IoU-149': 0.5397879660841465, 'IoU-150': 0.5244210498472445, 'IoU-151': 1.0148365785509639, 'IoU-152': 0.7311348141267023, 'IoU-153': 0.8474589983996876, 'IoU-154': 0.45651022338854047, 'IoU-155': 0.5222999101062769, 'IoU-156': 0.5605423647208823, 'IoU-157': 0.6856619693914162, 'IoU-158': 0.4567385090464267, 'IoU-159': 0.2950704784068971, 'IoU-160': 0.36405042314401637, 'IoU-161': 0.47879307637090796, 'IoU-162': 0.33451137896827615, 'IoU-163': 0.285058737317513, 'IoU-164': 0.2033999657362719, 'IoU-165': 0.152401247463471, 'IoU-166': 0.2439632631881225, 'IoU-167': 0.0605607649456417, 'IoU-168': 0.04217314115078258, 'IoU-169': 0.10263013937366569, 'IoU-170': 0.04064107160262945, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 6.320622881942558, 'pACC': 13.702359001115912, 'ACC-0': 0.0003605814247525888, 'ACC-1': 31.013862064997298, 'ACC-2': 6.602596530464933, 'ACC-3': 9.979526332694782, 'ACC-4': 7.243706561428493, 'ACC-5': 6.50492469734535, 'ACC-6': 6.433014795537366, 'ACC-7': 6.702072189344797, 'ACC-8': 11.920712173552884, 'ACC-9': 14.169735303438294, 'ACC-10': 17.47570231075856, 'ACC-11': 24.883369196113417, 'ACC-12': 28.422963338723, 'ACC-13': 23.011122435048378, 'ACC-14': 20.780328882477406, 'ACC-15': 18.18569741823493, 'ACC-16': 16.332769606380772, 'ACC-17': 14.267263290227358, 'ACC-18': 14.05215624338227, 'ACC-19': 11.215819958472032, 'ACC-20': 11.619828596174537, 'ACC-21': 12.232672924157644, 'ACC-22': 13.137341535760564, 'ACC-23': 12.561094449711963, 'ACC-24': 12.103715432707693, 'ACC-25': 11.88578428181385, 'ACC-26': 11.922786920516081, 'ACC-27': 12.170092763876307, 'ACC-28': 11.55216762080817, 'ACC-29': 11.14763107251405, 'ACC-30': 11.809458002382407, 'ACC-31': 12.078686942714699, 'ACC-32': 12.313438471704938, 'ACC-33': 12.260257817673184, 'ACC-34': 12.354474966065757, 'ACC-35': 12.594067202814315, 'ACC-36': 12.490987269168317, 'ACC-37': 12.54647814937362, 'ACC-38': 12.630551407189355, 'ACC-39': 12.23153456490666, 'ACC-40': 12.448289439075092, 'ACC-41': 12.709815804820607, 'ACC-42': 13.278637242162011, 'ACC-43': 13.24721966532551, 'ACC-44': 13.100795865138014, 'ACC-45': 12.855113907804158, 'ACC-46': 12.494686224925463, 'ACC-47': 12.106381683494547, 'ACC-48': 12.119887332996047, 'ACC-49': 11.507198840888343, 'ACC-50': 11.653873240199411, 'ACC-51': 11.177068237571147, 'ACC-52': 10.81699302000347, 'ACC-53': 10.375345923859882, 'ACC-54': 10.090868901591946, 'ACC-55': 9.092375535067871, 'ACC-56': 8.634260315884488, 'ACC-57': 8.303107682017034, 'ACC-58': 7.827281827584382, 'ACC-59': 7.746719536672201, 'ACC-60': 7.737000827579587, 'ACC-61': 7.343512943929227, 'ACC-62': 7.355962714936948, 'ACC-63': 7.340044963086589, 'ACC-64': 7.321177443101816, 'ACC-65': 7.380214621291891, 'ACC-66': 7.2640739222029485, 'ACC-67': 6.839792176595299, 'ACC-68': 6.857332587868696, 'ACC-69': 6.9763825782310604, 'ACC-70': 6.790635580996662, 'ACC-71': 6.886207506779566, 'ACC-72': 6.845211845191799, 'ACC-73': 6.782257248287235, 'ACC-74': 6.7461507467032344, 'ACC-75': 6.764460179155851, 'ACC-76': 6.806915226435772, 'ACC-77': 7.129898027198424, 'ACC-78': 7.095233056322933, 'ACC-79': 6.816361486291192, 'ACC-80': 6.959083539942748, 'ACC-81': 7.097262433837812, 'ACC-82': 7.12277865674285, 'ACC-83': 7.251132683418811, 'ACC-84': 7.369196348014912, 'ACC-85': 7.2328127046905655, 'ACC-86': 7.2779405983800425, 'ACC-87': 7.469335091206815, 'ACC-88': 7.1066026213211275, 'ACC-89': 7.0417202513329595, 'ACC-90': 7.0637697199347205, 'ACC-91': 6.968373892778715, 'ACC-92': 6.820375237525629, 'ACC-93': 6.977699029937193, 'ACC-94': 6.493157175143717, 'ACC-95': 6.463803518756945, 'ACC-96': 6.43169734427179, 'ACC-97': 6.165323449804814, 'ACC-98': 6.481749437057596, 'ACC-99': 5.996245777753437, 'ACC-100': 5.854756164512422, 'ACC-101': 5.735864580592912, 'ACC-102': 5.512143180788401, 'ACC-103': 5.465783508075942, 'ACC-104': 5.5455842207520725, 'ACC-105': 5.5160563609055275, 'ACC-106': 5.552824058085709, 'ACC-107': 5.258633256312851, 'ACC-108': 5.1038476111304725, 'ACC-109': 5.283755951596282, 'ACC-110': 4.714424348775989, 'ACC-111': 4.2637127489242, 'ACC-112': 4.201625716781479, 'ACC-113': 3.932267690349741, 'ACC-114': 4.009807590897512, 'ACC-115': 3.6925864116789198, 'ACC-116': 4.0416779989026725, 'ACC-117': 3.764203460987345, 'ACC-118': 4.013566797119869, 'ACC-119': 4.063628413359942, 'ACC-120': 3.879354269670423, 'ACC-121': 3.7346017286306896, 'ACC-122': 3.8496230669799125, 'ACC-123': 3.3902310976199455, 'ACC-124': 3.1507627985920843, 'ACC-125': 2.837344987779582, 'ACC-126': 3.1440404739569576, 'ACC-127': 2.852680615649151, 'ACC-128': 2.5774157784388416, 'ACC-129': 2.723149880236628, 'ACC-130': 2.807867032295179, 'ACC-131': 3.1164082452932886, 'ACC-132': 2.9640799831106555, 'ACC-133': 2.5339702109997484, 'ACC-134': 2.97106419646704, 'ACC-135': 2.546391311783821, 'ACC-136': 2.1745713753261278, 'ACC-137': 1.92616948184919, 'ACC-138': 2.296653298474503, 'ACC-139': 2.3131732408118695, 'ACC-140': 1.567451344819418, 'ACC-141': 1.6424607709643702, 'ACC-142': 1.8588529344724867, 'ACC-143': 1.7525225703664364, 'ACC-144': 1.3957581227436824, 'ACC-145': 1.6017352803059104, 'ACC-146': 1.5592058668981745, 'ACC-147': 1.5739338503950386, 'ACC-148': 2.346274087472946, 'ACC-149': 1.0521576076319201, 'ACC-150': 1.0332402551987734, 'ACC-151': 2.1030968268635366, 'ACC-152': 1.4861083013015037, 'ACC-153': 1.799226808845893, 'ACC-154': 1.120156117355727, 'ACC-155': 1.22244325955288, 'ACC-156': 1.3003936473462738, 'ACC-157': 1.5085752239248815, 'ACC-158': 1.047066477924666, 'ACC-159': 0.6327139928605251, 'ACC-160': 0.6075249966067955, 'ACC-161': 0.8176602251760152, 'ACC-162': 0.6686978021487588, 'ACC-163': 0.48106981856314973, 'ACC-164': 0.2955361984278235, 'ACC-165': 0.2021745275976965, 'ACC-166': 0.32518823815799414, 'ACC-167': 0.06826863447097019, 'ACC-168': 0.043603628947183344, 'ACC-169': 0.1115998968227369, 'ACC-170': 0.04365603305081136, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 01:25:53] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 01:25:53] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 01:25:53] d2.evaluation.testing INFO: copypaste: 4.2478,0.6013,0.3251,3.2871,8.7030,6.3206,13.7024
[01/29 01:25:53] d2.utils.events INFO:  eta: 1 day, 20:43:30  iter: 6999  total_loss: 46.93  loss_mask: 4.693  loss_mask_0: 4.752  loss_mask_1: 4.579  loss_mask_2: 4.637  loss_mask_3: 4.668  loss_mask_4: 4.772  loss_mask_5: 4.744  loss_mask_6: 4.673  loss_mask_7: 4.659  loss_mask_8: 4.722  time: 3.0589  data_time: 0.0778  lr: 8.9437e-05  max_mem: 27632M
[01/29 01:26:54] d2.utils.events INFO:  eta: 1 day, 20:41:40  iter: 7019  total_loss: 47.03  loss_mask: 4.666  loss_mask_0: 4.939  loss_mask_1: 4.592  loss_mask_2: 4.881  loss_mask_3: 4.717  loss_mask_4: 4.84  loss_mask_5: 4.748  loss_mask_6: 4.68  loss_mask_7: 4.619  loss_mask_8: 4.634  time: 3.0588  data_time: 0.0573  lr: 8.9407e-05  max_mem: 27632M
[01/29 01:27:55] d2.utils.events INFO:  eta: 1 day, 20:40:23  iter: 7039  total_loss: 45.78  loss_mask: 4.524  loss_mask_0: 4.714  loss_mask_1: 4.513  loss_mask_2: 4.714  loss_mask_3: 4.585  loss_mask_4: 4.642  loss_mask_5: 4.505  loss_mask_6: 4.493  loss_mask_7: 4.502  loss_mask_8: 4.465  time: 3.0587  data_time: 0.0608  lr: 8.9377e-05  max_mem: 27632M
[01/29 01:28:56] d2.utils.events INFO:  eta: 1 day, 20:39:27  iter: 7059  total_loss: 45.4  loss_mask: 4.505  loss_mask_0: 4.793  loss_mask_1: 4.49  loss_mask_2: 4.645  loss_mask_3: 4.516  loss_mask_4: 4.567  loss_mask_5: 4.511  loss_mask_6: 4.484  loss_mask_7: 4.518  loss_mask_8: 4.501  time: 3.0587  data_time: 0.0600  lr: 8.9346e-05  max_mem: 27632M
[01/29 01:29:56] d2.utils.events INFO:  eta: 1 day, 20:37:14  iter: 7079  total_loss: 42.96  loss_mask: 4.307  loss_mask_0: 4.453  loss_mask_1: 4.197  loss_mask_2: 4.352  loss_mask_3: 4.349  loss_mask_4: 4.383  loss_mask_5: 4.326  loss_mask_6: 4.239  loss_mask_7: 4.306  loss_mask_8: 4.312  time: 3.0585  data_time: 0.0544  lr: 8.9316e-05  max_mem: 27632M
[01/29 01:30:56] d2.utils.events INFO:  eta: 1 day, 20:34:59  iter: 7099  total_loss: 44.21  loss_mask: 4.266  loss_mask_0: 5.645  loss_mask_1: 4.352  loss_mask_2: 4.336  loss_mask_3: 4.289  loss_mask_4: 4.337  loss_mask_5: 4.298  loss_mask_6: 4.283  loss_mask_7: 4.262  loss_mask_8: 4.301  time: 3.0583  data_time: 0.0616  lr: 8.9286e-05  max_mem: 27632M
[01/29 01:31:56] d2.utils.events INFO:  eta: 1 day, 20:33:20  iter: 7119  total_loss: 50.14  loss_mask: 4.789  loss_mask_0: 7.145  loss_mask_1: 4.688  loss_mask_2: 4.84  loss_mask_3: 4.714  loss_mask_4: 4.802  loss_mask_5: 4.746  loss_mask_6: 4.793  loss_mask_7: 4.835  loss_mask_8: 4.821  time: 3.0582  data_time: 0.0553  lr: 8.9255e-05  max_mem: 27632M
[01/29 01:32:55] d2.utils.events INFO:  eta: 1 day, 20:31:40  iter: 7139  total_loss: 44.81  loss_mask: 4.39  loss_mask_0: 4.819  loss_mask_1: 4.465  loss_mask_2: 4.567  loss_mask_3: 4.359  loss_mask_4: 4.367  loss_mask_5: 4.351  loss_mask_6: 4.369  loss_mask_7: 4.431  loss_mask_8: 4.46  time: 3.0580  data_time: 0.0603  lr: 8.9225e-05  max_mem: 27632M
[01/29 01:33:56] d2.utils.events INFO:  eta: 1 day, 20:30:33  iter: 7159  total_loss: 43.51  loss_mask: 4.386  loss_mask_0: 4.497  loss_mask_1: 4.237  loss_mask_2: 4.391  loss_mask_3: 4.332  loss_mask_4: 4.329  loss_mask_5: 4.355  loss_mask_6: 4.293  loss_mask_7: 4.302  loss_mask_8: 4.347  time: 3.0578  data_time: 0.0589  lr: 8.9194e-05  max_mem: 27632M
[01/29 01:34:56] d2.utils.events INFO:  eta: 1 day, 20:29:58  iter: 7179  total_loss: 43.47  loss_mask: 4.338  loss_mask_0: 4.487  loss_mask_1: 4.286  loss_mask_2: 4.29  loss_mask_3: 4.297  loss_mask_4: 4.337  loss_mask_5: 4.315  loss_mask_6: 4.304  loss_mask_7: 4.291  loss_mask_8: 4.29  time: 3.0577  data_time: 0.0611  lr: 8.9164e-05  max_mem: 27632M
[01/29 01:35:56] d2.utils.events INFO:  eta: 1 day, 20:28:32  iter: 7199  total_loss: 47.56  loss_mask: 4.7  loss_mask_0: 4.884  loss_mask_1: 4.648  loss_mask_2: 4.69  loss_mask_3: 4.729  loss_mask_4: 4.794  loss_mask_5: 4.709  loss_mask_6: 4.697  loss_mask_7: 4.667  loss_mask_8: 4.706  time: 3.0576  data_time: 0.0587  lr: 8.9134e-05  max_mem: 27632M
[01/29 01:36:56] d2.utils.events INFO:  eta: 1 day, 20:26:23  iter: 7219  total_loss: 45.03  loss_mask: 4.52  loss_mask_0: 4.694  loss_mask_1: 4.443  loss_mask_2: 4.501  loss_mask_3: 4.481  loss_mask_4: 4.591  loss_mask_5: 4.524  loss_mask_6: 4.438  loss_mask_7: 4.506  loss_mask_8: 4.529  time: 3.0574  data_time: 0.0535  lr: 8.9103e-05  max_mem: 27632M
[01/29 01:37:56] d2.utils.events INFO:  eta: 1 day, 20:24:37  iter: 7239  total_loss: 45.18  loss_mask: 4.512  loss_mask_0: 4.683  loss_mask_1: 4.465  loss_mask_2: 4.527  loss_mask_3: 4.446  loss_mask_4: 4.487  loss_mask_5: 4.478  loss_mask_6: 4.457  loss_mask_7: 4.509  loss_mask_8: 4.482  time: 3.0573  data_time: 0.0526  lr: 8.9073e-05  max_mem: 27632M
[01/29 01:38:57] d2.utils.events INFO:  eta: 1 day, 20:23:13  iter: 7259  total_loss: 43.62  loss_mask: 4.388  loss_mask_0: 4.896  loss_mask_1: 4.26  loss_mask_2: 4.343  loss_mask_3: 4.352  loss_mask_4: 4.363  loss_mask_5: 4.382  loss_mask_6: 4.318  loss_mask_7: 4.393  loss_mask_8: 4.274  time: 3.0572  data_time: 0.0542  lr: 8.9043e-05  max_mem: 27632M
[01/29 01:39:57] d2.utils.events INFO:  eta: 1 day, 20:21:22  iter: 7279  total_loss: 47.31  loss_mask: 4.677  loss_mask_0: 4.997  loss_mask_1: 4.618  loss_mask_2: 4.708  loss_mask_3: 4.731  loss_mask_4: 4.684  loss_mask_5: 4.611  loss_mask_6: 4.721  loss_mask_7: 4.793  loss_mask_8: 4.718  time: 3.0571  data_time: 0.0591  lr: 8.9012e-05  max_mem: 27632M
[01/29 01:40:57] d2.utils.events INFO:  eta: 1 day, 20:19:18  iter: 7299  total_loss: 43.84  loss_mask: 4.44  loss_mask_0: 4.601  loss_mask_1: 4.308  loss_mask_2: 4.413  loss_mask_3: 4.399  loss_mask_4: 4.365  loss_mask_5: 4.316  loss_mask_6: 4.4  loss_mask_7: 4.357  loss_mask_8: 4.342  time: 3.0569  data_time: 0.0584  lr: 8.8982e-05  max_mem: 27632M
[01/29 01:41:57] d2.utils.events INFO:  eta: 1 day, 20:17:56  iter: 7319  total_loss: 43.71  loss_mask: 4.336  loss_mask_0: 4.85  loss_mask_1: 4.226  loss_mask_2: 4.282  loss_mask_3: 4.266  loss_mask_4: 4.273  loss_mask_5: 4.274  loss_mask_6: 4.216  loss_mask_7: 4.359  loss_mask_8: 4.263  time: 3.0568  data_time: 0.0710  lr: 8.8951e-05  max_mem: 27632M
[01/29 01:42:58] d2.utils.events INFO:  eta: 1 day, 20:16:00  iter: 7339  total_loss: 46.96  loss_mask: 4.669  loss_mask_0: 4.832  loss_mask_1: 4.631  loss_mask_2: 4.744  loss_mask_3: 4.668  loss_mask_4: 4.667  loss_mask_5: 4.613  loss_mask_6: 4.723  loss_mask_7: 4.634  loss_mask_8: 4.661  time: 3.0566  data_time: 0.0586  lr: 8.8921e-05  max_mem: 27632M
[01/29 01:43:58] d2.utils.events INFO:  eta: 1 day, 20:15:27  iter: 7359  total_loss: 48.96  loss_mask: 4.955  loss_mask_0: 5.228  loss_mask_1: 4.833  loss_mask_2: 4.796  loss_mask_3: 4.845  loss_mask_4: 4.889  loss_mask_5: 5.178  loss_mask_6: 4.881  loss_mask_7: 4.863  loss_mask_8: 4.858  time: 3.0566  data_time: 0.0633  lr: 8.8891e-05  max_mem: 27632M
[01/29 01:44:59] d2.utils.events INFO:  eta: 1 day, 20:13:59  iter: 7379  total_loss: 48.7  loss_mask: 4.833  loss_mask_0: 4.875  loss_mask_1: 4.925  loss_mask_2: 5.039  loss_mask_3: 4.81  loss_mask_4: 4.869  loss_mask_5: 4.827  loss_mask_6: 5.081  loss_mask_7: 4.871  loss_mask_8: 4.865  time: 3.0565  data_time: 0.0543  lr: 8.886e-05  max_mem: 27632M
[01/29 01:45:59] d2.utils.events INFO:  eta: 1 day, 20:12:36  iter: 7399  total_loss: 47.66  loss_mask: 4.751  loss_mask_0: 5.006  loss_mask_1: 4.838  loss_mask_2: 4.829  loss_mask_3: 4.655  loss_mask_4: 4.66  loss_mask_5: 4.76  loss_mask_6: 4.707  loss_mask_7: 4.743  loss_mask_8: 4.702  time: 3.0564  data_time: 0.0628  lr: 8.883e-05  max_mem: 27632M
[01/29 01:46:59] d2.utils.events INFO:  eta: 1 day, 20:11:49  iter: 7419  total_loss: 46.11  loss_mask: 4.579  loss_mask_0: 4.826  loss_mask_1: 4.585  loss_mask_2: 4.739  loss_mask_3: 4.581  loss_mask_4: 4.67  loss_mask_5: 4.509  loss_mask_6: 4.529  loss_mask_7: 4.658  loss_mask_8: 4.489  time: 3.0562  data_time: 0.0576  lr: 8.8799e-05  max_mem: 27632M
[01/29 01:48:00] d2.utils.events INFO:  eta: 1 day, 20:09:45  iter: 7439  total_loss: 42.04  loss_mask: 4.177  loss_mask_0: 4.36  loss_mask_1: 4.136  loss_mask_2: 4.134  loss_mask_3: 4.152  loss_mask_4: 4.181  loss_mask_5: 4.213  loss_mask_6: 4.189  loss_mask_7: 4.19  loss_mask_8: 4.166  time: 3.0562  data_time: 0.0681  lr: 8.8769e-05  max_mem: 27632M
[01/29 01:49:01] d2.utils.events INFO:  eta: 1 day, 20:09:18  iter: 7459  total_loss: 41.89  loss_mask: 4.175  loss_mask_0: 4.297  loss_mask_1: 4.2  loss_mask_2: 4.144  loss_mask_3: 4.212  loss_mask_4: 4.147  loss_mask_5: 4.196  loss_mask_6: 4.153  loss_mask_7: 4.19  loss_mask_8: 4.191  time: 3.0561  data_time: 0.0615  lr: 8.8739e-05  max_mem: 27632M
[01/29 01:50:01] d2.utils.events INFO:  eta: 1 day, 20:07:58  iter: 7479  total_loss: 42.87  loss_mask: 4.39  loss_mask_0: 4.35  loss_mask_1: 4.259  loss_mask_2: 4.289  loss_mask_3: 4.265  loss_mask_4: 4.342  loss_mask_5: 4.245  loss_mask_6: 4.305  loss_mask_7: 4.268  loss_mask_8: 4.225  time: 3.0561  data_time: 0.0595  lr: 8.8708e-05  max_mem: 27632M
[01/29 01:51:01] d2.utils.events INFO:  eta: 1 day, 20:05:43  iter: 7499  total_loss: 47.4  loss_mask: 4.618  loss_mask_0: 4.983  loss_mask_1: 4.637  loss_mask_2: 4.771  loss_mask_3: 4.624  loss_mask_4: 4.558  loss_mask_5: 4.724  loss_mask_6: 4.67  loss_mask_7: 4.812  loss_mask_8: 4.848  time: 3.0559  data_time: 0.0537  lr: 8.8678e-05  max_mem: 27632M
[01/29 01:52:01] d2.utils.events INFO:  eta: 1 day, 20:03:44  iter: 7519  total_loss: 45.84  loss_mask: 4.555  loss_mask_0: 4.71  loss_mask_1: 4.531  loss_mask_2: 4.541  loss_mask_3: 4.502  loss_mask_4: 4.56  loss_mask_5: 4.534  loss_mask_6: 4.496  loss_mask_7: 4.569  loss_mask_8: 4.584  time: 3.0557  data_time: 0.0563  lr: 8.8647e-05  max_mem: 27632M
[01/29 01:53:01] d2.utils.events INFO:  eta: 1 day, 20:01:43  iter: 7539  total_loss: 44.24  loss_mask: 4.43  loss_mask_0: 4.587  loss_mask_1: 4.363  loss_mask_2: 4.316  loss_mask_3: 4.415  loss_mask_4: 4.398  loss_mask_5: 4.359  loss_mask_6: 4.419  loss_mask_7: 4.345  loss_mask_8: 4.366  time: 3.0556  data_time: 0.0600  lr: 8.8617e-05  max_mem: 27632M
[01/29 01:54:01] d2.utils.events INFO:  eta: 1 day, 19:59:12  iter: 7559  total_loss: 47.06  loss_mask: 4.691  loss_mask_0: 4.847  loss_mask_1: 4.695  loss_mask_2: 4.712  loss_mask_3: 4.686  loss_mask_4: 4.671  loss_mask_5: 4.685  loss_mask_6: 4.712  loss_mask_7: 4.684  loss_mask_8: 4.694  time: 3.0554  data_time: 0.0591  lr: 8.8587e-05  max_mem: 27632M
[01/29 01:55:01] d2.utils.events INFO:  eta: 1 day, 19:57:53  iter: 7579  total_loss: 42.96  loss_mask: 4.35  loss_mask_0: 4.471  loss_mask_1: 4.27  loss_mask_2: 4.251  loss_mask_3: 4.292  loss_mask_4: 4.282  loss_mask_5: 4.271  loss_mask_6: 4.304  loss_mask_7: 4.266  loss_mask_8: 4.251  time: 3.0552  data_time: 0.0586  lr: 8.8556e-05  max_mem: 27632M
[01/29 01:56:01] d2.utils.events INFO:  eta: 1 day, 19:56:12  iter: 7599  total_loss: 44.45  loss_mask: 4.494  loss_mask_0: 4.5  loss_mask_1: 4.442  loss_mask_2: 4.402  loss_mask_3: 4.455  loss_mask_4: 4.463  loss_mask_5: 4.389  loss_mask_6: 4.442  loss_mask_7: 4.473  loss_mask_8: 4.393  time: 3.0551  data_time: 0.0611  lr: 8.8526e-05  max_mem: 27632M
[01/29 01:57:01] d2.utils.events INFO:  eta: 1 day, 19:53:54  iter: 7619  total_loss: 40.77  loss_mask: 4.092  loss_mask_0: 4.124  loss_mask_1: 4.039  loss_mask_2: 4.039  loss_mask_3: 4.083  loss_mask_4: 4.044  loss_mask_5: 4.013  loss_mask_6: 4.128  loss_mask_7: 4.051  loss_mask_8: 4.06  time: 3.0549  data_time: 0.0577  lr: 8.8495e-05  max_mem: 27632M
[01/29 01:58:01] d2.utils.events INFO:  eta: 1 day, 19:52:45  iter: 7639  total_loss: 45.14  loss_mask: 4.517  loss_mask_0: 4.637  loss_mask_1: 4.428  loss_mask_2: 4.477  loss_mask_3: 4.503  loss_mask_4: 4.482  loss_mask_5: 4.528  loss_mask_6: 4.491  loss_mask_7: 4.504  loss_mask_8: 4.535  time: 3.0548  data_time: 0.0595  lr: 8.8465e-05  max_mem: 27632M
[01/29 01:59:01] d2.utils.events INFO:  eta: 1 day, 19:51:37  iter: 7659  total_loss: 45.29  loss_mask: 4.497  loss_mask_0: 4.757  loss_mask_1: 4.465  loss_mask_2: 4.538  loss_mask_3: 4.465  loss_mask_4: 4.558  loss_mask_5: 4.541  loss_mask_6: 4.491  loss_mask_7: 4.506  loss_mask_8: 4.505  time: 3.0546  data_time: 0.0643  lr: 8.8434e-05  max_mem: 27632M
[01/29 02:00:01] d2.utils.events INFO:  eta: 1 day, 19:48:35  iter: 7679  total_loss: 42.65  loss_mask: 4.254  loss_mask_0: 4.38  loss_mask_1: 4.214  loss_mask_2: 4.248  loss_mask_3: 4.211  loss_mask_4: 4.274  loss_mask_5: 4.255  loss_mask_6: 4.243  loss_mask_7: 4.274  loss_mask_8: 4.275  time: 3.0544  data_time: 0.0617  lr: 8.8404e-05  max_mem: 27632M
[01/29 02:01:01] d2.utils.events INFO:  eta: 1 day, 19:47:37  iter: 7699  total_loss: 40.56  loss_mask: 4.061  loss_mask_0: 4.237  loss_mask_1: 4.058  loss_mask_2: 4.035  loss_mask_3: 4.035  loss_mask_4: 4.026  loss_mask_5: 4.025  loss_mask_6: 4.062  loss_mask_7: 4.067  loss_mask_8: 4.033  time: 3.0544  data_time: 0.0645  lr: 8.8374e-05  max_mem: 27632M
[01/29 02:02:01] d2.utils.events INFO:  eta: 1 day, 19:46:37  iter: 7719  total_loss: 44.61  loss_mask: 4.463  loss_mask_0: 4.673  loss_mask_1: 4.381  loss_mask_2: 4.41  loss_mask_3: 4.396  loss_mask_4: 4.428  loss_mask_5: 4.494  loss_mask_6: 4.461  loss_mask_7: 4.467  loss_mask_8: 4.449  time: 3.0542  data_time: 0.0476  lr: 8.8343e-05  max_mem: 27632M
[01/29 02:03:01] d2.utils.events INFO:  eta: 1 day, 19:45:36  iter: 7739  total_loss: 40.35  loss_mask: 4.085  loss_mask_0: 4.226  loss_mask_1: 3.966  loss_mask_2: 3.977  loss_mask_3: 4.063  loss_mask_4: 4.013  loss_mask_5: 4.065  loss_mask_6: 4.062  loss_mask_7: 3.993  loss_mask_8: 4.021  time: 3.0541  data_time: 0.0579  lr: 8.8313e-05  max_mem: 27632M
[01/29 02:04:02] d2.utils.events INFO:  eta: 1 day, 19:45:39  iter: 7759  total_loss: 43.57  loss_mask: 4.31  loss_mask_0: 4.552  loss_mask_1: 4.275  loss_mask_2: 4.233  loss_mask_3: 4.375  loss_mask_4: 4.188  loss_mask_5: 4.224  loss_mask_6: 4.343  loss_mask_7: 4.195  loss_mask_8: 4.265  time: 3.0540  data_time: 0.0568  lr: 8.8282e-05  max_mem: 27632M
[01/29 02:05:03] d2.utils.events INFO:  eta: 1 day, 19:45:24  iter: 7779  total_loss: 40.7  loss_mask: 4.079  loss_mask_0: 4.329  loss_mask_1: 3.971  loss_mask_2: 4.014  loss_mask_3: 4.093  loss_mask_4: 4.058  loss_mask_5: 4.043  loss_mask_6: 4.062  loss_mask_7: 4.006  loss_mask_8: 3.971  time: 3.0540  data_time: 0.0598  lr: 8.8252e-05  max_mem: 27632M
[01/29 02:06:04] d2.utils.events INFO:  eta: 1 day, 19:44:24  iter: 7799  total_loss: 48.95  loss_mask: 4.859  loss_mask_0: 5.726  loss_mask_1: 4.787  loss_mask_2: 4.802  loss_mask_3: 4.725  loss_mask_4: 4.746  loss_mask_5: 4.799  loss_mask_6: 4.772  loss_mask_7: 4.89  loss_mask_8: 4.776  time: 3.0540  data_time: 0.0667  lr: 8.8222e-05  max_mem: 27632M
[01/29 02:07:04] d2.utils.events INFO:  eta: 1 day, 19:42:59  iter: 7819  total_loss: 46.07  loss_mask: 4.571  loss_mask_0: 4.79  loss_mask_1: 4.555  loss_mask_2: 4.592  loss_mask_3: 4.615  loss_mask_4: 4.586  loss_mask_5: 4.603  loss_mask_6: 4.574  loss_mask_7: 4.611  loss_mask_8: 4.569  time: 3.0539  data_time: 0.0680  lr: 8.8191e-05  max_mem: 27632M
[01/29 02:08:05] d2.utils.events INFO:  eta: 1 day, 19:41:59  iter: 7839  total_loss: 45.85  loss_mask: 4.542  loss_mask_0: 4.625  loss_mask_1: 4.516  loss_mask_2: 4.633  loss_mask_3: 4.544  loss_mask_4: 4.58  loss_mask_5: 4.587  loss_mask_6: 4.64  loss_mask_7: 4.417  loss_mask_8: 4.507  time: 3.0538  data_time: 0.0622  lr: 8.8161e-05  max_mem: 27632M
[01/29 02:09:06] d2.utils.events INFO:  eta: 1 day, 19:40:58  iter: 7859  total_loss: 42.31  loss_mask: 4.321  loss_mask_0: 4.258  loss_mask_1: 4.141  loss_mask_2: 4.281  loss_mask_3: 4.145  loss_mask_4: 4.248  loss_mask_5: 4.208  loss_mask_6: 4.212  loss_mask_7: 4.227  loss_mask_8: 4.247  time: 3.0538  data_time: 0.0607  lr: 8.813e-05  max_mem: 27632M
[01/29 02:10:06] d2.utils.events INFO:  eta: 1 day, 19:38:34  iter: 7879  total_loss: 39.62  loss_mask: 3.951  loss_mask_0: 4.157  loss_mask_1: 3.91  loss_mask_2: 3.94  loss_mask_3: 4.11  loss_mask_4: 3.893  loss_mask_5: 3.936  loss_mask_6: 3.971  loss_mask_7: 3.905  loss_mask_8: 3.869  time: 3.0537  data_time: 0.0616  lr: 8.81e-05  max_mem: 27632M
[01/29 02:11:06] d2.utils.events INFO:  eta: 1 day, 19:37:24  iter: 7899  total_loss: 43.95  loss_mask: 4.371  loss_mask_0: 4.573  loss_mask_1: 4.4  loss_mask_2: 4.436  loss_mask_3: 4.389  loss_mask_4: 4.374  loss_mask_5: 4.354  loss_mask_6: 4.386  loss_mask_7: 4.37  loss_mask_8: 4.387  time: 3.0536  data_time: 0.0599  lr: 8.8069e-05  max_mem: 27632M
[01/29 02:12:07] d2.utils.events INFO:  eta: 1 day, 19:36:14  iter: 7919  total_loss: 39.25  loss_mask: 3.894  loss_mask_0: 4.037  loss_mask_1: 3.882  loss_mask_2: 3.881  loss_mask_3: 3.954  loss_mask_4: 3.932  loss_mask_5: 3.878  loss_mask_6: 3.905  loss_mask_7: 3.927  loss_mask_8: 3.875  time: 3.0535  data_time: 0.0709  lr: 8.8039e-05  max_mem: 27632M
[01/29 02:13:07] d2.utils.events INFO:  eta: 1 day, 19:35:01  iter: 7939  total_loss: 46.63  loss_mask: 4.63  loss_mask_0: 4.757  loss_mask_1: 4.627  loss_mask_2: 4.646  loss_mask_3: 4.58  loss_mask_4: 4.663  loss_mask_5: 4.627  loss_mask_6: 4.611  loss_mask_7: 4.532  loss_mask_8: 4.638  time: 3.0534  data_time: 0.0624  lr: 8.8009e-05  max_mem: 27632M
[01/29 02:14:07] d2.utils.events INFO:  eta: 1 day, 19:33:26  iter: 7959  total_loss: 43.44  loss_mask: 4.332  loss_mask_0: 4.433  loss_mask_1: 4.302  loss_mask_2: 4.293  loss_mask_3: 4.284  loss_mask_4: 4.34  loss_mask_5: 4.341  loss_mask_6: 4.289  loss_mask_7: 4.267  loss_mask_8: 4.32  time: 3.0533  data_time: 0.0627  lr: 8.7978e-05  max_mem: 27632M
[01/29 02:15:07] d2.utils.events INFO:  eta: 1 day, 19:30:41  iter: 7979  total_loss: 39.53  loss_mask: 3.978  loss_mask_0: 3.983  loss_mask_1: 3.987  loss_mask_2: 3.953  loss_mask_3: 3.966  loss_mask_4: 3.946  loss_mask_5: 3.957  loss_mask_6: 3.897  loss_mask_7: 3.931  loss_mask_8: 3.916  time: 3.0531  data_time: 0.0585  lr: 8.7948e-05  max_mem: 27632M
[01/29 02:16:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 02:16:07] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 02:16:07] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 02:30:04] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.9359972132333554, 'error_1pix': 0.5945468600848139, 'error_3pix': 0.3035249478424319, 'mIoU': 3.632963387558302, 'fwIoU': 9.93626128310324, 'IoU-0': 2.2360680883329183e-05, 'IoU-1': 42.86660260827374, 'IoU-2': 3.1262416548878456, 'IoU-3': 2.1090161793417885, 'IoU-4': 1.5897807775980364, 'IoU-5': 1.2272055779067406, 'IoU-6': 1.0330820593656889, 'IoU-7': 0.8818802584480697, 'IoU-8': 2.5836064834908385, 'IoU-9': 4.571342422349319, 'IoU-10': 5.466805391111947, 'IoU-11': 7.703486138948722, 'IoU-12': 7.473978236235499, 'IoU-13': 7.854243559162294, 'IoU-14': 7.183828768468925, 'IoU-15': 6.638323084134012, 'IoU-16': 6.012562415604313, 'IoU-17': 5.0897854576562995, 'IoU-18': 5.35144143007046, 'IoU-19': 6.417669131236221, 'IoU-20': 5.690597041972074, 'IoU-21': 6.2053728544209115, 'IoU-22': 6.261354121970097, 'IoU-23': 6.4908265157885765, 'IoU-24': 6.856385941924153, 'IoU-25': 7.579422264661797, 'IoU-26': 8.057878782478141, 'IoU-27': 8.978186237745607, 'IoU-28': 9.45811962930898, 'IoU-29': 9.77377639155763, 'IoU-30': 9.831904075123136, 'IoU-31': 10.279345176617168, 'IoU-32': 9.766324787347815, 'IoU-33': 8.875081937114956, 'IoU-34': 8.570333525598247, 'IoU-35': 8.815969550108163, 'IoU-36': 8.59075585950708, 'IoU-37': 8.14756241937279, 'IoU-38': 7.618054525783223, 'IoU-39': 7.248167061469295, 'IoU-40': 7.213908901343631, 'IoU-41': 6.7001550279476145, 'IoU-42': 6.676649472462125, 'IoU-43': 6.685708120240418, 'IoU-44': 6.642975613708919, 'IoU-45': 6.47600521650966, 'IoU-46': 6.135828302609816, 'IoU-47': 5.976014280482182, 'IoU-48': 6.040401956119911, 'IoU-49': 5.944033241105428, 'IoU-50': 5.797645378930779, 'IoU-51': 5.5098626773767165, 'IoU-52': 5.494499451291089, 'IoU-53': 5.611769957970381, 'IoU-54': 5.534865091754719, 'IoU-55': 5.32234729162605, 'IoU-56': 5.05954480593959, 'IoU-57': 5.063842727232222, 'IoU-58': 4.977718563084435, 'IoU-59': 4.899115257575672, 'IoU-60': 4.679367879626619, 'IoU-61': 4.382184207633289, 'IoU-62': 4.541118390251979, 'IoU-63': 4.4629258009108765, 'IoU-64': 4.421069459387624, 'IoU-65': 4.457186721670324, 'IoU-66': 4.460584292998602, 'IoU-67': 4.16382550692904, 'IoU-68': 4.014352319098646, 'IoU-69': 4.325119666361558, 'IoU-70': 4.400463130472538, 'IoU-71': 4.316936594505715, 'IoU-72': 4.135907084900726, 'IoU-73': 4.090669626285307, 'IoU-74': 4.153416633829608, 'IoU-75': 4.140116749021254, 'IoU-76': 4.119037295953943, 'IoU-77': 4.172661837826225, 'IoU-78': 4.053945919473486, 'IoU-79': 3.993812281028259, 'IoU-80': 4.185750046343139, 'IoU-81': 4.211469976608879, 'IoU-82': 4.115232347425211, 'IoU-83': 4.235445606689822, 'IoU-84': 4.205517107439299, 'IoU-85': 4.042886840745503, 'IoU-86': 4.078872289784624, 'IoU-87': 4.082625882794274, 'IoU-88': 3.9523975982932056, 'IoU-89': 3.888612902977942, 'IoU-90': 3.9144229608021046, 'IoU-91': 3.752924188158804, 'IoU-92': 3.526510354292986, 'IoU-93': 3.539770668189636, 'IoU-94': 3.658330834435096, 'IoU-95': 3.4809936699926047, 'IoU-96': 3.2920842788391282, 'IoU-97': 3.3408507123403264, 'IoU-98': 3.320873158727565, 'IoU-99': 3.22213633718658, 'IoU-100': 2.9080515748388756, 'IoU-101': 2.8151354528090775, 'IoU-102': 2.750375631954945, 'IoU-103': 2.8354300061065736, 'IoU-104': 2.8837433936065104, 'IoU-105': 2.8917694749226763, 'IoU-106': 2.897687662188926, 'IoU-107': 2.8811838627099773, 'IoU-108': 2.6264584368941644, 'IoU-109': 2.8505528590817892, 'IoU-110': 2.687619216129325, 'IoU-111': 2.53691958859381, 'IoU-112': 2.3889697010954314, 'IoU-113': 2.3714904214984585, 'IoU-114': 2.481894708811865, 'IoU-115': 2.5115401047665045, 'IoU-116': 2.5111230780732336, 'IoU-117': 2.4582317850072197, 'IoU-118': 2.516434602366378, 'IoU-119': 2.3471730207021078, 'IoU-120': 2.189628021469149, 'IoU-121': 2.165983762354081, 'IoU-122': 2.2799676944178873, 'IoU-123': 2.3358640959244594, 'IoU-124': 2.0418155398628275, 'IoU-125': 1.9110356469080558, 'IoU-126': 1.9646082380318373, 'IoU-127': 2.0266150377983245, 'IoU-128': 2.0454488582009254, 'IoU-129': 1.945410456718857, 'IoU-130': 1.8994332181252842, 'IoU-131': 1.5061385877990432, 'IoU-132': 1.4361881850943905, 'IoU-133': 1.4534064686552108, 'IoU-134': 1.4479309228308659, 'IoU-135': 1.5727178999825477, 'IoU-136': 1.7155266259497215, 'IoU-137': 1.6148966382555603, 'IoU-138': 1.6552141439852606, 'IoU-139': 1.6150834922959485, 'IoU-140': 2.0212623129623344, 'IoU-141': 1.6221571333522828, 'IoU-142': 1.6187259859445233, 'IoU-143': 1.675607168736941, 'IoU-144': 1.5993424798458906, 'IoU-145': 1.571810942095234, 'IoU-146': 1.6406376244023457, 'IoU-147': 1.4534864282571491, 'IoU-148': 1.662972458509034, 'IoU-149': 1.6409866350014486, 'IoU-150': 1.658352054735453, 'IoU-151': 1.618277010947168, 'IoU-152': 1.3013807889448596, 'IoU-153': 1.5915024034261926, 'IoU-154': 1.4369366627778934, 'IoU-155': 1.3787217662387654, 'IoU-156': 1.2077045683427565, 'IoU-157': 1.2343279822164643, 'IoU-158': 1.0410268482948282, 'IoU-159': 1.0466096611208315, 'IoU-160': 0.9190868798439256, 'IoU-161': 0.8991201929248657, 'IoU-162': 1.2747546233034508, 'IoU-163': 1.3609191858945575, 'IoU-164': 1.9559229739200858, 'IoU-165': 1.1852278529954494, 'IoU-166': 1.1415435669347591, 'IoU-167': 1.0999435683479328, 'IoU-168': 1.0212736934132776, 'IoU-169': 0.8914479606988445, 'IoU-170': 0.8909166881635001, 'IoU-171': 0.4048005438190844, 'IoU-172': 0.11408596210017267, 'IoU-173': 0.13961164449290847, 'IoU-174': 0.29512823854371617, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 6.953105534114333, 'pACC': 15.011267027842784, 'ACC-0': 0.00011631658862986736, 'ACC-1': 43.54023463603235, 'ACC-2': 7.641988977244489, 'ACC-3': 11.987725042807526, 'ACC-4': 7.9491831570647555, 'ACC-5': 6.094914644365992, 'ACC-6': 5.230952836745499, 'ACC-7': 4.816026194981969, 'ACC-8': 6.619885027987923, 'ACC-9': 7.000738820247382, 'ACC-10': 7.15042810065945, 'ACC-11': 9.400764071606085, 'ACC-12': 10.110769494412027, 'ACC-13': 12.177007957975057, 'ACC-14': 12.416963137047354, 'ACC-15': 12.364787497873754, 'ACC-16': 11.699769305463342, 'ACC-17': 10.684731015439862, 'ACC-18': 10.759137296700025, 'ACC-19': 12.565040518402373, 'ACC-20': 11.087006002656462, 'ACC-21': 11.863106100904048, 'ACC-22': 11.716705777756838, 'ACC-23': 13.118428715796465, 'ACC-24': 14.298954478658516, 'ACC-25': 15.829383974617626, 'ACC-26': 16.732573954308016, 'ACC-27': 17.986591657087466, 'ACC-28': 19.374668741226895, 'ACC-29': 19.376442844344243, 'ACC-30': 19.81671091587649, 'ACC-31': 20.31164496764923, 'ACC-32': 19.568349911738057, 'ACC-33': 18.19649544588153, 'ACC-34': 17.510556360332366, 'ACC-35': 17.476120200082658, 'ACC-36': 16.817111769700258, 'ACC-37': 15.948564242963476, 'ACC-38': 14.417300703371975, 'ACC-39': 13.644146972765178, 'ACC-40': 13.514147087933326, 'ACC-41': 12.908740733888335, 'ACC-42': 12.828443183490535, 'ACC-43': 12.732596847567528, 'ACC-44': 12.223416142619584, 'ACC-45': 11.968365256332717, 'ACC-46': 11.576688113810466, 'ACC-47': 11.269014142047379, 'ACC-48': 11.437953604227507, 'ACC-49': 11.19310326384714, 'ACC-50': 10.856315803998497, 'ACC-51': 10.490953905360406, 'ACC-52': 10.443054182249194, 'ACC-53': 10.640347204026442, 'ACC-54': 10.348802635376279, 'ACC-55': 9.914050664236264, 'ACC-56': 9.524577559585786, 'ACC-57': 9.33691760684629, 'ACC-58': 9.233453773300784, 'ACC-59': 9.127223501252534, 'ACC-60': 8.724357583846505, 'ACC-61': 8.244960388264456, 'ACC-62': 8.58443922740818, 'ACC-63': 8.493459914677857, 'ACC-64': 8.410068781143291, 'ACC-65': 8.572862875126058, 'ACC-66': 8.548695826013653, 'ACC-67': 8.05918772984481, 'ACC-68': 7.814121276366919, 'ACC-69': 8.306267985970612, 'ACC-70': 8.436320112307623, 'ACC-71': 8.411677114648104, 'ACC-72': 8.071049234395923, 'ACC-73': 7.912134392365493, 'ACC-74': 7.952180579975332, 'ACC-75': 7.970851956725661, 'ACC-76': 7.807705717162756, 'ACC-77': 8.022572128394863, 'ACC-78': 7.850295478499028, 'ACC-79': 7.775380471641487, 'ACC-80': 8.097504088969972, 'ACC-81': 8.125342791326922, 'ACC-82': 7.989376211327255, 'ACC-83': 8.116745551152082, 'ACC-84': 8.114460078486898, 'ACC-85': 7.787094501481989, 'ACC-86': 7.839334703753793, 'ACC-87': 7.871916013581433, 'ACC-88': 7.635393993750476, 'ACC-89': 7.45699954655104, 'ACC-90': 7.439891846488293, 'ACC-91': 7.150267485775233, 'ACC-92': 6.7403740885578305, 'ACC-93': 6.718561866824713, 'ACC-94': 6.930177155632757, 'ACC-95': 6.60184028029175, 'ACC-96': 6.216538612249493, 'ACC-97': 6.23363567055293, 'ACC-98': 6.215826512100396, 'ACC-99': 6.081230662901388, 'ACC-100': 5.489917260472596, 'ACC-101': 5.353731530629966, 'ACC-102': 5.252628001812415, 'ACC-103': 5.410975724945688, 'ACC-104': 5.5243845453874725, 'ACC-105': 5.503184609266997, 'ACC-106': 5.480188077367546, 'ACC-107': 5.443025512490808, 'ACC-108': 4.89314832107985, 'ACC-109': 5.258610058640676, 'ACC-110': 5.021846223423139, 'ACC-111': 4.787329894157757, 'ACC-112': 4.613426811047294, 'ACC-113': 4.594436670879996, 'ACC-114': 4.8368128682356435, 'ACC-115': 4.878670335122457, 'ACC-116': 4.937304568057086, 'ACC-117': 4.837635123243327, 'ACC-118': 4.957683534051561, 'ACC-119': 4.5406099066838745, 'ACC-120': 4.134206207810188, 'ACC-121': 4.1149113814465395, 'ACC-122': 4.348221951748799, 'ACC-123': 4.503038472849139, 'ACC-124': 4.070052703610514, 'ACC-125': 3.768752804252947, 'ACC-126': 3.9199469029772587, 'ACC-127': 4.076643086095562, 'ACC-128': 4.1373792369961375, 'ACC-129': 3.8800571550849385, 'ACC-130': 3.7576455656364236, 'ACC-131': 3.0572607533795484, 'ACC-132': 2.9000747286478807, 'ACC-133': 2.878197146298149, 'ACC-134': 2.8545626884963378, 'ACC-135': 3.0567670030214926, 'ACC-136': 3.3302855944837866, 'ACC-137': 3.2142003958122967, 'ACC-138': 3.380571490214991, 'ACC-139': 3.4068372859095244, 'ACC-140': 4.326828306721861, 'ACC-141': 3.4531481690311527, 'ACC-142': 3.4224377565911337, 'ACC-143': 3.6009248301437835, 'ACC-144': 3.412364620938628, 'ACC-145': 3.3186788613341087, 'ACC-146': 3.4700600854447012, 'ACC-147': 3.0274386875187442, 'ACC-148': 3.41380788573938, 'ACC-149': 3.470041143165438, 'ACC-150': 3.567717209240272, 'ACC-151': 3.5149309962985584, 'ACC-152': 2.7335583990828782, 'ACC-153': 3.651129555323476, 'ACC-154': 3.2988245405774794, 'ACC-155': 3.3551248203558126, 'ACC-156': 2.953324671798949, 'ACC-157': 3.0342995346608905, 'ACC-158': 2.7460267503680047, 'ACC-159': 2.733159997391455, 'ACC-160': 2.212652128670316, 'ACC-161': 2.203034736868711, 'ACC-162': 3.3543488415684575, 'ACC-163': 3.725195554040482, 'ACC-164': 5.49104354085344, 'ACC-165': 3.339770731226991, 'ACC-166': 3.3264221739093935, 'ACC-167': 2.82385476325723, 'ACC-168': 2.895949082213939, 'ACC-169': 2.0763546841249148, 'ACC-170': 1.9183809645498813, 'ACC-171': 0.7766219882478064, 'ACC-172': 0.17057450827869763, 'ACC-173': 0.17873739901336955, 'ACC-174': 0.3461445978515549, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 02:30:04] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 02:30:04] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 02:30:04] d2.evaluation.testing INFO: copypaste: 3.9360,0.5945,0.3035,3.6330,9.9363,6.9531,15.0113
[01/29 02:30:04] d2.utils.events INFO:  eta: 1 day, 19:27:47  iter: 7999  total_loss: 42.22  loss_mask: 4.198  loss_mask_0: 4.317  loss_mask_1: 4.125  loss_mask_2: 4.243  loss_mask_3: 4.192  loss_mask_4: 4.255  loss_mask_5: 4.224  loss_mask_6: 4.192  loss_mask_7: 4.201  loss_mask_8: 4.198  time: 3.0529  data_time: 0.0480  lr: 8.7917e-05  max_mem: 27632M
[01/29 02:31:04] d2.utils.events INFO:  eta: 1 day, 19:25:47  iter: 8019  total_loss: 39.79  loss_mask: 3.994  loss_mask_0: 4.125  loss_mask_1: 3.983  loss_mask_2: 3.929  loss_mask_3: 3.923  loss_mask_4: 4.007  loss_mask_5: 3.935  loss_mask_6: 3.956  loss_mask_7: 3.992  loss_mask_8: 3.953  time: 3.0527  data_time: 0.0529  lr: 8.7887e-05  max_mem: 27632M
[01/29 02:32:04] d2.utils.events INFO:  eta: 1 day, 19:24:32  iter: 8039  total_loss: 41.38  loss_mask: 4.219  loss_mask_0: 4.212  loss_mask_1: 4.079  loss_mask_2: 4.121  loss_mask_3: 4.114  loss_mask_4: 4.108  loss_mask_5: 4.122  loss_mask_6: 4.181  loss_mask_7: 4.147  loss_mask_8: 4.101  time: 3.0526  data_time: 0.0592  lr: 8.7856e-05  max_mem: 27632M
[01/29 02:33:04] d2.utils.events INFO:  eta: 1 day, 19:22:01  iter: 8059  total_loss: 41.14  loss_mask: 4.091  loss_mask_0: 4.423  loss_mask_1: 4.151  loss_mask_2: 4.079  loss_mask_3: 4.148  loss_mask_4: 4.134  loss_mask_5: 4.098  loss_mask_6: 4.09  loss_mask_7: 4.106  loss_mask_8: 4.081  time: 3.0524  data_time: 0.0619  lr: 8.7826e-05  max_mem: 27632M
[01/29 02:34:03] d2.utils.events INFO:  eta: 1 day, 19:20:02  iter: 8079  total_loss: 35.84  loss_mask: 3.61  loss_mask_0: 3.634  loss_mask_1: 3.529  loss_mask_2: 3.6  loss_mask_3: 3.572  loss_mask_4: 3.602  loss_mask_5: 3.564  loss_mask_6: 3.553  loss_mask_7: 3.607  loss_mask_8: 3.577  time: 3.0523  data_time: 0.0585  lr: 8.7796e-05  max_mem: 27632M
[01/29 02:35:03] d2.utils.events INFO:  eta: 1 day, 19:18:58  iter: 8099  total_loss: 38.49  loss_mask: 3.816  loss_mask_0: 3.858  loss_mask_1: 3.794  loss_mask_2: 3.854  loss_mask_3: 3.924  loss_mask_4: 3.866  loss_mask_5: 3.817  loss_mask_6: 3.87  loss_mask_7: 3.768  loss_mask_8: 3.89  time: 3.0521  data_time: 0.0658  lr: 8.7765e-05  max_mem: 27632M
[01/29 02:36:03] d2.utils.events INFO:  eta: 1 day, 19:17:14  iter: 8119  total_loss: 41.33  loss_mask: 4.116  loss_mask_0: 4.43  loss_mask_1: 4.019  loss_mask_2: 4.061  loss_mask_3: 4.108  loss_mask_4: 4.086  loss_mask_5: 4.068  loss_mask_6: 4.117  loss_mask_7: 4.12  loss_mask_8: 4.174  time: 3.0519  data_time: 0.0598  lr: 8.7735e-05  max_mem: 27632M
[01/29 02:37:03] d2.utils.events INFO:  eta: 1 day, 19:16:14  iter: 8139  total_loss: 39.67  loss_mask: 4.186  loss_mask_0: 3.918  loss_mask_1: 3.9  loss_mask_2: 3.9  loss_mask_3: 3.966  loss_mask_4: 4.031  loss_mask_5: 4.013  loss_mask_6: 3.975  loss_mask_7: 4.11  loss_mask_8: 4.044  time: 3.0518  data_time: 0.0605  lr: 8.7704e-05  max_mem: 27632M
[01/29 02:38:03] d2.utils.events INFO:  eta: 1 day, 19:14:29  iter: 8159  total_loss: 40.67  loss_mask: 4.105  loss_mask_0: 4.029  loss_mask_1: 3.985  loss_mask_2: 4.007  loss_mask_3: 3.961  loss_mask_4: 3.924  loss_mask_5: 4.097  loss_mask_6: 4.029  loss_mask_7: 4.04  loss_mask_8: 4.17  time: 3.0516  data_time: 0.0545  lr: 8.7674e-05  max_mem: 27632M
[01/29 02:39:03] d2.utils.events INFO:  eta: 1 day, 19:13:16  iter: 8179  total_loss: 44.84  loss_mask: 4.426  loss_mask_0: 4.684  loss_mask_1: 4.448  loss_mask_2: 4.486  loss_mask_3: 4.357  loss_mask_4: 4.429  loss_mask_5: 4.427  loss_mask_6: 4.441  loss_mask_7: 4.403  loss_mask_8: 4.337  time: 3.0516  data_time: 0.0551  lr: 8.7643e-05  max_mem: 27632M
[01/29 02:40:03] d2.utils.events INFO:  eta: 1 day, 19:11:14  iter: 8199  total_loss: 40.64  loss_mask: 3.987  loss_mask_0: 4.19  loss_mask_1: 3.948  loss_mask_2: 3.968  loss_mask_3: 4.156  loss_mask_4: 4.047  loss_mask_5: 4.039  loss_mask_6: 4.14  loss_mask_7: 3.993  loss_mask_8: 4.154  time: 3.0514  data_time: 0.0610  lr: 8.7613e-05  max_mem: 27632M
[01/29 02:41:03] d2.utils.events INFO:  eta: 1 day, 19:10:14  iter: 8219  total_loss: 44.76  loss_mask: 4.462  loss_mask_0: 4.558  loss_mask_1: 4.4  loss_mask_2: 4.397  loss_mask_3: 4.384  loss_mask_4: 4.55  loss_mask_5: 4.439  loss_mask_6: 4.392  loss_mask_7: 4.473  loss_mask_8: 4.407  time: 3.0513  data_time: 0.0523  lr: 8.7582e-05  max_mem: 27632M
[01/29 02:42:03] d2.utils.events INFO:  eta: 1 day, 19:09:17  iter: 8239  total_loss: 42.32  loss_mask: 4.209  loss_mask_0: 4.346  loss_mask_1: 4.19  loss_mask_2: 4.223  loss_mask_3: 4.2  loss_mask_4: 4.188  loss_mask_5: 4.215  loss_mask_6: 4.214  loss_mask_7: 4.205  loss_mask_8: 4.172  time: 3.0511  data_time: 0.0595  lr: 8.7552e-05  max_mem: 27632M
[01/29 02:43:03] d2.utils.events INFO:  eta: 1 day, 19:08:14  iter: 8259  total_loss: 45.05  loss_mask: 4.501  loss_mask_0: 4.682  loss_mask_1: 4.421  loss_mask_2: 4.486  loss_mask_3: 4.504  loss_mask_4: 4.535  loss_mask_5: 4.524  loss_mask_6: 4.485  loss_mask_7: 4.51  loss_mask_8: 4.432  time: 3.0510  data_time: 0.0637  lr: 8.7522e-05  max_mem: 27632M
[01/29 02:44:02] d2.utils.events INFO:  eta: 1 day, 19:06:18  iter: 8279  total_loss: 41.94  loss_mask: 4.109  loss_mask_0: 4.338  loss_mask_1: 4.08  loss_mask_2: 4.08  loss_mask_3: 4.062  loss_mask_4: 4.111  loss_mask_5: 4.139  loss_mask_6: 4.092  loss_mask_7: 4.459  loss_mask_8: 4.073  time: 3.0508  data_time: 0.0581  lr: 8.7491e-05  max_mem: 27632M
[01/29 02:45:02] d2.utils.events INFO:  eta: 1 day, 19:05:42  iter: 8299  total_loss: 38.86  loss_mask: 3.836  loss_mask_0: 4.156  loss_mask_1: 3.894  loss_mask_2: 3.855  loss_mask_3: 4.122  loss_mask_4: 3.859  loss_mask_5: 3.927  loss_mask_6: 3.891  loss_mask_7: 3.963  loss_mask_8: 3.881  time: 3.0507  data_time: 0.0478  lr: 8.7461e-05  max_mem: 27632M
[01/29 02:46:02] d2.utils.events INFO:  eta: 1 day, 19:04:32  iter: 8319  total_loss: 39.63  loss_mask: 3.923  loss_mask_0: 4.086  loss_mask_1: 3.889  loss_mask_2: 3.898  loss_mask_3: 3.941  loss_mask_4: 3.882  loss_mask_5: 3.825  loss_mask_6: 4.015  loss_mask_7: 4.079  loss_mask_8: 3.862  time: 3.0506  data_time: 0.0589  lr: 8.743e-05  max_mem: 27632M
[01/29 02:47:02] d2.utils.events INFO:  eta: 1 day, 19:03:07  iter: 8339  total_loss: 41.73  loss_mask: 4.186  loss_mask_0: 4.183  loss_mask_1: 4.056  loss_mask_2: 4.117  loss_mask_3: 4.12  loss_mask_4: 4.112  loss_mask_5: 4.176  loss_mask_6: 4.133  loss_mask_7: 4.217  loss_mask_8: 4.168  time: 3.0504  data_time: 0.0461  lr: 8.74e-05  max_mem: 27632M
[01/29 02:48:02] d2.utils.events INFO:  eta: 1 day, 19:01:54  iter: 8359  total_loss: 38.85  loss_mask: 3.885  loss_mask_0: 4.056  loss_mask_1: 3.819  loss_mask_2: 3.884  loss_mask_3: 3.886  loss_mask_4: 3.884  loss_mask_5: 3.851  loss_mask_6: 3.863  loss_mask_7: 4.091  loss_mask_8: 3.867  time: 3.0503  data_time: 0.0549  lr: 8.7369e-05  max_mem: 27632M
[01/29 02:49:02] d2.utils.events INFO:  eta: 1 day, 19:00:48  iter: 8379  total_loss: 41.57  loss_mask: 4.16  loss_mask_0: 4.288  loss_mask_1: 4.097  loss_mask_2: 4.111  loss_mask_3: 4.165  loss_mask_4: 4.172  loss_mask_5: 4.107  loss_mask_6: 4.171  loss_mask_7: 4.117  loss_mask_8: 4.091  time: 3.0501  data_time: 0.0569  lr: 8.7339e-05  max_mem: 27632M
[01/29 02:50:02] d2.utils.events INFO:  eta: 1 day, 18:59:39  iter: 8399  total_loss: 38.73  loss_mask: 3.862  loss_mask_0: 3.962  loss_mask_1: 3.835  loss_mask_2: 3.862  loss_mask_3: 3.824  loss_mask_4: 3.879  loss_mask_5: 3.853  loss_mask_6: 3.872  loss_mask_7: 3.956  loss_mask_8: 3.821  time: 3.0500  data_time: 0.0576  lr: 8.7308e-05  max_mem: 27632M
[01/29 02:51:01] d2.utils.events INFO:  eta: 1 day, 18:58:29  iter: 8419  total_loss: 42.48  loss_mask: 4.198  loss_mask_0: 4.512  loss_mask_1: 4.06  loss_mask_2: 4.206  loss_mask_3: 4.231  loss_mask_4: 4.251  loss_mask_5: 4.135  loss_mask_6: 4.193  loss_mask_7: 4.323  loss_mask_8: 4.089  time: 3.0498  data_time: 0.0570  lr: 8.7278e-05  max_mem: 27632M
[01/29 02:52:01] d2.utils.events INFO:  eta: 1 day, 18:56:23  iter: 8439  total_loss: 44.9  loss_mask: 4.646  loss_mask_0: 4.766  loss_mask_1: 4.453  loss_mask_2: 4.522  loss_mask_3: 4.491  loss_mask_4: 4.349  loss_mask_5: 4.505  loss_mask_6: 4.341  loss_mask_7: 4.521  loss_mask_8: 4.376  time: 3.0497  data_time: 0.0544  lr: 8.7248e-05  max_mem: 27632M
[01/29 02:53:01] d2.utils.events INFO:  eta: 1 day, 18:54:28  iter: 8459  total_loss: 41.75  loss_mask: 4.106  loss_mask_0: 4.135  loss_mask_1: 4.212  loss_mask_2: 4.222  loss_mask_3: 4.248  loss_mask_4: 4.18  loss_mask_5: 4.024  loss_mask_6: 4.184  loss_mask_7: 4.286  loss_mask_8: 4.079  time: 3.0495  data_time: 0.0536  lr: 8.7217e-05  max_mem: 27632M
[01/29 02:54:00] d2.utils.events INFO:  eta: 1 day, 18:52:33  iter: 8479  total_loss: 39.08  loss_mask: 3.85  loss_mask_0: 4.047  loss_mask_1: 3.82  loss_mask_2: 3.867  loss_mask_3: 4.175  loss_mask_4: 3.829  loss_mask_5: 3.804  loss_mask_6: 3.828  loss_mask_7: 3.839  loss_mask_8: 3.831  time: 3.0494  data_time: 0.0539  lr: 8.7187e-05  max_mem: 27632M
[01/29 02:55:01] d2.utils.events INFO:  eta: 1 day, 18:52:00  iter: 8499  total_loss: 44.42  loss_mask: 4.288  loss_mask_0: 4.166  loss_mask_1: 4.185  loss_mask_2: 4.444  loss_mask_3: 5.015  loss_mask_4: 4.321  loss_mask_5: 4.279  loss_mask_6: 4.292  loss_mask_7: 4.237  loss_mask_8: 4.197  time: 3.0493  data_time: 0.0599  lr: 8.7156e-05  max_mem: 27632M
[01/29 02:56:02] d2.utils.events INFO:  eta: 1 day, 18:53:33  iter: 8519  total_loss: 44.19  loss_mask: 4.129  loss_mask_0: 4.705  loss_mask_1: 4.221  loss_mask_2: 4.199  loss_mask_3: 5.19  loss_mask_4: 4.322  loss_mask_5: 4.119  loss_mask_6: 4.076  loss_mask_7: 4.168  loss_mask_8: 4.111  time: 3.0493  data_time: 0.0624  lr: 8.7126e-05  max_mem: 27632M
[01/29 02:57:03] d2.utils.events INFO:  eta: 1 day, 18:52:36  iter: 8539  total_loss: 40.24  loss_mask: 3.808  loss_mask_0: 5.196  loss_mask_1: 3.851  loss_mask_2: 4.066  loss_mask_3: 4.229  loss_mask_4: 3.82  loss_mask_5: 3.823  loss_mask_6: 3.837  loss_mask_7: 3.835  loss_mask_8: 3.793  time: 3.0492  data_time: 0.0557  lr: 8.7095e-05  max_mem: 27632M
[01/29 02:58:03] d2.utils.events INFO:  eta: 1 day, 18:51:44  iter: 8559  total_loss: 42.35  loss_mask: 4.188  loss_mask_0: 4.499  loss_mask_1: 4.132  loss_mask_2: 4.418  loss_mask_3: 4.394  loss_mask_4: 4.142  loss_mask_5: 4.245  loss_mask_6: 4.187  loss_mask_7: 4.157  loss_mask_8: 4.172  time: 3.0491  data_time: 0.0640  lr: 8.7065e-05  max_mem: 27632M
[01/29 02:59:03] d2.utils.events INFO:  eta: 1 day, 18:50:50  iter: 8579  total_loss: 39.33  loss_mask: 3.892  loss_mask_0: 4.128  loss_mask_1: 3.884  loss_mask_2: 3.904  loss_mask_3: 4.057  loss_mask_4: 3.881  loss_mask_5: 3.898  loss_mask_6: 3.854  loss_mask_7: 3.909  loss_mask_8: 3.838  time: 3.0491  data_time: 0.0551  lr: 8.7034e-05  max_mem: 27632M
[01/29 03:00:03] d2.utils.events INFO:  eta: 1 day, 18:49:55  iter: 8599  total_loss: 37.1  loss_mask: 3.713  loss_mask_0: 3.87  loss_mask_1: 3.698  loss_mask_2: 3.695  loss_mask_3: 3.714  loss_mask_4: 3.705  loss_mask_5: 3.644  loss_mask_6: 3.696  loss_mask_7: 3.695  loss_mask_8: 3.697  time: 3.0490  data_time: 0.0636  lr: 8.7004e-05  max_mem: 27632M
[01/29 03:01:04] d2.utils.events INFO:  eta: 1 day, 18:50:17  iter: 8619  total_loss: 39.83  loss_mask: 3.971  loss_mask_0: 4.16  loss_mask_1: 3.918  loss_mask_2: 3.958  loss_mask_3: 3.984  loss_mask_4: 3.966  loss_mask_5: 3.952  loss_mask_6: 3.971  loss_mask_7: 3.956  loss_mask_8: 3.97  time: 3.0490  data_time: 0.0537  lr: 8.6973e-05  max_mem: 27632M
[01/29 03:02:05] d2.utils.events INFO:  eta: 1 day, 18:49:17  iter: 8639  total_loss: 40.36  loss_mask: 3.976  loss_mask_0: 4.214  loss_mask_1: 3.947  loss_mask_2: 3.996  loss_mask_3: 4.209  loss_mask_4: 4.016  loss_mask_5: 3.993  loss_mask_6: 4.012  loss_mask_7: 4.014  loss_mask_8: 3.981  time: 3.0489  data_time: 0.0542  lr: 8.6943e-05  max_mem: 27632M
[01/29 03:03:05] d2.utils.events INFO:  eta: 1 day, 18:49:53  iter: 8659  total_loss: 39.86  loss_mask: 3.986  loss_mask_0: 4.023  loss_mask_1: 3.928  loss_mask_2: 4.056  loss_mask_3: 4.191  loss_mask_4: 4.023  loss_mask_5: 3.908  loss_mask_6: 3.966  loss_mask_7: 3.974  loss_mask_8: 3.919  time: 3.0488  data_time: 0.0642  lr: 8.6912e-05  max_mem: 27632M
[01/29 03:04:05] d2.utils.events INFO:  eta: 1 day, 18:49:14  iter: 8679  total_loss: 37.3  loss_mask: 3.672  loss_mask_0: 3.87  loss_mask_1: 3.652  loss_mask_2: 3.73  loss_mask_3: 3.778  loss_mask_4: 3.71  loss_mask_5: 3.742  loss_mask_6: 3.796  loss_mask_7: 3.708  loss_mask_8: 3.629  time: 3.0487  data_time: 0.0567  lr: 8.6882e-05  max_mem: 27632M
[01/29 03:05:06] d2.utils.events INFO:  eta: 1 day, 18:47:53  iter: 8699  total_loss: 40.25  loss_mask: 4.067  loss_mask_0: 4.049  loss_mask_1: 3.932  loss_mask_2: 3.992  loss_mask_3: 4.024  loss_mask_4: 4.047  loss_mask_5: 4  loss_mask_6: 4.063  loss_mask_7: 4.058  loss_mask_8: 4.051  time: 3.0487  data_time: 0.0645  lr: 8.6851e-05  max_mem: 27632M
[01/29 03:06:07] d2.utils.events INFO:  eta: 1 day, 18:47:50  iter: 8719  total_loss: 39.33  loss_mask: 3.935  loss_mask_0: 4.077  loss_mask_1: 3.87  loss_mask_2: 3.964  loss_mask_3: 3.978  loss_mask_4: 4.003  loss_mask_5: 3.938  loss_mask_6: 4.02  loss_mask_7: 3.976  loss_mask_8: 3.9  time: 3.0486  data_time: 0.0696  lr: 8.6821e-05  max_mem: 27632M
[01/29 03:07:07] d2.utils.events INFO:  eta: 1 day, 18:46:57  iter: 8739  total_loss: 40.22  loss_mask: 4.016  loss_mask_0: 4.046  loss_mask_1: 3.946  loss_mask_2: 3.962  loss_mask_3: 4.057  loss_mask_4: 4.042  loss_mask_5: 4.036  loss_mask_6: 4.051  loss_mask_7: 4.056  loss_mask_8: 4.012  time: 3.0486  data_time: 0.0610  lr: 8.6791e-05  max_mem: 27632M
[01/29 03:08:07] d2.utils.events INFO:  eta: 1 day, 18:45:14  iter: 8759  total_loss: 40.32  loss_mask: 3.971  loss_mask_0: 4.19  loss_mask_1: 4.052  loss_mask_2: 4.058  loss_mask_3: 4.042  loss_mask_4: 4.021  loss_mask_5: 4  loss_mask_6: 4.014  loss_mask_7: 4.005  loss_mask_8: 3.965  time: 3.0485  data_time: 0.0518  lr: 8.676e-05  max_mem: 27632M
[01/29 03:09:08] d2.utils.events INFO:  eta: 1 day, 18:43:57  iter: 8779  total_loss: 41.36  loss_mask: 4.13  loss_mask_0: 4.313  loss_mask_1: 4.063  loss_mask_2: 4.093  loss_mask_3: 4.114  loss_mask_4: 4.113  loss_mask_5: 4.117  loss_mask_6: 4.121  loss_mask_7: 4.069  loss_mask_8: 4.124  time: 3.0484  data_time: 0.0557  lr: 8.673e-05  max_mem: 27632M
[01/29 03:10:08] d2.utils.events INFO:  eta: 1 day, 18:41:51  iter: 8799  total_loss: 42.28  loss_mask: 4.228  loss_mask_0: 4.302  loss_mask_1: 4.213  loss_mask_2: 4.222  loss_mask_3: 4.314  loss_mask_4: 4.24  loss_mask_5: 4.172  loss_mask_6: 4.216  loss_mask_7: 4.207  loss_mask_8: 4.2  time: 3.0484  data_time: 0.0649  lr: 8.6699e-05  max_mem: 27632M
[01/29 03:11:08] d2.utils.events INFO:  eta: 1 day, 18:40:23  iter: 8819  total_loss: 34.54  loss_mask: 3.526  loss_mask_0: 3.521  loss_mask_1: 3.312  loss_mask_2: 3.513  loss_mask_3: 3.429  loss_mask_4: 3.446  loss_mask_5: 3.357  loss_mask_6: 3.367  loss_mask_7: 3.536  loss_mask_8: 3.532  time: 3.0482  data_time: 0.0600  lr: 8.6669e-05  max_mem: 27632M
[01/29 03:12:08] d2.utils.events INFO:  eta: 1 day, 18:38:57  iter: 8839  total_loss: 40.17  loss_mask: 4.054  loss_mask_0: 4.098  loss_mask_1: 3.925  loss_mask_2: 4.022  loss_mask_3: 4.08  loss_mask_4: 3.95  loss_mask_5: 3.945  loss_mask_6: 3.993  loss_mask_7: 3.98  loss_mask_8: 4.068  time: 3.0481  data_time: 0.0620  lr: 8.6638e-05  max_mem: 27632M
[01/29 03:13:08] d2.utils.events INFO:  eta: 1 day, 18:37:11  iter: 8859  total_loss: 41.94  loss_mask: 4.159  loss_mask_0: 4.306  loss_mask_1: 4.058  loss_mask_2: 4.134  loss_mask_3: 4.132  loss_mask_4: 4.095  loss_mask_5: 4.135  loss_mask_6: 4.131  loss_mask_7: 4.149  loss_mask_8: 4.25  time: 3.0480  data_time: 0.0556  lr: 8.6608e-05  max_mem: 27632M
[01/29 03:14:09] d2.utils.events INFO:  eta: 1 day, 18:36:14  iter: 8879  total_loss: 37.76  loss_mask: 3.783  loss_mask_0: 4.282  loss_mask_1: 3.702  loss_mask_2: 3.675  loss_mask_3: 3.779  loss_mask_4: 3.755  loss_mask_5: 3.806  loss_mask_6: 3.749  loss_mask_7: 3.83  loss_mask_8: 3.934  time: 3.0479  data_time: 0.0579  lr: 8.6577e-05  max_mem: 27632M
[01/29 03:15:09] d2.utils.events INFO:  eta: 1 day, 18:35:35  iter: 8899  total_loss: 34.45  loss_mask: 3.453  loss_mask_0: 3.506  loss_mask_1: 3.385  loss_mask_2: 3.445  loss_mask_3: 3.397  loss_mask_4: 3.438  loss_mask_5: 3.422  loss_mask_6: 3.432  loss_mask_7: 3.423  loss_mask_8: 3.45  time: 3.0479  data_time: 0.0716  lr: 8.6547e-05  max_mem: 27632M
[01/29 03:16:10] d2.utils.events INFO:  eta: 1 day, 18:34:14  iter: 8919  total_loss: 41.11  loss_mask: 4.04  loss_mask_0: 4.112  loss_mask_1: 4.038  loss_mask_2: 4.099  loss_mask_3: 4.151  loss_mask_4: 4.115  loss_mask_5: 4.019  loss_mask_6: 4.075  loss_mask_7: 4.216  loss_mask_8: 4.238  time: 3.0478  data_time: 0.0606  lr: 8.6516e-05  max_mem: 27632M
[01/29 03:17:10] d2.utils.events INFO:  eta: 1 day, 18:33:23  iter: 8939  total_loss: 46.92  loss_mask: 4.633  loss_mask_0: 4.982  loss_mask_1: 4.593  loss_mask_2: 4.511  loss_mask_3: 4.596  loss_mask_4: 4.527  loss_mask_5: 4.577  loss_mask_6: 4.655  loss_mask_7: 4.687  loss_mask_8: 4.763  time: 3.0477  data_time: 0.0551  lr: 8.6486e-05  max_mem: 27632M
[01/29 03:18:11] d2.utils.events INFO:  eta: 1 day, 18:32:23  iter: 8959  total_loss: 40.15  loss_mask: 4.025  loss_mask_0: 4.124  loss_mask_1: 3.961  loss_mask_2: 4.01  loss_mask_3: 4.018  loss_mask_4: 4.01  loss_mask_5: 3.958  loss_mask_6: 4.025  loss_mask_7: 3.998  loss_mask_8: 4.02  time: 3.0477  data_time: 0.0493  lr: 8.6455e-05  max_mem: 27632M
[01/29 03:19:11] d2.utils.events INFO:  eta: 1 day, 18:31:57  iter: 8979  total_loss: 38.25  loss_mask: 4.026  loss_mask_0: 3.875  loss_mask_1: 3.857  loss_mask_2: 4.002  loss_mask_3: 3.906  loss_mask_4: 3.803  loss_mask_5: 3.791  loss_mask_6: 3.804  loss_mask_7: 3.815  loss_mask_8: 3.84  time: 3.0477  data_time: 0.0609  lr: 8.6425e-05  max_mem: 27632M
[01/29 03:20:11] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 03:20:12] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 03:20:12] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 03:34:11] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.050498480294927, 'error_1pix': 0.6201823563958975, 'error_3pix': 0.31181052806636356, 'mIoU': 3.2913411142838647, 'fwIoU': 10.104299307462302, 'IoU-0': 1.0507318115906731e-05, 'IoU-1': 51.40356701505957, 'IoU-2': 2.196204673136008, 'IoU-3': 1.6599026523719405, 'IoU-4': 1.2970881465175927, 'IoU-5': 1.024598683450745, 'IoU-6': 0.8320906845627449, 'IoU-7': 0.6814135372846544, 'IoU-8': 0.6065772507828531, 'IoU-9': 0.7410505870581201, 'IoU-10': 0.9916001415540544, 'IoU-11': 1.0458462033688307, 'IoU-12': 2.1545899596436966, 'IoU-13': 3.393310981590772, 'IoU-14': 4.359857176670143, 'IoU-15': 4.30956374053003, 'IoU-16': 4.070200078248785, 'IoU-17': 3.803058479929961, 'IoU-18': 4.303023763610709, 'IoU-19': 5.2273123225314935, 'IoU-20': 4.696037366756861, 'IoU-21': 5.015187839647161, 'IoU-22': 4.74146041812967, 'IoU-23': 4.633668723092103, 'IoU-24': 4.725048529724236, 'IoU-25': 4.921342482781058, 'IoU-26': 4.9723834854556594, 'IoU-27': 5.421126546738267, 'IoU-28': 5.582087072453667, 'IoU-29': 6.1470286288944145, 'IoU-30': 6.35098185190857, 'IoU-31': 6.849383086276973, 'IoU-32': 6.95515827199568, 'IoU-33': 7.401640023518606, 'IoU-34': 7.212926430148864, 'IoU-35': 7.980547055912238, 'IoU-36': 8.518276328172806, 'IoU-37': 8.386938436706217, 'IoU-38': 8.975284406899464, 'IoU-39': 8.981868169365145, 'IoU-40': 9.200903515444018, 'IoU-41': 8.9509625568617, 'IoU-42': 8.533245716395585, 'IoU-43': 8.39061962399329, 'IoU-44': 8.683115631417406, 'IoU-45': 8.437684795486021, 'IoU-46': 7.988917423104787, 'IoU-47': 8.00622991144099, 'IoU-48': 7.940370904197318, 'IoU-49': 7.7632275038073, 'IoU-50': 7.407800833641934, 'IoU-51': 7.334926652797555, 'IoU-52': 7.2356625780599995, 'IoU-53': 7.160021238530237, 'IoU-54': 7.4183628343339985, 'IoU-55': 6.889752788799278, 'IoU-56': 6.761874422268482, 'IoU-57': 6.465833044305139, 'IoU-58': 6.440616880213994, 'IoU-59': 6.121990482969845, 'IoU-60': 6.091837330131587, 'IoU-61': 5.777320428761326, 'IoU-62': 5.758433168352383, 'IoU-63': 5.632716247864677, 'IoU-64': 5.64866256594681, 'IoU-65': 5.341889509987832, 'IoU-66': 5.407949526708568, 'IoU-67': 5.249579145305781, 'IoU-68': 5.192935582903122, 'IoU-69': 5.1262369151457925, 'IoU-70': 5.027948604829621, 'IoU-71': 4.931173810433811, 'IoU-72': 4.856279685740551, 'IoU-73': 4.766793315837868, 'IoU-74': 4.694030477481744, 'IoU-75': 4.49841979487254, 'IoU-76': 4.513346333929741, 'IoU-77': 4.46817525238007, 'IoU-78': 4.37557520977445, 'IoU-79': 4.159521828935114, 'IoU-80': 4.299958368608254, 'IoU-81': 4.2382570108054285, 'IoU-82': 4.161802425548525, 'IoU-83': 4.2313422454437335, 'IoU-84': 4.254039723294786, 'IoU-85': 4.208629576261951, 'IoU-86': 4.125019189772585, 'IoU-87': 4.049533694129174, 'IoU-88': 3.9010884235436305, 'IoU-89': 3.894323047786169, 'IoU-90': 3.7420912481244772, 'IoU-91': 3.55623462581584, 'IoU-92': 3.4288913402693537, 'IoU-93': 3.4665472507438873, 'IoU-94': 3.514124440883954, 'IoU-95': 3.434327062878816, 'IoU-96': 3.2682871236565414, 'IoU-97': 3.208274584657093, 'IoU-98': 3.1780980205731524, 'IoU-99': 2.9326974725314074, 'IoU-100': 2.811319503603717, 'IoU-101': 2.3954799785104437, 'IoU-102': 2.380336328711492, 'IoU-103': 2.4042188259752835, 'IoU-104': 2.2387309820715027, 'IoU-105': 2.12778844764388, 'IoU-106': 2.090739513157692, 'IoU-107': 2.198564553247038, 'IoU-108': 2.131702972248156, 'IoU-109': 1.919103847030216, 'IoU-110': 1.9178070453299043, 'IoU-111': 1.8057833427120806, 'IoU-112': 1.8892886632156412, 'IoU-113': 1.6324025494082093, 'IoU-114': 1.4645420963233717, 'IoU-115': 1.5727620773962705, 'IoU-116': 1.6488300316806284, 'IoU-117': 1.6211303726447197, 'IoU-118': 1.6337614242690979, 'IoU-119': 1.5538960580559888, 'IoU-120': 1.7022756844199547, 'IoU-121': 1.648542163400329, 'IoU-122': 1.6758625238326714, 'IoU-123': 1.6380198539527584, 'IoU-124': 1.6125120282950898, 'IoU-125': 1.161717001797496, 'IoU-126': 1.3322231473771857, 'IoU-127': 1.2911435803255693, 'IoU-128': 1.1880908682091331, 'IoU-129': 1.2132266149431654, 'IoU-130': 1.4190656121293979, 'IoU-131': 1.1994824674737143, 'IoU-132': 1.2004923014458184, 'IoU-133': 1.2480976902907623, 'IoU-134': 1.2808721210261855, 'IoU-135': 1.178953362755525, 'IoU-136': 1.123065983178594, 'IoU-137': 1.0848301858738574, 'IoU-138': 0.9004614838730324, 'IoU-139': 0.9353857128526367, 'IoU-140': 0.787700403660107, 'IoU-141': 0.728859052069343, 'IoU-142': 0.8686642983331232, 'IoU-143': 0.8346620627699591, 'IoU-144': 0.6860552565322733, 'IoU-145': 0.5882320145574129, 'IoU-146': 0.7445797059814327, 'IoU-147': 0.921520307886756, 'IoU-148': 1.0194855278655035, 'IoU-149': 0.856437818600162, 'IoU-150': 0.6474364028325226, 'IoU-151': 0.6762164028872293, 'IoU-152': 0.7751713515281935, 'IoU-153': 0.6839811309862524, 'IoU-154': 0.5233159208262428, 'IoU-155': 0.44231530299610416, 'IoU-156': 0.6409155564293488, 'IoU-157': 0.6809007427747207, 'IoU-158': 0.9587319018582204, 'IoU-159': 0.4976555333628248, 'IoU-160': 0.6873578047173156, 'IoU-161': 0.36345318214478656, 'IoU-162': 0.24095190323360388, 'IoU-163': 0.133300587535186, 'IoU-164': 0.21307206950332475, 'IoU-165': 0.24102796331937054, 'IoU-166': 0.4073462486914549, 'IoU-167': 0.41737332706537467, 'IoU-168': 0.17585358663006026, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 6.372857210170259, 'pACC': 14.806679723917282, 'ACC-0': 3.877219620995579e-05, 'ACC-1': 52.09383614543825, 'ACC-2': 8.354078656205994, 'ACC-3': 12.4605142449122, 'ACC-4': 7.424333243489327, 'ACC-5': 5.25059063226454, 'ACC-6': 3.953352407659394, 'ACC-7': 3.1622491804952397, 'ACC-8': 1.257874205916939, 'ACC-9': 0.9559568000187794, 'ACC-10': 1.1134357649517288, 'ACC-11': 1.1305940613855108, 'ACC-12': 2.5591069620224, 'ACC-13': 5.043494565465381, 'ACC-14': 7.81161932667878, 'ACC-15': 8.670566100448386, 'ACC-16': 8.498641290135222, 'ACC-17': 8.355623895883094, 'ACC-18': 8.767763493972542, 'ACC-19': 10.427306190366737, 'ACC-20': 9.264454730786968, 'ACC-21': 9.529701651555712, 'ACC-22': 8.727198899949595, 'ACC-23': 9.065423318137112, 'ACC-24': 9.431393802603504, 'ACC-25': 9.862611568768715, 'ACC-26': 9.945747708064555, 'ACC-27': 10.429418844930298, 'ACC-28': 10.95677433070922, 'ACC-29': 11.83889253213312, 'ACC-30': 12.43803089790578, 'ACC-31': 13.1374929999649, 'ACC-32': 13.691710155215098, 'ACC-33': 15.024901762503362, 'ACC-34': 14.644495027124357, 'ACC-35': 15.65986890843688, 'ACC-36': 16.5091991784467, 'ACC-37': 16.702365012953678, 'ACC-38': 17.795437349548887, 'ACC-39': 17.846653433207248, 'ACC-40': 17.891824249429494, 'ACC-41': 17.977070133227354, 'ACC-42': 17.06232972429348, 'ACC-43': 16.43328145188352, 'ACC-44': 16.455613790445028, 'ACC-45': 16.09965002529443, 'ACC-46': 15.525556531776683, 'ACC-47': 15.366536166482797, 'ACC-48': 15.176476188504347, 'ACC-49': 14.798314816843641, 'ACC-50': 14.266536222286415, 'ACC-51': 14.471901218359987, 'ACC-52': 14.309254191865243, 'ACC-53': 14.183913543998958, 'ACC-54': 14.520572408316617, 'ACC-55': 13.574542740278892, 'ACC-56': 13.502314161119934, 'ACC-57': 12.601456403209907, 'ACC-58': 12.55886583065204, 'ACC-59': 11.972140650018739, 'ACC-60': 11.965621504060381, 'ACC-61': 11.421419919120474, 'ACC-62': 11.312400851581081, 'ACC-63': 11.107548028751586, 'ACC-64': 11.066450528422632, 'ACC-65': 10.467944054242398, 'ACC-66': 10.596247553690038, 'ACC-67': 10.387435372596435, 'ACC-68': 10.305318684514525, 'ACC-69': 9.985839482285796, 'ACC-70': 9.754744331985263, 'ACC-71': 9.764524862630775, 'ACC-72': 9.709266896343435, 'ACC-73': 9.413038895167396, 'ACC-74': 9.120368459068873, 'ACC-75': 8.78355077156264, 'ACC-76': 8.688333992075606, 'ACC-77': 8.707827084414495, 'ACC-78': 8.631623642095555, 'ACC-79': 8.274003069457759, 'ACC-80': 8.508949953838401, 'ACC-81': 8.385958380839362, 'ACC-82': 8.25182060531653, 'ACC-83': 8.304122868591362, 'ACC-84': 8.36937634094449, 'ACC-85': 8.353249797595026, 'ACC-86': 8.195177598309487, 'ACC-87': 8.04221000715482, 'ACC-88': 7.741873695868734, 'ACC-89': 7.75035116988935, 'ACC-90': 7.399091981549915, 'ACC-91': 7.117350555913739, 'ACC-92': 6.915165080934685, 'ACC-93': 6.96458748501564, 'ACC-94': 7.100609170151635, 'ACC-95': 6.9304212875666185, 'ACC-96': 6.57148390747575, 'ACC-97': 6.395992760616687, 'ACC-98': 6.375506639136813, 'ACC-99': 5.938200734800105, 'ACC-100': 5.629945172797728, 'ACC-101': 4.795674130931563, 'ACC-102': 4.818667874943363, 'ACC-103': 4.896854633040522, 'ACC-104': 4.564275349843831, 'ACC-105': 4.396137350784091, 'ACC-106': 4.267534312634177, 'ACC-107': 4.428405763046704, 'ACC-108': 4.227168324799699, 'ACC-109': 3.8418218440416, 'ACC-110': 3.9084731912167068, 'ACC-111': 3.5761910268668746, 'ACC-112': 3.7737089258270893, 'ACC-113': 3.3415692659269935, 'ACC-114': 2.9389244959087053, 'ACC-115': 3.1275089080330156, 'ACC-116': 3.300235343685102, 'ACC-117': 3.219732433677, 'ACC-118': 3.347109225060954, 'ACC-119': 3.200463899993867, 'ACC-120': 3.4864904753370793, 'ACC-121': 3.355881809225632, 'ACC-122': 3.3682904507156537, 'ACC-123': 3.35041220204907, 'ACC-124': 3.368279064365743, 'ACC-125': 2.4112347353548054, 'ACC-126': 2.7532126886401516, 'ACC-127': 2.70105785494678, 'ACC-128': 2.556925249819793, 'ACC-129': 2.625130290124181, 'ACC-130': 3.078928292268918, 'ACC-131': 2.6166451675502236, 'ACC-132': 2.536484670574003, 'ACC-133': 2.6986330264617227, 'ACC-134': 2.777354588539423, 'ACC-135': 2.5080525625676984, 'ACC-136': 2.444281704248975, 'ACC-137': 2.4502048134011387, 'ACC-138': 2.031087392441049, 'ACC-139': 2.064024437734525, 'ACC-140': 1.7723588548370264, 'ACC-141': 1.4819764398566666, 'ACC-142': 1.7756259273523418, 'ACC-143': 1.7615983422788095, 'ACC-144': 1.5009025270758123, 'ACC-145': 1.226861065766229, 'ACC-146': 1.591647437801284, 'ACC-147': 2.0472003736363527, 'ACC-148': 2.231355704238673, 'ACC-149': 1.9689291520167451, 'ACC-150': 1.446515511111528, 'ACC-151': 1.479617556749936, 'ACC-152': 1.6078081799177288, 'ACC-153': 1.5195862877663568, 'ACC-154': 1.306379136446522, 'ACC-155': 1.0772488494144155, 'ACC-156': 1.3991609946544112, 'ACC-157': 1.6146001336539941, 'ACC-158': 2.0601198784561734, 'ACC-159': 1.3221354912429435, 'ACC-160': 1.5321732344025698, 'ACC-161': 0.8530458299749774, 'ACC-162': 0.5130898152638641, 'ACC-163': 0.2696559135511269, 'ACC-164': 0.41349699865867157, 'ACC-165': 0.3381222067992897, 'ACC-166': 0.624522584381899, 'ACC-167': 0.5583088834343466, 'ACC-168': 0.2684787959772136, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 03:34:11] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 03:34:11] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 03:34:11] d2.evaluation.testing INFO: copypaste: 4.0505,0.6202,0.3118,3.2913,10.1043,6.3729,14.8067
[01/29 03:34:11] d2.utils.events INFO:  eta: 1 day, 18:30:57  iter: 8999  total_loss: 40.9  loss_mask: 4.183  loss_mask_0: 4.12  loss_mask_1: 3.981  loss_mask_2: 4.002  loss_mask_3: 4.065  loss_mask_4: 4.034  loss_mask_5: 4.057  loss_mask_6: 4.062  loss_mask_7: 3.999  loss_mask_8: 4.222  time: 3.0475  data_time: 0.0625  lr: 8.6394e-05  max_mem: 27632M
[01/29 03:35:12] d2.utils.events INFO:  eta: 1 day, 18:31:56  iter: 9019  total_loss: 38.55  loss_mask: 3.952  loss_mask_0: 3.988  loss_mask_1: 3.751  loss_mask_2: 3.771  loss_mask_3: 3.824  loss_mask_4: 3.809  loss_mask_5: 3.759  loss_mask_6: 3.825  loss_mask_7: 3.846  loss_mask_8: 3.826  time: 3.0475  data_time: 0.0548  lr: 8.6364e-05  max_mem: 27632M
[01/29 03:36:12] d2.utils.events INFO:  eta: 1 day, 18:30:31  iter: 9039  total_loss: 36.55  loss_mask: 3.703  loss_mask_0: 3.813  loss_mask_1: 3.654  loss_mask_2: 3.627  loss_mask_3: 3.667  loss_mask_4: 3.792  loss_mask_5: 3.603  loss_mask_6: 3.606  loss_mask_7: 3.639  loss_mask_8: 3.635  time: 3.0474  data_time: 0.0649  lr: 8.6333e-05  max_mem: 27632M
[01/29 03:37:12] d2.utils.events INFO:  eta: 1 day, 18:29:31  iter: 9059  total_loss: 34.25  loss_mask: 3.408  loss_mask_0: 3.724  loss_mask_1: 3.353  loss_mask_2: 3.394  loss_mask_3: 3.407  loss_mask_4: 3.371  loss_mask_5: 3.428  loss_mask_6: 3.388  loss_mask_7: 3.376  loss_mask_8: 3.432  time: 3.0473  data_time: 0.0650  lr: 8.6303e-05  max_mem: 27632M
[01/29 03:38:12] d2.utils.events INFO:  eta: 1 day, 18:28:52  iter: 9079  total_loss: 37.39  loss_mask: 3.763  loss_mask_0: 3.82  loss_mask_1: 3.704  loss_mask_2: 3.744  loss_mask_3: 3.741  loss_mask_4: 3.702  loss_mask_5: 3.786  loss_mask_6: 3.738  loss_mask_7: 3.704  loss_mask_8: 3.679  time: 3.0472  data_time: 0.0520  lr: 8.6272e-05  max_mem: 27632M
[01/29 03:39:12] d2.utils.events INFO:  eta: 1 day, 18:27:52  iter: 9099  total_loss: 42.21  loss_mask: 4.29  loss_mask_0: 4.33  loss_mask_1: 4.104  loss_mask_2: 4.113  loss_mask_3: 4.202  loss_mask_4: 4.184  loss_mask_5: 4.168  loss_mask_6: 4.229  loss_mask_7: 4.174  loss_mask_8: 4.232  time: 3.0471  data_time: 0.0528  lr: 8.6242e-05  max_mem: 27632M
[01/29 03:40:13] d2.utils.events INFO:  eta: 1 day, 18:27:34  iter: 9119  total_loss: 37.53  loss_mask: 3.775  loss_mask_0: 3.837  loss_mask_1: 3.708  loss_mask_2: 3.733  loss_mask_3: 3.764  loss_mask_4: 3.726  loss_mask_5: 3.754  loss_mask_6: 3.752  loss_mask_7: 3.762  loss_mask_8: 3.735  time: 3.0470  data_time: 0.0627  lr: 8.6211e-05  max_mem: 27632M
[01/29 03:41:13] d2.utils.events INFO:  eta: 1 day, 18:26:55  iter: 9139  total_loss: 34.67  loss_mask: 3.46  loss_mask_0: 3.619  loss_mask_1: 3.382  loss_mask_2: 3.43  loss_mask_3: 3.514  loss_mask_4: 3.465  loss_mask_5: 3.448  loss_mask_6: 3.465  loss_mask_7: 3.436  loss_mask_8: 3.448  time: 3.0470  data_time: 0.0524  lr: 8.6181e-05  max_mem: 27632M
[01/29 03:42:13] d2.utils.events INFO:  eta: 1 day, 18:25:57  iter: 9159  total_loss: 41.55  loss_mask: 4.166  loss_mask_0: 4.285  loss_mask_1: 4.181  loss_mask_2: 4.179  loss_mask_3: 4.163  loss_mask_4: 4.144  loss_mask_5: 4.127  loss_mask_6: 4.094  loss_mask_7: 4.12  loss_mask_8: 4.114  time: 3.0468  data_time: 0.0569  lr: 8.615e-05  max_mem: 27632M
[01/29 03:43:13] d2.utils.events INFO:  eta: 1 day, 18:24:40  iter: 9179  total_loss: 39.17  loss_mask: 3.9  loss_mask_0: 3.929  loss_mask_1: 3.878  loss_mask_2: 3.936  loss_mask_3: 3.897  loss_mask_4: 3.914  loss_mask_5: 3.923  loss_mask_6: 3.918  loss_mask_7: 3.901  loss_mask_8: 3.903  time: 3.0467  data_time: 0.0616  lr: 8.612e-05  max_mem: 27632M
[01/29 03:44:13] d2.utils.events INFO:  eta: 1 day, 18:23:33  iter: 9199  total_loss: 35.09  loss_mask: 3.482  loss_mask_0: 3.593  loss_mask_1: 3.511  loss_mask_2: 3.528  loss_mask_3: 3.482  loss_mask_4: 3.495  loss_mask_5: 3.487  loss_mask_6: 3.499  loss_mask_7: 3.487  loss_mask_8: 3.482  time: 3.0467  data_time: 0.0625  lr: 8.6089e-05  max_mem: 27632M
[01/29 03:45:13] d2.utils.events INFO:  eta: 1 day, 18:22:54  iter: 9219  total_loss: 39.82  loss_mask: 4.016  loss_mask_0: 4.093  loss_mask_1: 3.964  loss_mask_2: 4.021  loss_mask_3: 3.977  loss_mask_4: 4.021  loss_mask_5: 3.983  loss_mask_6: 3.983  loss_mask_7: 4.003  loss_mask_8: 4.054  time: 3.0466  data_time: 0.0572  lr: 8.6059e-05  max_mem: 27632M
[01/29 03:46:13] d2.utils.events INFO:  eta: 1 day, 18:20:49  iter: 9239  total_loss: 36.39  loss_mask: 3.666  loss_mask_0: 3.796  loss_mask_1: 3.583  loss_mask_2: 3.615  loss_mask_3: 3.686  loss_mask_4: 3.608  loss_mask_5: 3.616  loss_mask_6: 3.634  loss_mask_7: 3.617  loss_mask_8: 3.609  time: 3.0464  data_time: 0.0555  lr: 8.6028e-05  max_mem: 27632M
[01/29 03:47:13] d2.utils.events INFO:  eta: 1 day, 18:18:40  iter: 9259  total_loss: 39.17  loss_mask: 3.859  loss_mask_0: 4.039  loss_mask_1: 3.867  loss_mask_2: 4.043  loss_mask_3: 3.902  loss_mask_4: 3.886  loss_mask_5: 3.928  loss_mask_6: 3.891  loss_mask_7: 3.896  loss_mask_8: 3.779  time: 3.0463  data_time: 0.0654  lr: 8.5998e-05  max_mem: 27632M
[01/29 03:48:13] d2.utils.events INFO:  eta: 1 day, 18:19:33  iter: 9279  total_loss: 37.44  loss_mask: 3.747  loss_mask_0: 3.721  loss_mask_1: 3.725  loss_mask_2: 3.697  loss_mask_3: 3.711  loss_mask_4: 3.719  loss_mask_5: 3.715  loss_mask_6: 3.714  loss_mask_7: 3.735  loss_mask_8: 3.767  time: 3.0462  data_time: 0.0552  lr: 8.5967e-05  max_mem: 27632M
[01/29 03:49:13] d2.utils.events INFO:  eta: 1 day, 18:17:10  iter: 9299  total_loss: 36.21  loss_mask: 3.557  loss_mask_0: 3.676  loss_mask_1: 3.566  loss_mask_2: 3.611  loss_mask_3: 3.527  loss_mask_4: 3.671  loss_mask_5: 3.581  loss_mask_6: 3.496  loss_mask_7: 3.62  loss_mask_8: 3.56  time: 3.0461  data_time: 0.0600  lr: 8.5937e-05  max_mem: 27632M
[01/29 03:50:13] d2.utils.events INFO:  eta: 1 day, 18:16:50  iter: 9319  total_loss: 38.73  loss_mask: 3.867  loss_mask_0: 4.105  loss_mask_1: 3.79  loss_mask_2: 3.77  loss_mask_3: 3.863  loss_mask_4: 3.91  loss_mask_5: 3.824  loss_mask_6: 3.877  loss_mask_7: 3.827  loss_mask_8: 3.782  time: 3.0460  data_time: 0.0572  lr: 8.5906e-05  max_mem: 27632M
[01/29 03:51:12] d2.utils.events INFO:  eta: 1 day, 18:14:56  iter: 9339  total_loss: 37.75  loss_mask: 3.773  loss_mask_0: 3.892  loss_mask_1: 3.709  loss_mask_2: 3.78  loss_mask_3: 3.798  loss_mask_4: 3.793  loss_mask_5: 3.723  loss_mask_6: 3.784  loss_mask_7: 3.79  loss_mask_8: 3.723  time: 3.0458  data_time: 0.0633  lr: 8.5876e-05  max_mem: 27632M
[01/29 03:52:12] d2.utils.events INFO:  eta: 1 day, 18:13:33  iter: 9359  total_loss: 42.48  loss_mask: 4.29  loss_mask_0: 4.391  loss_mask_1: 4.221  loss_mask_2: 4.176  loss_mask_3: 4.188  loss_mask_4: 4.231  loss_mask_5: 4.211  loss_mask_6: 4.267  loss_mask_7: 4.26  loss_mask_8: 4.244  time: 3.0457  data_time: 0.0627  lr: 8.5845e-05  max_mem: 27632M
[01/29 03:53:13] d2.utils.events INFO:  eta: 1 day, 18:12:52  iter: 9379  total_loss: 36.6  loss_mask: 3.586  loss_mask_0: 3.725  loss_mask_1: 3.591  loss_mask_2: 3.684  loss_mask_3: 3.684  loss_mask_4: 3.653  loss_mask_5: 3.66  loss_mask_6: 3.632  loss_mask_7: 3.719  loss_mask_8: 3.67  time: 3.0456  data_time: 0.0605  lr: 8.5815e-05  max_mem: 27632M
[01/29 03:54:12] d2.utils.events INFO:  eta: 1 day, 18:11:29  iter: 9399  total_loss: 35.78  loss_mask: 3.583  loss_mask_0: 3.762  loss_mask_1: 3.483  loss_mask_2: 3.57  loss_mask_3: 3.627  loss_mask_4: 3.622  loss_mask_5: 3.525  loss_mask_6: 3.569  loss_mask_7: 3.58  loss_mask_8: 3.559  time: 3.0455  data_time: 0.0579  lr: 8.5784e-05  max_mem: 27632M
[01/29 03:55:12] d2.utils.events INFO:  eta: 1 day, 18:10:29  iter: 9419  total_loss: 36.42  loss_mask: 3.613  loss_mask_0: 3.947  loss_mask_1: 3.573  loss_mask_2: 3.621  loss_mask_3: 3.602  loss_mask_4: 3.633  loss_mask_5: 3.636  loss_mask_6: 3.655  loss_mask_7: 3.591  loss_mask_8: 3.607  time: 3.0454  data_time: 0.0561  lr: 8.5754e-05  max_mem: 27632M
[01/29 03:56:12] d2.utils.events INFO:  eta: 1 day, 18:09:33  iter: 9439  total_loss: 41.49  loss_mask: 4.126  loss_mask_0: 4.304  loss_mask_1: 4.106  loss_mask_2: 4.1  loss_mask_3: 4.149  loss_mask_4: 4.117  loss_mask_5: 4.125  loss_mask_6: 4.112  loss_mask_7: 4.131  loss_mask_8: 4.105  time: 3.0453  data_time: 0.0555  lr: 8.5723e-05  max_mem: 27632M
[01/29 03:57:12] d2.utils.events INFO:  eta: 1 day, 18:08:30  iter: 9459  total_loss: 37.42  loss_mask: 3.747  loss_mask_0: 3.869  loss_mask_1: 3.741  loss_mask_2: 3.732  loss_mask_3: 3.772  loss_mask_4: 3.716  loss_mask_5: 3.743  loss_mask_6: 3.745  loss_mask_7: 3.717  loss_mask_8: 3.681  time: 3.0452  data_time: 0.0621  lr: 8.5693e-05  max_mem: 27632M
[01/29 03:58:12] d2.utils.events INFO:  eta: 1 day, 18:07:33  iter: 9479  total_loss: 37.94  loss_mask: 3.767  loss_mask_0: 4.233  loss_mask_1: 3.712  loss_mask_2: 3.737  loss_mask_3: 3.763  loss_mask_4: 3.794  loss_mask_5: 3.696  loss_mask_6: 3.757  loss_mask_7: 3.817  loss_mask_8: 3.769  time: 3.0451  data_time: 0.0578  lr: 8.5662e-05  max_mem: 27632M
[01/29 03:59:12] d2.utils.events INFO:  eta: 1 day, 18:06:30  iter: 9499  total_loss: 39.3  loss_mask: 3.822  loss_mask_0: 4.199  loss_mask_1: 3.949  loss_mask_2: 3.918  loss_mask_3: 4.017  loss_mask_4: 3.957  loss_mask_5: 3.864  loss_mask_6: 3.877  loss_mask_7: 3.845  loss_mask_8: 3.947  time: 3.0450  data_time: 0.0631  lr: 8.5632e-05  max_mem: 27632M
[01/29 04:00:12] d2.utils.events INFO:  eta: 1 day, 18:04:14  iter: 9519  total_loss: 36.32  loss_mask: 3.627  loss_mask_0: 3.714  loss_mask_1: 3.607  loss_mask_2: 3.662  loss_mask_3: 3.647  loss_mask_4: 3.598  loss_mask_5: 3.6  loss_mask_6: 3.617  loss_mask_7: 3.607  loss_mask_8: 3.637  time: 3.0449  data_time: 0.0600  lr: 8.5601e-05  max_mem: 27632M
[01/29 04:01:13] d2.utils.events INFO:  eta: 1 day, 18:03:25  iter: 9539  total_loss: 37.32  loss_mask: 3.736  loss_mask_0: 3.833  loss_mask_1: 3.704  loss_mask_2: 3.727  loss_mask_3: 3.773  loss_mask_4: 3.667  loss_mask_5: 3.7  loss_mask_6: 3.768  loss_mask_7: 3.635  loss_mask_8: 3.72  time: 3.0448  data_time: 0.0670  lr: 8.5571e-05  max_mem: 27632M
[01/29 04:02:13] d2.utils.events INFO:  eta: 1 day, 18:02:14  iter: 9559  total_loss: 34.41  loss_mask: 3.437  loss_mask_0: 3.539  loss_mask_1: 3.361  loss_mask_2: 3.414  loss_mask_3: 3.45  loss_mask_4: 3.447  loss_mask_5: 3.433  loss_mask_6: 3.407  loss_mask_7: 3.42  loss_mask_8: 3.429  time: 3.0448  data_time: 0.0595  lr: 8.554e-05  max_mem: 27632M
[01/29 04:03:13] d2.utils.events INFO:  eta: 1 day, 18:01:01  iter: 9579  total_loss: 39.8  loss_mask: 4  loss_mask_0: 3.951  loss_mask_1: 4.02  loss_mask_2: 4.055  loss_mask_3: 3.968  loss_mask_4: 4.062  loss_mask_5: 3.932  loss_mask_6: 3.999  loss_mask_7: 3.99  loss_mask_8: 3.976  time: 3.0446  data_time: 0.0581  lr: 8.5509e-05  max_mem: 27632M
[01/29 04:04:13] d2.utils.events INFO:  eta: 1 day, 18:00:01  iter: 9599  total_loss: 39.22  loss_mask: 3.991  loss_mask_0: 3.896  loss_mask_1: 3.869  loss_mask_2: 3.858  loss_mask_3: 3.988  loss_mask_4: 3.952  loss_mask_5: 3.908  loss_mask_6: 3.842  loss_mask_7: 3.906  loss_mask_8: 3.944  time: 3.0446  data_time: 0.0635  lr: 8.5479e-05  max_mem: 27632M
[01/29 04:05:12] d2.utils.events INFO:  eta: 1 day, 17:57:58  iter: 9619  total_loss: 40.67  loss_mask: 4.016  loss_mask_0: 4.034  loss_mask_1: 3.978  loss_mask_2: 3.999  loss_mask_3: 4.052  loss_mask_4: 4.064  loss_mask_5: 4.035  loss_mask_6: 4.022  loss_mask_7: 4.048  loss_mask_8: 4.038  time: 3.0444  data_time: 0.0603  lr: 8.5448e-05  max_mem: 27632M
[01/29 04:06:12] d2.utils.events INFO:  eta: 1 day, 17:55:37  iter: 9639  total_loss: 40.09  loss_mask: 4.012  loss_mask_0: 4.057  loss_mask_1: 3.934  loss_mask_2: 3.968  loss_mask_3: 4.003  loss_mask_4: 3.999  loss_mask_5: 3.99  loss_mask_6: 3.983  loss_mask_7: 3.937  loss_mask_8: 3.979  time: 3.0443  data_time: 0.0575  lr: 8.5418e-05  max_mem: 27632M
[01/29 04:07:11] d2.utils.events INFO:  eta: 1 day, 17:53:32  iter: 9659  total_loss: 36.55  loss_mask: 3.656  loss_mask_0: 3.739  loss_mask_1: 3.614  loss_mask_2: 3.643  loss_mask_3: 3.68  loss_mask_4: 3.639  loss_mask_5: 3.672  loss_mask_6: 3.65  loss_mask_7: 3.659  loss_mask_8: 3.63  time: 3.0441  data_time: 0.0547  lr: 8.5387e-05  max_mem: 27632M
[01/29 04:08:11] d2.utils.events INFO:  eta: 1 day, 17:52:28  iter: 9679  total_loss: 35.96  loss_mask: 3.547  loss_mask_0: 3.751  loss_mask_1: 3.596  loss_mask_2: 3.595  loss_mask_3: 3.6  loss_mask_4: 3.612  loss_mask_5: 3.584  loss_mask_6: 3.585  loss_mask_7: 3.552  loss_mask_8: 3.543  time: 3.0440  data_time: 0.0669  lr: 8.5357e-05  max_mem: 27632M
[01/29 04:09:11] d2.utils.events INFO:  eta: 1 day, 17:50:27  iter: 9699  total_loss: 39.47  loss_mask: 3.93  loss_mask_0: 4.086  loss_mask_1: 3.884  loss_mask_2: 3.932  loss_mask_3: 3.928  loss_mask_4: 3.928  loss_mask_5: 3.917  loss_mask_6: 3.876  loss_mask_7: 3.989  loss_mask_8: 3.886  time: 3.0439  data_time: 0.0520  lr: 8.5326e-05  max_mem: 27632M
[01/29 04:10:11] d2.utils.events INFO:  eta: 1 day, 17:48:33  iter: 9719  total_loss: 32.61  loss_mask: 3.256  loss_mask_0: 3.368  loss_mask_1: 3.253  loss_mask_2: 3.285  loss_mask_3: 3.266  loss_mask_4: 3.277  loss_mask_5: 3.298  loss_mask_6: 3.286  loss_mask_7: 3.285  loss_mask_8: 3.25  time: 3.0438  data_time: 0.0567  lr: 8.5296e-05  max_mem: 27632M
[01/29 04:11:11] d2.utils.events INFO:  eta: 1 day, 17:47:05  iter: 9739  total_loss: 37.62  loss_mask: 3.791  loss_mask_0: 3.722  loss_mask_1: 3.734  loss_mask_2: 3.735  loss_mask_3: 3.766  loss_mask_4: 3.779  loss_mask_5: 3.717  loss_mask_6: 3.872  loss_mask_7: 3.763  loss_mask_8: 3.721  time: 3.0436  data_time: 0.0603  lr: 8.5265e-05  max_mem: 27632M
[01/29 04:12:11] d2.utils.events INFO:  eta: 1 day, 17:46:02  iter: 9759  total_loss: 37.23  loss_mask: 3.697  loss_mask_0: 3.69  loss_mask_1: 3.681  loss_mask_2: 3.71  loss_mask_3: 3.725  loss_mask_4: 3.684  loss_mask_5: 3.706  loss_mask_6: 3.831  loss_mask_7: 3.759  loss_mask_8: 3.676  time: 3.0436  data_time: 0.0677  lr: 8.5235e-05  max_mem: 27632M
[01/29 04:13:11] d2.utils.events INFO:  eta: 1 day, 17:44:47  iter: 9779  total_loss: 39.61  loss_mask: 3.843  loss_mask_0: 4.311  loss_mask_1: 3.978  loss_mask_2: 3.94  loss_mask_3: 3.93  loss_mask_4: 3.937  loss_mask_5: 3.954  loss_mask_6: 4.095  loss_mask_7: 3.889  loss_mask_8: 3.875  time: 3.0435  data_time: 0.0660  lr: 8.5204e-05  max_mem: 27632M
[01/29 04:14:11] d2.utils.events INFO:  eta: 1 day, 17:43:36  iter: 9799  total_loss: 38.97  loss_mask: 3.871  loss_mask_0: 3.897  loss_mask_1: 3.815  loss_mask_2: 3.822  loss_mask_3: 3.863  loss_mask_4: 3.821  loss_mask_5: 3.925  loss_mask_6: 3.999  loss_mask_7: 3.889  loss_mask_8: 3.866  time: 3.0435  data_time: 0.0648  lr: 8.5174e-05  max_mem: 27632M
[01/29 04:15:12] d2.utils.events INFO:  eta: 1 day, 17:42:37  iter: 9819  total_loss: 35.7  loss_mask: 3.574  loss_mask_0: 3.627  loss_mask_1: 3.521  loss_mask_2: 3.54  loss_mask_3: 3.615  loss_mask_4: 3.517  loss_mask_5: 3.62  loss_mask_6: 3.898  loss_mask_7: 3.52  loss_mask_8: 3.504  time: 3.0434  data_time: 0.0535  lr: 8.5143e-05  max_mem: 27632M
[01/29 04:16:12] d2.utils.events INFO:  eta: 1 day, 17:41:48  iter: 9839  total_loss: 33.82  loss_mask: 3.369  loss_mask_0: 3.769  loss_mask_1: 3.3  loss_mask_2: 3.343  loss_mask_3: 3.367  loss_mask_4: 3.388  loss_mask_5: 3.487  loss_mask_6: 3.553  loss_mask_7: 3.367  loss_mask_8: 3.319  time: 3.0433  data_time: 0.0624  lr: 8.5113e-05  max_mem: 27632M
[01/29 04:17:11] d2.utils.events INFO:  eta: 1 day, 17:40:56  iter: 9859  total_loss: 37.87  loss_mask: 3.784  loss_mask_0: 3.787  loss_mask_1: 3.655  loss_mask_2: 3.879  loss_mask_3: 3.677  loss_mask_4: 4.025  loss_mask_5: 3.763  loss_mask_6: 3.705  loss_mask_7: 3.733  loss_mask_8: 3.632  time: 3.0432  data_time: 0.0602  lr: 8.5082e-05  max_mem: 27632M
[01/29 04:18:12] d2.utils.events INFO:  eta: 1 day, 17:39:37  iter: 9879  total_loss: 37.12  loss_mask: 3.685  loss_mask_0: 3.883  loss_mask_1: 3.692  loss_mask_2: 3.692  loss_mask_3: 3.696  loss_mask_4: 3.658  loss_mask_5: 3.739  loss_mask_6: 3.738  loss_mask_7: 3.655  loss_mask_8: 3.692  time: 3.0431  data_time: 0.0548  lr: 8.5051e-05  max_mem: 27632M
[01/29 04:19:12] d2.utils.events INFO:  eta: 1 day, 17:38:31  iter: 9899  total_loss: 38.64  loss_mask: 3.858  loss_mask_0: 4.034  loss_mask_1: 3.796  loss_mask_2: 3.866  loss_mask_3: 3.814  loss_mask_4: 3.886  loss_mask_5: 3.844  loss_mask_6: 3.915  loss_mask_7: 3.855  loss_mask_8: 3.93  time: 3.0431  data_time: 0.0599  lr: 8.5021e-05  max_mem: 27632M
[01/29 04:20:12] d2.utils.events INFO:  eta: 1 day, 17:37:09  iter: 9919  total_loss: 33.33  loss_mask: 3.332  loss_mask_0: 3.381  loss_mask_1: 3.26  loss_mask_2: 3.295  loss_mask_3: 3.456  loss_mask_4: 3.35  loss_mask_5: 3.307  loss_mask_6: 3.345  loss_mask_7: 3.386  loss_mask_8: 3.389  time: 3.0430  data_time: 0.0542  lr: 8.499e-05  max_mem: 27632M
[01/29 04:21:12] d2.utils.events INFO:  eta: 1 day, 17:35:38  iter: 9939  total_loss: 33.94  loss_mask: 3.39  loss_mask_0: 3.513  loss_mask_1: 3.413  loss_mask_2: 3.421  loss_mask_3: 3.424  loss_mask_4: 3.408  loss_mask_5: 3.373  loss_mask_6: 3.414  loss_mask_7: 3.394  loss_mask_8: 3.384  time: 3.0429  data_time: 0.0556  lr: 8.496e-05  max_mem: 27632M
[01/29 04:22:12] d2.utils.events INFO:  eta: 1 day, 17:34:38  iter: 9959  total_loss: 33.75  loss_mask: 3.349  loss_mask_0: 3.442  loss_mask_1: 3.324  loss_mask_2: 3.354  loss_mask_3: 3.419  loss_mask_4: 3.364  loss_mask_5: 3.344  loss_mask_6: 3.377  loss_mask_7: 3.393  loss_mask_8: 3.343  time: 3.0428  data_time: 0.0671  lr: 8.4929e-05  max_mem: 27632M
[01/29 04:23:12] d2.utils.events INFO:  eta: 1 day, 17:33:19  iter: 9979  total_loss: 37.86  loss_mask: 3.809  loss_mask_0: 3.934  loss_mask_1: 3.765  loss_mask_2: 3.791  loss_mask_3: 3.832  loss_mask_4: 3.75  loss_mask_5: 3.791  loss_mask_6: 3.871  loss_mask_7: 3.794  loss_mask_8: 3.759  time: 3.0427  data_time: 0.0689  lr: 8.4899e-05  max_mem: 27632M
[01/29 04:24:12] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/model_0009999.pth
[01/29 04:24:13] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 04:24:13] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 04:24:13] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 04:38:19] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.4637125694557485, 'error_1pix': 0.5291742583122468, 'error_3pix': 0.2392843947430591, 'mIoU': 4.352645124107621, 'fwIoU': 8.941352441834823, 'IoU-0': 0.00018323968878191795, 'IoU-1': 18.422542434156554, 'IoU-2': 1.5670643504473571, 'IoU-3': 1.113978128751146, 'IoU-4': 0.9805153521289165, 'IoU-5': 0.8840265052848332, 'IoU-6': 1.0207385546818675, 'IoU-7': 0.9380542278739425, 'IoU-8': 3.983470057081817, 'IoU-9': 7.789862428144175, 'IoU-10': 7.87041427057515, 'IoU-11': 9.51579483858913, 'IoU-12': 8.71489398855484, 'IoU-13': 8.63163727532763, 'IoU-14': 8.093554663562685, 'IoU-15': 8.294896017748636, 'IoU-16': 8.171609753827124, 'IoU-17': 8.139715646443218, 'IoU-18': 9.061915344790052, 'IoU-19': 8.85407712558531, 'IoU-20': 9.668153561062415, 'IoU-21': 10.153476823933179, 'IoU-22': 11.91710458214192, 'IoU-23': 10.809441960606922, 'IoU-24': 10.329637084032646, 'IoU-25': 10.058156627317354, 'IoU-26': 10.061069747620174, 'IoU-27': 10.677029626542874, 'IoU-28': 9.875815521035278, 'IoU-29': 10.06333173414373, 'IoU-30': 10.263405664955604, 'IoU-31': 10.691828616852792, 'IoU-32': 10.366077688698445, 'IoU-33': 9.834316516223886, 'IoU-34': 9.673365259876542, 'IoU-35': 10.009891919800225, 'IoU-36': 9.908535497749286, 'IoU-37': 9.606061244197345, 'IoU-38': 9.682465029650434, 'IoU-39': 9.086327684712932, 'IoU-40': 9.62368527750407, 'IoU-41': 9.13474300558384, 'IoU-42': 8.902919566212944, 'IoU-43': 8.94568219446621, 'IoU-44': 9.259149897648822, 'IoU-45': 9.290158824677489, 'IoU-46': 8.749943197303356, 'IoU-47': 8.549546793771166, 'IoU-48': 8.4668966285067, 'IoU-49': 8.507335770548304, 'IoU-50': 7.963804363559081, 'IoU-51': 7.597140947245096, 'IoU-52': 7.548892463967456, 'IoU-53': 7.260583451520748, 'IoU-54': 7.252490439328955, 'IoU-55': 6.979532430401353, 'IoU-56': 6.743640193749062, 'IoU-57': 6.527352059373431, 'IoU-58': 6.502754226124781, 'IoU-59': 6.422852339114341, 'IoU-60': 6.298144246949325, 'IoU-61': 5.904320075396907, 'IoU-62': 5.929497623450698, 'IoU-63': 5.741556709396269, 'IoU-64': 5.6490087289272575, 'IoU-65': 5.349632281993022, 'IoU-66': 5.327999125106688, 'IoU-67': 5.0730536230772305, 'IoU-68': 5.002624228982897, 'IoU-69': 4.965527805008466, 'IoU-70': 5.02082476559598, 'IoU-71': 4.9601241576244925, 'IoU-72': 4.813573844353678, 'IoU-73': 4.758765901281404, 'IoU-74': 4.753581195942603, 'IoU-75': 4.812071482536669, 'IoU-76': 4.803302709721022, 'IoU-77': 4.700757006228802, 'IoU-78': 4.510079731709335, 'IoU-79': 4.557891221041039, 'IoU-80': 4.607175379621015, 'IoU-81': 4.371130886403191, 'IoU-82': 4.41884537491365, 'IoU-83': 4.392872815816213, 'IoU-84': 4.319767600126338, 'IoU-85': 4.26236622910278, 'IoU-86': 4.26342918068613, 'IoU-87': 4.293558033821678, 'IoU-88': 4.284369740908871, 'IoU-89': 4.383709584861483, 'IoU-90': 4.360668793955085, 'IoU-91': 4.308784467713429, 'IoU-92': 4.300494342287482, 'IoU-93': 4.244645190026822, 'IoU-94': 4.311882913710447, 'IoU-95': 4.369529268431333, 'IoU-96': 4.431956023640014, 'IoU-97': 4.56017530549737, 'IoU-98': 4.559070169858361, 'IoU-99': 4.621795975858651, 'IoU-100': 4.57594230126173, 'IoU-101': 4.383863395353834, 'IoU-102': 4.59505442128509, 'IoU-103': 4.443234482383439, 'IoU-104': 4.173132165031985, 'IoU-105': 3.9562271394782247, 'IoU-106': 4.072059811667217, 'IoU-107': 4.091899011149943, 'IoU-108': 3.99198672382079, 'IoU-109': 4.121568562024091, 'IoU-110': 3.827566386668624, 'IoU-111': 3.796658651368533, 'IoU-112': 3.7316004513396632, 'IoU-113': 3.503455619227594, 'IoU-114': 3.7774973414844086, 'IoU-115': 3.645618855357686, 'IoU-116': 3.3969356643610498, 'IoU-117': 3.2690538669075537, 'IoU-118': 3.163756712670006, 'IoU-119': 3.2168535788650034, 'IoU-120': 3.0624094401184183, 'IoU-121': 2.904134302352191, 'IoU-122': 2.7183700082096656, 'IoU-123': 2.6106127649522737, 'IoU-124': 2.538766095955409, 'IoU-125': 2.485372247901835, 'IoU-126': 2.2345707486815956, 'IoU-127': 2.371153797036017, 'IoU-128': 2.2071205548101975, 'IoU-129': 2.13619360030999, 'IoU-130': 2.184388248961012, 'IoU-131': 1.921993938393068, 'IoU-132': 1.9489698345627426, 'IoU-133': 1.6684715486386077, 'IoU-134': 1.828752260864405, 'IoU-135': 2.074111110490593, 'IoU-136': 2.103119985880777, 'IoU-137': 1.8555006894735726, 'IoU-138': 1.6732550760296534, 'IoU-139': 1.586328625403947, 'IoU-140': 1.6765680895810164, 'IoU-141': 1.7716336954488736, 'IoU-142': 1.7406264115123617, 'IoU-143': 1.6244214141480422, 'IoU-144': 1.6638234207712277, 'IoU-145': 1.6302973067042605, 'IoU-146': 1.5773319928405132, 'IoU-147': 1.5988310227105722, 'IoU-148': 1.8619043573490295, 'IoU-149': 1.5803576477548056, 'IoU-150': 1.5088843049976477, 'IoU-151': 1.3812279925912632, 'IoU-152': 1.4050408367068723, 'IoU-153': 1.2060521660104917, 'IoU-154': 1.6835677713083494, 'IoU-155': 1.5926471543419682, 'IoU-156': 1.6773414384670453, 'IoU-157': 1.426428123240979, 'IoU-158': 1.073791815681986, 'IoU-159': 1.0115248758724578, 'IoU-160': 1.1720399013863325, 'IoU-161': 1.2633157249377067, 'IoU-162': 1.2155564584346297, 'IoU-163': 1.3825246800689934, 'IoU-164': 1.0536273804370573, 'IoU-165': 0.865096629398513, 'IoU-166': 0.9499400667707278, 'IoU-167': 0.7810524636313363, 'IoU-168': 0.604721689899744, 'IoU-169': 0.599839844985764, 'IoU-170': 0.7427780922352615, 'IoU-171': 0.4912748007779253, 'IoU-172': 0.4427367359127277, 'IoU-173': 0.08251836237816286, 'IoU-174': 0.120626427902379, 'IoU-175': 0.1408934282727177, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 8.530271295411998, 'pACC': 14.925479427988247, 'ACC-0': 0.0014229396009053773, 'ACC-1': 18.678085661124946, 'ACC-2': 3.131138544735939, 'ACC-3': 5.447012254160014, 'ACC-4': 4.572523557232644, 'ACC-5': 4.497485176984516, 'ACC-6': 6.116546546701918, 'ACC-7': 8.112641339502865, 'ACC-8': 21.201365362044132, 'ACC-9': 28.799287372042325, 'ACC-10': 23.781331394921143, 'ACC-11': 19.229470902043275, 'ACC-12': 15.469546965961811, 'ACC-13': 14.518148556577406, 'ACC-14': 13.62104715971848, 'ACC-15': 14.23254949111152, 'ACC-16': 14.041242186521192, 'ACC-17': 14.70165149714541, 'ACC-18': 15.86332337972266, 'ACC-19': 15.53751579733621, 'ACC-20': 17.134082565101036, 'ACC-21': 18.06196228241223, 'ACC-22': 20.509885759305526, 'ACC-23': 19.666786308503546, 'ACC-24': 18.958730451333295, 'ACC-25': 18.718311843943322, 'ACC-26': 18.973194675578714, 'ACC-27': 19.57732536321311, 'ACC-28': 18.28217294861498, 'ACC-29': 18.102161646095706, 'ACC-30': 18.93417997134343, 'ACC-31': 19.190675455585072, 'ACC-32': 18.69249216139633, 'ACC-33': 18.267808200141207, 'ACC-34': 18.027889432881153, 'ACC-35': 18.217271405901965, 'ACC-36': 17.924343153053872, 'ACC-37': 17.62589605891451, 'ACC-38': 17.418377442670888, 'ACC-39': 16.129793497350608, 'ACC-40': 16.983046832708926, 'ACC-41': 16.663778912013914, 'ACC-42': 16.186111225707933, 'ACC-43': 16.161297948123917, 'ACC-44': 16.171655367364508, 'ACC-45': 16.36019267888501, 'ACC-46': 15.80818557986506, 'ACC-47': 15.452392709035484, 'ACC-48': 15.378728396038285, 'ACC-49': 15.313730312670387, 'ACC-50': 14.308176826292748, 'ACC-51': 13.923426048714289, 'ACC-52': 13.857148381890891, 'ACC-53': 13.375087713856518, 'ACC-54': 13.324669816140291, 'ACC-55': 13.056342473734645, 'ACC-56': 12.836419877487607, 'ACC-57': 12.325994906722372, 'ACC-58': 12.369443712532211, 'ACC-59': 12.291658321657767, 'ACC-60': 12.140546758246668, 'ACC-61': 11.47505802865507, 'ACC-62': 11.504441218262867, 'ACC-63': 11.159878303060353, 'ACC-64': 10.942212561699389, 'ACC-65': 10.378938091001128, 'ACC-66': 10.337236118430225, 'ACC-67': 9.935749785800878, 'ACC-68': 9.791450766163399, 'ACC-69': 9.442721293705068, 'ACC-70': 9.460356197146643, 'ACC-71': 9.458864208584012, 'ACC-72': 9.196893038156812, 'ACC-73': 9.068286978209283, 'ACC-74': 8.953990218388597, 'ACC-75': 9.07045566476911, 'ACC-76': 8.905920165520117, 'ACC-77': 8.85300192845988, 'ACC-78': 8.567035207850973, 'ACC-79': 8.669809190841793, 'ACC-80': 8.795838566990051, 'ACC-81': 8.341371963076597, 'ACC-82': 8.429858849785631, 'ACC-83': 8.316632497054282, 'ACC-84': 8.243063722374005, 'ACC-85': 8.174186781022584, 'ACC-86': 8.280568983396646, 'ACC-87': 8.496384418350399, 'ACC-88': 8.544757294902775, 'ACC-89': 8.705259072598857, 'ACC-90': 8.617486415677153, 'ACC-91': 8.580990479808817, 'ACC-92': 8.56174400798362, 'ACC-93': 8.468393295080032, 'ACC-94': 8.565542961822256, 'ACC-95': 8.626117121909912, 'ACC-96': 8.84510553019558, 'ACC-97': 9.128104931680076, 'ACC-98': 9.199019569435942, 'ACC-99': 9.474995121130942, 'ACC-100': 9.274462006557208, 'ACC-101': 8.858742096837704, 'ACC-102': 9.239918441323063, 'ACC-103': 8.929725134599037, 'ACC-104': 8.397924300927178, 'ACC-105': 7.958394616747426, 'ACC-106': 8.147475689891039, 'ACC-107': 8.243340121579225, 'ACC-108': 7.996789765276459, 'ACC-109': 8.193989082656847, 'ACC-110': 7.781597383330991, 'ACC-111': 7.838493506965631, 'ACC-112': 7.796994272421339, 'ACC-113': 7.375373001052465, 'ACC-114': 8.070271213853369, 'ACC-115': 7.763106460391202, 'ACC-116': 7.208481176435447, 'ACC-117': 6.898548371931172, 'ACC-118': 6.7574086880069135, 'ACC-119': 6.815075205754831, 'ACC-120': 6.452120164314053, 'ACC-121': 6.138914539111303, 'ACC-122': 5.601583213035561, 'ACC-123': 5.398642900986641, 'ACC-124': 5.32320850076794, 'ACC-125': 5.148129737655311, 'ACC-126': 4.814479184692028, 'ACC-127': 5.096884374211514, 'ACC-128': 4.828568675592244, 'ACC-129': 4.6288213991449325, 'ACC-130': 4.779204061468929, 'ACC-131': 4.300421409265422, 'ACC-132': 4.307117987487141, 'ACC-133': 3.6419060061102155, 'ACC-134': 3.908797931925894, 'ACC-135': 4.49924462687418, 'ACC-136': 4.562872717107715, 'ACC-137': 4.065891375245475, 'ACC-138': 3.743622610858695, 'ACC-139': 3.6111409441091764, 'ACC-140': 3.769503070299675, 'ACC-141': 3.9776887226726405, 'ACC-142': 3.9779540129303155, 'ACC-143': 3.64837044964609, 'ACC-144': 3.7929602888086644, 'ACC-145': 3.7414074554439942, 'ACC-146': 3.5829201983048136, 'ACC-147': 3.697087140651245, 'ACC-148': 4.187154425023121, 'ACC-149': 3.6844277631687032, 'ACC-150': 3.4767236913558244, 'ACC-151': 3.1823021412516264, 'ACC-152': 3.2807336974846586, 'ACC-153': 3.0515399695853715, 'ACC-154': 3.867356607688216, 'ACC-155': 3.596458143828744, 'ACC-156': 3.871059486642492, 'ACC-157': 3.607705111925012, 'ACC-158': 2.922584259989754, 'ACC-159': 2.534116653009609, 'ACC-160': 3.140269420440664, 'ACC-161': 3.0192907713781008, 'ACC-162': 3.2579492473988476, 'ACC-163': 3.7395649734700775, 'ACC-164': 2.9136634755944812, 'ACC-165': 2.269341574896689, 'ACC-166': 2.4653532665720927, 'ACC-167': 2.006889399600811, 'ACC-168': 1.4086785287291652, 'ACC-169': 1.2776082527772756, 'ACC-170': 1.2901600011357668, 'ACC-171': 0.8185022657597505, 'ACC-172': 0.6713708930621921, 'ACC-173': 0.09501303842289645, 'ACC-174': 0.13010712401743957, 'ACC-175': 0.16842953784487844, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 04:38:19] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 04:38:19] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 04:38:19] d2.evaluation.testing INFO: copypaste: 3.4637,0.5292,0.2393,4.3526,8.9414,8.5303,14.9255
[01/29 04:38:19] d2.utils.events INFO:  eta: 1 day, 17:31:48  iter: 9999  total_loss: 34.14  loss_mask: 3.433  loss_mask_0: 3.497  loss_mask_1: 3.411  loss_mask_2: 3.407  loss_mask_3: 3.419  loss_mask_4: 3.37  loss_mask_5: 3.395  loss_mask_6: 3.393  loss_mask_7: 3.471  loss_mask_8: 3.377  time: 3.0426  data_time: 0.0639  lr: 8.4868e-05  max_mem: 27632M
[01/29 04:39:20] d2.utils.events INFO:  eta: 1 day, 17:30:17  iter: 10019  total_loss: 35.43  loss_mask: 3.599  loss_mask_0: 3.532  loss_mask_1: 3.497  loss_mask_2: 3.531  loss_mask_3: 3.573  loss_mask_4: 3.51  loss_mask_5: 3.525  loss_mask_6: 3.574  loss_mask_7: 3.57  loss_mask_8: 3.552  time: 3.0425  data_time: 0.0660  lr: 8.4838e-05  max_mem: 27632M
[01/29 04:40:20] d2.utils.events INFO:  eta: 1 day, 17:29:22  iter: 10039  total_loss: 37.32  loss_mask: 3.765  loss_mask_0: 3.954  loss_mask_1: 3.621  loss_mask_2: 3.681  loss_mask_3: 3.715  loss_mask_4: 3.623  loss_mask_5: 3.695  loss_mask_6: 3.733  loss_mask_7: 3.703  loss_mask_8: 3.707  time: 3.0425  data_time: 0.0646  lr: 8.4807e-05  max_mem: 27632M
[01/29 04:41:21] d2.utils.events INFO:  eta: 1 day, 17:29:39  iter: 10059  total_loss: 37.17  loss_mask: 3.741  loss_mask_0: 3.662  loss_mask_1: 3.632  loss_mask_2: 3.714  loss_mask_3: 3.722  loss_mask_4: 3.784  loss_mask_5: 3.672  loss_mask_6: 3.68  loss_mask_7: 3.799  loss_mask_8: 3.768  time: 3.0424  data_time: 0.0623  lr: 8.4776e-05  max_mem: 27632M
[01/29 04:42:21] d2.utils.events INFO:  eta: 1 day, 17:28:51  iter: 10079  total_loss: 34.32  loss_mask: 3.538  loss_mask_0: 3.623  loss_mask_1: 3.451  loss_mask_2: 3.44  loss_mask_3: 3.441  loss_mask_4: 3.357  loss_mask_5: 3.441  loss_mask_6: 3.471  loss_mask_7: 3.473  loss_mask_8: 3.429  time: 3.0424  data_time: 0.0643  lr: 8.4746e-05  max_mem: 27632M
[01/29 04:43:21] d2.utils.events INFO:  eta: 1 day, 17:27:58  iter: 10099  total_loss: 37.78  loss_mask: 3.795  loss_mask_0: 3.945  loss_mask_1: 3.713  loss_mask_2: 3.843  loss_mask_3: 3.722  loss_mask_4: 3.82  loss_mask_5: 3.746  loss_mask_6: 3.772  loss_mask_7: 3.749  loss_mask_8: 3.651  time: 3.0423  data_time: 0.0632  lr: 8.4715e-05  max_mem: 27632M
[01/29 04:44:21] d2.utils.events INFO:  eta: 1 day, 17:26:59  iter: 10119  total_loss: 39.06  loss_mask: 3.846  loss_mask_0: 4.075  loss_mask_1: 3.822  loss_mask_2: 3.851  loss_mask_3: 3.867  loss_mask_4: 3.891  loss_mask_5: 3.82  loss_mask_6: 3.872  loss_mask_7: 3.898  loss_mask_8: 3.987  time: 3.0422  data_time: 0.0599  lr: 8.4685e-05  max_mem: 27632M
[01/29 04:45:22] d2.utils.events INFO:  eta: 1 day, 17:25:51  iter: 10139  total_loss: 43.14  loss_mask: 4.126  loss_mask_0: 4.26  loss_mask_1: 3.713  loss_mask_2: 3.719  loss_mask_3: 3.762  loss_mask_4: 3.884  loss_mask_5: 3.724  loss_mask_6: 3.997  loss_mask_7: 4.082  loss_mask_8: 6.866  time: 3.0422  data_time: 0.0581  lr: 8.4654e-05  max_mem: 27632M
[01/29 04:46:23] d2.utils.events INFO:  eta: 1 day, 17:26:21  iter: 10159  total_loss: 44.28  loss_mask: 4.251  loss_mask_0: 5.301  loss_mask_1: 4.447  loss_mask_2: 4.293  loss_mask_3: 4.136  loss_mask_4: 4.172  loss_mask_5: 4.088  loss_mask_6: 4.149  loss_mask_7: 4.302  loss_mask_8: 5.342  time: 3.0422  data_time: 0.0555  lr: 8.4624e-05  max_mem: 27632M
[01/29 04:47:23] d2.utils.events INFO:  eta: 1 day, 17:25:21  iter: 10179  total_loss: 40.66  loss_mask: 4.092  loss_mask_0: 4.493  loss_mask_1: 3.849  loss_mask_2: 3.884  loss_mask_3: 4.248  loss_mask_4: 4.067  loss_mask_5: 3.949  loss_mask_6: 3.982  loss_mask_7: 4.146  loss_mask_8: 4.465  time: 3.0422  data_time: 0.0547  lr: 8.4593e-05  max_mem: 27632M
[01/29 04:48:24] d2.utils.events INFO:  eta: 1 day, 17:25:24  iter: 10199  total_loss: 46.54  loss_mask: 4.865  loss_mask_0: 4.904  loss_mask_1: 4.468  loss_mask_2: 4.499  loss_mask_3: 4.539  loss_mask_4: 4.627  loss_mask_5: 4.499  loss_mask_6: 4.556  loss_mask_7: 4.697  loss_mask_8: 5.377  time: 3.0422  data_time: 0.0601  lr: 8.4563e-05  max_mem: 27632M
[01/29 04:49:25] d2.utils.events INFO:  eta: 1 day, 17:25:26  iter: 10219  total_loss: 35.69  loss_mask: 3.565  loss_mask_0: 3.599  loss_mask_1: 3.485  loss_mask_2: 3.494  loss_mask_3: 3.521  loss_mask_4: 3.55  loss_mask_5: 3.488  loss_mask_6: 3.544  loss_mask_7: 3.583  loss_mask_8: 3.73  time: 3.0421  data_time: 0.0622  lr: 8.4532e-05  max_mem: 27632M
[01/29 04:50:25] d2.utils.events INFO:  eta: 1 day, 17:25:18  iter: 10239  total_loss: 36.1  loss_mask: 3.629  loss_mask_0: 3.653  loss_mask_1: 3.512  loss_mask_2: 3.608  loss_mask_3: 3.541  loss_mask_4: 3.55  loss_mask_5: 3.553  loss_mask_6: 3.619  loss_mask_7: 3.574  loss_mask_8: 3.694  time: 3.0421  data_time: 0.0656  lr: 8.4501e-05  max_mem: 27632M
[01/29 04:51:25] d2.utils.events INFO:  eta: 1 day, 17:24:39  iter: 10259  total_loss: 33.62  loss_mask: 3.342  loss_mask_0: 3.36  loss_mask_1: 3.247  loss_mask_2: 3.319  loss_mask_3: 3.265  loss_mask_4: 3.257  loss_mask_5: 3.275  loss_mask_6: 3.332  loss_mask_7: 3.378  loss_mask_8: 3.461  time: 3.0420  data_time: 0.0564  lr: 8.4471e-05  max_mem: 27632M
[01/29 04:52:26] d2.utils.events INFO:  eta: 1 day, 17:24:22  iter: 10279  total_loss: 41.59  loss_mask: 4.19  loss_mask_0: 4.256  loss_mask_1: 4.044  loss_mask_2: 4.145  loss_mask_3: 4.115  loss_mask_4: 4.071  loss_mask_5: 4.081  loss_mask_6: 4.131  loss_mask_7: 4.149  loss_mask_8: 4.32  time: 3.0420  data_time: 0.0587  lr: 8.444e-05  max_mem: 27632M
[01/29 04:53:27] d2.utils.events INFO:  eta: 1 day, 17:23:46  iter: 10299  total_loss: 38.19  loss_mask: 3.793  loss_mask_0: 3.855  loss_mask_1: 3.789  loss_mask_2: 3.772  loss_mask_3: 3.787  loss_mask_4: 3.787  loss_mask_5: 3.78  loss_mask_6: 3.776  loss_mask_7: 3.783  loss_mask_8: 3.982  time: 3.0420  data_time: 0.0639  lr: 8.441e-05  max_mem: 27632M
[01/29 04:54:27] d2.utils.events INFO:  eta: 1 day, 17:23:28  iter: 10319  total_loss: 35.39  loss_mask: 3.535  loss_mask_0: 3.583  loss_mask_1: 3.462  loss_mask_2: 3.548  loss_mask_3: 3.515  loss_mask_4: 3.512  loss_mask_5: 3.504  loss_mask_6: 3.542  loss_mask_7: 3.541  loss_mask_8: 3.554  time: 3.0419  data_time: 0.0573  lr: 8.4379e-05  max_mem: 27632M
[01/29 04:55:28] d2.utils.events INFO:  eta: 1 day, 17:23:49  iter: 10339  total_loss: 37.86  loss_mask: 3.808  loss_mask_0: 3.849  loss_mask_1: 3.724  loss_mask_2: 3.762  loss_mask_3: 3.72  loss_mask_4: 3.769  loss_mask_5: 3.763  loss_mask_6: 3.769  loss_mask_7: 3.779  loss_mask_8: 3.776  time: 3.0419  data_time: 0.0597  lr: 8.4349e-05  max_mem: 27632M
[01/29 04:56:28] d2.utils.events INFO:  eta: 1 day, 17:22:58  iter: 10359  total_loss: 34.28  loss_mask: 3.406  loss_mask_0: 3.522  loss_mask_1: 3.417  loss_mask_2: 3.435  loss_mask_3: 3.434  loss_mask_4: 3.386  loss_mask_5: 3.376  loss_mask_6: 3.421  loss_mask_7: 3.436  loss_mask_8: 3.453  time: 3.0419  data_time: 0.0619  lr: 8.4318e-05  max_mem: 27632M
[01/29 04:57:29] d2.utils.events INFO:  eta: 1 day, 17:23:30  iter: 10379  total_loss: 39.07  loss_mask: 3.904  loss_mask_0: 4.004  loss_mask_1: 3.864  loss_mask_2: 3.882  loss_mask_3: 3.892  loss_mask_4: 3.89  loss_mask_5: 3.857  loss_mask_6: 3.912  loss_mask_7: 3.905  loss_mask_8: 3.954  time: 3.0419  data_time: 0.0570  lr: 8.4287e-05  max_mem: 27632M
[01/29 04:58:29] d2.utils.events INFO:  eta: 1 day, 17:23:04  iter: 10399  total_loss: 38.83  loss_mask: 3.872  loss_mask_0: 4.042  loss_mask_1: 3.847  loss_mask_2: 3.836  loss_mask_3: 3.846  loss_mask_4: 3.821  loss_mask_5: 3.824  loss_mask_6: 3.873  loss_mask_7: 3.898  loss_mask_8: 3.979  time: 3.0418  data_time: 0.0618  lr: 8.4257e-05  max_mem: 27632M
[01/29 04:59:30] d2.utils.events INFO:  eta: 1 day, 17:24:01  iter: 10419  total_loss: 43.84  loss_mask: 4.297  loss_mask_0: 4.354  loss_mask_1: 4.282  loss_mask_2: 4.268  loss_mask_3: 4.263  loss_mask_4: 4.329  loss_mask_5: 4.302  loss_mask_6: 4.242  loss_mask_7: 4.207  loss_mask_8: 4.352  time: 3.0418  data_time: 0.0629  lr: 8.4226e-05  max_mem: 27632M
[01/29 05:00:30] d2.utils.events INFO:  eta: 1 day, 17:22:21  iter: 10439  total_loss: 33.48  loss_mask: 3.389  loss_mask_0: 3.381  loss_mask_1: 3.344  loss_mask_2: 3.316  loss_mask_3: 3.368  loss_mask_4: 3.352  loss_mask_5: 3.347  loss_mask_6: 3.431  loss_mask_7: 3.36  loss_mask_8: 3.367  time: 3.0417  data_time: 0.0603  lr: 8.4196e-05  max_mem: 27632M
[01/29 05:01:31] d2.utils.events INFO:  eta: 1 day, 17:22:17  iter: 10459  total_loss: 36.91  loss_mask: 3.668  loss_mask_0: 3.778  loss_mask_1: 3.673  loss_mask_2: 3.652  loss_mask_3: 3.648  loss_mask_4: 3.656  loss_mask_5: 3.654  loss_mask_6: 3.787  loss_mask_7: 3.681  loss_mask_8: 3.791  time: 3.0417  data_time: 0.0650  lr: 8.4165e-05  max_mem: 27632M
[01/29 05:02:32] d2.utils.events INFO:  eta: 1 day, 17:21:56  iter: 10479  total_loss: 32.09  loss_mask: 3.186  loss_mask_0: 3.369  loss_mask_1: 3.207  loss_mask_2: 3.182  loss_mask_3: 3.19  loss_mask_4: 3.214  loss_mask_5: 3.196  loss_mask_6: 3.255  loss_mask_7: 3.192  loss_mask_8: 3.207  time: 3.0417  data_time: 0.0600  lr: 8.4135e-05  max_mem: 27632M
[01/29 05:03:32] d2.utils.events INFO:  eta: 1 day, 17:21:22  iter: 10499  total_loss: 32.4  loss_mask: 3.245  loss_mask_0: 3.365  loss_mask_1: 3.174  loss_mask_2: 3.197  loss_mask_3: 3.243  loss_mask_4: 3.375  loss_mask_5: 3.231  loss_mask_6: 3.254  loss_mask_7: 3.236  loss_mask_8: 3.314  time: 3.0416  data_time: 0.0619  lr: 8.4104e-05  max_mem: 27632M
[01/29 05:04:32] d2.utils.events INFO:  eta: 1 day, 17:20:12  iter: 10519  total_loss: 34.81  loss_mask: 3.482  loss_mask_0: 3.417  loss_mask_1: 3.407  loss_mask_2: 3.441  loss_mask_3: 3.475  loss_mask_4: 3.511  loss_mask_5: 3.467  loss_mask_6: 3.458  loss_mask_7: 3.465  loss_mask_8: 3.482  time: 3.0416  data_time: 0.0534  lr: 8.4073e-05  max_mem: 27632M
[01/29 05:05:32] d2.utils.events INFO:  eta: 1 day, 17:18:58  iter: 10539  total_loss: 32.93  loss_mask: 3.282  loss_mask_0: 3.471  loss_mask_1: 3.296  loss_mask_2: 3.26  loss_mask_3: 3.254  loss_mask_4: 3.291  loss_mask_5: 3.273  loss_mask_6: 3.259  loss_mask_7: 3.276  loss_mask_8: 3.297  time: 3.0415  data_time: 0.0543  lr: 8.4043e-05  max_mem: 27632M
[01/29 05:06:33] d2.utils.events INFO:  eta: 1 day, 17:18:48  iter: 10559  total_loss: 35.52  loss_mask: 3.525  loss_mask_0: 3.719  loss_mask_1: 3.515  loss_mask_2: 3.584  loss_mask_3: 3.549  loss_mask_4: 3.518  loss_mask_5: 3.569  loss_mask_6: 3.593  loss_mask_7: 3.552  loss_mask_8: 3.595  time: 3.0415  data_time: 0.0748  lr: 8.4012e-05  max_mem: 27632M
[01/29 05:07:33] d2.utils.events INFO:  eta: 1 day, 17:18:23  iter: 10579  total_loss: 38.18  loss_mask: 3.841  loss_mask_0: 3.852  loss_mask_1: 3.798  loss_mask_2: 3.769  loss_mask_3: 3.83  loss_mask_4: 3.801  loss_mask_5: 3.77  loss_mask_6: 3.882  loss_mask_7: 3.81  loss_mask_8: 3.787  time: 3.0415  data_time: 0.0609  lr: 8.3982e-05  max_mem: 27632M
[01/29 05:08:34] d2.utils.events INFO:  eta: 1 day, 17:16:48  iter: 10599  total_loss: 35.5  loss_mask: 3.536  loss_mask_0: 3.623  loss_mask_1: 3.562  loss_mask_2: 3.52  loss_mask_3: 3.531  loss_mask_4: 3.527  loss_mask_5: 3.542  loss_mask_6: 3.511  loss_mask_7: 3.608  loss_mask_8: 3.535  time: 3.0414  data_time: 0.0621  lr: 8.3951e-05  max_mem: 27632M
[01/29 05:09:33] d2.utils.events INFO:  eta: 1 day, 17:15:43  iter: 10619  total_loss: 37.91  loss_mask: 3.879  loss_mask_0: 3.903  loss_mask_1: 3.83  loss_mask_2: 3.779  loss_mask_3: 3.744  loss_mask_4: 3.884  loss_mask_5: 3.816  loss_mask_6: 3.805  loss_mask_7: 3.815  loss_mask_8: 3.876  time: 3.0413  data_time: 0.0601  lr: 8.392e-05  max_mem: 27632M
[01/29 05:10:33] d2.utils.events INFO:  eta: 1 day, 17:15:49  iter: 10639  total_loss: 36.18  loss_mask: 3.651  loss_mask_0: 3.788  loss_mask_1: 3.676  loss_mask_2: 3.596  loss_mask_3: 3.565  loss_mask_4: 3.701  loss_mask_5: 3.558  loss_mask_6: 3.593  loss_mask_7: 3.604  loss_mask_8: 3.664  time: 3.0412  data_time: 0.0627  lr: 8.389e-05  max_mem: 27632M
[01/29 05:11:34] d2.utils.events INFO:  eta: 1 day, 17:16:39  iter: 10659  total_loss: 39.46  loss_mask: 3.863  loss_mask_0: 4.005  loss_mask_1: 4.009  loss_mask_2: 4.032  loss_mask_3: 3.803  loss_mask_4: 3.925  loss_mask_5: 3.965  loss_mask_6: 3.879  loss_mask_7: 3.896  loss_mask_8: 3.914  time: 3.0412  data_time: 0.0653  lr: 8.3859e-05  max_mem: 27632M
[01/29 05:12:34] d2.utils.events INFO:  eta: 1 day, 17:16:17  iter: 10679  total_loss: 35.2  loss_mask: 3.531  loss_mask_0: 3.655  loss_mask_1: 3.485  loss_mask_2: 3.5  loss_mask_3: 3.548  loss_mask_4: 3.606  loss_mask_5: 3.485  loss_mask_6: 3.567  loss_mask_7: 3.522  loss_mask_8: 3.518  time: 3.0411  data_time: 0.0583  lr: 8.3829e-05  max_mem: 27632M
[01/29 05:13:35] d2.utils.events INFO:  eta: 1 day, 17:15:06  iter: 10699  total_loss: 46.4  loss_mask: 4.728  loss_mask_0: 4.601  loss_mask_1: 4.286  loss_mask_2: 4.344  loss_mask_3: 4.947  loss_mask_4: 4.478  loss_mask_5: 4.474  loss_mask_6: 4.557  loss_mask_7: 4.546  loss_mask_8: 4.632  time: 3.0411  data_time: 0.0679  lr: 8.3798e-05  max_mem: 27646M
[01/29 05:14:36] d2.utils.events INFO:  eta: 1 day, 17:14:48  iter: 10719  total_loss: 39.54  loss_mask: 3.89  loss_mask_0: 4.154  loss_mask_1: 4.043  loss_mask_2: 4.049  loss_mask_3: 3.907  loss_mask_4: 3.925  loss_mask_5: 3.999  loss_mask_6: 3.847  loss_mask_7: 3.867  loss_mask_8: 3.997  time: 3.0411  data_time: 0.0720  lr: 8.3767e-05  max_mem: 27646M
[01/29 05:15:36] d2.utils.events INFO:  eta: 1 day, 17:14:24  iter: 10739  total_loss: 37.26  loss_mask: 3.654  loss_mask_0: 3.892  loss_mask_1: 3.703  loss_mask_2: 3.727  loss_mask_3: 3.672  loss_mask_4: 3.673  loss_mask_5: 3.647  loss_mask_6: 3.812  loss_mask_7: 3.941  loss_mask_8: 3.679  time: 3.0411  data_time: 0.0608  lr: 8.3737e-05  max_mem: 27646M
[01/29 05:16:37] d2.utils.events INFO:  eta: 1 day, 17:14:03  iter: 10759  total_loss: 34.77  loss_mask: 3.461  loss_mask_0: 3.585  loss_mask_1: 3.479  loss_mask_2: 3.469  loss_mask_3: 3.434  loss_mask_4: 3.467  loss_mask_5: 3.465  loss_mask_6: 3.476  loss_mask_7: 3.436  loss_mask_8: 3.524  time: 3.0410  data_time: 0.0616  lr: 8.3706e-05  max_mem: 27646M
[01/29 05:17:37] d2.utils.events INFO:  eta: 1 day, 17:13:03  iter: 10779  total_loss: 36.17  loss_mask: 3.591  loss_mask_0: 3.698  loss_mask_1: 3.624  loss_mask_2: 3.606  loss_mask_3: 3.588  loss_mask_4: 3.638  loss_mask_5: 3.547  loss_mask_6: 3.736  loss_mask_7: 3.564  loss_mask_8: 3.641  time: 3.0410  data_time: 0.0622  lr: 8.3676e-05  max_mem: 27646M
[01/29 05:18:37] d2.utils.events INFO:  eta: 1 day, 17:11:23  iter: 10799  total_loss: 34.81  loss_mask: 3.523  loss_mask_0: 3.692  loss_mask_1: 3.49  loss_mask_2: 3.429  loss_mask_3: 3.349  loss_mask_4: 3.463  loss_mask_5: 3.471  loss_mask_6: 3.488  loss_mask_7: 3.466  loss_mask_8: 3.442  time: 3.0409  data_time: 0.0644  lr: 8.3645e-05  max_mem: 27646M
[01/29 05:19:37] d2.utils.events INFO:  eta: 1 day, 17:10:29  iter: 10819  total_loss: 40.54  loss_mask: 4.05  loss_mask_0: 4.138  loss_mask_1: 4.038  loss_mask_2: 4.04  loss_mask_3: 4.029  loss_mask_4: 4.037  loss_mask_5: 4.03  loss_mask_6: 4.114  loss_mask_7: 4.057  loss_mask_8: 3.966  time: 3.0408  data_time: 0.0605  lr: 8.3614e-05  max_mem: 27646M
[01/29 05:20:37] d2.utils.events INFO:  eta: 1 day, 17:09:29  iter: 10839  total_loss: 41.17  loss_mask: 4.091  loss_mask_0: 4.221  loss_mask_1: 4.101  loss_mask_2: 4.103  loss_mask_3: 4.097  loss_mask_4: 4.073  loss_mask_5: 4.159  loss_mask_6: 4.184  loss_mask_7: 4.089  loss_mask_8: 4.128  time: 3.0408  data_time: 0.0584  lr: 8.3584e-05  max_mem: 27646M
[01/29 05:21:37] d2.utils.events INFO:  eta: 1 day, 17:08:44  iter: 10859  total_loss: 38.14  loss_mask: 3.796  loss_mask_0: 4.128  loss_mask_1: 3.815  loss_mask_2: 3.76  loss_mask_3: 3.764  loss_mask_4: 3.792  loss_mask_5: 3.791  loss_mask_6: 3.796  loss_mask_7: 3.795  loss_mask_8: 3.791  time: 3.0407  data_time: 0.0649  lr: 8.3553e-05  max_mem: 27646M
[01/29 05:22:37] d2.utils.events INFO:  eta: 1 day, 17:06:59  iter: 10879  total_loss: 37.72  loss_mask: 3.76  loss_mask_0: 3.866  loss_mask_1: 3.749  loss_mask_2: 3.758  loss_mask_3: 3.762  loss_mask_4: 3.769  loss_mask_5: 3.737  loss_mask_6: 3.746  loss_mask_7: 3.724  loss_mask_8: 3.74  time: 3.0406  data_time: 0.0587  lr: 8.3523e-05  max_mem: 27646M
[01/29 05:23:37] d2.utils.events INFO:  eta: 1 day, 17:04:39  iter: 10899  total_loss: 36.21  loss_mask: 3.597  loss_mask_0: 3.724  loss_mask_1: 3.597  loss_mask_2: 3.626  loss_mask_3: 3.602  loss_mask_4: 3.596  loss_mask_5: 3.616  loss_mask_6: 3.592  loss_mask_7: 3.59  loss_mask_8: 3.61  time: 3.0406  data_time: 0.0617  lr: 8.3492e-05  max_mem: 27646M
[01/29 05:24:38] d2.utils.events INFO:  eta: 1 day, 17:02:54  iter: 10919  total_loss: 33.95  loss_mask: 3.397  loss_mask_0: 3.363  loss_mask_1: 3.38  loss_mask_2: 3.409  loss_mask_3: 3.365  loss_mask_4: 3.377  loss_mask_5: 3.421  loss_mask_6: 3.401  loss_mask_7: 3.375  loss_mask_8: 3.398  time: 3.0405  data_time: 0.0638  lr: 8.3461e-05  max_mem: 27646M
[01/29 05:25:38] d2.utils.events INFO:  eta: 1 day, 17:02:38  iter: 10939  total_loss: 36.66  loss_mask: 3.636  loss_mask_0: 3.774  loss_mask_1: 3.619  loss_mask_2: 3.641  loss_mask_3: 3.655  loss_mask_4: 3.63  loss_mask_5: 3.652  loss_mask_6: 3.648  loss_mask_7: 3.649  loss_mask_8: 3.69  time: 3.0404  data_time: 0.0639  lr: 8.3431e-05  max_mem: 27646M
[01/29 05:26:38] d2.utils.events INFO:  eta: 1 day, 17:01:07  iter: 10959  total_loss: 36.13  loss_mask: 3.645  loss_mask_0: 3.743  loss_mask_1: 3.569  loss_mask_2: 3.626  loss_mask_3: 3.607  loss_mask_4: 3.61  loss_mask_5: 3.598  loss_mask_6: 3.591  loss_mask_7: 3.654  loss_mask_8: 3.576  time: 3.0404  data_time: 0.0579  lr: 8.34e-05  max_mem: 27646M
[01/29 05:27:38] d2.utils.events INFO:  eta: 1 day, 17:00:07  iter: 10979  total_loss: 32.68  loss_mask: 3.224  loss_mask_0: 3.299  loss_mask_1: 3.262  loss_mask_2: 3.292  loss_mask_3: 3.227  loss_mask_4: 3.334  loss_mask_5: 3.309  loss_mask_6: 3.258  loss_mask_7: 3.302  loss_mask_8: 3.238  time: 3.0403  data_time: 0.0578  lr: 8.337e-05  max_mem: 27646M
[01/29 05:28:38] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 05:28:39] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 05:28:39] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 05:42:44] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.55837226005271, 'error_1pix': 0.5560353195244643, 'error_3pix': 0.25208808837232877, 'mIoU': 3.9550738600293815, 'fwIoU': 7.834402540332803, 'IoU-0': 0.00016376394434978444, 'IoU-1': 14.906511603056746, 'IoU-2': 1.5443058289734308, 'IoU-3': 1.1894144756452263, 'IoU-4': 1.159343830159751, 'IoU-5': 1.0746738603905324, 'IoU-6': 1.201721019615254, 'IoU-7': 1.199402463301748, 'IoU-8': 3.9762318675057378, 'IoU-9': 10.368321668426313, 'IoU-10': 14.648005626219732, 'IoU-11': 19.25326652945812, 'IoU-12': 16.708616662758306, 'IoU-13': 14.175421544222402, 'IoU-14': 11.99036093769214, 'IoU-15': 11.026709472233788, 'IoU-16': 9.26592650926017, 'IoU-17': 8.257823155355322, 'IoU-18': 7.583998245787391, 'IoU-19': 6.7143830388884895, 'IoU-20': 6.504913605088657, 'IoU-21': 6.709593904322858, 'IoU-22': 7.13879913390835, 'IoU-23': 6.181098607276357, 'IoU-24': 6.148666707716269, 'IoU-25': 5.820743470010066, 'IoU-26': 5.779053061926389, 'IoU-27': 5.8905209229986255, 'IoU-28': 5.668756645000299, 'IoU-29': 5.949057190033231, 'IoU-30': 6.215521476218478, 'IoU-31': 6.58923010386721, 'IoU-32': 6.558174605349885, 'IoU-33': 6.5641946335308, 'IoU-34': 6.710249595472136, 'IoU-35': 6.981609683437704, 'IoU-36': 7.029270681842936, 'IoU-37': 7.172289363463144, 'IoU-38': 6.9703404358696694, 'IoU-39': 7.0672240218084035, 'IoU-40': 7.323225084926882, 'IoU-41': 7.275085963604945, 'IoU-42': 7.078236402570481, 'IoU-43': 7.22666607511823, 'IoU-44': 7.476759801006061, 'IoU-45': 7.499300471166722, 'IoU-46': 7.19600200175055, 'IoU-47': 6.988588964553768, 'IoU-48': 7.211388488898233, 'IoU-49': 7.08148324726335, 'IoU-50': 7.204487705295951, 'IoU-51': 6.824100757616894, 'IoU-52': 6.759473569184239, 'IoU-53': 6.70673710523968, 'IoU-54': 6.89490901571659, 'IoU-55': 6.58765282057151, 'IoU-56': 6.0476648236270005, 'IoU-57': 6.008004486910168, 'IoU-58': 5.859929220568144, 'IoU-59': 5.651962357345792, 'IoU-60': 5.478073579884113, 'IoU-61': 5.4339660906768605, 'IoU-62': 5.433626869154786, 'IoU-63': 5.330194452605771, 'IoU-64': 5.179939092857837, 'IoU-65': 5.136684419913386, 'IoU-66': 5.167279882366806, 'IoU-67': 4.943038086419848, 'IoU-68': 4.973847793938554, 'IoU-69': 5.058074348799145, 'IoU-70': 5.242694109457824, 'IoU-71': 5.276966333184764, 'IoU-72': 5.139609398748704, 'IoU-73': 5.173612443073386, 'IoU-74': 5.433024424129437, 'IoU-75': 5.457321282088231, 'IoU-76': 5.486668066662636, 'IoU-77': 5.436617749784086, 'IoU-78': 5.338478439536269, 'IoU-79': 5.188405289034296, 'IoU-80': 5.354248314849876, 'IoU-81': 5.345498096720146, 'IoU-82': 5.387375727418869, 'IoU-83': 5.2794806066491065, 'IoU-84': 5.145315206483737, 'IoU-85': 5.424153194446236, 'IoU-86': 5.3006018809617945, 'IoU-87': 5.226344797675036, 'IoU-88': 5.30684518067326, 'IoU-89': 5.412651662185372, 'IoU-90': 5.396769330004158, 'IoU-91': 5.3947078759291225, 'IoU-92': 5.305582115828496, 'IoU-93': 5.096163920183995, 'IoU-94': 5.2670392903814385, 'IoU-95': 5.29405390818596, 'IoU-96': 5.097043025111639, 'IoU-97': 4.9565169200337635, 'IoU-98': 4.9443028705861884, 'IoU-99': 4.6069044355276745, 'IoU-100': 4.2701155580399535, 'IoU-101': 4.08158694160962, 'IoU-102': 3.871716249803827, 'IoU-103': 3.7128807499086403, 'IoU-104': 3.6796083489579514, 'IoU-105': 3.448351288499569, 'IoU-106': 3.4461813809257897, 'IoU-107': 3.4131866854302446, 'IoU-108': 3.2741158230895286, 'IoU-109': 3.3258827553974935, 'IoU-110': 3.1863807273321743, 'IoU-111': 2.7492205448939524, 'IoU-112': 2.6583312666252494, 'IoU-113': 2.4789387276993358, 'IoU-114': 2.4471584219808755, 'IoU-115': 2.3562689153136067, 'IoU-116': 2.1506279007952775, 'IoU-117': 2.347465338670187, 'IoU-118': 2.1344444154760662, 'IoU-119': 1.9951713239694042, 'IoU-120': 1.9764251305710363, 'IoU-121': 1.8723503625416322, 'IoU-122': 1.7787767544197797, 'IoU-123': 1.7250063179399897, 'IoU-124': 1.791425326698659, 'IoU-125': 1.6770398098142296, 'IoU-126': 1.4726604464451163, 'IoU-127': 1.482178268932429, 'IoU-128': 1.5917514852838914, 'IoU-129': 1.4870620132413708, 'IoU-130': 1.4885408781828244, 'IoU-131': 1.5264873600913647, 'IoU-132': 1.418206083050348, 'IoU-133': 1.4305957297396712, 'IoU-134': 1.3778357157626697, 'IoU-135': 1.415254018589725, 'IoU-136': 1.275110752432355, 'IoU-137': 1.20741755410648, 'IoU-138': 1.3182629194505147, 'IoU-139': 1.321526785554775, 'IoU-140': 1.2590947131329622, 'IoU-141': 1.2042994448509652, 'IoU-142': 1.1341678386761396, 'IoU-143': 1.3915290511303633, 'IoU-144': 1.37169859209603, 'IoU-145': 1.5455081809040074, 'IoU-146': 1.4065586580679947, 'IoU-147': 1.5656040913229263, 'IoU-148': 1.6141425368986828, 'IoU-149': 1.3927297946447381, 'IoU-150': 1.3037558722420644, 'IoU-151': 1.1632661693997546, 'IoU-152': 1.2634217759782391, 'IoU-153': 1.2304161540380794, 'IoU-154': 1.4194517987307196, 'IoU-155': 1.12853817776754, 'IoU-156': 0.9408921769712891, 'IoU-157': 1.170200835114204, 'IoU-158': 1.0683233004703798, 'IoU-159': 0.7529991086788705, 'IoU-160': 0.81172486693564, 'IoU-161': 0.7608237029292608, 'IoU-162': 0.9803988058341053, 'IoU-163': 1.2397422700932081, 'IoU-164': 1.272753995292649, 'IoU-165': 0.9546804508571346, 'IoU-166': 1.17633658009328, 'IoU-167': 1.1748504982900443, 'IoU-168': 1.0107786444032625, 'IoU-169': 1.2770603789299593, 'IoU-170': 0.9148421194531134, 'IoU-171': 0.41729103588896266, 'IoU-172': 0.23844254937163378, 'IoU-173': 0.4787010468863994, 'IoU-174': 0.7408848600439178, 'IoU-175': 0.16396603600316836, 'IoU-176': 0.0007128028298272344, 'IoU-177': 0.0033867247519669737, 'IoU-178': 0.07844344127529967, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 7.58744442584799, 'pACC': 13.331197823968132, 'ACC-0': 0.0013221318907594923, 'ACC-1': 15.07461874380314, 'ACC-2': 3.10641795945898, 'ACC-3': 5.767635430074107, 'ACC-4': 5.0861094460915846, 'ACC-5': 4.873722269479817, 'ACC-6': 5.900278871475949, 'ACC-7': 6.970621802655232, 'ACC-8': 12.138908043488158, 'ACC-9': 20.560947419596157, 'ACC-10': 30.23478518910117, 'ACC-11': 34.475799136939486, 'ACC-12': 29.867317528691732, 'ACC-13': 25.185799063008268, 'ACC-14': 21.558677370644393, 'ACC-15': 20.23454785680511, 'ACC-16': 17.449379043652467, 'ACC-17': 16.632827265915495, 'ACC-18': 14.74146703854538, 'ACC-19': 13.12950256963149, 'ACC-20': 12.887156315401564, 'ACC-21': 13.111413653484702, 'ACC-22': 13.23505591155266, 'ACC-23': 11.94671797123207, 'ACC-24': 12.164919921710387, 'ACC-25': 11.747545980385867, 'ACC-26': 11.584756567148634, 'ACC-27': 11.18680582516881, 'ACC-28': 10.877288075727423, 'ACC-29': 11.092964487069894, 'ACC-30': 11.708920239905071, 'ACC-31': 11.996724324080802, 'ACC-32': 12.059772340649797, 'ACC-33': 12.46450108794441, 'ACC-34': 12.814202759524395, 'ACC-35': 12.981543608298615, 'ACC-36': 12.922055580023075, 'ACC-37': 13.174587645076866, 'ACC-38': 12.571863799231656, 'ACC-39': 12.630431332184921, 'ACC-40': 13.085278065910671, 'ACC-41': 13.393653262688144, 'ACC-42': 13.02689777728946, 'ACC-43': 13.22447245718306, 'ACC-44': 13.262702895562095, 'ACC-45': 13.406323974476333, 'ACC-46': 13.259808107390725, 'ACC-47': 13.031377937867623, 'ACC-48': 13.502021504554335, 'ACC-49': 13.077576840250254, 'ACC-50': 13.227630937847938, 'ACC-51': 12.725388150885022, 'ACC-52': 12.622238783193657, 'ACC-53': 12.558746857061854, 'ACC-54': 12.811451930643464, 'ACC-55': 12.275734236378899, 'ACC-56': 11.365512088807435, 'ACC-57': 11.075410338241786, 'ACC-58': 10.803606383235156, 'ACC-59': 10.459295391872434, 'ACC-60': 10.117405157516403, 'ACC-61': 10.019525407068679, 'ACC-62': 10.058232499581148, 'ACC-63': 9.968825027631565, 'ACC-64': 9.61833887419767, 'ACC-65': 9.610022716403044, 'ACC-66': 9.648385486528992, 'ACC-67': 9.213038034442414, 'ACC-68': 9.17698179807063, 'ACC-69': 9.19602175141952, 'ACC-70': 9.479778739750214, 'ACC-71': 9.730565017941935, 'ACC-72': 9.523645659884163, 'ACC-73': 9.552250119222885, 'ACC-74': 9.957662543665574, 'ACC-75': 10.045231228548746, 'ACC-76': 9.97795437436641, 'ACC-77': 10.063523682417392, 'ACC-78': 10.057948792008824, 'ACC-79': 9.82480433292757, 'ACC-80': 10.044396742712864, 'ACC-81': 10.005484661230758, 'ACC-82': 10.095367022735655, 'ACC-83': 9.77323627315909, 'ACC-84': 9.586579944931465, 'ACC-85': 10.226080222268203, 'ACC-86': 10.033564826480934, 'ACC-87': 9.957469934588707, 'ACC-88': 10.184333557972995, 'ACC-89': 10.409312322036659, 'ACC-90': 10.313872370935906, 'ACC-91': 10.470713457785365, 'ACC-92': 10.434945457446315, 'ACC-93': 10.053755860971071, 'ACC-94': 10.39361599898796, 'ACC-95': 10.473873749091036, 'ACC-96': 10.265536184053307, 'ACC-97': 9.952953596141917, 'ACC-98': 9.84958294511535, 'ACC-99': 9.257393704291939, 'ACC-100': 8.511535932050275, 'ACC-101': 8.146640736900569, 'ACC-102': 7.729723606705936, 'ACC-103': 7.384717105884575, 'ACC-104': 7.315535771377979, 'ACC-105': 6.884829236038555, 'ACC-106': 6.880934943072534, 'ACC-107': 6.8666805912736235, 'ACC-108': 6.555334679958999, 'ACC-109': 6.623178730033183, 'ACC-110': 6.455618488550266, 'ACC-111': 5.534866389564512, 'ACC-112': 5.346774424956574, 'ACC-113': 4.994755011348248, 'ACC-114': 5.025297039318921, 'ACC-115': 4.901034384255709, 'ACC-116': 4.480608906587265, 'ACC-117': 4.885492318337543, 'ACC-118': 4.399887979033437, 'ACC-119': 4.077095924276561, 'ACC-120': 4.0406462925675655, 'ACC-121': 3.7729370143080554, 'ACC-122': 3.5373677903893874, 'ACC-123': 3.364622662921947, 'ACC-124': 3.6202633742137476, 'ACC-125': 3.354659693722719, 'ACC-126': 2.904284192023607, 'ACC-127': 2.867632629031203, 'ACC-128': 3.1450522081593775, 'ACC-129': 2.9159259242990063, 'ACC-130': 3.0184344874020685, 'ACC-131': 3.098331708438752, 'ACC-132': 2.8160971539443658, 'ACC-133': 2.7945048888525994, 'ACC-134': 2.655062473071952, 'ACC-135': 2.657488170571803, 'ACC-136': 2.3877917676108833, 'ACC-137': 2.325034707991119, 'ACC-138': 2.5815734700611723, 'ACC-139': 2.607741075447242, 'ACC-140': 2.5233274859322794, 'ACC-141': 2.3794936875041026, 'ACC-142': 2.2902709986629533, 'ACC-143': 2.6759149681045025, 'ACC-144': 2.6534296028880866, 'ACC-145': 3.0202822066683064, 'ACC-146': 2.8226908226908227, 'ACC-147': 3.1662523920990395, 'ACC-148': 3.2907149938548605, 'ACC-149': 2.936711325475195, 'ACC-150': 2.7607620941642197, 'ACC-151': 2.461943784551143, 'ACC-152': 2.5595960617708546, 'ACC-153': 2.620284358452885, 'ACC-154': 2.8567503496084736, 'ACC-155': 2.427507561695299, 'ACC-156': 2.02046449094094, 'ACC-157': 2.5704575675789707, 'ACC-158': 2.582594619159383, 'ACC-159': 1.627647177242144, 'ACC-160': 1.6003200922951635, 'ACC-161': 1.4305894511580362, 'ACC-162': 2.1505440328948735, 'ACC-163': 2.6659859026823427, 'ACC-164': 2.8970157820135145, 'ACC-165': 2.2110555956128284, 'ACC-166': 3.1901016528023773, 'ACC-167': 2.777300071048019, 'ACC-168': 2.453055770447992, 'ACC-169': 3.7721116069156837, 'ACC-170': 2.396645229069949, 'ACC-171': 0.8721384106434684, 'ACC-172': 0.4407897173760047, 'ACC-173': 1.0135351247210755, 'ACC-174': 1.511889517056522, 'ACC-175': 0.2185331654584482, 'ACC-176': 0.0007255630369166473, 'ACC-177': 0.0035063825389531423, 'ACC-178': 0.09059108266967479, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 05:42:44] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 05:42:44] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 05:42:44] d2.evaluation.testing INFO: copypaste: 3.5584,0.5560,0.2521,3.9551,7.8344,7.5874,13.3312
[01/29 05:42:45] d2.utils.events INFO:  eta: 1 day, 16:59:37  iter: 10999  total_loss: 32.45  loss_mask: 3.229  loss_mask_0: 3.293  loss_mask_1: 3.263  loss_mask_2: 3.227  loss_mask_3: 3.217  loss_mask_4: 3.242  loss_mask_5: 3.219  loss_mask_6: 3.244  loss_mask_7: 3.238  loss_mask_8: 3.231  time: 3.0402  data_time: 0.0576  lr: 8.3339e-05  max_mem: 27646M
[01/29 05:43:45] d2.utils.events INFO:  eta: 1 day, 16:57:46  iter: 11019  total_loss: 32.6  loss_mask: 3.264  loss_mask_0: 3.238  loss_mask_1: 3.261  loss_mask_2: 3.287  loss_mask_3: 3.23  loss_mask_4: 3.275  loss_mask_5: 3.275  loss_mask_6: 3.226  loss_mask_7: 3.312  loss_mask_8: 3.227  time: 3.0402  data_time: 0.0628  lr: 8.3308e-05  max_mem: 27646M
[01/29 05:44:46] d2.utils.events INFO:  eta: 1 day, 16:57:21  iter: 11039  total_loss: 36.6  loss_mask: 3.624  loss_mask_0: 3.767  loss_mask_1: 3.621  loss_mask_2: 3.76  loss_mask_3: 3.602  loss_mask_4: 3.662  loss_mask_5: 3.741  loss_mask_6: 3.627  loss_mask_7: 3.615  loss_mask_8: 3.738  time: 3.0402  data_time: 0.0607  lr: 8.3278e-05  max_mem: 27646M
[01/29 05:45:45] d2.utils.events INFO:  eta: 1 day, 16:55:38  iter: 11059  total_loss: 36.68  loss_mask: 3.69  loss_mask_0: 3.774  loss_mask_1: 3.591  loss_mask_2: 3.645  loss_mask_3: 3.619  loss_mask_4: 3.639  loss_mask_5: 3.641  loss_mask_6: 3.649  loss_mask_7: 3.657  loss_mask_8: 3.68  time: 3.0401  data_time: 0.0669  lr: 8.3247e-05  max_mem: 27646M
[01/29 05:46:46] d2.utils.events INFO:  eta: 1 day, 16:54:38  iter: 11079  total_loss: 36.05  loss_mask: 3.574  loss_mask_0: 3.653  loss_mask_1: 3.563  loss_mask_2: 3.579  loss_mask_3: 3.578  loss_mask_4: 3.456  loss_mask_5: 3.585  loss_mask_6: 3.575  loss_mask_7: 3.58  loss_mask_8: 3.651  time: 3.0400  data_time: 0.0559  lr: 8.3217e-05  max_mem: 27646M
[01/29 05:47:45] d2.utils.events INFO:  eta: 1 day, 16:53:38  iter: 11099  total_loss: 38.47  loss_mask: 3.83  loss_mask_0: 4.105  loss_mask_1: 3.802  loss_mask_2: 3.828  loss_mask_3: 3.831  loss_mask_4: 3.815  loss_mask_5: 3.793  loss_mask_6: 3.825  loss_mask_7: 3.87  loss_mask_8: 3.8  time: 3.0399  data_time: 0.0592  lr: 8.3186e-05  max_mem: 27646M
[01/29 05:48:45] d2.utils.events INFO:  eta: 1 day, 16:52:00  iter: 11119  total_loss: 36.23  loss_mask: 3.608  loss_mask_0: 3.742  loss_mask_1: 3.585  loss_mask_2: 3.649  loss_mask_3: 3.615  loss_mask_4: 3.621  loss_mask_5: 3.603  loss_mask_6: 3.597  loss_mask_7: 3.613  loss_mask_8: 3.614  time: 3.0398  data_time: 0.0541  lr: 8.3155e-05  max_mem: 27646M
[01/29 05:49:45] d2.utils.events INFO:  eta: 1 day, 16:50:33  iter: 11139  total_loss: 32.98  loss_mask: 3.315  loss_mask_0: 3.471  loss_mask_1: 3.261  loss_mask_2: 3.264  loss_mask_3: 3.262  loss_mask_4: 3.28  loss_mask_5: 3.284  loss_mask_6: 3.297  loss_mask_7: 3.292  loss_mask_8: 3.313  time: 3.0397  data_time: 0.0561  lr: 8.3125e-05  max_mem: 27646M
[01/29 05:50:45] d2.utils.events INFO:  eta: 1 day, 16:48:57  iter: 11159  total_loss: 38.52  loss_mask: 3.826  loss_mask_0: 4.085  loss_mask_1: 3.825  loss_mask_2: 3.807  loss_mask_3: 3.845  loss_mask_4: 3.818  loss_mask_5: 3.808  loss_mask_6: 3.787  loss_mask_7: 3.822  loss_mask_8: 3.793  time: 3.0397  data_time: 0.0579  lr: 8.3094e-05  max_mem: 27646M
[01/29 05:51:46] d2.utils.events INFO:  eta: 1 day, 16:47:57  iter: 11179  total_loss: 34.89  loss_mask: 3.502  loss_mask_0: 3.771  loss_mask_1: 3.446  loss_mask_2: 3.56  loss_mask_3: 3.546  loss_mask_4: 3.481  loss_mask_5: 3.466  loss_mask_6: 3.499  loss_mask_7: 3.483  loss_mask_8: 3.545  time: 3.0396  data_time: 0.0662  lr: 8.3063e-05  max_mem: 27646M
[01/29 05:52:46] d2.utils.events INFO:  eta: 1 day, 16:46:24  iter: 11199  total_loss: 37.2  loss_mask: 3.667  loss_mask_0: 3.802  loss_mask_1: 3.613  loss_mask_2: 3.945  loss_mask_3: 3.666  loss_mask_4: 3.652  loss_mask_5: 3.621  loss_mask_6: 3.682  loss_mask_7: 3.667  loss_mask_8: 3.661  time: 3.0396  data_time: 0.0590  lr: 8.3033e-05  max_mem: 27646M
[01/29 05:53:46] d2.utils.events INFO:  eta: 1 day, 16:45:03  iter: 11219  total_loss: 36.76  loss_mask: 3.593  loss_mask_0: 3.763  loss_mask_1: 3.644  loss_mask_2: 4.141  loss_mask_3: 3.696  loss_mask_4: 3.568  loss_mask_5: 3.611  loss_mask_6: 3.58  loss_mask_7: 3.584  loss_mask_8: 3.583  time: 3.0396  data_time: 0.0575  lr: 8.3002e-05  max_mem: 27646M
[01/29 05:54:46] d2.utils.events INFO:  eta: 1 day, 16:43:55  iter: 11239  total_loss: 35.84  loss_mask: 3.502  loss_mask_0: 3.681  loss_mask_1: 3.583  loss_mask_2: 3.994  loss_mask_3: 3.641  loss_mask_4: 3.503  loss_mask_5: 3.485  loss_mask_6: 3.504  loss_mask_7: 3.489  loss_mask_8: 3.543  time: 3.0395  data_time: 0.0597  lr: 8.2972e-05  max_mem: 27646M
[01/29 05:55:47] d2.utils.events INFO:  eta: 1 day, 16:43:02  iter: 11259  total_loss: 33.99  loss_mask: 3.375  loss_mask_0: 3.407  loss_mask_1: 3.402  loss_mask_2: 3.497  loss_mask_3: 3.411  loss_mask_4: 3.389  loss_mask_5: 3.373  loss_mask_6: 3.37  loss_mask_7: 3.4  loss_mask_8: 3.366  time: 3.0395  data_time: 0.0668  lr: 8.2941e-05  max_mem: 27646M
[01/29 05:56:48] d2.utils.events INFO:  eta: 1 day, 16:41:52  iter: 11279  total_loss: 34.29  loss_mask: 3.412  loss_mask_0: 3.537  loss_mask_1: 3.414  loss_mask_2: 3.586  loss_mask_3: 3.401  loss_mask_4: 3.36  loss_mask_5: 3.408  loss_mask_6: 3.419  loss_mask_7: 3.419  loss_mask_8: 3.35  time: 3.0395  data_time: 0.0568  lr: 8.291e-05  max_mem: 27646M
[01/29 05:57:48] d2.utils.events INFO:  eta: 1 day, 16:39:56  iter: 11299  total_loss: 31.75  loss_mask: 3.142  loss_mask_0: 3.418  loss_mask_1: 3.151  loss_mask_2: 3.321  loss_mask_3: 3.242  loss_mask_4: 3.117  loss_mask_5: 3.148  loss_mask_6: 3.133  loss_mask_7: 3.148  loss_mask_8: 3.162  time: 3.0394  data_time: 0.0563  lr: 8.288e-05  max_mem: 27646M
[01/29 05:58:49] d2.utils.events INFO:  eta: 1 day, 16:38:56  iter: 11319  total_loss: 34.39  loss_mask: 3.397  loss_mask_0: 3.584  loss_mask_1: 3.436  loss_mask_2: 3.46  loss_mask_3: 3.403  loss_mask_4: 3.42  loss_mask_5: 3.437  loss_mask_6: 3.428  loss_mask_7: 3.407  loss_mask_8: 3.39  time: 3.0394  data_time: 0.0565  lr: 8.2849e-05  max_mem: 27646M
[01/29 05:59:49] d2.utils.events INFO:  eta: 1 day, 16:37:26  iter: 11339  total_loss: 33.14  loss_mask: 3.309  loss_mask_0: 3.445  loss_mask_1: 3.312  loss_mask_2: 3.471  loss_mask_3: 3.27  loss_mask_4: 3.281  loss_mask_5: 3.327  loss_mask_6: 3.37  loss_mask_7: 3.259  loss_mask_8: 3.269  time: 3.0394  data_time: 0.0694  lr: 8.2818e-05  max_mem: 27646M
[01/29 06:00:50] d2.utils.events INFO:  eta: 1 day, 16:36:56  iter: 11359  total_loss: 33.75  loss_mask: 3.371  loss_mask_0: 3.505  loss_mask_1: 3.333  loss_mask_2: 3.487  loss_mask_3: 3.375  loss_mask_4: 3.365  loss_mask_5: 3.344  loss_mask_6: 3.347  loss_mask_7: 3.362  loss_mask_8: 3.4  time: 3.0394  data_time: 0.0585  lr: 8.2788e-05  max_mem: 27646M
[01/29 06:01:50] d2.utils.events INFO:  eta: 1 day, 16:35:25  iter: 11379  total_loss: 31.72  loss_mask: 3.132  loss_mask_0: 3.314  loss_mask_1: 3.076  loss_mask_2: 3.253  loss_mask_3: 3.155  loss_mask_4: 3.148  loss_mask_5: 3.153  loss_mask_6: 3.135  loss_mask_7: 3.185  loss_mask_8: 3.168  time: 3.0393  data_time: 0.0634  lr: 8.2757e-05  max_mem: 27646M
[01/29 06:02:50] d2.utils.events INFO:  eta: 1 day, 16:34:17  iter: 11399  total_loss: 32.42  loss_mask: 3.215  loss_mask_0: 3.276  loss_mask_1: 3.196  loss_mask_2: 3.225  loss_mask_3: 3.239  loss_mask_4: 3.219  loss_mask_5: 3.221  loss_mask_6: 3.232  loss_mask_7: 3.227  loss_mask_8: 3.227  time: 3.0392  data_time: 0.0472  lr: 8.2726e-05  max_mem: 27646M
[01/29 06:03:50] d2.utils.events INFO:  eta: 1 day, 16:33:04  iter: 11419  total_loss: 32.57  loss_mask: 3.236  loss_mask_0: 3.281  loss_mask_1: 3.239  loss_mask_2: 3.341  loss_mask_3: 3.256  loss_mask_4: 3.246  loss_mask_5: 3.249  loss_mask_6: 3.276  loss_mask_7: 3.236  loss_mask_8: 3.28  time: 3.0391  data_time: 0.0520  lr: 8.2696e-05  max_mem: 27646M
[01/29 06:04:50] d2.utils.events INFO:  eta: 1 day, 16:32:04  iter: 11439  total_loss: 35.43  loss_mask: 3.509  loss_mask_0: 3.595  loss_mask_1: 3.534  loss_mask_2: 3.652  loss_mask_3: 3.515  loss_mask_4: 3.531  loss_mask_5: 3.503  loss_mask_6: 3.497  loss_mask_7: 3.551  loss_mask_8: 3.502  time: 3.0391  data_time: 0.0555  lr: 8.2665e-05  max_mem: 27646M
[01/29 06:05:50] d2.utils.events INFO:  eta: 1 day, 16:30:49  iter: 11459  total_loss: 34.61  loss_mask: 3.446  loss_mask_0: 3.519  loss_mask_1: 3.468  loss_mask_2: 3.635  loss_mask_3: 3.437  loss_mask_4: 3.437  loss_mask_5: 3.475  loss_mask_6: 3.442  loss_mask_7: 3.414  loss_mask_8: 3.48  time: 3.0390  data_time: 0.0562  lr: 8.2635e-05  max_mem: 27646M
[01/29 06:06:50] d2.utils.events INFO:  eta: 1 day, 16:29:20  iter: 11479  total_loss: 33.45  loss_mask: 3.343  loss_mask_0: 3.372  loss_mask_1: 3.285  loss_mask_2: 3.438  loss_mask_3: 3.418  loss_mask_4: 3.36  loss_mask_5: 3.347  loss_mask_6: 3.339  loss_mask_7: 3.346  loss_mask_8: 3.306  time: 3.0390  data_time: 0.0594  lr: 8.2604e-05  max_mem: 27646M
[01/29 06:07:50] d2.utils.events INFO:  eta: 1 day, 16:28:01  iter: 11499  total_loss: 33.67  loss_mask: 3.275  loss_mask_0: 3.451  loss_mask_1: 3.277  loss_mask_2: 3.409  loss_mask_3: 3.392  loss_mask_4: 3.373  loss_mask_5: 3.407  loss_mask_6: 3.406  loss_mask_7: 3.181  loss_mask_8: 3.448  time: 3.0389  data_time: 0.0544  lr: 8.2573e-05  max_mem: 27646M
[01/29 06:08:50] d2.utils.events INFO:  eta: 1 day, 16:26:54  iter: 11519  total_loss: 30.72  loss_mask: 3.036  loss_mask_0: 3.152  loss_mask_1: 3.026  loss_mask_2: 3.044  loss_mask_3: 3.061  loss_mask_4: 3.076  loss_mask_5: 3.028  loss_mask_6: 3.074  loss_mask_7: 2.99  loss_mask_8: 3.047  time: 3.0388  data_time: 0.0555  lr: 8.2543e-05  max_mem: 27646M
[01/29 06:09:50] d2.utils.events INFO:  eta: 1 day, 16:26:07  iter: 11539  total_loss: 33.48  loss_mask: 3.254  loss_mask_0: 3.46  loss_mask_1: 3.313  loss_mask_2: 3.286  loss_mask_3: 3.287  loss_mask_4: 3.3  loss_mask_5: 3.342  loss_mask_6: 3.281  loss_mask_7: 3.265  loss_mask_8: 3.304  time: 3.0387  data_time: 0.0533  lr: 8.2512e-05  max_mem: 27646M
[01/29 06:10:50] d2.utils.events INFO:  eta: 1 day, 16:23:33  iter: 11559  total_loss: 35.27  loss_mask: 3.482  loss_mask_0: 3.825  loss_mask_1: 3.463  loss_mask_2: 3.634  loss_mask_3: 3.429  loss_mask_4: 3.46  loss_mask_5: 3.48  loss_mask_6: 3.446  loss_mask_7: 3.462  loss_mask_8: 3.494  time: 3.0386  data_time: 0.0665  lr: 8.2481e-05  max_mem: 27646M
[01/29 06:11:49] d2.utils.events INFO:  eta: 1 day, 16:22:02  iter: 11579  total_loss: 32.56  loss_mask: 3.204  loss_mask_0: 3.787  loss_mask_1: 3.168  loss_mask_2: 3.171  loss_mask_3: 3.305  loss_mask_4: 3.277  loss_mask_5: 3.186  loss_mask_6: 3.207  loss_mask_7: 3.185  loss_mask_8: 3.269  time: 3.0385  data_time: 0.0565  lr: 8.2451e-05  max_mem: 27646M
[01/29 06:12:49] d2.utils.events INFO:  eta: 1 day, 16:20:58  iter: 11599  total_loss: 34.82  loss_mask: 3.497  loss_mask_0: 3.606  loss_mask_1: 3.479  loss_mask_2: 3.611  loss_mask_3: 3.473  loss_mask_4: 3.441  loss_mask_5: 3.458  loss_mask_6: 3.471  loss_mask_7: 3.493  loss_mask_8: 3.51  time: 3.0385  data_time: 0.0574  lr: 8.242e-05  max_mem: 27646M
[01/29 06:13:49] d2.utils.events INFO:  eta: 1 day, 16:19:57  iter: 11619  total_loss: 32.76  loss_mask: 3.285  loss_mask_0: 3.321  loss_mask_1: 3.29  loss_mask_2: 3.309  loss_mask_3: 3.286  loss_mask_4: 3.258  loss_mask_5: 3.242  loss_mask_6: 3.217  loss_mask_7: 3.279  loss_mask_8: 3.247  time: 3.0384  data_time: 0.0628  lr: 8.2389e-05  max_mem: 27646M
[01/29 06:14:49] d2.utils.events INFO:  eta: 1 day, 16:18:54  iter: 11639  total_loss: 32.66  loss_mask: 3.252  loss_mask_0: 3.386  loss_mask_1: 3.19  loss_mask_2: 3.332  loss_mask_3: 3.288  loss_mask_4: 3.186  loss_mask_5: 3.239  loss_mask_6: 3.226  loss_mask_7: 3.234  loss_mask_8: 3.253  time: 3.0383  data_time: 0.0608  lr: 8.2359e-05  max_mem: 27646M
[01/29 06:15:49] d2.utils.events INFO:  eta: 1 day, 16:17:28  iter: 11659  total_loss: 35.2  loss_mask: 3.21  loss_mask_0: 3.421  loss_mask_1: 3.217  loss_mask_2: 3.258  loss_mask_3: 3.279  loss_mask_4: 3.342  loss_mask_5: 3.395  loss_mask_6: 3.468  loss_mask_7: 3.346  loss_mask_8: 3.26  time: 3.0382  data_time: 0.0591  lr: 8.2328e-05  max_mem: 27646M
[01/29 06:16:49] d2.utils.events INFO:  eta: 1 day, 16:16:32  iter: 11679  total_loss: 33.63  loss_mask: 3.297  loss_mask_0: 3.356  loss_mask_1: 3.188  loss_mask_2: 3.399  loss_mask_3: 3.345  loss_mask_4: 3.25  loss_mask_5: 3.286  loss_mask_6: 3.594  loss_mask_7: 3.459  loss_mask_8: 3.248  time: 3.0382  data_time: 0.0640  lr: 8.2297e-05  max_mem: 27646M
[01/29 06:17:50] d2.utils.events INFO:  eta: 1 day, 16:15:40  iter: 11699  total_loss: 31.69  loss_mask: 3.146  loss_mask_0: 3.177  loss_mask_1: 3.155  loss_mask_2: 3.138  loss_mask_3: 3.146  loss_mask_4: 3.134  loss_mask_5: 3.143  loss_mask_6: 3.18  loss_mask_7: 3.146  loss_mask_8: 3.135  time: 3.0381  data_time: 0.0625  lr: 8.2267e-05  max_mem: 27646M
[01/29 06:18:49] d2.utils.events INFO:  eta: 1 day, 16:14:05  iter: 11719  total_loss: 32.22  loss_mask: 3.156  loss_mask_0: 3.274  loss_mask_1: 3.196  loss_mask_2: 3.218  loss_mask_3: 3.199  loss_mask_4: 3.232  loss_mask_5: 3.184  loss_mask_6: 3.277  loss_mask_7: 3.29  loss_mask_8: 3.19  time: 3.0380  data_time: 0.0525  lr: 8.2236e-05  max_mem: 27646M
[01/29 06:19:49] d2.utils.events INFO:  eta: 1 day, 16:12:45  iter: 11739  total_loss: 36.49  loss_mask: 3.495  loss_mask_0: 3.575  loss_mask_1: 3.471  loss_mask_2: 3.648  loss_mask_3: 3.608  loss_mask_4: 3.584  loss_mask_5: 3.657  loss_mask_6: 3.879  loss_mask_7: 3.654  loss_mask_8: 3.554  time: 3.0380  data_time: 0.0629  lr: 8.2205e-05  max_mem: 27646M
[01/29 06:20:49] d2.utils.events INFO:  eta: 1 day, 16:11:01  iter: 11759  total_loss: 34.35  loss_mask: 3.396  loss_mask_0: 3.497  loss_mask_1: 3.373  loss_mask_2: 3.431  loss_mask_3: 3.41  loss_mask_4: 3.395  loss_mask_5: 3.407  loss_mask_6: 3.616  loss_mask_7: 3.433  loss_mask_8: 3.402  time: 3.0379  data_time: 0.0577  lr: 8.2175e-05  max_mem: 27646M
[01/29 06:21:49] d2.utils.events INFO:  eta: 1 day, 16:10:26  iter: 11779  total_loss: 31.23  loss_mask: 3.104  loss_mask_0: 3.201  loss_mask_1: 3.052  loss_mask_2: 3.105  loss_mask_3: 3.116  loss_mask_4: 3.135  loss_mask_5: 3.105  loss_mask_6: 3.215  loss_mask_7: 3.135  loss_mask_8: 3.116  time: 3.0378  data_time: 0.0560  lr: 8.2144e-05  max_mem: 27646M
[01/29 06:22:49] d2.utils.events INFO:  eta: 1 day, 16:09:11  iter: 11799  total_loss: 36.37  loss_mask: 3.522  loss_mask_0: 3.721  loss_mask_1: 3.61  loss_mask_2: 3.59  loss_mask_3: 3.696  loss_mask_4: 3.728  loss_mask_5: 3.609  loss_mask_6: 3.616  loss_mask_7: 3.547  loss_mask_8: 3.596  time: 3.0377  data_time: 0.0618  lr: 8.2113e-05  max_mem: 27646M
[01/29 06:23:48] d2.utils.events INFO:  eta: 1 day, 16:07:35  iter: 11819  total_loss: 39.24  loss_mask: 3.911  loss_mask_0: 3.943  loss_mask_1: 3.783  loss_mask_2: 3.899  loss_mask_3: 3.849  loss_mask_4: 3.842  loss_mask_5: 4.026  loss_mask_6: 4.427  loss_mask_7: 3.958  loss_mask_8: 3.951  time: 3.0376  data_time: 0.0558  lr: 8.2083e-05  max_mem: 27646M
[01/29 06:24:48] d2.utils.events INFO:  eta: 1 day, 16:06:19  iter: 11839  total_loss: 33.76  loss_mask: 3.339  loss_mask_0: 3.323  loss_mask_1: 3.31  loss_mask_2: 3.418  loss_mask_3: 3.349  loss_mask_4: 3.366  loss_mask_5: 3.331  loss_mask_6: 3.583  loss_mask_7: 3.366  loss_mask_8: 3.332  time: 3.0375  data_time: 0.0614  lr: 8.2052e-05  max_mem: 27646M
[01/29 06:25:47] d2.utils.events INFO:  eta: 1 day, 16:04:01  iter: 11859  total_loss: 33.94  loss_mask: 3.406  loss_mask_0: 3.337  loss_mask_1: 3.34  loss_mask_2: 3.326  loss_mask_3: 3.377  loss_mask_4: 3.424  loss_mask_5: 3.356  loss_mask_6: 3.409  loss_mask_7: 3.367  loss_mask_8: 3.399  time: 3.0374  data_time: 0.0560  lr: 8.2021e-05  max_mem: 27646M
[01/29 06:26:47] d2.utils.events INFO:  eta: 1 day, 16:03:15  iter: 11879  total_loss: 33.79  loss_mask: 3.337  loss_mask_0: 3.426  loss_mask_1: 3.328  loss_mask_2: 3.473  loss_mask_3: 3.389  loss_mask_4: 3.363  loss_mask_5: 3.528  loss_mask_6: 3.519  loss_mask_7: 3.362  loss_mask_8: 3.441  time: 3.0373  data_time: 0.0580  lr: 8.1991e-05  max_mem: 27646M
[01/29 06:27:46] d2.utils.events INFO:  eta: 1 day, 16:01:56  iter: 11899  total_loss: 33.28  loss_mask: 3.284  loss_mask_0: 3.403  loss_mask_1: 3.31  loss_mask_2: 3.355  loss_mask_3: 3.311  loss_mask_4: 3.409  loss_mask_5: 3.283  loss_mask_6: 3.297  loss_mask_7: 3.313  loss_mask_8: 3.329  time: 3.0372  data_time: 0.0588  lr: 8.196e-05  max_mem: 27646M
[01/29 06:28:45] d2.utils.events INFO:  eta: 1 day, 15:59:30  iter: 11919  total_loss: 32.74  loss_mask: 3.226  loss_mask_0: 3.27  loss_mask_1: 3.216  loss_mask_2: 3.332  loss_mask_3: 3.249  loss_mask_4: 3.218  loss_mask_5: 3.334  loss_mask_6: 3.363  loss_mask_7: 3.347  loss_mask_8: 3.266  time: 3.0371  data_time: 0.0515  lr: 8.1929e-05  max_mem: 27646M
[01/29 06:29:45] d2.utils.events INFO:  eta: 1 day, 15:57:49  iter: 11939  total_loss: 31.79  loss_mask: 3.117  loss_mask_0: 3.295  loss_mask_1: 3.118  loss_mask_2: 3.171  loss_mask_3: 3.184  loss_mask_4: 3.181  loss_mask_5: 3.222  loss_mask_6: 3.131  loss_mask_7: 3.179  loss_mask_8: 3.193  time: 3.0370  data_time: 0.0586  lr: 8.1899e-05  max_mem: 27646M
[01/29 06:30:45] d2.utils.events INFO:  eta: 1 day, 15:56:42  iter: 11959  total_loss: 34.46  loss_mask: 3.421  loss_mask_0: 3.582  loss_mask_1: 3.434  loss_mask_2: 3.409  loss_mask_3: 3.408  loss_mask_4: 3.454  loss_mask_5: 3.441  loss_mask_6: 3.455  loss_mask_7: 3.411  loss_mask_8: 3.398  time: 3.0369  data_time: 0.0521  lr: 8.1868e-05  max_mem: 27646M
[01/29 06:31:44] d2.utils.events INFO:  eta: 1 day, 15:53:51  iter: 11979  total_loss: 33.8  loss_mask: 3.423  loss_mask_0: 3.41  loss_mask_1: 3.307  loss_mask_2: 3.381  loss_mask_3: 3.39  loss_mask_4: 3.389  loss_mask_5: 3.352  loss_mask_6: 3.375  loss_mask_7: 3.356  loss_mask_8: 3.286  time: 3.0368  data_time: 0.0472  lr: 8.1837e-05  max_mem: 27646M
[01/29 06:32:44] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 06:32:45] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 06:32:45] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 06:46:39] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.534455986868475, 'error_1pix': 0.5183990469251178, 'error_3pix': 0.2636274779251074, 'mIoU': 3.9089958483711476, 'fwIoU': 13.582554645075437, 'IoU-0': 8.074016533173875e-05, 'IoU-1': 58.06854860189464, 'IoU-2': 2.9434852935295406, 'IoU-3': 2.894891580785956, 'IoU-4': 1.8344817435515284, 'IoU-5': 1.6268849718583274, 'IoU-6': 1.7150362485087638, 'IoU-7': 1.7085372106840735, 'IoU-8': 4.056897290433608, 'IoU-9': 7.743170969765871, 'IoU-10': 10.334597016475552, 'IoU-11': 15.31603805276614, 'IoU-12': 17.604947635460288, 'IoU-13': 16.636374287235885, 'IoU-14': 16.049111906012392, 'IoU-15': 14.079486203925503, 'IoU-16': 12.723876890698305, 'IoU-17': 10.64934091200024, 'IoU-18': 10.728732407973274, 'IoU-19': 10.3315945529682, 'IoU-20': 9.30830172595639, 'IoU-21': 9.249341064432222, 'IoU-22': 8.993188064171147, 'IoU-23': 8.468649744271957, 'IoU-24': 8.156745783278195, 'IoU-25': 8.870659329597201, 'IoU-26': 9.18937277460005, 'IoU-27': 9.814246618473732, 'IoU-28': 9.988086984051666, 'IoU-29': 10.568757302142261, 'IoU-30': 11.022406874315212, 'IoU-31': 11.572578570843072, 'IoU-32': 11.79467453711507, 'IoU-33': 11.645729950797934, 'IoU-34': 11.632728659986036, 'IoU-35': 12.094277145837934, 'IoU-36': 12.023629990440392, 'IoU-37': 12.081438507961147, 'IoU-38': 12.642561160191883, 'IoU-39': 11.92811375828297, 'IoU-40': 11.909037005199869, 'IoU-41': 11.262905974835814, 'IoU-42': 10.67134389527126, 'IoU-43': 10.48246987047923, 'IoU-44': 10.463633602025798, 'IoU-45': 10.058047488696703, 'IoU-46': 9.283292090726944, 'IoU-47': 8.887865907195303, 'IoU-48': 8.885962926371322, 'IoU-49': 8.727163409127789, 'IoU-50': 8.363310778290879, 'IoU-51': 7.743069236837726, 'IoU-52': 7.097016150413375, 'IoU-53': 6.791252299379168, 'IoU-54': 6.622894549905613, 'IoU-55': 5.740984029581528, 'IoU-56': 4.9948265109713885, 'IoU-57': 4.640844177152924, 'IoU-58': 4.251196129045366, 'IoU-59': 3.871118847981158, 'IoU-60': 3.44615931030571, 'IoU-61': 3.202632552142416, 'IoU-62': 3.013020909054775, 'IoU-63': 2.7170159506053904, 'IoU-64': 2.5847784707261927, 'IoU-65': 2.4582038897681726, 'IoU-66': 2.2865177120568636, 'IoU-67': 2.3126631061108873, 'IoU-68': 2.1874976710306018, 'IoU-69': 2.2545158238146272, 'IoU-70': 2.2894017174735737, 'IoU-71': 2.1662957139536787, 'IoU-72': 2.108769952338739, 'IoU-73': 2.204006481161476, 'IoU-74': 2.18713425916934, 'IoU-75': 2.118949346048897, 'IoU-76': 2.233139096579449, 'IoU-77': 2.0353567694154955, 'IoU-78': 2.0161784011182524, 'IoU-79': 2.1821930837116903, 'IoU-80': 2.0293627953014948, 'IoU-81': 2.0737498284685145, 'IoU-82': 2.001976156610117, 'IoU-83': 2.097483896022255, 'IoU-84': 2.0975131200800265, 'IoU-85': 2.2210930018719757, 'IoU-86': 2.0005663435402337, 'IoU-87': 2.007697497369777, 'IoU-88': 1.9356209740753603, 'IoU-89': 1.9394987755343092, 'IoU-90': 1.8814134264006803, 'IoU-91': 1.7400329749329388, 'IoU-92': 1.7629939025550305, 'IoU-93': 1.8114563147632878, 'IoU-94': 1.8487480323202803, 'IoU-95': 1.7625332759431127, 'IoU-96': 1.6228048531683106, 'IoU-97': 1.6433845745362656, 'IoU-98': 1.6012377561110736, 'IoU-99': 1.479898156857027, 'IoU-100': 1.430774133118311, 'IoU-101': 1.4423732970265677, 'IoU-102': 1.3295238438857286, 'IoU-103': 1.3882729695124418, 'IoU-104': 1.413626375269274, 'IoU-105': 1.38060143370625, 'IoU-106': 1.4388620866203083, 'IoU-107': 1.530581052603519, 'IoU-108': 1.5957810142672162, 'IoU-109': 1.799153739734044, 'IoU-110': 1.6826018067692277, 'IoU-111': 1.4790663643028776, 'IoU-112': 1.3486450125590423, 'IoU-113': 1.2136617340358644, 'IoU-114': 1.122734456270426, 'IoU-115': 1.0888932661732842, 'IoU-116': 1.171510798234854, 'IoU-117': 1.1285017252999832, 'IoU-118': 1.1271622727445938, 'IoU-119': 1.1515206104971354, 'IoU-120': 1.163953547854291, 'IoU-121': 1.1674633337094593, 'IoU-122': 1.245604056406806, 'IoU-123': 1.2144375691923952, 'IoU-124': 1.0586866992171309, 'IoU-125': 0.912977730514971, 'IoU-126': 0.9737646242787903, 'IoU-127': 1.0765852939988687, 'IoU-128': 1.0386443047665581, 'IoU-129': 0.9681752148404416, 'IoU-130': 1.055344407222421, 'IoU-131': 1.181508529215856, 'IoU-132': 0.9539144034785381, 'IoU-133': 1.0813766647961527, 'IoU-134': 1.086978020481178, 'IoU-135': 1.099582752964711, 'IoU-136': 0.9750262813385051, 'IoU-137': 1.064329060826068, 'IoU-138': 0.8628431692609042, 'IoU-139': 0.8579091674270959, 'IoU-140': 0.9162620352940326, 'IoU-141': 0.8764542181685745, 'IoU-142': 0.8643731455282706, 'IoU-143': 0.8874655624442842, 'IoU-144': 0.8587121760848659, 'IoU-145': 0.9225572249220755, 'IoU-146': 1.011815165569327, 'IoU-147': 1.1752007345615096, 'IoU-148': 1.472445929830244, 'IoU-149': 1.3554112309783164, 'IoU-150': 1.0758326682661636, 'IoU-151': 1.071842819406492, 'IoU-152': 1.1061900977809667, 'IoU-153': 1.1032667132659575, 'IoU-154': 1.000678779425198, 'IoU-155': 0.8937472300645584, 'IoU-156': 0.8681504778733004, 'IoU-157': 0.8030316012859773, 'IoU-158': 0.6960180382809921, 'IoU-159': 0.8149846268310286, 'IoU-160': 0.8200683465783679, 'IoU-161': 0.8810424999078057, 'IoU-162': 0.8674218374812274, 'IoU-163': 0.9912857842794149, 'IoU-164': 1.0401850023892654, 'IoU-165': 1.2610369333476903, 'IoU-166': 1.1428664495114007, 'IoU-167': 0.8193813011874437, 'IoU-168': 0.5611500451482079, 'IoU-169': 0.5730661096174092, 'IoU-170': 0.6420400521071128, 'IoU-171': 0.5370483685056849, 'IoU-172': 0.8517060515906684, 'IoU-173': 0.37354668310288125, 'IoU-174': 0.43600365485192805, 'IoU-175': 0.09107187210327322, 'IoU-176': 0.04743833017077799, 'IoU-177': 0.019112297489281185, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 7.19827852451968, 'pACC': 19.987609340127694, 'ACC-0': 0.0003063003500586507, 'ACC-1': 59.01118883344406, 'ACC-2': 7.5257449087057875, 'ACC-3': 15.796381753017325, 'ACC-4': 8.490392725585561, 'ACC-5': 7.304744154042576, 'ACC-6': 7.7354497901996595, 'ACC-7': 8.419659363138148, 'ACC-8': 10.125176694238187, 'ACC-9': 12.417168428159924, 'ACC-10': 14.97452093497633, 'ACC-11': 21.03751722153399, 'ACC-12': 27.777044069009342, 'ACC-13': 27.594117044351513, 'ACC-14': 26.720173709484072, 'ACC-15': 24.58058253689865, 'ACC-16': 22.56569569353338, 'ACC-17': 20.01991453812851, 'ACC-18': 19.025831582161462, 'ACC-19': 18.373447183606846, 'ACC-20': 16.669257274723023, 'ACC-21': 16.494183392399133, 'ACC-22': 15.71651263794592, 'ACC-23': 15.93361962844626, 'ACC-24': 15.876012283552923, 'ACC-25': 16.963362515317474, 'ACC-26': 17.253828381759394, 'ACC-27': 17.900290040422956, 'ACC-28': 18.9023565206237, 'ACC-29': 19.46453037841106, 'ACC-30': 20.689820716952298, 'ACC-31': 21.448008008721168, 'ACC-32': 22.256542852720653, 'ACC-33': 22.443016424671296, 'ACC-34': 22.226981386618156, 'ACC-35': 22.54604214171872, 'ACC-36': 22.391383029167596, 'ACC-37': 22.94699252627804, 'ACC-38': 23.912118302815184, 'ACC-39': 22.45369401122317, 'ACC-40': 22.061736713631642, 'ACC-41': 21.51999801982538, 'ACC-42': 20.354364719582403, 'ACC-43': 19.910429591292598, 'ACC-44': 19.302622778452417, 'ACC-45': 18.7745591430083, 'ACC-46': 17.89182738307123, 'ACC-47': 17.183406981354423, 'ACC-48': 17.232271200669473, 'ACC-49': 16.82876701413471, 'ACC-50': 16.221939804131864, 'ACC-51': 15.347907920928675, 'ACC-52': 14.193757094448406, 'ACC-53': 13.783543832984654, 'ACC-54': 13.355221233941181, 'ACC-55': 11.561578620789149, 'ACC-56': 10.051670492344597, 'ACC-57': 9.09312550058434, 'ACC-58': 8.34848183855614, 'ACC-59': 7.62834574053125, 'ACC-60': 6.7768380018483985, 'ACC-61': 6.321442355976751, 'ACC-62': 5.938284906727756, 'ACC-63': 5.406093627105939, 'ACC-64': 5.115437658548423, 'ACC-65': 4.852862697074564, 'ACC-66': 4.534826009972891, 'ACC-67': 4.6061010935211675, 'ACC-68': 4.369382114738485, 'ACC-69': 4.4439812185925724, 'ACC-70': 4.492696742731585, 'ACC-71': 4.370643037377329, 'ACC-72': 4.2560918243801265, 'ACC-73': 4.425876072729715, 'ACC-74': 4.366802475783165, 'ACC-75': 4.262306181128029, 'ACC-76': 4.403946268659245, 'ACC-77': 4.031513824631758, 'ACC-78': 3.9964967180024376, 'ACC-79': 4.27254753298932, 'ACC-80': 3.922160121752944, 'ACC-81': 3.9700748019150884, 'ACC-82': 3.819293882140572, 'ACC-83': 3.9355135330474003, 'ACC-84': 3.93297594094508, 'ACC-85': 4.155921496958949, 'ACC-86': 3.737287195976253, 'ACC-87': 3.7486456250385394, 'ACC-88': 3.591176261360914, 'ACC-89': 3.568280713479324, 'ACC-90': 3.4308491791046327, 'ACC-91': 3.1921801675973853, 'ACC-92': 3.241582282233986, 'ACC-93': 3.3118731226735294, 'ACC-94': 3.3648653086843243, 'ACC-95': 3.192285051421448, 'ACC-96': 2.9353512957568264, 'ACC-97': 2.9501634100227894, 'ACC-98': 2.871877323779124, 'ACC-99': 2.6716147012473703, 'ACC-100': 2.586127201379884, 'ACC-101': 2.6217564149519146, 'ACC-102': 2.4376982328953334, 'ACC-103': 2.544464909795032, 'ACC-104': 2.604485870982022, 'ACC-105': 2.5635472504380608, 'ACC-106': 2.680241466124493, 'ACC-107': 2.87328281311872, 'ACC-108': 2.969936936685471, 'ACC-109': 3.3276776336212213, 'ACC-110': 3.155635861951018, 'ACC-111': 2.798882189589646, 'ACC-112': 2.6109096927073634, 'ACC-113': 2.3649090319571524, 'ACC-114': 2.221103011409998, 'ACC-115': 2.181678769563845, 'ACC-116': 2.334375112994839, 'ACC-117': 2.2040830103341005, 'ACC-118': 2.1982645147556554, 'ACC-119': 2.2316609172404296, 'ACC-120': 2.2187755862209526, 'ACC-121': 2.208730179998701, 'ACC-122': 2.372036193118024, 'ACC-123': 2.344232625244489, 'ACC-124': 2.088592995262375, 'ACC-125': 1.7724228623514324, 'ACC-126': 1.921864042477618, 'ACC-127': 2.16424553074975, 'ACC-128': 2.094851632717032, 'ACC-129': 1.929643019179083, 'ACC-130': 2.074976202330495, 'ACC-131': 2.2810329943318095, 'ACC-132': 1.8296790019201574, 'ACC-133': 2.054678941531092, 'ACC-134': 2.007893149504524, 'ACC-135': 2.0274642266689473, 'ACC-136': 1.87159313268729, 'ACC-137': 2.092630457397515, 'ACC-138': 1.666687818869457, 'ACC-139': 1.6486944487941408, 'ACC-140': 1.7846996870895016, 'ACC-141': 1.7436997066343063, 'ACC-142': 1.7544043505105842, 'ACC-143': 1.8195574797390133, 'ACC-144': 1.776173285198556, 'ACC-145': 1.842885574364364, 'ACC-146': 1.96696442850289, 'ACC-147': 2.2342042539204425, 'ACC-148': 2.851857942248047, 'ACC-149': 2.7520386504392693, 'ACC-150': 2.2410671569685086, 'ACC-151': 2.1834563772337345, 'ACC-152': 2.189860240070133, 'ACC-153': 2.2900291320837685, 'ACC-154': 2.14297372094962, 'ACC-155': 1.9735593337326793, 'ACC-156': 1.939795872197121, 'ACC-157': 1.8623091653702775, 'ACC-158': 1.5801262012191077, 'ACC-159': 1.8169084769214627, 'ACC-160': 1.7917533818938607, 'ACC-161': 1.8451065359458767, 'ACC-162': 1.9857126280493065, 'ACC-163': 2.2515657316862514, 'ACC-164': 2.3641310379599125, 'ACC-165': 2.9759201085040354, 'ACC-166': 2.945161209089154, 'ACC-167': 2.2344515145040447, 'ACC-168': 1.5788733384907518, 'ACC-169': 1.3916647511024, 'ACC-170': 1.3600806394366596, 'ACC-171': 1.0398432061189289, 'ACC-172': 1.6733340741563878, 'ACC-173': 0.5838127885668271, 'ACC-174': 0.7249091766530409, 'ACC-175': 0.1037200556871315, 'ACC-176': 0.05024524030647783, 'ACC-177': 0.02214557393023037, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 06:46:39] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 06:46:39] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 06:46:39] d2.evaluation.testing INFO: copypaste: 3.5345,0.5184,0.2636,3.9090,13.5826,7.1983,19.9876
[01/29 06:46:39] d2.utils.events INFO:  eta: 1 day, 15:53:36  iter: 11999  total_loss: 31.47  loss_mask: 3.138  loss_mask_0: 3.284  loss_mask_1: 3.14  loss_mask_2: 3.095  loss_mask_3: 3.141  loss_mask_4: 3.15  loss_mask_5: 3.053  loss_mask_6: 3.128  loss_mask_7: 3.295  loss_mask_8: 3.127  time: 3.0367  data_time: 0.0602  lr: 8.1807e-05  max_mem: 27646M
[01/29 06:47:39] d2.utils.events INFO:  eta: 1 day, 15:53:08  iter: 12019  total_loss: 31.62  loss_mask: 3.155  loss_mask_0: 3.12  loss_mask_1: 3.064  loss_mask_2: 3.152  loss_mask_3: 3.189  loss_mask_4: 3.16  loss_mask_5: 3.115  loss_mask_6: 3.144  loss_mask_7: 3.12  loss_mask_8: 3.149  time: 3.0366  data_time: 0.0662  lr: 8.1776e-05  max_mem: 27646M
[01/29 06:48:40] d2.utils.events INFO:  eta: 1 day, 15:52:30  iter: 12039  total_loss: 34.22  loss_mask: 3.405  loss_mask_0: 3.542  loss_mask_1: 3.375  loss_mask_2: 3.412  loss_mask_3: 3.456  loss_mask_4: 3.426  loss_mask_5: 3.344  loss_mask_6: 3.404  loss_mask_7: 3.488  loss_mask_8: 3.371  time: 3.0366  data_time: 0.0693  lr: 8.1745e-05  max_mem: 27646M
[01/29 06:49:40] d2.utils.events INFO:  eta: 1 day, 15:51:35  iter: 12059  total_loss: 32.53  loss_mask: 3.259  loss_mask_0: 3.313  loss_mask_1: 3.247  loss_mask_2: 3.261  loss_mask_3: 3.273  loss_mask_4: 3.26  loss_mask_5: 3.256  loss_mask_6: 3.277  loss_mask_7: 3.22  loss_mask_8: 3.245  time: 3.0366  data_time: 0.0656  lr: 8.1715e-05  max_mem: 27646M
[01/29 06:50:41] d2.utils.events INFO:  eta: 1 day, 15:50:24  iter: 12079  total_loss: 34.58  loss_mask: 3.455  loss_mask_0: 3.52  loss_mask_1: 3.431  loss_mask_2: 3.443  loss_mask_3: 3.545  loss_mask_4: 3.447  loss_mask_5: 3.431  loss_mask_6: 3.444  loss_mask_7: 3.499  loss_mask_8: 3.458  time: 3.0365  data_time: 0.0693  lr: 8.1684e-05  max_mem: 27646M
[01/29 06:51:41] d2.utils.events INFO:  eta: 1 day, 15:49:31  iter: 12099  total_loss: 33.2  loss_mask: 3.329  loss_mask_0: 3.375  loss_mask_1: 3.295  loss_mask_2: 3.307  loss_mask_3: 3.337  loss_mask_4: 3.346  loss_mask_5: 3.326  loss_mask_6: 3.405  loss_mask_7: 3.34  loss_mask_8: 3.311  time: 3.0365  data_time: 0.0553  lr: 8.1653e-05  max_mem: 27646M
[01/29 06:52:41] d2.utils.events INFO:  eta: 1 day, 15:48:50  iter: 12119  total_loss: 33.93  loss_mask: 3.481  loss_mask_0: 3.394  loss_mask_1: 3.362  loss_mask_2: 3.381  loss_mask_3: 3.379  loss_mask_4: 3.433  loss_mask_5: 3.334  loss_mask_6: 3.328  loss_mask_7: 3.43  loss_mask_8: 3.344  time: 3.0365  data_time: 0.0639  lr: 8.1623e-05  max_mem: 27646M
[01/29 06:53:42] d2.utils.events INFO:  eta: 1 day, 15:48:40  iter: 12139  total_loss: 39.65  loss_mask: 3.962  loss_mask_0: 4.053  loss_mask_1: 3.915  loss_mask_2: 4.017  loss_mask_3: 4.074  loss_mask_4: 3.99  loss_mask_5: 3.904  loss_mask_6: 4.064  loss_mask_7: 3.928  loss_mask_8: 4.001  time: 3.0365  data_time: 0.0572  lr: 8.1592e-05  max_mem: 27646M
[01/29 06:54:42] d2.utils.events INFO:  eta: 1 day, 15:47:15  iter: 12159  total_loss: 31.61  loss_mask: 3.147  loss_mask_0: 3.274  loss_mask_1: 3.162  loss_mask_2: 3.171  loss_mask_3: 3.143  loss_mask_4: 3.156  loss_mask_5: 3.154  loss_mask_6: 3.156  loss_mask_7: 3.229  loss_mask_8: 3.139  time: 3.0364  data_time: 0.0659  lr: 8.1561e-05  max_mem: 27646M
[01/29 06:55:42] d2.utils.events INFO:  eta: 1 day, 15:45:40  iter: 12179  total_loss: 29.82  loss_mask: 2.939  loss_mask_0: 3.135  loss_mask_1: 2.957  loss_mask_2: 2.971  loss_mask_3: 3.006  loss_mask_4: 2.974  loss_mask_5: 2.934  loss_mask_6: 2.974  loss_mask_7: 3.006  loss_mask_8: 2.977  time: 3.0363  data_time: 0.0502  lr: 8.1531e-05  max_mem: 27646M
[01/29 06:56:42] d2.utils.events INFO:  eta: 1 day, 15:44:12  iter: 12199  total_loss: 33.9  loss_mask: 3.365  loss_mask_0: 3.49  loss_mask_1: 3.362  loss_mask_2: 3.396  loss_mask_3: 3.362  loss_mask_4: 3.423  loss_mask_5: 3.375  loss_mask_6: 3.399  loss_mask_7: 3.42  loss_mask_8: 3.418  time: 3.0362  data_time: 0.0576  lr: 8.15e-05  max_mem: 27646M
[01/29 06:57:42] d2.utils.events INFO:  eta: 1 day, 15:43:31  iter: 12219  total_loss: 32.98  loss_mask: 3.303  loss_mask_0: 3.212  loss_mask_1: 3.239  loss_mask_2: 3.304  loss_mask_3: 3.265  loss_mask_4: 3.327  loss_mask_5: 3.283  loss_mask_6: 3.306  loss_mask_7: 3.318  loss_mask_8: 3.241  time: 3.0362  data_time: 0.0542  lr: 8.1469e-05  max_mem: 27646M
[01/29 06:58:42] d2.utils.events INFO:  eta: 1 day, 15:42:58  iter: 12239  total_loss: 34.11  loss_mask: 3.411  loss_mask_0: 3.373  loss_mask_1: 3.402  loss_mask_2: 3.434  loss_mask_3: 3.417  loss_mask_4: 3.392  loss_mask_5: 3.375  loss_mask_6: 3.47  loss_mask_7: 3.476  loss_mask_8: 3.413  time: 3.0362  data_time: 0.0582  lr: 8.1439e-05  max_mem: 27646M
[01/29 06:59:42] d2.utils.events INFO:  eta: 1 day, 15:40:39  iter: 12259  total_loss: 35.32  loss_mask: 3.5  loss_mask_0: 3.847  loss_mask_1: 3.503  loss_mask_2: 3.484  loss_mask_3: 3.509  loss_mask_4: 3.51  loss_mask_5: 3.492  loss_mask_6: 3.572  loss_mask_7: 3.594  loss_mask_8: 3.502  time: 3.0361  data_time: 0.0554  lr: 8.1408e-05  max_mem: 27646M
[01/29 07:00:41] d2.utils.events INFO:  eta: 1 day, 15:38:34  iter: 12279  total_loss: 34.9  loss_mask: 3.446  loss_mask_0: 3.308  loss_mask_1: 3.355  loss_mask_2: 3.543  loss_mask_3: 3.507  loss_mask_4: 3.524  loss_mask_5: 3.469  loss_mask_6: 3.496  loss_mask_7: 3.46  loss_mask_8: 3.553  time: 3.0360  data_time: 0.0533  lr: 8.1377e-05  max_mem: 27646M
[01/29 07:01:41] d2.utils.events INFO:  eta: 1 day, 15:36:41  iter: 12299  total_loss: 32.97  loss_mask: 3.308  loss_mask_0: 3.35  loss_mask_1: 3.265  loss_mask_2: 3.29  loss_mask_3: 3.288  loss_mask_4: 3.285  loss_mask_5: 3.342  loss_mask_6: 3.287  loss_mask_7: 3.294  loss_mask_8: 3.263  time: 3.0359  data_time: 0.0540  lr: 8.1346e-05  max_mem: 27646M
[01/29 07:02:40] d2.utils.events INFO:  eta: 1 day, 15:34:21  iter: 12319  total_loss: 33.95  loss_mask: 3.393  loss_mask_0: 3.423  loss_mask_1: 3.375  loss_mask_2: 3.409  loss_mask_3: 3.43  loss_mask_4: 3.399  loss_mask_5: 3.4  loss_mask_6: 3.418  loss_mask_7: 3.432  loss_mask_8: 3.386  time: 3.0358  data_time: 0.0555  lr: 8.1316e-05  max_mem: 27646M
[01/29 07:03:40] d2.utils.events INFO:  eta: 1 day, 15:32:20  iter: 12339  total_loss: 34.86  loss_mask: 3.492  loss_mask_0: 3.488  loss_mask_1: 3.423  loss_mask_2: 3.423  loss_mask_3: 3.495  loss_mask_4: 3.4  loss_mask_5: 3.463  loss_mask_6: 3.4  loss_mask_7: 3.441  loss_mask_8: 3.434  time: 3.0357  data_time: 0.0610  lr: 8.1285e-05  max_mem: 27646M
[01/29 07:04:39] d2.utils.events INFO:  eta: 1 day, 15:30:36  iter: 12359  total_loss: 35.11  loss_mask: 3.508  loss_mask_0: 3.536  loss_mask_1: 3.482  loss_mask_2: 3.503  loss_mask_3: 3.517  loss_mask_4: 3.563  loss_mask_5: 3.493  loss_mask_6: 3.522  loss_mask_7: 3.512  loss_mask_8: 3.545  time: 3.0356  data_time: 0.0612  lr: 8.1254e-05  max_mem: 27646M
[01/29 07:05:39] d2.utils.events INFO:  eta: 1 day, 15:29:25  iter: 12379  total_loss: 34.14  loss_mask: 3.406  loss_mask_0: 3.456  loss_mask_1: 3.347  loss_mask_2: 3.336  loss_mask_3: 3.365  loss_mask_4: 3.375  loss_mask_5: 3.426  loss_mask_6: 3.629  loss_mask_7: 3.414  loss_mask_8: 3.389  time: 3.0355  data_time: 0.0584  lr: 8.1224e-05  max_mem: 27646M
[01/29 07:06:39] d2.utils.events INFO:  eta: 1 day, 15:28:26  iter: 12399  total_loss: 32.6  loss_mask: 3.197  loss_mask_0: 3.117  loss_mask_1: 3.198  loss_mask_2: 3.252  loss_mask_3: 3.246  loss_mask_4: 3.318  loss_mask_5: 3.296  loss_mask_6: 3.359  loss_mask_7: 3.235  loss_mask_8: 3.259  time: 3.0355  data_time: 0.0617  lr: 8.1193e-05  max_mem: 27646M
[01/29 07:07:39] d2.utils.events INFO:  eta: 1 day, 15:27:27  iter: 12419  total_loss: 35.11  loss_mask: 3.515  loss_mask_0: 3.539  loss_mask_1: 3.495  loss_mask_2: 3.503  loss_mask_3: 3.475  loss_mask_4: 3.509  loss_mask_5: 3.494  loss_mask_6: 3.527  loss_mask_7: 3.492  loss_mask_8: 3.5  time: 3.0354  data_time: 0.0565  lr: 8.1162e-05  max_mem: 27646M
[01/29 07:08:39] d2.utils.events INFO:  eta: 1 day, 15:26:30  iter: 12439  total_loss: 35.21  loss_mask: 3.487  loss_mask_0: 3.599  loss_mask_1: 3.459  loss_mask_2: 3.452  loss_mask_3: 3.558  loss_mask_4: 3.474  loss_mask_5: 3.551  loss_mask_6: 3.617  loss_mask_7: 3.466  loss_mask_8: 3.543  time: 3.0353  data_time: 0.0560  lr: 8.1132e-05  max_mem: 27646M
[01/29 07:09:39] d2.utils.events INFO:  eta: 1 day, 15:25:09  iter: 12459  total_loss: 32.73  loss_mask: 3.221  loss_mask_0: 3.388  loss_mask_1: 3.221  loss_mask_2: 3.276  loss_mask_3: 3.227  loss_mask_4: 3.212  loss_mask_5: 3.265  loss_mask_6: 3.341  loss_mask_7: 3.304  loss_mask_8: 3.279  time: 3.0352  data_time: 0.0569  lr: 8.1101e-05  max_mem: 27646M
[01/29 07:10:38] d2.utils.events INFO:  eta: 1 day, 15:22:22  iter: 12479  total_loss: 35  loss_mask: 3.48  loss_mask_0: 3.641  loss_mask_1: 3.461  loss_mask_2: 3.502  loss_mask_3: 3.491  loss_mask_4: 3.431  loss_mask_5: 3.493  loss_mask_6: 3.511  loss_mask_7: 3.48  loss_mask_8: 3.494  time: 3.0351  data_time: 0.0532  lr: 8.107e-05  max_mem: 27646M
[01/29 07:11:38] d2.utils.events INFO:  eta: 1 day, 15:21:07  iter: 12499  total_loss: 33.3  loss_mask: 3.248  loss_mask_0: 3.392  loss_mask_1: 3.312  loss_mask_2: 3.312  loss_mask_3: 3.315  loss_mask_4: 3.285  loss_mask_5: 3.312  loss_mask_6: 3.394  loss_mask_7: 3.31  loss_mask_8: 3.322  time: 3.0350  data_time: 0.0619  lr: 8.1039e-05  max_mem: 27646M
[01/29 07:12:37] d2.utils.events INFO:  eta: 1 day, 15:19:57  iter: 12519  total_loss: 32.53  loss_mask: 3.227  loss_mask_0: 3.291  loss_mask_1: 3.228  loss_mask_2: 3.234  loss_mask_3: 3.268  loss_mask_4: 3.217  loss_mask_5: 3.253  loss_mask_6: 3.227  loss_mask_7: 3.231  loss_mask_8: 3.303  time: 3.0349  data_time: 0.0576  lr: 8.1009e-05  max_mem: 27646M
[01/29 07:13:37] d2.utils.events INFO:  eta: 1 day, 15:18:45  iter: 12539  total_loss: 35.81  loss_mask: 3.663  loss_mask_0: 3.585  loss_mask_1: 3.503  loss_mask_2: 3.661  loss_mask_3: 3.637  loss_mask_4: 3.553  loss_mask_5: 3.552  loss_mask_6: 3.659  loss_mask_7: 3.586  loss_mask_8: 3.555  time: 3.0348  data_time: 0.0613  lr: 8.0978e-05  max_mem: 27646M
[01/29 07:14:36] d2.utils.events INFO:  eta: 1 day, 15:17:34  iter: 12559  total_loss: 31.83  loss_mask: 3.134  loss_mask_0: 3.263  loss_mask_1: 3.112  loss_mask_2: 3.23  loss_mask_3: 3.209  loss_mask_4: 3.145  loss_mask_5: 3.158  loss_mask_6: 3.165  loss_mask_7: 3.191  loss_mask_8: 3.161  time: 3.0347  data_time: 0.0585  lr: 8.0947e-05  max_mem: 27646M
[01/29 07:15:35] d2.utils.events INFO:  eta: 1 day, 15:15:19  iter: 12579  total_loss: 32.06  loss_mask: 3.174  loss_mask_0: 3.261  loss_mask_1: 3.113  loss_mask_2: 3.232  loss_mask_3: 3.161  loss_mask_4: 3.222  loss_mask_5: 3.131  loss_mask_6: 3.184  loss_mask_7: 3.202  loss_mask_8: 3.388  time: 3.0346  data_time: 0.0597  lr: 8.0917e-05  max_mem: 27646M
[01/29 07:16:35] d2.utils.events INFO:  eta: 1 day, 15:14:20  iter: 12599  total_loss: 33.95  loss_mask: 3.429  loss_mask_0: 3.449  loss_mask_1: 3.331  loss_mask_2: 3.333  loss_mask_3: 3.418  loss_mask_4: 3.367  loss_mask_5: 3.373  loss_mask_6: 3.341  loss_mask_7: 3.405  loss_mask_8: 3.356  time: 3.0345  data_time: 0.0585  lr: 8.0886e-05  max_mem: 27646M
[01/29 07:17:34] d2.utils.events INFO:  eta: 1 day, 15:12:54  iter: 12619  total_loss: 31.54  loss_mask: 3.156  loss_mask_0: 3.144  loss_mask_1: 3.127  loss_mask_2: 3.11  loss_mask_3: 3.144  loss_mask_4: 3.154  loss_mask_5: 3.153  loss_mask_6: 3.141  loss_mask_7: 3.122  loss_mask_8: 3.134  time: 3.0344  data_time: 0.0558  lr: 8.0855e-05  max_mem: 27646M
[01/29 07:18:33] d2.utils.events INFO:  eta: 1 day, 15:10:53  iter: 12639  total_loss: 35.85  loss_mask: 3.558  loss_mask_0: 3.607  loss_mask_1: 3.573  loss_mask_2: 3.588  loss_mask_3: 3.598  loss_mask_4: 3.641  loss_mask_5: 3.705  loss_mask_6: 3.593  loss_mask_7: 3.574  loss_mask_8: 3.616  time: 3.0343  data_time: 0.0604  lr: 8.0824e-05  max_mem: 27646M
[01/29 07:19:33] d2.utils.events INFO:  eta: 1 day, 15:09:31  iter: 12659  total_loss: 31.99  loss_mask: 3.151  loss_mask_0: 3.304  loss_mask_1: 3.234  loss_mask_2: 3.145  loss_mask_3: 3.29  loss_mask_4: 3.175  loss_mask_5: 3.227  loss_mask_6: 3.194  loss_mask_7: 3.182  loss_mask_8: 3.156  time: 3.0342  data_time: 0.0589  lr: 8.0794e-05  max_mem: 27646M
[01/29 07:20:32] d2.utils.events INFO:  eta: 1 day, 15:08:11  iter: 12679  total_loss: 30.15  loss_mask: 3.012  loss_mask_0: 3.094  loss_mask_1: 2.998  loss_mask_2: 2.982  loss_mask_3: 3.061  loss_mask_4: 3.018  loss_mask_5: 2.999  loss_mask_6: 3.019  loss_mask_7: 2.987  loss_mask_8: 3.002  time: 3.0341  data_time: 0.0566  lr: 8.0763e-05  max_mem: 27646M
[01/29 07:21:31] d2.utils.events INFO:  eta: 1 day, 15:05:25  iter: 12699  total_loss: 31.58  loss_mask: 3.158  loss_mask_0: 3.208  loss_mask_1: 3.165  loss_mask_2: 3.167  loss_mask_3: 3.127  loss_mask_4: 3.157  loss_mask_5: 3.145  loss_mask_6: 3.127  loss_mask_7: 3.198  loss_mask_8: 3.172  time: 3.0339  data_time: 0.0521  lr: 8.0732e-05  max_mem: 27646M
[01/29 07:22:30] d2.utils.events INFO:  eta: 1 day, 15:04:12  iter: 12719  total_loss: 28.66  loss_mask: 2.882  loss_mask_0: 3  loss_mask_1: 2.85  loss_mask_2: 2.866  loss_mask_3: 2.911  loss_mask_4: 2.868  loss_mask_5: 2.886  loss_mask_6: 2.872  loss_mask_7: 2.858  loss_mask_8: 2.841  time: 3.0338  data_time: 0.0532  lr: 8.0702e-05  max_mem: 27646M
[01/29 07:23:30] d2.utils.events INFO:  eta: 1 day, 15:02:45  iter: 12739  total_loss: 35.95  loss_mask: 3.6  loss_mask_0: 3.736  loss_mask_1: 3.599  loss_mask_2: 3.622  loss_mask_3: 3.6  loss_mask_4: 3.611  loss_mask_5: 3.588  loss_mask_6: 3.592  loss_mask_7: 3.567  loss_mask_8: 3.576  time: 3.0337  data_time: 0.0543  lr: 8.0671e-05  max_mem: 27646M
[01/29 07:24:29] d2.utils.events INFO:  eta: 1 day, 15:01:53  iter: 12759  total_loss: 31.08  loss_mask: 3.091  loss_mask_0: 3.221  loss_mask_1: 3.09  loss_mask_2: 3.134  loss_mask_3: 3.096  loss_mask_4: 3.089  loss_mask_5: 3.097  loss_mask_6: 3.118  loss_mask_7: 3.122  loss_mask_8: 3.096  time: 3.0336  data_time: 0.0593  lr: 8.064e-05  max_mem: 27646M
[01/29 07:25:29] d2.utils.events INFO:  eta: 1 day, 15:00:30  iter: 12779  total_loss: 34.03  loss_mask: 3.409  loss_mask_0: 3.462  loss_mask_1: 3.417  loss_mask_2: 3.402  loss_mask_3: 3.379  loss_mask_4: 3.398  loss_mask_5: 3.387  loss_mask_6: 3.375  loss_mask_7: 3.388  loss_mask_8: 3.41  time: 3.0335  data_time: 0.0687  lr: 8.0609e-05  max_mem: 27646M
[01/29 07:26:28] d2.utils.events INFO:  eta: 1 day, 14:59:47  iter: 12799  total_loss: 30.39  loss_mask: 3.033  loss_mask_0: 3.185  loss_mask_1: 2.989  loss_mask_2: 3.002  loss_mask_3: 3.005  loss_mask_4: 3.015  loss_mask_5: 2.996  loss_mask_6: 2.991  loss_mask_7: 3.012  loss_mask_8: 3.016  time: 3.0334  data_time: 0.0606  lr: 8.0579e-05  max_mem: 27646M
[01/29 07:27:28] d2.utils.events INFO:  eta: 1 day, 14:58:20  iter: 12819  total_loss: 31.19  loss_mask: 3.069  loss_mask_0: 3.086  loss_mask_1: 3.075  loss_mask_2: 3.141  loss_mask_3: 3.153  loss_mask_4: 3.065  loss_mask_5: 3.147  loss_mask_6: 3.116  loss_mask_7: 3.078  loss_mask_8: 3.12  time: 3.0333  data_time: 0.0576  lr: 8.0548e-05  max_mem: 27646M
[01/29 07:28:27] d2.utils.events INFO:  eta: 1 day, 14:57:21  iter: 12839  total_loss: 29.59  loss_mask: 2.969  loss_mask_0: 3.021  loss_mask_1: 2.966  loss_mask_2: 2.955  loss_mask_3: 2.945  loss_mask_4: 2.976  loss_mask_5: 2.938  loss_mask_6: 2.97  loss_mask_7: 2.967  loss_mask_8: 2.946  time: 3.0332  data_time: 0.0566  lr: 8.0517e-05  max_mem: 27646M
[01/29 07:29:27] d2.utils.events INFO:  eta: 1 day, 14:56:32  iter: 12859  total_loss: 29.47  loss_mask: 2.982  loss_mask_0: 2.937  loss_mask_1: 2.928  loss_mask_2: 2.935  loss_mask_3: 2.948  loss_mask_4: 2.924  loss_mask_5: 2.962  loss_mask_6: 2.954  loss_mask_7: 2.931  loss_mask_8: 2.959  time: 3.0331  data_time: 0.0633  lr: 8.0486e-05  max_mem: 27646M
[01/29 07:30:26] d2.utils.events INFO:  eta: 1 day, 14:55:21  iter: 12879  total_loss: 30.8  loss_mask: 3.065  loss_mask_0: 3.181  loss_mask_1: 3.045  loss_mask_2: 3.06  loss_mask_3: 3.096  loss_mask_4: 3.068  loss_mask_5: 3.067  loss_mask_6: 3.078  loss_mask_7: 3.058  loss_mask_8: 3.08  time: 3.0330  data_time: 0.0617  lr: 8.0456e-05  max_mem: 27646M
[01/29 07:31:25] d2.utils.events INFO:  eta: 1 day, 14:54:19  iter: 12899  total_loss: 29.17  loss_mask: 2.955  loss_mask_0: 2.911  loss_mask_1: 2.883  loss_mask_2: 2.928  loss_mask_3: 2.983  loss_mask_4: 2.935  loss_mask_5: 2.918  loss_mask_6: 2.972  loss_mask_7: 2.918  loss_mask_8: 2.844  time: 3.0329  data_time: 0.0625  lr: 8.0425e-05  max_mem: 27646M
[01/29 07:32:25] d2.utils.events INFO:  eta: 1 day, 14:53:34  iter: 12919  total_loss: 31.9  loss_mask: 3.128  loss_mask_0: 3.335  loss_mask_1: 3.19  loss_mask_2: 3.141  loss_mask_3: 3.152  loss_mask_4: 3.179  loss_mask_5: 3.194  loss_mask_6: 3.146  loss_mask_7: 3.281  loss_mask_8: 3.243  time: 3.0328  data_time: 0.0600  lr: 8.0394e-05  max_mem: 27646M
[01/29 07:33:24] d2.utils.events INFO:  eta: 1 day, 14:52:20  iter: 12939  total_loss: 35.6  loss_mask: 3.479  loss_mask_0: 3.619  loss_mask_1: 3.588  loss_mask_2: 3.493  loss_mask_3: 3.504  loss_mask_4: 3.56  loss_mask_5: 3.493  loss_mask_6: 3.55  loss_mask_7: 3.502  loss_mask_8: 3.566  time: 3.0327  data_time: 0.0539  lr: 8.0364e-05  max_mem: 27646M
[01/29 07:34:23] d2.utils.events INFO:  eta: 1 day, 14:51:16  iter: 12959  total_loss: 31.65  loss_mask: 3.188  loss_mask_0: 3.25  loss_mask_1: 3.067  loss_mask_2: 3.203  loss_mask_3: 3.141  loss_mask_4: 3.097  loss_mask_5: 3.122  loss_mask_6: 3.189  loss_mask_7: 3.219  loss_mask_8: 3.185  time: 3.0326  data_time: 0.0638  lr: 8.0333e-05  max_mem: 27646M
[01/29 07:35:23] d2.utils.events INFO:  eta: 1 day, 14:50:17  iter: 12979  total_loss: 28.84  loss_mask: 2.836  loss_mask_0: 2.996  loss_mask_1: 2.871  loss_mask_2: 2.881  loss_mask_3: 2.955  loss_mask_4: 2.92  loss_mask_5: 2.859  loss_mask_6: 2.855  loss_mask_7: 2.938  loss_mask_8: 2.909  time: 3.0325  data_time: 0.0626  lr: 8.0302e-05  max_mem: 27646M
[01/29 07:36:22] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 07:36:23] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 07:36:23] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 07:50:31] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.1259669174573035, 'error_1pix': 0.4959704590272478, 'error_3pix': 0.21353634248640835, 'mIoU': 4.956865632920295, 'fwIoU': 11.652019457869804, 'IoU-0': 0.00024655978967950417, 'IoU-1': 35.99912520406409, 'IoU-2': 2.367232091199235, 'IoU-3': 2.700985073095152, 'IoU-4': 1.9116244833769143, 'IoU-5': 1.7860973434342293, 'IoU-6': 1.6319058103106778, 'IoU-7': 1.4905342334220706, 'IoU-8': 2.0039272589224857, 'IoU-9': 3.4285229092396357, 'IoU-10': 6.432684857655749, 'IoU-11': 15.640333343413063, 'IoU-12': 18.558096445128353, 'IoU-13': 19.134039611512755, 'IoU-14': 18.945620421053917, 'IoU-15': 17.972319304053148, 'IoU-16': 16.903398644518706, 'IoU-17': 14.073131221920804, 'IoU-18': 13.203454924580887, 'IoU-19': 11.927537356142194, 'IoU-20': 11.621731775908893, 'IoU-21': 10.823602562390066, 'IoU-22': 11.649256461351541, 'IoU-23': 10.118560121852989, 'IoU-24': 9.228871985595323, 'IoU-25': 8.389117308544494, 'IoU-26': 8.317694609830683, 'IoU-27': 8.009104947401948, 'IoU-28': 7.47614750577389, 'IoU-29': 7.628995371639034, 'IoU-30': 7.592426842110267, 'IoU-31': 7.678907004033894, 'IoU-32': 7.543459291762241, 'IoU-33': 7.24734554804915, 'IoU-34': 7.601208271512876, 'IoU-35': 7.829320540877695, 'IoU-36': 8.070734930912966, 'IoU-37': 8.01935995210809, 'IoU-38': 7.802454900569322, 'IoU-39': 7.9009186103176585, 'IoU-40': 8.360120169934326, 'IoU-41': 8.260692289550182, 'IoU-42': 8.447543291868705, 'IoU-43': 8.647463476643761, 'IoU-44': 8.894960624403597, 'IoU-45': 9.19168030898206, 'IoU-46': 8.894175512484411, 'IoU-47': 8.627162783249698, 'IoU-48': 8.83548856708404, 'IoU-49': 8.564445734497005, 'IoU-50': 8.701245506795445, 'IoU-51': 8.533195784754003, 'IoU-52': 8.400635076234037, 'IoU-53': 8.365136079771366, 'IoU-54': 8.848297990085147, 'IoU-55': 8.555627417933428, 'IoU-56': 7.983034222396318, 'IoU-57': 7.887583927417249, 'IoU-58': 7.921271529336736, 'IoU-59': 7.554072957707121, 'IoU-60': 7.455056774420591, 'IoU-61': 6.725565570886944, 'IoU-62': 6.7228326042399225, 'IoU-63': 6.633569552257878, 'IoU-64': 6.572116404289688, 'IoU-65': 6.512709095110791, 'IoU-66': 6.526143022343919, 'IoU-67': 6.158729961027747, 'IoU-68': 6.063390395189695, 'IoU-69': 6.155655553896247, 'IoU-70': 6.066773575152533, 'IoU-71': 6.003002637976035, 'IoU-72': 5.977253516706449, 'IoU-73': 6.059412001840489, 'IoU-74': 5.967650507818146, 'IoU-75': 6.119564324698381, 'IoU-76': 5.921703979856317, 'IoU-77': 5.741632100321413, 'IoU-78': 5.570536571536143, 'IoU-79': 5.331979595579635, 'IoU-80': 5.3968631680235095, 'IoU-81': 5.36193684159765, 'IoU-82': 5.204056982819093, 'IoU-83': 4.9907326570653785, 'IoU-84': 5.036988248851424, 'IoU-85': 4.797269553363584, 'IoU-86': 4.6574696243290115, 'IoU-87': 4.575910026203257, 'IoU-88': 4.5760227026981095, 'IoU-89': 4.476121565721355, 'IoU-90': 4.382767100360612, 'IoU-91': 4.305681635721532, 'IoU-92': 4.349910247143887, 'IoU-93': 4.173469544202446, 'IoU-94': 4.146010070853063, 'IoU-95': 4.360634153411482, 'IoU-96': 4.368530560215333, 'IoU-97': 4.413662898406118, 'IoU-98': 4.42466085249886, 'IoU-99': 4.3923648812820515, 'IoU-100': 4.406385408553124, 'IoU-101': 4.237722701357635, 'IoU-102': 4.282513686056609, 'IoU-103': 4.123442561692382, 'IoU-104': 4.075998242052136, 'IoU-105': 4.088864782638512, 'IoU-106': 4.32599355982567, 'IoU-107': 4.198373018615128, 'IoU-108': 4.274301951099298, 'IoU-109': 4.225454657681063, 'IoU-110': 4.124105232610442, 'IoU-111': 4.416276918313212, 'IoU-112': 4.277387640782206, 'IoU-113': 4.169427661080379, 'IoU-114': 4.29563702536973, 'IoU-115': 4.14165597167662, 'IoU-116': 4.019705783272724, 'IoU-117': 4.0369858231152485, 'IoU-118': 3.93801559723826, 'IoU-119': 3.884168885860542, 'IoU-120': 3.882589134999629, 'IoU-121': 3.8332640048674795, 'IoU-122': 3.594332811613295, 'IoU-123': 3.526471416816715, 'IoU-124': 3.2303221534175566, 'IoU-125': 3.0410912846368374, 'IoU-126': 3.0920886018298304, 'IoU-127': 3.15160971004897, 'IoU-128': 2.8708501226760395, 'IoU-129': 2.823228055495916, 'IoU-130': 2.8687852476790057, 'IoU-131': 2.538665924433091, 'IoU-132': 2.284730942637734, 'IoU-133': 2.2498731487769397, 'IoU-134': 2.3283645805590014, 'IoU-135': 2.0951191295123803, 'IoU-136': 2.3028834117651327, 'IoU-137': 2.412748845752867, 'IoU-138': 2.1625888655242913, 'IoU-139': 2.0633842658613495, 'IoU-140': 2.2102600516449344, 'IoU-141': 1.9620357783910032, 'IoU-142': 2.018300349743732, 'IoU-143': 1.7547594083307587, 'IoU-144': 1.7883229837982808, 'IoU-145': 1.9061950608172964, 'IoU-146': 1.8493302859455738, 'IoU-147': 2.3147419760855885, 'IoU-148': 2.134657345148506, 'IoU-149': 2.189753476126068, 'IoU-150': 2.255092961421141, 'IoU-151': 2.299945285675829, 'IoU-152': 1.9982829231152057, 'IoU-153': 1.4645585232631657, 'IoU-154': 1.672631382686884, 'IoU-155': 1.5512843179349887, 'IoU-156': 1.4969662230175595, 'IoU-157': 1.3794954212813175, 'IoU-158': 1.3462327520396822, 'IoU-159': 1.116491535009429, 'IoU-160': 1.2769906208768333, 'IoU-161': 1.0610511526917428, 'IoU-162': 0.8959153376177708, 'IoU-163': 0.9895498270124055, 'IoU-164': 1.1873220715264452, 'IoU-165': 0.9878169936101746, 'IoU-166': 1.0273348587405235, 'IoU-167': 1.003246540137435, 'IoU-168': 1.0544389412274542, 'IoU-169': 0.8495905555165695, 'IoU-170': 0.8855337364370081, 'IoU-171': 0.9885475109908612, 'IoU-172': 0.7745155639793875, 'IoU-173': 0.8320050715450099, 'IoU-174': 0.6047059218640093, 'IoU-175': 0.7330341760563852, 'IoU-176': 0.6013753056472486, 'IoU-177': 0.8659143664177643, 'IoU-178': 0.1947021665296367, 'IoU-179': 0.4377090473634224, 'IoU-180': 0.008810628134852958, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 9.37221919243981, 'pACC': 18.32608073247733, 'ACC-0': 0.0014927295540832978, 'ACC-1': 36.47874951663433, 'ACC-2': 4.93167355958678, 'ACC-3': 12.467677717671362, 'ACC-4': 7.804359982138475, 'ACC-5': 7.240354584521567, 'ACC-6': 6.776387157080352, 'ACC-7': 6.6677970180600985, 'ACC-8': 4.384348971259218, 'ACC-9': 4.870267859404236, 'ACC-10': 8.403983137808888, 'ACC-11': 21.955667159311503, 'ACC-12': 30.92523857079923, 'ACC-13': 34.134855704727684, 'ACC-14': 33.894846842726935, 'ACC-15': 33.19270162349611, 'ACC-16': 31.249662186219823, 'ACC-17': 27.933374431289455, 'ACC-18': 24.965130027962537, 'ACC-19': 22.705426144236913, 'ACC-20': 22.31559838365764, 'ACC-21': 20.649133575870074, 'ACC-22': 21.25495543819583, 'ACC-23': 19.176744479782947, 'ACC-24': 17.725988042160097, 'ACC-25': 16.605590467905593, 'ACC-26': 16.652031020858722, 'ACC-27': 15.373797454399766, 'ACC-28': 14.512626429501116, 'ACC-29': 14.273091947986982, 'ACC-30': 14.45219809958094, 'ACC-31': 14.109598154767175, 'ACC-32': 13.913108042287991, 'ACC-33': 13.704194695330862, 'ACC-34': 14.473130552614435, 'ACC-35': 14.575891465352536, 'ACC-36': 14.863171455297621, 'ACC-37': 14.749736125660226, 'ACC-38': 14.026864171363332, 'ACC-39': 14.084154495968134, 'ACC-40': 14.691766950222476, 'ACC-41': 14.93873123697357, 'ACC-42': 15.22825618975735, 'ACC-43': 15.433430976185441, 'ACC-44': 15.472699264565431, 'ACC-45': 16.133524770547982, 'ACC-46': 16.05816037415561, 'ACC-47': 15.588381225030663, 'ACC-48': 15.927198761137209, 'ACC-49': 15.35638156810151, 'ACC-50': 15.602840753840924, 'ACC-51': 15.468181300782597, 'ACC-52': 15.329386224384207, 'ACC-53': 15.315542691310077, 'ACC-54': 16.08312562402419, 'ACC-55': 15.603951368752403, 'ACC-56': 14.650920292435812, 'ACC-57': 14.21691277609806, 'ACC-58': 14.426059363300084, 'ACC-59': 13.963901315610197, 'ACC-60': 13.832672311637234, 'ACC-61': 12.541284483311252, 'ACC-62': 12.482071792743616, 'ACC-63': 12.313883515059757, 'ACC-64': 12.095909237912997, 'ACC-65': 11.967622325085427, 'ACC-66': 11.961060591627824, 'ACC-67': 11.30036059938088, 'ACC-68': 10.946086747532249, 'ACC-69': 10.87136701797334, 'ACC-70': 10.594689872616078, 'ACC-71': 10.656268485650036, 'ACC-72': 10.732110291176332, 'ACC-73': 10.901678578642242, 'ACC-74': 10.713161799843512, 'ACC-75': 11.04177063551951, 'ACC-76': 10.585013973385117, 'ACC-77': 10.34284798570586, 'ACC-78': 10.086288728380953, 'ACC-79': 9.685332128628524, 'ACC-80': 9.75587154635329, 'ACC-81': 9.658865151570552, 'ACC-82': 9.431053947253245, 'ACC-83': 9.004472859949257, 'ACC-84': 9.14547817951499, 'ACC-85': 8.727542768900042, 'ACC-86': 8.565250414001769, 'ACC-87': 8.5049731376182, 'ACC-88': 8.52900905756163, 'ACC-89': 8.392457448639123, 'ACC-90': 8.262741229852786, 'ACC-91': 8.217557092979238, 'ACC-92': 8.431347538727538, 'ACC-93': 8.180823231182613, 'ACC-94': 8.163053368073548, 'ACC-95': 8.6471138197306, 'ACC-96': 8.85000155706977, 'ACC-97': 8.947137469698223, 'ACC-98': 9.028886667548864, 'ACC-99': 9.056820118990409, 'ACC-100': 9.092630481199727, 'ACC-101': 8.79950599324932, 'ACC-102': 8.937698232895332, 'ACC-103': 8.507745348068385, 'ACC-104': 8.443963503111089, 'ACC-105': 8.375040958475575, 'ACC-106': 8.78273896385429, 'ACC-107': 8.575817309156735, 'ACC-108': 8.69032317081428, 'ACC-109': 8.539085987897653, 'ACC-110': 8.43386771344668, 'ACC-111': 9.109427772455318, 'ACC-112': 9.035467211730893, 'ACC-113': 8.904620965043234, 'ACC-114': 9.289915404426463, 'ACC-115': 8.92494700284155, 'ACC-116': 8.694785808948719, 'ACC-117': 8.74440561042234, 'ACC-118': 8.69741197138007, 'ACC-119': 8.47904193671385, 'ACC-120': 8.547291242791934, 'ACC-121': 8.413141735634602, 'ACC-122': 7.903186239821864, 'ACC-123': 7.794733840041526, 'ACC-124': 7.206378346183823, 'ACC-125': 6.660481224500008, 'ACC-126': 6.859579777593602, 'ACC-127': 7.019795063966583, 'ACC-128': 6.52342811422494, 'ACC-129': 6.419781131417161, 'ACC-130': 6.498247098490105, 'ACC-131': 5.7947927611444845, 'ACC-132': 5.221488339985188, 'ACC-133': 4.993229772670055, 'ACC-134': 5.06829814735028, 'ACC-135': 4.59687304030557, 'ACC-136': 5.082419982295938, 'ACC-137': 5.378498370880549, 'ACC-138': 4.815404726248191, 'ACC-139': 4.565842428754018, 'ACC-140': 4.8597203517716965, 'ACC-141': 4.245302866837558, 'ACC-142': 4.428410364164005, 'ACC-143': 3.889013194015742, 'ACC-144': 3.957490974729242, 'ACC-145': 4.080144904850287, 'ACC-146': 3.841356149048457, 'ACC-147': 4.917904925147379, 'ACC-148': 4.55662320552901, 'ACC-149': 4.825321554576809, 'ACC-150': 4.9478376792379475, 'ACC-151': 5.044533472310593, 'ACC-152': 4.24769455121721, 'ACC-153': 3.2362492900199715, 'ACC-154': 3.6762020836782447, 'ACC-155': 3.406645417501719, 'ACC-156': 3.3221509046132365, 'ACC-157': 3.1133758794010884, 'ACC-158': 3.121017400300049, 'ACC-159': 2.5440404664759404, 'ACC-160': 2.9748506990001355, 'ACC-161': 2.33306279259823, 'ACC-162': 2.0603925605695905, 'ACC-163': 2.3889924132522737, 'ACC-164': 2.937287345533186, 'ACC-165': 2.2455189675599616, 'ACC-166': 2.309558385306931, 'ACC-167': 2.416153783350444, 'ACC-168': 2.5924818904283002, 'ACC-169': 2.209362108325598, 'ACC-170': 2.201612788733194, 'ACC-171': 2.377807861368934, 'ACC-172': 1.5772122828462423, 'ACC-173': 1.728484720774554, 'ACC-174': 1.2082440943854489, 'ACC-175': 1.4167678907851848, 'ACC-176': 1.4021505688414209, 'ACC-177': 1.8284862208393542, 'ACC-178': 0.24106113256237555, 'ACC-179': 0.5806675444985706, 'ACC-180': 0.00888956618916997, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 07:50:31] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 07:50:31] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 07:50:31] d2.evaluation.testing INFO: copypaste: 3.1260,0.4960,0.2135,4.9569,11.6520,9.3722,18.3261
[01/29 07:50:32] d2.utils.events INFO:  eta: 1 day, 14:48:44  iter: 12999  total_loss: 29.78  loss_mask: 3.054  loss_mask_0: 3.096  loss_mask_1: 2.961  loss_mask_2: 2.986  loss_mask_3: 2.97  loss_mask_4: 2.961  loss_mask_5: 2.998  loss_mask_6: 2.998  loss_mask_7: 2.958  loss_mask_8: 2.968  time: 3.0324  data_time: 0.0518  lr: 8.0271e-05  max_mem: 27646M
[01/29 07:51:31] d2.utils.events INFO:  eta: 1 day, 14:47:42  iter: 13019  total_loss: 30.09  loss_mask: 3.021  loss_mask_0: 3.138  loss_mask_1: 2.946  loss_mask_2: 3.037  loss_mask_3: 2.967  loss_mask_4: 2.978  loss_mask_5: 3.029  loss_mask_6: 3.008  loss_mask_7: 3.004  loss_mask_8: 3.003  time: 3.0323  data_time: 0.0538  lr: 8.0241e-05  max_mem: 27646M
[01/29 07:52:31] d2.utils.events INFO:  eta: 1 day, 14:44:52  iter: 13039  total_loss: 33.29  loss_mask: 3.297  loss_mask_0: 3.44  loss_mask_1: 3.294  loss_mask_2: 3.318  loss_mask_3: 3.328  loss_mask_4: 3.316  loss_mask_5: 3.382  loss_mask_6: 3.315  loss_mask_7: 3.334  loss_mask_8: 3.29  time: 3.0322  data_time: 0.0584  lr: 8.021e-05  max_mem: 27646M
[01/29 07:53:30] d2.utils.events INFO:  eta: 1 day, 14:43:24  iter: 13059  total_loss: 32.31  loss_mask: 3.227  loss_mask_0: 3.299  loss_mask_1: 3.223  loss_mask_2: 3.202  loss_mask_3: 3.227  loss_mask_4: 3.23  loss_mask_5: 3.25  loss_mask_6: 3.217  loss_mask_7: 3.218  loss_mask_8: 3.287  time: 3.0322  data_time: 0.0588  lr: 8.0179e-05  max_mem: 27646M
[01/29 07:54:30] d2.utils.events INFO:  eta: 1 day, 14:41:58  iter: 13079  total_loss: 32.16  loss_mask: 3.208  loss_mask_0: 3.383  loss_mask_1: 3.226  loss_mask_2: 3.184  loss_mask_3: 3.174  loss_mask_4: 3.207  loss_mask_5: 3.203  loss_mask_6: 3.177  loss_mask_7: 3.175  loss_mask_8: 3.176  time: 3.0320  data_time: 0.0633  lr: 8.0148e-05  max_mem: 27646M
[01/29 07:55:29] d2.utils.events INFO:  eta: 1 day, 14:40:45  iter: 13099  total_loss: 30.1  loss_mask: 3.025  loss_mask_0: 3.13  loss_mask_1: 2.961  loss_mask_2: 2.992  loss_mask_3: 2.998  loss_mask_4: 3.05  loss_mask_5: 3.033  loss_mask_6: 3  loss_mask_7: 3.018  loss_mask_8: 2.999  time: 3.0320  data_time: 0.0547  lr: 8.0118e-05  max_mem: 27646M
[01/29 07:56:29] d2.utils.events INFO:  eta: 1 day, 14:39:46  iter: 13119  total_loss: 31.86  loss_mask: 3.178  loss_mask_0: 3.28  loss_mask_1: 3.204  loss_mask_2: 3.194  loss_mask_3: 3.161  loss_mask_4: 3.174  loss_mask_5: 3.19  loss_mask_6: 3.191  loss_mask_7: 3.193  loss_mask_8: 3.19  time: 3.0319  data_time: 0.0681  lr: 8.0087e-05  max_mem: 27646M
[01/29 07:57:29] d2.utils.events INFO:  eta: 1 day, 14:38:20  iter: 13139  total_loss: 30.02  loss_mask: 2.986  loss_mask_0: 3.079  loss_mask_1: 3.01  loss_mask_2: 3.007  loss_mask_3: 2.966  loss_mask_4: 2.989  loss_mask_5: 3.004  loss_mask_6: 2.993  loss_mask_7: 2.975  loss_mask_8: 2.971  time: 3.0318  data_time: 0.0535  lr: 8.0056e-05  max_mem: 27646M
[01/29 07:58:28] d2.utils.events INFO:  eta: 1 day, 14:36:45  iter: 13159  total_loss: 31.31  loss_mask: 3.076  loss_mask_0: 3.215  loss_mask_1: 3.105  loss_mask_2: 3.157  loss_mask_3: 3.129  loss_mask_4: 3.17  loss_mask_5: 3.157  loss_mask_6: 3.065  loss_mask_7: 3.091  loss_mask_8: 3.096  time: 3.0317  data_time: 0.0457  lr: 8.0025e-05  max_mem: 27646M
[01/29 07:59:26] d2.utils.events INFO:  eta: 1 day, 14:35:12  iter: 13179  total_loss: 29.83  loss_mask: 2.972  loss_mask_0: 3.025  loss_mask_1: 2.967  loss_mask_2: 2.955  loss_mask_3: 3.032  loss_mask_4: 3.02  loss_mask_5: 2.967  loss_mask_6: 2.965  loss_mask_7: 2.943  loss_mask_8: 2.969  time: 3.0316  data_time: 0.0512  lr: 7.9995e-05  max_mem: 27646M
[01/29 08:00:26] d2.utils.events INFO:  eta: 1 day, 14:33:35  iter: 13199  total_loss: 33.58  loss_mask: 3.353  loss_mask_0: 3.458  loss_mask_1: 3.353  loss_mask_2: 3.386  loss_mask_3: 3.34  loss_mask_4: 3.337  loss_mask_5: 3.362  loss_mask_6: 3.358  loss_mask_7: 3.35  loss_mask_8: 3.364  time: 3.0314  data_time: 0.0640  lr: 7.9964e-05  max_mem: 27646M
[01/29 08:01:25] d2.utils.events INFO:  eta: 1 day, 14:31:56  iter: 13219  total_loss: 31.74  loss_mask: 3.071  loss_mask_0: 3.061  loss_mask_1: 3.1  loss_mask_2: 3.27  loss_mask_3: 3.195  loss_mask_4: 3.143  loss_mask_5: 3.285  loss_mask_6: 3.227  loss_mask_7: 3.115  loss_mask_8: 3.109  time: 3.0313  data_time: 0.0526  lr: 7.9933e-05  max_mem: 27646M
[01/29 08:02:24] d2.utils.events INFO:  eta: 1 day, 14:29:43  iter: 13239  total_loss: 34.46  loss_mask: 3.468  loss_mask_0: 3.516  loss_mask_1: 3.435  loss_mask_2: 3.458  loss_mask_3: 3.48  loss_mask_4: 3.437  loss_mask_5: 3.459  loss_mask_6: 3.462  loss_mask_7: 3.455  loss_mask_8: 3.445  time: 3.0312  data_time: 0.0584  lr: 7.9902e-05  max_mem: 27646M
[01/29 08:03:23] d2.utils.events INFO:  eta: 1 day, 14:27:58  iter: 13259  total_loss: 29.19  loss_mask: 2.886  loss_mask_0: 2.964  loss_mask_1: 2.911  loss_mask_2: 2.972  loss_mask_3: 2.897  loss_mask_4: 2.913  loss_mask_5: 2.909  loss_mask_6: 2.909  loss_mask_7: 2.884  loss_mask_8: 2.903  time: 3.0311  data_time: 0.0617  lr: 7.9872e-05  max_mem: 27646M
[01/29 08:04:22] d2.utils.events INFO:  eta: 1 day, 14:27:10  iter: 13279  total_loss: 32.24  loss_mask: 3.182  loss_mask_0: 3.272  loss_mask_1: 3.182  loss_mask_2: 3.177  loss_mask_3: 3.205  loss_mask_4: 3.204  loss_mask_5: 3.226  loss_mask_6: 3.239  loss_mask_7: 3.221  loss_mask_8: 3.191  time: 3.0310  data_time: 0.0550  lr: 7.9841e-05  max_mem: 27646M
[01/29 08:05:22] d2.utils.events INFO:  eta: 1 day, 14:26:17  iter: 13299  total_loss: 34.5  loss_mask: 3.47  loss_mask_0: 3.554  loss_mask_1: 3.403  loss_mask_2: 3.437  loss_mask_3: 3.447  loss_mask_4: 3.438  loss_mask_5: 3.382  loss_mask_6: 3.465  loss_mask_7: 3.469  loss_mask_8: 3.39  time: 3.0309  data_time: 0.0642  lr: 7.981e-05  max_mem: 27646M
[01/29 08:06:21] d2.utils.events INFO:  eta: 1 day, 14:24:55  iter: 13319  total_loss: 30.17  loss_mask: 2.997  loss_mask_0: 3.014  loss_mask_1: 2.981  loss_mask_2: 2.945  loss_mask_3: 3.017  loss_mask_4: 3.25  loss_mask_5: 3.007  loss_mask_6: 3.02  loss_mask_7: 2.949  loss_mask_8: 2.933  time: 3.0308  data_time: 0.0582  lr: 7.9779e-05  max_mem: 27646M
[01/29 08:07:21] d2.utils.events INFO:  eta: 1 day, 14:23:32  iter: 13339  total_loss: 30.52  loss_mask: 3  loss_mask_0: 3.131  loss_mask_1: 2.983  loss_mask_2: 2.995  loss_mask_3: 3.033  loss_mask_4: 3.408  loss_mask_5: 3.109  loss_mask_6: 3.008  loss_mask_7: 3.015  loss_mask_8: 2.984  time: 3.0307  data_time: 0.0579  lr: 7.9748e-05  max_mem: 27646M
[01/29 08:08:21] d2.utils.events INFO:  eta: 1 day, 14:22:14  iter: 13359  total_loss: 31.3  loss_mask: 3.071  loss_mask_0: 3.322  loss_mask_1: 3.123  loss_mask_2: 3.126  loss_mask_3: 3.116  loss_mask_4: 3.226  loss_mask_5: 3.182  loss_mask_6: 3.076  loss_mask_7: 3.099  loss_mask_8: 3.115  time: 3.0307  data_time: 0.0547  lr: 7.9718e-05  max_mem: 27646M
[01/29 08:09:20] d2.utils.events INFO:  eta: 1 day, 14:21:14  iter: 13379  total_loss: 28.85  loss_mask: 2.833  loss_mask_0: 2.946  loss_mask_1: 2.857  loss_mask_2: 2.882  loss_mask_3: 2.871  loss_mask_4: 2.978  loss_mask_5: 2.858  loss_mask_6: 2.842  loss_mask_7: 2.873  loss_mask_8: 2.868  time: 3.0306  data_time: 0.0508  lr: 7.9687e-05  max_mem: 27646M
[01/29 08:10:19] d2.utils.events INFO:  eta: 1 day, 14:19:37  iter: 13399  total_loss: 28.45  loss_mask: 2.847  loss_mask_0: 2.912  loss_mask_1: 2.802  loss_mask_2: 2.818  loss_mask_3: 2.844  loss_mask_4: 2.865  loss_mask_5: 2.837  loss_mask_6: 2.854  loss_mask_7: 2.832  loss_mask_8: 2.83  time: 3.0305  data_time: 0.0605  lr: 7.9656e-05  max_mem: 27646M
[01/29 08:11:19] d2.utils.events INFO:  eta: 1 day, 14:18:28  iter: 13419  total_loss: 30.2  loss_mask: 2.996  loss_mask_0: 3.109  loss_mask_1: 2.975  loss_mask_2: 2.996  loss_mask_3: 3.027  loss_mask_4: 3.095  loss_mask_5: 2.978  loss_mask_6: 2.975  loss_mask_7: 2.99  loss_mask_8: 3.022  time: 3.0304  data_time: 0.0561  lr: 7.9625e-05  max_mem: 27646M
[01/29 08:12:19] d2.utils.events INFO:  eta: 1 day, 14:17:03  iter: 13439  total_loss: 31.46  loss_mask: 3.15  loss_mask_0: 3.141  loss_mask_1: 3.095  loss_mask_2: 3.133  loss_mask_3: 3.176  loss_mask_4: 3.156  loss_mask_5: 3.144  loss_mask_6: 3.17  loss_mask_7: 3.156  loss_mask_8: 3.134  time: 3.0303  data_time: 0.0649  lr: 7.9595e-05  max_mem: 27646M
[01/29 08:13:18] d2.utils.events INFO:  eta: 1 day, 14:16:04  iter: 13459  total_loss: 34.2  loss_mask: 3.427  loss_mask_0: 3.467  loss_mask_1: 3.378  loss_mask_2: 3.488  loss_mask_3: 3.431  loss_mask_4: 3.637  loss_mask_5: 3.423  loss_mask_6: 3.425  loss_mask_7: 3.428  loss_mask_8: 3.529  time: 3.0302  data_time: 0.0561  lr: 7.9564e-05  max_mem: 27646M
[01/29 08:14:17] d2.utils.events INFO:  eta: 1 day, 14:14:46  iter: 13479  total_loss: 31.53  loss_mask: 3.157  loss_mask_0: 3.173  loss_mask_1: 3.121  loss_mask_2: 3.122  loss_mask_3: 3.115  loss_mask_4: 3.242  loss_mask_5: 3.086  loss_mask_6: 3.114  loss_mask_7: 3.112  loss_mask_8: 3.198  time: 3.0301  data_time: 0.0498  lr: 7.9533e-05  max_mem: 27646M
[01/29 08:15:17] d2.utils.events INFO:  eta: 1 day, 14:14:26  iter: 13499  total_loss: 32.67  loss_mask: 3.244  loss_mask_0: 3.466  loss_mask_1: 3.178  loss_mask_2: 3.23  loss_mask_3: 3.305  loss_mask_4: 3.514  loss_mask_5: 3.214  loss_mask_6: 3.186  loss_mask_7: 3.287  loss_mask_8: 3.277  time: 3.0301  data_time: 0.0579  lr: 7.9502e-05  max_mem: 27646M
[01/29 08:16:16] d2.utils.events INFO:  eta: 1 day, 14:13:32  iter: 13519  total_loss: 30.56  loss_mask: 3.024  loss_mask_0: 3.151  loss_mask_1: 2.96  loss_mask_2: 2.984  loss_mask_3: 3.099  loss_mask_4: 3.234  loss_mask_5: 3.03  loss_mask_6: 2.994  loss_mask_7: 3.049  loss_mask_8: 3.08  time: 3.0300  data_time: 0.0558  lr: 7.9472e-05  max_mem: 27646M
[01/29 08:17:16] d2.utils.events INFO:  eta: 1 day, 14:12:55  iter: 13539  total_loss: 29.01  loss_mask: 3.074  loss_mask_0: 2.913  loss_mask_1: 2.867  loss_mask_2: 2.873  loss_mask_3: 2.861  loss_mask_4: 2.896  loss_mask_5: 2.893  loss_mask_6: 2.858  loss_mask_7: 2.879  loss_mask_8: 2.88  time: 3.0299  data_time: 0.0579  lr: 7.9441e-05  max_mem: 27646M
[01/29 08:18:15] d2.utils.events INFO:  eta: 1 day, 14:11:37  iter: 13559  total_loss: 31.52  loss_mask: 3.17  loss_mask_0: 3.172  loss_mask_1: 3.127  loss_mask_2: 3.175  loss_mask_3: 3.101  loss_mask_4: 3.17  loss_mask_5: 3.119  loss_mask_6: 3.14  loss_mask_7: 3.135  loss_mask_8: 3.117  time: 3.0298  data_time: 0.0596  lr: 7.941e-05  max_mem: 27646M
[01/29 08:19:15] d2.utils.events INFO:  eta: 1 day, 14:10:57  iter: 13579  total_loss: 34.63  loss_mask: 3.526  loss_mask_0: 3.536  loss_mask_1: 3.437  loss_mask_2: 3.49  loss_mask_3: 3.437  loss_mask_4: 3.605  loss_mask_5: 3.444  loss_mask_6: 3.469  loss_mask_7: 3.468  loss_mask_8: 3.511  time: 3.0297  data_time: 0.0493  lr: 7.9379e-05  max_mem: 27646M
[01/29 08:20:14] d2.utils.events INFO:  eta: 1 day, 14:09:45  iter: 13599  total_loss: 29.9  loss_mask: 3.037  loss_mask_0: 2.987  loss_mask_1: 3.029  loss_mask_2: 3.144  loss_mask_3: 2.937  loss_mask_4: 2.921  loss_mask_5: 2.967  loss_mask_6: 3.006  loss_mask_7: 2.955  loss_mask_8: 2.912  time: 3.0296  data_time: 0.0609  lr: 7.9348e-05  max_mem: 27646M
[01/29 08:21:14] d2.utils.events INFO:  eta: 1 day, 14:09:05  iter: 13619  total_loss: 31.55  loss_mask: 3.146  loss_mask_0: 3.346  loss_mask_1: 3.095  loss_mask_2: 3.107  loss_mask_3: 3.209  loss_mask_4: 3.378  loss_mask_5: 3.122  loss_mask_6: 3.103  loss_mask_7: 3.162  loss_mask_8: 3.18  time: 3.0295  data_time: 0.0572  lr: 7.9318e-05  max_mem: 27646M
[01/29 08:22:13] d2.utils.events INFO:  eta: 1 day, 14:08:24  iter: 13639  total_loss: 36.67  loss_mask: 3.691  loss_mask_0: 3.73  loss_mask_1: 3.671  loss_mask_2: 3.682  loss_mask_3: 3.653  loss_mask_4: 3.676  loss_mask_5: 3.629  loss_mask_6: 3.672  loss_mask_7: 3.654  loss_mask_8: 3.648  time: 3.0295  data_time: 0.0604  lr: 7.9287e-05  max_mem: 27646M
[01/29 08:23:12] d2.utils.events INFO:  eta: 1 day, 14:07:31  iter: 13659  total_loss: 27.69  loss_mask: 2.752  loss_mask_0: 2.819  loss_mask_1: 2.739  loss_mask_2: 2.825  loss_mask_3: 2.734  loss_mask_4: 2.83  loss_mask_5: 2.815  loss_mask_6: 2.783  loss_mask_7: 2.732  loss_mask_8: 2.757  time: 3.0294  data_time: 0.0572  lr: 7.9256e-05  max_mem: 27646M
[01/29 08:24:12] d2.utils.events INFO:  eta: 1 day, 14:06:32  iter: 13679  total_loss: 28.7  loss_mask: 2.856  loss_mask_0: 2.902  loss_mask_1: 2.804  loss_mask_2: 2.821  loss_mask_3: 2.887  loss_mask_4: 2.991  loss_mask_5: 2.872  loss_mask_6: 2.834  loss_mask_7: 2.857  loss_mask_8: 2.923  time: 3.0293  data_time: 0.0610  lr: 7.9225e-05  max_mem: 27646M
[01/29 08:25:10] d2.utils.events INFO:  eta: 1 day, 14:05:08  iter: 13699  total_loss: 31.44  loss_mask: 3.153  loss_mask_0: 3.178  loss_mask_1: 3.106  loss_mask_2: 3.12  loss_mask_3: 3.132  loss_mask_4: 3.253  loss_mask_5: 3.178  loss_mask_6: 3.112  loss_mask_7: 3.122  loss_mask_8: 3.221  time: 3.0291  data_time: 0.0543  lr: 7.9195e-05  max_mem: 27646M
[01/29 08:26:10] d2.utils.events INFO:  eta: 1 day, 14:04:09  iter: 13719  total_loss: 30.05  loss_mask: 3.03  loss_mask_0: 3.061  loss_mask_1: 3.025  loss_mask_2: 3.028  loss_mask_3: 2.986  loss_mask_4: 2.998  loss_mask_5: 2.998  loss_mask_6: 3.005  loss_mask_7: 2.985  loss_mask_8: 2.993  time: 3.0290  data_time: 0.0561  lr: 7.9164e-05  max_mem: 27646M
[01/29 08:27:09] d2.utils.events INFO:  eta: 1 day, 14:03:59  iter: 13739  total_loss: 31.45  loss_mask: 3.092  loss_mask_0: 3.157  loss_mask_1: 3.131  loss_mask_2: 3.181  loss_mask_3: 3.136  loss_mask_4: 3.139  loss_mask_5: 3.132  loss_mask_6: 3.097  loss_mask_7: 3.128  loss_mask_8: 3.161  time: 3.0290  data_time: 0.0606  lr: 7.9133e-05  max_mem: 27646M
[01/29 08:28:09] d2.utils.events INFO:  eta: 1 day, 14:02:29  iter: 13759  total_loss: 30.37  loss_mask: 3.037  loss_mask_0: 3.088  loss_mask_1: 3.013  loss_mask_2: 3.022  loss_mask_3: 3.025  loss_mask_4: 3.064  loss_mask_5: 3.065  loss_mask_6: 3.046  loss_mask_7: 3.013  loss_mask_8: 3.061  time: 3.0289  data_time: 0.0581  lr: 7.9102e-05  max_mem: 27646M
[01/29 08:29:09] d2.utils.events INFO:  eta: 1 day, 14:02:12  iter: 13779  total_loss: 29.6  loss_mask: 2.939  loss_mask_0: 3.037  loss_mask_1: 2.984  loss_mask_2: 2.987  loss_mask_3: 3.003  loss_mask_4: 2.965  loss_mask_5: 2.941  loss_mask_6: 2.935  loss_mask_7: 2.94  loss_mask_8: 2.936  time: 3.0288  data_time: 0.0615  lr: 7.9071e-05  max_mem: 27646M
[01/29 08:30:08] d2.utils.events INFO:  eta: 1 day, 14:01:13  iter: 13799  total_loss: 30.56  loss_mask: 3.076  loss_mask_0: 3.12  loss_mask_1: 3.027  loss_mask_2: 3.097  loss_mask_3: 3.17  loss_mask_4: 3.091  loss_mask_5: 3.019  loss_mask_6: 3.059  loss_mask_7: 3.03  loss_mask_8: 3.133  time: 3.0287  data_time: 0.0601  lr: 7.9041e-05  max_mem: 27646M
[01/29 08:31:07] d2.utils.events INFO:  eta: 1 day, 14:00:47  iter: 13819  total_loss: 29.48  loss_mask: 2.992  loss_mask_0: 2.957  loss_mask_1: 2.915  loss_mask_2: 2.958  loss_mask_3: 2.948  loss_mask_4: 2.968  loss_mask_5: 2.92  loss_mask_6: 2.944  loss_mask_7: 2.942  loss_mask_8: 2.981  time: 3.0286  data_time: 0.0614  lr: 7.901e-05  max_mem: 27646M
[01/29 08:32:06] d2.utils.events INFO:  eta: 1 day, 13:59:03  iter: 13839  total_loss: 28.69  loss_mask: 2.845  loss_mask_0: 2.961  loss_mask_1: 2.856  loss_mask_2: 2.863  loss_mask_3: 2.861  loss_mask_4: 2.875  loss_mask_5: 2.838  loss_mask_6: 2.863  loss_mask_7: 2.86  loss_mask_8: 2.85  time: 3.0285  data_time: 0.0566  lr: 7.8979e-05  max_mem: 27646M
[01/29 08:33:05] d2.utils.events INFO:  eta: 1 day, 13:57:33  iter: 13859  total_loss: 31.94  loss_mask: 3.149  loss_mask_0: 3.267  loss_mask_1: 3.144  loss_mask_2: 3.197  loss_mask_3: 3.233  loss_mask_4: 3.229  loss_mask_5: 3.143  loss_mask_6: 3.167  loss_mask_7: 3.168  loss_mask_8: 3.184  time: 3.0284  data_time: 0.0515  lr: 7.8948e-05  max_mem: 27646M
[01/29 08:34:05] d2.utils.events INFO:  eta: 1 day, 13:57:25  iter: 13879  total_loss: 28.13  loss_mask: 2.812  loss_mask_0: 2.869  loss_mask_1: 2.786  loss_mask_2: 2.816  loss_mask_3: 2.839  loss_mask_4: 2.808  loss_mask_5: 2.79  loss_mask_6: 2.834  loss_mask_7: 2.792  loss_mask_8: 2.808  time: 3.0283  data_time: 0.0605  lr: 7.8917e-05  max_mem: 27646M
[01/29 08:35:04] d2.utils.events INFO:  eta: 1 day, 13:56:51  iter: 13899  total_loss: 33.13  loss_mask: 3.318  loss_mask_0: 3.341  loss_mask_1: 3.301  loss_mask_2: 3.367  loss_mask_3: 3.326  loss_mask_4: 3.305  loss_mask_5: 3.311  loss_mask_6: 3.437  loss_mask_7: 3.262  loss_mask_8: 3.328  time: 3.0282  data_time: 0.0575  lr: 7.8887e-05  max_mem: 27646M
[01/29 08:36:03] d2.utils.events INFO:  eta: 1 day, 13:55:26  iter: 13919  total_loss: 35.33  loss_mask: 3.482  loss_mask_0: 3.789  loss_mask_1: 3.566  loss_mask_2: 3.475  loss_mask_3: 3.502  loss_mask_4: 3.485  loss_mask_5: 3.5  loss_mask_6: 3.603  loss_mask_7: 3.531  loss_mask_8: 3.58  time: 3.0281  data_time: 0.0647  lr: 7.8856e-05  max_mem: 27646M
[01/29 08:37:02] d2.utils.events INFO:  eta: 1 day, 13:54:02  iter: 13939  total_loss: 31.99  loss_mask: 3.243  loss_mask_0: 3.304  loss_mask_1: 3.218  loss_mask_2: 3.211  loss_mask_3: 3.167  loss_mask_4: 3.169  loss_mask_5: 3.175  loss_mask_6: 3.186  loss_mask_7: 3.207  loss_mask_8: 3.193  time: 3.0280  data_time: 0.0534  lr: 7.8825e-05  max_mem: 27646M
[01/29 08:38:02] d2.utils.events INFO:  eta: 1 day, 13:52:37  iter: 13959  total_loss: 32.02  loss_mask: 3.233  loss_mask_0: 3.214  loss_mask_1: 3.148  loss_mask_2: 3.202  loss_mask_3: 3.204  loss_mask_4: 3.168  loss_mask_5: 3.23  loss_mask_6: 3.205  loss_mask_7: 3.236  loss_mask_8: 3.187  time: 3.0279  data_time: 0.0569  lr: 7.8794e-05  max_mem: 27646M
[01/29 08:39:00] d2.utils.events INFO:  eta: 1 day, 13:50:45  iter: 13979  total_loss: 29.61  loss_mask: 2.936  loss_mask_0: 2.993  loss_mask_1: 2.956  loss_mask_2: 2.962  loss_mask_3: 2.916  loss_mask_4: 2.988  loss_mask_5: 2.922  loss_mask_6: 2.987  loss_mask_7: 2.93  loss_mask_8: 2.961  time: 3.0278  data_time: 0.0496  lr: 7.8763e-05  max_mem: 27646M
[01/29 08:39:59] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 08:40:00] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 08:40:00] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 08:54:09] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.0125441342345223, 'error_1pix': 0.468410218189656, 'error_3pix': 0.21165873179484487, 'mIoU': 5.261366058790524, 'fwIoU': 13.589069919321272, 'IoU-0': 0.00024184322340933204, 'IoU-1': 44.63234690435808, 'IoU-2': 2.7265430618442594, 'IoU-3': 2.3914022029786683, 'IoU-4': 1.5811199921211272, 'IoU-5': 1.5015868014307472, 'IoU-6': 2.0005464166218467, 'IoU-7': 2.1035839641851113, 'IoU-8': 5.271167835018911, 'IoU-9': 10.390644434296068, 'IoU-10': 13.097496359726273, 'IoU-11': 21.5560515313046, 'IoU-12': 20.069801812065712, 'IoU-13': 17.999231291788508, 'IoU-14': 16.651935612239146, 'IoU-15': 15.51363856074563, 'IoU-16': 13.480695466363668, 'IoU-17': 10.75648482687153, 'IoU-18': 11.803803703129418, 'IoU-19': 11.690623720693111, 'IoU-20': 10.869329617322034, 'IoU-21': 11.039899093267811, 'IoU-22': 10.7487131179044, 'IoU-23': 10.460348857618564, 'IoU-24': 10.038281627501346, 'IoU-25': 10.60005152337192, 'IoU-26': 10.918217100447682, 'IoU-27': 11.477381444975546, 'IoU-28': 11.225927179965737, 'IoU-29': 11.463948045711362, 'IoU-30': 11.758639820574185, 'IoU-31': 12.32156803293031, 'IoU-32': 12.51762239036591, 'IoU-33': 12.471702093651617, 'IoU-34': 12.525974245707442, 'IoU-35': 13.19428294732233, 'IoU-36': 13.31650459139468, 'IoU-37': 13.351774988885046, 'IoU-38': 13.798015944766881, 'IoU-39': 13.139398616582646, 'IoU-40': 13.191705093210244, 'IoU-41': 12.306252425044352, 'IoU-42': 11.86208929556877, 'IoU-43': 11.707144771629183, 'IoU-44': 11.890052995648073, 'IoU-45': 11.529081483001242, 'IoU-46': 10.62387774019005, 'IoU-47': 10.705189093220174, 'IoU-48': 10.354837250943998, 'IoU-49': 10.410340423698301, 'IoU-50': 10.242597142855633, 'IoU-51': 9.52997906659144, 'IoU-52': 9.08686812014768, 'IoU-53': 8.678026494005891, 'IoU-54': 8.742497571531706, 'IoU-55': 8.16472075880697, 'IoU-56': 7.506558394484168, 'IoU-57': 7.100508391539123, 'IoU-58': 6.654487061675655, 'IoU-59': 5.928860590722555, 'IoU-60': 5.333686018045967, 'IoU-61': 4.942142327857575, 'IoU-62': 4.694278610957432, 'IoU-63': 4.1822669040586895, 'IoU-64': 4.046897904910931, 'IoU-65': 3.7353791770842526, 'IoU-66': 3.4659811442625434, 'IoU-67': 3.3934120737639804, 'IoU-68': 3.2296098060449627, 'IoU-69': 3.261097853598328, 'IoU-70': 3.28768991425577, 'IoU-71': 3.25507692049358, 'IoU-72': 3.270637966134192, 'IoU-73': 3.2522479114673604, 'IoU-74': 3.278155480791066, 'IoU-75': 3.2327334361079645, 'IoU-76': 3.4035108937630913, 'IoU-77': 3.2987325464648998, 'IoU-78': 3.3934316900519566, 'IoU-79': 3.4794552709723163, 'IoU-80': 3.4332649410326876, 'IoU-81': 3.4970776768718146, 'IoU-82': 3.4618455540877524, 'IoU-83': 3.6967843811346492, 'IoU-84': 3.6417841585971216, 'IoU-85': 3.6953808223650566, 'IoU-86': 3.8130577088443105, 'IoU-87': 3.7787751576081963, 'IoU-88': 3.817834491428592, 'IoU-89': 3.8802723831622954, 'IoU-90': 3.8313775536242414, 'IoU-91': 3.9654466722167028, 'IoU-92': 3.9567091600256328, 'IoU-93': 4.260246711943632, 'IoU-94': 4.287452259442633, 'IoU-95': 4.102218601153171, 'IoU-96': 4.080889025588165, 'IoU-97': 4.072250493319474, 'IoU-98': 4.164673671679322, 'IoU-99': 4.096455564595992, 'IoU-100': 4.106847534339355, 'IoU-101': 4.111409490506126, 'IoU-102': 4.026923214598215, 'IoU-103': 3.8515406620052373, 'IoU-104': 3.8611371456624988, 'IoU-105': 3.902344352211737, 'IoU-106': 4.164596656323339, 'IoU-107': 4.028558236183734, 'IoU-108': 3.8250110297731488, 'IoU-109': 3.812615932461337, 'IoU-110': 3.7946606416324595, 'IoU-111': 3.705572026770983, 'IoU-112': 3.5844001953185294, 'IoU-113': 3.536629653818635, 'IoU-114': 3.6710366811400457, 'IoU-115': 3.5675487104134316, 'IoU-116': 3.5482169731455953, 'IoU-117': 3.390025718630152, 'IoU-118': 3.2707024240443494, 'IoU-119': 3.521069864830595, 'IoU-120': 3.3272073754477405, 'IoU-121': 3.624086610555878, 'IoU-122': 3.401655832211977, 'IoU-123': 3.221219466660394, 'IoU-124': 3.3897687879401643, 'IoU-125': 3.461863221826732, 'IoU-126': 2.861278918719688, 'IoU-127': 2.839231671384015, 'IoU-128': 2.6628084614967635, 'IoU-129': 2.7459137114967875, 'IoU-130': 2.5852063217442987, 'IoU-131': 2.4647138481090827, 'IoU-132': 2.3628296918665375, 'IoU-133': 2.4145509885501917, 'IoU-134': 2.3656252552978754, 'IoU-135': 2.326257452751878, 'IoU-136': 2.4996223142096947, 'IoU-137': 2.652299678958615, 'IoU-138': 2.4287275460606845, 'IoU-139': 2.270761145269596, 'IoU-140': 2.2441753406199325, 'IoU-141': 2.1491842515191166, 'IoU-142': 2.4243354237418178, 'IoU-143': 2.3283288149531813, 'IoU-144': 2.541795571955116, 'IoU-145': 2.3661689908161407, 'IoU-146': 2.0359356585655326, 'IoU-147': 1.940416887875587, 'IoU-148': 2.225686385221156, 'IoU-149': 2.04787887054972, 'IoU-150': 2.1869179070712437, 'IoU-151': 2.6792022073372577, 'IoU-152': 2.340887659755275, 'IoU-153': 2.0035739507994075, 'IoU-154': 1.7722649502123682, 'IoU-155': 1.7697747500464676, 'IoU-156': 1.9380930838452275, 'IoU-157': 1.7013764067865391, 'IoU-158': 1.9061394802228058, 'IoU-159': 1.7524168557192144, 'IoU-160': 1.7731088729500448, 'IoU-161': 2.089099141883925, 'IoU-162': 1.4540061781346532, 'IoU-163': 1.4605333291433447, 'IoU-164': 1.4110036768884857, 'IoU-165': 1.969325023719772, 'IoU-166': 1.9691949351974867, 'IoU-167': 1.7522831298330415, 'IoU-168': 1.776763234289226, 'IoU-169': 2.1903923141173336, 'IoU-170': 1.7791280040377375, 'IoU-171': 1.7849019662549932, 'IoU-172': 1.4764083094658633, 'IoU-173': 1.2649473116831926, 'IoU-174': 1.0262705158065755, 'IoU-175': 0.8591989558382968, 'IoU-176': 1.0208124373119358, 'IoU-177': 1.1193515273877317, 'IoU-178': 0.6330945841610294, 'IoU-179': 0.8198334812929047, 'IoU-180': 1.6299657383449566, 'IoU-181': 1.000575161250565, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 9.865466148943273, 'pACC': 20.78551272000452, 'ACC-0': 0.0012639735964445585, 'ACC-1': 45.32259096515687, 'ACC-2': 6.035335830167915, 'ACC-3': 11.355721881636322, 'ACC-4': 6.5445324558121705, 'ACC-5': 6.182029944306178, 'ACC-6': 8.448408776949384, 'ACC-7': 10.070883971252611, 'ACC-8': 13.164817276227089, 'ACC-9': 17.288054030245917, 'ACC-10': 20.148485532354734, 'ACC-11': 31.177345945409087, 'ACC-12': 30.75342697230447, 'ACC-13': 27.79424363004225, 'ACC-14': 26.270236686023146, 'ACC-15': 25.934772076447754, 'ACC-16': 22.913351589644066, 'ACC-17': 19.794172684860715, 'ACC-18': 20.822018308097107, 'ACC-19': 20.76482781712334, 'ACC-20': 19.492615658538316, 'ACC-21': 19.64008831316045, 'ACC-22': 18.617967699705687, 'ACC-23': 19.474317989714784, 'ACC-24': 19.14722057129366, 'ACC-25': 19.787352222410565, 'ACC-26': 20.129277398882294, 'ACC-27': 20.467462156167326, 'ACC-28': 20.684591041474558, 'ACC-29': 20.466752903754067, 'ACC-30': 21.475939408432566, 'ACC-31': 22.297384016817894, 'ACC-32': 23.078120333238033, 'ACC-33': 23.496651299884544, 'ACC-34': 23.376460692949692, 'ACC-35': 24.02714131380396, 'ACC-36': 24.405888675537962, 'ACC-37': 24.89165180147779, 'ACC-38': 25.628194190090607, 'ACC-39': 24.44990738787386, 'ACC-40': 24.201149833051197, 'ACC-41': 23.319654394516405, 'ACC-42': 22.478689321557, 'ACC-43': 21.99913154304893, 'ACC-44': 21.577204855325146, 'ACC-45': 21.157525625438783, 'ACC-46': 20.040802385180278, 'ACC-47': 20.25528966231251, 'ACC-48': 19.642601498604932, 'ACC-49': 19.57981839209852, 'ACC-50': 19.172003762630286, 'ACC-51': 18.173749130705318, 'ACC-52': 17.500684620803693, 'ACC-53': 16.779743057919305, 'ACC-54': 16.72667157819639, 'ACC-55': 15.773828649754918, 'ACC-56': 14.731856489842066, 'ACC-57': 13.747210625158168, 'ACC-58': 13.043978181719446, 'ACC-59': 11.766551893943511, 'ACC-60': 10.552997457900322, 'ACC-61': 9.80201811509039, 'ACC-62': 9.329467523481922, 'ACC-63': 8.401914214503584, 'ACC-64': 8.135423472693178, 'ACC-65': 7.480418045123194, 'ACC-66': 6.8933406812914475, 'ACC-67': 6.726963357931229, 'ACC-68': 6.3761713372011055, 'ACC-69': 6.302283043211664, 'ACC-70': 6.316340055891173, 'ACC-71': 6.3693783639403785, 'ACC-72': 6.443778637209596, 'ACC-73': 6.32897825436484, 'ACC-74': 6.313538999379867, 'ACC-75': 6.217142657460259, 'ACC-76': 6.4613826640215315, 'ACC-77': 6.339956496669788, 'ACC-78': 6.539626108058235, 'ACC-79': 6.675341075923023, 'ACC-80': 6.471249048044886, 'ACC-81': 6.520475514588645, 'ACC-82': 6.417308863725809, 'ACC-83': 6.722055532288586, 'ACC-84': 6.578225528305334, 'ACC-85': 6.627796579413806, 'ACC-86': 6.83472598804568, 'ACC-87': 6.7989133679622675, 'ACC-88': 6.833038268593791, 'ACC-89': 6.894525516722323, 'ACC-90': 6.747948543189497, 'ACC-91': 7.063749982650233, 'ACC-92': 7.1723319453290415, 'ACC-93': 7.793133999547136, 'ACC-94': 7.822858355775804, 'ACC-95': 7.417720961126204, 'ACC-96': 7.357779162209867, 'ACC-97': 7.245238646774285, 'ACC-98': 7.472668882269801, 'ACC-99': 7.405062607653306, 'ACC-100': 7.434819206469302, 'ACC-101': 7.503426064917266, 'ACC-102': 7.340144993203443, 'ACC-103': 6.959360536507036, 'ACC-104': 6.97875113745358, 'ACC-105': 7.091696673086368, 'ACC-106': 7.579289252995316, 'ACC-107': 7.341613035172687, 'ACC-108': 6.936411871788486, 'ACC-109': 6.971365716820959, 'ACC-110': 7.055497627492007, 'ACC-111': 6.945511286694803, 'ACC-112': 6.818741454176368, 'ACC-113': 6.683207887075827, 'ACC-114': 6.911960909578253, 'ACC-115': 6.6727557018928625, 'ACC-116': 6.6846960576395515, 'ACC-117': 6.374891808985901, 'ACC-118': 6.235553892875542, 'ACC-119': 6.729251991283003, 'ACC-120': 6.351532274217522, 'ACC-121': 7.026485412833328, 'ACC-122': 6.6175568701821925, 'ACC-123': 6.351089172615652, 'ACC-124': 6.79393383733747, 'ACC-125': 6.934529668912062, 'ACC-126': 5.797582400568311, 'ACC-127': 5.770367445728864, 'ACC-128': 5.422184168383358, 'ACC-129': 5.5398011620529894, 'ACC-130': 5.358022716778066, 'ACC-131': 5.11413139914389, 'ACC-132': 4.864265296753158, 'ACC-133': 5.030721182306232, 'ACC-134': 4.930495476087893, 'ACC-135': 4.8128669973205636, 'ACC-136': 5.118963729966455, 'ACC-137': 5.554499750804638, 'ACC-138': 5.1387161458994335, 'ACC-139': 4.811793863183776, 'ACC-140': 4.921838634921739, 'ACC-141': 4.614155946672412, 'ACC-142': 5.243039453793291, 'ACC-143': 5.052599040484233, 'ACC-144': 5.61028880866426, 'ACC-145': 5.206467049799861, 'ACC-146': 4.4772109387494, 'ACC-147': 4.218358135643738, 'ACC-148': 4.90461013772146, 'ACC-149': 4.5675302641093065, 'ACC-150': 5.043000430473343, 'ACC-151': 6.2486477960274245, 'ACC-152': 5.294208139456471, 'ACC-153': 4.606739771707067, 'ACC-154': 4.072835979320557, 'ACC-155': 4.037094829945053, 'ACC-156': 4.596818502071658, 'ACC-157': 4.199893022363225, 'ACC-158': 4.8895562916430855, 'ACC-159': 4.584092977626054, 'ACC-160': 4.77296633941094, 'ACC-161': 5.732187139298523, 'ACC-162': 3.6915986563562737, 'ACC-163': 3.694469455047412, 'ACC-164': 3.6804086770949938, 'ACC-165': 5.623723505290207, 'ACC-166': 5.626243379137252, 'ACC-167': 5.602197103533814, 'ACC-168': 5.4493986918911315, 'ACC-169': 6.934635098167551, 'ACC-170': 4.55406959410537, 'ACC-171': 5.405494765883738, 'ACC-172': 4.9559210282623996, 'ACC-173': 4.896652154444165, 'ACC-174': 3.2368341096888797, 'ACC-175': 2.687292351893862, 'ACC-176': 2.953767123287671, 'ACC-177': 3.580016572271158, 'ACC-178': 1.727991099281259, 'ACC-179': 2.137838545206652, 'ACC-180': 4.113329269531647, 'ACC-181': 2.3075410783526498, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 08:54:09] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 08:54:09] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 08:54:09] d2.evaluation.testing INFO: copypaste: 3.0125,0.4684,0.2117,5.2614,13.5891,9.8655,20.7855
[01/29 08:54:09] d2.utils.events INFO:  eta: 1 day, 13:49:43  iter: 13999  total_loss: 30.47  loss_mask: 3.052  loss_mask_0: 3.081  loss_mask_1: 3.018  loss_mask_2: 3.049  loss_mask_3: 3.027  loss_mask_4: 3.037  loss_mask_5: 3.053  loss_mask_6: 3.053  loss_mask_7: 3.057  loss_mask_8: 3.061  time: 3.0277  data_time: 0.0567  lr: 7.8733e-05  max_mem: 27646M
[01/29 08:55:09] d2.utils.events INFO:  eta: 1 day, 13:48:52  iter: 14019  total_loss: 28.15  loss_mask: 2.817  loss_mask_0: 2.882  loss_mask_1: 2.813  loss_mask_2: 2.819  loss_mask_3: 2.828  loss_mask_4: 2.792  loss_mask_5: 2.81  loss_mask_6: 2.831  loss_mask_7: 2.805  loss_mask_8: 2.817  time: 3.0276  data_time: 0.0608  lr: 7.8702e-05  max_mem: 27646M
[01/29 08:56:08] d2.utils.events INFO:  eta: 1 day, 13:48:02  iter: 14039  total_loss: 30.62  loss_mask: 3.055  loss_mask_0: 3.075  loss_mask_1: 3.012  loss_mask_2: 3.059  loss_mask_3: 3.066  loss_mask_4: 3.064  loss_mask_5: 3.035  loss_mask_6: 3.045  loss_mask_7: 3.055  loss_mask_8: 3.075  time: 3.0275  data_time: 0.0509  lr: 7.8671e-05  max_mem: 27646M
[01/29 08:57:07] d2.utils.events INFO:  eta: 1 day, 13:46:38  iter: 14059  total_loss: 29.28  loss_mask: 2.929  loss_mask_0: 2.983  loss_mask_1: 2.889  loss_mask_2: 2.933  loss_mask_3: 2.898  loss_mask_4: 2.899  loss_mask_5: 2.915  loss_mask_6: 2.936  loss_mask_7: 2.968  loss_mask_8: 2.905  time: 3.0274  data_time: 0.0555  lr: 7.864e-05  max_mem: 27646M
[01/29 08:58:06] d2.utils.events INFO:  eta: 1 day, 13:45:26  iter: 14079  total_loss: 30.08  loss_mask: 2.983  loss_mask_0: 3.041  loss_mask_1: 2.948  loss_mask_2: 2.994  loss_mask_3: 2.939  loss_mask_4: 2.955  loss_mask_5: 3.055  loss_mask_6: 2.984  loss_mask_7: 3.071  loss_mask_8: 3.016  time: 3.0273  data_time: 0.0516  lr: 7.8609e-05  max_mem: 27646M
[01/29 08:59:06] d2.utils.events INFO:  eta: 1 day, 13:44:11  iter: 14099  total_loss: 28.47  loss_mask: 2.802  loss_mask_0: 2.871  loss_mask_1: 2.777  loss_mask_2: 2.787  loss_mask_3: 2.776  loss_mask_4: 2.809  loss_mask_5: 2.885  loss_mask_6: 2.84  loss_mask_7: 2.942  loss_mask_8: 2.866  time: 3.0273  data_time: 0.0503  lr: 7.8579e-05  max_mem: 27646M
[01/29 09:00:06] d2.utils.events INFO:  eta: 1 day, 13:43:10  iter: 14119  total_loss: 31.55  loss_mask: 3.121  loss_mask_0: 3.169  loss_mask_1: 3.161  loss_mask_2: 3.138  loss_mask_3: 3.135  loss_mask_4: 3.14  loss_mask_5: 3.134  loss_mask_6: 3.139  loss_mask_7: 3.244  loss_mask_8: 3.165  time: 3.0272  data_time: 0.0537  lr: 7.8548e-05  max_mem: 27646M
[01/29 09:01:05] d2.utils.events INFO:  eta: 1 day, 13:42:11  iter: 14139  total_loss: 30.79  loss_mask: 3.094  loss_mask_0: 3.162  loss_mask_1: 3.026  loss_mask_2: 3.02  loss_mask_3: 3.063  loss_mask_4: 3.016  loss_mask_5: 3.077  loss_mask_6: 3.042  loss_mask_7: 3.169  loss_mask_8: 3.089  time: 3.0271  data_time: 0.0513  lr: 7.8517e-05  max_mem: 27646M
[01/29 09:02:04] d2.utils.events INFO:  eta: 1 day, 13:40:57  iter: 14159  total_loss: 29.18  loss_mask: 2.906  loss_mask_0: 3.011  loss_mask_1: 2.912  loss_mask_2: 2.912  loss_mask_3: 2.882  loss_mask_4: 2.912  loss_mask_5: 2.916  loss_mask_6: 2.893  loss_mask_7: 3.024  loss_mask_8: 2.927  time: 3.0270  data_time: 0.0623  lr: 7.8486e-05  max_mem: 27646M
[01/29 09:03:04] d2.utils.events INFO:  eta: 1 day, 13:40:19  iter: 14179  total_loss: 32.63  loss_mask: 3.201  loss_mask_0: 3.199  loss_mask_1: 3.174  loss_mask_2: 3.197  loss_mask_3: 3.161  loss_mask_4: 3.239  loss_mask_5: 3.233  loss_mask_6: 3.184  loss_mask_7: 3.547  loss_mask_8: 3.26  time: 3.0269  data_time: 0.0681  lr: 7.8455e-05  max_mem: 27646M
[01/29 09:04:02] d2.utils.events INFO:  eta: 1 day, 13:39:15  iter: 14199  total_loss: 28.29  loss_mask: 2.783  loss_mask_0: 3.001  loss_mask_1: 2.817  loss_mask_2: 2.863  loss_mask_3: 2.835  loss_mask_4: 2.846  loss_mask_5: 2.829  loss_mask_6: 2.85  loss_mask_7: 3.091  loss_mask_8: 2.855  time: 3.0268  data_time: 0.0587  lr: 7.8424e-05  max_mem: 27646M
[01/29 09:05:02] d2.utils.events INFO:  eta: 1 day, 13:38:32  iter: 14219  total_loss: 32.36  loss_mask: 3.337  loss_mask_0: 3.23  loss_mask_1: 3.241  loss_mask_2: 3.259  loss_mask_3: 3.209  loss_mask_4: 3.198  loss_mask_5: 3.2  loss_mask_6: 3.215  loss_mask_7: 3.427  loss_mask_8: 3.215  time: 3.0267  data_time: 0.0508  lr: 7.8394e-05  max_mem: 27646M
[01/29 09:06:01] d2.utils.events INFO:  eta: 1 day, 13:38:21  iter: 14239  total_loss: 32.06  loss_mask: 3.166  loss_mask_0: 3.216  loss_mask_1: 3.147  loss_mask_2: 3.167  loss_mask_3: 3.162  loss_mask_4: 3.217  loss_mask_5: 3.16  loss_mask_6: 3.177  loss_mask_7: 3.296  loss_mask_8: 3.165  time: 3.0266  data_time: 0.0564  lr: 7.8363e-05  max_mem: 27646M
[01/29 09:07:01] d2.utils.events INFO:  eta: 1 day, 13:37:07  iter: 14259  total_loss: 28.72  loss_mask: 2.871  loss_mask_0: 2.898  loss_mask_1: 2.873  loss_mask_2: 2.864  loss_mask_3: 2.874  loss_mask_4: 2.866  loss_mask_5: 2.891  loss_mask_6: 2.879  loss_mask_7: 2.854  loss_mask_8: 2.88  time: 3.0266  data_time: 0.0494  lr: 7.8332e-05  max_mem: 27646M
[01/29 09:07:59] d2.utils.events INFO:  eta: 1 day, 13:35:14  iter: 14279  total_loss: 31.53  loss_mask: 3.139  loss_mask_0: 3.198  loss_mask_1: 3.137  loss_mask_2: 3.159  loss_mask_3: 3.146  loss_mask_4: 3.156  loss_mask_5: 3.129  loss_mask_6: 3.173  loss_mask_7: 3.138  loss_mask_8: 3.133  time: 3.0264  data_time: 0.0535  lr: 7.8301e-05  max_mem: 27646M
[01/29 09:08:59] d2.utils.events INFO:  eta: 1 day, 13:33:41  iter: 14299  total_loss: 29.17  loss_mask: 2.956  loss_mask_0: 2.988  loss_mask_1: 2.898  loss_mask_2: 2.894  loss_mask_3: 2.913  loss_mask_4: 2.953  loss_mask_5: 2.885  loss_mask_6: 2.943  loss_mask_7: 2.949  loss_mask_8: 2.888  time: 3.0264  data_time: 0.0536  lr: 7.827e-05  max_mem: 27646M
[01/29 09:09:58] d2.utils.events INFO:  eta: 1 day, 13:32:09  iter: 14319  total_loss: 28.66  loss_mask: 2.868  loss_mask_0: 2.961  loss_mask_1: 2.847  loss_mask_2: 2.85  loss_mask_3: 2.858  loss_mask_4: 2.871  loss_mask_5: 2.861  loss_mask_6: 2.872  loss_mask_7: 2.893  loss_mask_8: 2.878  time: 3.0262  data_time: 0.0615  lr: 7.8239e-05  max_mem: 27646M
[01/29 09:10:57] d2.utils.events INFO:  eta: 1 day, 13:30:43  iter: 14339  total_loss: 33.61  loss_mask: 3.329  loss_mask_0: 3.377  loss_mask_1: 3.345  loss_mask_2: 3.363  loss_mask_3: 3.344  loss_mask_4: 3.365  loss_mask_5: 3.313  loss_mask_6: 3.315  loss_mask_7: 3.407  loss_mask_8: 3.377  time: 3.0262  data_time: 0.0541  lr: 7.8209e-05  max_mem: 27646M
[01/29 09:11:57] d2.utils.events INFO:  eta: 1 day, 13:30:43  iter: 14359  total_loss: 31.98  loss_mask: 3.222  loss_mask_0: 3.209  loss_mask_1: 3.206  loss_mask_2: 3.216  loss_mask_3: 3.203  loss_mask_4: 3.176  loss_mask_5: 3.188  loss_mask_6: 3.184  loss_mask_7: 3.216  loss_mask_8: 3.184  time: 3.0261  data_time: 0.0610  lr: 7.8178e-05  max_mem: 27646M
[01/29 09:12:56] d2.utils.events INFO:  eta: 1 day, 13:29:16  iter: 14379  total_loss: 29.53  loss_mask: 2.97  loss_mask_0: 3.038  loss_mask_1: 2.984  loss_mask_2: 2.876  loss_mask_3: 2.973  loss_mask_4: 2.916  loss_mask_5: 2.938  loss_mask_6: 2.933  loss_mask_7: 2.91  loss_mask_8: 2.965  time: 3.0260  data_time: 0.0498  lr: 7.8147e-05  max_mem: 27646M
[01/29 09:13:56] d2.utils.events INFO:  eta: 1 day, 13:28:31  iter: 14399  total_loss: 29.94  loss_mask: 3.139  loss_mask_0: 2.952  loss_mask_1: 2.965  loss_mask_2: 2.955  loss_mask_3: 2.975  loss_mask_4: 2.959  loss_mask_5: 2.998  loss_mask_6: 3.008  loss_mask_7: 3.001  loss_mask_8: 3.094  time: 3.0260  data_time: 0.0600  lr: 7.8116e-05  max_mem: 27646M
[01/29 09:14:55] d2.utils.events INFO:  eta: 1 day, 13:27:26  iter: 14419  total_loss: 30.23  loss_mask: 3.016  loss_mask_0: 3.056  loss_mask_1: 3.03  loss_mask_2: 2.994  loss_mask_3: 3.019  loss_mask_4: 3.002  loss_mask_5: 3.007  loss_mask_6: 3.03  loss_mask_7: 3.02  loss_mask_8: 3.014  time: 3.0259  data_time: 0.0533  lr: 7.8085e-05  max_mem: 27646M
[01/29 09:15:54] d2.utils.events INFO:  eta: 1 day, 13:26:19  iter: 14439  total_loss: 29.21  loss_mask: 2.983  loss_mask_0: 2.992  loss_mask_1: 2.888  loss_mask_2: 2.92  loss_mask_3: 2.911  loss_mask_4: 2.918  loss_mask_5: 2.937  loss_mask_6: 2.92  loss_mask_7: 2.924  loss_mask_8: 2.938  time: 3.0258  data_time: 0.0557  lr: 7.8054e-05  max_mem: 27646M
[01/29 09:16:53] d2.utils.events INFO:  eta: 1 day, 13:25:19  iter: 14459  total_loss: 28.17  loss_mask: 2.791  loss_mask_0: 2.856  loss_mask_1: 2.773  loss_mask_2: 2.812  loss_mask_3: 2.811  loss_mask_4: 2.791  loss_mask_5: 2.794  loss_mask_6: 2.796  loss_mask_7: 2.793  loss_mask_8: 2.813  time: 3.0257  data_time: 0.0603  lr: 7.8024e-05  max_mem: 27646M
[01/29 09:17:53] d2.utils.events INFO:  eta: 1 day, 13:24:37  iter: 14479  total_loss: 31.85  loss_mask: 3.198  loss_mask_0: 3.195  loss_mask_1: 3.147  loss_mask_2: 3.175  loss_mask_3: 3.197  loss_mask_4: 3.204  loss_mask_5: 3.19  loss_mask_6: 3.201  loss_mask_7: 3.182  loss_mask_8: 3.17  time: 3.0256  data_time: 0.0589  lr: 7.7993e-05  max_mem: 27646M
[01/29 09:18:52] d2.utils.events INFO:  eta: 1 day, 13:23:35  iter: 14499  total_loss: 30.48  loss_mask: 3.047  loss_mask_0: 3.092  loss_mask_1: 3.034  loss_mask_2: 3.014  loss_mask_3: 3.019  loss_mask_4: 3.041  loss_mask_5: 3.04  loss_mask_6: 3.022  loss_mask_7: 3.029  loss_mask_8: 3  time: 3.0255  data_time: 0.0594  lr: 7.7962e-05  max_mem: 27646M
[01/29 09:19:51] d2.utils.events INFO:  eta: 1 day, 13:22:17  iter: 14519  total_loss: 29.62  loss_mask: 2.952  loss_mask_0: 3.072  loss_mask_1: 2.944  loss_mask_2: 2.965  loss_mask_3: 2.949  loss_mask_4: 2.916  loss_mask_5: 2.926  loss_mask_6: 2.993  loss_mask_7: 2.985  loss_mask_8: 2.934  time: 3.0254  data_time: 0.0567  lr: 7.7931e-05  max_mem: 27646M
[01/29 09:20:50] d2.utils.events INFO:  eta: 1 day, 13:20:16  iter: 14539  total_loss: 27.95  loss_mask: 2.772  loss_mask_0: 2.812  loss_mask_1: 2.747  loss_mask_2: 2.801  loss_mask_3: 2.788  loss_mask_4: 2.784  loss_mask_5: 2.761  loss_mask_6: 2.826  loss_mask_7: 2.824  loss_mask_8: 2.839  time: 3.0253  data_time: 0.0550  lr: 7.79e-05  max_mem: 27646M
[01/29 09:21:49] d2.utils.events INFO:  eta: 1 day, 13:19:17  iter: 14559  total_loss: 30.07  loss_mask: 2.983  loss_mask_0: 3.02  loss_mask_1: 3.007  loss_mask_2: 3  loss_mask_3: 2.982  loss_mask_4: 2.974  loss_mask_5: 3.022  loss_mask_6: 2.989  loss_mask_7: 2.995  loss_mask_8: 3.022  time: 3.0252  data_time: 0.0586  lr: 7.7869e-05  max_mem: 27646M
[01/29 09:22:49] d2.utils.events INFO:  eta: 1 day, 13:18:26  iter: 14579  total_loss: 26.67  loss_mask: 2.655  loss_mask_0: 2.701  loss_mask_1: 2.672  loss_mask_2: 2.662  loss_mask_3: 2.678  loss_mask_4: 2.655  loss_mask_5: 2.679  loss_mask_6: 2.655  loss_mask_7: 2.664  loss_mask_8: 2.681  time: 3.0251  data_time: 0.0598  lr: 7.7839e-05  max_mem: 27646M
[01/29 09:23:48] d2.utils.events INFO:  eta: 1 day, 13:17:19  iter: 14599  total_loss: 29.98  loss_mask: 2.993  loss_mask_0: 3.036  loss_mask_1: 2.98  loss_mask_2: 3.003  loss_mask_3: 3.009  loss_mask_4: 3.004  loss_mask_5: 2.978  loss_mask_6: 2.995  loss_mask_7: 2.995  loss_mask_8: 2.985  time: 3.0250  data_time: 0.0601  lr: 7.7808e-05  max_mem: 27646M
[01/29 09:24:48] d2.utils.events INFO:  eta: 1 day, 13:16:09  iter: 14619  total_loss: 29.33  loss_mask: 2.908  loss_mask_0: 3.015  loss_mask_1: 2.888  loss_mask_2: 2.923  loss_mask_3: 2.94  loss_mask_4: 2.921  loss_mask_5: 2.929  loss_mask_6: 2.918  loss_mask_7: 2.955  loss_mask_8: 2.968  time: 3.0250  data_time: 0.0478  lr: 7.7777e-05  max_mem: 27646M
[01/29 09:25:47] d2.utils.events INFO:  eta: 1 day, 13:14:38  iter: 14639  total_loss: 30.81  loss_mask: 3.08  loss_mask_0: 3.156  loss_mask_1: 3.048  loss_mask_2: 3.061  loss_mask_3: 3.091  loss_mask_4: 3.079  loss_mask_5: 3.065  loss_mask_6: 3.092  loss_mask_7: 3.088  loss_mask_8: 3.074  time: 3.0249  data_time: 0.0502  lr: 7.7746e-05  max_mem: 27646M
[01/29 09:26:46] d2.utils.events INFO:  eta: 1 day, 13:13:07  iter: 14659  total_loss: 27.51  loss_mask: 2.751  loss_mask_0: 2.744  loss_mask_1: 2.747  loss_mask_2: 2.772  loss_mask_3: 2.726  loss_mask_4: 2.745  loss_mask_5: 2.703  loss_mask_6: 2.753  loss_mask_7: 2.822  loss_mask_8: 2.732  time: 3.0248  data_time: 0.0602  lr: 7.7715e-05  max_mem: 27646M
[01/29 09:27:45] d2.utils.events INFO:  eta: 1 day, 13:11:42  iter: 14679  total_loss: 28.94  loss_mask: 2.866  loss_mask_0: 2.98  loss_mask_1: 2.85  loss_mask_2: 2.854  loss_mask_3: 2.896  loss_mask_4: 2.866  loss_mask_5: 2.921  loss_mask_6: 2.866  loss_mask_7: 2.854  loss_mask_8: 2.879  time: 3.0247  data_time: 0.0447  lr: 7.7684e-05  max_mem: 27646M
[01/29 09:28:44] d2.utils.events INFO:  eta: 1 day, 13:10:58  iter: 14699  total_loss: 28.21  loss_mask: 2.848  loss_mask_0: 2.927  loss_mask_1: 2.795  loss_mask_2: 2.787  loss_mask_3: 2.784  loss_mask_4: 2.804  loss_mask_5: 2.8  loss_mask_6: 2.794  loss_mask_7: 2.803  loss_mask_8: 2.808  time: 3.0246  data_time: 0.0536  lr: 7.7653e-05  max_mem: 27646M
[01/29 09:29:43] d2.utils.events INFO:  eta: 1 day, 13:10:16  iter: 14719  total_loss: 30.28  loss_mask: 3.009  loss_mask_0: 3.13  loss_mask_1: 3.005  loss_mask_2: 3.045  loss_mask_3: 3.047  loss_mask_4: 3.025  loss_mask_5: 3.018  loss_mask_6: 3.009  loss_mask_7: 3.024  loss_mask_8: 3.041  time: 3.0245  data_time: 0.0680  lr: 7.7623e-05  max_mem: 27646M
[01/29 09:30:42] d2.utils.events INFO:  eta: 1 day, 13:08:44  iter: 14739  total_loss: 29.15  loss_mask: 3.011  loss_mask_0: 3.074  loss_mask_1: 2.89  loss_mask_2: 3.005  loss_mask_3: 2.916  loss_mask_4: 2.934  loss_mask_5: 2.906  loss_mask_6: 2.909  loss_mask_7: 2.908  loss_mask_8: 2.922  time: 3.0244  data_time: 0.0519  lr: 7.7592e-05  max_mem: 27646M
[01/29 09:31:42] d2.utils.events INFO:  eta: 1 day, 13:07:46  iter: 14759  total_loss: 31.51  loss_mask: 3.132  loss_mask_0: 3.203  loss_mask_1: 3.15  loss_mask_2: 3.179  loss_mask_3: 3.113  loss_mask_4: 3.141  loss_mask_5: 3.106  loss_mask_6: 3.116  loss_mask_7: 3.109  loss_mask_8: 3.121  time: 3.0243  data_time: 0.0615  lr: 7.7561e-05  max_mem: 27646M
[01/29 09:32:41] d2.utils.events INFO:  eta: 1 day, 13:05:54  iter: 14779  total_loss: 29.2  loss_mask: 2.904  loss_mask_0: 2.965  loss_mask_1: 2.881  loss_mask_2: 2.927  loss_mask_3: 2.923  loss_mask_4: 2.923  loss_mask_5: 2.902  loss_mask_6: 2.913  loss_mask_7: 2.905  loss_mask_8: 2.913  time: 3.0242  data_time: 0.0585  lr: 7.753e-05  max_mem: 27646M
[01/29 09:33:40] d2.utils.events INFO:  eta: 1 day, 13:04:02  iter: 14799  total_loss: 30.93  loss_mask: 3.081  loss_mask_0: 3.118  loss_mask_1: 3.08  loss_mask_2: 3.083  loss_mask_3: 3.094  loss_mask_4: 3.11  loss_mask_5: 3.094  loss_mask_6: 3.077  loss_mask_7: 3.091  loss_mask_8: 3.095  time: 3.0241  data_time: 0.0573  lr: 7.7499e-05  max_mem: 27646M
[01/29 09:34:39] d2.utils.events INFO:  eta: 1 day, 13:03:12  iter: 14819  total_loss: 27.13  loss_mask: 2.723  loss_mask_0: 2.703  loss_mask_1: 2.71  loss_mask_2: 2.742  loss_mask_3: 2.716  loss_mask_4: 2.734  loss_mask_5: 2.685  loss_mask_6: 2.701  loss_mask_7: 2.727  loss_mask_8: 2.698  time: 3.0240  data_time: 0.0596  lr: 7.7468e-05  max_mem: 27646M
[01/29 09:35:38] d2.utils.events INFO:  eta: 1 day, 13:02:13  iter: 14839  total_loss: 27.08  loss_mask: 2.693  loss_mask_0: 2.867  loss_mask_1: 2.695  loss_mask_2: 2.708  loss_mask_3: 2.716  loss_mask_4: 2.693  loss_mask_5: 2.698  loss_mask_6: 2.704  loss_mask_7: 2.715  loss_mask_8: 2.674  time: 3.0239  data_time: 0.0623  lr: 7.7437e-05  max_mem: 27646M
[01/29 09:36:37] d2.utils.events INFO:  eta: 1 day, 13:02:04  iter: 14859  total_loss: 35.09  loss_mask: 3.481  loss_mask_0: 3.581  loss_mask_1: 3.489  loss_mask_2: 3.496  loss_mask_3: 3.502  loss_mask_4: 3.487  loss_mask_5: 3.506  loss_mask_6: 3.502  loss_mask_7: 3.502  loss_mask_8: 3.499  time: 3.0239  data_time: 0.0534  lr: 7.7407e-05  max_mem: 27646M
[01/29 09:37:37] d2.utils.events INFO:  eta: 1 day, 13:01:05  iter: 14879  total_loss: 31.88  loss_mask: 3.215  loss_mask_0: 3.133  loss_mask_1: 3.208  loss_mask_2: 3.152  loss_mask_3: 3.208  loss_mask_4: 3.243  loss_mask_5: 3.211  loss_mask_6: 3.112  loss_mask_7: 3.167  loss_mask_8: 3.17  time: 3.0238  data_time: 0.0556  lr: 7.7376e-05  max_mem: 27646M
[01/29 09:38:36] d2.utils.events INFO:  eta: 1 day, 12:59:59  iter: 14899  total_loss: 30.26  loss_mask: 3.081  loss_mask_0: 3.032  loss_mask_1: 2.997  loss_mask_2: 3.074  loss_mask_3: 3.048  loss_mask_4: 3.074  loss_mask_5: 3.045  loss_mask_6: 2.978  loss_mask_7: 3.056  loss_mask_8: 3.056  time: 3.0237  data_time: 0.0678  lr: 7.7345e-05  max_mem: 27646M
[01/29 09:39:35] d2.utils.events INFO:  eta: 1 day, 12:59:00  iter: 14919  total_loss: 30.09  loss_mask: 2.988  loss_mask_0: 3.009  loss_mask_1: 2.968  loss_mask_2: 3  loss_mask_3: 2.994  loss_mask_4: 2.995  loss_mask_5: 2.985  loss_mask_6: 2.993  loss_mask_7: 3.008  loss_mask_8: 2.985  time: 3.0236  data_time: 0.0565  lr: 7.7314e-05  max_mem: 27646M
[01/29 09:40:35] d2.utils.events INFO:  eta: 1 day, 12:58:58  iter: 14939  total_loss: 30.83  loss_mask: 3.158  loss_mask_0: 3.169  loss_mask_1: 3.024  loss_mask_2: 3.034  loss_mask_3: 3.071  loss_mask_4: 3.075  loss_mask_5: 3.055  loss_mask_6: 3.079  loss_mask_7: 3.093  loss_mask_8: 3.081  time: 3.0236  data_time: 0.0593  lr: 7.7283e-05  max_mem: 27646M
[01/29 09:41:35] d2.utils.events INFO:  eta: 1 day, 12:57:30  iter: 14959  total_loss: 30.48  loss_mask: 3.082  loss_mask_0: 3.159  loss_mask_1: 3.063  loss_mask_2: 3.016  loss_mask_3: 3.108  loss_mask_4: 3.023  loss_mask_5: 3.131  loss_mask_6: 3.065  loss_mask_7: 3.032  loss_mask_8: 3.004  time: 3.0235  data_time: 0.0541  lr: 7.7252e-05  max_mem: 27646M
[01/29 09:42:34] d2.utils.events INFO:  eta: 1 day, 12:57:10  iter: 14979  total_loss: 28.08  loss_mask: 2.836  loss_mask_0: 2.912  loss_mask_1: 2.698  loss_mask_2: 2.702  loss_mask_3: 2.749  loss_mask_4: 2.808  loss_mask_5: 3.004  loss_mask_6: 2.798  loss_mask_7: 2.755  loss_mask_8: 2.768  time: 3.0234  data_time: 0.0521  lr: 7.7221e-05  max_mem: 27646M
[01/29 09:43:34] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/model_0014999.pth
[01/29 09:43:34] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 09:43:35] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 09:43:35] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 09:57:34] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.0791179002662528, 'error_1pix': 0.45809273268115924, 'error_3pix': 0.21864107002520503, 'mIoU': 5.048539949015495, 'fwIoU': 14.431953180182763, 'IoU-0': 0.00028478254476874815, 'IoU-1': 49.30606534960316, 'IoU-2': 1.8607961845310248, 'IoU-3': 1.3217632533349817, 'IoU-4': 1.1788430549798323, 'IoU-5': 1.1848088517473443, 'IoU-6': 1.4965032210442126, 'IoU-7': 1.655809467059902, 'IoU-8': 3.187613137199563, 'IoU-9': 6.521366486204546, 'IoU-10': 8.154860851649518, 'IoU-11': 15.825151337642687, 'IoU-12': 17.040068369141874, 'IoU-13': 16.769159464862348, 'IoU-14': 16.424408173803617, 'IoU-15': 15.618929969259629, 'IoU-16': 14.277938599645266, 'IoU-17': 11.592278256648726, 'IoU-18': 12.767517797540098, 'IoU-19': 13.417021491721048, 'IoU-20': 13.158103576830877, 'IoU-21': 13.501896649076848, 'IoU-22': 13.787273097245958, 'IoU-23': 13.468936936108975, 'IoU-24': 14.222351119690396, 'IoU-25': 15.204018125477214, 'IoU-26': 15.34862431487334, 'IoU-27': 17.050162734046705, 'IoU-28': 16.050534277121578, 'IoU-29': 16.156678867469466, 'IoU-30': 15.83591133252748, 'IoU-31': 16.126973459883075, 'IoU-32': 15.49807235961811, 'IoU-33': 14.367472449307325, 'IoU-34': 13.886445629968897, 'IoU-35': 14.405560378041576, 'IoU-36': 14.023172265944167, 'IoU-37': 13.312916207127119, 'IoU-38': 12.958352747821694, 'IoU-39': 12.015215617869314, 'IoU-40': 11.78829011572047, 'IoU-41': 10.976299746825864, 'IoU-42': 10.381291517119767, 'IoU-43': 10.327697476207822, 'IoU-44': 10.391218483976969, 'IoU-45': 10.161398661245984, 'IoU-46': 9.417174271273758, 'IoU-47': 9.125693463819069, 'IoU-48': 8.617290555009733, 'IoU-49': 8.90333331169203, 'IoU-50': 8.92492740557591, 'IoU-51': 8.456606988397613, 'IoU-52': 8.208650631398681, 'IoU-53': 8.057369998773549, 'IoU-54': 8.149090280368906, 'IoU-55': 7.6933369162653085, 'IoU-56': 7.21629538263677, 'IoU-57': 7.028308676136359, 'IoU-58': 6.918621975340787, 'IoU-59': 6.650881790968169, 'IoU-60': 6.319399897521954, 'IoU-61': 5.764004047188633, 'IoU-62': 5.629055171496043, 'IoU-63': 5.370315659978192, 'IoU-64': 5.141252692850738, 'IoU-65': 4.894546493366017, 'IoU-66': 4.596909900633402, 'IoU-67': 4.385836529158695, 'IoU-68': 4.18388219662589, 'IoU-69': 4.252368983360795, 'IoU-70': 4.008677744755882, 'IoU-71': 3.7883231111512483, 'IoU-72': 3.713600723880618, 'IoU-73': 3.588940012413201, 'IoU-74': 3.590684169374667, 'IoU-75': 3.4955118195128905, 'IoU-76': 3.5839659051611883, 'IoU-77': 3.3826470999210003, 'IoU-78': 3.2754209175469464, 'IoU-79': 3.307014603988113, 'IoU-80': 3.1892080697712273, 'IoU-81': 3.050544117675024, 'IoU-82': 2.8838410729820576, 'IoU-83': 3.106419933332368, 'IoU-84': 2.7841611394409367, 'IoU-85': 2.9367142604564926, 'IoU-86': 2.8422651250824673, 'IoU-87': 2.7574924890863075, 'IoU-88': 2.820494735320821, 'IoU-89': 2.846338238778063, 'IoU-90': 2.931378537623492, 'IoU-91': 2.8787076082331606, 'IoU-92': 2.878402759671147, 'IoU-93': 2.8103685219370047, 'IoU-94': 2.8239494943654537, 'IoU-95': 2.6695974725120504, 'IoU-96': 2.535786491698915, 'IoU-97': 2.5746541960822382, 'IoU-98': 2.2653650778846757, 'IoU-99': 2.310789206945806, 'IoU-100': 2.136290775115638, 'IoU-101': 2.1038114868974773, 'IoU-102': 2.0090192752222547, 'IoU-103': 1.9719996835828413, 'IoU-104': 1.9304608601349162, 'IoU-105': 2.063580333185629, 'IoU-106': 2.1334464235227597, 'IoU-107': 2.1309813853605926, 'IoU-108': 2.2041813534272707, 'IoU-109': 2.2957969909576477, 'IoU-110': 2.2209166612640567, 'IoU-111': 2.1719571436917566, 'IoU-112': 2.3847642490673837, 'IoU-113': 2.278717419723755, 'IoU-114': 2.192543896401913, 'IoU-115': 2.19932159505968, 'IoU-116': 2.1032034913981335, 'IoU-117': 2.149409314143365, 'IoU-118': 2.2903046954338984, 'IoU-119': 2.31001802268454, 'IoU-120': 2.4794553808000606, 'IoU-121': 2.3186397220370196, 'IoU-122': 2.2940272278932508, 'IoU-123': 2.221650713032519, 'IoU-124': 2.1273214795050177, 'IoU-125': 2.165381549623412, 'IoU-126': 2.299312341549836, 'IoU-127': 2.4138122763843777, 'IoU-128': 2.397478857507579, 'IoU-129': 2.307670485866425, 'IoU-130': 2.3217493815066335, 'IoU-131': 2.5280726896132344, 'IoU-132': 2.5679155918148, 'IoU-133': 2.5700634363611825, 'IoU-134': 2.2414167816541273, 'IoU-135': 2.109857895033096, 'IoU-136': 2.029964206592217, 'IoU-137': 2.0672024666411066, 'IoU-138': 2.078584977911148, 'IoU-139': 2.0796245551571455, 'IoU-140': 2.0647907415307127, 'IoU-141': 1.9144806790153523, 'IoU-142': 1.6428703349833504, 'IoU-143': 1.6088817598225873, 'IoU-144': 1.7825220532767676, 'IoU-145': 2.0659389858015955, 'IoU-146': 2.06889979466389, 'IoU-147': 2.5218126921062733, 'IoU-148': 2.0529365996370394, 'IoU-149': 2.1571818708449424, 'IoU-150': 2.4467982576521043, 'IoU-151': 2.1982004095605028, 'IoU-152': 1.9449334412531092, 'IoU-153': 1.8944984117162518, 'IoU-154': 2.029701869293983, 'IoU-155': 2.0411468493147646, 'IoU-156': 1.683012054782471, 'IoU-157': 1.742517460853402, 'IoU-158': 1.8457269972340313, 'IoU-159': 1.7278322894809521, 'IoU-160': 1.503902379089842, 'IoU-161': 1.26392286260927, 'IoU-162': 1.3292555438067823, 'IoU-163': 1.5123021916251014, 'IoU-164': 1.4466240233298697, 'IoU-165': 1.5404704849411823, 'IoU-166': 1.4875661318996722, 'IoU-167': 1.3227699848965822, 'IoU-168': 1.5268323034936515, 'IoU-169': 1.3469568962979561, 'IoU-170': 1.6390458802837176, 'IoU-171': 1.7503892895357234, 'IoU-172': 1.4448161251257992, 'IoU-173': 1.3713914861151733, 'IoU-174': 1.4915619293125792, 'IoU-175': 1.1851531756463427, 'IoU-176': 1.1552025489246092, 'IoU-177': 1.1039173424802289, 'IoU-178': 0.8713967702523852, 'IoU-179': 0.19764806100688193, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 9.25225202498893, 'pACC': 22.018908028929005, 'ACC-0': 0.0013919218439374125, 'ACC-1': 50.27441959504368, 'ACC-2': 3.8093552900943113, 'ACC-3': 5.731818066278298, 'ACC-4': 4.572389461700305, 'ACC-5': 4.66382489824712, 'ACC-6': 6.027900944575803, 'ACC-7': 7.123036926027616, 'ACC-8': 6.847630437268965, 'ACC-9': 9.330061150348067, 'ACC-10': 10.888257436433255, 'ACC-11': 21.344662027217947, 'ACC-12': 26.633586334133447, 'ACC-13': 27.66750401603038, 'ACC-14': 27.674916454122183, 'ACC-15': 27.587215446674485, 'ACC-16': 25.39601176223556, 'ACC-17': 21.88419908600021, 'ACC-18': 22.87716108239211, 'ACC-19': 24.28197595823668, 'ACC-20': 24.03621682379464, 'ACC-21': 24.239097549742, 'ACC-22': 24.297216550689495, 'ACC-23': 25.69363513149243, 'ACC-24': 27.217585435046555, 'ACC-25': 28.566831415117775, 'ACC-26': 28.493827986434265, 'ACC-27': 30.673670831327975, 'ACC-28': 29.48707777015766, 'ACC-29': 28.765183586980736, 'ACC-30': 28.605976148978296, 'ACC-31': 28.506563138614055, 'ACC-32': 27.965277301449063, 'ACC-33': 26.25030625350154, 'ACC-34': 25.48875504866903, 'ACC-35': 26.286240209920386, 'ACC-36': 25.38428377042018, 'ACC-37': 24.545995821512193, 'ACC-38': 23.869626325198258, 'ACC-39': 21.98601978730756, 'ACC-40': 21.293028444522037, 'ACC-41': 20.43267289475829, 'ACC-42': 19.263345230074304, 'ACC-43': 19.02320473721532, 'ACC-44': 18.615795093622925, 'ACC-45': 18.325703632230155, 'ACC-46': 17.546729327717433, 'ACC-47': 17.041863392843183, 'ACC-48': 16.028632333207515, 'ACC-49': 16.43740065615011, 'ACC-50': 16.37371938188804, 'ACC-51': 15.641039718672308, 'ACC-52': 15.223520853236113, 'ACC-53': 15.025863173730167, 'ACC-54': 15.001519168409901, 'ACC-55': 14.205298244455467, 'ACC-56': 13.503763650791493, 'ACC-57': 12.971180984474874, 'ACC-58': 13.02378710136989, 'ACC-59': 12.67688875037208, 'ACC-60': 12.118736357645734, 'ACC-61': 11.13797097365272, 'ACC-62': 11.012274250047142, 'ACC-63': 10.628920620304664, 'ACC-64': 10.173506189409029, 'ACC-65': 9.772079250719749, 'ACC-66': 9.194149624432397, 'ACC-67': 8.792035453472607, 'ACC-68': 8.333296477204952, 'ACC-69': 8.307083574170173, 'ACC-70': 7.759168096705199, 'ACC-71': 7.465057469870286, 'ACC-72': 7.352084330039636, 'ACC-73': 7.167472019637853, 'ACC-74': 7.160963486217805, 'ACC-75': 7.024359560966607, 'ACC-76': 7.112457261182627, 'ACC-77': 6.791538792216034, 'ACC-78': 6.5974484518186705, 'ACC-79': 6.608578866006997, 'ACC-80': 6.231578072040845, 'ACC-81': 5.865618043759841, 'ACC-82': 5.499057265893322, 'ACC-83': 5.778947519548798, 'ACC-84': 5.200037699842339, 'ACC-85': 5.449450138940773, 'ACC-86': 5.253319277333455, 'ACC-87': 5.040048879845041, 'ACC-88': 5.126472296801864, 'ACC-89': 5.1539426547867055, 'ACC-90': 5.294381707487374, 'ACC-91': 5.273417354284413, 'ACC-92': 5.318526437421995, 'ACC-93': 5.167966993085207, 'ACC-94': 5.161160050699305, 'ACC-95': 4.871281113360133, 'ACC-96': 4.623148315142262, 'ACC-97': 4.622545874909195, 'ACC-98': 4.069288718459113, 'ACC-99': 4.181345055989361, 'ACC-100': 3.874497525436951, 'ACC-101': 3.7942916686010824, 'ACC-102': 3.6178522881739923, 'ACC-103': 3.5791300651742706, 'ACC-104': 3.5215316888418875, 'ACC-105': 3.7595730460412855, 'ACC-106': 3.858543918677071, 'ACC-107': 3.8516768272783053, 'ACC-108': 3.9139935668178465, 'ACC-109': 4.069523999869593, 'ACC-110': 3.991787229135283, 'ACC-111': 3.9030286619902155, 'ACC-112': 4.313501350315207, 'ACC-113': 4.123618747410016, 'ACC-114': 3.966731742053654, 'ACC-115': 3.979447626779727, 'ACC-116': 3.8481522297910207, 'ACC-117': 3.9614586840918826, 'ACC-118': 4.275312938631572, 'ACC-119': 4.269243850730226, 'ACC-120': 4.52597188107261, 'ACC-121': 4.215882163509078, 'ACC-122': 4.14829177163237, 'ACC-123': 4.0706062537869885, 'ACC-124': 3.9653700040647784, 'ACC-125': 4.054056993809844, 'ACC-126': 4.394905691308664, 'ACC-127': 4.589392013755853, 'ACC-128': 4.581401674124975, 'ACC-129': 4.4921461960303954, 'ACC-130': 4.5090456941051436, 'ACC-131': 4.857138869671492, 'ACC-132': 4.842282340246571, 'ACC-133': 4.858641735899896, 'ACC-134': 4.237277035760448, 'ACC-135': 3.9532381278148336, 'ACC-136': 3.8614074729780095, 'ACC-137': 3.925838239009263, 'ACC-138': 3.9504118333883294, 'ACC-139': 4.049262432640051, 'ACC-140': 4.020957880491049, 'ACC-141': 3.671699720099169, 'ACC-142': 3.1384354195977333, 'ACC-143': 3.01576218961534, 'ACC-144': 3.3567689530685922, 'ACC-145': 3.9624320758514275, 'ACC-146': 4.027415412030797, 'ACC-147': 4.824495836981643, 'ACC-148': 3.8472469490547514, 'ACC-149': 4.203154140328922, 'ACC-150': 4.86893493807125, 'ACC-151': 4.428621215560764, 'ACC-152': 3.878907040258952, 'ACC-153': 3.905806262481907, 'ACC-154': 4.28629969225061, 'ACC-155': 4.535907884130424, 'ACC-156': 3.858648929912674, 'ACC-157': 4.088015646500157, 'ACC-158': 4.570454349792747, 'ACC-159': 3.8582369069458187, 'ACC-160': 3.4438198434601635, 'ACC-161': 2.9443069897803005, 'ACC-162': 3.3007935114742293, 'ACC-163': 4.059208122696497, 'ACC-164': 3.8915965613792536, 'ACC-165': 4.374783611316691, 'ACC-166': 4.1973961437409235, 'ACC-167': 3.81105743424584, 'ACC-168': 4.357549757366903, 'ACC-169': 3.9342473060732455, 'ACC-170': 4.698347459431833, 'ACC-171': 5.913568658857587, 'ACC-172': 4.498833203689299, 'ACC-173': 4.91396146045388, 'ACC-174': 4.760653219778519, 'ACC-175': 3.2857626197356526, 'ACC-176': 3.3172742047829114, 'ACC-177': 2.4291849136968526, 'ACC-178': 2.0513375222855994, 'ACC-179': 0.274914228789505, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 09:57:34] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 09:57:34] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 09:57:34] d2.evaluation.testing INFO: copypaste: 3.0791,0.4581,0.2186,5.0485,14.4320,9.2523,22.0189
[01/29 09:57:34] d2.utils.events INFO:  eta: 1 day, 12:56:20  iter: 14999  total_loss: 31.32  loss_mask: 3.119  loss_mask_0: 3.163  loss_mask_1: 3.048  loss_mask_2: 3.117  loss_mask_3: 3.116  loss_mask_4: 3.163  loss_mask_5: 3.166  loss_mask_6: 3.109  loss_mask_7: 3.162  loss_mask_8: 3.133  time: 3.0234  data_time: 0.0579  lr: 7.719e-05  max_mem: 27646M
[01/29 09:58:33] d2.utils.events INFO:  eta: 1 day, 12:54:54  iter: 15019  total_loss: 28.92  loss_mask: 2.914  loss_mask_0: 2.926  loss_mask_1: 2.867  loss_mask_2: 2.877  loss_mask_3: 2.876  loss_mask_4: 2.908  loss_mask_5: 2.955  loss_mask_6: 2.874  loss_mask_7: 2.923  loss_mask_8: 2.932  time: 3.0233  data_time: 0.0542  lr: 7.716e-05  max_mem: 27646M
[01/29 09:59:33] d2.utils.events INFO:  eta: 1 day, 12:54:19  iter: 15039  total_loss: 28.72  loss_mask: 2.866  loss_mask_0: 2.917  loss_mask_1: 2.844  loss_mask_2: 2.858  loss_mask_3: 2.872  loss_mask_4: 2.865  loss_mask_5: 2.988  loss_mask_6: 2.88  loss_mask_7: 2.849  loss_mask_8: 2.83  time: 3.0232  data_time: 0.0573  lr: 7.7129e-05  max_mem: 27646M
[01/29 10:00:32] d2.utils.events INFO:  eta: 1 day, 12:53:20  iter: 15059  total_loss: 27.65  loss_mask: 2.755  loss_mask_0: 2.933  loss_mask_1: 2.734  loss_mask_2: 2.711  loss_mask_3: 2.77  loss_mask_4: 2.778  loss_mask_5: 2.781  loss_mask_6: 2.762  loss_mask_7: 2.768  loss_mask_8: 2.746  time: 3.0231  data_time: 0.0586  lr: 7.7098e-05  max_mem: 27646M
[01/29 10:01:32] d2.utils.events INFO:  eta: 1 day, 12:52:24  iter: 15079  total_loss: 25.7  loss_mask: 2.571  loss_mask_0: 2.63  loss_mask_1: 2.553  loss_mask_2: 2.559  loss_mask_3: 2.562  loss_mask_4: 2.556  loss_mask_5: 2.596  loss_mask_6: 2.561  loss_mask_7: 2.555  loss_mask_8: 2.558  time: 3.0231  data_time: 0.0577  lr: 7.7067e-05  max_mem: 27646M
[01/29 10:02:31] d2.utils.events INFO:  eta: 1 day, 12:51:22  iter: 15099  total_loss: 29.18  loss_mask: 2.89  loss_mask_0: 2.988  loss_mask_1: 2.899  loss_mask_2: 2.898  loss_mask_3: 2.937  loss_mask_4: 2.9  loss_mask_5: 2.958  loss_mask_6: 2.939  loss_mask_7: 2.902  loss_mask_8: 2.934  time: 3.0230  data_time: 0.0563  lr: 7.7036e-05  max_mem: 27646M
[01/29 10:03:30] d2.utils.events INFO:  eta: 1 day, 12:49:34  iter: 15119  total_loss: 26.18  loss_mask: 2.621  loss_mask_0: 2.646  loss_mask_1: 2.612  loss_mask_2: 2.667  loss_mask_3: 2.634  loss_mask_4: 2.594  loss_mask_5: 2.583  loss_mask_6: 2.593  loss_mask_7: 2.606  loss_mask_8: 2.637  time: 3.0229  data_time: 0.0564  lr: 7.7005e-05  max_mem: 27646M
[01/29 10:04:29] d2.utils.events INFO:  eta: 1 day, 12:48:35  iter: 15139  total_loss: 25.31  loss_mask: 2.513  loss_mask_0: 2.609  loss_mask_1: 2.505  loss_mask_2: 2.532  loss_mask_3: 2.51  loss_mask_4: 2.519  loss_mask_5: 2.583  loss_mask_6: 2.545  loss_mask_7: 2.542  loss_mask_8: 2.546  time: 3.0228  data_time: 0.0571  lr: 7.6974e-05  max_mem: 27646M
[01/29 10:05:29] d2.utils.events INFO:  eta: 1 day, 12:48:11  iter: 15159  total_loss: 30.49  loss_mask: 3.041  loss_mask_0: 3.064  loss_mask_1: 2.968  loss_mask_2: 3.037  loss_mask_3: 3.115  loss_mask_4: 2.978  loss_mask_5: 3.146  loss_mask_6: 3.022  loss_mask_7: 3.034  loss_mask_8: 3.017  time: 3.0227  data_time: 0.0530  lr: 7.6943e-05  max_mem: 27646M
[01/29 10:06:28] d2.utils.events INFO:  eta: 1 day, 12:47:12  iter: 15179  total_loss: 27.88  loss_mask: 2.789  loss_mask_0: 2.856  loss_mask_1: 2.815  loss_mask_2: 2.797  loss_mask_3: 2.799  loss_mask_4: 2.819  loss_mask_5: 2.816  loss_mask_6: 2.804  loss_mask_7: 2.756  loss_mask_8: 2.749  time: 3.0227  data_time: 0.0613  lr: 7.6913e-05  max_mem: 27646M
[01/29 10:07:27] d2.utils.events INFO:  eta: 1 day, 12:46:27  iter: 15199  total_loss: 26.46  loss_mask: 2.624  loss_mask_0: 2.723  loss_mask_1: 2.662  loss_mask_2: 2.661  loss_mask_3: 2.629  loss_mask_4: 2.672  loss_mask_5: 2.629  loss_mask_6: 2.618  loss_mask_7: 2.633  loss_mask_8: 2.627  time: 3.0226  data_time: 0.0528  lr: 7.6882e-05  max_mem: 27646M
[01/29 10:08:26] d2.utils.events INFO:  eta: 1 day, 12:45:20  iter: 15219  total_loss: 30.41  loss_mask: 2.988  loss_mask_0: 3.011  loss_mask_1: 3.013  loss_mask_2: 3.021  loss_mask_3: 3.027  loss_mask_4: 3.034  loss_mask_5: 3.12  loss_mask_6: 3.017  loss_mask_7: 3.065  loss_mask_8: 3.056  time: 3.0225  data_time: 0.0623  lr: 7.6851e-05  max_mem: 27646M
[01/29 10:09:25] d2.utils.events INFO:  eta: 1 day, 12:43:50  iter: 15239  total_loss: 27.38  loss_mask: 2.72  loss_mask_0: 2.779  loss_mask_1: 2.705  loss_mask_2: 2.693  loss_mask_3: 2.733  loss_mask_4: 2.741  loss_mask_5: 2.748  loss_mask_6: 2.735  loss_mask_7: 2.746  loss_mask_8: 2.726  time: 3.0224  data_time: 0.0562  lr: 7.682e-05  max_mem: 27646M
[01/29 10:10:24] d2.utils.events INFO:  eta: 1 day, 12:43:06  iter: 15259  total_loss: 29.05  loss_mask: 2.923  loss_mask_0: 2.908  loss_mask_1: 2.896  loss_mask_2: 2.896  loss_mask_3: 2.914  loss_mask_4: 2.919  loss_mask_5: 2.935  loss_mask_6: 2.903  loss_mask_7: 2.896  loss_mask_8: 2.899  time: 3.0223  data_time: 0.0555  lr: 7.6789e-05  max_mem: 27646M
[01/29 10:11:23] d2.utils.events INFO:  eta: 1 day, 12:42:13  iter: 15279  total_loss: 30.02  loss_mask: 2.982  loss_mask_0: 3.061  loss_mask_1: 2.967  loss_mask_2: 3.018  loss_mask_3: 2.976  loss_mask_4: 3.007  loss_mask_5: 2.955  loss_mask_6: 2.991  loss_mask_7: 2.982  loss_mask_8: 3.016  time: 3.0222  data_time: 0.0545  lr: 7.6758e-05  max_mem: 27646M
[01/29 10:12:22] d2.utils.events INFO:  eta: 1 day, 12:41:07  iter: 15299  total_loss: 27.31  loss_mask: 2.733  loss_mask_0: 2.78  loss_mask_1: 2.699  loss_mask_2: 2.726  loss_mask_3: 2.809  loss_mask_4: 2.75  loss_mask_5: 2.723  loss_mask_6: 2.763  loss_mask_7: 2.708  loss_mask_8: 2.727  time: 3.0221  data_time: 0.0613  lr: 7.6727e-05  max_mem: 27646M
[01/29 10:13:22] d2.utils.events INFO:  eta: 1 day, 12:40:32  iter: 15319  total_loss: 28.8  loss_mask: 2.839  loss_mask_0: 3.007  loss_mask_1: 2.849  loss_mask_2: 2.905  loss_mask_3: 2.855  loss_mask_4: 2.895  loss_mask_5: 2.878  loss_mask_6: 2.84  loss_mask_7: 2.848  loss_mask_8: 2.872  time: 3.0220  data_time: 0.0602  lr: 7.6696e-05  max_mem: 27646M
[01/29 10:14:21] d2.utils.events INFO:  eta: 1 day, 12:39:59  iter: 15339  total_loss: 28.18  loss_mask: 2.825  loss_mask_0: 2.891  loss_mask_1: 2.81  loss_mask_2: 2.821  loss_mask_3: 2.809  loss_mask_4: 2.805  loss_mask_5: 2.809  loss_mask_6: 2.831  loss_mask_7: 2.826  loss_mask_8: 2.803  time: 3.0220  data_time: 0.0756  lr: 7.6665e-05  max_mem: 27646M
[01/29 10:15:20] d2.utils.events INFO:  eta: 1 day, 12:38:31  iter: 15359  total_loss: 29.08  loss_mask: 2.885  loss_mask_0: 2.958  loss_mask_1: 2.894  loss_mask_2: 2.914  loss_mask_3: 2.909  loss_mask_4: 2.914  loss_mask_5: 2.899  loss_mask_6: 2.902  loss_mask_7: 2.907  loss_mask_8: 2.906  time: 3.0219  data_time: 0.0570  lr: 7.6635e-05  max_mem: 27646M
[01/29 10:16:20] d2.utils.events INFO:  eta: 1 day, 12:37:27  iter: 15379  total_loss: 28.16  loss_mask: 2.794  loss_mask_0: 2.87  loss_mask_1: 2.775  loss_mask_2: 2.827  loss_mask_3: 2.805  loss_mask_4: 2.816  loss_mask_5: 2.824  loss_mask_6: 2.787  loss_mask_7: 2.848  loss_mask_8: 2.814  time: 3.0218  data_time: 0.0676  lr: 7.6604e-05  max_mem: 27646M
[01/29 10:17:19] d2.utils.events INFO:  eta: 1 day, 12:36:22  iter: 15399  total_loss: 28.32  loss_mask: 2.818  loss_mask_0: 2.838  loss_mask_1: 2.803  loss_mask_2: 2.859  loss_mask_3: 2.857  loss_mask_4: 2.857  loss_mask_5: 2.829  loss_mask_6: 2.817  loss_mask_7: 2.826  loss_mask_8: 2.817  time: 3.0217  data_time: 0.0545  lr: 7.6573e-05  max_mem: 27646M
[01/29 10:18:18] d2.utils.events INFO:  eta: 1 day, 12:35:19  iter: 15419  total_loss: 28.4  loss_mask: 2.83  loss_mask_0: 2.888  loss_mask_1: 2.831  loss_mask_2: 2.851  loss_mask_3: 2.839  loss_mask_4: 2.828  loss_mask_5: 2.83  loss_mask_6: 2.833  loss_mask_7: 2.822  loss_mask_8: 2.844  time: 3.0217  data_time: 0.0606  lr: 7.6542e-05  max_mem: 27646M
[01/29 10:19:17] d2.utils.events INFO:  eta: 1 day, 12:33:49  iter: 15439  total_loss: 27.12  loss_mask: 2.717  loss_mask_0: 2.742  loss_mask_1: 2.69  loss_mask_2: 2.721  loss_mask_3: 2.697  loss_mask_4: 2.696  loss_mask_5: 2.728  loss_mask_6: 2.701  loss_mask_7: 2.673  loss_mask_8: 2.692  time: 3.0216  data_time: 0.0592  lr: 7.6511e-05  max_mem: 27646M
[01/29 10:20:16] d2.utils.events INFO:  eta: 1 day, 12:33:09  iter: 15459  total_loss: 29.2  loss_mask: 2.909  loss_mask_0: 2.911  loss_mask_1: 2.887  loss_mask_2: 2.937  loss_mask_3: 2.908  loss_mask_4: 2.915  loss_mask_5: 2.951  loss_mask_6: 2.908  loss_mask_7: 2.902  loss_mask_8: 2.936  time: 3.0215  data_time: 0.0576  lr: 7.648e-05  max_mem: 27646M
[01/29 10:21:16] d2.utils.events INFO:  eta: 1 day, 12:32:16  iter: 15479  total_loss: 30.76  loss_mask: 3.046  loss_mask_0: 3.159  loss_mask_1: 3.052  loss_mask_2: 3.093  loss_mask_3: 3.005  loss_mask_4: 3.012  loss_mask_5: 3.074  loss_mask_6: 3.022  loss_mask_7: 3.19  loss_mask_8: 3.114  time: 3.0214  data_time: 0.0600  lr: 7.6449e-05  max_mem: 27646M
[01/29 10:22:15] d2.utils.events INFO:  eta: 1 day, 12:30:58  iter: 15499  total_loss: 27.19  loss_mask: 2.701  loss_mask_0: 2.686  loss_mask_1: 2.718  loss_mask_2: 2.724  loss_mask_3: 2.729  loss_mask_4: 2.727  loss_mask_5: 2.723  loss_mask_6: 2.721  loss_mask_7: 2.718  loss_mask_8: 2.703  time: 3.0214  data_time: 0.0582  lr: 7.6418e-05  max_mem: 27646M
[01/29 10:23:14] d2.utils.events INFO:  eta: 1 day, 12:29:59  iter: 15519  total_loss: 30.53  loss_mask: 3.04  loss_mask_0: 3.174  loss_mask_1: 3.013  loss_mask_2: 3.043  loss_mask_3: 3.04  loss_mask_4: 3.059  loss_mask_5: 3.056  loss_mask_6: 3.007  loss_mask_7: 3.073  loss_mask_8: 3.057  time: 3.0213  data_time: 0.0667  lr: 7.6387e-05  max_mem: 27646M
[01/29 10:24:14] d2.utils.events INFO:  eta: 1 day, 12:29:00  iter: 15539  total_loss: 31.16  loss_mask: 3.121  loss_mask_0: 3.06  loss_mask_1: 3.056  loss_mask_2: 3.119  loss_mask_3: 3.095  loss_mask_4: 3.095  loss_mask_5: 3.093  loss_mask_6: 3.107  loss_mask_7: 3.122  loss_mask_8: 3.087  time: 3.0212  data_time: 0.0594  lr: 7.6356e-05  max_mem: 27646M
[01/29 10:25:13] d2.utils.events INFO:  eta: 1 day, 12:28:13  iter: 15559  total_loss: 29.9  loss_mask: 2.956  loss_mask_0: 3.104  loss_mask_1: 3.008  loss_mask_2: 3.018  loss_mask_3: 2.988  loss_mask_4: 2.978  loss_mask_5: 2.997  loss_mask_6: 2.952  loss_mask_7: 2.952  loss_mask_8: 2.945  time: 3.0211  data_time: 0.0557  lr: 7.6325e-05  max_mem: 27646M
[01/29 10:26:13] d2.utils.events INFO:  eta: 1 day, 12:27:31  iter: 15579  total_loss: 27.86  loss_mask: 2.808  loss_mask_0: 2.808  loss_mask_1: 2.733  loss_mask_2: 2.787  loss_mask_3: 2.759  loss_mask_4: 2.773  loss_mask_5: 2.776  loss_mask_6: 2.775  loss_mask_7: 2.795  loss_mask_8: 2.787  time: 3.0211  data_time: 0.0629  lr: 7.6295e-05  max_mem: 27646M
[01/29 10:27:12] d2.utils.events INFO:  eta: 1 day, 12:26:42  iter: 15599  total_loss: 29.19  loss_mask: 2.895  loss_mask_0: 2.994  loss_mask_1: 2.927  loss_mask_2: 2.914  loss_mask_3: 2.871  loss_mask_4: 2.894  loss_mask_5: 2.913  loss_mask_6: 2.883  loss_mask_7: 2.909  loss_mask_8: 2.914  time: 3.0210  data_time: 0.0561  lr: 7.6264e-05  max_mem: 27646M
[01/29 10:28:11] d2.utils.events INFO:  eta: 1 day, 12:25:43  iter: 15619  total_loss: 27.87  loss_mask: 2.731  loss_mask_0: 2.782  loss_mask_1: 2.759  loss_mask_2: 2.794  loss_mask_3: 2.757  loss_mask_4: 2.853  loss_mask_5: 2.771  loss_mask_6: 2.814  loss_mask_7: 2.796  loss_mask_8: 2.787  time: 3.0209  data_time: 0.0599  lr: 7.6233e-05  max_mem: 27646M
[01/29 10:29:10] d2.utils.events INFO:  eta: 1 day, 12:24:39  iter: 15639  total_loss: 28.59  loss_mask: 2.883  loss_mask_0: 2.96  loss_mask_1: 2.805  loss_mask_2: 2.854  loss_mask_3: 2.898  loss_mask_4: 2.888  loss_mask_5: 2.87  loss_mask_6: 2.869  loss_mask_7: 2.85  loss_mask_8: 2.869  time: 3.0208  data_time: 0.0518  lr: 7.6202e-05  max_mem: 27646M
[01/29 10:30:09] d2.utils.events INFO:  eta: 1 day, 12:23:24  iter: 15659  total_loss: 31.86  loss_mask: 3.169  loss_mask_0: 3.28  loss_mask_1: 3.169  loss_mask_2: 3.182  loss_mask_3: 3.202  loss_mask_4: 3.214  loss_mask_5: 3.138  loss_mask_6: 3.243  loss_mask_7: 3.194  loss_mask_8: 3.209  time: 3.0207  data_time: 0.0591  lr: 7.6171e-05  max_mem: 27646M
[01/29 10:31:08] d2.utils.events INFO:  eta: 1 day, 12:22:35  iter: 15679  total_loss: 29.95  loss_mask: 3.039  loss_mask_0: 3.08  loss_mask_1: 2.988  loss_mask_2: 3.057  loss_mask_3: 2.994  loss_mask_4: 2.967  loss_mask_5: 2.954  loss_mask_6: 2.986  loss_mask_7: 2.982  loss_mask_8: 2.944  time: 3.0206  data_time: 0.0593  lr: 7.614e-05  max_mem: 27646M
[01/29 10:32:08] d2.utils.events INFO:  eta: 1 day, 12:21:42  iter: 15699  total_loss: 26.6  loss_mask: 2.686  loss_mask_0: 2.707  loss_mask_1: 2.639  loss_mask_2: 2.689  loss_mask_3: 2.656  loss_mask_4: 2.666  loss_mask_5: 2.622  loss_mask_6: 2.648  loss_mask_7: 2.651  loss_mask_8: 2.658  time: 3.0206  data_time: 0.0568  lr: 7.6109e-05  max_mem: 27646M
[01/29 10:33:07] d2.utils.events INFO:  eta: 1 day, 12:20:21  iter: 15719  total_loss: 27.3  loss_mask: 2.709  loss_mask_0: 2.812  loss_mask_1: 2.687  loss_mask_2: 2.723  loss_mask_3: 2.73  loss_mask_4: 2.727  loss_mask_5: 2.707  loss_mask_6: 2.716  loss_mask_7: 2.715  loss_mask_8: 2.742  time: 3.0205  data_time: 0.0603  lr: 7.6078e-05  max_mem: 27646M
[01/29 10:34:06] d2.utils.events INFO:  eta: 1 day, 12:19:22  iter: 15739  total_loss: 27.55  loss_mask: 2.755  loss_mask_0: 2.878  loss_mask_1: 2.677  loss_mask_2: 2.736  loss_mask_3: 2.725  loss_mask_4: 2.721  loss_mask_5: 2.726  loss_mask_6: 2.759  loss_mask_7: 2.758  loss_mask_8: 2.776  time: 3.0204  data_time: 0.0598  lr: 7.6047e-05  max_mem: 27646M
[01/29 10:35:06] d2.utils.events INFO:  eta: 1 day, 12:18:34  iter: 15759  total_loss: 28.67  loss_mask: 2.881  loss_mask_0: 2.927  loss_mask_1: 2.841  loss_mask_2: 2.9  loss_mask_3: 2.891  loss_mask_4: 2.857  loss_mask_5: 2.862  loss_mask_6: 2.885  loss_mask_7: 2.843  loss_mask_8: 2.883  time: 3.0204  data_time: 0.0621  lr: 7.6016e-05  max_mem: 27646M
[01/29 10:36:05] d2.utils.events INFO:  eta: 1 day, 12:17:35  iter: 15779  total_loss: 32.47  loss_mask: 3.272  loss_mask_0: 3.346  loss_mask_1: 3.24  loss_mask_2: 3.271  loss_mask_3: 3.206  loss_mask_4: 3.207  loss_mask_5: 3.299  loss_mask_6: 3.243  loss_mask_7: 3.219  loss_mask_8: 3.23  time: 3.0203  data_time: 0.0611  lr: 7.5985e-05  max_mem: 27646M
[01/29 10:37:04] d2.utils.events INFO:  eta: 1 day, 12:16:46  iter: 15799  total_loss: 26.63  loss_mask: 2.635  loss_mask_0: 2.757  loss_mask_1: 2.62  loss_mask_2: 2.648  loss_mask_3: 2.645  loss_mask_4: 2.656  loss_mask_5: 2.658  loss_mask_6: 2.618  loss_mask_7: 2.63  loss_mask_8: 2.645  time: 3.0202  data_time: 0.0611  lr: 7.5954e-05  max_mem: 27646M
[01/29 10:38:03] d2.utils.events INFO:  eta: 1 day, 12:15:31  iter: 15819  total_loss: 26.73  loss_mask: 2.675  loss_mask_0: 2.701  loss_mask_1: 2.65  loss_mask_2: 2.67  loss_mask_3: 2.678  loss_mask_4: 2.652  loss_mask_5: 2.701  loss_mask_6: 2.671  loss_mask_7: 2.68  loss_mask_8: 2.648  time: 3.0201  data_time: 0.0607  lr: 7.5923e-05  max_mem: 27646M
[01/29 10:39:03] d2.utils.events INFO:  eta: 1 day, 12:14:48  iter: 15839  total_loss: 28.06  loss_mask: 2.795  loss_mask_0: 2.826  loss_mask_1: 2.794  loss_mask_2: 2.824  loss_mask_3: 2.799  loss_mask_4: 2.802  loss_mask_5: 2.789  loss_mask_6: 2.797  loss_mask_7: 2.801  loss_mask_8: 2.842  time: 3.0201  data_time: 0.0560  lr: 7.5893e-05  max_mem: 27646M
[01/29 10:40:02] d2.utils.events INFO:  eta: 1 day, 12:13:57  iter: 15859  total_loss: 26.48  loss_mask: 2.65  loss_mask_0: 2.671  loss_mask_1: 2.627  loss_mask_2: 2.634  loss_mask_3: 2.615  loss_mask_4: 2.618  loss_mask_5: 2.656  loss_mask_6: 2.656  loss_mask_7: 2.658  loss_mask_8: 2.614  time: 3.0200  data_time: 0.0558  lr: 7.5862e-05  max_mem: 27646M
[01/29 10:41:02] d2.utils.events INFO:  eta: 1 day, 12:13:23  iter: 15879  total_loss: 28.37  loss_mask: 2.81  loss_mask_0: 2.874  loss_mask_1: 2.812  loss_mask_2: 2.828  loss_mask_3: 2.816  loss_mask_4: 2.806  loss_mask_5: 2.79  loss_mask_6: 2.808  loss_mask_7: 2.819  loss_mask_8: 2.828  time: 3.0199  data_time: 0.0491  lr: 7.5831e-05  max_mem: 27646M
[01/29 10:42:01] d2.utils.events INFO:  eta: 1 day, 12:12:51  iter: 15899  total_loss: 30.48  loss_mask: 3.02  loss_mask_0: 3.059  loss_mask_1: 2.998  loss_mask_2: 3.014  loss_mask_3: 3.044  loss_mask_4: 3.043  loss_mask_5: 3.041  loss_mask_6: 3.255  loss_mask_7: 3.097  loss_mask_8: 3.047  time: 3.0199  data_time: 0.0615  lr: 7.58e-05  max_mem: 27646M
[01/29 10:43:01] d2.utils.events INFO:  eta: 1 day, 12:12:16  iter: 15919  total_loss: 27.49  loss_mask: 2.696  loss_mask_0: 2.729  loss_mask_1: 2.696  loss_mask_2: 2.695  loss_mask_3: 2.801  loss_mask_4: 2.76  loss_mask_5: 2.707  loss_mask_6: 2.77  loss_mask_7: 2.745  loss_mask_8: 2.775  time: 3.0199  data_time: 0.0566  lr: 7.5769e-05  max_mem: 27646M
[01/29 10:44:01] d2.utils.events INFO:  eta: 1 day, 12:11:17  iter: 15939  total_loss: 28.17  loss_mask: 2.779  loss_mask_0: 2.798  loss_mask_1: 2.787  loss_mask_2: 2.807  loss_mask_3: 2.842  loss_mask_4: 2.781  loss_mask_5: 2.81  loss_mask_6: 2.965  loss_mask_7: 2.806  loss_mask_8: 2.817  time: 3.0198  data_time: 0.0667  lr: 7.5738e-05  max_mem: 27646M
[01/29 10:45:01] d2.utils.events INFO:  eta: 1 day, 12:11:27  iter: 15959  total_loss: 28.74  loss_mask: 2.732  loss_mask_0: 2.934  loss_mask_1: 2.65  loss_mask_2: 2.781  loss_mask_3: 2.799  loss_mask_4: 2.726  loss_mask_5: 2.847  loss_mask_6: 3.217  loss_mask_7: 2.905  loss_mask_8: 2.806  time: 3.0198  data_time: 0.0633  lr: 7.5707e-05  max_mem: 27646M
[01/29 10:46:00] d2.utils.events INFO:  eta: 1 day, 12:10:22  iter: 15979  total_loss: 27.5  loss_mask: 2.686  loss_mask_0: 2.819  loss_mask_1: 2.65  loss_mask_2: 2.751  loss_mask_3: 2.692  loss_mask_4: 2.671  loss_mask_5: 2.715  loss_mask_6: 2.996  loss_mask_7: 2.739  loss_mask_8: 2.692  time: 3.0197  data_time: 0.0562  lr: 7.5676e-05  max_mem: 27646M
[01/29 10:47:00] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 10:47:01] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 10:47:01] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 11:00:58] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.975629731467758, 'error_1pix': 0.4307039914498257, 'error_3pix': 0.19795804784744464, 'mIoU': 5.667653457757139, 'fwIoU': 16.7743092331166, 'IoU-0': 0.0001753059459596497, 'IoU-1': 60.58147910627601, 'IoU-2': 2.7796499167003814, 'IoU-3': 2.5064488161802347, 'IoU-4': 1.961277225146364, 'IoU-5': 2.1928648470653305, 'IoU-6': 2.5879415299647914, 'IoU-7': 2.5290351093138366, 'IoU-8': 4.215031505738032, 'IoU-9': 10.425736005430002, 'IoU-10': 14.567757975579926, 'IoU-11': 24.396210163525087, 'IoU-12': 22.397514736819037, 'IoU-13': 20.36315906122989, 'IoU-14': 19.840831863042514, 'IoU-15': 19.05804246702235, 'IoU-16': 18.506765736556613, 'IoU-17': 15.134128178603953, 'IoU-18': 15.494144153939946, 'IoU-19': 16.197808527130352, 'IoU-20': 15.867154538617696, 'IoU-21': 15.87120976911351, 'IoU-22': 15.99982309764137, 'IoU-23': 14.76433027443829, 'IoU-24': 14.485020091753572, 'IoU-25': 14.645039279617688, 'IoU-26': 14.552290065137964, 'IoU-27': 15.805831146632384, 'IoU-28': 15.396798964352481, 'IoU-29': 15.11547637113321, 'IoU-30': 14.617939535818836, 'IoU-31': 14.945419769188131, 'IoU-32': 14.734318459111456, 'IoU-33': 13.96439802042061, 'IoU-34': 13.724393535654308, 'IoU-35': 14.28954013526828, 'IoU-36': 14.263598357205836, 'IoU-37': 13.843067950506555, 'IoU-38': 14.272011032530827, 'IoU-39': 13.824415135846804, 'IoU-40': 13.947675170338911, 'IoU-41': 12.857705973426981, 'IoU-42': 12.724680220960696, 'IoU-43': 12.380157352899019, 'IoU-44': 12.478888168421358, 'IoU-45': 12.377086929179008, 'IoU-46': 11.60898558085486, 'IoU-47': 11.170501785251405, 'IoU-48': 10.748992680964234, 'IoU-49': 10.528264794507756, 'IoU-50': 10.545415380372459, 'IoU-51': 9.649119505760954, 'IoU-52': 9.244377032100209, 'IoU-53': 8.88691886498392, 'IoU-54': 8.839141853260626, 'IoU-55': 7.963462222719837, 'IoU-56': 7.230623773481557, 'IoU-57': 6.816535113772433, 'IoU-58': 6.466477741659141, 'IoU-59': 5.8646548717132205, 'IoU-60': 5.305960403923649, 'IoU-61': 5.025186029584944, 'IoU-62': 4.808532569698685, 'IoU-63': 4.349836723800697, 'IoU-64': 4.05074046062582, 'IoU-65': 3.832314622144876, 'IoU-66': 3.513184256611876, 'IoU-67': 3.5166065698333027, 'IoU-68': 3.405791682697275, 'IoU-69': 3.492578761421719, 'IoU-70': 3.4782670907937803, 'IoU-71': 3.462043479617152, 'IoU-72': 3.6009069306193, 'IoU-73': 3.7303778598891544, 'IoU-74': 3.6945054985126715, 'IoU-75': 3.720652028733863, 'IoU-76': 4.039645125449214, 'IoU-77': 3.8657227752774843, 'IoU-78': 3.907981318086853, 'IoU-79': 4.082979539963501, 'IoU-80': 4.300369290495146, 'IoU-81': 4.388184511238901, 'IoU-82': 4.2103150109735, 'IoU-83': 4.592921228860613, 'IoU-84': 4.592436793330726, 'IoU-85': 4.650392822439085, 'IoU-86': 4.727849038005013, 'IoU-87': 4.7229911859831315, 'IoU-88': 4.675997250109125, 'IoU-89': 4.643651636313419, 'IoU-90': 4.8782251337621325, 'IoU-91': 4.860714758982675, 'IoU-92': 4.848572195057952, 'IoU-93': 5.136569939827103, 'IoU-94': 5.091886530794902, 'IoU-95': 4.987583090604727, 'IoU-96': 4.834562165148698, 'IoU-97': 4.949408745001648, 'IoU-98': 5.011289116009754, 'IoU-99': 5.001790909116238, 'IoU-100': 4.533065817579902, 'IoU-101': 4.561316416769067, 'IoU-102': 4.529389483603081, 'IoU-103': 4.211463146618458, 'IoU-104': 3.982063606849255, 'IoU-105': 3.8588949308372733, 'IoU-106': 3.919740550694939, 'IoU-107': 4.1049327875358514, 'IoU-108': 4.228558673701466, 'IoU-109': 3.9801144123544354, 'IoU-110': 3.8940658157867762, 'IoU-111': 3.5002967766461874, 'IoU-112': 3.6029943794325696, 'IoU-113': 3.5876498144090156, 'IoU-114': 3.36816615503993, 'IoU-115': 2.9785454270877176, 'IoU-116': 2.9447747431678057, 'IoU-117': 3.053540790763621, 'IoU-118': 2.8943916088984607, 'IoU-119': 3.254826772842646, 'IoU-120': 3.2067544989714527, 'IoU-121': 3.0763561502369505, 'IoU-122': 2.61624828125503, 'IoU-123': 2.735710475764641, 'IoU-124': 2.355102515726353, 'IoU-125': 2.401687643577269, 'IoU-126': 2.2062920375591024, 'IoU-127': 2.088644585079985, 'IoU-128': 2.0567923488484237, 'IoU-129': 1.9312092203983646, 'IoU-130': 1.7598397393444913, 'IoU-131': 1.737239973809598, 'IoU-132': 1.5869200255251035, 'IoU-133': 1.4872444412200663, 'IoU-134': 1.4026930176170178, 'IoU-135': 1.3289051986368074, 'IoU-136': 1.2014844187025442, 'IoU-137': 1.1819294386771055, 'IoU-138': 1.0273803414040035, 'IoU-139': 1.0302433785225247, 'IoU-140': 0.9740381296328524, 'IoU-141': 1.0325469832480638, 'IoU-142': 1.011914740266551, 'IoU-143': 1.0243903111300174, 'IoU-144': 0.9411205317841792, 'IoU-145': 0.8456034175032722, 'IoU-146': 1.0065762407679146, 'IoU-147': 1.05161980107148, 'IoU-148': 1.0158598227488427, 'IoU-149': 0.9061917713125018, 'IoU-150': 0.9722307766284257, 'IoU-151': 0.8656425063023369, 'IoU-152': 0.945351522180374, 'IoU-153': 0.9020711006538937, 'IoU-154': 0.9608361232193071, 'IoU-155': 1.0260672666994306, 'IoU-156': 0.8664379964571798, 'IoU-157': 0.9442872564523795, 'IoU-158': 0.9771671553091453, 'IoU-159': 0.9012557684949453, 'IoU-160': 0.8077437615088011, 'IoU-161': 0.7281439748391247, 'IoU-162': 0.7846959840068382, 'IoU-163': 0.6814866824032633, 'IoU-164': 0.837342530707187, 'IoU-165': 1.0157956914207, 'IoU-166': 0.9795027677045008, 'IoU-167': 0.9699282137229688, 'IoU-168': 1.0629295120050903, 'IoU-169': 0.8519383186919931, 'IoU-170': 0.7831166095332939, 'IoU-171': 0.8843832530386404, 'IoU-172': 0.7251636402027026, 'IoU-173': 0.7394203085511232, 'IoU-174': 0.7290439830437448, 'IoU-175': 0.7742442784444236, 'IoU-176': 0.44542318529138797, 'IoU-177': 0.44031853240002505, 'IoU-178': 0.0005491990846681922, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 10.196731427436802, 'pACC': 24.950723048563436, 'ACC-0': 0.0006552501159482528, 'ACC-1': 61.72127893678198, 'ACC-2': 6.284298194232431, 'ACC-3': 11.353526623855288, 'ACC-4': 7.741871464068431, 'ACC-5': 8.659923647858495, 'ACC-6': 10.53158042691308, 'ACC-7': 10.975529715479615, 'ACC-8': 9.360991464266402, 'ACC-9': 15.786738547205115, 'ACC-10': 22.125366725226332, 'ACC-11': 35.82913987306705, 'ACC-12': 34.89104019411673, 'ACC-13': 32.331429862763834, 'ACC-14': 31.955184426093503, 'ACC-15': 31.450935139998297, 'ACC-16': 30.65038285738301, 'ACC-17': 26.835868358402305, 'ACC-18': 26.603477729585833, 'ACC-19': 27.8985628846004, 'ACC-20': 27.56882806310869, 'ACC-21': 27.211684121817186, 'ACC-22': 27.038760425574775, 'ACC-23': 26.88778786429446, 'ACC-24': 26.247384060772077, 'ACC-25': 26.431910870212704, 'ACC-26': 26.21523476610817, 'ACC-27': 27.63690784823389, 'ACC-28': 27.469494076802782, 'ACC-29': 26.08904521414543, 'ACC-30': 25.813438230447893, 'ACC-31': 25.981896036447854, 'ACC-32': 26.27339921385777, 'ACC-33': 25.251990537070306, 'ACC-34': 24.819204547234715, 'ACC-35': 25.631738886592537, 'ACC-36': 25.554763862615836, 'ACC-37': 25.236941003005963, 'ACC-38': 26.140612324713768, 'ACC-39': 25.442137502551592, 'ACC-40': 25.22163745089388, 'ACC-41': 24.087916773342027, 'ACC-42': 23.933080310619726, 'ACC-43': 23.143234560523613, 'ACC-44': 22.746455332718032, 'ACC-45': 22.857559534240416, 'ACC-46': 22.126938010415618, 'ACC-47': 21.359650006575347, 'ACC-48': 20.43826310757285, 'ACC-49': 19.854368255407014, 'ACC-50': 19.88739612100961, 'ACC-51': 18.562568703943473, 'ACC-52': 17.833844098777718, 'ACC-53': 17.13015770400427, 'ACC-54': 16.86288138297205, 'ACC-55': 15.231633246856163, 'ACC-56': 13.986265703917322, 'ACC-57': 12.937535496864093, 'ACC-58': 12.48934340407623, 'ACC-59': 11.413939592211616, 'ACC-60': 10.343039790443335, 'ACC-61': 9.896706990683363, 'ACC-62': 9.525170642183827, 'ACC-63': 8.702006295127253, 'ACC-64': 8.077093913727976, 'ACC-65': 7.614322659970611, 'ACC-66': 6.955032458705553, 'ACC-67': 6.943077522412877, 'ACC-68': 6.642376859989466, 'ACC-69': 6.626304583637458, 'ACC-70': 6.538820303991385, 'ACC-71': 6.632368693654085, 'ACC-72': 6.953802718524795, 'ACC-73': 7.175880602978296, 'ACC-74': 7.063177872325778, 'ACC-75': 7.136465739692205, 'ACC-76': 7.594482916970091, 'ACC-77': 7.327809142511067, 'ACC-78': 7.43601108574012, 'ACC-79': 7.722418458269664, 'ACC-80': 8.034462461480858, 'ACC-81': 8.114484270102391, 'ACC-82': 7.79212099759923, 'ACC-83': 8.360861379182086, 'ACC-84': 8.285572449535914, 'ACC-85': 8.364683537682506, 'ACC-86': 8.526770335594902, 'ACC-87': 8.531302088991856, 'ACC-88': 8.397379935715016, 'ACC-89': 8.323895555802988, 'ACC-90': 8.700948974636344, 'ACC-91': 8.729871889322913, 'ACC-92': 8.802344690624068, 'ACC-93': 9.411614265419804, 'ACC-94': 9.359589807590787, 'ACC-95': 9.196663823035928, 'ACC-96': 8.999563520869481, 'ACC-97': 9.160668802322409, 'ACC-98': 9.312122565013462, 'ACC-99': 9.347064617824495, 'ACC-100': 8.509528872064726, 'ACC-101': 8.63819722785352, 'ACC-102': 8.598618033529679, 'ACC-103': 7.994002078020214, 'ACC-104': 7.608224096800374, 'ACC-105': 7.398882047507491, 'ACC-106': 7.528732512625419, 'ACC-107': 7.9355029611546986, 'ACC-108': 8.15691459299856, 'ACC-109': 7.5677231060138945, 'ACC-110': 7.4467152981374936, 'ACC-111': 6.775276169810156, 'ACC-112': 7.087803520629092, 'ACC-113': 7.121810310000503, 'ACC-114': 6.631239028322552, 'ACC-115': 5.886142558597567, 'ACC-116': 5.891806361039537, 'ACC-117': 6.0801541716928105, 'ACC-118': 5.868420710107121, 'ACC-119': 6.627988318435435, 'ACC-120': 6.591932939063944, 'ACC-121': 6.237614273444139, 'ACC-122': 5.290601677564229, 'ACC-123': 5.554859286832232, 'ACC-124': 4.863190632789605, 'ACC-125': 4.899479313394165, 'ACC-126': 4.526054426725198, 'ACC-127': 4.306063041426422, 'ACC-128': 4.369910146592656, 'ACC-129': 4.128745782239628, 'ACC-130': 3.7188856757377278, 'ACC-131': 3.665881799386328, 'ACC-132': 3.3050838937981926, 'ACC-133': 3.0408186871882803, 'ACC-134': 2.7812149935372683, 'ACC-135': 2.6487229918476713, 'ACC-136': 2.3500104826686545, 'ACC-137': 2.2651209685113227, 'ACC-138': 1.995948295555499, 'ACC-139': 2.0698452883493625, 'ACC-140': 1.9608671381030236, 'ACC-141': 2.043208744081772, 'ACC-142': 1.9715980196688212, 'ACC-143': 2.003768691821831, 'ACC-144': 1.8042418772563178, 'ACC-145': 1.6209664795724412, 'ACC-146': 1.9251102328025405, 'ACC-147': 2.025658715132922, 'ACC-148': 1.9981921028543292, 'ACC-149': 1.7898341799610373, 'ACC-150': 1.8756338537578865, 'ACC-151': 1.6947978381788864, 'ACC-152': 1.8113788859666868, 'ACC-153': 1.7710566335037288, 'ACC-154': 1.8611734398538395, 'ACC-155': 2.025203185895682, 'ACC-156': 1.7382536019701758, 'ACC-157': 1.8846301989974588, 'ACC-158': 1.9511651243170922, 'ACC-159': 1.81322248906254, 'ACC-160': 1.623648373523956, 'ACC-161': 1.4193559258250321, 'ACC-162': 1.5760143528284654, 'ACC-163': 1.4184451370980193, 'ACC-164': 1.7213715162719314, 'ACC-165': 2.1221178615557115, 'ACC-166': 2.1190118441043895, 'ACC-167': 2.267977841356201, 'ACC-168': 2.6169210211688587, 'ACC-169': 1.9036906928142652, 'ACC-170': 1.8142098612944901, 'ACC-171': 1.9209822027189116, 'ACC-172': 1.6283290736007705, 'ACC-173': 1.660752653780014, 'ACC-174': 1.2322896803428267, 'ACC-175': 1.2925256850423108, 'ACC-176': 0.7286466798235431, 'ACC-177': 0.674701819074352, 'ACC-178': 0.0005794738763518643, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 11:00:58] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 11:00:58] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 11:00:58] d2.evaluation.testing INFO: copypaste: 2.9756,0.4307,0.1980,5.6677,16.7743,10.1967,24.9507
[01/29 11:00:59] d2.utils.events INFO:  eta: 1 day, 12:09:31  iter: 15999  total_loss: 27.82  loss_mask: 2.742  loss_mask_0: 2.667  loss_mask_1: 2.697  loss_mask_2: 2.736  loss_mask_3: 2.742  loss_mask_4: 2.729  loss_mask_5: 2.784  loss_mask_6: 3.07  loss_mask_7: 2.762  loss_mask_8: 2.748  time: 3.0197  data_time: 0.0656  lr: 7.5645e-05  max_mem: 27646M
[01/29 11:01:58] d2.utils.events INFO:  eta: 1 day, 12:08:37  iter: 16019  total_loss: 28.61  loss_mask: 2.808  loss_mask_0: 2.89  loss_mask_1: 2.808  loss_mask_2: 2.842  loss_mask_3: 2.84  loss_mask_4: 2.838  loss_mask_5: 2.834  loss_mask_6: 2.971  loss_mask_7: 2.857  loss_mask_8: 2.846  time: 3.0196  data_time: 0.0600  lr: 7.5614e-05  max_mem: 27646M
[01/29 11:02:58] d2.utils.events INFO:  eta: 1 day, 12:07:25  iter: 16039  total_loss: 28.86  loss_mask: 2.867  loss_mask_0: 2.898  loss_mask_1: 2.849  loss_mask_2: 2.89  loss_mask_3: 2.884  loss_mask_4: 2.88  loss_mask_5: 2.878  loss_mask_6: 2.893  loss_mask_7: 2.879  loss_mask_8: 2.87  time: 3.0195  data_time: 0.0517  lr: 7.5583e-05  max_mem: 27646M
[01/29 11:03:57] d2.utils.events INFO:  eta: 1 day, 12:06:26  iter: 16059  total_loss: 29.03  loss_mask: 2.899  loss_mask_0: 2.909  loss_mask_1: 2.828  loss_mask_2: 2.885  loss_mask_3: 2.874  loss_mask_4: 2.871  loss_mask_5: 2.883  loss_mask_6: 2.973  loss_mask_7: 2.891  loss_mask_8: 2.852  time: 3.0195  data_time: 0.0524  lr: 7.5552e-05  max_mem: 27646M
[01/29 11:04:56] d2.utils.events INFO:  eta: 1 day, 12:05:40  iter: 16079  total_loss: 28.99  loss_mask: 2.867  loss_mask_0: 3.005  loss_mask_1: 2.922  loss_mask_2: 2.872  loss_mask_3: 2.904  loss_mask_4: 2.889  loss_mask_5: 2.842  loss_mask_6: 3.128  loss_mask_7: 2.947  loss_mask_8: 2.876  time: 3.0194  data_time: 0.0624  lr: 7.5521e-05  max_mem: 27646M
[01/29 11:05:55] d2.utils.events INFO:  eta: 1 day, 12:04:22  iter: 16099  total_loss: 26.44  loss_mask: 2.599  loss_mask_0: 2.873  loss_mask_1: 2.603  loss_mask_2: 2.558  loss_mask_3: 2.548  loss_mask_4: 2.57  loss_mask_5: 2.602  loss_mask_6: 2.808  loss_mask_7: 2.622  loss_mask_8: 2.596  time: 3.0193  data_time: 0.0580  lr: 7.549e-05  max_mem: 27646M
[01/29 11:06:54] d2.utils.events INFO:  eta: 1 day, 12:02:55  iter: 16119  total_loss: 28  loss_mask: 2.782  loss_mask_0: 2.863  loss_mask_1: 2.796  loss_mask_2: 2.804  loss_mask_3: 2.783  loss_mask_4: 2.799  loss_mask_5: 2.786  loss_mask_6: 2.795  loss_mask_7: 2.791  loss_mask_8: 2.794  time: 3.0192  data_time: 0.0603  lr: 7.5459e-05  max_mem: 27646M
[01/29 11:07:53] d2.utils.events INFO:  eta: 1 day, 12:01:56  iter: 16139  total_loss: 30.34  loss_mask: 3.029  loss_mask_0: 3.175  loss_mask_1: 2.981  loss_mask_2: 3.026  loss_mask_3: 3.028  loss_mask_4: 3.022  loss_mask_5: 3.014  loss_mask_6: 3.165  loss_mask_7: 3.026  loss_mask_8: 3.034  time: 3.0191  data_time: 0.0551  lr: 7.5428e-05  max_mem: 27646M
[01/29 11:08:52] d2.utils.events INFO:  eta: 1 day, 12:00:57  iter: 16159  total_loss: 28.03  loss_mask: 2.785  loss_mask_0: 2.855  loss_mask_1: 2.733  loss_mask_2: 2.786  loss_mask_3: 2.799  loss_mask_4: 2.762  loss_mask_5: 2.766  loss_mask_6: 2.818  loss_mask_7: 2.779  loss_mask_8: 2.752  time: 3.0190  data_time: 0.0522  lr: 7.5397e-05  max_mem: 27646M
[01/29 11:09:52] d2.utils.events INFO:  eta: 1 day, 12:00:22  iter: 16179  total_loss: 27.91  loss_mask: 2.668  loss_mask_0: 2.745  loss_mask_1: 2.617  loss_mask_2: 2.974  loss_mask_3: 2.627  loss_mask_4: 2.644  loss_mask_5: 2.62  loss_mask_6: 2.614  loss_mask_7: 2.669  loss_mask_8: 2.659  time: 3.0190  data_time: 0.0522  lr: 7.5366e-05  max_mem: 27646M
[01/29 11:10:51] d2.utils.events INFO:  eta: 1 day, 11:59:32  iter: 16199  total_loss: 27.42  loss_mask: 2.708  loss_mask_0: 2.753  loss_mask_1: 2.719  loss_mask_2: 2.84  loss_mask_3: 2.709  loss_mask_4: 2.714  loss_mask_5: 2.694  loss_mask_6: 2.704  loss_mask_7: 2.763  loss_mask_8: 2.717  time: 3.0189  data_time: 0.0525  lr: 7.5335e-05  max_mem: 27646M
[01/29 11:11:51] d2.utils.events INFO:  eta: 1 day, 11:58:45  iter: 16219  total_loss: 32.28  loss_mask: 3.224  loss_mask_0: 3.315  loss_mask_1: 3.21  loss_mask_2: 3.271  loss_mask_3: 3.235  loss_mask_4: 3.27  loss_mask_5: 3.252  loss_mask_6: 3.234  loss_mask_7: 3.244  loss_mask_8: 3.198  time: 3.0189  data_time: 0.0525  lr: 7.5305e-05  max_mem: 27646M
[01/29 11:12:50] d2.utils.events INFO:  eta: 1 day, 11:58:18  iter: 16239  total_loss: 30.17  loss_mask: 2.985  loss_mask_0: 2.999  loss_mask_1: 2.997  loss_mask_2: 3.105  loss_mask_3: 2.962  loss_mask_4: 2.98  loss_mask_5: 2.985  loss_mask_6: 3.104  loss_mask_7: 3.03  loss_mask_8: 3.01  time: 3.0188  data_time: 0.0579  lr: 7.5274e-05  max_mem: 27646M
[01/29 11:13:50] d2.utils.events INFO:  eta: 1 day, 11:57:19  iter: 16259  total_loss: 26.1  loss_mask: 2.599  loss_mask_0: 2.703  loss_mask_1: 2.601  loss_mask_2: 2.698  loss_mask_3: 2.602  loss_mask_4: 2.605  loss_mask_5: 2.592  loss_mask_6: 2.646  loss_mask_7: 2.621  loss_mask_8: 2.594  time: 3.0188  data_time: 0.0628  lr: 7.5243e-05  max_mem: 27646M
[01/29 11:14:49] d2.utils.events INFO:  eta: 1 day, 11:56:54  iter: 16279  total_loss: 28.03  loss_mask: 2.796  loss_mask_0: 2.849  loss_mask_1: 2.778  loss_mask_2: 2.85  loss_mask_3: 2.781  loss_mask_4: 2.78  loss_mask_5: 2.792  loss_mask_6: 2.861  loss_mask_7: 2.777  loss_mask_8: 2.792  time: 3.0187  data_time: 0.0599  lr: 7.5212e-05  max_mem: 27646M
[01/29 11:15:48] d2.utils.events INFO:  eta: 1 day, 11:56:06  iter: 16299  total_loss: 27.06  loss_mask: 2.696  loss_mask_0: 2.74  loss_mask_1: 2.676  loss_mask_2: 2.741  loss_mask_3: 2.691  loss_mask_4: 2.694  loss_mask_5: 2.69  loss_mask_6: 2.718  loss_mask_7: 2.694  loss_mask_8: 2.709  time: 3.0186  data_time: 0.0491  lr: 7.5181e-05  max_mem: 27646M
[01/29 11:16:47] d2.utils.events INFO:  eta: 1 day, 11:54:45  iter: 16319  total_loss: 26.62  loss_mask: 2.651  loss_mask_0: 2.679  loss_mask_1: 2.637  loss_mask_2: 2.704  loss_mask_3: 2.635  loss_mask_4: 2.742  loss_mask_5: 2.697  loss_mask_6: 2.696  loss_mask_7: 2.673  loss_mask_8: 2.704  time: 3.0185  data_time: 0.0581  lr: 7.515e-05  max_mem: 27646M
[01/29 11:17:46] d2.utils.events INFO:  eta: 1 day, 11:52:50  iter: 16339  total_loss: 26.92  loss_mask: 2.664  loss_mask_0: 2.74  loss_mask_1: 2.686  loss_mask_2: 2.734  loss_mask_3: 2.684  loss_mask_4: 2.686  loss_mask_5: 2.681  loss_mask_6: 2.696  loss_mask_7: 2.698  loss_mask_8: 2.687  time: 3.0185  data_time: 0.0531  lr: 7.5119e-05  max_mem: 27646M
[01/29 11:18:45] d2.utils.events INFO:  eta: 1 day, 11:51:51  iter: 16359  total_loss: 29.15  loss_mask: 2.868  loss_mask_0: 3.006  loss_mask_1: 2.879  loss_mask_2: 2.953  loss_mask_3: 2.929  loss_mask_4: 2.933  loss_mask_5: 2.888  loss_mask_6: 2.881  loss_mask_7: 2.906  loss_mask_8: 2.905  time: 3.0184  data_time: 0.0606  lr: 7.5088e-05  max_mem: 27646M
[01/29 11:19:45] d2.utils.events INFO:  eta: 1 day, 11:50:57  iter: 16379  total_loss: 27.1  loss_mask: 2.697  loss_mask_0: 2.755  loss_mask_1: 2.712  loss_mask_2: 2.74  loss_mask_3: 2.712  loss_mask_4: 2.725  loss_mask_5: 2.691  loss_mask_6: 2.725  loss_mask_7: 2.71  loss_mask_8: 2.679  time: 3.0183  data_time: 0.0626  lr: 7.5057e-05  max_mem: 27646M
[01/29 11:20:44] d2.utils.events INFO:  eta: 1 day, 11:50:00  iter: 16399  total_loss: 29.9  loss_mask: 2.972  loss_mask_0: 3.012  loss_mask_1: 2.955  loss_mask_2: 3.025  loss_mask_3: 2.973  loss_mask_4: 3.003  loss_mask_5: 2.978  loss_mask_6: 3.036  loss_mask_7: 2.937  loss_mask_8: 2.989  time: 3.0183  data_time: 0.0624  lr: 7.5026e-05  max_mem: 27646M
[01/29 11:21:43] d2.utils.events INFO:  eta: 1 day, 11:48:59  iter: 16419  total_loss: 28.82  loss_mask: 2.842  loss_mask_0: 2.946  loss_mask_1: 2.84  loss_mask_2: 2.942  loss_mask_3: 2.885  loss_mask_4: 2.831  loss_mask_5: 2.877  loss_mask_6: 2.869  loss_mask_7: 2.854  loss_mask_8: 2.856  time: 3.0182  data_time: 0.0558  lr: 7.4995e-05  max_mem: 27646M
[01/29 11:22:43] d2.utils.events INFO:  eta: 1 day, 11:48:50  iter: 16439  total_loss: 30.13  loss_mask: 2.995  loss_mask_0: 3.123  loss_mask_1: 2.969  loss_mask_2: 3.029  loss_mask_3: 3.013  loss_mask_4: 3.027  loss_mask_5: 2.969  loss_mask_6: 2.993  loss_mask_7: 3.018  loss_mask_8: 3.013  time: 3.0181  data_time: 0.0608  lr: 7.4964e-05  max_mem: 27646M
[01/29 11:23:43] d2.utils.events INFO:  eta: 1 day, 11:47:33  iter: 16459  total_loss: 28.78  loss_mask: 2.885  loss_mask_0: 2.845  loss_mask_1: 2.847  loss_mask_2: 2.902  loss_mask_3: 2.886  loss_mask_4: 2.865  loss_mask_5: 2.865  loss_mask_6: 2.844  loss_mask_7: 2.877  loss_mask_8: 2.863  time: 3.0181  data_time: 0.0500  lr: 7.4933e-05  max_mem: 27646M
[01/29 11:24:42] d2.utils.events INFO:  eta: 1 day, 11:46:01  iter: 16479  total_loss: 29.27  loss_mask: 2.909  loss_mask_0: 3.089  loss_mask_1: 2.927  loss_mask_2: 2.923  loss_mask_3: 2.917  loss_mask_4: 2.921  loss_mask_5: 2.923  loss_mask_6: 2.918  loss_mask_7: 2.958  loss_mask_8: 2.946  time: 3.0180  data_time: 0.0582  lr: 7.4902e-05  max_mem: 27646M
[01/29 11:25:41] d2.utils.events INFO:  eta: 1 day, 11:44:55  iter: 16499  total_loss: 29.68  loss_mask: 2.945  loss_mask_0: 3.078  loss_mask_1: 2.943  loss_mask_2: 2.981  loss_mask_3: 2.969  loss_mask_4: 2.94  loss_mask_5: 2.93  loss_mask_6: 3.01  loss_mask_7: 2.916  loss_mask_8: 2.955  time: 3.0179  data_time: 0.0633  lr: 7.4871e-05  max_mem: 27646M
[01/29 11:26:40] d2.utils.events INFO:  eta: 1 day, 11:44:41  iter: 16519  total_loss: 26.82  loss_mask: 2.77  loss_mask_0: 2.707  loss_mask_1: 2.677  loss_mask_2: 2.705  loss_mask_3: 2.651  loss_mask_4: 2.661  loss_mask_5: 2.667  loss_mask_6: 2.677  loss_mask_7: 2.654  loss_mask_8: 2.664  time: 3.0178  data_time: 0.0634  lr: 7.484e-05  max_mem: 27646M
[01/29 11:27:39] d2.utils.events INFO:  eta: 1 day, 11:44:04  iter: 16539  total_loss: 28.18  loss_mask: 2.808  loss_mask_0: 2.922  loss_mask_1: 2.787  loss_mask_2: 2.814  loss_mask_3: 2.807  loss_mask_4: 2.819  loss_mask_5: 2.798  loss_mask_6: 2.778  loss_mask_7: 2.808  loss_mask_8: 2.814  time: 3.0178  data_time: 0.0612  lr: 7.4809e-05  max_mem: 27646M
[01/29 11:28:38] d2.utils.events INFO:  eta: 1 day, 11:43:05  iter: 16559  total_loss: 29.37  loss_mask: 2.933  loss_mask_0: 2.964  loss_mask_1: 2.95  loss_mask_2: 2.957  loss_mask_3: 2.966  loss_mask_4: 2.941  loss_mask_5: 2.932  loss_mask_6: 2.93  loss_mask_7: 2.939  loss_mask_8: 2.957  time: 3.0177  data_time: 0.0542  lr: 7.4778e-05  max_mem: 27646M
[01/29 11:29:37] d2.utils.events INFO:  eta: 1 day, 11:41:07  iter: 16579  total_loss: 30.07  loss_mask: 2.978  loss_mask_0: 2.979  loss_mask_1: 2.947  loss_mask_2: 3.025  loss_mask_3: 3.016  loss_mask_4: 2.987  loss_mask_5: 2.955  loss_mask_6: 3.003  loss_mask_7: 2.945  loss_mask_8: 2.986  time: 3.0176  data_time: 0.0626  lr: 7.4747e-05  max_mem: 27646M
[01/29 11:30:37] d2.utils.events INFO:  eta: 1 day, 11:39:59  iter: 16599  total_loss: 28.35  loss_mask: 2.814  loss_mask_0: 2.888  loss_mask_1: 2.822  loss_mask_2: 2.838  loss_mask_3: 2.828  loss_mask_4: 2.85  loss_mask_5: 2.819  loss_mask_6: 2.836  loss_mask_7: 2.813  loss_mask_8: 2.834  time: 3.0176  data_time: 0.0487  lr: 7.4716e-05  max_mem: 27646M
[01/29 11:31:36] d2.utils.events INFO:  eta: 1 day, 11:39:22  iter: 16619  total_loss: 29.74  loss_mask: 2.975  loss_mask_0: 2.971  loss_mask_1: 2.906  loss_mask_2: 3.006  loss_mask_3: 2.992  loss_mask_4: 2.916  loss_mask_5: 2.945  loss_mask_6: 3.006  loss_mask_7: 2.956  loss_mask_8: 2.952  time: 3.0175  data_time: 0.0588  lr: 7.4685e-05  max_mem: 27646M
[01/29 11:32:35] d2.utils.events INFO:  eta: 1 day, 11:38:32  iter: 16639  total_loss: 29.4  loss_mask: 2.927  loss_mask_0: 2.987  loss_mask_1: 2.898  loss_mask_2: 2.916  loss_mask_3: 2.967  loss_mask_4: 2.928  loss_mask_5: 2.882  loss_mask_6: 2.953  loss_mask_7: 2.989  loss_mask_8: 2.956  time: 3.0174  data_time: 0.0547  lr: 7.4654e-05  max_mem: 27646M
[01/29 11:33:35] d2.utils.events INFO:  eta: 1 day, 11:37:57  iter: 16659  total_loss: 26.3  loss_mask: 2.615  loss_mask_0: 2.661  loss_mask_1: 2.605  loss_mask_2: 2.637  loss_mask_3: 2.614  loss_mask_4: 2.641  loss_mask_5: 2.626  loss_mask_6: 2.615  loss_mask_7: 2.635  loss_mask_8: 2.634  time: 3.0174  data_time: 0.0652  lr: 7.4623e-05  max_mem: 27646M
[01/29 11:34:34] d2.utils.events INFO:  eta: 1 day, 11:37:24  iter: 16679  total_loss: 26.55  loss_mask: 2.654  loss_mask_0: 2.747  loss_mask_1: 2.589  loss_mask_2: 2.62  loss_mask_3: 2.589  loss_mask_4: 2.598  loss_mask_5: 2.608  loss_mask_6: 2.837  loss_mask_7: 2.624  loss_mask_8: 2.936  time: 3.0173  data_time: 0.0588  lr: 7.4592e-05  max_mem: 27646M
[01/29 11:35:33] d2.utils.events INFO:  eta: 1 day, 11:36:25  iter: 16699  total_loss: 26.5  loss_mask: 2.639  loss_mask_0: 2.635  loss_mask_1: 2.55  loss_mask_2: 2.582  loss_mask_3: 2.583  loss_mask_4: 2.621  loss_mask_5: 2.578  loss_mask_6: 2.658  loss_mask_7: 2.621  loss_mask_8: 3.002  time: 3.0172  data_time: 0.0585  lr: 7.4561e-05  max_mem: 27646M
[01/29 11:36:33] d2.utils.events INFO:  eta: 1 day, 11:35:40  iter: 16719  total_loss: 28.51  loss_mask: 2.834  loss_mask_0: 2.907  loss_mask_1: 2.779  loss_mask_2: 2.862  loss_mask_3: 2.844  loss_mask_4: 2.849  loss_mask_5: 2.808  loss_mask_6: 2.841  loss_mask_7: 2.834  loss_mask_8: 2.984  time: 3.0172  data_time: 0.0592  lr: 7.453e-05  max_mem: 27646M
[01/29 11:37:32] d2.utils.events INFO:  eta: 1 day, 11:34:35  iter: 16739  total_loss: 27.9  loss_mask: 2.777  loss_mask_0: 2.786  loss_mask_1: 2.749  loss_mask_2: 2.78  loss_mask_3: 2.763  loss_mask_4: 2.791  loss_mask_5: 2.777  loss_mask_6: 2.778  loss_mask_7: 2.771  loss_mask_8: 2.877  time: 3.0171  data_time: 0.0490  lr: 7.4499e-05  max_mem: 27646M
[01/29 11:38:32] d2.utils.events INFO:  eta: 1 day, 11:33:17  iter: 16759  total_loss: 27.18  loss_mask: 2.711  loss_mask_0: 2.792  loss_mask_1: 2.679  loss_mask_2: 2.759  loss_mask_3: 2.669  loss_mask_4: 2.681  loss_mask_5: 2.729  loss_mask_6: 2.7  loss_mask_7: 2.69  loss_mask_8: 2.871  time: 3.0171  data_time: 0.0578  lr: 7.4468e-05  max_mem: 27646M
[01/29 11:39:31] d2.utils.events INFO:  eta: 1 day, 11:32:42  iter: 16779  total_loss: 26.32  loss_mask: 2.648  loss_mask_0: 2.663  loss_mask_1: 2.611  loss_mask_2: 2.638  loss_mask_3: 2.633  loss_mask_4: 2.622  loss_mask_5: 2.606  loss_mask_6: 2.632  loss_mask_7: 2.614  loss_mask_8: 2.655  time: 3.0170  data_time: 0.0599  lr: 7.4437e-05  max_mem: 27646M
[01/29 11:40:30] d2.utils.events INFO:  eta: 1 day, 11:31:21  iter: 16799  total_loss: 29.91  loss_mask: 3.017  loss_mask_0: 3.043  loss_mask_1: 2.991  loss_mask_2: 3.056  loss_mask_3: 2.981  loss_mask_4: 3.007  loss_mask_5: 2.996  loss_mask_6: 2.98  loss_mask_7: 3.004  loss_mask_8: 3.261  time: 3.0169  data_time: 0.0535  lr: 7.4406e-05  max_mem: 27646M
[01/29 11:41:29] d2.utils.events INFO:  eta: 1 day, 11:30:29  iter: 16819  total_loss: 27.62  loss_mask: 2.673  loss_mask_0: 2.73  loss_mask_1: 2.719  loss_mask_2: 2.73  loss_mask_3: 2.678  loss_mask_4: 2.696  loss_mask_5: 2.697  loss_mask_6: 2.731  loss_mask_7: 2.678  loss_mask_8: 2.936  time: 3.0169  data_time: 0.0546  lr: 7.4375e-05  max_mem: 27646M
[01/29 11:42:29] d2.utils.events INFO:  eta: 1 day, 11:29:32  iter: 16839  total_loss: 30.21  loss_mask: 2.992  loss_mask_0: 3.004  loss_mask_1: 2.981  loss_mask_2: 3.009  loss_mask_3: 2.986  loss_mask_4: 3.024  loss_mask_5: 3.022  loss_mask_6: 3.002  loss_mask_7: 3  loss_mask_8: 3.091  time: 3.0168  data_time: 0.0529  lr: 7.4344e-05  max_mem: 27646M
[01/29 11:43:28] d2.utils.events INFO:  eta: 1 day, 11:27:41  iter: 16859  total_loss: 26.09  loss_mask: 2.635  loss_mask_0: 2.628  loss_mask_1: 2.604  loss_mask_2: 2.608  loss_mask_3: 2.597  loss_mask_4: 2.59  loss_mask_5: 2.614  loss_mask_6: 2.603  loss_mask_7: 2.597  loss_mask_8: 2.766  time: 3.0167  data_time: 0.0554  lr: 7.4313e-05  max_mem: 27646M
[01/29 11:44:27] d2.utils.events INFO:  eta: 1 day, 11:26:42  iter: 16879  total_loss: 26.32  loss_mask: 2.666  loss_mask_0: 2.68  loss_mask_1: 2.645  loss_mask_2: 2.616  loss_mask_3: 2.624  loss_mask_4: 2.64  loss_mask_5: 2.669  loss_mask_6: 2.598  loss_mask_7: 2.674  loss_mask_8: 2.922  time: 3.0167  data_time: 0.0629  lr: 7.4282e-05  max_mem: 27646M
[01/29 11:45:27] d2.utils.events INFO:  eta: 1 day, 11:25:07  iter: 16899  total_loss: 26.47  loss_mask: 2.627  loss_mask_0: 2.666  loss_mask_1: 2.596  loss_mask_2: 2.619  loss_mask_3: 2.665  loss_mask_4: 2.695  loss_mask_5: 2.656  loss_mask_6: 2.612  loss_mask_7: 2.642  loss_mask_8: 2.714  time: 3.0166  data_time: 0.0567  lr: 7.4251e-05  max_mem: 27646M
[01/29 11:46:26] d2.utils.events INFO:  eta: 1 day, 11:23:44  iter: 16919  total_loss: 27.91  loss_mask: 2.795  loss_mask_0: 2.819  loss_mask_1: 2.714  loss_mask_2: 2.757  loss_mask_3: 2.799  loss_mask_4: 2.778  loss_mask_5: 2.751  loss_mask_6: 2.754  loss_mask_7: 2.781  loss_mask_8: 2.831  time: 3.0165  data_time: 0.0533  lr: 7.422e-05  max_mem: 27646M
[01/29 11:47:25] d2.utils.events INFO:  eta: 1 day, 11:22:22  iter: 16939  total_loss: 27.18  loss_mask: 2.675  loss_mask_0: 2.8  loss_mask_1: 2.716  loss_mask_2: 2.741  loss_mask_3: 2.727  loss_mask_4: 2.693  loss_mask_5: 2.684  loss_mask_6: 2.694  loss_mask_7: 2.703  loss_mask_8: 2.748  time: 3.0165  data_time: 0.0560  lr: 7.4189e-05  max_mem: 27646M
[01/29 11:48:24] d2.utils.events INFO:  eta: 1 day, 11:20:12  iter: 16959  total_loss: 26.49  loss_mask: 2.658  loss_mask_0: 2.672  loss_mask_1: 2.647  loss_mask_2: 2.674  loss_mask_3: 2.65  loss_mask_4: 2.658  loss_mask_5: 2.666  loss_mask_6: 2.66  loss_mask_7: 2.625  loss_mask_8: 2.634  time: 3.0164  data_time: 0.0553  lr: 7.4158e-05  max_mem: 27646M
[01/29 11:49:23] d2.utils.events INFO:  eta: 1 day, 11:18:49  iter: 16979  total_loss: 26.58  loss_mask: 2.641  loss_mask_0: 2.719  loss_mask_1: 2.643  loss_mask_2: 2.662  loss_mask_3: 2.65  loss_mask_4: 2.662  loss_mask_5: 2.639  loss_mask_6: 2.628  loss_mask_7: 2.678  loss_mask_8: 2.693  time: 3.0163  data_time: 0.0624  lr: 7.4127e-05  max_mem: 27646M
[01/29 11:50:22] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 11:50:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 11:50:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 12:04:21] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.10213942888306, 'error_1pix': 0.47183052092880773, 'error_3pix': 0.2227788692048401, 'mIoU': 4.938427860162364, 'fwIoU': 11.345383603872888, 'IoU-0': 0.00016636351863769027, 'IoU-1': 17.421023244591545, 'IoU-2': 1.881488243671183, 'IoU-3': 2.21348382556682, 'IoU-4': 1.8931095543443965, 'IoU-5': 2.3033722681806905, 'IoU-6': 2.5288691378630515, 'IoU-7': 2.268347495369894, 'IoU-8': 5.014341110589856, 'IoU-9': 13.560485787908258, 'IoU-10': 16.083919750234415, 'IoU-11': 24.407005553251167, 'IoU-12': 23.46993954278405, 'IoU-13': 20.98390412986845, 'IoU-14': 20.76686476898466, 'IoU-15': 19.76624299854908, 'IoU-16': 19.366748257286613, 'IoU-17': 16.379854113736712, 'IoU-18': 17.098324067117765, 'IoU-19': 17.71635745461075, 'IoU-20': 16.904509247221693, 'IoU-21': 17.229894894712587, 'IoU-22': 17.697515976062263, 'IoU-23': 15.782761588222325, 'IoU-24': 16.304942768253365, 'IoU-25': 16.401623154690327, 'IoU-26': 15.936987082596119, 'IoU-27': 17.22578463262135, 'IoU-28': 15.890211277032348, 'IoU-29': 16.05544204874201, 'IoU-30': 15.051237840296617, 'IoU-31': 14.951977284640366, 'IoU-32': 13.08749102109425, 'IoU-33': 11.806664440327602, 'IoU-34': 11.20717689635611, 'IoU-35': 11.010988816272212, 'IoU-36': 10.353715204990811, 'IoU-37': 9.46835455430629, 'IoU-38': 8.995004390981888, 'IoU-39': 8.150493461820176, 'IoU-40': 8.054264961394757, 'IoU-41': 7.845574672199226, 'IoU-42': 7.512896156567368, 'IoU-43': 7.2751480850733135, 'IoU-44': 7.209987447915549, 'IoU-45': 7.0430208195105735, 'IoU-46': 6.790365210051889, 'IoU-47': 6.575153295975696, 'IoU-48': 6.245774872116696, 'IoU-49': 6.191323759197516, 'IoU-50': 6.276571518159916, 'IoU-51': 6.01693541343133, 'IoU-52': 5.616208585581157, 'IoU-53': 5.676308482384657, 'IoU-54': 5.436202159145622, 'IoU-55': 5.169723126716366, 'IoU-56': 4.956516674108301, 'IoU-57': 5.0072174069500885, 'IoU-58': 4.855329432873424, 'IoU-59': 4.642493181303093, 'IoU-60': 4.374036760668495, 'IoU-61': 4.133064621922555, 'IoU-62': 4.060093735098386, 'IoU-63': 3.711633789033259, 'IoU-64': 3.6938774154222322, 'IoU-65': 3.4466529537667747, 'IoU-66': 3.261335153762778, 'IoU-67': 3.2300216733125797, 'IoU-68': 3.37842559611044, 'IoU-69': 3.4173652676100867, 'IoU-70': 3.294732581480009, 'IoU-71': 3.313201521787286, 'IoU-72': 3.4000342094825373, 'IoU-73': 3.426036935362272, 'IoU-74': 3.4843542987370335, 'IoU-75': 3.2118408802303837, 'IoU-76': 3.309533633717891, 'IoU-77': 3.2976107007749866, 'IoU-78': 3.3087865700850885, 'IoU-79': 3.315132386485127, 'IoU-80': 3.387050649292368, 'IoU-81': 3.3863192759363963, 'IoU-82': 3.3142315761108323, 'IoU-83': 3.632159211040173, 'IoU-84': 3.64340643160703, 'IoU-85': 3.5995109432157237, 'IoU-86': 3.5982337369911916, 'IoU-87': 3.5283697934163145, 'IoU-88': 3.4476878278887124, 'IoU-89': 3.3378109544369114, 'IoU-90': 3.319154745774603, 'IoU-91': 3.340110095814064, 'IoU-92': 3.3550524641697397, 'IoU-93': 3.3001116795947487, 'IoU-94': 3.2311871573415774, 'IoU-95': 3.16213254590325, 'IoU-96': 3.0779700146302833, 'IoU-97': 3.0470503712459984, 'IoU-98': 3.0489410633852607, 'IoU-99': 2.8537948611189967, 'IoU-100': 2.709135242980828, 'IoU-101': 2.6012570933763692, 'IoU-102': 2.659377840455648, 'IoU-103': 2.6727436345457076, 'IoU-104': 2.7177542404931208, 'IoU-105': 2.8274105816378103, 'IoU-106': 2.8629875364710458, 'IoU-107': 2.8404844501945536, 'IoU-108': 3.081106666870759, 'IoU-109': 3.1452352405020765, 'IoU-110': 3.2204718551125042, 'IoU-111': 3.0513944165960307, 'IoU-112': 3.189043461615578, 'IoU-113': 2.9791319259008984, 'IoU-114': 2.988701322824254, 'IoU-115': 2.95035072145416, 'IoU-116': 2.967361816774963, 'IoU-117': 3.083506133618251, 'IoU-118': 3.227341337349325, 'IoU-119': 3.2787505224522424, 'IoU-120': 2.959324435576607, 'IoU-121': 3.2076329668119956, 'IoU-122': 3.189867783877111, 'IoU-123': 2.9540986552991244, 'IoU-124': 2.8863553542610236, 'IoU-125': 3.024024335606216, 'IoU-126': 3.155888568557931, 'IoU-127': 3.1711363331341538, 'IoU-128': 3.0262422451891533, 'IoU-129': 2.753785166217487, 'IoU-130': 2.741132246772604, 'IoU-131': 2.4145814982596248, 'IoU-132': 2.4595655208676446, 'IoU-133': 2.5035188462222004, 'IoU-134': 2.343179705283497, 'IoU-135': 2.38752014556613, 'IoU-136': 2.182536756042906, 'IoU-137': 2.069120539054208, 'IoU-138': 2.0068234258214686, 'IoU-139': 1.8510484627393458, 'IoU-140': 2.0009369715711567, 'IoU-141': 2.1163421807677083, 'IoU-142': 2.0841766817750464, 'IoU-143': 2.0396852073617477, 'IoU-144': 1.808178636859898, 'IoU-145': 1.8647443825687713, 'IoU-146': 2.019685917737565, 'IoU-147': 2.031828102439057, 'IoU-148': 2.311295905221803, 'IoU-149': 2.3211457080955435, 'IoU-150': 1.736303659194324, 'IoU-151': 1.704564497176984, 'IoU-152': 2.1138002401141613, 'IoU-153': 1.6434594511970317, 'IoU-154': 1.7414215410889642, 'IoU-155': 1.6376476177626793, 'IoU-156': 1.498691512764196, 'IoU-157': 1.4815835351346196, 'IoU-158': 1.673888560138966, 'IoU-159': 1.4782596762884455, 'IoU-160': 1.423661915705281, 'IoU-161': 1.4218025701710368, 'IoU-162': 1.4350433063308097, 'IoU-163': 1.3228547112052544, 'IoU-164': 1.4542433186893649, 'IoU-165': 1.174276726141615, 'IoU-166': 1.1760866288199765, 'IoU-167': 1.1644728681499688, 'IoU-168': 1.070098426879836, 'IoU-169': 0.8642138406323623, 'IoU-170': 1.0195669798020475, 'IoU-171': 0.8508343196783803, 'IoU-172': 0.9010385536645978, 'IoU-173': 0.8290605530613702, 'IoU-174': 0.9335576343693169, 'IoU-175': 0.2665106534098576, 'IoU-176': 0.19273233338487708, 'IoU-177': 0.2562570599053389, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 9.17209109410658, 'pACC': 18.688711922973695, 'ACC-0': 0.0013143774515175012, 'ACC-1': 17.58850969114746, 'ACC-2': 3.4814793449063393, 'ACC-3': 9.30361801590291, 'ACC-4': 7.361576534354605, 'ACC-5': 9.510402545281806, 'ACC-6': 11.204700631384338, 'ACC-7': 12.01107744365563, 'ACC-8': 14.53328847270664, 'ACC-9': 24.550005343474197, 'ACC-10': 26.010185391836476, 'ACC-11': 36.09627842254848, 'ACC-12': 36.39065794488681, 'ACC-13': 32.755520888613646, 'ACC-14': 33.27374166280757, 'ACC-15': 32.73348626170034, 'ACC-16': 31.9321989569767, 'ACC-17': 28.877692951387996, 'ACC-18': 29.636898908793956, 'ACC-19': 30.86971989211702, 'ACC-20': 29.388383302919348, 'ACC-21': 29.816610474239656, 'ACC-22': 29.89916213911697, 'ACC-23': 28.59404646939337, 'ACC-24': 29.82511368385389, 'ACC-25': 30.02629936530078, 'ACC-26': 29.294364412223757, 'ACC-27': 31.13161440610227, 'ACC-28': 29.103107946864643, 'ACC-29': 28.855650266762723, 'ACC-30': 27.91588422557476, 'ACC-31': 27.361132138136817, 'ACC-32': 24.142157625702552, 'ACC-33': 22.224967645033473, 'ACC-34': 21.479736902487772, 'ACC-35': 20.777399213231043, 'ACC-36': 19.326607883237536, 'ACC-37': 18.038524644255478, 'ACC-38': 16.860774763782594, 'ACC-39': 15.082735173419545, 'ACC-40': 14.679773523721638, 'ACC-41': 14.738587322162255, 'ACC-42': 14.197386775305162, 'ACC-43': 13.646351616134892, 'ACC-44': 13.119836369967011, 'ACC-45': 12.879831271074513, 'ACC-46': 12.731829769897592, 'ACC-47': 12.324269178877213, 'ACC-48': 11.73356115186209, 'ACC-49': 11.66565865202328, 'ACC-50': 11.719517707429027, 'ACC-51': 11.40859524794959, 'ACC-52': 10.683805530063738, 'ACC-53': 10.673596163363946, 'ACC-54': 10.049405462911677, 'ACC-55': 9.575828713899746, 'ACC-56': 9.266911698233542, 'ACC-57': 9.238896697533091, 'ACC-58': 9.141378290938299, 'ACC-59': 8.845677171227372, 'ACC-60': 8.333112308643928, 'ACC-61': 7.889426364374547, 'ACC-62': 7.780097131276538, 'ACC-63': 7.190967318756853, 'ACC-64': 7.136926785372803, 'ACC-65': 6.702877064840913, 'ACC-66': 6.380346365193246, 'ACC-67': 6.359127019814662, 'ACC-68': 6.60219469075425, 'ACC-69': 6.557509189401717, 'ACC-70': 6.253275038876856, 'ACC-71': 6.4152021024231125, 'ACC-72': 6.6299121472996045, 'ACC-73': 6.727419141692474, 'ACC-74': 6.780615900134713, 'ACC-75': 6.293518131257923, 'ACC-76': 6.370990939010633, 'ACC-77': 6.451083642498951, 'ACC-78': 6.534867660816106, 'ACC-79': 6.515486014742709, 'ACC-80': 6.543247651199002, 'ACC-81': 6.4566650822089775, 'ACC-82': 6.287909353511001, 'ACC-83': 6.782043875184625, 'ACC-84': 6.832461288193632, 'ACC-85': 6.75783801399175, 'ACC-86': 6.738543579429937, 'ACC-87': 6.596062989813927, 'ACC-88': 6.433865069906839, 'ACC-89': 6.199745356184223, 'ACC-90': 6.15667617100302, 'ACC-91': 6.2850380238847094, 'ACC-92': 6.355384556536111, 'ACC-93': 6.213030783697665, 'ACC-94': 6.015996190253764, 'ACC-95': 5.842323298779547, 'ACC-96': 5.728301483346264, 'ACC-97': 5.577376088223093, 'ACC-98': 5.54309386609869, 'ACC-99': 5.234178001198698, 'ACC-100': 4.981543157466223, 'ACC-101': 4.785765624489529, 'ACC-102': 4.93352967829633, 'ACC-103': 4.975323509965052, 'ACC-104': 5.0634760581392495, 'ACC-105': 5.280406256999334, 'ACC-106': 5.390087994426172, 'ACC-107': 5.389421215008985, 'ACC-108': 5.785386854564152, 'ACC-109': 5.817744722410037, 'ACC-110': 6.021343689526188, 'ACC-111': 5.73346357949419, 'ACC-112': 6.092333933250987, 'ACC-113': 5.687232223823172, 'ACC-114': 5.740640386997508, 'ACC-115': 5.6551726730112915, 'ACC-116': 5.754601149835479, 'ACC-117': 5.932805444228085, 'ACC-118': 6.330822098696853, 'ACC-119': 6.470066741381329, 'ACC-120': 5.889399002730368, 'ACC-121': 6.375966501137567, 'ACC-122': 6.383518733429572, 'ACC-123': 5.887768937906207, 'ACC-124': 5.907407219963124, 'ACC-125': 6.229367507720019, 'ACC-126': 6.5725211522873614, 'ACC-127': 6.651776953340373, 'ACC-128': 6.379140641865809, 'ACC-129': 5.784222611149007, 'ACC-130': 5.825914565721553, 'ACC-131': 5.19933037064211, 'ACC-132': 5.169680945535215, 'ACC-133': 5.147141875386992, 'ACC-134': 4.788487720809996, 'ACC-135': 4.79490907017844, 'ACC-136': 4.416479337495341, 'ACC-137': 4.194267056525751, 'ACC-138': 4.082084295758561, 'ACC-139': 3.798883872390558, 'ACC-140': 4.121175377306452, 'ACC-141': 4.355125652414671, 'ACC-142': 4.388412495054848, 'ACC-143': 4.30227532297617, 'ACC-144': 3.8444945848375456, 'ACC-145': 3.936581766139672, 'ACC-146': 4.2769870462178154, 'ACC-147': 4.239899794147169, 'ACC-148': 4.812504336766944, 'ACC-149': 4.994579486831043, 'ACC-150': 3.811825821938297, 'ACC-151': 3.6317401039984736, 'ACC-152': 4.367076336907411, 'ACC-153': 3.496651642573151, 'ACC-154': 3.6396854639195833, 'ACC-155': 3.5008122505626593, 'ACC-156': 3.344127932155623, 'ACC-157': 3.4249176231365683, 'ACC-158': 3.7127884937005238, 'ACC-159': 3.2070929747906782, 'ACC-160': 2.9700436592317785, 'ACC-161': 2.916223176447791, 'ACC-162': 3.047000752749917, 'ACC-163': 2.882138658782849, 'ACC-164': 3.224578971901864, 'ACC-165': 2.6422447884076017, 'ACC-166': 2.698206176394054, 'ACC-167': 2.8049202056049762, 'ACC-168': 2.816829594204937, 'ACC-169': 2.341667646382742, 'ACC-170': 2.38581995258174, 'ACC-171': 2.0109880622840546, 'ACC-172': 1.8566877801237174, 'ACC-173': 1.8782478466847035, 'ACC-174': 1.9146996818153856, 'ACC-175': 0.45647917556422046, 'ACC-176': 0.2826068028790341, 'ACC-177': 0.3039480021924118, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 12:04:21] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 12:04:21] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 12:04:21] d2.evaluation.testing INFO: copypaste: 3.1021,0.4718,0.2228,4.9384,11.3454,9.1721,18.6887
[01/29 12:04:21] d2.utils.events INFO:  eta: 1 day, 11:16:40  iter: 16999  total_loss: 27.15  loss_mask: 2.723  loss_mask_0: 2.787  loss_mask_1: 2.694  loss_mask_2: 2.71  loss_mask_3: 2.723  loss_mask_4: 2.722  loss_mask_5: 2.717  loss_mask_6: 2.714  loss_mask_7: 2.714  loss_mask_8: 2.732  time: 3.0162  data_time: 0.0495  lr: 7.4096e-05  max_mem: 27646M
[01/29 12:05:20] d2.utils.events INFO:  eta: 1 day, 11:15:41  iter: 17019  total_loss: 26.29  loss_mask: 2.619  loss_mask_0: 2.708  loss_mask_1: 2.599  loss_mask_2: 2.623  loss_mask_3: 2.629  loss_mask_4: 2.621  loss_mask_5: 2.61  loss_mask_6: 2.62  loss_mask_7: 2.621  loss_mask_8: 2.644  time: 3.0162  data_time: 0.0604  lr: 7.4065e-05  max_mem: 27646M
[01/29 12:06:19] d2.utils.events INFO:  eta: 1 day, 11:14:15  iter: 17039  total_loss: 25.88  loss_mask: 2.558  loss_mask_0: 2.589  loss_mask_1: 2.592  loss_mask_2: 2.614  loss_mask_3: 2.6  loss_mask_4: 2.587  loss_mask_5: 2.571  loss_mask_6: 2.592  loss_mask_7: 2.589  loss_mask_8: 2.608  time: 3.0161  data_time: 0.0564  lr: 7.4034e-05  max_mem: 27646M
[01/29 12:07:19] d2.utils.events INFO:  eta: 1 day, 11:13:49  iter: 17059  total_loss: 28.31  loss_mask: 2.835  loss_mask_0: 2.842  loss_mask_1: 2.839  loss_mask_2: 2.855  loss_mask_3: 2.81  loss_mask_4: 2.8  loss_mask_5: 2.795  loss_mask_6: 2.839  loss_mask_7: 2.805  loss_mask_8: 2.889  time: 3.0160  data_time: 0.0676  lr: 7.4003e-05  max_mem: 27646M
[01/29 12:08:18] d2.utils.events INFO:  eta: 1 day, 11:11:49  iter: 17079  total_loss: 27.79  loss_mask: 2.772  loss_mask_0: 2.819  loss_mask_1: 2.733  loss_mask_2: 2.753  loss_mask_3: 2.768  loss_mask_4: 2.786  loss_mask_5: 2.75  loss_mask_6: 2.78  loss_mask_7: 2.78  loss_mask_8: 2.805  time: 3.0159  data_time: 0.0571  lr: 7.3972e-05  max_mem: 27646M
[01/29 12:09:17] d2.utils.events INFO:  eta: 1 day, 11:11:09  iter: 17099  total_loss: 31.03  loss_mask: 3.046  loss_mask_0: 3.085  loss_mask_1: 3.091  loss_mask_2: 3.136  loss_mask_3: 3.13  loss_mask_4: 3.131  loss_mask_5: 3.097  loss_mask_6: 3.042  loss_mask_7: 3.042  loss_mask_8: 3.018  time: 3.0159  data_time: 0.0523  lr: 7.3941e-05  max_mem: 27646M
[01/29 12:10:16] d2.utils.events INFO:  eta: 1 day, 11:10:31  iter: 17119  total_loss: 27.82  loss_mask: 2.752  loss_mask_0: 2.894  loss_mask_1: 2.753  loss_mask_2: 2.78  loss_mask_3: 2.808  loss_mask_4: 2.769  loss_mask_5: 2.749  loss_mask_6: 2.755  loss_mask_7: 2.768  loss_mask_8: 2.786  time: 3.0158  data_time: 0.0632  lr: 7.391e-05  max_mem: 27646M
[01/29 12:11:15] d2.utils.events INFO:  eta: 1 day, 11:09:32  iter: 17139  total_loss: 29.29  loss_mask: 2.931  loss_mask_0: 3.008  loss_mask_1: 2.894  loss_mask_2: 2.912  loss_mask_3: 2.911  loss_mask_4: 2.902  loss_mask_5: 2.928  loss_mask_6: 2.903  loss_mask_7: 2.919  loss_mask_8: 2.927  time: 3.0157  data_time: 0.0517  lr: 7.3879e-05  max_mem: 27646M
[01/29 12:12:14] d2.utils.events INFO:  eta: 1 day, 11:08:22  iter: 17159  total_loss: 27.83  loss_mask: 2.827  loss_mask_0: 2.845  loss_mask_1: 2.782  loss_mask_2: 2.782  loss_mask_3: 2.791  loss_mask_4: 2.795  loss_mask_5: 2.808  loss_mask_6: 2.759  loss_mask_7: 2.795  loss_mask_8: 2.756  time: 3.0156  data_time: 0.0630  lr: 7.3848e-05  max_mem: 27646M
[01/29 12:13:12] d2.utils.events INFO:  eta: 1 day, 11:06:48  iter: 17179  total_loss: 28.77  loss_mask: 2.878  loss_mask_0: 2.899  loss_mask_1: 2.832  loss_mask_2: 2.865  loss_mask_3: 2.848  loss_mask_4: 2.862  loss_mask_5: 2.86  loss_mask_6: 2.869  loss_mask_7: 2.865  loss_mask_8: 2.857  time: 3.0155  data_time: 0.0597  lr: 7.3817e-05  max_mem: 27646M
[01/29 12:14:12] d2.utils.events INFO:  eta: 1 day, 11:05:36  iter: 17199  total_loss: 28.93  loss_mask: 2.941  loss_mask_0: 2.854  loss_mask_1: 2.868  loss_mask_2: 2.902  loss_mask_3: 2.891  loss_mask_4: 2.865  loss_mask_5: 2.903  loss_mask_6: 2.903  loss_mask_7: 2.894  loss_mask_8: 2.911  time: 3.0155  data_time: 0.0582  lr: 7.3786e-05  max_mem: 27646M
[01/29 12:15:10] d2.utils.events INFO:  eta: 1 day, 11:04:03  iter: 17219  total_loss: 26.06  loss_mask: 2.591  loss_mask_0: 2.692  loss_mask_1: 2.579  loss_mask_2: 2.6  loss_mask_3: 2.595  loss_mask_4: 2.601  loss_mask_5: 2.6  loss_mask_6: 2.595  loss_mask_7: 2.614  loss_mask_8: 2.619  time: 3.0154  data_time: 0.0503  lr: 7.3755e-05  max_mem: 27646M
[01/29 12:16:10] d2.utils.events INFO:  eta: 1 day, 11:02:49  iter: 17239  total_loss: 26.99  loss_mask: 2.674  loss_mask_0: 2.77  loss_mask_1: 2.697  loss_mask_2: 2.653  loss_mask_3: 2.67  loss_mask_4: 2.714  loss_mask_5: 2.706  loss_mask_6: 2.727  loss_mask_7: 2.718  loss_mask_8: 2.686  time: 3.0153  data_time: 0.0642  lr: 7.3724e-05  max_mem: 27646M
[01/29 12:17:09] d2.utils.events INFO:  eta: 1 day, 11:01:45  iter: 17259  total_loss: 27.95  loss_mask: 2.773  loss_mask_0: 2.821  loss_mask_1: 2.76  loss_mask_2: 2.786  loss_mask_3: 2.799  loss_mask_4: 2.793  loss_mask_5: 2.754  loss_mask_6: 2.784  loss_mask_7: 2.771  loss_mask_8: 2.787  time: 3.0152  data_time: 0.0581  lr: 7.3693e-05  max_mem: 27646M
[01/29 12:18:07] d2.utils.events INFO:  eta: 1 day, 11:00:28  iter: 17279  total_loss: 27.44  loss_mask: 2.752  loss_mask_0: 2.739  loss_mask_1: 2.709  loss_mask_2: 2.736  loss_mask_3: 2.725  loss_mask_4: 2.712  loss_mask_5: 2.738  loss_mask_6: 2.738  loss_mask_7: 2.779  loss_mask_8: 2.765  time: 3.0152  data_time: 0.0558  lr: 7.3662e-05  max_mem: 27646M
[01/29 12:19:06] d2.utils.events INFO:  eta: 1 day, 10:59:29  iter: 17299  total_loss: 27.43  loss_mask: 2.748  loss_mask_0: 2.795  loss_mask_1: 2.724  loss_mask_2: 2.73  loss_mask_3: 2.725  loss_mask_4: 2.73  loss_mask_5: 2.732  loss_mask_6: 2.728  loss_mask_7: 2.738  loss_mask_8: 2.745  time: 3.0151  data_time: 0.0556  lr: 7.3631e-05  max_mem: 27646M
[01/29 12:20:05] d2.utils.events INFO:  eta: 1 day, 10:58:28  iter: 17319  total_loss: 26.84  loss_mask: 2.691  loss_mask_0: 2.755  loss_mask_1: 2.657  loss_mask_2: 2.673  loss_mask_3: 2.681  loss_mask_4: 2.683  loss_mask_5: 2.688  loss_mask_6: 2.665  loss_mask_7: 2.698  loss_mask_8: 2.65  time: 3.0150  data_time: 0.0525  lr: 7.36e-05  max_mem: 27646M
[01/29 12:21:05] d2.utils.events INFO:  eta: 1 day, 10:57:49  iter: 17339  total_loss: 29.14  loss_mask: 2.881  loss_mask_0: 3.022  loss_mask_1: 2.906  loss_mask_2: 2.903  loss_mask_3: 2.937  loss_mask_4: 2.918  loss_mask_5: 2.886  loss_mask_6: 2.889  loss_mask_7: 2.902  loss_mask_8: 2.9  time: 3.0149  data_time: 0.0553  lr: 7.3568e-05  max_mem: 27646M
[01/29 12:22:04] d2.utils.events INFO:  eta: 1 day, 10:57:21  iter: 17359  total_loss: 26.66  loss_mask: 2.709  loss_mask_0: 2.751  loss_mask_1: 2.657  loss_mask_2: 2.658  loss_mask_3: 2.656  loss_mask_4: 2.652  loss_mask_5: 2.655  loss_mask_6: 2.668  loss_mask_7: 2.685  loss_mask_8: 2.7  time: 3.0149  data_time: 0.0571  lr: 7.3537e-05  max_mem: 27646M
[01/29 12:23:03] d2.utils.events INFO:  eta: 1 day, 10:55:56  iter: 17379  total_loss: 28.23  loss_mask: 2.809  loss_mask_0: 2.957  loss_mask_1: 2.81  loss_mask_2: 2.797  loss_mask_3: 2.801  loss_mask_4: 2.8  loss_mask_5: 2.799  loss_mask_6: 2.831  loss_mask_7: 2.801  loss_mask_8: 2.825  time: 3.0148  data_time: 0.0504  lr: 7.3506e-05  max_mem: 27646M
[01/29 12:24:02] d2.utils.events INFO:  eta: 1 day, 10:54:57  iter: 17399  total_loss: 31.17  loss_mask: 3.134  loss_mask_0: 3.173  loss_mask_1: 3.074  loss_mask_2: 3.134  loss_mask_3: 3.1  loss_mask_4: 3.122  loss_mask_5: 3.071  loss_mask_6: 3.111  loss_mask_7: 3.158  loss_mask_8: 3.117  time: 3.0147  data_time: 0.0646  lr: 7.3475e-05  max_mem: 27646M
[01/29 12:25:01] d2.utils.events INFO:  eta: 1 day, 10:54:00  iter: 17419  total_loss: 27.63  loss_mask: 2.744  loss_mask_0: 2.775  loss_mask_1: 2.74  loss_mask_2: 2.755  loss_mask_3: 2.795  loss_mask_4: 2.762  loss_mask_5: 2.769  loss_mask_6: 2.758  loss_mask_7: 2.763  loss_mask_8: 2.752  time: 3.0147  data_time: 0.0546  lr: 7.3444e-05  max_mem: 27646M
[01/29 12:26:01] d2.utils.events INFO:  eta: 1 day, 10:52:59  iter: 17439  total_loss: 26.44  loss_mask: 2.631  loss_mask_0: 2.674  loss_mask_1: 2.63  loss_mask_2: 2.647  loss_mask_3: 2.66  loss_mask_4: 2.633  loss_mask_5: 2.657  loss_mask_6: 2.678  loss_mask_7: 2.628  loss_mask_8: 2.652  time: 3.0146  data_time: 0.0565  lr: 7.3413e-05  max_mem: 27646M
[01/29 12:27:00] d2.utils.events INFO:  eta: 1 day, 10:52:00  iter: 17459  total_loss: 26.97  loss_mask: 2.68  loss_mask_0: 2.648  loss_mask_1: 2.671  loss_mask_2: 2.696  loss_mask_3: 2.687  loss_mask_4: 2.691  loss_mask_5: 2.695  loss_mask_6: 2.672  loss_mask_7: 2.677  loss_mask_8: 2.687  time: 3.0146  data_time: 0.0595  lr: 7.3382e-05  max_mem: 27646M
[01/29 12:27:59] d2.utils.events INFO:  eta: 1 day, 10:50:46  iter: 17479  total_loss: 26.18  loss_mask: 2.631  loss_mask_0: 2.711  loss_mask_1: 2.609  loss_mask_2: 2.613  loss_mask_3: 2.609  loss_mask_4: 2.612  loss_mask_5: 2.575  loss_mask_6: 2.604  loss_mask_7: 2.64  loss_mask_8: 2.581  time: 3.0145  data_time: 0.0525  lr: 7.3351e-05  max_mem: 27646M
[01/29 12:28:58] d2.utils.events INFO:  eta: 1 day, 10:50:04  iter: 17499  total_loss: 27.85  loss_mask: 2.738  loss_mask_0: 2.762  loss_mask_1: 2.759  loss_mask_2: 2.82  loss_mask_3: 2.772  loss_mask_4: 2.78  loss_mask_5: 2.79  loss_mask_6: 2.797  loss_mask_7: 2.785  loss_mask_8: 2.831  time: 3.0144  data_time: 0.0635  lr: 7.332e-05  max_mem: 27646M
[01/29 12:29:58] d2.utils.events INFO:  eta: 1 day, 10:49:03  iter: 17519  total_loss: 24.79  loss_mask: 2.473  loss_mask_0: 2.552  loss_mask_1: 2.454  loss_mask_2: 2.482  loss_mask_3: 2.495  loss_mask_4: 2.486  loss_mask_5: 2.487  loss_mask_6: 2.483  loss_mask_7: 2.469  loss_mask_8: 2.496  time: 3.0144  data_time: 0.0605  lr: 7.3289e-05  max_mem: 27646M
[01/29 12:30:57] d2.utils.events INFO:  eta: 1 day, 10:47:49  iter: 17539  total_loss: 26.78  loss_mask: 2.663  loss_mask_0: 2.717  loss_mask_1: 2.657  loss_mask_2: 2.643  loss_mask_3: 2.664  loss_mask_4: 2.69  loss_mask_5: 2.669  loss_mask_6: 2.682  loss_mask_7: 2.663  loss_mask_8: 2.656  time: 3.0143  data_time: 0.0587  lr: 7.3258e-05  max_mem: 27646M
[01/29 12:31:56] d2.utils.events INFO:  eta: 1 day, 10:46:35  iter: 17559  total_loss: 30.38  loss_mask: 2.985  loss_mask_0: 3.213  loss_mask_1: 2.958  loss_mask_2: 2.989  loss_mask_3: 3.051  loss_mask_4: 3.012  loss_mask_5: 2.953  loss_mask_6: 2.965  loss_mask_7: 3.01  loss_mask_8: 3.038  time: 3.0142  data_time: 0.0539  lr: 7.3227e-05  max_mem: 27646M
[01/29 12:32:55] d2.utils.events INFO:  eta: 1 day, 10:45:41  iter: 17579  total_loss: 30.33  loss_mask: 3.031  loss_mask_0: 3.123  loss_mask_1: 2.997  loss_mask_2: 3.06  loss_mask_3: 3.034  loss_mask_4: 3.033  loss_mask_5: 3.034  loss_mask_6: 3.024  loss_mask_7: 3.036  loss_mask_8: 3.044  time: 3.0142  data_time: 0.0554  lr: 7.3196e-05  max_mem: 27646M
[01/29 12:33:54] d2.utils.events INFO:  eta: 1 day, 10:44:30  iter: 17599  total_loss: 27.82  loss_mask: 2.791  loss_mask_0: 2.772  loss_mask_1: 2.777  loss_mask_2: 2.748  loss_mask_3: 2.772  loss_mask_4: 2.781  loss_mask_5: 2.775  loss_mask_6: 2.768  loss_mask_7: 2.758  loss_mask_8: 2.817  time: 3.0141  data_time: 0.0597  lr: 7.3165e-05  max_mem: 27646M
[01/29 12:34:54] d2.utils.events INFO:  eta: 1 day, 10:43:20  iter: 17619  total_loss: 29.63  loss_mask: 2.969  loss_mask_0: 3.032  loss_mask_1: 2.937  loss_mask_2: 2.95  loss_mask_3: 2.956  loss_mask_4: 2.941  loss_mask_5: 2.949  loss_mask_6: 2.953  loss_mask_7: 2.961  loss_mask_8: 2.974  time: 3.0140  data_time: 0.0515  lr: 7.3134e-05  max_mem: 27646M
[01/29 12:35:53] d2.utils.events INFO:  eta: 1 day, 10:42:38  iter: 17639  total_loss: 27.78  loss_mask: 2.753  loss_mask_0: 2.836  loss_mask_1: 2.765  loss_mask_2: 2.769  loss_mask_3: 2.759  loss_mask_4: 2.804  loss_mask_5: 2.761  loss_mask_6: 2.752  loss_mask_7: 2.792  loss_mask_8: 2.795  time: 3.0140  data_time: 0.0533  lr: 7.3103e-05  max_mem: 27646M
[01/29 12:36:53] d2.utils.events INFO:  eta: 1 day, 10:41:25  iter: 17659  total_loss: 30.41  loss_mask: 3.044  loss_mask_0: 3.078  loss_mask_1: 3.015  loss_mask_2: 3.026  loss_mask_3: 3  loss_mask_4: 3.019  loss_mask_5: 3.087  loss_mask_6: 3.038  loss_mask_7: 3.044  loss_mask_8: 3.063  time: 3.0139  data_time: 0.0547  lr: 7.3072e-05  max_mem: 27646M
[01/29 12:37:51] d2.utils.events INFO:  eta: 1 day, 10:39:42  iter: 17679  total_loss: 28.62  loss_mask: 2.867  loss_mask_0: 3.009  loss_mask_1: 2.856  loss_mask_2: 2.848  loss_mask_3: 2.85  loss_mask_4: 2.866  loss_mask_5: 2.862  loss_mask_6: 2.857  loss_mask_7: 2.841  loss_mask_8: 2.838  time: 3.0139  data_time: 0.0540  lr: 7.3041e-05  max_mem: 27646M
[01/29 12:38:51] d2.utils.events INFO:  eta: 1 day, 10:39:17  iter: 17699  total_loss: 26.65  loss_mask: 2.674  loss_mask_0: 2.7  loss_mask_1: 2.649  loss_mask_2: 2.713  loss_mask_3: 2.702  loss_mask_4: 2.683  loss_mask_5: 2.662  loss_mask_6: 2.663  loss_mask_7: 2.683  loss_mask_8: 2.649  time: 3.0138  data_time: 0.0619  lr: 7.301e-05  max_mem: 27646M
[01/29 12:39:50] d2.utils.events INFO:  eta: 1 day, 10:38:04  iter: 17719  total_loss: 25.56  loss_mask: 2.565  loss_mask_0: 2.602  loss_mask_1: 2.522  loss_mask_2: 2.553  loss_mask_3: 2.589  loss_mask_4: 2.57  loss_mask_5: 2.53  loss_mask_6: 2.534  loss_mask_7: 2.573  loss_mask_8: 2.557  time: 3.0138  data_time: 0.0576  lr: 7.2978e-05  max_mem: 27646M
[01/29 12:40:50] d2.utils.events INFO:  eta: 1 day, 10:37:13  iter: 17739  total_loss: 27.5  loss_mask: 2.748  loss_mask_0: 2.756  loss_mask_1: 2.726  loss_mask_2: 2.75  loss_mask_3: 2.758  loss_mask_4: 2.772  loss_mask_5: 2.733  loss_mask_6: 2.755  loss_mask_7: 2.771  loss_mask_8: 2.747  time: 3.0137  data_time: 0.0593  lr: 7.2947e-05  max_mem: 27646M
[01/29 12:41:49] d2.utils.events INFO:  eta: 1 day, 10:36:20  iter: 17759  total_loss: 25  loss_mask: 2.46  loss_mask_0: 2.558  loss_mask_1: 2.452  loss_mask_2: 2.512  loss_mask_3: 2.542  loss_mask_4: 2.496  loss_mask_5: 2.464  loss_mask_6: 2.477  loss_mask_7: 2.486  loss_mask_8: 2.486  time: 3.0136  data_time: 0.0617  lr: 7.2916e-05  max_mem: 27646M
[01/29 12:42:48] d2.utils.events INFO:  eta: 1 day, 10:35:29  iter: 17779  total_loss: 28.7  loss_mask: 2.854  loss_mask_0: 3.005  loss_mask_1: 2.86  loss_mask_2: 2.863  loss_mask_3: 2.86  loss_mask_4: 2.851  loss_mask_5: 2.825  loss_mask_6: 2.847  loss_mask_7: 2.872  loss_mask_8: 2.863  time: 3.0136  data_time: 0.0573  lr: 7.2885e-05  max_mem: 27646M
[01/29 12:43:48] d2.utils.events INFO:  eta: 1 day, 10:34:36  iter: 17799  total_loss: 25.83  loss_mask: 2.568  loss_mask_0: 2.624  loss_mask_1: 2.549  loss_mask_2: 2.574  loss_mask_3: 2.633  loss_mask_4: 2.58  loss_mask_5: 2.594  loss_mask_6: 2.577  loss_mask_7: 2.573  loss_mask_8: 2.603  time: 3.0135  data_time: 0.0660  lr: 7.2854e-05  max_mem: 27646M
[01/29 12:44:47] d2.utils.events INFO:  eta: 1 day, 10:34:06  iter: 17819  total_loss: 25.89  loss_mask: 2.576  loss_mask_0: 2.617  loss_mask_1: 2.558  loss_mask_2: 2.617  loss_mask_3: 2.581  loss_mask_4: 2.591  loss_mask_5: 2.582  loss_mask_6: 2.582  loss_mask_7: 2.616  loss_mask_8: 2.583  time: 3.0135  data_time: 0.0610  lr: 7.2823e-05  max_mem: 27646M
[01/29 12:45:46] d2.utils.events INFO:  eta: 1 day, 10:32:38  iter: 17839  total_loss: 25.45  loss_mask: 2.507  loss_mask_0: 2.581  loss_mask_1: 2.562  loss_mask_2: 2.526  loss_mask_3: 2.562  loss_mask_4: 2.531  loss_mask_5: 2.546  loss_mask_6: 2.515  loss_mask_7: 2.526  loss_mask_8: 2.524  time: 3.0134  data_time: 0.0525  lr: 7.2792e-05  max_mem: 27646M
[01/29 12:46:45] d2.utils.events INFO:  eta: 1 day, 10:32:08  iter: 17859  total_loss: 26.94  loss_mask: 2.727  loss_mask_0: 2.675  loss_mask_1: 2.668  loss_mask_2: 2.71  loss_mask_3: 2.714  loss_mask_4: 2.715  loss_mask_5: 2.68  loss_mask_6: 2.679  loss_mask_7: 2.677  loss_mask_8: 2.686  time: 3.0134  data_time: 0.0613  lr: 7.2761e-05  max_mem: 27646M
[01/29 12:47:44] d2.utils.events INFO:  eta: 1 day, 10:30:40  iter: 17879  total_loss: 24.1  loss_mask: 2.401  loss_mask_0: 2.424  loss_mask_1: 2.383  loss_mask_2: 2.401  loss_mask_3: 2.427  loss_mask_4: 2.41  loss_mask_5: 2.373  loss_mask_6: 2.439  loss_mask_7: 2.42  loss_mask_8: 2.4  time: 3.0133  data_time: 0.0520  lr: 7.273e-05  max_mem: 27646M
[01/29 12:48:43] d2.utils.events INFO:  eta: 1 day, 10:29:24  iter: 17899  total_loss: 23.77  loss_mask: 2.426  loss_mask_0: 2.397  loss_mask_1: 2.347  loss_mask_2: 2.382  loss_mask_3: 2.375  loss_mask_4: 2.331  loss_mask_5: 2.503  loss_mask_6: 2.436  loss_mask_7: 2.396  loss_mask_8: 2.367  time: 3.0132  data_time: 0.0526  lr: 7.2699e-05  max_mem: 27646M
[01/29 12:49:43] d2.utils.events INFO:  eta: 1 day, 10:28:47  iter: 17919  total_loss: 29.91  loss_mask: 2.856  loss_mask_0: 2.936  loss_mask_1: 2.787  loss_mask_2: 2.897  loss_mask_3: 2.927  loss_mask_4: 2.944  loss_mask_5: 3.355  loss_mask_6: 3.004  loss_mask_7: 2.971  loss_mask_8: 2.87  time: 3.0132  data_time: 0.0534  lr: 7.2668e-05  max_mem: 27646M
[01/29 12:50:42] d2.utils.events INFO:  eta: 1 day, 10:28:23  iter: 17939  total_loss: 27.59  loss_mask: 2.664  loss_mask_0: 2.696  loss_mask_1: 2.634  loss_mask_2: 2.67  loss_mask_3: 2.71  loss_mask_4: 2.764  loss_mask_5: 3.116  loss_mask_6: 2.746  loss_mask_7: 2.862  loss_mask_8: 2.669  time: 3.0131  data_time: 0.0582  lr: 7.2637e-05  max_mem: 27646M
[01/29 12:51:41] d2.utils.events INFO:  eta: 1 day, 10:27:26  iter: 17959  total_loss: 27.34  loss_mask: 2.683  loss_mask_0: 2.745  loss_mask_1: 2.652  loss_mask_2: 2.687  loss_mask_3: 2.704  loss_mask_4: 2.755  loss_mask_5: 2.838  loss_mask_6: 2.737  loss_mask_7: 2.751  loss_mask_8: 2.676  time: 3.0131  data_time: 0.0490  lr: 7.2606e-05  max_mem: 27646M
[01/29 12:52:40] d2.utils.events INFO:  eta: 1 day, 10:25:55  iter: 17979  total_loss: 26.44  loss_mask: 2.628  loss_mask_0: 2.697  loss_mask_1: 2.629  loss_mask_2: 2.616  loss_mask_3: 2.644  loss_mask_4: 2.658  loss_mask_5: 2.821  loss_mask_6: 2.643  loss_mask_7: 2.655  loss_mask_8: 2.611  time: 3.0130  data_time: 0.0442  lr: 7.2574e-05  max_mem: 27646M
[01/29 12:53:39] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 12:53:39] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 12:53:39] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 13:07:07] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.962857035737986, 'error_1pix': 0.48983592681141164, 'error_3pix': 0.19305884309802326, 'mIoU': 5.008287551238901, 'fwIoU': 9.328250209783489, 'IoU-0': 0.0001617008614068584, 'IoU-1': 18.571382007152895, 'IoU-2': 2.1318595974675723, 'IoU-3': 2.4239671437774537, 'IoU-4': 2.296827568181076, 'IoU-5': 2.6146573775338378, 'IoU-6': 2.9565394851100995, 'IoU-7': 2.6407027913451784, 'IoU-8': 6.061047825902421, 'IoU-9': 14.692967257456488, 'IoU-10': 15.335050064029279, 'IoU-11': 17.47751886882598, 'IoU-12': 14.431586163126465, 'IoU-13': 13.33840511354894, 'IoU-14': 12.556167726460366, 'IoU-15': 12.221987654106917, 'IoU-16': 12.887819125405816, 'IoU-17': 12.274852346418271, 'IoU-18': 12.312842902543274, 'IoU-19': 11.708553254091349, 'IoU-20': 11.860326855438235, 'IoU-21': 11.952237928555444, 'IoU-22': 13.224356790576033, 'IoU-23': 12.112215708506767, 'IoU-24': 11.56166060335587, 'IoU-25': 10.422751772499373, 'IoU-26': 10.074486814636817, 'IoU-27': 9.953329546411787, 'IoU-28': 9.438932871733021, 'IoU-29': 9.56931789205098, 'IoU-30': 9.307226288713501, 'IoU-31': 9.121943990744155, 'IoU-32': 8.607531765962593, 'IoU-33': 8.270052153434662, 'IoU-34': 8.168552648013323, 'IoU-35': 8.083473770402767, 'IoU-36': 7.720290264436747, 'IoU-37': 7.4095973128320916, 'IoU-38': 7.0887540459293445, 'IoU-39': 6.607720645075851, 'IoU-40': 6.626673132306991, 'IoU-41': 6.649687986681857, 'IoU-42': 6.42219273588196, 'IoU-43': 6.409795997926383, 'IoU-44': 6.515143994893209, 'IoU-45': 6.466309379275055, 'IoU-46': 6.302956407098495, 'IoU-47': 6.057812572497366, 'IoU-48': 5.916034112269441, 'IoU-49': 5.903766898216175, 'IoU-50': 5.9860984387184155, 'IoU-51': 5.766565913473285, 'IoU-52': 5.751930388510306, 'IoU-53': 5.877248614242457, 'IoU-54': 6.291046547223092, 'IoU-55': 6.273856051394966, 'IoU-56': 6.214277721861971, 'IoU-57': 6.409609744452038, 'IoU-58': 6.28712164695841, 'IoU-59': 6.199724481156003, 'IoU-60': 5.906600226903466, 'IoU-61': 5.912179395033692, 'IoU-62': 5.889154225666875, 'IoU-63': 5.638986447846869, 'IoU-64': 5.431296462903401, 'IoU-65': 5.439979385475921, 'IoU-66': 5.194948034138722, 'IoU-67': 5.01643554933397, 'IoU-68': 5.086954129109016, 'IoU-69': 4.911654434953302, 'IoU-70': 4.993343195649587, 'IoU-71': 4.9797778425503845, 'IoU-72': 4.95526235477047, 'IoU-73': 5.144187366726282, 'IoU-74': 5.1223453296112, 'IoU-75': 4.985673656464035, 'IoU-76': 5.200509009736667, 'IoU-77': 5.159942839975701, 'IoU-78': 5.1312315739941345, 'IoU-79': 5.0715270147451, 'IoU-80': 5.222592815484916, 'IoU-81': 5.151987993214499, 'IoU-82': 5.276806484723736, 'IoU-83': 5.371431070050425, 'IoU-84': 5.415151840545695, 'IoU-85': 5.453589812499383, 'IoU-86': 5.38228908447995, 'IoU-87': 5.490706968186925, 'IoU-88': 5.471750844898682, 'IoU-89': 5.55398324855624, 'IoU-90': 5.510408835071505, 'IoU-91': 5.464982124178415, 'IoU-92': 5.417477378188938, 'IoU-93': 5.652636765539743, 'IoU-94': 5.762522459465398, 'IoU-95': 5.75744670669305, 'IoU-96': 5.96072123039231, 'IoU-97': 6.011737398816259, 'IoU-98': 5.884594345943558, 'IoU-99': 5.632061726398724, 'IoU-100': 5.372078409647852, 'IoU-101': 5.440627105576544, 'IoU-102': 5.444362679909846, 'IoU-103': 5.255238381849038, 'IoU-104': 5.186935662724501, 'IoU-105': 5.138606208814561, 'IoU-106': 5.12086678007264, 'IoU-107': 5.22380544157059, 'IoU-108': 4.953839340490278, 'IoU-109': 4.861976273372373, 'IoU-110': 4.693218483804802, 'IoU-111': 4.82864475620213, 'IoU-112': 4.68755578914287, 'IoU-113': 4.7456422160405225, 'IoU-114': 4.673881403526839, 'IoU-115': 4.81824955509166, 'IoU-116': 4.623805599901489, 'IoU-117': 4.357017144444784, 'IoU-118': 4.257779591198193, 'IoU-119': 4.312604112660359, 'IoU-120': 4.199925208861628, 'IoU-121': 4.191599080327368, 'IoU-122': 4.046820758432246, 'IoU-123': 3.904473235669155, 'IoU-124': 3.8323802582145787, 'IoU-125': 3.3765469861530466, 'IoU-126': 3.1170893552676877, 'IoU-127': 3.033083716106429, 'IoU-128': 3.011081697940521, 'IoU-129': 2.953637483178517, 'IoU-130': 2.736870164344567, 'IoU-131': 2.7086303879799587, 'IoU-132': 2.921144872180663, 'IoU-133': 2.8562318020687902, 'IoU-134': 2.8045341592954265, 'IoU-135': 2.7977913412909183, 'IoU-136': 2.6552150766507365, 'IoU-137': 2.7045402363598248, 'IoU-138': 2.824041561163764, 'IoU-139': 2.832775955451016, 'IoU-140': 2.6243290884263133, 'IoU-141': 2.8554628071147006, 'IoU-142': 2.7175986084578287, 'IoU-143': 2.561476194564804, 'IoU-144': 2.668337494559959, 'IoU-145': 2.6362944851271117, 'IoU-146': 2.627082144912585, 'IoU-147': 2.6037746139658378, 'IoU-148': 2.4093001516808354, 'IoU-149': 2.21094806179843, 'IoU-150': 2.2833920168482016, 'IoU-151': 2.210738187781467, 'IoU-152': 2.400136520817249, 'IoU-153': 2.366977979607574, 'IoU-154': 2.073094897019991, 'IoU-155': 2.0408983452739298, 'IoU-156': 2.0212004286465244, 'IoU-157': 2.1439340788902217, 'IoU-158': 2.112754233582044, 'IoU-159': 1.9714170550418024, 'IoU-160': 2.109237894097972, 'IoU-161': 2.2667794831342754, 'IoU-162': 2.3412008213629374, 'IoU-163': 1.9018532070507317, 'IoU-164': 1.7823464510867784, 'IoU-165': 1.9136548491002394, 'IoU-166': 2.1951420049035533, 'IoU-167': 2.1347733466526377, 'IoU-168': 1.99109497961764, 'IoU-169': 1.834317909666552, 'IoU-170': 1.5007507250248435, 'IoU-171': 1.5981494899501514, 'IoU-172': 1.5352237251042675, 'IoU-173': 1.4181104601729695, 'IoU-174': 1.6156009504110849, 'IoU-175': 1.626579522921542, 'IoU-176': 2.100500660419702, 'IoU-177': 1.6304438725459898, 'IoU-178': 1.3298563556562697, 'IoU-179': 1.02995948771563, 'IoU-180': 0.8492248146295853, 'IoU-181': 1.0039161206340177, 'IoU-182': 0.012108573542766808, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 9.73175088949144, 'pACC': 15.661581754809731, 'ACC-0': 0.0012600963768235629, 'ACC-1': 18.73561572269533, 'ACC-2': 3.9375066562533285, 'ACC-3': 9.96415952822755, 'ACC-4': 8.672762649566804, 'ACC-5': 10.272661419758444, 'ACC-6': 12.342606629104386, 'ACC-7': 13.058475629988585, 'ACC-8': 18.23573370998493, 'ACC-9': 33.231683775050236, 'ACC-10': 36.318621100680645, 'ACC-11': 33.516563447711945, 'ACC-12': 25.508110272118095, 'ACC-13': 22.652134878347653, 'ACC-14': 21.003843677735677, 'ACC-15': 20.67757710187397, 'ACC-16': 21.92121122033525, 'ACC-17': 22.543110271441844, 'ACC-18': 21.99964451745782, 'ACC-19': 21.10353891171373, 'ACC-20': 21.94803482466962, 'ACC-21': 21.873430494092283, 'ACC-22': 23.188411366300148, 'ACC-23': 22.389146087681453, 'ACC-24': 21.76821885894615, 'ACC-25': 20.003113601232513, 'ACC-26': 19.620551737035807, 'ACC-27': 18.586214353603456, 'ACC-28': 18.12036751059776, 'ACC-29': 17.812266101076972, 'ACC-30': 17.747479509218024, 'ACC-31': 16.845539281656265, 'ACC-32': 15.932486745550131, 'ACC-33': 15.719202052413348, 'ACC-34': 15.880140358297695, 'ACC-35': 15.341761758402084, 'ACC-36': 14.584034384403905, 'ACC-37': 14.170885827075566, 'ACC-38': 13.276842116455088, 'ACC-39': 12.219469387152268, 'ACC-40': 12.13409226022884, 'ACC-41': 12.55963676121041, 'ACC-42': 12.183976578554143, 'ACC-43': 12.04886994469421, 'ACC-44': 11.934348941647647, 'ACC-45': 11.928560917042937, 'ACC-46': 11.910860265719618, 'ACC-47': 11.351905707244866, 'ACC-48': 11.0981767970173, 'ACC-49': 11.019052180501166, 'ACC-50': 10.97654233415883, 'ACC-51': 10.651821184927586, 'ACC-52': 10.634627806683989, 'ACC-53': 10.775231321063869, 'ACC-54': 11.270213006232623, 'ACC-55': 11.257529768466759, 'ACC-56': 11.270087352096427, 'ACC-57': 11.564270915306281, 'ACC-58': 11.53002119266876, 'ACC-59': 11.487574213498112, 'ACC-60': 10.977396436513658, 'ACC-61': 11.140249716868242, 'ACC-62': 11.174907449792256, 'ACC-63': 10.796775923868212, 'ACC-64': 10.434781533740283, 'ACC-65': 10.433006394521554, 'ACC-66': 9.983234063672947, 'ACC-67': 9.664543755341752, 'ACC-68': 9.682349434715086, 'ACC-69': 9.11272583451885, 'ACC-70': 9.18351612833535, 'ACC-71': 9.30191018613413, 'ACC-72': 9.297721852345813, 'ACC-73': 9.65203713124329, 'ACC-74': 9.553045563826053, 'ACC-75': 9.338643434428368, 'ACC-76': 9.543195065236667, 'ACC-77': 9.59767388396361, 'ACC-78': 9.653270029347086, 'ACC-79': 9.48873223419613, 'ACC-80': 9.610691134617705, 'ACC-81': 9.3687653528964, 'ACC-82': 9.536837287401026, 'ACC-83': 9.570344345330742, 'ACC-84': 9.608923112623287, 'ACC-85': 9.658906536349804, 'ACC-86': 9.53932409060428, 'ACC-87': 9.746752681099629, 'ACC-88': 9.680415099907673, 'ACC-89': 9.768628276533907, 'ACC-90': 9.59736056659184, 'ACC-91': 9.526682036065198, 'ACC-92': 9.500683906018416, 'ACC-93': 10.04250055724066, 'ACC-94': 10.344990645929581, 'ACC-95': 10.339441368216603, 'ACC-96': 10.851943647729867, 'ACC-97': 10.90942741175953, 'ACC-98': 10.708894914228575, 'ACC-99': 10.397236361728995, 'ACC-100': 9.924141241879516, 'ACC-101': 10.081765596977842, 'ACC-102': 10.142251925690983, 'ACC-103': 9.772952677812413, 'ACC-104': 9.591918546026905, 'ACC-105': 9.445669332362163, 'ACC-106': 9.400774136975725, 'ACC-107': 9.663296476639296, 'ACC-108': 9.107106485774066, 'ACC-109': 9.017935230189813, 'ACC-110': 8.910808212409545, 'ACC-111': 9.169912635413228, 'ACC-112': 9.067531775949774, 'ACC-113': 9.166749025992603, 'ACC-114': 9.064040521910192, 'ACC-115': 9.411092568370092, 'ACC-116': 9.19420334511886, 'ACC-117': 8.532041818589487, 'ACC-118': 8.456155421953339, 'ACC-119': 8.576617055616103, 'ACC-120': 8.381562810768264, 'ACC-121': 8.250807243915522, 'ACC-122': 8.013246907639617, 'ACC-123': 7.789997019750566, 'ACC-124': 7.618982675945514, 'ACC-125': 6.705947487553883, 'ACC-126': 6.308288326851792, 'ACC-127': 6.197025483837808, 'ACC-128': 6.261746988319179, 'ACC-129': 6.16626055263721, 'ACC-130': 5.734335458140609, 'ACC-131': 5.669719075996552, 'ACC-132': 6.102683194096771, 'ACC-133': 5.99120891084393, 'ACC-134': 5.852994398965962, 'ACC-135': 5.927113619519981, 'ACC-136': 5.621112677040626, 'ACC-137': 5.789804284328474, 'ACC-138': 6.258170038327791, 'ACC-139': 6.306276762590459, 'ACC-140': 5.8226365649748955, 'ACC-141': 6.179025446907206, 'ACC-142': 5.998021066126609, 'ACC-143': 5.710008419800279, 'ACC-144': 5.826895306859206, 'ACC-145': 5.725798877434647, 'ACC-146': 5.66895889972813, 'ACC-147': 5.585324930848491, 'ACC-148': 5.193759618117372, 'ACC-149': 4.836274134974328, 'ACC-150': 5.062804288890348, 'ACC-151': 4.8907419190159045, 'ACC-152': 5.2313035268730195, 'ACC-153': 5.441080818629876, 'ACC-154': 4.924342495364972, 'ACC-155': 4.9447447758361, 'ACC-156': 5.025370539148196, 'ACC-157': 5.415164420272398, 'ACC-158': 5.318318653138589, 'ACC-159': 4.832897158103361, 'ACC-160': 5.345852372981043, 'ACC-161': 5.665347663567149, 'ACC-162': 5.943302757206911, 'ACC-163': 4.811003917959787, 'ACC-164': 4.477119727041245, 'ACC-165': 4.657319734330283, 'ACC-166': 5.468266026475057, 'ACC-167': 5.434739180811129, 'ACC-168': 5.138898656726915, 'ACC-169': 4.593669337928348, 'ACC-170': 3.8083677612618367, 'ACC-171': 4.379611652268791, 'ACC-172': 4.066562951439049, 'ACC-173': 3.5459618517947114, 'ACC-174': 4.306769484846621, 'ACC-175': 4.123657971561108, 'ACC-176': 5.933654515904341, 'ACC-177': 4.137715942414126, 'ACC-178': 3.5185653772085197, 'ACC-179': 2.5584268819451346, 'ACC-180': 1.6532476548477768, 'ACC-181': 1.7390645244575194, 'ACC-182': 0.01279351037340466, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 13:07:07] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 13:07:07] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 13:07:07] d2.evaluation.testing INFO: copypaste: 2.9629,0.4898,0.1931,5.0083,9.3283,9.7318,15.6616
[01/29 13:07:07] d2.utils.events INFO:  eta: 1 day, 10:24:44  iter: 17999  total_loss: 25.25  loss_mask: 2.504  loss_mask_0: 2.544  loss_mask_1: 2.504  loss_mask_2: 2.523  loss_mask_3: 2.53  loss_mask_4: 2.538  loss_mask_5: 2.554  loss_mask_6: 2.525  loss_mask_7: 2.529  loss_mask_8: 2.497  time: 3.0129  data_time: 0.0464  lr: 7.2543e-05  max_mem: 27646M
[01/29 13:08:07] d2.utils.events INFO:  eta: 1 day, 10:23:36  iter: 18019  total_loss: 27.78  loss_mask: 2.764  loss_mask_0: 2.825  loss_mask_1: 2.747  loss_mask_2: 2.781  loss_mask_3: 2.782  loss_mask_4: 2.776  loss_mask_5: 2.806  loss_mask_6: 2.79  loss_mask_7: 2.776  loss_mask_8: 2.782  time: 3.0128  data_time: 0.0486  lr: 7.2512e-05  max_mem: 27646M
[01/29 13:09:05] d2.utils.events INFO:  eta: 1 day, 10:22:42  iter: 18039  total_loss: 26.46  loss_mask: 2.638  loss_mask_0: 2.678  loss_mask_1: 2.642  loss_mask_2: 2.644  loss_mask_3: 2.645  loss_mask_4: 2.645  loss_mask_5: 2.624  loss_mask_6: 2.658  loss_mask_7: 2.652  loss_mask_8: 2.637  time: 3.0127  data_time: 0.0521  lr: 7.2481e-05  max_mem: 27646M
[01/29 13:10:04] d2.utils.events INFO:  eta: 1 day, 10:20:49  iter: 18059  total_loss: 27.39  loss_mask: 2.721  loss_mask_0: 2.737  loss_mask_1: 2.694  loss_mask_2: 2.762  loss_mask_3: 2.714  loss_mask_4: 2.723  loss_mask_5: 2.767  loss_mask_6: 2.751  loss_mask_7: 2.743  loss_mask_8: 2.732  time: 3.0126  data_time: 0.0467  lr: 7.245e-05  max_mem: 27646M
[01/29 13:11:02] d2.utils.events INFO:  eta: 1 day, 10:19:37  iter: 18079  total_loss: 23.65  loss_mask: 2.368  loss_mask_0: 2.42  loss_mask_1: 2.334  loss_mask_2: 2.375  loss_mask_3: 2.38  loss_mask_4: 2.364  loss_mask_5: 2.415  loss_mask_6: 2.366  loss_mask_7: 2.394  loss_mask_8: 2.367  time: 3.0125  data_time: 0.0480  lr: 7.2419e-05  max_mem: 27646M
[01/29 13:12:01] d2.utils.events INFO:  eta: 1 day, 10:18:08  iter: 18099  total_loss: 26.59  loss_mask: 2.642  loss_mask_0: 2.735  loss_mask_1: 2.635  loss_mask_2: 2.652  loss_mask_3: 2.673  loss_mask_4: 2.665  loss_mask_5: 2.692  loss_mask_6: 2.671  loss_mask_7: 2.632  loss_mask_8: 2.645  time: 3.0124  data_time: 0.0449  lr: 7.2388e-05  max_mem: 27646M
[01/29 13:12:59] d2.utils.events INFO:  eta: 1 day, 10:16:45  iter: 18119  total_loss: 28.03  loss_mask: 2.8  loss_mask_0: 2.847  loss_mask_1: 2.782  loss_mask_2: 2.787  loss_mask_3: 2.781  loss_mask_4: 2.812  loss_mask_5: 2.813  loss_mask_6: 2.778  loss_mask_7: 2.782  loss_mask_8: 2.793  time: 3.0123  data_time: 0.0450  lr: 7.2357e-05  max_mem: 27646M
[01/29 13:13:58] d2.utils.events INFO:  eta: 1 day, 10:15:29  iter: 18139  total_loss: 24.33  loss_mask: 2.463  loss_mask_0: 2.456  loss_mask_1: 2.411  loss_mask_2: 2.42  loss_mask_3: 2.455  loss_mask_4: 2.41  loss_mask_5: 2.482  loss_mask_6: 2.427  loss_mask_7: 2.424  loss_mask_8: 2.432  time: 3.0122  data_time: 0.0479  lr: 7.2326e-05  max_mem: 27646M
[01/29 13:14:57] d2.utils.events INFO:  eta: 1 day, 10:14:13  iter: 18159  total_loss: 25.54  loss_mask: 2.537  loss_mask_0: 2.598  loss_mask_1: 2.543  loss_mask_2: 2.552  loss_mask_3: 2.558  loss_mask_4: 2.573  loss_mask_5: 2.555  loss_mask_6: 2.548  loss_mask_7: 2.585  loss_mask_8: 2.545  time: 3.0121  data_time: 0.0472  lr: 7.2295e-05  max_mem: 27646M
[01/29 13:15:55] d2.utils.events INFO:  eta: 1 day, 10:13:09  iter: 18179  total_loss: 26.28  loss_mask: 2.63  loss_mask_0: 2.645  loss_mask_1: 2.632  loss_mask_2: 2.622  loss_mask_3: 2.619  loss_mask_4: 2.634  loss_mask_5: 2.636  loss_mask_6: 2.636  loss_mask_7: 2.617  loss_mask_8: 2.616  time: 3.0121  data_time: 0.0460  lr: 7.2263e-05  max_mem: 27646M
[01/29 13:16:54] d2.utils.events INFO:  eta: 1 day, 10:11:43  iter: 18199  total_loss: 26.95  loss_mask: 2.709  loss_mask_0: 2.751  loss_mask_1: 2.65  loss_mask_2: 2.694  loss_mask_3: 2.71  loss_mask_4: 2.668  loss_mask_5: 2.683  loss_mask_6: 2.695  loss_mask_7: 2.675  loss_mask_8: 2.712  time: 3.0120  data_time: 0.0471  lr: 7.2232e-05  max_mem: 27646M
[01/29 13:17:52] d2.utils.events INFO:  eta: 1 day, 10:10:30  iter: 18219  total_loss: 25.21  loss_mask: 2.512  loss_mask_0: 2.577  loss_mask_1: 2.475  loss_mask_2: 2.514  loss_mask_3: 2.536  loss_mask_4: 2.503  loss_mask_5: 2.566  loss_mask_6: 2.536  loss_mask_7: 2.514  loss_mask_8: 2.506  time: 3.0119  data_time: 0.0493  lr: 7.2201e-05  max_mem: 27646M
[01/29 13:18:51] d2.utils.events INFO:  eta: 1 day, 10:09:07  iter: 18239  total_loss: 26.37  loss_mask: 2.608  loss_mask_0: 2.715  loss_mask_1: 2.616  loss_mask_2: 2.646  loss_mask_3: 2.625  loss_mask_4: 2.622  loss_mask_5: 2.611  loss_mask_6: 2.611  loss_mask_7: 2.629  loss_mask_8: 2.627  time: 3.0118  data_time: 0.0514  lr: 7.217e-05  max_mem: 27646M
[01/29 13:19:50] d2.utils.events INFO:  eta: 1 day, 10:07:49  iter: 18259  total_loss: 27.83  loss_mask: 2.803  loss_mask_0: 2.842  loss_mask_1: 2.796  loss_mask_2: 2.788  loss_mask_3: 2.774  loss_mask_4: 2.766  loss_mask_5: 2.784  loss_mask_6: 2.776  loss_mask_7: 2.786  loss_mask_8: 2.776  time: 3.0117  data_time: 0.0505  lr: 7.2139e-05  max_mem: 27646M
[01/29 13:20:49] d2.utils.events INFO:  eta: 1 day, 10:06:46  iter: 18279  total_loss: 25.27  loss_mask: 2.513  loss_mask_0: 2.534  loss_mask_1: 2.508  loss_mask_2: 2.536  loss_mask_3: 2.53  loss_mask_4: 2.534  loss_mask_5: 2.538  loss_mask_6: 2.533  loss_mask_7: 2.521  loss_mask_8: 2.549  time: 3.0116  data_time: 0.0496  lr: 7.2108e-05  max_mem: 27646M
[01/29 13:21:47] d2.utils.events INFO:  eta: 1 day, 10:05:03  iter: 18299  total_loss: 26.15  loss_mask: 2.609  loss_mask_0: 2.679  loss_mask_1: 2.6  loss_mask_2: 2.612  loss_mask_3: 2.612  loss_mask_4: 2.619  loss_mask_5: 2.619  loss_mask_6: 2.593  loss_mask_7: 2.602  loss_mask_8: 2.626  time: 3.0115  data_time: 0.0449  lr: 7.2077e-05  max_mem: 27646M
[01/29 13:22:46] d2.utils.events INFO:  eta: 1 day, 10:04:04  iter: 18319  total_loss: 28.19  loss_mask: 2.81  loss_mask_0: 2.918  loss_mask_1: 2.793  loss_mask_2: 2.852  loss_mask_3: 2.799  loss_mask_4: 2.811  loss_mask_5: 2.822  loss_mask_6: 2.817  loss_mask_7: 2.815  loss_mask_8: 2.793  time: 3.0114  data_time: 0.0473  lr: 7.2046e-05  max_mem: 27646M
[01/29 13:23:45] d2.utils.events INFO:  eta: 1 day, 10:03:03  iter: 18339  total_loss: 26.46  loss_mask: 2.645  loss_mask_0: 2.627  loss_mask_1: 2.614  loss_mask_2: 2.647  loss_mask_3: 2.664  loss_mask_4: 2.653  loss_mask_5: 2.663  loss_mask_6: 2.648  loss_mask_7: 2.656  loss_mask_8: 2.641  time: 3.0113  data_time: 0.0453  lr: 7.2015e-05  max_mem: 27646M
[01/29 13:24:43] d2.utils.events INFO:  eta: 1 day, 10:00:57  iter: 18359  total_loss: 24.42  loss_mask: 2.444  loss_mask_0: 2.568  loss_mask_1: 2.431  loss_mask_2: 2.432  loss_mask_3: 2.449  loss_mask_4: 2.445  loss_mask_5: 2.439  loss_mask_6: 2.429  loss_mask_7: 2.43  loss_mask_8: 2.44  time: 3.0112  data_time: 0.0443  lr: 7.1983e-05  max_mem: 27646M
[01/29 13:25:41] d2.utils.events INFO:  eta: 1 day, 9:59:55  iter: 18379  total_loss: 26.64  loss_mask: 2.631  loss_mask_0: 2.638  loss_mask_1: 2.603  loss_mask_2: 2.636  loss_mask_3: 2.638  loss_mask_4: 2.653  loss_mask_5: 2.705  loss_mask_6: 2.667  loss_mask_7: 2.659  loss_mask_8: 2.644  time: 3.0112  data_time: 0.0454  lr: 7.1952e-05  max_mem: 27646M
[01/29 13:26:40] d2.utils.events INFO:  eta: 1 day, 9:58:52  iter: 18399  total_loss: 24.11  loss_mask: 2.406  loss_mask_0: 2.445  loss_mask_1: 2.404  loss_mask_2: 2.404  loss_mask_3: 2.401  loss_mask_4: 2.419  loss_mask_5: 2.408  loss_mask_6: 2.405  loss_mask_7: 2.414  loss_mask_8: 2.401  time: 3.0111  data_time: 0.0475  lr: 7.1921e-05  max_mem: 27646M
[01/29 13:27:39] d2.utils.events INFO:  eta: 1 day, 9:57:31  iter: 18419  total_loss: 30.52  loss_mask: 3.033  loss_mask_0: 3.045  loss_mask_1: 3.021  loss_mask_2: 3.047  loss_mask_3: 3.073  loss_mask_4: 3.053  loss_mask_5: 3.051  loss_mask_6: 3.032  loss_mask_7: 3.066  loss_mask_8: 3.06  time: 3.0110  data_time: 0.0465  lr: 7.189e-05  max_mem: 27646M
[01/29 13:28:38] d2.utils.events INFO:  eta: 1 day, 9:56:26  iter: 18439  total_loss: 28.85  loss_mask: 2.898  loss_mask_0: 2.885  loss_mask_1: 2.884  loss_mask_2: 2.881  loss_mask_3: 2.888  loss_mask_4: 2.893  loss_mask_5: 2.888  loss_mask_6: 2.884  loss_mask_7: 2.89  loss_mask_8: 2.857  time: 3.0109  data_time: 0.0508  lr: 7.1859e-05  max_mem: 27646M
[01/29 13:29:36] d2.utils.events INFO:  eta: 1 day, 9:54:55  iter: 18459  total_loss: 27.7  loss_mask: 2.754  loss_mask_0: 2.815  loss_mask_1: 2.728  loss_mask_2: 2.75  loss_mask_3: 2.766  loss_mask_4: 2.772  loss_mask_5: 2.771  loss_mask_6: 2.74  loss_mask_7: 2.771  loss_mask_8: 2.763  time: 3.0108  data_time: 0.0481  lr: 7.1828e-05  max_mem: 27646M
[01/29 13:30:34] d2.utils.events INFO:  eta: 1 day, 9:53:32  iter: 18479  total_loss: 27.32  loss_mask: 2.747  loss_mask_0: 2.773  loss_mask_1: 2.697  loss_mask_2: 2.714  loss_mask_3: 2.727  loss_mask_4: 2.719  loss_mask_5: 2.754  loss_mask_6: 2.742  loss_mask_7: 2.715  loss_mask_8: 2.729  time: 3.0107  data_time: 0.0443  lr: 7.1797e-05  max_mem: 27646M
[01/29 13:31:33] d2.utils.events INFO:  eta: 1 day, 9:51:51  iter: 18499  total_loss: 27.82  loss_mask: 2.763  loss_mask_0: 2.969  loss_mask_1: 2.769  loss_mask_2: 2.76  loss_mask_3: 2.76  loss_mask_4: 2.783  loss_mask_5: 2.789  loss_mask_6: 2.748  loss_mask_7: 2.777  loss_mask_8: 2.789  time: 3.0106  data_time: 0.0467  lr: 7.1766e-05  max_mem: 27646M
[01/29 13:32:31] d2.utils.events INFO:  eta: 1 day, 9:50:15  iter: 18519  total_loss: 26.03  loss_mask: 2.575  loss_mask_0: 2.782  loss_mask_1: 2.625  loss_mask_2: 2.592  loss_mask_3: 2.578  loss_mask_4: 2.592  loss_mask_5: 2.579  loss_mask_6: 2.594  loss_mask_7: 2.587  loss_mask_8: 2.592  time: 3.0105  data_time: 0.0463  lr: 7.1735e-05  max_mem: 27646M
[01/29 13:33:30] d2.utils.events INFO:  eta: 1 day, 9:48:39  iter: 18539  total_loss: 28.91  loss_mask: 2.875  loss_mask_0: 2.948  loss_mask_1: 2.968  loss_mask_2: 2.837  loss_mask_3: 2.853  loss_mask_4: 2.907  loss_mask_5: 2.901  loss_mask_6: 2.876  loss_mask_7: 2.904  loss_mask_8: 2.862  time: 3.0104  data_time: 0.0452  lr: 7.1703e-05  max_mem: 27646M
[01/29 13:34:28] d2.utils.events INFO:  eta: 1 day, 9:47:01  iter: 18559  total_loss: 28.74  loss_mask: 2.881  loss_mask_0: 3.034  loss_mask_1: 2.897  loss_mask_2: 2.829  loss_mask_3: 2.852  loss_mask_4: 2.87  loss_mask_5: 2.862  loss_mask_6: 2.871  loss_mask_7: 2.882  loss_mask_8: 2.832  time: 3.0103  data_time: 0.0465  lr: 7.1672e-05  max_mem: 27646M
[01/29 13:35:26] d2.utils.events INFO:  eta: 1 day, 9:45:22  iter: 18579  total_loss: 25.61  loss_mask: 2.554  loss_mask_0: 2.62  loss_mask_1: 2.539  loss_mask_2: 2.55  loss_mask_3: 2.549  loss_mask_4: 2.559  loss_mask_5: 2.541  loss_mask_6: 2.551  loss_mask_7: 2.564  loss_mask_8: 2.561  time: 3.0102  data_time: 0.0463  lr: 7.1641e-05  max_mem: 27646M
[01/29 13:36:25] d2.utils.events INFO:  eta: 1 day, 9:43:53  iter: 18599  total_loss: 27.43  loss_mask: 2.742  loss_mask_0: 2.851  loss_mask_1: 2.736  loss_mask_2: 2.759  loss_mask_3: 2.769  loss_mask_4: 2.742  loss_mask_5: 2.741  loss_mask_6: 2.729  loss_mask_7: 2.753  loss_mask_8: 2.748  time: 3.0101  data_time: 0.0495  lr: 7.161e-05  max_mem: 27646M
[01/29 13:37:24] d2.utils.events INFO:  eta: 1 day, 9:42:52  iter: 18619  total_loss: 28.26  loss_mask: 2.843  loss_mask_0: 2.825  loss_mask_1: 2.823  loss_mask_2: 2.84  loss_mask_3: 2.814  loss_mask_4: 2.811  loss_mask_5: 2.822  loss_mask_6: 2.833  loss_mask_7: 2.815  loss_mask_8: 2.82  time: 3.0100  data_time: 0.0462  lr: 7.1579e-05  max_mem: 27646M
[01/29 13:38:22] d2.utils.events INFO:  eta: 1 day, 9:41:35  iter: 18639  total_loss: 27.62  loss_mask: 2.774  loss_mask_0: 2.784  loss_mask_1: 2.733  loss_mask_2: 2.772  loss_mask_3: 2.756  loss_mask_4: 2.914  loss_mask_5: 2.774  loss_mask_6: 2.769  loss_mask_7: 2.742  loss_mask_8: 2.757  time: 3.0099  data_time: 0.0474  lr: 7.1548e-05  max_mem: 27646M
[01/29 13:39:21] d2.utils.events INFO:  eta: 1 day, 9:40:30  iter: 18659  total_loss: 27.59  loss_mask: 2.696  loss_mask_0: 2.746  loss_mask_1: 2.661  loss_mask_2: 2.686  loss_mask_3: 2.74  loss_mask_4: 3.231  loss_mask_5: 2.684  loss_mask_6: 2.694  loss_mask_7: 2.69  loss_mask_8: 2.686  time: 3.0098  data_time: 0.0482  lr: 7.1517e-05  max_mem: 27646M
[01/29 13:40:20] d2.utils.events INFO:  eta: 1 day, 9:39:44  iter: 18679  total_loss: 25.4  loss_mask: 2.484  loss_mask_0: 2.597  loss_mask_1: 2.483  loss_mask_2: 2.501  loss_mask_3: 2.568  loss_mask_4: 2.793  loss_mask_5: 2.57  loss_mask_6: 2.49  loss_mask_7: 2.485  loss_mask_8: 2.504  time: 3.0098  data_time: 0.0521  lr: 7.1485e-05  max_mem: 27646M
[01/29 13:41:19] d2.utils.events INFO:  eta: 1 day, 9:38:13  iter: 18699  total_loss: 33.37  loss_mask: 3.151  loss_mask_0: 3.275  loss_mask_1: 3.106  loss_mask_2: 3.11  loss_mask_3: 3.274  loss_mask_4: 3.568  loss_mask_5: 3.475  loss_mask_6: 3.133  loss_mask_7: 3.074  loss_mask_8: 3.126  time: 3.0097  data_time: 0.0442  lr: 7.1454e-05  max_mem: 27646M
[01/29 13:42:18] d2.utils.events INFO:  eta: 1 day, 9:37:27  iter: 18719  total_loss: 29.54  loss_mask: 2.849  loss_mask_0: 2.88  loss_mask_1: 2.798  loss_mask_2: 2.816  loss_mask_3: 2.957  loss_mask_4: 3.37  loss_mask_5: 2.976  loss_mask_6: 2.863  loss_mask_7: 2.808  loss_mask_8: 2.88  time: 3.0097  data_time: 0.0497  lr: 7.1423e-05  max_mem: 27646M
[01/29 13:43:17] d2.utils.events INFO:  eta: 1 day, 9:36:14  iter: 18739  total_loss: 27.44  loss_mask: 2.705  loss_mask_0: 2.746  loss_mask_1: 2.693  loss_mask_2: 2.739  loss_mask_3: 2.745  loss_mask_4: 2.922  loss_mask_5: 2.781  loss_mask_6: 2.709  loss_mask_7: 2.719  loss_mask_8: 2.719  time: 3.0096  data_time: 0.0504  lr: 7.1392e-05  max_mem: 27646M
[01/29 13:44:15] d2.utils.events INFO:  eta: 1 day, 9:34:53  iter: 18759  total_loss: 28.29  loss_mask: 2.773  loss_mask_0: 2.865  loss_mask_1: 2.744  loss_mask_2: 2.783  loss_mask_3: 2.791  loss_mask_4: 2.895  loss_mask_5: 2.863  loss_mask_6: 2.772  loss_mask_7: 2.774  loss_mask_8: 2.784  time: 3.0095  data_time: 0.0476  lr: 7.1361e-05  max_mem: 27646M
[01/29 13:45:14] d2.utils.events INFO:  eta: 1 day, 9:33:06  iter: 18779  total_loss: 25.68  loss_mask: 2.548  loss_mask_0: 2.591  loss_mask_1: 2.535  loss_mask_2: 2.558  loss_mask_3: 2.586  loss_mask_4: 2.644  loss_mask_5: 2.564  loss_mask_6: 2.548  loss_mask_7: 2.545  loss_mask_8: 2.568  time: 3.0094  data_time: 0.0485  lr: 7.133e-05  max_mem: 27646M
[01/29 13:46:13] d2.utils.events INFO:  eta: 1 day, 9:31:57  iter: 18799  total_loss: 27.34  loss_mask: 2.707  loss_mask_0: 2.728  loss_mask_1: 2.69  loss_mask_2: 2.729  loss_mask_3: 2.715  loss_mask_4: 2.853  loss_mask_5: 2.734  loss_mask_6: 2.703  loss_mask_7: 2.696  loss_mask_8: 2.724  time: 3.0093  data_time: 0.0517  lr: 7.1299e-05  max_mem: 27646M
[01/29 13:47:12] d2.utils.events INFO:  eta: 1 day, 9:30:34  iter: 18819  total_loss: 26.92  loss_mask: 2.688  loss_mask_0: 2.705  loss_mask_1: 2.685  loss_mask_2: 2.683  loss_mask_3: 2.688  loss_mask_4: 2.74  loss_mask_5: 2.698  loss_mask_6: 2.673  loss_mask_7: 2.67  loss_mask_8: 2.686  time: 3.0093  data_time: 0.0473  lr: 7.1267e-05  max_mem: 27646M
[01/29 13:48:11] d2.utils.events INFO:  eta: 1 day, 9:29:46  iter: 18839  total_loss: 27.44  loss_mask: 2.756  loss_mask_0: 2.806  loss_mask_1: 2.747  loss_mask_2: 2.737  loss_mask_3: 2.767  loss_mask_4: 2.773  loss_mask_5: 2.736  loss_mask_6: 2.728  loss_mask_7: 2.74  loss_mask_8: 2.729  time: 3.0092  data_time: 0.0520  lr: 7.1236e-05  max_mem: 27646M
[01/29 13:49:09] d2.utils.events INFO:  eta: 1 day, 9:28:33  iter: 18859  total_loss: 26.77  loss_mask: 2.666  loss_mask_0: 2.686  loss_mask_1: 2.618  loss_mask_2: 2.686  loss_mask_3: 2.672  loss_mask_4: 2.756  loss_mask_5: 2.673  loss_mask_6: 2.669  loss_mask_7: 2.661  loss_mask_8: 2.674  time: 3.0091  data_time: 0.0471  lr: 7.1205e-05  max_mem: 27646M
[01/29 13:50:08] d2.utils.events INFO:  eta: 1 day, 9:27:31  iter: 18879  total_loss: 28.27  loss_mask: 2.811  loss_mask_0: 2.853  loss_mask_1: 2.769  loss_mask_2: 2.803  loss_mask_3: 2.919  loss_mask_4: 2.935  loss_mask_5: 2.816  loss_mask_6: 2.808  loss_mask_7: 2.8  loss_mask_8: 2.827  time: 3.0091  data_time: 0.0514  lr: 7.1174e-05  max_mem: 27646M
[01/29 13:51:07] d2.utils.events INFO:  eta: 1 day, 9:26:23  iter: 18899  total_loss: 22.91  loss_mask: 2.269  loss_mask_0: 2.298  loss_mask_1: 2.271  loss_mask_2: 2.315  loss_mask_3: 2.282  loss_mask_4: 2.36  loss_mask_5: 2.267  loss_mask_6: 2.277  loss_mask_7: 2.302  loss_mask_8: 2.281  time: 3.0090  data_time: 0.0473  lr: 7.1143e-05  max_mem: 27646M
[01/29 13:52:06] d2.utils.events INFO:  eta: 1 day, 9:25:15  iter: 18919  total_loss: 25.39  loss_mask: 2.505  loss_mask_0: 2.571  loss_mask_1: 2.508  loss_mask_2: 2.549  loss_mask_3: 2.54  loss_mask_4: 2.569  loss_mask_5: 2.53  loss_mask_6: 2.509  loss_mask_7: 2.549  loss_mask_8: 2.543  time: 3.0089  data_time: 0.0513  lr: 7.1112e-05  max_mem: 27646M
[01/29 13:53:04] d2.utils.events INFO:  eta: 1 day, 9:24:09  iter: 18939  total_loss: 27.38  loss_mask: 2.786  loss_mask_0: 2.774  loss_mask_1: 2.666  loss_mask_2: 2.728  loss_mask_3: 2.775  loss_mask_4: 2.776  loss_mask_5: 2.733  loss_mask_6: 2.724  loss_mask_7: 2.765  loss_mask_8: 2.74  time: 3.0088  data_time: 0.0484  lr: 7.108e-05  max_mem: 27646M
[01/29 13:54:03] d2.utils.events INFO:  eta: 1 day, 9:22:54  iter: 18959  total_loss: 25.6  loss_mask: 2.559  loss_mask_0: 2.596  loss_mask_1: 2.512  loss_mask_2: 2.553  loss_mask_3: 2.556  loss_mask_4: 2.641  loss_mask_5: 2.556  loss_mask_6: 2.537  loss_mask_7: 2.55  loss_mask_8: 2.555  time: 3.0087  data_time: 0.0487  lr: 7.1049e-05  max_mem: 27646M
[01/29 13:55:02] d2.utils.events INFO:  eta: 1 day, 9:22:04  iter: 18979  total_loss: 24.79  loss_mask: 2.468  loss_mask_0: 2.52  loss_mask_1: 2.462  loss_mask_2: 2.478  loss_mask_3: 2.471  loss_mask_4: 2.472  loss_mask_5: 2.465  loss_mask_6: 2.478  loss_mask_7: 2.486  loss_mask_8: 2.487  time: 3.0086  data_time: 0.0484  lr: 7.1018e-05  max_mem: 27646M
[01/29 13:56:00] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 13:56:01] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 13:56:01] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 14:09:37] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.8241852038459747, 'error_1pix': 0.42864119014075164, 'error_3pix': 0.18889760189275312, 'mIoU': 6.3819294380892675, 'fwIoU': 17.87845330927749, 'IoU-0': 0.0002604390516985971, 'IoU-1': 69.07095649364973, 'IoU-2': 3.0093887521611986, 'IoU-3': 3.377826785737279, 'IoU-4': 2.7259648929861378, 'IoU-5': 2.856651389267525, 'IoU-6': 3.0715210205861614, 'IoU-7': 2.953372249533697, 'IoU-8': 5.051176581337037, 'IoU-9': 13.428930270972, 'IoU-10': 16.326182405677084, 'IoU-11': 24.716561271672607, 'IoU-12': 23.68815466220928, 'IoU-13': 21.152104837898957, 'IoU-14': 20.26820682857847, 'IoU-15': 20.25353863407593, 'IoU-16': 19.396282822832074, 'IoU-17': 16.49993689920899, 'IoU-18': 17.70340494861925, 'IoU-19': 19.062419315352493, 'IoU-20': 18.73827610088783, 'IoU-21': 18.758306914508182, 'IoU-22': 18.865182408484326, 'IoU-23': 17.113247948939026, 'IoU-24': 17.3763408806631, 'IoU-25': 17.27012011944906, 'IoU-26': 16.9298670963662, 'IoU-27': 17.975317613561455, 'IoU-28': 16.933168359430347, 'IoU-29': 16.98356096138349, 'IoU-30': 15.90979130012014, 'IoU-31': 16.63379356965457, 'IoU-32': 15.801492500304178, 'IoU-33': 14.832651620384581, 'IoU-34': 14.174338235703779, 'IoU-35': 14.62941153498021, 'IoU-36': 14.20049809330326, 'IoU-37': 13.453219306646917, 'IoU-38': 12.675274537824452, 'IoU-39': 11.695071777414118, 'IoU-40': 11.277652669316318, 'IoU-41': 10.521424121070625, 'IoU-42': 9.888801144209056, 'IoU-43': 9.497228751664382, 'IoU-44': 8.968486336917744, 'IoU-45': 8.494917936672907, 'IoU-46': 8.017601973332287, 'IoU-47': 7.4066115366496375, 'IoU-48': 6.902551607624359, 'IoU-49': 6.718484911651668, 'IoU-50': 6.54656074042807, 'IoU-51': 6.172615292047621, 'IoU-52': 5.870688305877253, 'IoU-53': 5.761667235265132, 'IoU-54': 5.838028355205822, 'IoU-55': 5.520192680096285, 'IoU-56': 5.604723278175838, 'IoU-57': 5.740111312433366, 'IoU-58': 5.73727231408445, 'IoU-59': 5.546173973315058, 'IoU-60': 5.368041393736321, 'IoU-61': 5.299505520429055, 'IoU-62': 5.320665184993355, 'IoU-63': 4.996367104736149, 'IoU-64': 5.0534613085700855, 'IoU-65': 4.855002408086849, 'IoU-66': 4.694079777511588, 'IoU-67': 4.69365344633493, 'IoU-68': 4.8093513475084215, 'IoU-69': 4.908089591690779, 'IoU-70': 4.891176786251262, 'IoU-71': 4.991737698611887, 'IoU-72': 5.1052152680027065, 'IoU-73': 5.182728941803263, 'IoU-74': 5.083490578336189, 'IoU-75': 5.077189959157416, 'IoU-76': 5.339035026918855, 'IoU-77': 5.3854517528188985, 'IoU-78': 5.354251768585268, 'IoU-79': 5.2300980839416065, 'IoU-80': 5.506613502151196, 'IoU-81': 5.351741736307674, 'IoU-82': 5.422439724417548, 'IoU-83': 5.5995363852471325, 'IoU-84': 5.599054488303766, 'IoU-85': 5.625279218909925, 'IoU-86': 5.551725749576451, 'IoU-87': 5.53587507394553, 'IoU-88': 5.4926385149313, 'IoU-89': 5.446306007419339, 'IoU-90': 5.379955899798064, 'IoU-91': 5.267380914505921, 'IoU-92': 5.220176821697402, 'IoU-93': 5.4005501379354595, 'IoU-94': 5.389932130721159, 'IoU-95': 5.419809558257736, 'IoU-96': 5.442810696173648, 'IoU-97': 5.525770906779767, 'IoU-98': 5.542396581117361, 'IoU-99': 5.22408695184438, 'IoU-100': 5.1193532798082835, 'IoU-101': 5.046424798984967, 'IoU-102': 4.970792883709718, 'IoU-103': 4.807466853842604, 'IoU-104': 4.596278452440923, 'IoU-105': 4.515834912587151, 'IoU-106': 4.867084990603128, 'IoU-107': 4.755995214675473, 'IoU-108': 4.817238006015723, 'IoU-109': 4.537104040235458, 'IoU-110': 4.421347317165998, 'IoU-111': 4.361317734294652, 'IoU-112': 4.255358980585932, 'IoU-113': 4.384028324466311, 'IoU-114': 4.348089651825294, 'IoU-115': 4.148512743156648, 'IoU-116': 3.8891529342625164, 'IoU-117': 4.1781295289864415, 'IoU-118': 3.855521038543932, 'IoU-119': 3.720356128924893, 'IoU-120': 3.743281558839947, 'IoU-121': 3.836266495945933, 'IoU-122': 3.7271251398602505, 'IoU-123': 3.946141614147711, 'IoU-124': 3.8676671525295587, 'IoU-125': 3.3864824248839827, 'IoU-126': 3.5289541675368836, 'IoU-127': 3.467449031072009, 'IoU-128': 3.47396751447998, 'IoU-129': 3.3538600848631117, 'IoU-130': 3.1966341309419453, 'IoU-131': 2.9417274676014746, 'IoU-132': 3.1122031679094007, 'IoU-133': 2.964582033880836, 'IoU-134': 3.031772954120584, 'IoU-135': 2.7608332721802307, 'IoU-136': 2.9705998279435675, 'IoU-137': 2.791801749452523, 'IoU-138': 3.0077272495278926, 'IoU-139': 2.607269484189435, 'IoU-140': 2.8197400928567604, 'IoU-141': 2.85143889346765, 'IoU-142': 2.838350802330099, 'IoU-143': 3.084843550054665, 'IoU-144': 2.8863959232595047, 'IoU-145': 2.6605028694512645, 'IoU-146': 2.8063724025143397, 'IoU-147': 2.8940939032169517, 'IoU-148': 2.3980979039375723, 'IoU-149': 2.3798159062313755, 'IoU-150': 2.515756066126626, 'IoU-151': 2.4776797068339795, 'IoU-152': 2.5075701013836533, 'IoU-153': 2.4157512458539805, 'IoU-154': 2.279786480252711, 'IoU-155': 2.2698983618606947, 'IoU-156': 2.123411337057089, 'IoU-157': 2.182075001240186, 'IoU-158': 2.0001269964340738, 'IoU-159': 1.9761245828818628, 'IoU-160': 1.8832395612099433, 'IoU-161': 2.0258008113471657, 'IoU-162': 1.9593311806204334, 'IoU-163': 2.2605812800168925, 'IoU-164': 2.011046766265998, 'IoU-165': 1.979387962045473, 'IoU-166': 2.0154399893680015, 'IoU-167': 2.1102091346672047, 'IoU-168': 2.399901491686904, 'IoU-169': 2.229513829989378, 'IoU-170': 1.9887138682014045, 'IoU-171': 1.7253507247958717, 'IoU-172': 2.122040354925128, 'IoU-173': 1.5991937608080715, 'IoU-174': 1.66456442824089, 'IoU-175': 1.4274499344191072, 'IoU-176': 1.7947582339829016, 'IoU-177': 2.320954529238043, 'IoU-178': 2.1416770649972734, 'IoU-179': 1.473424367689987, 'IoU-180': 1.4474519781957356, 'IoU-181': 1.4781353676594629, 'IoU-182': 1.7984076610687127, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 11.588079744037616, 'pACC': 26.203729438582368, 'ACC-0': 0.0007405489476101555, 'ACC-1': 70.33432573329252, 'ACC-2': 7.721568183700758, 'ACC-3': 16.670209889751845, 'ACC-4': 11.101232740228793, 'ACC-5': 11.42709696153828, 'ACC-6': 12.675286330468735, 'ACC-7': 12.693116889272964, 'ACC-8': 11.24619267639165, 'ACC-9': 20.616065510375915, 'ACC-10': 24.051988015425838, 'ACC-11': 34.13042288428198, 'ACC-12': 35.9065310596488, 'ACC-13': 33.29000730710239, 'ACC-14': 32.718233565349905, 'ACC-15': 34.386958835241074, 'ACC-16': 32.706493961299785, 'ACC-17': 29.849164250403753, 'ACC-18': 31.10653716277474, 'ACC-19': 33.522674600967406, 'ACC-20': 32.70996673018789, 'ACC-21': 32.45615200820732, 'ACC-22': 31.82121791748224, 'ACC-23': 30.68209623714638, 'ACC-24': 31.341652973946044, 'ACC-25': 31.339850662114138, 'ACC-26': 30.821994977850387, 'ACC-27': 31.813343325588207, 'ACC-28': 30.539267019780723, 'ACC-29': 29.619848000278292, 'ACC-30': 28.12416913976239, 'ACC-31': 29.128496285070245, 'ACC-32': 28.151126254018237, 'ACC-33': 26.847248137505957, 'ACC-34': 26.008406270071426, 'ACC-35': 26.618242836087745, 'ACC-36': 25.894099069997985, 'ACC-37': 25.27731222031545, 'ACC-38': 23.553311526512875, 'ACC-39': 21.714042152224447, 'ACC-40': 20.6338917527784, 'ACC-41': 19.96055633019466, 'ACC-42': 18.882725877672314, 'ACC-43': 18.05695809172768, 'ACC-44': 16.47400539085413, 'ACC-45': 15.796362831669875, 'ACC-46': 15.346046613072811, 'ACC-47': 14.125390681561814, 'ACC-48': 13.183254294071356, 'ACC-49': 12.797038366561342, 'ACC-50': 12.258957086065694, 'ACC-51': 11.725840043343062, 'ACC-52': 11.104596470910408, 'ACC-53': 10.754449361045879, 'ACC-54': 10.587841992145137, 'ACC-55': 9.96152020402316, 'ACC-56': 10.259042876540224, 'ACC-57': 10.373811539398005, 'ACC-58': 10.489588329153815, 'ACC-59': 10.317907984569043, 'ACC-60': 10.07161357811502, 'ACC-61': 9.980394461301765, 'ACC-62': 10.002485063332314, 'ACC-63': 9.460555479313586, 'ACC-64': 9.580863035938481, 'ACC-65': 9.24158471764248, 'ACC-66': 8.925602332922193, 'ACC-67': 8.951534182032328, 'ACC-68': 9.106973132745383, 'ACC-69': 9.137913740214398, 'ACC-70': 9.010767755952893, 'ACC-71': 9.385916698044609, 'ACC-72': 9.675467973098062, 'ACC-73': 9.76150340608397, 'ACC-74': 9.47227466853705, 'ACC-75': 9.487266568312586, 'ACC-76': 9.805749400883435, 'ACC-77': 10.074800140338958, 'ACC-78': 10.068208847251181, 'ACC-79': 9.806760492409724, 'ACC-80': 10.204936709014731, 'ACC-81': 9.860357201027792, 'ACC-82': 10.005886603229666, 'ACC-83': 10.163438741050578, 'ACC-84': 10.165165912764335, 'ACC-85': 10.19437126696487, 'ACC-86': 10.127695754799486, 'ACC-87': 10.210408940489717, 'ACC-88': 10.10344317048089, 'ACC-89': 9.922114151002988, 'ACC-90': 9.701353325788224, 'ACC-91': 9.525348485372174, 'ACC-92': 9.480676508827216, 'ACC-93': 9.920975687512696, 'ACC-94': 9.951897696392905, 'ACC-95': 9.99974816554338, 'ACC-96': 10.165001101606046, 'ACC-97': 10.276845975117572, 'ACC-98': 10.406594888538939, 'ACC-99': 9.851362265091131, 'ACC-100': 9.675083343672734, 'ACC-101': 9.544642872495361, 'ACC-102': 9.399456275487086, 'ACC-103': 9.044181543402285, 'ACC-104': 8.625783920710264, 'ACC-105': 8.396468338683368, 'ACC-106': 8.899480980517561, 'ACC-107': 8.657107641563211, 'ACC-108': 8.742417630644477, 'ACC-109': 8.215477906625674, 'ACC-110': 8.143036382671283, 'ACC-111': 8.181251510162866, 'ACC-112': 8.190978012584257, 'ACC-113': 8.43147964164157, 'ACC-114': 8.495381008069614, 'ACC-115': 8.12078089997444, 'ACC-116': 7.683177407006231, 'ACC-117': 8.140223590744233, 'ACC-118': 7.463711798772052, 'ACC-119': 7.057104390794571, 'ACC-120': 7.122369341162497, 'ACC-121': 7.392260360179086, 'ACC-122': 7.22720711030598, 'ACC-123': 7.672514008159173, 'ACC-124': 7.680087539242694, 'ACC-125': 6.625348203049285, 'ACC-126': 6.84808149436698, 'ACC-127': 6.6516017344335525, 'ACC-128': 6.730223895615393, 'ACC-129': 6.526460582883972, 'ACC-130': 6.262656619621662, 'ACC-131': 5.802236041025764, 'ACC-132': 6.133244865337636, 'ACC-133': 5.675695904522784, 'ACC-134': 5.691615682895304, 'ACC-135': 5.147511544381734, 'ACC-136': 5.557779887253075, 'ACC-137': 5.342779096897689, 'ACC-138': 5.843005178059243, 'ACC-139': 5.09070278982712, 'ACC-140': 5.495977219983203, 'ACC-141': 5.619307939724543, 'ACC-142': 5.633499001363247, 'ACC-143': 6.158585186003902, 'ACC-144': 5.631407942238267, 'ACC-145': 5.055658668574878, 'ACC-146': 5.363094286171209, 'ACC-147': 5.501665300195082, 'ACC-148': 4.57496832377898, 'ACC-149': 4.555664968678663, 'ACC-150': 4.777211804350387, 'ACC-151': 4.776064364376206, 'ACC-152': 4.7668419987861625, 'ACC-153': 4.727321863720479, 'ACC-154': 4.559880798481097, 'ACC-155': 4.64375602408896, 'ACC-156': 4.35132217675994, 'ACC-157': 4.549952159491951, 'ACC-158': 4.223266920800338, 'ACC-159': 4.15240709184064, 'ACC-160': 3.8587804822874725, 'ACC-161': 3.9891652648163176, 'ACC-162': 4.074668031335818, 'ACC-163': 4.811462516452221, 'ACC-164': 4.193316188851436, 'ACC-165': 4.076683384843104, 'ACC-166': 4.302658418044001, 'ACC-167': 4.761259547620413, 'ACC-168': 5.79119488009002, 'ACC-169': 5.373640314936313, 'ACC-170': 4.592401720686571, 'ACC-171': 4.181047704942424, 'ACC-172': 5.075934363077379, 'ACC-173': 3.9408774312989885, 'ACC-174': 3.950559292873373, 'ACC-175': 3.839121134301757, 'ACC-176': 4.895555200835848, 'ACC-177': 7.5156541525719325, 'ACC-178': 8.185454819387651, 'ACC-179': 3.8147138964577656, 'ACC-180': 3.594136272816553, 'ACC-181': 3.735838420014165, 'ACC-182': 3.744470952808531, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 14:09:37] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 14:09:37] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 14:09:37] d2.evaluation.testing INFO: copypaste: 2.8242,0.4286,0.1889,6.3819,17.8785,11.5881,26.2037
[01/29 14:09:37] d2.utils.events INFO:  eta: 1 day, 9:21:11  iter: 18999  total_loss: 24.57  loss_mask: 2.457  loss_mask_0: 2.504  loss_mask_1: 2.442  loss_mask_2: 2.461  loss_mask_3: 2.475  loss_mask_4: 2.461  loss_mask_5: 2.466  loss_mask_6: 2.451  loss_mask_7: 2.481  loss_mask_8: 2.464  time: 3.0086  data_time: 0.0475  lr: 7.0987e-05  max_mem: 27646M
[01/29 14:10:36] d2.utils.events INFO:  eta: 1 day, 9:20:13  iter: 19019  total_loss: 29.03  loss_mask: 2.882  loss_mask_0: 2.92  loss_mask_1: 2.896  loss_mask_2: 2.882  loss_mask_3: 2.905  loss_mask_4: 2.909  loss_mask_5: 2.904  loss_mask_6: 2.886  loss_mask_7: 2.898  loss_mask_8: 2.9  time: 3.0085  data_time: 0.0534  lr: 7.0956e-05  max_mem: 27646M
[01/29 14:11:35] d2.utils.events INFO:  eta: 1 day, 9:18:46  iter: 19039  total_loss: 27.31  loss_mask: 2.729  loss_mask_0: 2.765  loss_mask_1: 2.7  loss_mask_2: 2.732  loss_mask_3: 2.741  loss_mask_4: 2.762  loss_mask_5: 2.707  loss_mask_6: 2.722  loss_mask_7: 2.739  loss_mask_8: 2.742  time: 3.0084  data_time: 0.0511  lr: 7.0925e-05  max_mem: 27646M
[01/29 14:12:33] d2.utils.events INFO:  eta: 1 day, 9:18:10  iter: 19059  total_loss: 25.48  loss_mask: 2.529  loss_mask_0: 2.589  loss_mask_1: 2.524  loss_mask_2: 2.546  loss_mask_3: 2.545  loss_mask_4: 2.565  loss_mask_5: 2.537  loss_mask_6: 2.525  loss_mask_7: 2.548  loss_mask_8: 2.559  time: 3.0083  data_time: 0.0423  lr: 7.0894e-05  max_mem: 27646M
[01/29 14:13:32] d2.utils.events INFO:  eta: 1 day, 9:17:20  iter: 19079  total_loss: 26.18  loss_mask: 2.651  loss_mask_0: 2.661  loss_mask_1: 2.613  loss_mask_2: 2.621  loss_mask_3: 2.617  loss_mask_4: 2.623  loss_mask_5: 2.591  loss_mask_6: 2.661  loss_mask_7: 2.62  loss_mask_8: 2.626  time: 3.0082  data_time: 0.0444  lr: 7.0862e-05  max_mem: 27646M
[01/29 14:14:31] d2.utils.events INFO:  eta: 1 day, 9:16:31  iter: 19099  total_loss: 25.15  loss_mask: 2.523  loss_mask_0: 2.61  loss_mask_1: 2.497  loss_mask_2: 2.507  loss_mask_3: 2.519  loss_mask_4: 2.535  loss_mask_5: 2.511  loss_mask_6: 2.518  loss_mask_7: 2.519  loss_mask_8: 2.549  time: 3.0082  data_time: 0.0467  lr: 7.0831e-05  max_mem: 27646M
[01/29 14:15:30] d2.utils.events INFO:  eta: 1 day, 9:15:39  iter: 19119  total_loss: 28.36  loss_mask: 2.81  loss_mask_0: 2.887  loss_mask_1: 2.797  loss_mask_2: 2.822  loss_mask_3: 2.883  loss_mask_4: 2.843  loss_mask_5: 2.807  loss_mask_6: 2.809  loss_mask_7: 2.846  loss_mask_8: 2.829  time: 3.0081  data_time: 0.0471  lr: 7.08e-05  max_mem: 27646M
[01/29 14:16:28] d2.utils.events INFO:  eta: 1 day, 9:14:47  iter: 19139  total_loss: 28.76  loss_mask: 2.901  loss_mask_0: 2.951  loss_mask_1: 2.845  loss_mask_2: 2.878  loss_mask_3: 2.865  loss_mask_4: 2.873  loss_mask_5: 2.853  loss_mask_6: 2.874  loss_mask_7: 2.862  loss_mask_8: 2.838  time: 3.0080  data_time: 0.0483  lr: 7.0769e-05  max_mem: 27646M
[01/29 14:17:27] d2.utils.events INFO:  eta: 1 day, 9:13:28  iter: 19159  total_loss: 28.08  loss_mask: 2.803  loss_mask_0: 2.797  loss_mask_1: 2.896  loss_mask_2: 2.77  loss_mask_3: 2.777  loss_mask_4: 2.809  loss_mask_5: 2.763  loss_mask_6: 2.771  loss_mask_7: 2.774  loss_mask_8: 2.768  time: 3.0079  data_time: 0.0503  lr: 7.0738e-05  max_mem: 27646M
[01/29 14:18:25] d2.utils.events INFO:  eta: 1 day, 9:12:37  iter: 19179  total_loss: 25.77  loss_mask: 2.555  loss_mask_0: 2.669  loss_mask_1: 2.771  loss_mask_2: 2.63  loss_mask_3: 2.563  loss_mask_4: 2.558  loss_mask_5: 2.542  loss_mask_6: 2.557  loss_mask_7: 2.553  loss_mask_8: 2.571  time: 3.0078  data_time: 0.0478  lr: 7.0706e-05  max_mem: 27646M
[01/29 14:19:25] d2.utils.events INFO:  eta: 1 day, 9:12:23  iter: 19199  total_loss: 27.24  loss_mask: 2.654  loss_mask_0: 2.843  loss_mask_1: 2.916  loss_mask_2: 2.748  loss_mask_3: 2.684  loss_mask_4: 2.681  loss_mask_5: 2.65  loss_mask_6: 2.652  loss_mask_7: 2.685  loss_mask_8: 2.698  time: 3.0078  data_time: 0.0446  lr: 7.0675e-05  max_mem: 27646M
[01/29 14:20:23] d2.utils.events INFO:  eta: 1 day, 9:10:46  iter: 19219  total_loss: 28.38  loss_mask: 2.794  loss_mask_0: 2.879  loss_mask_1: 3.187  loss_mask_2: 2.825  loss_mask_3: 2.785  loss_mask_4: 2.811  loss_mask_5: 2.806  loss_mask_6: 2.798  loss_mask_7: 2.8  loss_mask_8: 2.788  time: 3.0077  data_time: 0.0482  lr: 7.0644e-05  max_mem: 27646M
[01/29 14:21:22] d2.utils.events INFO:  eta: 1 day, 9:09:45  iter: 19239  total_loss: 27.09  loss_mask: 2.637  loss_mask_0: 2.756  loss_mask_1: 2.98  loss_mask_2: 2.686  loss_mask_3: 2.669  loss_mask_4: 2.682  loss_mask_5: 2.656  loss_mask_6: 2.629  loss_mask_7: 2.67  loss_mask_8: 2.674  time: 3.0076  data_time: 0.0486  lr: 7.0613e-05  max_mem: 27646M
[01/29 14:22:21] d2.utils.events INFO:  eta: 1 day, 9:08:56  iter: 19259  total_loss: 22.81  loss_mask: 2.259  loss_mask_0: 2.318  loss_mask_1: 2.451  loss_mask_2: 2.362  loss_mask_3: 2.275  loss_mask_4: 2.291  loss_mask_5: 2.243  loss_mask_6: 2.245  loss_mask_7: 2.261  loss_mask_8: 2.269  time: 3.0076  data_time: 0.0482  lr: 7.0582e-05  max_mem: 27646M
[01/29 14:23:19] d2.utils.events INFO:  eta: 1 day, 9:07:44  iter: 19279  total_loss: 25.42  loss_mask: 2.54  loss_mask_0: 2.542  loss_mask_1: 2.619  loss_mask_2: 2.518  loss_mask_3: 2.528  loss_mask_4: 2.534  loss_mask_5: 2.537  loss_mask_6: 2.538  loss_mask_7: 2.539  loss_mask_8: 2.521  time: 3.0075  data_time: 0.0538  lr: 7.0551e-05  max_mem: 27646M
[01/29 14:24:18] d2.utils.events INFO:  eta: 1 day, 9:06:52  iter: 19299  total_loss: 26.01  loss_mask: 2.598  loss_mask_0: 2.609  loss_mask_1: 2.571  loss_mask_2: 2.584  loss_mask_3: 2.622  loss_mask_4: 2.595  loss_mask_5: 2.605  loss_mask_6: 2.586  loss_mask_7: 2.597  loss_mask_8: 2.59  time: 3.0074  data_time: 0.0468  lr: 7.0519e-05  max_mem: 27646M
[01/29 14:25:17] d2.utils.events INFO:  eta: 1 day, 9:05:56  iter: 19319  total_loss: 25.37  loss_mask: 2.542  loss_mask_0: 2.565  loss_mask_1: 2.548  loss_mask_2: 2.548  loss_mask_3: 2.57  loss_mask_4: 2.573  loss_mask_5: 2.53  loss_mask_6: 2.529  loss_mask_7: 2.534  loss_mask_8: 2.556  time: 3.0073  data_time: 0.0436  lr: 7.0488e-05  max_mem: 27646M
[01/29 14:26:15] d2.utils.events INFO:  eta: 1 day, 9:04:45  iter: 19339  total_loss: 23.75  loss_mask: 2.365  loss_mask_0: 2.416  loss_mask_1: 2.392  loss_mask_2: 2.379  loss_mask_3: 2.38  loss_mask_4: 2.382  loss_mask_5: 2.363  loss_mask_6: 2.358  loss_mask_7: 2.365  loss_mask_8: 2.375  time: 3.0072  data_time: 0.0468  lr: 7.0457e-05  max_mem: 27646M
[01/29 14:27:14] d2.utils.events INFO:  eta: 1 day, 9:03:59  iter: 19359  total_loss: 23.94  loss_mask: 2.355  loss_mask_0: 2.546  loss_mask_1: 2.498  loss_mask_2: 2.395  loss_mask_3: 2.364  loss_mask_4: 2.377  loss_mask_5: 2.361  loss_mask_6: 2.363  loss_mask_7: 2.35  loss_mask_8: 2.363  time: 3.0072  data_time: 0.0499  lr: 7.0426e-05  max_mem: 27646M
[01/29 14:28:14] d2.utils.events INFO:  eta: 1 day, 9:03:36  iter: 19379  total_loss: 24.87  loss_mask: 2.46  loss_mask_0: 2.539  loss_mask_1: 2.464  loss_mask_2: 2.483  loss_mask_3: 2.475  loss_mask_4: 2.486  loss_mask_5: 2.458  loss_mask_6: 2.463  loss_mask_7: 2.471  loss_mask_8: 2.46  time: 3.0071  data_time: 0.0642  lr: 7.0395e-05  max_mem: 27646M
[01/29 14:29:13] d2.utils.events INFO:  eta: 1 day, 9:02:47  iter: 19399  total_loss: 29.98  loss_mask: 2.946  loss_mask_0: 2.947  loss_mask_1: 3.029  loss_mask_2: 3.026  loss_mask_3: 2.959  loss_mask_4: 2.958  loss_mask_5: 3.002  loss_mask_6: 2.945  loss_mask_7: 2.964  loss_mask_8: 2.96  time: 3.0071  data_time: 0.0521  lr: 7.0363e-05  max_mem: 27646M
[01/29 14:30:13] d2.utils.events INFO:  eta: 1 day, 9:02:21  iter: 19419  total_loss: 26.31  loss_mask: 2.596  loss_mask_0: 2.682  loss_mask_1: 2.663  loss_mask_2: 2.744  loss_mask_3: 2.592  loss_mask_4: 2.58  loss_mask_5: 2.62  loss_mask_6: 2.592  loss_mask_7: 2.83  loss_mask_8: 2.596  time: 3.0071  data_time: 0.0565  lr: 7.0332e-05  max_mem: 27646M
[01/29 14:31:12] d2.utils.events INFO:  eta: 1 day, 9:01:28  iter: 19439  total_loss: 24.54  loss_mask: 2.407  loss_mask_0: 2.472  loss_mask_1: 2.46  loss_mask_2: 2.475  loss_mask_3: 2.402  loss_mask_4: 2.427  loss_mask_5: 2.43  loss_mask_6: 2.398  loss_mask_7: 2.627  loss_mask_8: 2.42  time: 3.0070  data_time: 0.0627  lr: 7.0301e-05  max_mem: 27646M
[01/29 14:32:12] d2.utils.events INFO:  eta: 1 day, 9:00:55  iter: 19459  total_loss: 28.63  loss_mask: 2.828  loss_mask_0: 2.882  loss_mask_1: 2.915  loss_mask_2: 2.905  loss_mask_3: 2.806  loss_mask_4: 2.82  loss_mask_5: 2.849  loss_mask_6: 2.817  loss_mask_7: 2.984  loss_mask_8: 2.801  time: 3.0070  data_time: 0.0583  lr: 7.027e-05  max_mem: 27646M
[01/29 14:33:11] d2.utils.events INFO:  eta: 1 day, 9:00:19  iter: 19479  total_loss: 25.92  loss_mask: 2.624  loss_mask_0: 2.571  loss_mask_1: 2.568  loss_mask_2: 2.563  loss_mask_3: 2.623  loss_mask_4: 2.591  loss_mask_5: 2.558  loss_mask_6: 2.572  loss_mask_7: 2.648  loss_mask_8: 2.571  time: 3.0069  data_time: 0.0540  lr: 7.0239e-05  max_mem: 27646M
[01/29 14:34:10] d2.utils.events INFO:  eta: 1 day, 8:59:31  iter: 19499  total_loss: 26.63  loss_mask: 2.664  loss_mask_0: 2.705  loss_mask_1: 2.679  loss_mask_2: 2.649  loss_mask_3: 2.626  loss_mask_4: 2.633  loss_mask_5: 2.631  loss_mask_6: 2.649  loss_mask_7: 2.71  loss_mask_8: 2.637  time: 3.0069  data_time: 0.0555  lr: 7.0207e-05  max_mem: 27646M
[01/29 14:35:10] d2.utils.events INFO:  eta: 1 day, 8:58:52  iter: 19519  total_loss: 28.69  loss_mask: 2.795  loss_mask_0: 2.836  loss_mask_1: 2.921  loss_mask_2: 2.852  loss_mask_3: 2.822  loss_mask_4: 2.848  loss_mask_5: 2.86  loss_mask_6: 2.808  loss_mask_7: 2.944  loss_mask_8: 2.808  time: 3.0069  data_time: 0.0620  lr: 7.0176e-05  max_mem: 27646M
[01/29 14:36:09] d2.utils.events INFO:  eta: 1 day, 8:58:17  iter: 19539  total_loss: 24.87  loss_mask: 2.451  loss_mask_0: 2.539  loss_mask_1: 2.489  loss_mask_2: 2.503  loss_mask_3: 2.477  loss_mask_4: 2.488  loss_mask_5: 2.493  loss_mask_6: 2.455  loss_mask_7: 2.505  loss_mask_8: 2.471  time: 3.0068  data_time: 0.0607  lr: 7.0145e-05  max_mem: 27646M
[01/29 14:37:09] d2.utils.events INFO:  eta: 1 day, 8:58:29  iter: 19559  total_loss: 26.16  loss_mask: 2.603  loss_mask_0: 2.623  loss_mask_1: 2.636  loss_mask_2: 2.592  loss_mask_3: 2.597  loss_mask_4: 2.618  loss_mask_5: 2.641  loss_mask_6: 2.595  loss_mask_7: 2.608  loss_mask_8: 2.583  time: 3.0068  data_time: 0.0608  lr: 7.0114e-05  max_mem: 27646M
[01/29 14:38:08] d2.utils.events INFO:  eta: 1 day, 8:57:51  iter: 19579  total_loss: 29.91  loss_mask: 2.951  loss_mask_0: 3.019  loss_mask_1: 2.963  loss_mask_2: 2.98  loss_mask_3: 3.005  loss_mask_4: 2.974  loss_mask_5: 2.977  loss_mask_6: 3.003  loss_mask_7: 2.973  loss_mask_8: 2.924  time: 3.0067  data_time: 0.0579  lr: 7.0083e-05  max_mem: 27646M
[01/29 14:39:07] d2.utils.events INFO:  eta: 1 day, 8:57:26  iter: 19599  total_loss: 27.25  loss_mask: 2.719  loss_mask_0: 2.738  loss_mask_1: 2.688  loss_mask_2: 2.711  loss_mask_3: 2.73  loss_mask_4: 2.741  loss_mask_5: 2.715  loss_mask_6: 2.72  loss_mask_7: 2.734  loss_mask_8: 2.748  time: 3.0067  data_time: 0.0598  lr: 7.0051e-05  max_mem: 27646M
[01/29 14:40:06] d2.utils.events INFO:  eta: 1 day, 8:56:24  iter: 19619  total_loss: 24.91  loss_mask: 2.503  loss_mask_0: 2.517  loss_mask_1: 2.491  loss_mask_2: 2.497  loss_mask_3: 2.498  loss_mask_4: 2.491  loss_mask_5: 2.477  loss_mask_6: 2.494  loss_mask_7: 2.506  loss_mask_8: 2.485  time: 3.0066  data_time: 0.0560  lr: 7.002e-05  max_mem: 27646M
[01/29 14:41:05] d2.utils.events INFO:  eta: 1 day, 8:55:34  iter: 19639  total_loss: 22.87  loss_mask: 2.303  loss_mask_0: 2.379  loss_mask_1: 2.294  loss_mask_2: 2.304  loss_mask_3: 2.294  loss_mask_4: 2.305  loss_mask_5: 2.3  loss_mask_6: 2.305  loss_mask_7: 2.257  loss_mask_8: 2.267  time: 3.0066  data_time: 0.0582  lr: 6.9989e-05  max_mem: 27646M
[01/29 14:42:04] d2.utils.events INFO:  eta: 1 day, 8:54:35  iter: 19659  total_loss: 26.78  loss_mask: 2.706  loss_mask_0: 2.699  loss_mask_1: 2.684  loss_mask_2: 2.648  loss_mask_3: 2.644  loss_mask_4: 2.669  loss_mask_5: 2.627  loss_mask_6: 2.673  loss_mask_7: 2.721  loss_mask_8: 2.67  time: 3.0065  data_time: 0.0560  lr: 6.9958e-05  max_mem: 27646M
[01/29 14:43:03] d2.utils.events INFO:  eta: 1 day, 8:53:26  iter: 19679  total_loss: 25.14  loss_mask: 2.524  loss_mask_0: 2.613  loss_mask_1: 2.532  loss_mask_2: 2.483  loss_mask_3: 2.491  loss_mask_4: 2.501  loss_mask_5: 2.486  loss_mask_6: 2.492  loss_mask_7: 2.509  loss_mask_8: 2.48  time: 3.0065  data_time: 0.0588  lr: 6.9927e-05  max_mem: 27646M
[01/29 14:44:03] d2.utils.events INFO:  eta: 1 day, 8:53:00  iter: 19699  total_loss: 28.64  loss_mask: 2.829  loss_mask_0: 2.883  loss_mask_1: 2.834  loss_mask_2: 2.876  loss_mask_3: 2.878  loss_mask_4: 2.923  loss_mask_5: 2.832  loss_mask_6: 2.864  loss_mask_7: 2.844  loss_mask_8: 2.872  time: 3.0065  data_time: 0.0602  lr: 6.9895e-05  max_mem: 27646M
[01/29 14:45:02] d2.utils.events INFO:  eta: 1 day, 8:51:45  iter: 19719  total_loss: 29.03  loss_mask: 2.91  loss_mask_0: 2.957  loss_mask_1: 2.89  loss_mask_2: 2.905  loss_mask_3: 2.895  loss_mask_4: 2.884  loss_mask_5: 2.876  loss_mask_6: 2.88  loss_mask_7: 2.926  loss_mask_8: 2.905  time: 3.0064  data_time: 0.0528  lr: 6.9864e-05  max_mem: 27646M
[01/29 14:46:02] d2.utils.events INFO:  eta: 1 day, 8:51:09  iter: 19739  total_loss: 25.85  loss_mask: 2.577  loss_mask_0: 2.554  loss_mask_1: 2.589  loss_mask_2: 2.565  loss_mask_3: 2.581  loss_mask_4: 2.613  loss_mask_5: 2.56  loss_mask_6: 2.607  loss_mask_7: 2.548  loss_mask_8: 2.558  time: 3.0064  data_time: 0.0565  lr: 6.9833e-05  max_mem: 27646M
[01/29 14:47:01] d2.utils.events INFO:  eta: 1 day, 8:50:30  iter: 19759  total_loss: 23.93  loss_mask: 2.386  loss_mask_0: 2.459  loss_mask_1: 2.388  loss_mask_2: 2.368  loss_mask_3: 2.382  loss_mask_4: 2.381  loss_mask_5: 2.384  loss_mask_6: 2.377  loss_mask_7: 2.391  loss_mask_8: 2.373  time: 3.0063  data_time: 0.0611  lr: 6.9802e-05  max_mem: 27646M
[01/29 14:48:00] d2.utils.events INFO:  eta: 1 day, 8:50:26  iter: 19779  total_loss: 26.6  loss_mask: 2.634  loss_mask_0: 2.672  loss_mask_1: 2.665  loss_mask_2: 2.656  loss_mask_3: 2.651  loss_mask_4: 2.657  loss_mask_5: 2.662  loss_mask_6: 2.641  loss_mask_7: 2.654  loss_mask_8: 2.679  time: 3.0063  data_time: 0.0522  lr: 6.977e-05  max_mem: 27646M
[01/29 14:49:00] d2.utils.events INFO:  eta: 1 day, 8:50:06  iter: 19799  total_loss: 24.7  loss_mask: 2.432  loss_mask_0: 2.457  loss_mask_1: 2.452  loss_mask_2: 2.491  loss_mask_3: 2.463  loss_mask_4: 2.464  loss_mask_5: 2.445  loss_mask_6: 2.432  loss_mask_7: 2.444  loss_mask_8: 2.504  time: 3.0062  data_time: 0.0586  lr: 6.9739e-05  max_mem: 27646M
[01/29 14:49:59] d2.utils.events INFO:  eta: 1 day, 8:49:10  iter: 19819  total_loss: 26.13  loss_mask: 2.646  loss_mask_0: 2.708  loss_mask_1: 2.59  loss_mask_2: 2.607  loss_mask_3: 2.615  loss_mask_4: 2.617  loss_mask_5: 2.582  loss_mask_6: 2.606  loss_mask_7: 2.597  loss_mask_8: 2.598  time: 3.0062  data_time: 0.0594  lr: 6.9708e-05  max_mem: 27646M
[01/29 14:50:59] d2.utils.events INFO:  eta: 1 day, 8:48:18  iter: 19839  total_loss: 25.59  loss_mask: 2.546  loss_mask_0: 2.642  loss_mask_1: 2.538  loss_mask_2: 2.549  loss_mask_3: 2.553  loss_mask_4: 2.567  loss_mask_5: 2.542  loss_mask_6: 2.54  loss_mask_7: 2.55  loss_mask_8: 2.55  time: 3.0062  data_time: 0.0567  lr: 6.9677e-05  max_mem: 27646M
[01/29 14:51:58] d2.utils.events INFO:  eta: 1 day, 8:47:50  iter: 19859  total_loss: 25.34  loss_mask: 2.548  loss_mask_0: 2.576  loss_mask_1: 2.527  loss_mask_2: 2.513  loss_mask_3: 2.538  loss_mask_4: 2.557  loss_mask_5: 2.528  loss_mask_6: 2.548  loss_mask_7: 2.54  loss_mask_8: 2.536  time: 3.0061  data_time: 0.0599  lr: 6.9646e-05  max_mem: 27646M
[01/29 14:52:58] d2.utils.events INFO:  eta: 1 day, 8:47:23  iter: 19879  total_loss: 28.79  loss_mask: 2.886  loss_mask_0: 2.957  loss_mask_1: 2.867  loss_mask_2: 2.879  loss_mask_3: 2.899  loss_mask_4: 2.856  loss_mask_5: 2.865  loss_mask_6: 2.888  loss_mask_7: 2.878  loss_mask_8: 2.889  time: 3.0061  data_time: 0.0566  lr: 6.9614e-05  max_mem: 27646M
[01/29 14:53:58] d2.utils.events INFO:  eta: 1 day, 8:46:37  iter: 19899  total_loss: 26.59  loss_mask: 2.644  loss_mask_0: 2.656  loss_mask_1: 2.659  loss_mask_2: 2.664  loss_mask_3: 2.673  loss_mask_4: 2.656  loss_mask_5: 2.657  loss_mask_6: 2.647  loss_mask_7: 2.666  loss_mask_8: 2.649  time: 3.0061  data_time: 0.0565  lr: 6.9583e-05  max_mem: 27646M
[01/29 14:54:57] d2.utils.events INFO:  eta: 1 day, 8:45:52  iter: 19919  total_loss: 27.45  loss_mask: 2.724  loss_mask_0: 2.737  loss_mask_1: 2.741  loss_mask_2: 2.755  loss_mask_3: 2.754  loss_mask_4: 2.758  loss_mask_5: 2.766  loss_mask_6: 2.76  loss_mask_7: 2.734  loss_mask_8: 2.752  time: 3.0061  data_time: 0.0612  lr: 6.9552e-05  max_mem: 27646M
[01/29 14:55:57] d2.utils.events INFO:  eta: 1 day, 8:45:42  iter: 19939  total_loss: 25.12  loss_mask: 2.476  loss_mask_0: 2.544  loss_mask_1: 2.476  loss_mask_2: 2.492  loss_mask_3: 2.515  loss_mask_4: 2.497  loss_mask_5: 2.498  loss_mask_6: 2.541  loss_mask_7: 2.494  loss_mask_8: 2.473  time: 3.0060  data_time: 0.0571  lr: 6.9521e-05  max_mem: 27646M
[01/29 14:56:56] d2.utils.events INFO:  eta: 1 day, 8:44:47  iter: 19959  total_loss: 28.38  loss_mask: 2.868  loss_mask_0: 2.898  loss_mask_1: 2.771  loss_mask_2: 2.765  loss_mask_3: 2.884  loss_mask_4: 2.884  loss_mask_5: 2.815  loss_mask_6: 2.855  loss_mask_7: 2.785  loss_mask_8: 2.838  time: 3.0060  data_time: 0.0500  lr: 6.9489e-05  max_mem: 27646M
[01/29 14:57:55] d2.utils.events INFO:  eta: 1 day, 8:44:24  iter: 19979  total_loss: 23.87  loss_mask: 2.344  loss_mask_0: 2.433  loss_mask_1: 2.376  loss_mask_2: 2.395  loss_mask_3: 2.337  loss_mask_4: 2.376  loss_mask_5: 2.388  loss_mask_6: 2.374  loss_mask_7: 2.4  loss_mask_8: 2.387  time: 3.0059  data_time: 0.0583  lr: 6.9458e-05  max_mem: 27646M
[01/29 14:58:55] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/model_0019999.pth
[01/29 14:58:55] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 14:58:56] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 14:58:56] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 15:13:06] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.8469856632942148, 'error_1pix': 0.42421597263312333, 'error_3pix': 0.18829613238366938, 'mIoU': 5.712046918949889, 'fwIoU': 13.21511290621547, 'IoU-0': 0.00035231698706542444, 'IoU-1': 20.934890172613006, 'IoU-2': 1.9575512866983866, 'IoU-3': 2.6011388698703217, 'IoU-4': 2.6264345057114005, 'IoU-5': 2.699409686304375, 'IoU-6': 2.9843928240096185, 'IoU-7': 2.6518964427355565, 'IoU-8': 4.817784692282875, 'IoU-9': 14.283992633396785, 'IoU-10': 18.821551811880706, 'IoU-11': 26.880258456631818, 'IoU-12': 25.733259782009704, 'IoU-13': 23.343599553518498, 'IoU-14': 22.859913409359837, 'IoU-15': 22.195112712588, 'IoU-16': 21.627600267337304, 'IoU-17': 19.15907199093781, 'IoU-18': 18.957465601592812, 'IoU-19': 19.135335217838332, 'IoU-20': 19.25126015077452, 'IoU-21': 19.339674523964913, 'IoU-22': 20.007697913726105, 'IoU-23': 17.772388571143757, 'IoU-24': 17.699576543183316, 'IoU-25': 17.386993856753715, 'IoU-26': 16.597341042820027, 'IoU-27': 17.969100314628758, 'IoU-28': 17.095677040125608, 'IoU-29': 17.1904806111711, 'IoU-30': 16.311164003757987, 'IoU-31': 16.571032558066324, 'IoU-32': 15.047613578516359, 'IoU-33': 14.044866941455403, 'IoU-34': 13.597932627567207, 'IoU-35': 13.78617316927458, 'IoU-36': 13.218693488884004, 'IoU-37': 12.375424069225446, 'IoU-38': 11.6447538193077, 'IoU-39': 10.485874161999892, 'IoU-40': 9.998565295338175, 'IoU-41': 9.63475569614998, 'IoU-42': 9.320872507517459, 'IoU-43': 9.171134373022207, 'IoU-44': 9.178231312762335, 'IoU-45': 9.067655030594265, 'IoU-46': 8.549180530317107, 'IoU-47': 8.291262004815383, 'IoU-48': 8.042147907766033, 'IoU-49': 8.287452867739038, 'IoU-50': 8.22620112517504, 'IoU-51': 7.935726175392818, 'IoU-52': 8.090922624115532, 'IoU-53': 7.994131379588251, 'IoU-54': 8.17923250624215, 'IoU-55': 7.706746778756349, 'IoU-56': 7.4250740969463, 'IoU-57': 7.507309245306357, 'IoU-58': 7.4392982900201226, 'IoU-59': 7.089428955751156, 'IoU-60': 6.97870346654339, 'IoU-61': 6.5899820217495835, 'IoU-62': 6.233869768126351, 'IoU-63': 5.637447327060197, 'IoU-64': 5.451629638716982, 'IoU-65': 5.4472636402590275, 'IoU-66': 4.9740999165986315, 'IoU-67': 4.682638098006135, 'IoU-68': 4.7621418926530605, 'IoU-69': 4.75552166677715, 'IoU-70': 4.755525090288957, 'IoU-71': 4.692457927389084, 'IoU-72': 4.5529801324503305, 'IoU-73': 4.710227870133822, 'IoU-74': 4.683576271354095, 'IoU-75': 4.275759792979956, 'IoU-76': 4.424283990151818, 'IoU-77': 4.199000368212706, 'IoU-78': 4.135829550840313, 'IoU-79': 4.049271033982571, 'IoU-80': 4.043038707412397, 'IoU-81': 3.9938483940312928, 'IoU-82': 3.8617219129056988, 'IoU-83': 4.114272597111278, 'IoU-84': 4.037196354222107, 'IoU-85': 3.9440930518859822, 'IoU-86': 3.9724254853515504, 'IoU-87': 3.9515435359178985, 'IoU-88': 3.908367829213905, 'IoU-89': 3.9822830326092817, 'IoU-90': 3.9282494378626014, 'IoU-91': 3.7931733123264566, 'IoU-92': 3.9355091896621257, 'IoU-93': 3.8821275215228845, 'IoU-94': 3.7707654739027285, 'IoU-95': 3.6126866121454624, 'IoU-96': 3.4628006919724426, 'IoU-97': 3.4617776947580072, 'IoU-98': 3.468443519217821, 'IoU-99': 3.2837077323725072, 'IoU-100': 3.0092348617493414, 'IoU-101': 3.0382918518317266, 'IoU-102': 2.9013985839793195, 'IoU-103': 2.6580562814919797, 'IoU-104': 2.526128629882599, 'IoU-105': 2.6015202720996387, 'IoU-106': 2.5413288975206845, 'IoU-107': 2.5497819183822164, 'IoU-108': 2.5105085178256963, 'IoU-109': 2.6925734986720955, 'IoU-110': 2.6876982980798108, 'IoU-111': 2.3707870994675035, 'IoU-112': 2.4867906356639806, 'IoU-113': 2.355312967402515, 'IoU-114': 2.363819863809214, 'IoU-115': 2.23507434504358, 'IoU-116': 2.5492075978144184, 'IoU-117': 2.4214915542222757, 'IoU-118': 2.3986274826452205, 'IoU-119': 2.5221864308761615, 'IoU-120': 2.4448612266783307, 'IoU-121': 2.471697628236495, 'IoU-122': 2.372357958480638, 'IoU-123': 2.3837000052142487, 'IoU-124': 2.074103019198699, 'IoU-125': 2.2606341460633494, 'IoU-126': 2.4145333939447395, 'IoU-127': 2.169396585689391, 'IoU-128': 2.2524413276964044, 'IoU-129': 2.140330054309771, 'IoU-130': 2.2004262968884047, 'IoU-131': 2.1231106254833922, 'IoU-132': 2.1631786181396806, 'IoU-133': 2.351593054828986, 'IoU-134': 2.4623630089368103, 'IoU-135': 2.081607948829014, 'IoU-136': 1.9939237756011992, 'IoU-137': 1.8777333166556311, 'IoU-138': 1.9146818429876933, 'IoU-139': 1.933764222256858, 'IoU-140': 2.0328562498191913, 'IoU-141': 1.8573679408856232, 'IoU-142': 1.9152788450270557, 'IoU-143': 1.9383259107667226, 'IoU-144': 2.079280875109093, 'IoU-145': 2.07616185075537, 'IoU-146': 1.8736750051062117, 'IoU-147': 2.0558078817758707, 'IoU-148': 1.8228618132209111, 'IoU-149': 2.0603588063905525, 'IoU-150': 2.0546294536777623, 'IoU-151': 2.0439227378849845, 'IoU-152': 2.3951091863839187, 'IoU-153': 2.2522293704732266, 'IoU-154': 1.9601388849656391, 'IoU-155': 1.7329108720807285, 'IoU-156': 1.8814473650570354, 'IoU-157': 1.8698968775406208, 'IoU-158': 1.9078925545818213, 'IoU-159': 1.9340568621407417, 'IoU-160': 1.8592203853493434, 'IoU-161': 1.979375279817297, 'IoU-162': 2.0395698663225006, 'IoU-163': 1.9059663929633677, 'IoU-164': 1.814826409816784, 'IoU-165': 1.8993065577288841, 'IoU-166': 1.8641320365458296, 'IoU-167': 1.7309987277403867, 'IoU-168': 1.6033273352225585, 'IoU-169': 1.6437651526326342, 'IoU-170': 1.4113714161416258, 'IoU-171': 1.303600813086826, 'IoU-172': 1.3496368886166767, 'IoU-173': 1.1814805036370755, 'IoU-174': 1.3520381470575045, 'IoU-175': 1.4497003768114338, 'IoU-176': 1.21629864491934, 'IoU-177': 1.4877917757457457, 'IoU-178': 0.8129290953733498, 'IoU-179': 0.5926210956618995, 'IoU-180': 0.24524419966448263, 'IoU-181': 0.6024378289579008, 'IoU-182': 0.5428771542690561, 'IoU-183': 0.08577081037764199, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 10.40078752430697, 'pACC': 21.451717527262197, 'ACC-0': 0.002694667636591927, 'ACC-1': 21.129946894517094, 'ACC-2': 3.412993893996947, 'ACC-3': 9.999283652724083, 'ACC-4': 9.525073853114435, 'ACC-5': 10.304067116657171, 'ACC-6': 12.03338179522866, 'ACC-7': 11.671425081403532, 'ACC-8': 11.051815134243204, 'ACC-9': 23.154972488829667, 'ACC-10': 30.400102988537846, 'ACC-11': 40.65967007649184, 'ACC-12': 41.10438450705211, 'ACC-13': 37.411369814054005, 'ACC-14': 37.035816448063244, 'ACC-15': 36.49928496038643, 'ACC-16': 34.87333515901737, 'ACC-17': 33.45603964155707, 'ACC-18': 32.26603704569831, 'ACC-19': 32.437997250617975, 'ACC-20': 32.7412387770425, 'ACC-21': 32.78700909147615, 'ACC-22': 33.041947288146915, 'ACC-23': 30.952348005592118, 'ACC-24': 30.935515712441735, 'ACC-25': 30.627336269088477, 'ACC-26': 29.550696266382236, 'ACC-27': 31.204706735495936, 'ACC-28': 30.338255932484202, 'ACC-29': 29.798380707725148, 'ACC-30': 29.28097674565983, 'ACC-31': 29.229540383850754, 'ACC-32': 26.825413289860755, 'ACC-33': 25.377222760563136, 'ACC-34': 25.088754864369, 'ACC-35': 25.054073003316148, 'ACC-36': 23.78851798370003, 'ACC-37': 23.08872253828193, 'ACC-38': 21.5904505551946, 'ACC-39': 19.28541696526248, 'ACC-40': 18.015142374057778, 'ACC-41': 17.87763475726557, 'ACC-42': 17.29483813372647, 'ACC-43': 16.90224966174996, 'ACC-44': 16.452121895942405, 'ACC-45': 16.427499436461524, 'ACC-46': 15.896724492336437, 'ACC-47': 15.275052130990144, 'ACC-48': 14.766273655814938, 'ACC-49': 15.204650430646465, 'ACC-50': 14.87275032657404, 'ACC-51': 14.50016209404592, 'ACC-52': 14.886671739480356, 'ACC-53': 14.796788183178366, 'ACC-54': 14.853725144343406, 'ACC-55': 13.88931987428087, 'ACC-56': 13.535626993922442, 'ACC-57': 13.507953824370425, 'ACC-58': 13.664304968294116, 'ACC-59': 13.299737878617087, 'ACC-60': 13.227167281273179, 'ACC-61': 12.680655089426898, 'ACC-62': 12.04845628146199, 'ACC-63': 10.919236512918587, 'ACC-64': 10.522028632453315, 'ACC-65': 10.532814148367342, 'ACC-66': 9.709136965148847, 'ACC-67': 9.216910441384561, 'ACC-68': 9.284206163761379, 'ACC-69': 9.072709052467637, 'ACC-70': 9.005377312013298, 'ACC-71': 9.058380611574904, 'ACC-72': 8.864728134156891, 'ACC-73': 9.216735489613798, 'ACC-74': 9.129082783577463, 'ACC-75': 8.370529157325395, 'ACC-76': 8.524951081502305, 'ACC-77': 8.230995566048714, 'ACC-78': 8.152806274850132, 'ACC-79': 7.96907330287934, 'ACC-80': 7.860973583446006, 'ACC-81': 7.662071739368899, 'ACC-82': 7.400592125678079, 'ACC-83': 7.775613325158298, 'ACC-84': 7.6180674793152745, 'ACC-85': 7.431398716736265, 'ACC-86': 7.604208973506851, 'ACC-87': 7.559125134948111, 'ACC-88': 7.344145866131687, 'ACC-89': 7.43624262889181, 'ACC-90': 7.269123829413838, 'ACC-91': 7.10530777669612, 'ACC-92': 7.519382788149535, 'ACC-93': 7.416464358474942, 'ACC-94': 7.1941194644946735, 'ACC-95': 6.867840425096563, 'ACC-96': 6.574248330812879, 'ACC-97': 6.463260609067651, 'ACC-98': 6.4801246534020525, 'ACC-99': 6.2284645177016165, 'ACC-100': 5.736217985365897, 'ACC-101': 5.816680164588674, 'ACC-102': 5.567897598550068, 'ACC-103': 5.124161707754793, 'ACC-104': 4.875039964585229, 'ACC-105': 4.969313386545086, 'ACC-106': 4.858271992640952, 'ACC-107': 4.861564386077133, 'ACC-108': 4.709311532331591, 'ACC-109': 5.026655497014102, 'ACC-110': 5.082427301953017, 'ACC-111': 4.499258982080497, 'ACC-112': 4.743586920327065, 'ACC-113': 4.489328832179436, 'ACC-114': 4.448729353567078, 'ACC-115': 4.17106430321892, 'ACC-116': 4.819593422953634, 'ACC-117': 4.601885195772494, 'ACC-118': 4.608646691833596, 'ACC-119': 4.803655271179483, 'ACC-120': 4.6746135492327205, 'ACC-121': 4.717193239363435, 'ACC-122': 4.51649730627341, 'ACC-123': 4.624123441536782, 'ACC-124': 4.162375919036855, 'ACC-125': 4.528515939840956, 'ACC-126': 4.8616676836765365, 'ACC-127': 4.357577400031773, 'ACC-128': 4.499683494513295, 'ACC-129': 4.30238227765649, 'ACC-130': 4.421465110939705, 'ACC-131': 4.234229384606898, 'ACC-132': 4.228837215536856, 'ACC-133': 4.624711669966727, 'ACC-134': 4.834330030159414, 'ACC-135': 4.085570948064535, 'ACC-136': 3.9601920657845695, 'ACC-137': 3.7466312832149176, 'ACC-138': 3.871091072924334, 'ACC-139': 3.905954730178979, 'ACC-140': 4.01582276908398, 'ACC-141': 3.6339139494293424, 'ACC-142': 3.739626098522262, 'ACC-143': 3.8163171595889125, 'ACC-144': 4.059657039711191, 'ACC-145': 3.946868221561305, 'ACC-146': 3.512553974092435, 'ACC-147': 3.8047954331683975, 'ACC-148': 3.3643806241332403, 'ACC-149': 3.88116855919819, 'ACC-150': 3.8655047013317576, 'ACC-151': 3.8926421985690887, 'ACC-152': 4.606050644008362, 'ACC-153': 4.620252294838674, 'ACC-154': 3.9924054824244686, 'ACC-155': 3.595718613726172, 'ACC-156': 3.90053455887581, 'ACC-157': 3.9255076333851893, 'ACC-158': 4.058846857883201, 'ACC-159': 4.0387085432692444, 'ACC-160': 3.8032167579061666, 'ACC-161': 4.0538984545477526, 'ACC-162': 4.391537067726666, 'ACC-163': 4.126010636427701, 'ACC-164': 3.933770718451035, 'ACC-165': 4.07588929793188, 'ACC-166': 4.035053848284662, 'ACC-167': 3.812273415012499, 'ACC-168': 3.6627048315634005, 'ACC-169': 3.812996474776844, 'ACC-170': 3.281655947868308, 'ACC-171': 2.9685401968005674, 'ACC-172': 3.31388672815498, 'ACC-173': 2.929976331405478, 'ACC-174': 3.0347766276904493, 'ACC-175': 3.390776865065939, 'ACC-176': 2.904428836777339, 'ACC-177': 3.7106754584595167, 'ACC-178': 1.631412119889282, 'ACC-179': 1.1373942188885349, 'ACC-180': 0.40997832639100545, 'ACC-181': 1.1587447090229073, 'ACC-182': 0.9512211879485132, 'ACC-183': 0.09676257383737767, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 15:13:06] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 15:13:06] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 15:13:06] d2.evaluation.testing INFO: copypaste: 2.8470,0.4242,0.1883,5.7120,13.2151,10.4008,21.4517
[01/29 15:13:06] d2.utils.events INFO:  eta: 1 day, 8:43:23  iter: 19999  total_loss: 24.49  loss_mask: 2.444  loss_mask_0: 2.46  loss_mask_1: 2.409  loss_mask_2: 2.416  loss_mask_3: 2.458  loss_mask_4: 2.46  loss_mask_5: 2.394  loss_mask_6: 2.436  loss_mask_7: 2.425  loss_mask_8: 2.419  time: 3.0059  data_time: 0.0575  lr: 6.9427e-05  max_mem: 27646M
[01/29 15:14:06] d2.utils.events INFO:  eta: 1 day, 8:43:02  iter: 20019  total_loss: 24.58  loss_mask: 2.451  loss_mask_0: 2.466  loss_mask_1: 2.437  loss_mask_2: 2.446  loss_mask_3: 2.464  loss_mask_4: 2.453  loss_mask_5: 2.449  loss_mask_6: 2.435  loss_mask_7: 2.46  loss_mask_8: 2.437  time: 3.0059  data_time: 0.0592  lr: 6.9396e-05  max_mem: 27646M
[01/29 15:15:06] d2.utils.events INFO:  eta: 1 day, 8:42:50  iter: 20039  total_loss: 22.87  loss_mask: 2.291  loss_mask_0: 2.335  loss_mask_1: 2.293  loss_mask_2: 2.289  loss_mask_3: 2.289  loss_mask_4: 2.291  loss_mask_5: 2.282  loss_mask_6: 2.281  loss_mask_7: 2.278  loss_mask_8: 2.28  time: 3.0059  data_time: 0.0620  lr: 6.9364e-05  max_mem: 27646M
[01/29 15:16:06] d2.utils.events INFO:  eta: 1 day, 8:42:26  iter: 20059  total_loss: 24.91  loss_mask: 2.486  loss_mask_0: 2.486  loss_mask_1: 2.483  loss_mask_2: 2.488  loss_mask_3: 2.491  loss_mask_4: 2.497  loss_mask_5: 2.484  loss_mask_6: 2.493  loss_mask_7: 2.494  loss_mask_8: 2.503  time: 3.0058  data_time: 0.0653  lr: 6.9333e-05  max_mem: 27646M
[01/29 15:17:06] d2.utils.events INFO:  eta: 1 day, 8:41:57  iter: 20079  total_loss: 24.52  loss_mask: 2.448  loss_mask_0: 2.477  loss_mask_1: 2.442  loss_mask_2: 2.46  loss_mask_3: 2.454  loss_mask_4: 2.445  loss_mask_5: 2.452  loss_mask_6: 2.446  loss_mask_7: 2.447  loss_mask_8: 2.445  time: 3.0058  data_time: 0.0579  lr: 6.9302e-05  max_mem: 27646M
[01/29 15:18:06] d2.utils.events INFO:  eta: 1 day, 8:42:01  iter: 20099  total_loss: 24.72  loss_mask: 2.473  loss_mask_0: 2.5  loss_mask_1: 2.454  loss_mask_2: 2.467  loss_mask_3: 2.469  loss_mask_4: 2.461  loss_mask_5: 2.461  loss_mask_6: 2.465  loss_mask_7: 2.468  loss_mask_8: 2.478  time: 3.0058  data_time: 0.0585  lr: 6.9271e-05  max_mem: 27646M
[01/29 15:19:06] d2.utils.events INFO:  eta: 1 day, 8:42:37  iter: 20119  total_loss: 26.3  loss_mask: 2.618  loss_mask_0: 2.661  loss_mask_1: 2.599  loss_mask_2: 2.647  loss_mask_3: 2.64  loss_mask_4: 2.626  loss_mask_5: 2.626  loss_mask_6: 2.629  loss_mask_7: 2.631  loss_mask_8: 2.625  time: 3.0058  data_time: 0.0714  lr: 6.9239e-05  max_mem: 27646M
[01/29 15:20:06] d2.utils.events INFO:  eta: 1 day, 8:42:17  iter: 20139  total_loss: 25.92  loss_mask: 2.566  loss_mask_0: 2.632  loss_mask_1: 2.578  loss_mask_2: 2.591  loss_mask_3: 2.59  loss_mask_4: 2.571  loss_mask_5: 2.57  loss_mask_6: 2.581  loss_mask_7: 2.594  loss_mask_8: 2.569  time: 3.0058  data_time: 0.0559  lr: 6.9208e-05  max_mem: 27646M
[01/29 15:21:05] d2.utils.events INFO:  eta: 1 day, 8:42:46  iter: 20159  total_loss: 26.33  loss_mask: 2.625  loss_mask_0: 2.685  loss_mask_1: 2.608  loss_mask_2: 2.636  loss_mask_3: 2.633  loss_mask_4: 2.631  loss_mask_5: 2.592  loss_mask_6: 2.604  loss_mask_7: 2.626  loss_mask_8: 2.644  time: 3.0058  data_time: 0.0584  lr: 6.9177e-05  max_mem: 27646M
[01/29 15:22:05] d2.utils.events INFO:  eta: 1 day, 8:42:05  iter: 20179  total_loss: 25.36  loss_mask: 2.545  loss_mask_0: 2.548  loss_mask_1: 2.528  loss_mask_2: 2.531  loss_mask_3: 2.535  loss_mask_4: 2.531  loss_mask_5: 2.535  loss_mask_6: 2.531  loss_mask_7: 2.538  loss_mask_8: 2.533  time: 3.0058  data_time: 0.0643  lr: 6.9146e-05  max_mem: 27646M
[01/29 15:23:05] d2.utils.events INFO:  eta: 1 day, 8:40:54  iter: 20199  total_loss: 26.03  loss_mask: 2.607  loss_mask_0: 2.64  loss_mask_1: 2.578  loss_mask_2: 2.596  loss_mask_3: 2.6  loss_mask_4: 2.609  loss_mask_5: 2.587  loss_mask_6: 2.585  loss_mask_7: 2.596  loss_mask_8: 2.608  time: 3.0057  data_time: 0.0545  lr: 6.9114e-05  max_mem: 27646M
[01/29 15:24:04] d2.utils.events INFO:  eta: 1 day, 8:40:44  iter: 20219  total_loss: 24.86  loss_mask: 2.49  loss_mask_0: 2.543  loss_mask_1: 2.472  loss_mask_2: 2.479  loss_mask_3: 2.487  loss_mask_4: 2.521  loss_mask_5: 2.452  loss_mask_6: 2.487  loss_mask_7: 2.501  loss_mask_8: 2.486  time: 3.0057  data_time: 0.0650  lr: 6.9083e-05  max_mem: 27646M
[01/29 15:25:03] d2.utils.events INFO:  eta: 1 day, 8:40:01  iter: 20239  total_loss: 25.21  loss_mask: 2.5  loss_mask_0: 2.532  loss_mask_1: 2.511  loss_mask_2: 2.51  loss_mask_3: 2.512  loss_mask_4: 2.507  loss_mask_5: 2.502  loss_mask_6: 2.486  loss_mask_7: 2.503  loss_mask_8: 2.512  time: 3.0056  data_time: 0.0575  lr: 6.9052e-05  max_mem: 27646M
[01/29 15:26:03] d2.utils.events INFO:  eta: 1 day, 8:39:48  iter: 20259  total_loss: 25.98  loss_mask: 2.61  loss_mask_0: 2.656  loss_mask_1: 2.563  loss_mask_2: 2.625  loss_mask_3: 2.599  loss_mask_4: 2.616  loss_mask_5: 2.594  loss_mask_6: 2.58  loss_mask_7: 2.609  loss_mask_8: 2.568  time: 3.0056  data_time: 0.0692  lr: 6.9021e-05  max_mem: 27646M
[01/29 15:27:02] d2.utils.events INFO:  eta: 1 day, 8:39:11  iter: 20279  total_loss: 23.78  loss_mask: 2.368  loss_mask_0: 2.523  loss_mask_1: 2.407  loss_mask_2: 2.386  loss_mask_3: 2.358  loss_mask_4: 2.369  loss_mask_5: 2.372  loss_mask_6: 2.368  loss_mask_7: 2.351  loss_mask_8: 2.369  time: 3.0056  data_time: 0.0590  lr: 6.8989e-05  max_mem: 27646M
[01/29 15:28:01] d2.utils.events INFO:  eta: 1 day, 8:38:36  iter: 20299  total_loss: 26.1  loss_mask: 2.605  loss_mask_0: 2.678  loss_mask_1: 2.666  loss_mask_2: 2.588  loss_mask_3: 2.599  loss_mask_4: 2.599  loss_mask_5: 2.593  loss_mask_6: 2.59  loss_mask_7: 2.623  loss_mask_8: 2.592  time: 3.0055  data_time: 0.0483  lr: 6.8958e-05  max_mem: 27646M
[01/29 15:29:00] d2.utils.events INFO:  eta: 1 day, 8:37:55  iter: 20319  total_loss: 24.88  loss_mask: 2.495  loss_mask_0: 2.538  loss_mask_1: 2.495  loss_mask_2: 2.476  loss_mask_3: 2.483  loss_mask_4: 2.477  loss_mask_5: 2.486  loss_mask_6: 2.489  loss_mask_7: 2.494  loss_mask_8: 2.488  time: 3.0055  data_time: 0.0589  lr: 6.8927e-05  max_mem: 27646M
[01/29 15:29:59] d2.utils.events INFO:  eta: 1 day, 8:37:20  iter: 20339  total_loss: 23.47  loss_mask: 2.358  loss_mask_0: 2.406  loss_mask_1: 2.344  loss_mask_2: 2.314  loss_mask_3: 2.357  loss_mask_4: 2.363  loss_mask_5: 2.326  loss_mask_6: 2.323  loss_mask_7: 2.359  loss_mask_8: 2.334  time: 3.0054  data_time: 0.0594  lr: 6.8896e-05  max_mem: 27646M
[01/29 15:30:59] d2.utils.events INFO:  eta: 1 day, 8:37:31  iter: 20359  total_loss: 25.28  loss_mask: 2.525  loss_mask_0: 2.557  loss_mask_1: 2.527  loss_mask_2: 2.528  loss_mask_3: 2.524  loss_mask_4: 2.534  loss_mask_5: 2.519  loss_mask_6: 2.535  loss_mask_7: 2.532  loss_mask_8: 2.508  time: 3.0054  data_time: 0.0599  lr: 6.8864e-05  max_mem: 27646M
[01/29 15:31:59] d2.utils.events INFO:  eta: 1 day, 8:36:46  iter: 20379  total_loss: 26.44  loss_mask: 2.606  loss_mask_0: 2.716  loss_mask_1: 2.596  loss_mask_2: 2.607  loss_mask_3: 2.63  loss_mask_4: 2.63  loss_mask_5: 2.618  loss_mask_6: 2.622  loss_mask_7: 2.64  loss_mask_8: 2.638  time: 3.0054  data_time: 0.0553  lr: 6.8833e-05  max_mem: 27646M
[01/29 15:32:58] d2.utils.events INFO:  eta: 1 day, 8:35:38  iter: 20399  total_loss: 24.19  loss_mask: 2.446  loss_mask_0: 2.395  loss_mask_1: 2.376  loss_mask_2: 2.42  loss_mask_3: 2.419  loss_mask_4: 2.39  loss_mask_5: 2.395  loss_mask_6: 2.415  loss_mask_7: 2.442  loss_mask_8: 2.425  time: 3.0053  data_time: 0.0624  lr: 6.8802e-05  max_mem: 27646M
[01/29 15:33:58] d2.utils.events INFO:  eta: 1 day, 8:34:33  iter: 20419  total_loss: 29.32  loss_mask: 2.932  loss_mask_0: 2.948  loss_mask_1: 2.886  loss_mask_2: 2.906  loss_mask_3: 2.93  loss_mask_4: 2.93  loss_mask_5: 2.914  loss_mask_6: 2.93  loss_mask_7: 2.954  loss_mask_8: 2.911  time: 3.0053  data_time: 0.0563  lr: 6.877e-05  max_mem: 27646M
[01/29 15:34:57] d2.utils.events INFO:  eta: 1 day, 8:33:40  iter: 20439  total_loss: 25.12  loss_mask: 2.525  loss_mask_0: 2.516  loss_mask_1: 2.486  loss_mask_2: 2.498  loss_mask_3: 2.542  loss_mask_4: 2.517  loss_mask_5: 2.512  loss_mask_6: 2.54  loss_mask_7: 2.507  loss_mask_8: 2.505  time: 3.0053  data_time: 0.0589  lr: 6.8739e-05  max_mem: 27646M
[01/29 15:35:56] d2.utils.events INFO:  eta: 1 day, 8:32:34  iter: 20459  total_loss: 27.29  loss_mask: 2.693  loss_mask_0: 2.849  loss_mask_1: 2.708  loss_mask_2: 2.714  loss_mask_3: 2.699  loss_mask_4: 2.714  loss_mask_5: 2.707  loss_mask_6: 2.754  loss_mask_7: 2.737  loss_mask_8: 2.721  time: 3.0052  data_time: 0.0612  lr: 6.8708e-05  max_mem: 27646M
[01/29 15:36:56] d2.utils.events INFO:  eta: 1 day, 8:31:41  iter: 20479  total_loss: 26.01  loss_mask: 2.596  loss_mask_0: 2.658  loss_mask_1: 2.582  loss_mask_2: 2.597  loss_mask_3: 2.586  loss_mask_4: 2.587  loss_mask_5: 2.58  loss_mask_6: 2.638  loss_mask_7: 2.608  loss_mask_8: 2.62  time: 3.0052  data_time: 0.0544  lr: 6.8677e-05  max_mem: 27646M
[01/29 15:37:55] d2.utils.events INFO:  eta: 1 day, 8:31:09  iter: 20499  total_loss: 24.83  loss_mask: 2.453  loss_mask_0: 2.476  loss_mask_1: 2.48  loss_mask_2: 2.555  loss_mask_3: 2.491  loss_mask_4: 2.437  loss_mask_5: 2.531  loss_mask_6: 2.492  loss_mask_7: 2.457  loss_mask_8: 2.438  time: 3.0051  data_time: 0.0613  lr: 6.8645e-05  max_mem: 27646M
[01/29 15:38:54] d2.utils.events INFO:  eta: 1 day, 8:29:51  iter: 20519  total_loss: 25.53  loss_mask: 2.539  loss_mask_0: 2.585  loss_mask_1: 2.539  loss_mask_2: 2.554  loss_mask_3: 2.534  loss_mask_4: 2.54  loss_mask_5: 2.513  loss_mask_6: 2.558  loss_mask_7: 2.543  loss_mask_8: 2.552  time: 3.0051  data_time: 0.0564  lr: 6.8614e-05  max_mem: 27646M
[01/29 15:39:53] d2.utils.events INFO:  eta: 1 day, 8:27:33  iter: 20539  total_loss: 24.56  loss_mask: 2.471  loss_mask_0: 2.459  loss_mask_1: 2.408  loss_mask_2: 2.451  loss_mask_3: 2.476  loss_mask_4: 2.48  loss_mask_5: 2.447  loss_mask_6: 2.464  loss_mask_7: 2.444  loss_mask_8: 2.439  time: 3.0050  data_time: 0.0601  lr: 6.8583e-05  max_mem: 27646M
[01/29 15:40:52] d2.utils.events INFO:  eta: 1 day, 8:26:23  iter: 20559  total_loss: 26.19  loss_mask: 2.6  loss_mask_0: 2.675  loss_mask_1: 2.624  loss_mask_2: 2.643  loss_mask_3: 2.627  loss_mask_4: 2.627  loss_mask_5: 2.596  loss_mask_6: 2.606  loss_mask_7: 2.613  loss_mask_8: 2.661  time: 3.0050  data_time: 0.0532  lr: 6.8552e-05  max_mem: 27646M
[01/29 15:41:51] d2.utils.events INFO:  eta: 1 day, 8:25:22  iter: 20579  total_loss: 24.25  loss_mask: 2.418  loss_mask_0: 2.491  loss_mask_1: 2.378  loss_mask_2: 2.433  loss_mask_3: 2.441  loss_mask_4: 2.415  loss_mask_5: 2.42  loss_mask_6: 2.4  loss_mask_7: 2.425  loss_mask_8: 2.455  time: 3.0049  data_time: 0.0550  lr: 6.852e-05  max_mem: 27646M
[01/29 15:42:51] d2.utils.events INFO:  eta: 1 day, 8:24:25  iter: 20599  total_loss: 23.47  loss_mask: 2.339  loss_mask_0: 2.422  loss_mask_1: 2.322  loss_mask_2: 2.342  loss_mask_3: 2.35  loss_mask_4: 2.341  loss_mask_5: 2.339  loss_mask_6: 2.342  loss_mask_7: 2.343  loss_mask_8: 2.351  time: 3.0049  data_time: 0.0537  lr: 6.8489e-05  max_mem: 27646M
[01/29 15:43:50] d2.utils.events INFO:  eta: 1 day, 8:23:47  iter: 20619  total_loss: 25.49  loss_mask: 2.535  loss_mask_0: 2.661  loss_mask_1: 2.532  loss_mask_2: 2.557  loss_mask_3: 2.557  loss_mask_4: 2.554  loss_mask_5: 2.549  loss_mask_6: 2.54  loss_mask_7: 2.537  loss_mask_8: 2.542  time: 3.0049  data_time: 0.0569  lr: 6.8458e-05  max_mem: 27646M
[01/29 15:44:50] d2.utils.events INFO:  eta: 1 day, 8:23:45  iter: 20639  total_loss: 26.38  loss_mask: 2.634  loss_mask_0: 2.618  loss_mask_1: 2.642  loss_mask_2: 2.641  loss_mask_3: 2.624  loss_mask_4: 2.625  loss_mask_5: 2.668  loss_mask_6: 2.64  loss_mask_7: 2.622  loss_mask_8: 2.638  time: 3.0048  data_time: 0.0674  lr: 6.8426e-05  max_mem: 27646M
[01/29 15:45:49] d2.utils.events INFO:  eta: 1 day, 8:22:46  iter: 20659  total_loss: 25.16  loss_mask: 2.511  loss_mask_0: 2.521  loss_mask_1: 2.499  loss_mask_2: 2.54  loss_mask_3: 2.512  loss_mask_4: 2.52  loss_mask_5: 2.512  loss_mask_6: 2.513  loss_mask_7: 2.518  loss_mask_8: 2.541  time: 3.0048  data_time: 0.0545  lr: 6.8395e-05  max_mem: 27646M
[01/29 15:46:48] d2.utils.events INFO:  eta: 1 day, 8:22:06  iter: 20679  total_loss: 25.29  loss_mask: 2.53  loss_mask_0: 2.56  loss_mask_1: 2.514  loss_mask_2: 2.509  loss_mask_3: 2.519  loss_mask_4: 2.534  loss_mask_5: 2.527  loss_mask_6: 2.531  loss_mask_7: 2.536  loss_mask_8: 2.529  time: 3.0048  data_time: 0.0551  lr: 6.8364e-05  max_mem: 27646M
[01/29 15:47:48] d2.utils.events INFO:  eta: 1 day, 8:21:07  iter: 20699  total_loss: 24.97  loss_mask: 2.515  loss_mask_0: 2.519  loss_mask_1: 2.483  loss_mask_2: 2.515  loss_mask_3: 2.492  loss_mask_4: 2.502  loss_mask_5: 2.479  loss_mask_6: 2.502  loss_mask_7: 2.495  loss_mask_8: 2.482  time: 3.0047  data_time: 0.0568  lr: 6.8332e-05  max_mem: 27646M
[01/29 15:48:47] d2.utils.events INFO:  eta: 1 day, 8:19:48  iter: 20719  total_loss: 26.78  loss_mask: 2.697  loss_mask_0: 2.649  loss_mask_1: 2.638  loss_mask_2: 2.677  loss_mask_3: 2.673  loss_mask_4: 2.685  loss_mask_5: 2.672  loss_mask_6: 2.686  loss_mask_7: 2.671  loss_mask_8: 2.673  time: 3.0047  data_time: 0.0528  lr: 6.8301e-05  max_mem: 27646M
[01/29 15:49:46] d2.utils.events INFO:  eta: 1 day, 8:18:05  iter: 20739  total_loss: 26.03  loss_mask: 2.593  loss_mask_0: 2.684  loss_mask_1: 2.588  loss_mask_2: 2.612  loss_mask_3: 2.591  loss_mask_4: 2.603  loss_mask_5: 2.586  loss_mask_6: 2.59  loss_mask_7: 2.582  loss_mask_8: 2.591  time: 3.0046  data_time: 0.0539  lr: 6.827e-05  max_mem: 27646M
[01/29 15:50:45] d2.utils.events INFO:  eta: 1 day, 8:17:05  iter: 20759  total_loss: 24.18  loss_mask: 2.387  loss_mask_0: 2.483  loss_mask_1: 2.372  loss_mask_2: 2.424  loss_mask_3: 2.423  loss_mask_4: 2.433  loss_mask_5: 2.389  loss_mask_6: 2.413  loss_mask_7: 2.398  loss_mask_8: 2.407  time: 3.0046  data_time: 0.0548  lr: 6.8239e-05  max_mem: 27646M
[01/29 15:51:45] d2.utils.events INFO:  eta: 1 day, 8:16:53  iter: 20779  total_loss: 27.44  loss_mask: 2.759  loss_mask_0: 2.825  loss_mask_1: 2.738  loss_mask_2: 2.734  loss_mask_3: 2.736  loss_mask_4: 2.719  loss_mask_5: 2.727  loss_mask_6: 2.738  loss_mask_7: 2.728  loss_mask_8: 2.734  time: 3.0045  data_time: 0.0549  lr: 6.8207e-05  max_mem: 27646M
[01/29 15:52:44] d2.utils.events INFO:  eta: 1 day, 8:16:08  iter: 20799  total_loss: 26.82  loss_mask: 2.672  loss_mask_0: 2.687  loss_mask_1: 2.648  loss_mask_2: 2.715  loss_mask_3: 2.684  loss_mask_4: 2.681  loss_mask_5: 2.661  loss_mask_6: 2.684  loss_mask_7: 2.662  loss_mask_8: 2.669  time: 3.0045  data_time: 0.0651  lr: 6.8176e-05  max_mem: 27646M
[01/29 15:53:43] d2.utils.events INFO:  eta: 1 day, 8:14:31  iter: 20819  total_loss: 24.72  loss_mask: 2.467  loss_mask_0: 2.508  loss_mask_1: 2.456  loss_mask_2: 2.469  loss_mask_3: 2.464  loss_mask_4: 2.463  loss_mask_5: 2.478  loss_mask_6: 2.476  loss_mask_7: 2.437  loss_mask_8: 2.46  time: 3.0045  data_time: 0.0495  lr: 6.8145e-05  max_mem: 27646M
[01/29 15:54:43] d2.utils.events INFO:  eta: 1 day, 8:12:55  iter: 20839  total_loss: 26.74  loss_mask: 2.657  loss_mask_0: 2.713  loss_mask_1: 2.654  loss_mask_2: 2.67  loss_mask_3: 2.682  loss_mask_4: 2.689  loss_mask_5: 2.659  loss_mask_6: 2.654  loss_mask_7: 2.693  loss_mask_8: 2.669  time: 3.0044  data_time: 0.0709  lr: 6.8113e-05  max_mem: 27646M
[01/29 15:55:42] d2.utils.events INFO:  eta: 1 day, 8:11:44  iter: 20859  total_loss: 24.54  loss_mask: 2.443  loss_mask_0: 2.507  loss_mask_1: 2.423  loss_mask_2: 2.49  loss_mask_3: 2.486  loss_mask_4: 2.444  loss_mask_5: 2.455  loss_mask_6: 2.445  loss_mask_7: 2.454  loss_mask_8: 2.447  time: 3.0044  data_time: 0.0607  lr: 6.8082e-05  max_mem: 27646M
[01/29 15:56:41] d2.utils.events INFO:  eta: 1 day, 8:09:50  iter: 20879  total_loss: 27.42  loss_mask: 2.761  loss_mask_0: 2.744  loss_mask_1: 2.691  loss_mask_2: 2.745  loss_mask_3: 2.762  loss_mask_4: 2.752  loss_mask_5: 2.735  loss_mask_6: 2.736  loss_mask_7: 2.738  loss_mask_8: 2.738  time: 3.0043  data_time: 0.0638  lr: 6.8051e-05  max_mem: 27646M
[01/29 15:57:40] d2.utils.events INFO:  eta: 1 day, 8:08:51  iter: 20899  total_loss: 24.14  loss_mask: 2.411  loss_mask_0: 2.421  loss_mask_1: 2.399  loss_mask_2: 2.414  loss_mask_3: 2.412  loss_mask_4: 2.405  loss_mask_5: 2.416  loss_mask_6: 2.411  loss_mask_7: 2.405  loss_mask_8: 2.414  time: 3.0043  data_time: 0.0561  lr: 6.8019e-05  max_mem: 27646M
[01/29 15:58:40] d2.utils.events INFO:  eta: 1 day, 8:07:52  iter: 20919  total_loss: 25.92  loss_mask: 2.582  loss_mask_0: 2.55  loss_mask_1: 2.555  loss_mask_2: 2.592  loss_mask_3: 2.593  loss_mask_4: 2.604  loss_mask_5: 2.6  loss_mask_6: 2.569  loss_mask_7: 2.599  loss_mask_8: 2.589  time: 3.0043  data_time: 0.0704  lr: 6.7988e-05  max_mem: 27646M
[01/29 15:59:39] d2.utils.events INFO:  eta: 1 day, 8:07:26  iter: 20939  total_loss: 24.18  loss_mask: 2.415  loss_mask_0: 2.484  loss_mask_1: 2.409  loss_mask_2: 2.399  loss_mask_3: 2.401  loss_mask_4: 2.413  loss_mask_5: 2.409  loss_mask_6: 2.424  loss_mask_7: 2.423  loss_mask_8: 2.406  time: 3.0042  data_time: 0.0732  lr: 6.7957e-05  max_mem: 27646M
[01/29 16:00:38] d2.utils.events INFO:  eta: 1 day, 8:06:11  iter: 20959  total_loss: 28.06  loss_mask: 2.766  loss_mask_0: 3.005  loss_mask_1: 2.796  loss_mask_2: 2.798  loss_mask_3: 2.762  loss_mask_4: 2.773  loss_mask_5: 2.848  loss_mask_6: 2.825  loss_mask_7: 2.772  loss_mask_8: 2.808  time: 3.0042  data_time: 0.0538  lr: 6.7925e-05  max_mem: 27646M
[01/29 16:01:37] d2.utils.events INFO:  eta: 1 day, 8:04:54  iter: 20979  total_loss: 24.85  loss_mask: 2.486  loss_mask_0: 2.848  loss_mask_1: 2.455  loss_mask_2: 2.437  loss_mask_3: 2.509  loss_mask_4: 2.438  loss_mask_5: 2.458  loss_mask_6: 2.46  loss_mask_7: 2.451  loss_mask_8: 2.455  time: 3.0041  data_time: 0.0523  lr: 6.7894e-05  max_mem: 27646M
[01/29 16:02:36] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 16:02:37] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 16:02:37] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 16:16:04] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.169856358094058, 'error_1pix': 0.4699539991959145, 'error_3pix': 0.22938152975391593, 'mIoU': 4.770428552278734, 'fwIoU': 14.774562245074083, 'IoU-0': 0.0019541279249169273, 'IoU-1': 48.481173204286, 'IoU-2': 2.2432746274246425, 'IoU-3': 2.7755022144464467, 'IoU-4': 2.676000233077913, 'IoU-5': 2.918293170365445, 'IoU-6': 3.0440223067373444, 'IoU-7': 2.4459912823686656, 'IoU-8': 4.979413681856812, 'IoU-9': 13.29040200555108, 'IoU-10': 17.45359339969084, 'IoU-11': 26.27447899824467, 'IoU-12': 25.336344617979655, 'IoU-13': 23.46648931579126, 'IoU-14': 23.03119754500155, 'IoU-15': 22.352758853432185, 'IoU-16': 21.505285674934058, 'IoU-17': 18.821799448545597, 'IoU-18': 18.641698607082816, 'IoU-19': 18.83375884265383, 'IoU-20': 18.620134266942063, 'IoU-21': 18.746548526921845, 'IoU-22': 19.574010153015177, 'IoU-23': 18.204609941442275, 'IoU-24': 17.85836399831258, 'IoU-25': 17.817779287144276, 'IoU-26': 16.905064972400933, 'IoU-27': 18.229947677953735, 'IoU-28': 17.09266314244004, 'IoU-29': 16.621613054808996, 'IoU-30': 15.549715840546652, 'IoU-31': 15.17477373505907, 'IoU-32': 13.634941323303714, 'IoU-33': 12.778114184002733, 'IoU-34': 11.820166709614911, 'IoU-35': 11.444464472499902, 'IoU-36': 11.07672769022886, 'IoU-37': 9.93319779820151, 'IoU-38': 8.76643260475574, 'IoU-39': 7.762566160798952, 'IoU-40': 7.0967181409278295, 'IoU-41': 6.955244335259687, 'IoU-42': 6.334284999436752, 'IoU-43': 6.0635747615721565, 'IoU-44': 5.9171433674692535, 'IoU-45': 5.513582436324204, 'IoU-46': 5.365553169785483, 'IoU-47': 5.170717866456374, 'IoU-48': 5.089702416541718, 'IoU-49': 5.0043639115343765, 'IoU-50': 5.085904806656857, 'IoU-51': 5.074808143184759, 'IoU-52': 4.995802007090728, 'IoU-53': 4.878466932040477, 'IoU-54': 5.084427335557522, 'IoU-55': 5.042171956420307, 'IoU-56': 4.925478720113887, 'IoU-57': 5.242352627904765, 'IoU-58': 5.090558694192809, 'IoU-59': 4.810281067150685, 'IoU-60': 4.678936266018517, 'IoU-61': 4.585927928878308, 'IoU-62': 4.408354368901509, 'IoU-63': 4.092327849181043, 'IoU-64': 3.853562900224093, 'IoU-65': 3.714688990441697, 'IoU-66': 3.556755449051573, 'IoU-67': 3.472531433180094, 'IoU-68': 3.493787587828075, 'IoU-69': 3.4771061713103166, 'IoU-70': 3.2234551452035096, 'IoU-71': 3.0589190651177183, 'IoU-72': 3.070954434692835, 'IoU-73': 2.8828885144963663, 'IoU-74': 2.863899070193363, 'IoU-75': 2.6098447747565126, 'IoU-76': 2.881406695604457, 'IoU-77': 2.492719822237181, 'IoU-78': 2.4192660945636124, 'IoU-79': 2.431645383159779, 'IoU-80': 2.422362459011845, 'IoU-81': 2.3152658045307044, 'IoU-82': 2.119084903367589, 'IoU-83': 2.24298411588673, 'IoU-84': 2.2590433721396916, 'IoU-85': 2.241038823908061, 'IoU-86': 2.1134600833346857, 'IoU-87': 2.008102110225467, 'IoU-88': 1.9166817107705907, 'IoU-89': 2.003639248598136, 'IoU-90': 1.9411455298073774, 'IoU-91': 1.8268137761237344, 'IoU-92': 1.810199013927376, 'IoU-93': 1.9152464259512885, 'IoU-94': 2.039077278000361, 'IoU-95': 1.731488591402923, 'IoU-96': 1.5795013435151262, 'IoU-97': 1.559599139040633, 'IoU-98': 1.6437233200972803, 'IoU-99': 1.5105435156151612, 'IoU-100': 1.4414922451834127, 'IoU-101': 1.3704418031370014, 'IoU-102': 1.3054639442651332, 'IoU-103': 1.3248110195293146, 'IoU-104': 1.3282465698122115, 'IoU-105': 1.3449976331790856, 'IoU-106': 1.373344634925887, 'IoU-107': 1.4243069939437192, 'IoU-108': 1.4721871133682767, 'IoU-109': 1.6958320105836446, 'IoU-110': 1.573284403145855, 'IoU-111': 1.4024943670141437, 'IoU-112': 1.2953420374605564, 'IoU-113': 1.2839651998209778, 'IoU-114': 1.2639436256828795, 'IoU-115': 1.261350286946809, 'IoU-116': 1.2895546938574567, 'IoU-117': 1.33971721321875, 'IoU-118': 1.3195938846471167, 'IoU-119': 1.3351002221475234, 'IoU-120': 1.6145458824913943, 'IoU-121': 1.3886490801044655, 'IoU-122': 1.2878459759735037, 'IoU-123': 1.4528587333464733, 'IoU-124': 1.2249166968433716, 'IoU-125': 1.3011158828883582, 'IoU-126': 1.3425042420667022, 'IoU-127': 1.380541485628431, 'IoU-128': 1.3882715379884483, 'IoU-129': 1.2799871456005947, 'IoU-130': 1.2552751264984712, 'IoU-131': 1.318258750722521, 'IoU-132': 1.2015882171056775, 'IoU-133': 1.1908511162404547, 'IoU-134': 1.2589908183821348, 'IoU-135': 1.2697608611767965, 'IoU-136': 1.283636384059128, 'IoU-137': 1.124487910383434, 'IoU-138': 1.0259065470165971, 'IoU-139': 1.190300590240961, 'IoU-140': 1.0337880750380721, 'IoU-141': 1.0295066758568294, 'IoU-142': 1.067173722824258, 'IoU-143': 0.9817811042836778, 'IoU-144': 0.9665107963141246, 'IoU-145': 1.0974136484453856, 'IoU-146': 1.2410470147176282, 'IoU-147': 1.3159169047503754, 'IoU-148': 1.2802503409887225, 'IoU-149': 1.266471042611184, 'IoU-150': 1.3570883320630494, 'IoU-151': 1.4978996963917557, 'IoU-152': 1.588381680480975, 'IoU-153': 1.5075715196776274, 'IoU-154': 1.3224032103830718, 'IoU-155': 1.3071187325621236, 'IoU-156': 1.3506016031650354, 'IoU-157': 1.439736146022827, 'IoU-158': 1.4960588454757384, 'IoU-159': 1.3467436898382756, 'IoU-160': 1.2390400087778985, 'IoU-161': 1.4909861200963164, 'IoU-162': 1.7860818891410355, 'IoU-163': 1.5029960290161732, 'IoU-164': 1.9509555502271416, 'IoU-165': 1.8004265126629226, 'IoU-166': 1.576348360332467, 'IoU-167': 1.3690951912807927, 'IoU-168': 1.259459454671241, 'IoU-169': 1.1561088684007519, 'IoU-170': 1.3743925530029568, 'IoU-171': 1.2853723375707984, 'IoU-172': 1.5817257209014297, 'IoU-173': 1.8773363425102312, 'IoU-174': 1.5295420962243442, 'IoU-175': 1.3848395138381093, 'IoU-176': 1.2455565309687933, 'IoU-177': 0.5375194065896153, 'IoU-178': 0.8486031658818008, 'IoU-179': 1.1245088411632784, 'IoU-180': 1.4524683001309602, 'IoU-181': 0.6028212922981453, 'IoU-182': 0.6029169318842241, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 8.574721317650285, 'pACC': 22.257314355736362, 'ACC-0': 0.009875278374675738, 'ACC-1': 49.230939148318896, 'ACC-2': 4.281616463724899, 'ACC-3': 11.598817795914972, 'ACC-4': 10.530656250125714, 'ACC-5': 12.32918220512181, 'ACC-6': 13.853376034989143, 'ACC-7': 12.77515852266719, 'ACC-8': 13.402445348319446, 'ACC-9': 22.924508137833218, 'ACC-10': 27.97070811477362, 'ACC-11': 39.300750595501256, 'ACC-12': 40.02582123844654, 'ACC-13': 36.98078970700482, 'ACC-14': 36.7972934753822, 'ACC-15': 36.893169136045664, 'ACC-16': 34.83681088537758, 'ACC-17': 32.879815043570865, 'ACC-18': 31.69650983897178, 'ACC-19': 32.16706828591517, 'ACC-20': 32.0115741060062, 'ACC-21': 32.15412145442068, 'ACC-22': 33.00866575671529, 'ACC-23': 32.6707892301377, 'ACC-24': 32.23890722813197, 'ACC-25': 32.46446975479769, 'ACC-26': 31.15354199911356, 'ACC-27': 32.44340800175485, 'ACC-28': 31.240158781150427, 'ACC-29': 29.667358330475224, 'ACC-30': 28.420481325289693, 'ACC-31': 27.36352092466993, 'ACC-32': 24.820223843788025, 'ACC-33': 23.88795593708744, 'ACC-34': 22.554494064156685, 'ACC-35': 21.351940555086564, 'ACC-36': 20.784288987884302, 'ACC-37': 19.114766309393193, 'ACC-38': 16.707715137368314, 'ACC-39': 14.565350039780911, 'ACC-40': 13.167864433649749, 'ACC-41': 13.317781558364242, 'ACC-42': 12.17727045499369, 'ACC-43': 11.559189688233275, 'ACC-44': 10.932562410981786, 'ACC-45': 10.290505834482138, 'ACC-46': 10.13366227641507, 'ACC-47': 9.702564632991823, 'ACC-48': 9.639418869865079, 'ACC-49': 9.338036988000486, 'ACC-50': 9.348273214730922, 'ACC-51': 9.459645621389337, 'ACC-52': 9.390849494216784, 'ACC-53': 9.069385571747418, 'ACC-54': 9.256631461395196, 'ACC-55': 9.129010279622927, 'ACC-56': 9.030695741056045, 'ACC-57': 9.51043839428935, 'ACC-58': 9.349419147987666, 'ACC-59': 9.057229661544309, 'ACC-60': 8.94880815593734, 'ACC-61': 8.846531903072782, 'ACC-62': 8.537305392201878, 'ACC-63': 8.031959280885745, 'ACC-64': 7.587949116921477, 'ACC-65': 7.395467699233439, 'ACC-66': 7.170524412814065, 'ACC-67': 7.054139423155259, 'ACC-68': 7.077444578001465, 'ACC-69': 6.9030220084886835, 'ACC-70': 6.396063556828835, 'ACC-71': 6.225037998089208, 'ACC-72': 6.307224305468321, 'ACC-73': 5.890715377078003, 'ACC-74': 5.841810827918561, 'ACC-75': 5.34955920846442, 'ACC-76': 5.774045469738312, 'ACC-77': 5.090180006327043, 'ACC-78': 4.952678406831932, 'ACC-79': 4.900016517910795, 'ACC-80': 4.779254228936539, 'ACC-81': 4.538751070616953, 'ACC-82': 4.14086308494463, 'ACC-83': 4.303301061682373, 'ACC-84': 4.324423702222056, 'ACC-85': 4.248155210012809, 'ACC-86': 3.9533922649706184, 'ACC-87': 3.7419165714811458, 'ACC-88': 3.5761695611331996, 'ACC-89': 3.714809176658923, 'ACC-90': 3.589723748960463, 'ACC-91': 3.400567874872666, 'ACC-92': 3.390336640455128, 'ACC-93': 3.5955981155321575, 'ACC-94': 3.7704719122444663, 'ACC-95': 3.1814719094403294, 'ACC-96': 2.8951339321473957, 'ACC-97': 2.828588202119939, 'ACC-98': 2.969743459297996, 'ACC-99': 2.7293511991218806, 'ACC-100': 2.610820121202095, 'ACC-101': 2.508335181774882, 'ACC-102': 2.419664703217037, 'ACC-103': 2.4454047416643054, 'ACC-104': 2.446890140429404, 'ACC-105': 2.4774035633809905, 'ACC-106': 2.542390437014247, 'ACC-107': 2.6552484889625734, 'ACC-108': 2.7126704504471144, 'ACC-109': 3.113583176348686, 'ACC-110': 2.9201766004680882, 'ACC-111': 2.5922934763157888, 'ACC-112': 2.3887266197276147, 'ACC-113': 2.3657412946192484, 'ACC-114': 2.349127932720043, 'ACC-115': 2.3633349871453704, 'ACC-116': 2.450199735572426, 'ACC-117': 2.5670101187228114, 'ACC-118': 2.5237047365806817, 'ACC-119': 2.50757333038249, 'ACC-120': 3.013068519240838, 'ACC-121': 2.5571089017349444, 'ACC-122': 2.376234821251663, 'ACC-123': 2.6914514209474034, 'ACC-124': 2.322837183507973, 'ACC-125': 2.461323764389039, 'ACC-126': 2.5648002258672666, 'ACC-127': 2.655442532871067, 'ACC-128': 2.700846819882155, 'ACC-129': 2.4894591289058012, 'ACC-130': 2.43877743181226, 'ACC-131': 2.531180364627673, 'ACC-132': 2.263306223254349, 'ACC-133': 2.220362394278988, 'ACC-134': 2.277776820336062, 'ACC-135': 2.286357676301237, 'ACC-136': 2.3293363306000745, 'ACC-137': 2.0650014463253035, 'ACC-138': 1.876570551057187, 'ACC-139': 2.1765882108918775, 'ACC-140': 1.8806931406507015, 'ACC-141': 1.8565520862963043, 'ACC-142': 1.9384993463230342, 'ACC-143': 1.8040118506217802, 'ACC-144': 1.7759025270758122, 'ACC-145': 1.9362687001051007, 'ACC-146': 2.179616641155103, 'ACC-147': 2.321392259673551, 'ACC-148': 2.267950888312449, 'ACC-149': 2.2646488227497263, 'ACC-150': 2.3959541759562395, 'ACC-151': 2.6869292100570936, 'ACC-152': 2.855574381279925, 'ACC-153': 2.820681947269096, 'ACC-154': 2.4697446302369355, 'ACC-155': 2.4685514823880905, 'ACC-156': 2.621471555908912, 'ACC-157': 2.7424928511445654, 'ACC-158': 2.8466546515353164, 'ACC-159': 2.5197980078653313, 'ACC-160': 2.2990374609781474, 'ACC-161': 2.6893059647211137, 'ACC-162': 3.2655362524955294, 'ACC-163': 2.905680048061122, 'ACC-164': 3.818505259085677, 'ACC-165': 3.45396042906104, 'ACC-166': 3.053109602034735, 'ACC-167': 2.6900968789247948, 'ACC-168': 2.4998241789155355, 'ACC-169': 2.1668979966414748, 'ACC-170': 2.614925394324006, 'ACC-171': 2.639559595818585, 'ACC-172': 3.4816831499796272, 'ACC-173': 4.745195726859151, 'ACC-174': 3.3302204551512538, 'ACC-175': 2.738135516446377, 'ACC-176': 2.609668853029951, 'ACC-177': 0.8625701045824729, 'ACC-178': 1.348435710270788, 'ACC-179': 1.8748947514714505, 'ACC-180': 2.504741101967557, 'ACC-181': 0.7731281132973772, 'ACC-182': 0.7225964192385966, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 16:16:04] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 16:16:04] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 16:16:04] d2.evaluation.testing INFO: copypaste: 3.1699,0.4700,0.2294,4.7704,14.7746,8.5747,22.2573
[01/29 16:16:04] d2.utils.events INFO:  eta: 1 day, 8:03:39  iter: 20999  total_loss: 24.77  loss_mask: 2.446  loss_mask_0: 2.591  loss_mask_1: 2.458  loss_mask_2: 2.454  loss_mask_3: 2.455  loss_mask_4: 2.469  loss_mask_5: 2.477  loss_mask_6: 2.491  loss_mask_7: 2.479  loss_mask_8: 2.483  time: 3.0041  data_time: 0.0515  lr: 6.7863e-05  max_mem: 27646M
[01/29 16:17:03] d2.utils.events INFO:  eta: 1 day, 8:01:42  iter: 21019  total_loss: 23.82  loss_mask: 2.391  loss_mask_0: 2.423  loss_mask_1: 2.342  loss_mask_2: 2.369  loss_mask_3: 2.394  loss_mask_4: 2.362  loss_mask_5: 2.375  loss_mask_6: 2.396  loss_mask_7: 2.409  loss_mask_8: 2.388  time: 3.0040  data_time: 0.0496  lr: 6.7832e-05  max_mem: 27646M
[01/29 16:18:03] d2.utils.events INFO:  eta: 1 day, 8:00:50  iter: 21039  total_loss: 26.87  loss_mask: 2.689  loss_mask_0: 2.746  loss_mask_1: 2.759  loss_mask_2: 2.682  loss_mask_3: 2.696  loss_mask_4: 2.663  loss_mask_5: 2.679  loss_mask_6: 2.736  loss_mask_7: 2.683  loss_mask_8: 2.662  time: 3.0040  data_time: 0.0515  lr: 6.78e-05  max_mem: 27646M
[01/29 16:19:01] d2.utils.events INFO:  eta: 1 day, 7:59:08  iter: 21059  total_loss: 24.62  loss_mask: 2.466  loss_mask_0: 2.492  loss_mask_1: 2.465  loss_mask_2: 2.452  loss_mask_3: 2.471  loss_mask_4: 2.449  loss_mask_5: 2.446  loss_mask_6: 2.456  loss_mask_7: 2.467  loss_mask_8: 2.454  time: 3.0039  data_time: 0.0484  lr: 6.7769e-05  max_mem: 27646M
[01/29 16:20:00] d2.utils.events INFO:  eta: 1 day, 7:57:24  iter: 21079  total_loss: 24.65  loss_mask: 2.486  loss_mask_0: 2.499  loss_mask_1: 2.462  loss_mask_2: 2.447  loss_mask_3: 2.443  loss_mask_4: 2.458  loss_mask_5: 2.474  loss_mask_6: 2.464  loss_mask_7: 2.457  loss_mask_8: 2.466  time: 3.0039  data_time: 0.0453  lr: 6.7738e-05  max_mem: 27646M
[01/29 16:20:58] d2.utils.events INFO:  eta: 1 day, 7:54:54  iter: 21099  total_loss: 23.33  loss_mask: 2.314  loss_mask_0: 2.353  loss_mask_1: 2.295  loss_mask_2: 2.332  loss_mask_3: 2.423  loss_mask_4: 2.353  loss_mask_5: 2.287  loss_mask_6: 2.337  loss_mask_7: 2.36  loss_mask_8: 2.328  time: 3.0038  data_time: 0.0444  lr: 6.7706e-05  max_mem: 27646M
[01/29 16:21:57] d2.utils.events INFO:  eta: 1 day, 7:53:03  iter: 21119  total_loss: 28.24  loss_mask: 2.818  loss_mask_0: 2.881  loss_mask_1: 2.791  loss_mask_2: 2.817  loss_mask_3: 2.804  loss_mask_4: 2.813  loss_mask_5: 2.808  loss_mask_6: 2.848  loss_mask_7: 2.817  loss_mask_8: 2.819  time: 3.0037  data_time: 0.0480  lr: 6.7675e-05  max_mem: 27646M
[01/29 16:22:56] d2.utils.events INFO:  eta: 1 day, 7:51:55  iter: 21139  total_loss: 27.18  loss_mask: 2.715  loss_mask_0: 2.763  loss_mask_1: 2.7  loss_mask_2: 2.71  loss_mask_3: 2.721  loss_mask_4: 2.717  loss_mask_5: 2.692  loss_mask_6: 2.714  loss_mask_7: 2.699  loss_mask_8: 2.71  time: 3.0037  data_time: 0.0513  lr: 6.7644e-05  max_mem: 27646M
[01/29 16:23:55] d2.utils.events INFO:  eta: 1 day, 7:49:44  iter: 21159  total_loss: 27.61  loss_mask: 2.752  loss_mask_0: 2.79  loss_mask_1: 2.734  loss_mask_2: 2.754  loss_mask_3: 2.767  loss_mask_4: 2.768  loss_mask_5: 2.739  loss_mask_6: 2.741  loss_mask_7: 2.758  loss_mask_8: 2.763  time: 3.0036  data_time: 0.0445  lr: 6.7612e-05  max_mem: 27646M
[01/29 16:24:53] d2.utils.events INFO:  eta: 1 day, 7:47:39  iter: 21179  total_loss: 26.28  loss_mask: 2.638  loss_mask_0: 2.659  loss_mask_1: 2.621  loss_mask_2: 2.62  loss_mask_3: 2.626  loss_mask_4: 2.621  loss_mask_5: 2.632  loss_mask_6: 2.627  loss_mask_7: 2.638  loss_mask_8: 2.644  time: 3.0035  data_time: 0.0429  lr: 6.7581e-05  max_mem: 27646M
[01/29 16:25:51] d2.utils.events INFO:  eta: 1 day, 7:46:30  iter: 21199  total_loss: 23.14  loss_mask: 2.302  loss_mask_0: 2.392  loss_mask_1: 2.307  loss_mask_2: 2.315  loss_mask_3: 2.316  loss_mask_4: 2.329  loss_mask_5: 2.318  loss_mask_6: 2.31  loss_mask_7: 2.331  loss_mask_8: 2.315  time: 3.0034  data_time: 0.0457  lr: 6.755e-05  max_mem: 27646M
[01/29 16:26:50] d2.utils.events INFO:  eta: 1 day, 7:45:12  iter: 21219  total_loss: 24.58  loss_mask: 2.454  loss_mask_0: 2.428  loss_mask_1: 2.433  loss_mask_2: 2.456  loss_mask_3: 2.472  loss_mask_4: 2.479  loss_mask_5: 2.453  loss_mask_6: 2.445  loss_mask_7: 2.47  loss_mask_8: 2.467  time: 3.0034  data_time: 0.0503  lr: 6.7518e-05  max_mem: 27646M
[01/29 16:27:49] d2.utils.events INFO:  eta: 1 day, 7:44:16  iter: 21239  total_loss: 24.4  loss_mask: 2.499  loss_mask_0: 2.45  loss_mask_1: 2.401  loss_mask_2: 2.442  loss_mask_3: 2.458  loss_mask_4: 2.457  loss_mask_5: 2.439  loss_mask_6: 2.421  loss_mask_7: 2.471  loss_mask_8: 2.452  time: 3.0033  data_time: 0.0487  lr: 6.7487e-05  max_mem: 27646M
[01/29 16:28:48] d2.utils.events INFO:  eta: 1 day, 7:43:00  iter: 21259  total_loss: 24.34  loss_mask: 2.529  loss_mask_0: 2.439  loss_mask_1: 2.375  loss_mask_2: 2.452  loss_mask_3: 2.396  loss_mask_4: 2.437  loss_mask_5: 2.405  loss_mask_6: 2.421  loss_mask_7: 2.408  loss_mask_8: 2.474  time: 3.0033  data_time: 0.0473  lr: 6.7456e-05  max_mem: 27646M
[01/29 16:29:47] d2.utils.events INFO:  eta: 1 day, 7:41:55  iter: 21279  total_loss: 28.6  loss_mask: 3.041  loss_mask_0: 2.931  loss_mask_1: 2.794  loss_mask_2: 2.857  loss_mask_3: 2.804  loss_mask_4: 2.812  loss_mask_5: 2.829  loss_mask_6: 2.866  loss_mask_7: 2.801  loss_mask_8: 2.8  time: 3.0032  data_time: 0.0479  lr: 6.7424e-05  max_mem: 27646M
[01/29 16:30:46] d2.utils.events INFO:  eta: 1 day, 7:40:56  iter: 21299  total_loss: 24.59  loss_mask: 2.511  loss_mask_0: 2.491  loss_mask_1: 2.405  loss_mask_2: 2.442  loss_mask_3: 2.449  loss_mask_4: 2.434  loss_mask_5: 2.441  loss_mask_6: 2.458  loss_mask_7: 2.442  loss_mask_8: 2.438  time: 3.0031  data_time: 0.0477  lr: 6.7393e-05  max_mem: 27646M
[01/29 16:31:44] d2.utils.events INFO:  eta: 1 day, 7:39:54  iter: 21319  total_loss: 24.61  loss_mask: 2.464  loss_mask_0: 2.54  loss_mask_1: 2.447  loss_mask_2: 2.453  loss_mask_3: 2.439  loss_mask_4: 2.434  loss_mask_5: 2.437  loss_mask_6: 2.438  loss_mask_7: 2.428  loss_mask_8: 2.446  time: 3.0031  data_time: 0.0455  lr: 6.7362e-05  max_mem: 27646M
[01/29 16:32:43] d2.utils.events INFO:  eta: 1 day, 7:38:51  iter: 21339  total_loss: 27.03  loss_mask: 2.769  loss_mask_0: 2.736  loss_mask_1: 2.667  loss_mask_2: 2.703  loss_mask_3: 2.675  loss_mask_4: 2.662  loss_mask_5: 2.691  loss_mask_6: 2.726  loss_mask_7: 2.665  loss_mask_8: 2.716  time: 3.0030  data_time: 0.0469  lr: 6.733e-05  max_mem: 27646M
[01/29 16:33:43] d2.utils.events INFO:  eta: 1 day, 7:37:48  iter: 21359  total_loss: 24.62  loss_mask: 2.522  loss_mask_0: 2.463  loss_mask_1: 2.416  loss_mask_2: 2.455  loss_mask_3: 2.444  loss_mask_4: 2.439  loss_mask_5: 2.445  loss_mask_6: 2.456  loss_mask_7: 2.465  loss_mask_8: 2.435  time: 3.0030  data_time: 0.0466  lr: 6.7299e-05  max_mem: 27646M
[01/29 16:34:42] d2.utils.events INFO:  eta: 1 day, 7:36:54  iter: 21379  total_loss: 24.25  loss_mask: 2.43  loss_mask_0: 2.664  loss_mask_1: 2.38  loss_mask_2: 2.403  loss_mask_3: 2.463  loss_mask_4: 2.421  loss_mask_5: 2.383  loss_mask_6: 2.399  loss_mask_7: 2.412  loss_mask_8: 2.385  time: 3.0030  data_time: 0.0611  lr: 6.7267e-05  max_mem: 27646M
[01/29 16:35:42] d2.utils.events INFO:  eta: 1 day, 7:35:50  iter: 21399  total_loss: 23.87  loss_mask: 2.39  loss_mask_0: 2.473  loss_mask_1: 2.366  loss_mask_2: 2.375  loss_mask_3: 2.364  loss_mask_4: 2.372  loss_mask_5: 2.377  loss_mask_6: 2.374  loss_mask_7: 2.366  loss_mask_8: 2.368  time: 3.0029  data_time: 0.0529  lr: 6.7236e-05  max_mem: 27646M
[01/29 16:36:41] d2.utils.events INFO:  eta: 1 day, 7:34:51  iter: 21419  total_loss: 26.71  loss_mask: 2.641  loss_mask_0: 2.879  loss_mask_1: 2.667  loss_mask_2: 2.636  loss_mask_3: 2.645  loss_mask_4: 2.66  loss_mask_5: 2.635  loss_mask_6: 2.618  loss_mask_7: 2.647  loss_mask_8: 2.628  time: 3.0029  data_time: 0.0494  lr: 6.7205e-05  max_mem: 27646M
[01/29 16:37:40] d2.utils.events INFO:  eta: 1 day, 7:33:38  iter: 21439  total_loss: 24.72  loss_mask: 2.473  loss_mask_0: 2.494  loss_mask_1: 2.454  loss_mask_2: 2.481  loss_mask_3: 2.473  loss_mask_4: 2.502  loss_mask_5: 2.466  loss_mask_6: 2.468  loss_mask_7: 2.489  loss_mask_8: 2.474  time: 3.0028  data_time: 0.0478  lr: 6.7173e-05  max_mem: 27646M
[01/29 16:38:38] d2.utils.events INFO:  eta: 1 day, 7:31:38  iter: 21459  total_loss: 24.23  loss_mask: 2.435  loss_mask_0: 2.42  loss_mask_1: 2.393  loss_mask_2: 2.417  loss_mask_3: 2.421  loss_mask_4: 2.419  loss_mask_5: 2.401  loss_mask_6: 2.435  loss_mask_7: 2.425  loss_mask_8: 2.406  time: 3.0027  data_time: 0.0444  lr: 6.7142e-05  max_mem: 27646M
[01/29 16:39:37] d2.utils.events INFO:  eta: 1 day, 7:30:27  iter: 21479  total_loss: 25.05  loss_mask: 2.542  loss_mask_0: 2.471  loss_mask_1: 2.478  loss_mask_2: 2.538  loss_mask_3: 2.486  loss_mask_4: 2.485  loss_mask_5: 2.467  loss_mask_6: 2.501  loss_mask_7: 2.531  loss_mask_8: 2.493  time: 3.0027  data_time: 0.0470  lr: 6.7111e-05  max_mem: 27646M
[01/29 16:40:35] d2.utils.events INFO:  eta: 1 day, 7:28:46  iter: 21499  total_loss: 25.45  loss_mask: 2.534  loss_mask_0: 2.613  loss_mask_1: 2.525  loss_mask_2: 2.548  loss_mask_3: 2.546  loss_mask_4: 2.565  loss_mask_5: 2.537  loss_mask_6: 2.531  loss_mask_7: 2.549  loss_mask_8: 2.55  time: 3.0026  data_time: 0.0499  lr: 6.7079e-05  max_mem: 27646M
[01/29 16:41:34] d2.utils.events INFO:  eta: 1 day, 7:27:16  iter: 21519  total_loss: 26.77  loss_mask: 2.647  loss_mask_0: 2.667  loss_mask_1: 2.658  loss_mask_2: 2.679  loss_mask_3: 2.672  loss_mask_4: 2.656  loss_mask_5: 2.662  loss_mask_6: 2.664  loss_mask_7: 2.657  loss_mask_8: 2.68  time: 3.0025  data_time: 0.0470  lr: 6.7048e-05  max_mem: 27646M
[01/29 16:42:33] d2.utils.events INFO:  eta: 1 day, 7:26:29  iter: 21539  total_loss: 24.04  loss_mask: 2.419  loss_mask_0: 2.394  loss_mask_1: 2.391  loss_mask_2: 2.407  loss_mask_3: 2.395  loss_mask_4: 2.41  loss_mask_5: 2.384  loss_mask_6: 2.397  loss_mask_7: 2.428  loss_mask_8: 2.402  time: 3.0025  data_time: 0.0451  lr: 6.7017e-05  max_mem: 27646M
[01/29 16:43:32] d2.utils.events INFO:  eta: 1 day, 7:25:30  iter: 21559  total_loss: 26.63  loss_mask: 2.645  loss_mask_0: 2.691  loss_mask_1: 2.628  loss_mask_2: 2.649  loss_mask_3: 2.654  loss_mask_4: 2.656  loss_mask_5: 2.661  loss_mask_6: 2.654  loss_mask_7: 2.65  loss_mask_8: 2.665  time: 3.0024  data_time: 0.0534  lr: 6.6985e-05  max_mem: 27646M
[01/29 16:44:32] d2.utils.events INFO:  eta: 1 day, 7:24:51  iter: 21579  total_loss: 25.65  loss_mask: 2.593  loss_mask_0: 2.596  loss_mask_1: 2.541  loss_mask_2: 2.538  loss_mask_3: 2.548  loss_mask_4: 2.577  loss_mask_5: 2.551  loss_mask_6: 2.563  loss_mask_7: 2.571  loss_mask_8: 2.561  time: 3.0024  data_time: 0.0596  lr: 6.6954e-05  max_mem: 27646M
[01/29 16:45:32] d2.utils.events INFO:  eta: 1 day, 7:24:34  iter: 21599  total_loss: 22.91  loss_mask: 2.278  loss_mask_0: 2.321  loss_mask_1: 2.282  loss_mask_2: 2.288  loss_mask_3: 2.273  loss_mask_4: 2.309  loss_mask_5: 2.267  loss_mask_6: 2.288  loss_mask_7: 2.281  loss_mask_8: 2.299  time: 3.0024  data_time: 0.0608  lr: 6.6922e-05  max_mem: 27646M
[01/29 16:46:32] d2.utils.events INFO:  eta: 1 day, 7:23:47  iter: 21619  total_loss: 25.56  loss_mask: 2.564  loss_mask_0: 2.572  loss_mask_1: 2.527  loss_mask_2: 2.555  loss_mask_3: 2.558  loss_mask_4: 2.552  loss_mask_5: 2.558  loss_mask_6: 2.538  loss_mask_7: 2.541  loss_mask_8: 2.552  time: 3.0024  data_time: 0.0576  lr: 6.6891e-05  max_mem: 27646M
[01/29 16:47:32] d2.utils.events INFO:  eta: 1 day, 7:23:33  iter: 21639  total_loss: 24.36  loss_mask: 2.429  loss_mask_0: 2.485  loss_mask_1: 2.396  loss_mask_2: 2.445  loss_mask_3: 2.432  loss_mask_4: 2.44  loss_mask_5: 2.429  loss_mask_6: 2.423  loss_mask_7: 2.441  loss_mask_8: 2.434  time: 3.0024  data_time: 0.0733  lr: 6.686e-05  max_mem: 27646M
[01/29 16:48:31] d2.utils.events INFO:  eta: 1 day, 7:22:42  iter: 21659  total_loss: 25.48  loss_mask: 2.537  loss_mask_0: 2.576  loss_mask_1: 2.513  loss_mask_2: 2.532  loss_mask_3: 2.536  loss_mask_4: 2.549  loss_mask_5: 2.536  loss_mask_6: 2.535  loss_mask_7: 2.55  loss_mask_8: 2.545  time: 3.0024  data_time: 0.0598  lr: 6.6828e-05  max_mem: 27646M
[01/29 16:49:31] d2.utils.events INFO:  eta: 1 day, 7:22:10  iter: 21679  total_loss: 21.63  loss_mask: 2.162  loss_mask_0: 2.242  loss_mask_1: 2.141  loss_mask_2: 2.155  loss_mask_3: 2.158  loss_mask_4: 2.172  loss_mask_5: 2.155  loss_mask_6: 2.167  loss_mask_7: 2.163  loss_mask_8: 2.164  time: 3.0024  data_time: 0.0659  lr: 6.6797e-05  max_mem: 27646M
[01/29 16:50:31] d2.utils.events INFO:  eta: 1 day, 7:21:15  iter: 21699  total_loss: 24.47  loss_mask: 2.44  loss_mask_0: 2.496  loss_mask_1: 2.426  loss_mask_2: 2.447  loss_mask_3: 2.434  loss_mask_4: 2.439  loss_mask_5: 2.431  loss_mask_6: 2.438  loss_mask_7: 2.449  loss_mask_8: 2.437  time: 3.0023  data_time: 0.0678  lr: 6.6766e-05  max_mem: 27646M
[01/29 16:51:31] d2.utils.events INFO:  eta: 1 day, 7:20:33  iter: 21719  total_loss: 22.04  loss_mask: 2.193  loss_mask_0: 2.24  loss_mask_1: 2.205  loss_mask_2: 2.2  loss_mask_3: 2.199  loss_mask_4: 2.199  loss_mask_5: 2.207  loss_mask_6: 2.203  loss_mask_7: 2.201  loss_mask_8: 2.196  time: 3.0023  data_time: 0.0647  lr: 6.6734e-05  max_mem: 27646M
[01/29 16:52:30] d2.utils.events INFO:  eta: 1 day, 7:19:46  iter: 21739  total_loss: 25.95  loss_mask: 2.581  loss_mask_0: 2.693  loss_mask_1: 2.576  loss_mask_2: 2.587  loss_mask_3: 2.593  loss_mask_4: 2.596  loss_mask_5: 2.589  loss_mask_6: 2.574  loss_mask_7: 2.579  loss_mask_8: 2.588  time: 3.0023  data_time: 0.0723  lr: 6.6703e-05  max_mem: 27646M
[01/29 16:53:30] d2.utils.events INFO:  eta: 1 day, 7:19:08  iter: 21759  total_loss: 24.89  loss_mask: 2.482  loss_mask_0: 2.511  loss_mask_1: 2.464  loss_mask_2: 2.495  loss_mask_3: 2.48  loss_mask_4: 2.487  loss_mask_5: 2.481  loss_mask_6: 2.479  loss_mask_7: 2.486  loss_mask_8: 2.489  time: 3.0023  data_time: 0.0631  lr: 6.6671e-05  max_mem: 27646M
[01/29 16:54:30] d2.utils.events INFO:  eta: 1 day, 7:18:09  iter: 21779  total_loss: 24.37  loss_mask: 2.419  loss_mask_0: 2.48  loss_mask_1: 2.415  loss_mask_2: 2.427  loss_mask_3: 2.434  loss_mask_4: 2.453  loss_mask_5: 2.417  loss_mask_6: 2.416  loss_mask_7: 2.447  loss_mask_8: 2.43  time: 3.0023  data_time: 0.0568  lr: 6.664e-05  max_mem: 27646M
[01/29 16:55:30] d2.utils.events INFO:  eta: 1 day, 7:17:31  iter: 21799  total_loss: 25.45  loss_mask: 2.529  loss_mask_0: 2.591  loss_mask_1: 2.532  loss_mask_2: 2.533  loss_mask_3: 2.541  loss_mask_4: 2.553  loss_mask_5: 2.54  loss_mask_6: 2.542  loss_mask_7: 2.549  loss_mask_8: 2.545  time: 3.0023  data_time: 0.0637  lr: 6.6609e-05  max_mem: 27646M
[01/29 16:56:30] d2.utils.events INFO:  eta: 1 day, 7:17:48  iter: 21819  total_loss: 27.94  loss_mask: 2.773  loss_mask_0: 2.84  loss_mask_1: 2.76  loss_mask_2: 2.795  loss_mask_3: 2.794  loss_mask_4: 2.79  loss_mask_5: 2.796  loss_mask_6: 2.785  loss_mask_7: 2.793  loss_mask_8: 2.798  time: 3.0023  data_time: 0.0622  lr: 6.6577e-05  max_mem: 27646M
[01/29 16:57:30] d2.utils.events INFO:  eta: 1 day, 7:17:14  iter: 21839  total_loss: 25.44  loss_mask: 2.543  loss_mask_0: 2.614  loss_mask_1: 2.513  loss_mask_2: 2.552  loss_mask_3: 2.544  loss_mask_4: 2.562  loss_mask_5: 2.529  loss_mask_6: 2.542  loss_mask_7: 2.542  loss_mask_8: 2.555  time: 3.0023  data_time: 0.0595  lr: 6.6546e-05  max_mem: 27646M
[01/29 16:58:30] d2.utils.events INFO:  eta: 1 day, 7:16:44  iter: 21859  total_loss: 25.21  loss_mask: 2.507  loss_mask_0: 2.594  loss_mask_1: 2.507  loss_mask_2: 2.537  loss_mask_3: 2.52  loss_mask_4: 2.517  loss_mask_5: 2.507  loss_mask_6: 2.498  loss_mask_7: 2.53  loss_mask_8: 2.517  time: 3.0023  data_time: 0.0724  lr: 6.6515e-05  max_mem: 27646M
[01/29 16:59:29] d2.utils.events INFO:  eta: 1 day, 7:15:37  iter: 21879  total_loss: 23.47  loss_mask: 2.331  loss_mask_0: 2.428  loss_mask_1: 2.338  loss_mask_2: 2.336  loss_mask_3: 2.343  loss_mask_4: 2.364  loss_mask_5: 2.327  loss_mask_6: 2.326  loss_mask_7: 2.342  loss_mask_8: 2.347  time: 3.0022  data_time: 0.0463  lr: 6.6483e-05  max_mem: 27646M
[01/29 17:00:29] d2.utils.events INFO:  eta: 1 day, 7:14:38  iter: 21899  total_loss: 25.81  loss_mask: 2.579  loss_mask_0: 2.776  loss_mask_1: 2.554  loss_mask_2: 2.568  loss_mask_3: 2.575  loss_mask_4: 2.563  loss_mask_5: 2.563  loss_mask_6: 2.573  loss_mask_7: 2.571  loss_mask_8: 2.572  time: 3.0022  data_time: 0.0537  lr: 6.6452e-05  max_mem: 27646M
[01/29 17:01:28] d2.utils.events INFO:  eta: 1 day, 7:13:56  iter: 21919  total_loss: 24.54  loss_mask: 2.441  loss_mask_0: 2.54  loss_mask_1: 2.451  loss_mask_2: 2.434  loss_mask_3: 2.441  loss_mask_4: 2.46  loss_mask_5: 2.428  loss_mask_6: 2.438  loss_mask_7: 2.462  loss_mask_8: 2.448  time: 3.0022  data_time: 0.0615  lr: 6.642e-05  max_mem: 27646M
[01/29 17:02:27] d2.utils.events INFO:  eta: 1 day, 7:12:32  iter: 21939  total_loss: 25.56  loss_mask: 2.565  loss_mask_0: 2.52  loss_mask_1: 2.542  loss_mask_2: 2.565  loss_mask_3: 2.567  loss_mask_4: 2.561  loss_mask_5: 2.554  loss_mask_6: 2.565  loss_mask_7: 2.563  loss_mask_8: 2.557  time: 3.0021  data_time: 0.0503  lr: 6.6389e-05  max_mem: 27646M
[01/29 17:03:27] d2.utils.events INFO:  eta: 1 day, 7:12:03  iter: 21959  total_loss: 25.94  loss_mask: 2.577  loss_mask_0: 2.692  loss_mask_1: 2.564  loss_mask_2: 2.581  loss_mask_3: 2.583  loss_mask_4: 2.588  loss_mask_5: 2.577  loss_mask_6: 2.569  loss_mask_7: 2.584  loss_mask_8: 2.597  time: 3.0021  data_time: 0.0616  lr: 6.6358e-05  max_mem: 27646M
[01/29 17:04:26] d2.utils.events INFO:  eta: 1 day, 7:11:06  iter: 21979  total_loss: 24.52  loss_mask: 2.441  loss_mask_0: 2.541  loss_mask_1: 2.457  loss_mask_2: 2.438  loss_mask_3: 2.441  loss_mask_4: 2.462  loss_mask_5: 2.442  loss_mask_6: 2.431  loss_mask_7: 2.429  loss_mask_8: 2.439  time: 3.0021  data_time: 0.0618  lr: 6.6326e-05  max_mem: 27646M
[01/29 17:05:26] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 17:05:26] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 17:05:26] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 17:19:24] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.7499038817482457, 'error_1pix': 0.44075751719916456, 'error_3pix': 0.1862343383093763, 'mIoU': 5.717881675979616, 'fwIoU': 15.385003610133264, 'IoU-0': 0.00037613128126463515, 'IoU-1': 51.8251916432336, 'IoU-2': 2.2572651511398267, 'IoU-3': 3.035130276641929, 'IoU-4': 2.8714405320509386, 'IoU-5': 3.2293112177924463, 'IoU-6': 3.2835663880052457, 'IoU-7': 2.7057554272054496, 'IoU-8': 5.995808910219605, 'IoU-9': 16.376757576495848, 'IoU-10': 19.746303898077052, 'IoU-11': 26.022010737198347, 'IoU-12': 23.587857170312915, 'IoU-13': 21.547774548349224, 'IoU-14': 20.6611989275121, 'IoU-15': 19.689064637277482, 'IoU-16': 20.144052924488765, 'IoU-17': 19.151873675656336, 'IoU-18': 18.660266116227948, 'IoU-19': 18.51570267989449, 'IoU-20': 19.159417948949393, 'IoU-21': 19.56603352836898, 'IoU-22': 20.557379927282472, 'IoU-23': 18.54742230442187, 'IoU-24': 18.384080013344324, 'IoU-25': 17.96174579312419, 'IoU-26': 16.81526798956072, 'IoU-27': 17.057990534214788, 'IoU-28': 15.973864369818763, 'IoU-29': 16.235054306322784, 'IoU-30': 15.00313062864712, 'IoU-31': 14.568023916791597, 'IoU-32': 12.891474566778605, 'IoU-33': 12.282839246730333, 'IoU-34': 11.59867883791518, 'IoU-35': 11.15956947813102, 'IoU-36': 10.365524185976641, 'IoU-37': 9.6111861681431, 'IoU-38': 8.535981925105638, 'IoU-39': 7.644875864467333, 'IoU-40': 7.133792693492841, 'IoU-41': 6.936993191303614, 'IoU-42': 6.435287702225902, 'IoU-43': 6.230537400817846, 'IoU-44': 6.106198219505301, 'IoU-45': 5.823566864505174, 'IoU-46': 5.498847931687198, 'IoU-47': 5.15062925593688, 'IoU-48': 5.05752443658595, 'IoU-49': 4.886981931315799, 'IoU-50': 4.872647612660681, 'IoU-51': 4.855377718411368, 'IoU-52': 4.753646105839603, 'IoU-53': 4.66007960251661, 'IoU-54': 4.903650773419279, 'IoU-55': 4.907758549179526, 'IoU-56': 5.142171843026457, 'IoU-57': 5.476331561808865, 'IoU-58': 5.418498146757361, 'IoU-59': 5.478067375895955, 'IoU-60': 5.549447725584181, 'IoU-61': 5.454523531184712, 'IoU-62': 5.356277444554679, 'IoU-63': 5.284359170905794, 'IoU-64': 5.2397221114798285, 'IoU-65': 5.338251310745029, 'IoU-66': 5.381771572809297, 'IoU-67': 5.377680703267324, 'IoU-68': 5.508873642363444, 'IoU-69': 5.634101995307858, 'IoU-70': 5.552340184528153, 'IoU-71': 5.615572400500691, 'IoU-72': 5.769354786367578, 'IoU-73': 6.003510632612708, 'IoU-74': 6.065858289728465, 'IoU-75': 5.897060186987335, 'IoU-76': 5.994590265396326, 'IoU-77': 5.992534686684732, 'IoU-78': 5.653626358023386, 'IoU-79': 5.6710172286689575, 'IoU-80': 5.854182190274804, 'IoU-81': 5.823322896954134, 'IoU-82': 5.812954606412308, 'IoU-83': 5.802069196709899, 'IoU-84': 5.797129794880571, 'IoU-85': 5.465408386421395, 'IoU-86': 5.351400076748261, 'IoU-87': 5.340901398490637, 'IoU-88': 5.212706491192687, 'IoU-89': 5.26477436281626, 'IoU-90': 5.193649691535697, 'IoU-91': 5.074125488922431, 'IoU-92': 5.10783410875879, 'IoU-93': 5.145301493179218, 'IoU-94': 5.244725150285605, 'IoU-95': 5.110081559754288, 'IoU-96': 4.8778188151738515, 'IoU-97': 4.7862465737251485, 'IoU-98': 4.8561137402072285, 'IoU-99': 4.448143670114254, 'IoU-100': 4.395588704315892, 'IoU-101': 4.375667360026266, 'IoU-102': 4.180122174105708, 'IoU-103': 3.984713161861571, 'IoU-104': 3.9562396074292203, 'IoU-105': 3.8522143734627674, 'IoU-106': 3.7911752585714034, 'IoU-107': 3.6370936377475975, 'IoU-108': 3.6612358216848078, 'IoU-109': 3.771033182244818, 'IoU-110': 3.5307632572104093, 'IoU-111': 3.2098628702281378, 'IoU-112': 3.233938920601689, 'IoU-113': 3.0972390719085294, 'IoU-114': 3.0404167460096483, 'IoU-115': 2.9280377338559136, 'IoU-116': 2.9694010255305194, 'IoU-117': 3.068970775811412, 'IoU-118': 3.0535751617174265, 'IoU-119': 3.25520895600901, 'IoU-120': 2.892106128042157, 'IoU-121': 2.7259414766653403, 'IoU-122': 2.561977816465079, 'IoU-123': 2.628943634896722, 'IoU-124': 2.4069121957382515, 'IoU-125': 2.357876980593891, 'IoU-126': 2.337935259184472, 'IoU-127': 2.507694084596431, 'IoU-128': 2.4952718027373852, 'IoU-129': 2.410208011009517, 'IoU-130': 2.421416061859718, 'IoU-131': 2.393250071674312, 'IoU-132': 2.3297190683323867, 'IoU-133': 2.075820667279735, 'IoU-134': 1.9993853974424138, 'IoU-135': 2.0473195443967076, 'IoU-136': 1.9025004881607208, 'IoU-137': 2.0036513397961064, 'IoU-138': 1.7854633985973405, 'IoU-139': 1.77695783120228, 'IoU-140': 1.7978607283601875, 'IoU-141': 1.7764109077026469, 'IoU-142': 1.6116018558845615, 'IoU-143': 1.5685238161504962, 'IoU-144': 1.704147628963658, 'IoU-145': 1.955600452129456, 'IoU-146': 2.0522308941830256, 'IoU-147': 2.3068002884207734, 'IoU-148': 2.234557303595693, 'IoU-149': 1.9870908548934776, 'IoU-150': 1.842082932624314, 'IoU-151': 1.991173916492147, 'IoU-152': 2.0268152784822133, 'IoU-153': 1.715813667509166, 'IoU-154': 1.7126824373017353, 'IoU-155': 1.8584811125268088, 'IoU-156': 1.8307750034891515, 'IoU-157': 1.7365962355537403, 'IoU-158': 1.8792237470823303, 'IoU-159': 1.7899235014310657, 'IoU-160': 2.1027843915091156, 'IoU-161': 2.0920186679469523, 'IoU-162': 1.885696893669615, 'IoU-163': 1.8651553602750628, 'IoU-164': 1.6289473555827672, 'IoU-165': 1.5852234921778257, 'IoU-166': 1.370811087869202, 'IoU-167': 1.283075379352263, 'IoU-168': 1.1441359706572078, 'IoU-169': 1.0237433290037294, 'IoU-170': 1.2092557102254253, 'IoU-171': 1.3734201002169173, 'IoU-172': 1.3703253999120968, 'IoU-173': 1.1976718000721172, 'IoU-174': 1.2006752126752795, 'IoU-175': 1.3379439427937547, 'IoU-176': 1.0056986093775855, 'IoU-177': 0.6430141180134248, 'IoU-178': 0.5725935565048498, 'IoU-179': 0.8340356391742403, 'IoU-180': 0.6122562033126947, 'IoU-181': 0.5011817211138171, 'IoU-182': 0.2544003652928322, 'IoU-183': 0.1479386846012752, 'IoU-184': 0.013715910649535302, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 10.502073369178857, 'pACC': 23.150946849309264, 'ACC-0': 0.0017835210256579661, 'ACC-1': 52.653713470732285, 'ACC-2': 4.237370868685434, 'ACC-3': 12.371779614605167, 'ACC-4': 10.986983346675839, 'ACC-5': 13.045042713325957, 'ACC-6': 14.211062764190627, 'ACC-7': 13.735410262861395, 'ACC-8': 17.150139856334953, 'ACC-9': 31.973897900725046, 'ACC-10': 36.82204927240967, 'ACC-11': 43.10209165325888, 'ACC-12': 38.82013599162824, 'ACC-13': 34.57005351000863, 'ACC-14': 33.388456806101416, 'ACC-15': 31.834165472326337, 'ACC-16': 31.948390184429837, 'ACC-17': 32.86493539573191, 'ACC-18': 31.358120903164437, 'ACC-19': 30.820859190047994, 'ACC-20': 32.287557001588354, 'ACC-21': 33.103101220956624, 'ACC-22': 33.8708723918642, 'ACC-23': 32.25622660781621, 'ACC-24': 32.251850314068605, 'ACC-25': 32.14479426538044, 'ACC-26': 30.740475895430418, 'ACC-27': 30.136062707602207, 'ACC-28': 28.732167287081754, 'ACC-29': 28.690276789006013, 'ACC-30': 27.53981765904488, 'ACC-31': 26.236293944373752, 'ACC-32': 23.29429131156756, 'ACC-33': 22.71519034221067, 'ACC-34': 22.02964212619576, 'ACC-35': 20.84358847843233, 'ACC-36': 19.361812064750044, 'ACC-37': 18.40982668240345, 'ACC-38': 16.167242010016807, 'ACC-39': 14.322343689901635, 'ACC-40': 13.100802210315074, 'ACC-41': 13.162310084983961, 'ACC-42': 12.286498607745825, 'ACC-43': 11.805043756519389, 'ACC-44': 11.30237698349646, 'ACC-45': 10.88892561091563, 'ACC-46': 10.43787152701332, 'ACC-47': 9.688843092674158, 'ACC-48': 9.591183950278438, 'ACC-49': 9.117802322554727, 'ACC-50': 8.985540321451147, 'ACC-51': 9.05556185697835, 'ACC-52': 8.858219735056975, 'ACC-53': 8.596836777811244, 'ACC-54': 8.820811621324644, 'ACC-55': 8.755958397700065, 'ACC-56': 9.274292652218984, 'ACC-57': 9.76248475651435, 'ACC-58': 9.722472734768584, 'ACC-59': 9.968817338637805, 'ACC-60': 10.185559699242233, 'ACC-61': 10.081635767019959, 'ACC-62': 9.881228693824076, 'ACC-63': 9.818133389998332, 'ACC-64': 9.743356597007505, 'ACC-65': 9.994346865081976, 'ACC-66': 10.096846687552203, 'ACC-67': 10.194915381560106, 'ACC-68': 10.376406065792395, 'ACC-69': 10.377989117511325, 'ACC-70': 10.141373658796123, 'ACC-71': 10.404502546161408, 'ACC-72': 10.829687281448479, 'ACC-73': 11.295721810030987, 'ACC-74': 11.334885281908942, 'ACC-75': 11.092210771846563, 'ACC-76': 11.093749404272463, 'ACC-77': 11.281020902601314, 'ACC-78': 10.705785317938592, 'ACC-79': 10.825914474646343, 'ACC-80': 11.121224261549882, 'ACC-81': 11.027969556252126, 'ACC-82': 10.94128495817609, 'ACC-83': 10.723589631209698, 'ACC-84': 10.757384615402064, 'ACC-85': 10.234412502493898, 'ACC-86': 9.973312968735085, 'ACC-87': 9.942543670334123, 'ACC-88': 9.725661432252542, 'ACC-89': 9.765091912784557, 'ACC-90': 9.549226626314923, 'ACC-91': 9.456276002537557, 'ACC-92': 9.619903535052547, 'ACC-93': 9.757199232576856, 'ACC-94': 9.932283341969733, 'ACC-95': 9.708344219927032, 'ACC-96': 9.36495034279682, 'ACC-97': 9.078420203707385, 'ACC-98': 9.107544249628873, 'ACC-99': 8.40494150370987, 'ACC-100': 8.362709393121825, 'ACC-101': 8.324327554159337, 'ACC-102': 7.967149977344812, 'ACC-103': 7.664777557381694, 'ACC-104': 7.635522982710706, 'ACC-105': 7.524764713829548, 'ACC-106': 7.4231087832634115, 'ACC-107': 7.1544739327006335, 'ACC-108': 7.117733755579427, 'ACC-109': 7.254292449286518, 'ACC-110': 6.877819225700348, 'ACC-111': 6.285411458465546, 'ACC-112': 6.333201871956619, 'ACC-113': 5.9953774744642745, 'ACC-114': 5.842025337491258, 'ACC-115': 5.6050320989881675, 'ACC-116': 5.69749454087544, 'ACC-117': 5.95169115513848, 'ACC-118': 5.961085730048785, 'ACC-119': 6.42297334333532, 'ACC-120': 5.7013128257027095, 'ACC-121': 5.3174311543235975, 'ACC-122': 4.928434619340108, 'ACC-123': 5.172262364581216, 'ACC-124': 4.891851850273373, 'ACC-125': 4.673725177106323, 'ACC-126': 4.692494922540278, 'ACC-127': 5.021715463185339, 'ACC-128': 5.12927937982, 'ACC-129': 4.998371569549668, 'ACC-130': 5.019244511057855, 'ACC-131': 4.97071534571709, 'ACC-132': 4.825862144075493, 'ACC-133': 4.237617968659631, 'ACC-134': 4.005239121068505, 'ACC-135': 4.101818596431219, 'ACC-136': 3.7591286572866194, 'ACC-137': 3.935225996915015, 'ACC-138': 3.5583293144148027, 'ACC-139': 3.56686968591182, 'ACC-140': 3.5223551277400373, 'ACC-141': 3.512477719860167, 'ACC-142': 3.2218370899017605, 'ACC-143': 3.1093954008301186, 'ACC-144': 3.3894404332129966, 'ACC-145': 3.8580469151814665, 'ACC-146': 4.068629914783761, 'ACC-147': 4.541947273076734, 'ACC-148': 4.4142346711328635, 'ACC-149': 4.076489576287258, 'ACC-150': 3.801298507727153, 'ACC-151': 4.1201854877473, 'ACC-152': 4.143275001685886, 'ACC-153': 3.6365864160208137, 'ACC-154': 3.5829731573490577, 'ACC-155': 4.0415320105604895, 'ACC-156': 4.137757179700983, 'ACC-157': 3.95858087223522, 'ACC-158': 4.340548527911188, 'ACC-159': 4.010071252980688, 'ACC-160': 4.667494231552278, 'ACC-161': 4.7541683399938774, 'ACC-162': 4.396446306318636, 'ACC-163': 4.249067898564128, 'ACC-164': 3.7057765911231324, 'ACC-165': 3.621036315182624, 'ACC-166': 3.268670623095584, 'ACC-167': 2.9409363399326347, 'ACC-168': 2.7981925592517056, 'ACC-169': 2.6194390876883906, 'ACC-170': 2.8049888552891233, 'ACC-171': 3.027319533659436, 'ACC-172': 3.2105419120643033, 'ACC-173': 3.2620516043092644, 'ACC-174': 3.347742044918646, 'ACC-175': 3.4229467219100758, 'ACC-176': 2.4364406779661016, 'ACC-177': 1.6690380885416956, 'ACC-178': 1.4907931258945628, 'ACC-179': 2.2287326961274627, 'ACC-180': 1.5205391310237393, 'ACC-181': 1.1874054019484535, 'ACC-182': 0.4435083596113616, 'ACC-183': 0.25520834559541944, 'ACC-184': 0.01674461165472139, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 17:19:24] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 17:19:24] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 17:19:24] d2.evaluation.testing INFO: copypaste: 2.7499,0.4408,0.1862,5.7179,15.3850,10.5021,23.1509
[01/29 17:19:25] d2.utils.events INFO:  eta: 1 day, 7:10:43  iter: 21999  total_loss: 23.96  loss_mask: 2.381  loss_mask_0: 2.463  loss_mask_1: 2.38  loss_mask_2: 2.38  loss_mask_3: 2.381  loss_mask_4: 2.378  loss_mask_5: 2.379  loss_mask_6: 2.387  loss_mask_7: 2.395  loss_mask_8: 2.424  time: 3.0021  data_time: 0.0671  lr: 6.6295e-05  max_mem: 27646M
[01/29 17:20:24] d2.utils.events INFO:  eta: 1 day, 7:09:55  iter: 22019  total_loss: 24.32  loss_mask: 2.438  loss_mask_0: 2.45  loss_mask_1: 2.405  loss_mask_2: 2.422  loss_mask_3: 2.429  loss_mask_4: 2.428  loss_mask_5: 2.425  loss_mask_6: 2.434  loss_mask_7: 2.439  loss_mask_8: 2.433  time: 3.0020  data_time: 0.0577  lr: 6.6263e-05  max_mem: 27646M
[01/29 17:21:26] d2.utils.events INFO:  eta: 1 day, 7:09:10  iter: 22039  total_loss: 22.57  loss_mask: 2.25  loss_mask_0: 2.301  loss_mask_1: 2.27  loss_mask_2: 2.258  loss_mask_3: 2.25  loss_mask_4: 2.256  loss_mask_5: 2.236  loss_mask_6: 2.252  loss_mask_7: 2.258  loss_mask_8: 2.266  time: 3.0021  data_time: 0.0846  lr: 6.6232e-05  max_mem: 27646M
[01/29 17:22:26] d2.utils.events INFO:  eta: 1 day, 7:09:06  iter: 22059  total_loss: 26.05  loss_mask: 2.581  loss_mask_0: 2.667  loss_mask_1: 2.607  loss_mask_2: 2.598  loss_mask_3: 2.595  loss_mask_4: 2.595  loss_mask_5: 2.589  loss_mask_6: 2.582  loss_mask_7: 2.613  loss_mask_8: 2.598  time: 3.0021  data_time: 0.0711  lr: 6.6201e-05  max_mem: 27646M
[01/29 17:23:25] d2.utils.events INFO:  eta: 1 day, 7:08:54  iter: 22079  total_loss: 23.16  loss_mask: 2.32  loss_mask_0: 2.37  loss_mask_1: 2.306  loss_mask_2: 2.293  loss_mask_3: 2.348  loss_mask_4: 2.325  loss_mask_5: 2.296  loss_mask_6: 2.31  loss_mask_7: 2.32  loss_mask_8: 2.307  time: 3.0021  data_time: 0.0737  lr: 6.6169e-05  max_mem: 27646M
[01/29 17:24:25] d2.utils.events INFO:  eta: 1 day, 7:08:45  iter: 22099  total_loss: 24.89  loss_mask: 2.46  loss_mask_0: 2.588  loss_mask_1: 2.447  loss_mask_2: 2.489  loss_mask_3: 2.491  loss_mask_4: 2.496  loss_mask_5: 2.461  loss_mask_6: 2.461  loss_mask_7: 2.504  loss_mask_8: 2.494  time: 3.0020  data_time: 0.0581  lr: 6.6138e-05  max_mem: 27646M
[01/29 17:25:25] d2.utils.events INFO:  eta: 1 day, 7:09:07  iter: 22119  total_loss: 27.08  loss_mask: 2.7  loss_mask_0: 2.751  loss_mask_1: 2.709  loss_mask_2: 2.71  loss_mask_3: 2.708  loss_mask_4: 2.696  loss_mask_5: 2.688  loss_mask_6: 2.699  loss_mask_7: 2.709  loss_mask_8: 2.71  time: 3.0020  data_time: 0.0738  lr: 6.6106e-05  max_mem: 27646M
[01/29 17:26:25] d2.utils.events INFO:  eta: 1 day, 7:08:43  iter: 22139  total_loss: 25.17  loss_mask: 2.512  loss_mask_0: 2.563  loss_mask_1: 2.504  loss_mask_2: 2.52  loss_mask_3: 2.517  loss_mask_4: 2.509  loss_mask_5: 2.512  loss_mask_6: 2.509  loss_mask_7: 2.51  loss_mask_8: 2.511  time: 3.0020  data_time: 0.0609  lr: 6.6075e-05  max_mem: 27646M
[01/29 17:27:24] d2.utils.events INFO:  eta: 1 day, 7:08:11  iter: 22159  total_loss: 25.71  loss_mask: 2.541  loss_mask_0: 2.68  loss_mask_1: 2.55  loss_mask_2: 2.556  loss_mask_3: 2.565  loss_mask_4: 2.559  loss_mask_5: 2.548  loss_mask_6: 2.541  loss_mask_7: 2.555  loss_mask_8: 2.559  time: 3.0020  data_time: 0.0564  lr: 6.6044e-05  max_mem: 27646M
[01/29 17:28:23] d2.utils.events INFO:  eta: 1 day, 7:07:40  iter: 22179  total_loss: 22.36  loss_mask: 2.249  loss_mask_0: 2.311  loss_mask_1: 2.222  loss_mask_2: 2.245  loss_mask_3: 2.249  loss_mask_4: 2.256  loss_mask_5: 2.237  loss_mask_6: 2.237  loss_mask_7: 2.246  loss_mask_8: 2.24  time: 3.0019  data_time: 0.0566  lr: 6.6012e-05  max_mem: 27646M
[01/29 17:29:22] d2.utils.events INFO:  eta: 1 day, 7:06:51  iter: 22199  total_loss: 27.52  loss_mask: 2.734  loss_mask_0: 2.823  loss_mask_1: 2.73  loss_mask_2: 2.741  loss_mask_3: 2.742  loss_mask_4: 2.749  loss_mask_5: 2.745  loss_mask_6: 2.734  loss_mask_7: 2.743  loss_mask_8: 2.747  time: 3.0019  data_time: 0.0559  lr: 6.5981e-05  max_mem: 27646M
[01/29 17:30:22] d2.utils.events INFO:  eta: 1 day, 7:06:01  iter: 22219  total_loss: 24.39  loss_mask: 2.375  loss_mask_0: 2.412  loss_mask_1: 2.34  loss_mask_2: 2.369  loss_mask_3: 2.37  loss_mask_4: 2.399  loss_mask_5: 2.437  loss_mask_6: 2.357  loss_mask_7: 2.386  loss_mask_8: 2.382  time: 3.0019  data_time: 0.0724  lr: 6.5949e-05  max_mem: 27646M
[01/29 17:31:21] d2.utils.events INFO:  eta: 1 day, 7:05:01  iter: 22239  total_loss: 22.28  loss_mask: 2.196  loss_mask_0: 2.262  loss_mask_1: 2.123  loss_mask_2: 2.129  loss_mask_3: 2.165  loss_mask_4: 2.197  loss_mask_5: 2.264  loss_mask_6: 2.187  loss_mask_7: 2.154  loss_mask_8: 2.16  time: 3.0018  data_time: 0.0530  lr: 6.5918e-05  max_mem: 27646M
[01/29 17:32:21] d2.utils.events INFO:  eta: 1 day, 7:05:02  iter: 22259  total_loss: 25.58  loss_mask: 2.549  loss_mask_0: 2.591  loss_mask_1: 2.512  loss_mask_2: 2.519  loss_mask_3: 2.562  loss_mask_4: 2.625  loss_mask_5: 2.564  loss_mask_6: 2.559  loss_mask_7: 2.553  loss_mask_8: 2.546  time: 3.0018  data_time: 0.0573  lr: 6.5886e-05  max_mem: 27646M
[01/29 17:33:21] d2.utils.events INFO:  eta: 1 day, 7:04:31  iter: 22279  total_loss: 28.69  loss_mask: 2.837  loss_mask_0: 2.858  loss_mask_1: 2.753  loss_mask_2: 2.775  loss_mask_3: 2.881  loss_mask_4: 3.172  loss_mask_5: 3.075  loss_mask_6: 2.847  loss_mask_7: 2.888  loss_mask_8: 2.812  time: 3.0018  data_time: 0.0621  lr: 6.5855e-05  max_mem: 27646M
[01/29 17:34:19] d2.utils.events INFO:  eta: 1 day, 7:03:24  iter: 22299  total_loss: 23.86  loss_mask: 2.397  loss_mask_0: 2.393  loss_mask_1: 2.359  loss_mask_2: 2.362  loss_mask_3: 2.381  loss_mask_4: 2.363  loss_mask_5: 2.368  loss_mask_6: 2.382  loss_mask_7: 2.393  loss_mask_8: 2.392  time: 3.0018  data_time: 0.0602  lr: 6.5824e-05  max_mem: 27646M
[01/29 17:35:19] d2.utils.events INFO:  eta: 1 day, 7:02:45  iter: 22319  total_loss: 23.53  loss_mask: 2.322  loss_mask_0: 2.433  loss_mask_1: 2.327  loss_mask_2: 2.371  loss_mask_3: 2.357  loss_mask_4: 2.343  loss_mask_5: 2.374  loss_mask_6: 2.318  loss_mask_7: 2.374  loss_mask_8: 2.359  time: 3.0017  data_time: 0.0602  lr: 6.5792e-05  max_mem: 27646M
[01/29 17:36:18] d2.utils.events INFO:  eta: 1 day, 7:01:28  iter: 22339  total_loss: 25.19  loss_mask: 2.51  loss_mask_0: 2.541  loss_mask_1: 2.502  loss_mask_2: 2.513  loss_mask_3: 2.516  loss_mask_4: 2.526  loss_mask_5: 2.527  loss_mask_6: 2.517  loss_mask_7: 2.52  loss_mask_8: 2.512  time: 3.0017  data_time: 0.0528  lr: 6.5761e-05  max_mem: 27646M
[01/29 17:37:18] d2.utils.events INFO:  eta: 1 day, 7:00:58  iter: 22359  total_loss: 22.64  loss_mask: 2.258  loss_mask_0: 2.302  loss_mask_1: 2.25  loss_mask_2: 2.278  loss_mask_3: 2.284  loss_mask_4: 2.266  loss_mask_5: 2.279  loss_mask_6: 2.265  loss_mask_7: 2.263  loss_mask_8: 2.294  time: 3.0017  data_time: 0.0701  lr: 6.5729e-05  max_mem: 27646M
[01/29 17:38:17] d2.utils.events INFO:  eta: 1 day, 6:59:59  iter: 22379  total_loss: 24.5  loss_mask: 2.435  loss_mask_0: 2.496  loss_mask_1: 2.405  loss_mask_2: 2.441  loss_mask_3: 2.448  loss_mask_4: 2.467  loss_mask_5: 2.467  loss_mask_6: 2.436  loss_mask_7: 2.447  loss_mask_8: 2.455  time: 3.0016  data_time: 0.0566  lr: 6.5698e-05  max_mem: 27646M
[01/29 17:39:16] d2.utils.events INFO:  eta: 1 day, 6:58:35  iter: 22399  total_loss: 22.91  loss_mask: 2.279  loss_mask_0: 2.361  loss_mask_1: 2.264  loss_mask_2: 2.293  loss_mask_3: 2.289  loss_mask_4: 2.277  loss_mask_5: 2.276  loss_mask_6: 2.271  loss_mask_7: 2.278  loss_mask_8: 2.269  time: 3.0016  data_time: 0.0492  lr: 6.5666e-05  max_mem: 27646M
[01/29 17:40:15] d2.utils.events INFO:  eta: 1 day, 6:57:21  iter: 22419  total_loss: 25.23  loss_mask: 2.515  loss_mask_0: 2.569  loss_mask_1: 2.484  loss_mask_2: 2.535  loss_mask_3: 2.549  loss_mask_4: 2.516  loss_mask_5: 2.514  loss_mask_6: 2.517  loss_mask_7: 2.524  loss_mask_8: 2.511  time: 3.0015  data_time: 0.0523  lr: 6.5635e-05  max_mem: 27646M
[01/29 17:41:14] d2.utils.events INFO:  eta: 1 day, 6:56:17  iter: 22439  total_loss: 22.86  loss_mask: 2.265  loss_mask_0: 2.295  loss_mask_1: 2.261  loss_mask_2: 2.269  loss_mask_3: 2.284  loss_mask_4: 2.281  loss_mask_5: 2.275  loss_mask_6: 2.277  loss_mask_7: 2.274  loss_mask_8: 2.259  time: 3.0015  data_time: 0.0615  lr: 6.5604e-05  max_mem: 27646M
[01/29 17:42:13] d2.utils.events INFO:  eta: 1 day, 6:56:11  iter: 22459  total_loss: 23.63  loss_mask: 2.359  loss_mask_0: 2.404  loss_mask_1: 2.356  loss_mask_2: 2.375  loss_mask_3: 2.383  loss_mask_4: 2.385  loss_mask_5: 2.355  loss_mask_6: 2.341  loss_mask_7: 2.36  loss_mask_8: 2.356  time: 3.0015  data_time: 0.0641  lr: 6.5572e-05  max_mem: 27646M
[01/29 17:43:13] d2.utils.events INFO:  eta: 1 day, 6:55:37  iter: 22479  total_loss: 24.6  loss_mask: 2.446  loss_mask_0: 2.509  loss_mask_1: 2.437  loss_mask_2: 2.453  loss_mask_3: 2.463  loss_mask_4: 2.467  loss_mask_5: 2.453  loss_mask_6: 2.437  loss_mask_7: 2.463  loss_mask_8: 2.462  time: 3.0014  data_time: 0.0609  lr: 6.5541e-05  max_mem: 27646M
[01/29 17:44:12] d2.utils.events INFO:  eta: 1 day, 6:54:27  iter: 22499  total_loss: 23.79  loss_mask: 2.365  loss_mask_0: 2.382  loss_mask_1: 2.358  loss_mask_2: 2.35  loss_mask_3: 2.365  loss_mask_4: 2.378  loss_mask_5: 2.374  loss_mask_6: 2.356  loss_mask_7: 2.392  loss_mask_8: 2.367  time: 3.0014  data_time: 0.0608  lr: 6.5509e-05  max_mem: 27646M
[01/29 17:45:11] d2.utils.events INFO:  eta: 1 day, 6:53:44  iter: 22519  total_loss: 24.75  loss_mask: 2.494  loss_mask_0: 2.475  loss_mask_1: 2.473  loss_mask_2: 2.497  loss_mask_3: 2.471  loss_mask_4: 2.454  loss_mask_5: 2.467  loss_mask_6: 2.466  loss_mask_7: 2.503  loss_mask_8: 2.459  time: 3.0013  data_time: 0.0505  lr: 6.5478e-05  max_mem: 27646M
[01/29 17:46:11] d2.utils.events INFO:  eta: 1 day, 6:53:39  iter: 22539  total_loss: 21.69  loss_mask: 2.154  loss_mask_0: 2.205  loss_mask_1: 2.154  loss_mask_2: 2.184  loss_mask_3: 2.166  loss_mask_4: 2.16  loss_mask_5: 2.163  loss_mask_6: 2.159  loss_mask_7: 2.166  loss_mask_8: 2.16  time: 3.0013  data_time: 0.0695  lr: 6.5446e-05  max_mem: 27646M
[01/29 17:47:11] d2.utils.events INFO:  eta: 1 day, 6:53:00  iter: 22559  total_loss: 23.66  loss_mask: 2.363  loss_mask_0: 2.425  loss_mask_1: 2.371  loss_mask_2: 2.37  loss_mask_3: 2.368  loss_mask_4: 2.368  loss_mask_5: 2.351  loss_mask_6: 2.37  loss_mask_7: 2.389  loss_mask_8: 2.358  time: 3.0013  data_time: 0.0763  lr: 6.5415e-05  max_mem: 27646M
[01/29 17:48:10] d2.utils.events INFO:  eta: 1 day, 6:51:35  iter: 22579  total_loss: 24.68  loss_mask: 2.489  loss_mask_0: 2.507  loss_mask_1: 2.444  loss_mask_2: 2.434  loss_mask_3: 2.454  loss_mask_4: 2.531  loss_mask_5: 2.449  loss_mask_6: 2.485  loss_mask_7: 2.464  loss_mask_8: 2.426  time: 3.0013  data_time: 0.0592  lr: 6.5383e-05  max_mem: 27646M
[01/29 17:49:09] d2.utils.events INFO:  eta: 1 day, 6:49:47  iter: 22599  total_loss: 24.07  loss_mask: 2.459  loss_mask_0: 2.397  loss_mask_1: 2.388  loss_mask_2: 2.355  loss_mask_3: 2.4  loss_mask_4: 2.46  loss_mask_5: 2.399  loss_mask_6: 2.45  loss_mask_7: 2.384  loss_mask_8: 2.343  time: 3.0012  data_time: 0.0608  lr: 6.5352e-05  max_mem: 27646M
[01/29 17:50:09] d2.utils.events INFO:  eta: 1 day, 6:49:10  iter: 22619  total_loss: 25.29  loss_mask: 2.528  loss_mask_0: 2.557  loss_mask_1: 2.507  loss_mask_2: 2.51  loss_mask_3: 2.525  loss_mask_4: 2.537  loss_mask_5: 2.515  loss_mask_6: 2.52  loss_mask_7: 2.537  loss_mask_8: 2.519  time: 3.0012  data_time: 0.0650  lr: 6.5321e-05  max_mem: 27646M
[01/29 17:51:08] d2.utils.events INFO:  eta: 1 day, 6:47:34  iter: 22639  total_loss: 22.99  loss_mask: 2.278  loss_mask_0: 2.364  loss_mask_1: 2.272  loss_mask_2: 2.285  loss_mask_3: 2.294  loss_mask_4: 2.296  loss_mask_5: 2.317  loss_mask_6: 2.29  loss_mask_7: 2.298  loss_mask_8: 2.292  time: 3.0012  data_time: 0.0573  lr: 6.5289e-05  max_mem: 27646M
[01/29 17:52:08] d2.utils.events INFO:  eta: 1 day, 6:46:21  iter: 22659  total_loss: 23.77  loss_mask: 2.352  loss_mask_0: 2.39  loss_mask_1: 2.328  loss_mask_2: 2.415  loss_mask_3: 2.434  loss_mask_4: 2.387  loss_mask_5: 2.368  loss_mask_6: 2.388  loss_mask_7: 2.392  loss_mask_8: 2.385  time: 3.0012  data_time: 0.0608  lr: 6.5258e-05  max_mem: 27646M
[01/29 17:53:07] d2.utils.events INFO:  eta: 1 day, 6:45:18  iter: 22679  total_loss: 24.42  loss_mask: 2.416  loss_mask_0: 2.458  loss_mask_1: 2.405  loss_mask_2: 2.468  loss_mask_3: 2.42  loss_mask_4: 2.485  loss_mask_5: 2.446  loss_mask_6: 2.453  loss_mask_7: 2.435  loss_mask_8: 2.495  time: 3.0012  data_time: 0.0581  lr: 6.5226e-05  max_mem: 27646M
[01/29 17:54:07] d2.utils.events INFO:  eta: 1 day, 6:44:04  iter: 22699  total_loss: 26.01  loss_mask: 2.594  loss_mask_0: 2.617  loss_mask_1: 2.521  loss_mask_2: 2.527  loss_mask_3: 2.565  loss_mask_4: 2.603  loss_mask_5: 2.625  loss_mask_6: 2.607  loss_mask_7: 2.522  loss_mask_8: 2.605  time: 3.0011  data_time: 0.0498  lr: 6.5195e-05  max_mem: 27646M
[01/29 17:55:06] d2.utils.events INFO:  eta: 1 day, 6:42:41  iter: 22719  total_loss: 25.42  loss_mask: 2.463  loss_mask_0: 2.513  loss_mask_1: 2.477  loss_mask_2: 2.626  loss_mask_3: 2.639  loss_mask_4: 2.488  loss_mask_5: 2.478  loss_mask_6: 2.46  loss_mask_7: 2.587  loss_mask_8: 2.484  time: 3.0011  data_time: 0.0500  lr: 6.5163e-05  max_mem: 27646M
[01/29 17:56:06] d2.utils.events INFO:  eta: 1 day, 6:41:39  iter: 22739  total_loss: 25.82  loss_mask: 2.579  loss_mask_0: 2.577  loss_mask_1: 2.544  loss_mask_2: 2.568  loss_mask_3: 2.577  loss_mask_4: 2.595  loss_mask_5: 2.628  loss_mask_6: 2.654  loss_mask_7: 2.513  loss_mask_8: 2.576  time: 3.0011  data_time: 0.0641  lr: 6.5132e-05  max_mem: 27646M
[01/29 17:57:04] d2.utils.events INFO:  eta: 1 day, 6:40:25  iter: 22759  total_loss: 24.27  loss_mask: 2.402  loss_mask_0: 2.512  loss_mask_1: 2.397  loss_mask_2: 2.448  loss_mask_3: 2.528  loss_mask_4: 2.425  loss_mask_5: 2.393  loss_mask_6: 2.41  loss_mask_7: 2.4  loss_mask_8: 2.413  time: 3.0010  data_time: 0.0489  lr: 6.51e-05  max_mem: 27646M
[01/29 17:58:04] d2.utils.events INFO:  eta: 1 day, 6:39:12  iter: 22779  total_loss: 27.16  loss_mask: 2.714  loss_mask_0: 2.75  loss_mask_1: 2.681  loss_mask_2: 2.701  loss_mask_3: 2.714  loss_mask_4: 2.717  loss_mask_5: 2.714  loss_mask_6: 2.705  loss_mask_7: 2.728  loss_mask_8: 2.713  time: 3.0010  data_time: 0.0626  lr: 6.5069e-05  max_mem: 27646M
[01/29 17:59:03] d2.utils.events INFO:  eta: 1 day, 6:37:54  iter: 22799  total_loss: 24.61  loss_mask: 2.427  loss_mask_0: 2.464  loss_mask_1: 2.451  loss_mask_2: 2.49  loss_mask_3: 2.473  loss_mask_4: 2.457  loss_mask_5: 2.447  loss_mask_6: 2.449  loss_mask_7: 2.449  loss_mask_8: 2.458  time: 3.0010  data_time: 0.0596  lr: 6.5037e-05  max_mem: 27646M
[01/29 18:00:02] d2.utils.events INFO:  eta: 1 day, 6:36:38  iter: 22819  total_loss: 24.74  loss_mask: 2.469  loss_mask_0: 2.536  loss_mask_1: 2.458  loss_mask_2: 2.495  loss_mask_3: 2.493  loss_mask_4: 2.467  loss_mask_5: 2.468  loss_mask_6: 2.464  loss_mask_7: 2.487  loss_mask_8: 2.481  time: 3.0009  data_time: 0.0645  lr: 6.5006e-05  max_mem: 27646M
[01/29 18:01:02] d2.utils.events INFO:  eta: 1 day, 6:35:31  iter: 22839  total_loss: 25.54  loss_mask: 2.55  loss_mask_0: 2.568  loss_mask_1: 2.534  loss_mask_2: 2.537  loss_mask_3: 2.576  loss_mask_4: 2.558  loss_mask_5: 2.551  loss_mask_6: 2.552  loss_mask_7: 2.566  loss_mask_8: 2.56  time: 3.0009  data_time: 0.0599  lr: 6.4974e-05  max_mem: 27646M
[01/29 18:02:01] d2.utils.events INFO:  eta: 1 day, 6:33:58  iter: 22859  total_loss: 23.26  loss_mask: 2.302  loss_mask_0: 2.394  loss_mask_1: 2.31  loss_mask_2: 2.347  loss_mask_3: 2.327  loss_mask_4: 2.322  loss_mask_5: 2.319  loss_mask_6: 2.312  loss_mask_7: 2.317  loss_mask_8: 2.327  time: 3.0008  data_time: 0.0544  lr: 6.4943e-05  max_mem: 27646M
[01/29 18:03:01] d2.utils.events INFO:  eta: 1 day, 6:33:20  iter: 22879  total_loss: 22.78  loss_mask: 2.262  loss_mask_0: 2.391  loss_mask_1: 2.252  loss_mask_2: 2.279  loss_mask_3: 2.292  loss_mask_4: 2.29  loss_mask_5: 2.26  loss_mask_6: 2.263  loss_mask_7: 2.29  loss_mask_8: 2.28  time: 3.0009  data_time: 0.0834  lr: 6.4911e-05  max_mem: 27646M
[01/29 18:04:00] d2.utils.events INFO:  eta: 1 day, 6:32:25  iter: 22899  total_loss: 22.53  loss_mask: 2.246  loss_mask_0: 2.31  loss_mask_1: 2.224  loss_mask_2: 2.256  loss_mask_3: 2.256  loss_mask_4: 2.262  loss_mask_5: 2.246  loss_mask_6: 2.238  loss_mask_7: 2.245  loss_mask_8: 2.246  time: 3.0008  data_time: 0.0586  lr: 6.488e-05  max_mem: 27646M
[01/29 18:05:01] d2.utils.events INFO:  eta: 1 day, 6:31:34  iter: 22919  total_loss: 23.63  loss_mask: 2.371  loss_mask_0: 2.361  loss_mask_1: 2.334  loss_mask_2: 2.352  loss_mask_3: 2.38  loss_mask_4: 2.391  loss_mask_5: 2.357  loss_mask_6: 2.358  loss_mask_7: 2.379  loss_mask_8: 2.364  time: 3.0008  data_time: 0.0675  lr: 6.4849e-05  max_mem: 27646M
[01/29 18:06:01] d2.utils.events INFO:  eta: 1 day, 6:31:06  iter: 22939  total_loss: 25.67  loss_mask: 2.575  loss_mask_0: 2.614  loss_mask_1: 2.522  loss_mask_2: 2.538  loss_mask_3: 2.578  loss_mask_4: 2.59  loss_mask_5: 2.561  loss_mask_6: 2.564  loss_mask_7: 2.584  loss_mask_8: 2.535  time: 3.0008  data_time: 0.0721  lr: 6.4817e-05  max_mem: 27646M
[01/29 18:07:01] d2.utils.events INFO:  eta: 1 day, 6:30:18  iter: 22959  total_loss: 24.32  loss_mask: 2.422  loss_mask_0: 2.462  loss_mask_1: 2.441  loss_mask_2: 2.433  loss_mask_3: 2.435  loss_mask_4: 2.423  loss_mask_5: 2.418  loss_mask_6: 2.437  loss_mask_7: 2.438  loss_mask_8: 2.418  time: 3.0008  data_time: 0.0671  lr: 6.4786e-05  max_mem: 27646M
[01/29 18:08:01] d2.utils.events INFO:  eta: 1 day, 6:29:35  iter: 22979  total_loss: 25.54  loss_mask: 2.549  loss_mask_0: 2.572  loss_mask_1: 2.537  loss_mask_2: 2.545  loss_mask_3: 2.557  loss_mask_4: 2.559  loss_mask_5: 2.558  loss_mask_6: 2.557  loss_mask_7: 2.551  loss_mask_8: 2.559  time: 3.0008  data_time: 0.0649  lr: 6.4754e-05  max_mem: 27646M
[01/29 18:08:59] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 18:09:00] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 18:09:00] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 18:23:02] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.729440439559964, 'error_1pix': 0.4114069293801449, 'error_3pix': 0.19534792092648623, 'mIoU': 5.850260312836759, 'fwIoU': 17.624452809282406, 'IoU-0': 0.0008947468198317291, 'IoU-1': 58.038311028568344, 'IoU-2': 2.4299144849272984, 'IoU-3': 3.2158962636066093, 'IoU-4': 3.005792514990018, 'IoU-5': 3.4415851185822057, 'IoU-6': 3.3970038560195683, 'IoU-7': 2.7730065534489605, 'IoU-8': 6.142706344193682, 'IoU-9': 15.802727379423375, 'IoU-10': 18.976353184171167, 'IoU-11': 26.77091063811563, 'IoU-12': 27.046420215777196, 'IoU-13': 25.223655204943913, 'IoU-14': 24.331531277095404, 'IoU-15': 23.352221454877288, 'IoU-16': 22.941690473588555, 'IoU-17': 19.711418167552008, 'IoU-18': 19.438488226634128, 'IoU-19': 19.50396628698012, 'IoU-20': 18.42441711401508, 'IoU-21': 18.18092835384792, 'IoU-22': 17.580867730954093, 'IoU-23': 15.822365085504275, 'IoU-24': 14.748261974926887, 'IoU-25': 15.019318295019875, 'IoU-26': 14.92992908971865, 'IoU-27': 16.416056622100065, 'IoU-28': 15.647109664179348, 'IoU-29': 15.629355705412697, 'IoU-30': 15.238226436385292, 'IoU-31': 16.04766950240216, 'IoU-32': 16.03791466096987, 'IoU-33': 15.615002614152518, 'IoU-34': 15.720351524479298, 'IoU-35': 16.740455661229188, 'IoU-36': 17.182808056408334, 'IoU-37': 16.822737662629056, 'IoU-38': 17.642499862436207, 'IoU-39': 16.964495285274037, 'IoU-40': 17.417018191145303, 'IoU-41': 15.988791394399659, 'IoU-42': 15.535833975831729, 'IoU-43': 15.190560088311472, 'IoU-44': 15.09844482044157, 'IoU-45': 14.521528096450833, 'IoU-46': 13.087490557136693, 'IoU-47': 12.34396449810125, 'IoU-48': 11.422451377001389, 'IoU-49': 10.720764099470802, 'IoU-50': 10.406360096033387, 'IoU-51': 8.897981937998146, 'IoU-52': 8.407530751767874, 'IoU-53': 7.87743210523755, 'IoU-54': 7.462049237224287, 'IoU-55': 6.575051801633476, 'IoU-56': 6.150579340836605, 'IoU-57': 5.735351232020886, 'IoU-58': 5.328188875274703, 'IoU-59': 4.800828180898226, 'IoU-60': 4.229904141809283, 'IoU-61': 3.9774829916217156, 'IoU-62': 3.650738487043051, 'IoU-63': 3.3008500982840814, 'IoU-64': 3.020100950080562, 'IoU-65': 2.8134877022916855, 'IoU-66': 2.6941932853098103, 'IoU-67': 2.6566014344847453, 'IoU-68': 2.5378135075497052, 'IoU-69': 2.445580597557323, 'IoU-70': 2.300969803941971, 'IoU-71': 2.4182806844716334, 'IoU-72': 2.3372063665650984, 'IoU-73': 2.1917327115570955, 'IoU-74': 2.2476629336432485, 'IoU-75': 2.039587840466846, 'IoU-76': 2.1786974038166775, 'IoU-77': 2.1386695987638173, 'IoU-78': 2.186642267433651, 'IoU-79': 2.2291177703299208, 'IoU-80': 2.196476655637907, 'IoU-81': 2.240241341866403, 'IoU-82': 2.2204919955188718, 'IoU-83': 2.5331393774821467, 'IoU-84': 2.5253089513161475, 'IoU-85': 2.6310871700393026, 'IoU-86': 2.5736301664831815, 'IoU-87': 2.4850901000692263, 'IoU-88': 2.5444582285721418, 'IoU-89': 2.6651165507436616, 'IoU-90': 2.614123242379421, 'IoU-91': 2.6128090926318244, 'IoU-92': 2.7131225677811384, 'IoU-93': 2.832917204745326, 'IoU-94': 3.1288551213481335, 'IoU-95': 3.0372829354039106, 'IoU-96': 2.8323644754399613, 'IoU-97': 3.001836625251728, 'IoU-98': 3.106024996561895, 'IoU-99': 3.022572717206363, 'IoU-100': 2.9427092628142426, 'IoU-101': 3.159412212349543, 'IoU-102': 2.9884690499873834, 'IoU-103': 2.8809084609770568, 'IoU-104': 2.8926174496644292, 'IoU-105': 3.0725130850448066, 'IoU-106': 3.1311121660696557, 'IoU-107': 3.123217730614695, 'IoU-108': 3.29906777075173, 'IoU-109': 3.281221299103692, 'IoU-110': 3.2730599320773592, 'IoU-111': 3.054164050216949, 'IoU-112': 2.9031780010466397, 'IoU-113': 2.9011198986862734, 'IoU-114': 2.957435214278504, 'IoU-115': 2.7660212542825167, 'IoU-116': 2.8123454750881285, 'IoU-117': 3.045657833571792, 'IoU-118': 3.1179691077392317, 'IoU-119': 3.178626217326634, 'IoU-120': 3.0434179630524087, 'IoU-121': 2.8021015761821366, 'IoU-122': 2.7902651967525167, 'IoU-123': 2.6151787707649436, 'IoU-124': 2.465656921451215, 'IoU-125': 2.26786752953686, 'IoU-126': 2.161264755509811, 'IoU-127': 2.1595210228151354, 'IoU-128': 2.2855605361467064, 'IoU-129': 2.237135128146163, 'IoU-130': 2.0255705094819594, 'IoU-131': 2.0667587802105998, 'IoU-132': 2.0128675941687937, 'IoU-133': 2.2284481304728683, 'IoU-134': 2.0200381562373537, 'IoU-135': 1.8010630712387374, 'IoU-136': 1.8251503112758825, 'IoU-137': 1.6489886868661172, 'IoU-138': 1.7071019574334343, 'IoU-139': 1.6566517652674833, 'IoU-140': 1.5055319680524941, 'IoU-141': 1.5196402892201002, 'IoU-142': 1.6365654136558796, 'IoU-143': 1.6103567191095753, 'IoU-144': 1.7593067659667099, 'IoU-145': 1.7693476204337069, 'IoU-146': 1.8760867912969177, 'IoU-147': 1.7539136318036535, 'IoU-148': 1.906273104211614, 'IoU-149': 1.68255998385692, 'IoU-150': 2.0439207476814563, 'IoU-151': 1.9093308497164858, 'IoU-152': 1.7604894068073462, 'IoU-153': 1.6973010708686085, 'IoU-154': 1.6450539490582532, 'IoU-155': 1.5587422984756598, 'IoU-156': 1.5129997638465196, 'IoU-157': 1.410628434764318, 'IoU-158': 1.4290069219913584, 'IoU-159': 1.3078398414842225, 'IoU-160': 1.3614642612590808, 'IoU-161': 1.1774418039395596, 'IoU-162': 1.0348572871937358, 'IoU-163': 1.1631731197295536, 'IoU-164': 1.1624924646585104, 'IoU-165': 1.1667098452175946, 'IoU-166': 1.1870212143813126, 'IoU-167': 1.0775218824045367, 'IoU-168': 1.054049283614848, 'IoU-169': 0.8980149646383545, 'IoU-170': 0.9134794115794159, 'IoU-171': 0.9465385848322159, 'IoU-172': 0.8383672173919865, 'IoU-173': 0.9450539781292498, 'IoU-174': 0.7098583557039656, 'IoU-175': 0.5903902631021224, 'IoU-176': 0.8740850203358831, 'IoU-177': 0.536059026105937, 'IoU-178': 0.3862971872918838, 'IoU-179': 0.5872001181605145, 'IoU-180': 0.3542907006285001, 'IoU-181': 0.11841608930865058, 'IoU-182': 0.08518588431176097, 'IoU-183': 0.00020793349455110278, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 10.485896634172134, 'pACC': 26.155094692404447, 'ACC-0': 0.0037376397146397376, 'ACC-1': 59.07572143837411, 'ACC-2': 4.651999982249991, 'ACC-3': 13.100836277674691, 'ACC-4': 11.488232446559579, 'ACC-5': 13.934660368693413, 'ACC-6': 14.667570368914024, 'ACC-7': 13.933768700934547, 'ACC-8': 17.068635648430377, 'ACC-9': 29.31956570218502, 'ACC-10': 31.55358084662563, 'ACC-11': 38.89700855092806, 'ACC-12': 41.68123606036312, 'ACC-13': 39.08804591547478, 'ACC-14': 37.922829707284876, 'ACC-15': 37.13991390775395, 'ACC-16': 35.903318616370896, 'ACC-17': 33.18906231809662, 'ACC-18': 31.939551253284893, 'ACC-19': 32.33616078363858, 'ACC-20': 30.641805492056235, 'ACC-21': 30.166024766810708, 'ACC-22': 28.762522099624665, 'ACC-23': 27.731933361284984, 'ACC-24': 25.989208316239843, 'ACC-25': 26.578023288929298, 'ACC-26': 26.366039138708185, 'ACC-27': 28.081013390580157, 'ACC-28': 27.606434302971888, 'ACC-29': 26.46640729587481, 'ACC-30': 26.524939606670266, 'ACC-31': 27.55109305318874, 'ACC-32': 28.430531730097048, 'ACC-33': 28.076609750814413, 'ACC-34': 27.989798647606356, 'ACC-35': 29.44137829371926, 'ACC-36': 30.23393859570857, 'ACC-37': 30.236984078148033, 'ACC-38': 31.943074254294796, 'ACC-39': 30.864284848029726, 'ACC-40': 31.080089746320976, 'ACC-41': 29.047334166126365, 'ACC-42': 28.351012294123862, 'ACC-43': 27.836306167955733, 'ACC-44': 27.06209993787726, 'ACC-45': 26.37042964809127, 'ACC-46': 24.643628305291553, 'ACC-47': 23.281820117805875, 'ACC-48': 21.556071866358263, 'ACC-49': 20.287695748445312, 'ACC-50': 19.56140604524368, 'ACC-51': 16.905016307948117, 'ACC-52': 16.062317216697643, 'ACC-53': 15.241790948936726, 'ACC-54': 14.172412842753971, 'ACC-55': 12.410899934186459, 'ACC-56': 11.736079209270326, 'ACC-57': 10.827931676530092, 'ACC-58': 10.235949570923959, 'ACC-59': 9.352497792078166, 'ACC-60': 8.304718529794286, 'ACC-61': 7.855403809991881, 'ACC-62': 7.242391114619252, 'ACC-63': 6.58939051185907, 'ACC-64': 6.026478044303269, 'ACC-65': 5.6305223783525, 'ACC-66': 5.4455564954000995, 'ACC-67': 5.408779678537288, 'ACC-68': 5.139671602187679, 'ACC-69': 4.817838375627936, 'ACC-70': 4.524446351633167, 'ACC-71': 4.867118325250413, 'ACC-72': 4.726737654428227, 'ACC-73': 4.414484154958368, 'ACC-74': 4.476297963233612, 'ACC-75': 4.06706540477859, 'ACC-76': 4.23314985984252, 'ACC-77': 4.194744100818738, 'ACC-78': 4.292718377788766, 'ACC-79': 4.31555201955685, 'ACC-80': 4.18723131146379, 'ACC-81': 4.235798328452539, 'ACC-82': 4.196995087071548, 'ACC-83': 4.711099368185856, 'ACC-84': 4.673419444884566, 'ACC-85': 4.840800213676697, 'ACC-86': 4.67716162878049, 'ACC-87': 4.5084047102396125, 'ACC-88': 4.585703214726776, 'ACC-89': 4.747158320314347, 'ACC-90': 4.636881202048435, 'ACC-91': 4.683008196438005, 'ACC-92': 4.89180150329923, 'ACC-93': 5.143688536870917, 'ACC-94': 5.664275844116666, 'ACC-95': 5.4398131388331885, 'ACC-96': 5.072133963288791, 'ACC-97': 5.278685611237719, 'ACC-98': 5.463659998494367, 'ACC-99': 5.395527793355019, 'ACC-100': 5.281872315303852, 'ACC-101': 5.702078014137142, 'ACC-102': 5.411848663343906, 'ACC-103': 5.235784452630584, 'ACC-104': 5.246919652738496, 'ACC-105': 5.601689264167418, 'ACC-106': 5.707378740523561, 'ACC-107': 5.762230809063178, 'ACC-108': 6.014934113635566, 'ACC-109': 5.950334735209778, 'ACC-110': 6.04895444947246, 'ACC-111': 5.6763320224101115, 'ACC-112': 5.438263535350098, 'ACC-113': 5.414596846764839, 'ACC-114': 5.520159096383852, 'ACC-115': 5.134221881436711, 'ACC-116': 5.23289906632856, 'ACC-117': 5.681344212574348, 'ACC-118': 5.943787140009833, 'ACC-119': 6.075048347935289, 'ACC-120': 5.870291696096311, 'ACC-121': 5.402550023232818, 'ACC-122': 5.371036070461472, 'ACC-123': 4.993743449865692, 'ACC-124': 4.859088562629289, 'ACC-125': 4.4403026878392975, 'ACC-126': 4.26233390103735, 'ACC-127': 4.33106093879954, 'ACC-128': 4.569021979750967, 'ACC-129': 4.462526960093728, 'ACC-130': 4.078430411486858, 'ACC-131': 4.123446878871173, 'ACC-132': 3.985416184951728, 'ACC-133': 4.450386821531365, 'ACC-134': 3.9743558810857387, 'ACC-135': 3.5640071831708564, 'ACC-136': 3.679125512486023, 'ACC-137': 3.36402290612929, 'ACC-138': 3.4467250044419626, 'ACC-139': 3.3687148135729115, 'ACC-140': 3.034436719690833, 'ACC-141': 3.0449945214840297, 'ACC-142': 3.2402640558013935, 'ACC-143': 3.2087795962269947, 'ACC-144': 3.493953068592058, 'ACC-145': 3.4797736979807237, 'ACC-146': 3.7220077220077217, 'ACC-147': 3.490212937437267, 'ACC-148': 3.7717753226792237, 'ACC-149': 3.4500628252181134, 'ACC-150': 4.270128798041294, 'ACC-151': 4.037694384316885, 'ACC-152': 3.6908254096702406, 'ACC-153': 3.7474349108631526, 'ACC-154': 3.61866785962119, 'ACC-155': 3.574148985734464, 'ACC-156': 3.6277608640850127, 'ACC-157': 3.304193496140775, 'ACC-158': 3.426993963737261, 'ACC-159': 3.06546597974975, 'ACC-160': 3.165294303940642, 'ACC-161': 2.659677541655316, 'ACC-162': 2.4379576377338954, 'ACC-163': 2.751896686931625, 'ACC-164': 2.8098135775417856, 'ACC-165': 2.9181105813669093, 'ACC-166': 3.094072911332902, 'ACC-167': 2.7656613979957165, 'ACC-168': 2.897883114143048, 'ACC-169': 2.3060469245981263, 'ACC-170': 2.3416315288839673, 'ACC-171': 2.581698686098136, 'ACC-172': 2.57324887950513, 'ACC-173': 2.7482286183034623, 'ACC-174': 2.182556325387106, 'ACC-175': 1.6584115855856854, 'ACC-176': 2.3475592059438126, 'ACC-177': 1.294408796221965, 'ACC-178': 0.8929692434582229, 'ACC-179': 1.322834517865367, 'ACC-180': 0.5431101628907176, 'ACC-181': 0.1762277317074904, 'ACC-182': 0.12509210142884558, 'ACC-183': 0.00023543205313230576, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 18:23:02] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 18:23:02] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 18:23:02] d2.evaluation.testing INFO: copypaste: 2.7294,0.4114,0.1953,5.8503,17.6245,10.4859,26.1551
[01/29 18:23:02] d2.utils.events INFO:  eta: 1 day, 6:28:16  iter: 22999  total_loss: 25  loss_mask: 2.487  loss_mask_0: 2.562  loss_mask_1: 2.47  loss_mask_2: 2.505  loss_mask_3: 2.488  loss_mask_4: 2.508  loss_mask_5: 2.492  loss_mask_6: 2.477  loss_mask_7: 2.496  loss_mask_8: 2.541  time: 3.0008  data_time: 0.0554  lr: 6.4723e-05  max_mem: 27646M
[01/29 18:24:02] d2.utils.events INFO:  eta: 1 day, 6:27:15  iter: 23019  total_loss: 25.26  loss_mask: 2.504  loss_mask_0: 2.525  loss_mask_1: 2.499  loss_mask_2: 2.533  loss_mask_3: 2.532  loss_mask_4: 2.532  loss_mask_5: 2.508  loss_mask_6: 2.515  loss_mask_7: 2.513  loss_mask_8: 2.567  time: 3.0007  data_time: 0.0548  lr: 6.4691e-05  max_mem: 27646M
[01/29 18:25:02] d2.utils.events INFO:  eta: 1 day, 6:26:02  iter: 23039  total_loss: 24.44  loss_mask: 2.442  loss_mask_0: 2.512  loss_mask_1: 2.427  loss_mask_2: 2.439  loss_mask_3: 2.428  loss_mask_4: 2.435  loss_mask_5: 2.429  loss_mask_6: 2.433  loss_mask_7: 2.439  loss_mask_8: 2.476  time: 3.0007  data_time: 0.0549  lr: 6.466e-05  max_mem: 27646M
[01/29 18:26:01] d2.utils.events INFO:  eta: 1 day, 6:24:55  iter: 23059  total_loss: 24.77  loss_mask: 2.469  loss_mask_0: 2.512  loss_mask_1: 2.466  loss_mask_2: 2.479  loss_mask_3: 2.473  loss_mask_4: 2.472  loss_mask_5: 2.464  loss_mask_6: 2.479  loss_mask_7: 2.467  loss_mask_8: 2.482  time: 3.0007  data_time: 0.0733  lr: 6.4628e-05  max_mem: 27646M
[01/29 18:27:00] d2.utils.events INFO:  eta: 1 day, 6:23:48  iter: 23079  total_loss: 23.83  loss_mask: 2.348  loss_mask_0: 2.472  loss_mask_1: 2.35  loss_mask_2: 2.382  loss_mask_3: 2.384  loss_mask_4: 2.354  loss_mask_5: 2.324  loss_mask_6: 2.347  loss_mask_7: 2.389  loss_mask_8: 2.369  time: 3.0007  data_time: 0.0591  lr: 6.4597e-05  max_mem: 27646M
[01/29 18:27:59] d2.utils.events INFO:  eta: 1 day, 6:22:07  iter: 23099  total_loss: 24.42  loss_mask: 2.427  loss_mask_0: 2.484  loss_mask_1: 2.429  loss_mask_2: 2.43  loss_mask_3: 2.449  loss_mask_4: 2.494  loss_mask_5: 2.455  loss_mask_6: 2.425  loss_mask_7: 2.444  loss_mask_8: 2.431  time: 3.0006  data_time: 0.0567  lr: 6.4565e-05  max_mem: 27646M
[01/29 18:28:58] d2.utils.events INFO:  eta: 1 day, 6:20:33  iter: 23119  total_loss: 24.64  loss_mask: 2.437  loss_mask_0: 2.561  loss_mask_1: 2.462  loss_mask_2: 2.458  loss_mask_3: 2.458  loss_mask_4: 2.452  loss_mask_5: 2.468  loss_mask_6: 2.459  loss_mask_7: 2.458  loss_mask_8: 2.46  time: 3.0006  data_time: 0.0534  lr: 6.4534e-05  max_mem: 27646M
[01/29 18:29:57] d2.utils.events INFO:  eta: 1 day, 6:18:48  iter: 23139  total_loss: 23.66  loss_mask: 2.395  loss_mask_0: 2.374  loss_mask_1: 2.359  loss_mask_2: 2.372  loss_mask_3: 2.359  loss_mask_4: 2.366  loss_mask_5: 2.376  loss_mask_6: 2.367  loss_mask_7: 2.386  loss_mask_8: 2.362  time: 3.0005  data_time: 0.0611  lr: 6.4502e-05  max_mem: 27646M
[01/29 18:30:55] d2.utils.events INFO:  eta: 1 day, 6:17:13  iter: 23159  total_loss: 25.08  loss_mask: 2.5  loss_mask_0: 2.585  loss_mask_1: 2.486  loss_mask_2: 2.479  loss_mask_3: 2.499  loss_mask_4: 2.494  loss_mask_5: 2.505  loss_mask_6: 2.501  loss_mask_7: 2.493  loss_mask_8: 2.491  time: 3.0004  data_time: 0.0515  lr: 6.4471e-05  max_mem: 27646M
[01/29 18:31:55] d2.utils.events INFO:  eta: 1 day, 6:16:29  iter: 23179  total_loss: 23.59  loss_mask: 2.34  loss_mask_0: 2.408  loss_mask_1: 2.324  loss_mask_2: 2.362  loss_mask_3: 2.357  loss_mask_4: 2.371  loss_mask_5: 2.356  loss_mask_6: 2.342  loss_mask_7: 2.365  loss_mask_8: 2.367  time: 3.0004  data_time: 0.0649  lr: 6.4439e-05  max_mem: 27646M
[01/29 18:32:54] d2.utils.events INFO:  eta: 1 day, 6:15:14  iter: 23199  total_loss: 24.48  loss_mask: 2.432  loss_mask_0: 2.54  loss_mask_1: 2.434  loss_mask_2: 2.461  loss_mask_3: 2.462  loss_mask_4: 2.453  loss_mask_5: 2.456  loss_mask_6: 2.427  loss_mask_7: 2.429  loss_mask_8: 2.436  time: 3.0004  data_time: 0.0559  lr: 6.4408e-05  max_mem: 27646M
[01/29 18:33:52] d2.utils.events INFO:  eta: 1 day, 6:13:42  iter: 23219  total_loss: 24.83  loss_mask: 2.466  loss_mask_0: 2.579  loss_mask_1: 2.474  loss_mask_2: 2.484  loss_mask_3: 2.456  loss_mask_4: 2.452  loss_mask_5: 2.475  loss_mask_6: 2.464  loss_mask_7: 2.485  loss_mask_8: 2.471  time: 3.0003  data_time: 0.0624  lr: 6.4376e-05  max_mem: 27646M
[01/29 18:34:52] d2.utils.events INFO:  eta: 1 day, 6:13:04  iter: 23239  total_loss: 22.79  loss_mask: 2.256  loss_mask_0: 2.331  loss_mask_1: 2.268  loss_mask_2: 2.273  loss_mask_3: 2.265  loss_mask_4: 2.281  loss_mask_5: 2.26  loss_mask_6: 2.256  loss_mask_7: 2.275  loss_mask_8: 2.285  time: 3.0003  data_time: 0.0598  lr: 6.4345e-05  max_mem: 27646M
[01/29 18:35:51] d2.utils.events INFO:  eta: 1 day, 6:11:28  iter: 23259  total_loss: 25.26  loss_mask: 2.524  loss_mask_0: 2.532  loss_mask_1: 2.499  loss_mask_2: 2.515  loss_mask_3: 2.531  loss_mask_4: 2.527  loss_mask_5: 2.536  loss_mask_6: 2.51  loss_mask_7: 2.535  loss_mask_8: 2.53  time: 3.0003  data_time: 0.0701  lr: 6.4313e-05  max_mem: 27646M
[01/29 18:36:51] d2.utils.events INFO:  eta: 1 day, 6:10:54  iter: 23279  total_loss: 22.86  loss_mask: 2.287  loss_mask_0: 2.307  loss_mask_1: 2.265  loss_mask_2: 2.263  loss_mask_3: 2.293  loss_mask_4: 2.31  loss_mask_5: 2.272  loss_mask_6: 2.281  loss_mask_7: 2.286  loss_mask_8: 2.273  time: 3.0002  data_time: 0.0588  lr: 6.4282e-05  max_mem: 27646M
[01/29 18:37:50] d2.utils.events INFO:  eta: 1 day, 6:10:03  iter: 23299  total_loss: 23.47  loss_mask: 2.35  loss_mask_0: 2.373  loss_mask_1: 2.334  loss_mask_2: 2.353  loss_mask_3: 2.345  loss_mask_4: 2.36  loss_mask_5: 2.343  loss_mask_6: 2.352  loss_mask_7: 2.371  loss_mask_8: 2.343  time: 3.0002  data_time: 0.0567  lr: 6.425e-05  max_mem: 27646M
[01/29 18:38:50] d2.utils.events INFO:  eta: 1 day, 6:09:11  iter: 23319  total_loss: 24.38  loss_mask: 2.42  loss_mask_0: 2.497  loss_mask_1: 2.412  loss_mask_2: 2.439  loss_mask_3: 2.442  loss_mask_4: 2.444  loss_mask_5: 2.422  loss_mask_6: 2.42  loss_mask_7: 2.447  loss_mask_8: 2.443  time: 3.0002  data_time: 0.0485  lr: 6.4219e-05  max_mem: 27646M
[01/29 18:39:49] d2.utils.events INFO:  eta: 1 day, 6:09:19  iter: 23339  total_loss: 23.02  loss_mask: 2.304  loss_mask_0: 2.334  loss_mask_1: 2.293  loss_mask_2: 2.298  loss_mask_3: 2.296  loss_mask_4: 2.299  loss_mask_5: 2.305  loss_mask_6: 2.301  loss_mask_7: 2.301  loss_mask_8: 2.298  time: 3.0002  data_time: 0.0586  lr: 6.4187e-05  max_mem: 27646M
[01/29 18:40:49] d2.utils.events INFO:  eta: 1 day, 6:07:48  iter: 23359  total_loss: 23.72  loss_mask: 2.354  loss_mask_0: 2.417  loss_mask_1: 2.35  loss_mask_2: 2.356  loss_mask_3: 2.378  loss_mask_4: 2.373  loss_mask_5: 2.4  loss_mask_6: 2.363  loss_mask_7: 2.367  loss_mask_8: 2.372  time: 3.0002  data_time: 0.0573  lr: 6.4156e-05  max_mem: 27646M
[01/29 18:41:49] d2.utils.events INFO:  eta: 1 day, 6:07:43  iter: 23379  total_loss: 23.88  loss_mask: 2.381  loss_mask_0: 2.425  loss_mask_1: 2.37  loss_mask_2: 2.368  loss_mask_3: 2.399  loss_mask_4: 2.4  loss_mask_5: 2.383  loss_mask_6: 2.358  loss_mask_7: 2.403  loss_mask_8: 2.379  time: 3.0002  data_time: 0.0803  lr: 6.4124e-05  max_mem: 27646M
[01/29 18:42:48] d2.utils.events INFO:  eta: 1 day, 6:06:44  iter: 23399  total_loss: 24.46  loss_mask: 2.437  loss_mask_0: 2.442  loss_mask_1: 2.402  loss_mask_2: 2.441  loss_mask_3: 2.438  loss_mask_4: 2.422  loss_mask_5: 2.405  loss_mask_6: 2.44  loss_mask_7: 2.447  loss_mask_8: 2.427  time: 3.0001  data_time: 0.0605  lr: 6.4093e-05  max_mem: 27646M
[01/29 18:43:48] d2.utils.events INFO:  eta: 1 day, 6:06:00  iter: 23419  total_loss: 22.15  loss_mask: 2.226  loss_mask_0: 2.219  loss_mask_1: 2.198  loss_mask_2: 2.195  loss_mask_3: 2.227  loss_mask_4: 2.223  loss_mask_5: 2.221  loss_mask_6: 2.216  loss_mask_7: 2.246  loss_mask_8: 2.21  time: 3.0001  data_time: 0.0698  lr: 6.4061e-05  max_mem: 27646M
[01/29 18:44:48] d2.utils.events INFO:  eta: 1 day, 6:05:51  iter: 23439  total_loss: 25.28  loss_mask: 2.524  loss_mask_0: 2.588  loss_mask_1: 2.507  loss_mask_2: 2.492  loss_mask_3: 2.52  loss_mask_4: 2.535  loss_mask_5: 2.481  loss_mask_6: 2.554  loss_mask_7: 2.548  loss_mask_8: 2.52  time: 3.0001  data_time: 0.0656  lr: 6.403e-05  max_mem: 27646M
[01/29 18:45:47] d2.utils.events INFO:  eta: 1 day, 6:04:33  iter: 23459  total_loss: 25.64  loss_mask: 2.503  loss_mask_0: 2.621  loss_mask_1: 2.511  loss_mask_2: 2.563  loss_mask_3: 2.573  loss_mask_4: 2.54  loss_mask_5: 2.581  loss_mask_6: 2.482  loss_mask_7: 2.643  loss_mask_8: 2.551  time: 3.0001  data_time: 0.0557  lr: 6.3998e-05  max_mem: 27646M
[01/29 18:46:46] d2.utils.events INFO:  eta: 1 day, 6:03:01  iter: 23479  total_loss: 22.75  loss_mask: 2.265  loss_mask_0: 2.319  loss_mask_1: 2.261  loss_mask_2: 2.26  loss_mask_3: 2.272  loss_mask_4: 2.268  loss_mask_5: 2.273  loss_mask_6: 2.255  loss_mask_7: 2.285  loss_mask_8: 2.277  time: 3.0000  data_time: 0.0552  lr: 6.3966e-05  max_mem: 27646M
[01/29 18:47:45] d2.utils.events INFO:  eta: 1 day, 6:02:13  iter: 23499  total_loss: 25.41  loss_mask: 2.549  loss_mask_0: 2.584  loss_mask_1: 2.517  loss_mask_2: 2.539  loss_mask_3: 2.555  loss_mask_4: 2.537  loss_mask_5: 2.53  loss_mask_6: 2.539  loss_mask_7: 2.566  loss_mask_8: 2.54  time: 3.0000  data_time: 0.0581  lr: 6.3935e-05  max_mem: 27646M
[01/29 18:48:44] d2.utils.events INFO:  eta: 1 day, 6:01:33  iter: 23519  total_loss: 23.1  loss_mask: 2.297  loss_mask_0: 2.368  loss_mask_1: 2.297  loss_mask_2: 2.303  loss_mask_3: 2.319  loss_mask_4: 2.303  loss_mask_5: 2.311  loss_mask_6: 2.297  loss_mask_7: 2.334  loss_mask_8: 2.31  time: 2.9999  data_time: 0.0573  lr: 6.3903e-05  max_mem: 27646M
[01/29 18:49:43] d2.utils.events INFO:  eta: 1 day, 5:59:49  iter: 23539  total_loss: 22.69  loss_mask: 2.274  loss_mask_0: 2.35  loss_mask_1: 2.255  loss_mask_2: 2.255  loss_mask_3: 2.261  loss_mask_4: 2.279  loss_mask_5: 2.267  loss_mask_6: 2.263  loss_mask_7: 2.296  loss_mask_8: 2.266  time: 2.9999  data_time: 0.0588  lr: 6.3872e-05  max_mem: 27646M
[01/29 18:50:41] d2.utils.events INFO:  eta: 1 day, 5:58:27  iter: 23559  total_loss: 21.59  loss_mask: 2.159  loss_mask_0: 2.167  loss_mask_1: 2.147  loss_mask_2: 2.158  loss_mask_3: 2.16  loss_mask_4: 2.166  loss_mask_5: 2.148  loss_mask_6: 2.167  loss_mask_7: 2.159  loss_mask_8: 2.156  time: 2.9998  data_time: 0.0548  lr: 6.384e-05  max_mem: 27646M
[01/29 18:51:41] d2.utils.events INFO:  eta: 1 day, 5:57:04  iter: 23579  total_loss: 21.31  loss_mask: 2.127  loss_mask_0: 2.136  loss_mask_1: 2.111  loss_mask_2: 2.118  loss_mask_3: 2.125  loss_mask_4: 2.13  loss_mask_5: 2.136  loss_mask_6: 2.131  loss_mask_7: 2.122  loss_mask_8: 2.118  time: 2.9998  data_time: 0.0628  lr: 6.3809e-05  max_mem: 27646M
[01/29 18:52:40] d2.utils.events INFO:  eta: 1 day, 5:55:36  iter: 23599  total_loss: 21.9  loss_mask: 2.176  loss_mask_0: 2.262  loss_mask_1: 2.176  loss_mask_2: 2.185  loss_mask_3: 2.193  loss_mask_4: 2.192  loss_mask_5: 2.184  loss_mask_6: 2.194  loss_mask_7: 2.188  loss_mask_8: 2.191  time: 2.9997  data_time: 0.0520  lr: 6.3777e-05  max_mem: 27646M
[01/29 18:53:40] d2.utils.events INFO:  eta: 1 day, 5:54:33  iter: 23619  total_loss: 22.96  loss_mask: 2.296  loss_mask_0: 2.331  loss_mask_1: 2.27  loss_mask_2: 2.303  loss_mask_3: 2.297  loss_mask_4: 2.298  loss_mask_5: 2.283  loss_mask_6: 2.281  loss_mask_7: 2.309  loss_mask_8: 2.297  time: 2.9997  data_time: 0.0589  lr: 6.3746e-05  max_mem: 27646M
[01/29 18:54:39] d2.utils.events INFO:  eta: 1 day, 5:52:50  iter: 23639  total_loss: 22.69  loss_mask: 2.254  loss_mask_0: 2.372  loss_mask_1: 2.24  loss_mask_2: 2.249  loss_mask_3: 2.268  loss_mask_4: 2.282  loss_mask_5: 2.248  loss_mask_6: 2.251  loss_mask_7: 2.264  loss_mask_8: 2.263  time: 2.9997  data_time: 0.0570  lr: 6.3714e-05  max_mem: 27646M
[01/29 18:55:38] d2.utils.events INFO:  eta: 1 day, 5:52:09  iter: 23659  total_loss: 23.91  loss_mask: 2.394  loss_mask_0: 2.464  loss_mask_1: 2.361  loss_mask_2: 2.373  loss_mask_3: 2.374  loss_mask_4: 2.384  loss_mask_5: 2.386  loss_mask_6: 2.378  loss_mask_7: 2.366  loss_mask_8: 2.373  time: 2.9997  data_time: 0.0630  lr: 6.3683e-05  max_mem: 27646M
[01/29 18:56:38] d2.utils.events INFO:  eta: 1 day, 5:51:21  iter: 23679  total_loss: 23.91  loss_mask: 2.371  loss_mask_0: 2.466  loss_mask_1: 2.36  loss_mask_2: 2.378  loss_mask_3: 2.387  loss_mask_4: 2.386  loss_mask_5: 2.378  loss_mask_6: 2.377  loss_mask_7: 2.378  loss_mask_8: 2.391  time: 2.9997  data_time: 0.0671  lr: 6.3651e-05  max_mem: 27646M
[01/29 18:57:37] d2.utils.events INFO:  eta: 1 day, 5:50:13  iter: 23699  total_loss: 24.13  loss_mask: 2.393  loss_mask_0: 2.466  loss_mask_1: 2.395  loss_mask_2: 2.414  loss_mask_3: 2.4  loss_mask_4: 2.419  loss_mask_5: 2.403  loss_mask_6: 2.411  loss_mask_7: 2.433  loss_mask_8: 2.4  time: 2.9996  data_time: 0.0586  lr: 6.362e-05  max_mem: 27646M
[01/29 18:58:36] d2.utils.events INFO:  eta: 1 day, 5:49:20  iter: 23719  total_loss: 22.34  loss_mask: 2.219  loss_mask_0: 2.286  loss_mask_1: 2.222  loss_mask_2: 2.218  loss_mask_3: 2.226  loss_mask_4: 2.244  loss_mask_5: 2.223  loss_mask_6: 2.211  loss_mask_7: 2.236  loss_mask_8: 2.234  time: 2.9996  data_time: 0.0565  lr: 6.3588e-05  max_mem: 27646M
[01/29 18:59:35] d2.utils.events INFO:  eta: 1 day, 5:47:38  iter: 23739  total_loss: 23.67  loss_mask: 2.357  loss_mask_0: 2.375  loss_mask_1: 2.356  loss_mask_2: 2.38  loss_mask_3: 2.374  loss_mask_4: 2.37  loss_mask_5: 2.354  loss_mask_6: 2.35  loss_mask_7: 2.384  loss_mask_8: 2.373  time: 2.9996  data_time: 0.0576  lr: 6.3556e-05  max_mem: 27646M
[01/29 19:00:35] d2.utils.events INFO:  eta: 1 day, 5:47:24  iter: 23759  total_loss: 22.56  loss_mask: 2.243  loss_mask_0: 2.284  loss_mask_1: 2.252  loss_mask_2: 2.27  loss_mask_3: 2.256  loss_mask_4: 2.262  loss_mask_5: 2.246  loss_mask_6: 2.251  loss_mask_7: 2.264  loss_mask_8: 2.254  time: 2.9995  data_time: 0.0521  lr: 6.3525e-05  max_mem: 27646M
[01/29 19:01:34] d2.utils.events INFO:  eta: 1 day, 5:46:23  iter: 23779  total_loss: 23.73  loss_mask: 2.383  loss_mask_0: 2.381  loss_mask_1: 2.376  loss_mask_2: 2.369  loss_mask_3: 2.397  loss_mask_4: 2.382  loss_mask_5: 2.361  loss_mask_6: 2.39  loss_mask_7: 2.368  loss_mask_8: 2.377  time: 2.9995  data_time: 0.0606  lr: 6.3493e-05  max_mem: 27646M
[01/29 19:02:33] d2.utils.events INFO:  eta: 1 day, 5:45:19  iter: 23799  total_loss: 22.4  loss_mask: 2.253  loss_mask_0: 2.277  loss_mask_1: 2.218  loss_mask_2: 2.231  loss_mask_3: 2.232  loss_mask_4: 2.225  loss_mask_5: 2.236  loss_mask_6: 2.242  loss_mask_7: 2.253  loss_mask_8: 2.235  time: 2.9995  data_time: 0.0519  lr: 6.3462e-05  max_mem: 27646M
[01/29 19:03:32] d2.utils.events INFO:  eta: 1 day, 5:44:09  iter: 23819  total_loss: 23.71  loss_mask: 2.382  loss_mask_0: 2.348  loss_mask_1: 2.363  loss_mask_2: 2.376  loss_mask_3: 2.381  loss_mask_4: 2.359  loss_mask_5: 2.376  loss_mask_6: 2.376  loss_mask_7: 2.374  loss_mask_8: 2.373  time: 2.9994  data_time: 0.0543  lr: 6.343e-05  max_mem: 27646M
[01/29 19:04:31] d2.utils.events INFO:  eta: 1 day, 5:42:31  iter: 23839  total_loss: 26.54  loss_mask: 2.629  loss_mask_0: 2.754  loss_mask_1: 2.639  loss_mask_2: 2.659  loss_mask_3: 2.648  loss_mask_4: 2.666  loss_mask_5: 2.628  loss_mask_6: 2.611  loss_mask_7: 2.659  loss_mask_8: 2.653  time: 2.9994  data_time: 0.0477  lr: 6.3399e-05  max_mem: 27646M
[01/29 19:05:30] d2.utils.events INFO:  eta: 1 day, 5:41:32  iter: 23859  total_loss: 24.46  loss_mask: 2.443  loss_mask_0: 2.543  loss_mask_1: 2.404  loss_mask_2: 2.429  loss_mask_3: 2.443  loss_mask_4: 2.452  loss_mask_5: 2.434  loss_mask_6: 2.429  loss_mask_7: 2.436  loss_mask_8: 2.448  time: 2.9993  data_time: 0.0454  lr: 6.3367e-05  max_mem: 27646M
[01/29 19:06:29] d2.utils.events INFO:  eta: 1 day, 5:40:15  iter: 23879  total_loss: 22.21  loss_mask: 2.235  loss_mask_0: 2.249  loss_mask_1: 2.176  loss_mask_2: 2.212  loss_mask_3: 2.224  loss_mask_4: 2.237  loss_mask_5: 2.209  loss_mask_6: 2.212  loss_mask_7: 2.235  loss_mask_8: 2.214  time: 2.9993  data_time: 0.0461  lr: 6.3336e-05  max_mem: 27646M
[01/29 19:07:27] d2.utils.events INFO:  eta: 1 day, 5:38:48  iter: 23899  total_loss: 24.09  loss_mask: 2.421  loss_mask_0: 2.472  loss_mask_1: 2.376  loss_mask_2: 2.395  loss_mask_3: 2.404  loss_mask_4: 2.413  loss_mask_5: 2.39  loss_mask_6: 2.41  loss_mask_7: 2.397  loss_mask_8: 2.385  time: 2.9992  data_time: 0.0474  lr: 6.3304e-05  max_mem: 27646M
[01/29 19:08:26] d2.utils.events INFO:  eta: 1 day, 5:36:53  iter: 23919  total_loss: 24.78  loss_mask: 2.459  loss_mask_0: 2.515  loss_mask_1: 2.463  loss_mask_2: 2.47  loss_mask_3: 2.469  loss_mask_4: 2.476  loss_mask_5: 2.471  loss_mask_6: 2.476  loss_mask_7: 2.472  loss_mask_8: 2.495  time: 2.9992  data_time: 0.0483  lr: 6.3272e-05  max_mem: 27646M
[01/29 19:09:25] d2.utils.events INFO:  eta: 1 day, 5:35:25  iter: 23939  total_loss: 22.58  loss_mask: 2.272  loss_mask_0: 2.282  loss_mask_1: 2.225  loss_mask_2: 2.263  loss_mask_3: 2.262  loss_mask_4: 2.269  loss_mask_5: 2.246  loss_mask_6: 2.248  loss_mask_7: 2.257  loss_mask_8: 2.256  time: 2.9991  data_time: 0.0472  lr: 6.3241e-05  max_mem: 27646M
[01/29 19:10:23] d2.utils.events INFO:  eta: 1 day, 5:33:12  iter: 23959  total_loss: 21.77  loss_mask: 2.154  loss_mask_0: 2.22  loss_mask_1: 2.165  loss_mask_2: 2.187  loss_mask_3: 2.18  loss_mask_4: 2.175  loss_mask_5: 2.167  loss_mask_6: 2.151  loss_mask_7: 2.184  loss_mask_8: 2.167  time: 2.9990  data_time: 0.0452  lr: 6.3209e-05  max_mem: 27646M
[01/29 19:11:22] d2.utils.events INFO:  eta: 1 day, 5:31:44  iter: 23979  total_loss: 23.68  loss_mask: 2.389  loss_mask_0: 2.385  loss_mask_1: 2.362  loss_mask_2: 2.361  loss_mask_3: 2.358  loss_mask_4: 2.363  loss_mask_5: 2.374  loss_mask_6: 2.385  loss_mask_7: 2.36  loss_mask_8: 2.363  time: 2.9990  data_time: 0.0499  lr: 6.3178e-05  max_mem: 27646M
[01/29 19:12:20] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 19:12:21] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 19:12:21] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 19:25:54] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.9150379629359353, 'error_1pix': 0.48192137814165237, 'error_3pix': 0.1958734544068807, 'mIoU': 5.211970092599652, 'fwIoU': 13.066764078311829, 'IoU-0': 0.0002444489440004137, 'IoU-1': 49.78690926599881, 'IoU-2': 2.9477942832055124, 'IoU-3': 5.261166842078148, 'IoU-4': 4.653020497884502, 'IoU-5': 4.45972791914724, 'IoU-6': 4.025086508423281, 'IoU-7': 3.252189323629514, 'IoU-8': 6.299175666575477, 'IoU-9': 17.07161187189475, 'IoU-10': 20.714445275470815, 'IoU-11': 26.38681152106553, 'IoU-12': 23.657900295543673, 'IoU-13': 20.30683156829116, 'IoU-14': 19.166856646509984, 'IoU-15': 18.009000620278123, 'IoU-16': 17.90155016147825, 'IoU-17': 15.999458105180894, 'IoU-18': 14.620757983266996, 'IoU-19': 12.8834308716231, 'IoU-20': 11.658066049868959, 'IoU-21': 12.3464923143018, 'IoU-22': 12.392852638193359, 'IoU-23': 10.748038951100158, 'IoU-24': 11.108177209810712, 'IoU-25': 9.762171021764662, 'IoU-26': 9.369089505357202, 'IoU-27': 8.928134302514277, 'IoU-28': 8.287981994369476, 'IoU-29': 7.906639044822084, 'IoU-30': 7.735314849775309, 'IoU-31': 7.23950942652472, 'IoU-32': 6.636993842181366, 'IoU-33': 6.516302778504938, 'IoU-34': 6.6033214839887515, 'IoU-35': 6.745834316286979, 'IoU-36': 6.468133412433058, 'IoU-37': 6.506980686051815, 'IoU-38': 6.314049739546694, 'IoU-39': 5.960815021258462, 'IoU-40': 5.9753712816074, 'IoU-41': 6.241858773931606, 'IoU-42': 6.158664886843813, 'IoU-43': 6.57458152320434, 'IoU-44': 6.914987504743365, 'IoU-45': 7.082614456801957, 'IoU-46': 6.9450248341611385, 'IoU-47': 6.84580744720737, 'IoU-48': 6.5883949062907385, 'IoU-49': 6.791114878596422, 'IoU-50': 7.1817686517196515, 'IoU-51': 6.99496393638145, 'IoU-52': 7.140280893257704, 'IoU-53': 7.230194321254826, 'IoU-54': 7.411562879823257, 'IoU-55': 7.568490320366355, 'IoU-56': 7.112152478918301, 'IoU-57': 7.159389576629185, 'IoU-58': 6.870423151571297, 'IoU-59': 6.63992819255963, 'IoU-60': 6.336335546967893, 'IoU-61': 6.000883677277892, 'IoU-62': 5.661823346778725, 'IoU-63': 5.150055039584348, 'IoU-64': 5.028519403526755, 'IoU-65': 4.7555758048900465, 'IoU-66': 4.51837011336822, 'IoU-67': 4.536271879346988, 'IoU-68': 4.50423144951518, 'IoU-69': 4.325498470317815, 'IoU-70': 4.085980762275045, 'IoU-71': 4.129646965548735, 'IoU-72': 4.011463752252191, 'IoU-73': 3.781956216645326, 'IoU-74': 3.7563051262949267, 'IoU-75': 3.524894860594012, 'IoU-76': 3.8472386116394355, 'IoU-77': 3.6593675602901805, 'IoU-78': 3.6414554951708644, 'IoU-79': 3.642134626459593, 'IoU-80': 3.6921660651825348, 'IoU-81': 3.7499073754165875, 'IoU-82': 3.681745614652373, 'IoU-83': 3.995550911307924, 'IoU-84': 3.882871507384157, 'IoU-85': 3.93445779191293, 'IoU-86': 3.9337401541892394, 'IoU-87': 4.000830768536557, 'IoU-88': 4.081745577045183, 'IoU-89': 4.0381388509592, 'IoU-90': 3.8824953334441825, 'IoU-91': 4.002969822306612, 'IoU-92': 3.920469735924305, 'IoU-93': 4.03549966864776, 'IoU-94': 4.197489288074042, 'IoU-95': 4.246609118011206, 'IoU-96': 4.172844960700706, 'IoU-97': 4.483573180969087, 'IoU-98': 4.7023548407739595, 'IoU-99': 4.451930970590078, 'IoU-100': 4.292332612115214, 'IoU-101': 4.546627159529887, 'IoU-102': 4.6608201633234145, 'IoU-103': 4.503251042335528, 'IoU-104': 4.310216319093387, 'IoU-105': 4.499573658490174, 'IoU-106': 4.510238020627707, 'IoU-107': 4.947619369178493, 'IoU-108': 4.8137385476606, 'IoU-109': 4.632155739561733, 'IoU-110': 4.473551235427148, 'IoU-111': 4.401018291724351, 'IoU-112': 4.251566776064142, 'IoU-113': 4.4570970491724555, 'IoU-114': 4.3798336781368405, 'IoU-115': 4.162051276671844, 'IoU-116': 4.100088148004757, 'IoU-117': 4.234463625905241, 'IoU-118': 4.169039949552723, 'IoU-119': 4.468985315437571, 'IoU-120': 4.385479661620815, 'IoU-121': 4.163959067007089, 'IoU-122': 3.8877692932527355, 'IoU-123': 3.6798788169256054, 'IoU-124': 3.446797509006025, 'IoU-125': 3.257815178509909, 'IoU-126': 3.6068832233744486, 'IoU-127': 3.3903923761022656, 'IoU-128': 3.135363307573998, 'IoU-129': 3.1393181854479715, 'IoU-130': 3.205474712281665, 'IoU-131': 3.2357834987291905, 'IoU-132': 3.1544148460438253, 'IoU-133': 3.119590720708716, 'IoU-134': 3.22140524388964, 'IoU-135': 3.3053484514854024, 'IoU-136': 3.0810206660566806, 'IoU-137': 3.044615535558587, 'IoU-138': 2.7972645954963262, 'IoU-139': 2.9685019521516, 'IoU-140': 2.880340745858149, 'IoU-141': 2.7315936102401803, 'IoU-142': 3.0293653011718593, 'IoU-143': 2.619156673904624, 'IoU-144': 2.5444957898822143, 'IoU-145': 2.625546212372961, 'IoU-146': 2.726562275193924, 'IoU-147': 2.9146523630682135, 'IoU-148': 2.8301532406113235, 'IoU-149': 2.3944383499265207, 'IoU-150': 2.453827137589079, 'IoU-151': 2.7555392349988868, 'IoU-152': 2.6512968299711814, 'IoU-153': 2.1906618794196593, 'IoU-154': 2.1336372959491556, 'IoU-155': 2.1493516552821714, 'IoU-156': 2.261183454900732, 'IoU-157': 2.198604227972016, 'IoU-158': 2.158680533556867, 'IoU-159': 2.0490332529933513, 'IoU-160': 2.037950610046668, 'IoU-161': 2.0580467835732894, 'IoU-162': 2.2473792974931928, 'IoU-163': 2.05927805726746, 'IoU-164': 1.84564097529424, 'IoU-165': 1.7138706407525395, 'IoU-166': 1.7574863641419278, 'IoU-167': 1.6355094102935317, 'IoU-168': 1.4927246923784718, 'IoU-169': 2.0915482680815876, 'IoU-170': 2.6063147654073493, 'IoU-171': 1.9976716572168465, 'IoU-172': 1.4328667290575656, 'IoU-173': 1.4343442384275213, 'IoU-174': 1.5198354845814084, 'IoU-175': 1.2756842316198094, 'IoU-176': 1.1822122266022281, 'IoU-177': 1.1443852988316705, 'IoU-178': 0.6460738990723788, 'IoU-179': 0.7367847188423082, 'IoU-180': 0.9574753821768095, 'IoU-181': 0.7298822299625919, 'IoU-182': 0.7213193095677565, 'IoU-183': 0.19463431115792346, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 9.824480706713482, 'pACC': 19.66676775073968, 'ACC-0': 0.0012174469609926117, 'ACC-1': 50.50428265637462, 'ACC-2': 5.31335421917711, 'ACC-3': 20.64813252886764, 'ACC-4': 17.434028350477448, 'ACC-5': 17.51585672058241, 'ACC-6': 16.716766953471407, 'ACC-7': 15.309698050326162, 'ACC-8': 16.478785032096447, 'ACC-9': 32.42304316106343, 'ACC-10': 39.986615230583354, 'ACC-11': 45.40432494495183, 'ACC-12': 40.26711233109218, 'ACC-13': 33.78192381369054, 'ACC-14': 31.694367565894144, 'ACC-15': 30.074692291433415, 'ACC-16': 29.972771778981855, 'ACC-17': 29.47637297254641, 'ACC-18': 26.40485521697493, 'ACC-19': 23.739779390301887, 'ACC-20': 21.878377849094083, 'ACC-21': 23.307103615914134, 'ACC-22': 21.759282580278814, 'ACC-23': 19.724008349407157, 'ACC-24': 20.906133254791364, 'ACC-25': 18.827654558683538, 'ACC-26': 18.457377489122855, 'ACC-27': 16.94083620850317, 'ACC-28': 16.112977170778674, 'ACC-29': 14.951468384540703, 'ACC-30': 15.112375295268505, 'ACC-31': 13.590500696991334, 'ACC-32': 12.399123503435332, 'ACC-33': 12.5302236535365, 'ACC-34': 12.903389577095927, 'ACC-35': 12.79074419340573, 'ACC-36': 12.195444233090868, 'ACC-37': 12.423877480989574, 'ACC-38': 11.81784743520814, 'ACC-39': 10.916855145446164, 'ACC-40': 10.802237545048396, 'ACC-41': 11.53363000511737, 'ACC-42': 11.433767449664039, 'ACC-43': 12.095128911828974, 'ACC-44': 12.436995324446473, 'ACC-45': 12.839338236114923, 'ACC-46': 12.860701932712074, 'ACC-47': 12.581540604789776, 'ACC-48': 12.141330482151, 'ACC-49': 12.466016679210663, 'ACC-50': 13.053090781131957, 'ACC-51': 12.752578119877999, 'ACC-52': 13.058890977011375, 'ACC-53': 13.264980507184331, 'ACC-54': 13.415959962070085, 'ACC-55': 13.612662757145905, 'ACC-56': 13.040480050635505, 'ACC-57': 13.049304860771954, 'ACC-58': 12.727584298972616, 'ACC-59': 12.621428255532535, 'ACC-60': 12.17802623057864, 'ACC-61': 11.643860314543357, 'ACC-62': 10.992199214453604, 'ACC-63': 10.069243079565627, 'ACC-64': 9.797302405290779, 'ACC-65': 9.33364723152184, 'ACC-66': 8.909413751237592, 'ACC-67': 9.021576078089732, 'ACC-68': 8.916320875278753, 'ACC-69': 8.355054989180747, 'ACC-70': 7.8432547860576225, 'ACC-71': 8.102333802118853, 'ACC-72': 7.8878120623748895, 'ACC-73': 7.392735867944801, 'ACC-74': 7.294435053548441, 'ACC-75': 6.886853883787179, 'ACC-76': 7.382202690125517, 'ACC-77': 7.101144696931821, 'ACC-78': 7.074724037789835, 'ACC-79': 7.006033437018587, 'ACC-80': 6.980757209453126, 'ACC-81': 6.981010549497743, 'ACC-82': 6.8401609454928884, 'ACC-83': 7.312757072030196, 'ACC-84': 7.061529794727534, 'ACC-85': 7.104219490828124, 'ACC-86': 7.09252556702092, 'ACC-87': 7.18114807930789, 'ACC-88': 7.2780359472055745, 'ACC-89': 7.11270378456267, 'ACC-90': 6.777037335784451, 'ACC-91': 7.040208730620311, 'ACC-92': 6.933338111219229, 'ACC-93': 7.170527132721687, 'ACC-94': 7.478284324816142, 'ACC-95': 7.576943296324161, 'ACC-96': 7.477315491811728, 'ACC-97': 7.884154800628472, 'ACC-98': 8.238140568699553, 'ACC-99': 7.811879294079714, 'ACC-100': 7.513702745901341, 'ACC-101': 7.970114568986418, 'ACC-102': 8.194245582238333, 'ACC-103': 7.940988948710682, 'ACC-104': 7.5803349647081975, 'ACC-105': 7.995860608123863, 'ACC-106': 8.016363811338397, 'ACC-107': 8.907097850823945, 'ACC-108': 8.651107235271018, 'ACC-109': 8.289611514380928, 'ACC-110': 8.172968064247277, 'ACC-111': 8.159345334407645, 'ACC-112': 7.997689749816321, 'ACC-113': 8.367811547991213, 'ACC-114': 8.213675160723573, 'ACC-115': 7.754837400207479, 'ACC-116': 7.68353112997983, 'ACC-117': 7.821095258722184, 'ACC-118': 7.747501046522711, 'ACC-119': 8.39416230580943, 'ACC-120': 8.315543771984384, 'ACC-121': 7.995132690505703, 'ACC-122': 7.482757319293876, 'ACC-123': 7.076908198449086, 'ACC-124': 6.754351523972338, 'ACC-125': 6.402911581170875, 'ACC-126': 7.08590242169783, 'ACC-127': 6.744000504630451, 'ACC-128': 6.288091953686527, 'ACC-129': 6.29076174776083, 'ACC-130': 6.524430984178742, 'ACC-131': 6.600328434724761, 'ACC-132': 6.351532942599686, 'ACC-133': 6.29202474024781, 'ACC-134': 6.474726411029728, 'ACC-135': 6.762656062938259, 'ACC-136': 6.329202385389489, 'ACC-137': 6.276364907492423, 'ACC-138': 5.824999365433917, 'ACC-139': 6.323739314434971, 'ACC-140': 6.056863904639324, 'ACC-141': 5.684360057158342, 'ACC-142': 6.266653042938324, 'ACC-143': 5.390199783798939, 'ACC-144': 5.272202166064982, 'ACC-145': 5.293320512533822, 'ACC-146': 5.455210070594687, 'ACC-147': 5.795727509162169, 'ACC-148': 5.514181346721784, 'ACC-149': 4.6926736364290935, 'ACC-150': 4.797432586102486, 'ACC-151': 5.486297844040657, 'ACC-152': 5.263756827837346, 'ACC-153': 4.700067791641474, 'ACC-154': 4.558354380291828, 'ACC-155': 4.565982108301719, 'ACC-156': 4.899325822360979, 'ACC-157': 4.887217533444122, 'ACC-158': 5.001051441604062, 'ACC-159': 4.792067754127598, 'ACC-160': 4.6496799077048365, 'ACC-161': 4.5116646118676575, 'ACC-162': 4.80822728882092, 'ACC-163': 4.371360829879832, 'ACC-164': 4.053634112233993, 'ACC-165': 3.837186772417868, 'ACC-166': 4.058725268821718, 'ACC-167': 3.6010401846901074, 'ACC-168': 3.365743019902947, 'ACC-169': 4.904078484908571, 'ACC-170': 6.275643482828627, 'ACC-171': 5.0557577115734675, 'ACC-172': 3.3318516872245065, 'ACC-173': 3.864678855930131, 'ACC-174': 4.193438351032003, 'ACC-175': 3.2602485953420266, 'ACC-176': 2.7536931158579057, 'ACC-177': 2.8224533974078607, 'ACC-178': 2.0167622476632716, 'ACC-179': 2.045524173177704, 'ACC-180': 2.142808764265637, 'ACC-181': 1.4091112579675542, 'ACC-182': 1.5591498475440013, 'ACC-183': 0.2888751291933392, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 19:25:54] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 19:25:54] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 19:25:54] d2.evaluation.testing INFO: copypaste: 2.9150,0.4819,0.1959,5.2120,13.0668,9.8245,19.6668
[01/29 19:25:54] d2.utils.events INFO:  eta: 1 day, 5:30:32  iter: 23999  total_loss: 22.47  loss_mask: 2.232  loss_mask_0: 2.271  loss_mask_1: 2.238  loss_mask_2: 2.272  loss_mask_3: 2.242  loss_mask_4: 2.252  loss_mask_5: 2.229  loss_mask_6: 2.253  loss_mask_7: 2.241  loss_mask_8: 2.237  time: 2.9989  data_time: 0.0423  lr: 6.3146e-05  max_mem: 27646M
[01/29 19:26:53] d2.utils.events INFO:  eta: 1 day, 5:29:17  iter: 24019  total_loss: 22.5  loss_mask: 2.263  loss_mask_0: 2.267  loss_mask_1: 2.238  loss_mask_2: 2.259  loss_mask_3: 2.258  loss_mask_4: 2.259  loss_mask_5: 2.245  loss_mask_6: 2.243  loss_mask_7: 2.251  loss_mask_8: 2.258  time: 2.9988  data_time: 0.0495  lr: 6.3115e-05  max_mem: 27646M
[01/29 19:27:52] d2.utils.events INFO:  eta: 1 day, 5:27:49  iter: 24039  total_loss: 23.95  loss_mask: 2.4  loss_mask_0: 2.452  loss_mask_1: 2.362  loss_mask_2: 2.368  loss_mask_3: 2.382  loss_mask_4: 2.46  loss_mask_5: 2.374  loss_mask_6: 2.409  loss_mask_7: 2.399  loss_mask_8: 2.363  time: 2.9988  data_time: 0.0502  lr: 6.3083e-05  max_mem: 27646M
[01/29 19:28:50] d2.utils.events INFO:  eta: 1 day, 5:26:44  iter: 24059  total_loss: 23.77  loss_mask: 2.365  loss_mask_0: 2.414  loss_mask_1: 2.32  loss_mask_2: 2.366  loss_mask_3: 2.405  loss_mask_4: 2.401  loss_mask_5: 2.378  loss_mask_6: 2.357  loss_mask_7: 2.375  loss_mask_8: 2.383  time: 2.9987  data_time: 0.0477  lr: 6.3051e-05  max_mem: 27646M
[01/29 19:29:49] d2.utils.events INFO:  eta: 1 day, 5:25:38  iter: 24079  total_loss: 22.3  loss_mask: 2.25  loss_mask_0: 2.222  loss_mask_1: 2.239  loss_mask_2: 2.238  loss_mask_3: 2.201  loss_mask_4: 2.202  loss_mask_5: 2.243  loss_mask_6: 2.241  loss_mask_7: 2.229  loss_mask_8: 2.212  time: 2.9987  data_time: 0.0443  lr: 6.302e-05  max_mem: 27646M
[01/29 19:30:47] d2.utils.events INFO:  eta: 1 day, 5:24:30  iter: 24099  total_loss: 21.12  loss_mask: 2.095  loss_mask_0: 2.15  loss_mask_1: 2.074  loss_mask_2: 2.115  loss_mask_3: 2.097  loss_mask_4: 2.116  loss_mask_5: 2.092  loss_mask_6: 2.116  loss_mask_7: 2.117  loss_mask_8: 2.091  time: 2.9986  data_time: 0.0488  lr: 6.2988e-05  max_mem: 27646M
[01/29 19:31:46] d2.utils.events INFO:  eta: 1 day, 5:23:24  iter: 24119  total_loss: 24.24  loss_mask: 2.409  loss_mask_0: 2.48  loss_mask_1: 2.39  loss_mask_2: 2.425  loss_mask_3: 2.429  loss_mask_4: 2.426  loss_mask_5: 2.418  loss_mask_6: 2.416  loss_mask_7: 2.418  loss_mask_8: 2.425  time: 2.9986  data_time: 0.0464  lr: 6.2957e-05  max_mem: 27646M
[01/29 19:32:45] d2.utils.events INFO:  eta: 1 day, 5:22:11  iter: 24139  total_loss: 24.65  loss_mask: 2.45  loss_mask_0: 2.493  loss_mask_1: 2.43  loss_mask_2: 2.461  loss_mask_3: 2.468  loss_mask_4: 2.469  loss_mask_5: 2.455  loss_mask_6: 2.451  loss_mask_7: 2.471  loss_mask_8: 2.463  time: 2.9985  data_time: 0.0501  lr: 6.2925e-05  max_mem: 27646M
[01/29 19:33:44] d2.utils.events INFO:  eta: 1 day, 5:21:20  iter: 24159  total_loss: 24.62  loss_mask: 2.451  loss_mask_0: 2.518  loss_mask_1: 2.431  loss_mask_2: 2.459  loss_mask_3: 2.465  loss_mask_4: 2.462  loss_mask_5: 2.452  loss_mask_6: 2.456  loss_mask_7: 2.459  loss_mask_8: 2.467  time: 2.9985  data_time: 0.0516  lr: 6.2894e-05  max_mem: 27646M
[01/29 19:34:44] d2.utils.events INFO:  eta: 1 day, 5:20:27  iter: 24179  total_loss: 25.08  loss_mask: 2.506  loss_mask_0: 2.547  loss_mask_1: 2.495  loss_mask_2: 2.51  loss_mask_3: 2.518  loss_mask_4: 2.516  loss_mask_5: 2.512  loss_mask_6: 2.511  loss_mask_7: 2.51  loss_mask_8: 2.517  time: 2.9985  data_time: 0.0580  lr: 6.2862e-05  max_mem: 27646M
[01/29 19:35:43] d2.utils.events INFO:  eta: 1 day, 5:19:41  iter: 24199  total_loss: 26.81  loss_mask: 2.686  loss_mask_0: 2.726  loss_mask_1: 2.663  loss_mask_2: 2.657  loss_mask_3: 2.691  loss_mask_4: 2.681  loss_mask_5: 2.662  loss_mask_6: 2.672  loss_mask_7: 2.687  loss_mask_8: 2.684  time: 2.9984  data_time: 0.0632  lr: 6.283e-05  max_mem: 27646M
[01/29 19:36:42] d2.utils.events INFO:  eta: 1 day, 5:18:54  iter: 24219  total_loss: 22.86  loss_mask: 2.296  loss_mask_0: 2.286  loss_mask_1: 2.303  loss_mask_2: 2.281  loss_mask_3: 2.285  loss_mask_4: 2.29  loss_mask_5: 2.271  loss_mask_6: 2.293  loss_mask_7: 2.286  loss_mask_8: 2.278  time: 2.9984  data_time: 0.0523  lr: 6.2799e-05  max_mem: 27646M
[01/29 19:37:42] d2.utils.events INFO:  eta: 1 day, 5:17:55  iter: 24239  total_loss: 24.39  loss_mask: 2.468  loss_mask_0: 2.489  loss_mask_1: 2.431  loss_mask_2: 2.439  loss_mask_3: 2.423  loss_mask_4: 2.429  loss_mask_5: 2.426  loss_mask_6: 2.435  loss_mask_7: 2.448  loss_mask_8: 2.432  time: 2.9984  data_time: 0.0570  lr: 6.2767e-05  max_mem: 27646M
[01/29 19:38:42] d2.utils.events INFO:  eta: 1 day, 5:17:03  iter: 24259  total_loss: 22.98  loss_mask: 2.286  loss_mask_0: 2.338  loss_mask_1: 2.282  loss_mask_2: 2.306  loss_mask_3: 2.299  loss_mask_4: 2.31  loss_mask_5: 2.279  loss_mask_6: 2.288  loss_mask_7: 2.308  loss_mask_8: 2.31  time: 2.9984  data_time: 0.0561  lr: 6.2736e-05  max_mem: 27646M
[01/29 19:39:42] d2.utils.events INFO:  eta: 1 day, 5:16:17  iter: 24279  total_loss: 21.77  loss_mask: 2.168  loss_mask_0: 2.236  loss_mask_1: 2.155  loss_mask_2: 2.181  loss_mask_3: 2.174  loss_mask_4: 2.178  loss_mask_5: 2.174  loss_mask_6: 2.158  loss_mask_7: 2.185  loss_mask_8: 2.182  time: 2.9984  data_time: 0.0607  lr: 6.2704e-05  max_mem: 27646M
[01/29 19:40:43] d2.utils.events INFO:  eta: 1 day, 5:15:47  iter: 24299  total_loss: 23.67  loss_mask: 2.361  loss_mask_0: 2.39  loss_mask_1: 2.348  loss_mask_2: 2.369  loss_mask_3: 2.38  loss_mask_4: 2.372  loss_mask_5: 2.359  loss_mask_6: 2.349  loss_mask_7: 2.373  loss_mask_8: 2.363  time: 2.9984  data_time: 0.0591  lr: 6.2672e-05  max_mem: 27646M
[01/29 19:41:42] d2.utils.events INFO:  eta: 1 day, 5:14:48  iter: 24319  total_loss: 24.57  loss_mask: 2.474  loss_mask_0: 2.494  loss_mask_1: 2.426  loss_mask_2: 2.469  loss_mask_3: 2.478  loss_mask_4: 2.44  loss_mask_5: 2.432  loss_mask_6: 2.478  loss_mask_7: 2.455  loss_mask_8: 2.462  time: 2.9984  data_time: 0.0627  lr: 6.2641e-05  max_mem: 27646M
[01/29 19:42:42] d2.utils.events INFO:  eta: 1 day, 5:13:51  iter: 24339  total_loss: 24.04  loss_mask: 2.395  loss_mask_0: 2.42  loss_mask_1: 2.362  loss_mask_2: 2.396  loss_mask_3: 2.385  loss_mask_4: 2.393  loss_mask_5: 2.376  loss_mask_6: 2.38  loss_mask_7: 2.39  loss_mask_8: 2.391  time: 2.9984  data_time: 0.0570  lr: 6.2609e-05  max_mem: 27646M
[01/29 19:43:42] d2.utils.events INFO:  eta: 1 day, 5:12:54  iter: 24359  total_loss: 23.06  loss_mask: 2.293  loss_mask_0: 2.328  loss_mask_1: 2.259  loss_mask_2: 2.317  loss_mask_3: 2.32  loss_mask_4: 2.32  loss_mask_5: 2.257  loss_mask_6: 2.268  loss_mask_7: 2.328  loss_mask_8: 2.307  time: 2.9984  data_time: 0.0514  lr: 6.2578e-05  max_mem: 27646M
[01/29 19:44:41] d2.utils.events INFO:  eta: 1 day, 5:11:37  iter: 24379  total_loss: 24.4  loss_mask: 2.442  loss_mask_0: 2.474  loss_mask_1: 2.427  loss_mask_2: 2.444  loss_mask_3: 2.431  loss_mask_4: 2.443  loss_mask_5: 2.432  loss_mask_6: 2.42  loss_mask_7: 2.432  loss_mask_8: 2.443  time: 2.9983  data_time: 0.0547  lr: 6.2546e-05  max_mem: 27646M
[01/29 19:45:41] d2.utils.events INFO:  eta: 1 day, 5:10:54  iter: 24399  total_loss: 22.3  loss_mask: 2.222  loss_mask_0: 2.269  loss_mask_1: 2.211  loss_mask_2: 2.226  loss_mask_3: 2.234  loss_mask_4: 2.241  loss_mask_5: 2.208  loss_mask_6: 2.209  loss_mask_7: 2.234  loss_mask_8: 2.226  time: 2.9983  data_time: 0.0516  lr: 6.2514e-05  max_mem: 27646M
[01/29 19:46:41] d2.utils.events INFO:  eta: 1 day, 5:10:01  iter: 24419  total_loss: 23.88  loss_mask: 2.405  loss_mask_0: 2.524  loss_mask_1: 2.375  loss_mask_2: 2.382  loss_mask_3: 2.374  loss_mask_4: 2.39  loss_mask_5: 2.381  loss_mask_6: 2.4  loss_mask_7: 2.386  loss_mask_8: 2.405  time: 2.9983  data_time: 0.0578  lr: 6.2483e-05  max_mem: 27646M
[01/29 19:47:41] d2.utils.events INFO:  eta: 1 day, 5:09:35  iter: 24439  total_loss: 21.97  loss_mask: 2.19  loss_mask_0: 2.235  loss_mask_1: 2.184  loss_mask_2: 2.212  loss_mask_3: 2.187  loss_mask_4: 2.205  loss_mask_5: 2.198  loss_mask_6: 2.195  loss_mask_7: 2.207  loss_mask_8: 2.215  time: 2.9983  data_time: 0.0724  lr: 6.2451e-05  max_mem: 27646M
[01/29 19:48:41] d2.utils.events INFO:  eta: 1 day, 5:08:46  iter: 24459  total_loss: 24.22  loss_mask: 2.417  loss_mask_0: 2.422  loss_mask_1: 2.376  loss_mask_2: 2.395  loss_mask_3: 2.392  loss_mask_4: 2.469  loss_mask_5: 2.404  loss_mask_6: 2.416  loss_mask_7: 2.423  loss_mask_8: 2.441  time: 2.9983  data_time: 0.0723  lr: 6.242e-05  max_mem: 27646M
[01/29 19:49:40] d2.utils.events INFO:  eta: 1 day, 5:08:30  iter: 24479  total_loss: 21.5  loss_mask: 2.129  loss_mask_0: 2.207  loss_mask_1: 2.114  loss_mask_2: 2.162  loss_mask_3: 2.151  loss_mask_4: 2.18  loss_mask_5: 2.125  loss_mask_6: 2.108  loss_mask_7: 2.163  loss_mask_8: 2.158  time: 2.9983  data_time: 0.0577  lr: 6.2388e-05  max_mem: 27646M
[01/29 19:50:41] d2.utils.events INFO:  eta: 1 day, 5:08:00  iter: 24499  total_loss: 23.2  loss_mask: 2.31  loss_mask_0: 2.333  loss_mask_1: 2.309  loss_mask_2: 2.309  loss_mask_3: 2.323  loss_mask_4: 2.332  loss_mask_5: 2.32  loss_mask_6: 2.317  loss_mask_7: 2.316  loss_mask_8: 2.327  time: 2.9983  data_time: 0.0713  lr: 6.2356e-05  max_mem: 27646M
[01/29 19:51:41] d2.utils.events INFO:  eta: 1 day, 5:07:48  iter: 24519  total_loss: 25.58  loss_mask: 2.532  loss_mask_0: 2.596  loss_mask_1: 2.533  loss_mask_2: 2.565  loss_mask_3: 2.568  loss_mask_4: 2.552  loss_mask_5: 2.549  loss_mask_6: 2.515  loss_mask_7: 2.567  loss_mask_8: 2.568  time: 2.9983  data_time: 0.0698  lr: 6.2325e-05  max_mem: 27646M
[01/29 19:52:40] d2.utils.events INFO:  eta: 1 day, 5:07:09  iter: 24539  total_loss: 21.54  loss_mask: 2.153  loss_mask_0: 2.19  loss_mask_1: 2.132  loss_mask_2: 2.152  loss_mask_3: 2.146  loss_mask_4: 2.15  loss_mask_5: 2.16  loss_mask_6: 2.162  loss_mask_7: 2.151  loss_mask_8: 2.158  time: 2.9983  data_time: 0.0699  lr: 6.2293e-05  max_mem: 27646M
[01/29 19:53:40] d2.utils.events INFO:  eta: 1 day, 5:06:36  iter: 24559  total_loss: 22.36  loss_mask: 2.22  loss_mask_0: 2.32  loss_mask_1: 2.222  loss_mask_2: 2.24  loss_mask_3: 2.263  loss_mask_4: 2.251  loss_mask_5: 2.21  loss_mask_6: 2.201  loss_mask_7: 2.246  loss_mask_8: 2.234  time: 2.9983  data_time: 0.0609  lr: 6.2261e-05  max_mem: 27646M
[01/29 19:54:40] d2.utils.events INFO:  eta: 1 day, 5:05:42  iter: 24579  total_loss: 22.95  loss_mask: 2.288  loss_mask_0: 2.351  loss_mask_1: 2.266  loss_mask_2: 2.276  loss_mask_3: 2.304  loss_mask_4: 2.289  loss_mask_5: 2.29  loss_mask_6: 2.286  loss_mask_7: 2.29  loss_mask_8: 2.299  time: 2.9983  data_time: 0.0625  lr: 6.223e-05  max_mem: 27646M
[01/29 19:55:39] d2.utils.events INFO:  eta: 1 day, 5:05:04  iter: 24599  total_loss: 24.64  loss_mask: 2.459  loss_mask_0: 2.562  loss_mask_1: 2.441  loss_mask_2: 2.457  loss_mask_3: 2.478  loss_mask_4: 2.455  loss_mask_5: 2.447  loss_mask_6: 2.433  loss_mask_7: 2.442  loss_mask_8: 2.463  time: 2.9983  data_time: 0.0576  lr: 6.2198e-05  max_mem: 27646M
[01/29 19:56:39] d2.utils.events INFO:  eta: 1 day, 5:04:14  iter: 24619  total_loss: 24.9  loss_mask: 2.682  loss_mask_0: 2.54  loss_mask_1: 2.459  loss_mask_2: 2.474  loss_mask_3: 2.45  loss_mask_4: 2.465  loss_mask_5: 2.459  loss_mask_6: 2.468  loss_mask_7: 2.479  loss_mask_8: 2.453  time: 2.9983  data_time: 0.0522  lr: 6.2167e-05  max_mem: 27646M
[01/29 19:57:39] d2.utils.events INFO:  eta: 1 day, 5:03:47  iter: 24639  total_loss: 21.93  loss_mask: 2.271  loss_mask_0: 2.251  loss_mask_1: 2.167  loss_mask_2: 2.186  loss_mask_3: 2.178  loss_mask_4: 2.191  loss_mask_5: 2.163  loss_mask_6: 2.167  loss_mask_7: 2.189  loss_mask_8: 2.208  time: 2.9983  data_time: 0.0587  lr: 6.2135e-05  max_mem: 27646M
[01/29 19:58:38] d2.utils.events INFO:  eta: 1 day, 5:02:48  iter: 24659  total_loss: 21.09  loss_mask: 2.241  loss_mask_0: 2.102  loss_mask_1: 2.089  loss_mask_2: 2.097  loss_mask_3: 2.088  loss_mask_4: 2.098  loss_mask_5: 2.086  loss_mask_6: 2.105  loss_mask_7: 2.097  loss_mask_8: 2.116  time: 2.9982  data_time: 0.0529  lr: 6.2103e-05  max_mem: 27646M
[01/29 19:59:38] d2.utils.events INFO:  eta: 1 day, 5:01:42  iter: 24679  total_loss: 22.43  loss_mask: 2.271  loss_mask_0: 2.244  loss_mask_1: 2.224  loss_mask_2: 2.246  loss_mask_3: 2.237  loss_mask_4: 2.245  loss_mask_5: 2.24  loss_mask_6: 2.246  loss_mask_7: 2.234  loss_mask_8: 2.249  time: 2.9982  data_time: 0.0549  lr: 6.2072e-05  max_mem: 27646M
[01/29 20:00:37] d2.utils.events INFO:  eta: 1 day, 5:01:03  iter: 24699  total_loss: 25.7  loss_mask: 2.574  loss_mask_0: 2.567  loss_mask_1: 2.565  loss_mask_2: 2.587  loss_mask_3: 2.587  loss_mask_4: 2.57  loss_mask_5: 2.558  loss_mask_6: 2.562  loss_mask_7: 2.569  loss_mask_8: 2.586  time: 2.9982  data_time: 0.0561  lr: 6.204e-05  max_mem: 27646M
[01/29 20:01:37] d2.utils.events INFO:  eta: 1 day, 5:00:21  iter: 24719  total_loss: 26.02  loss_mask: 2.599  loss_mask_0: 2.606  loss_mask_1: 2.572  loss_mask_2: 2.61  loss_mask_3: 2.621  loss_mask_4: 2.607  loss_mask_5: 2.604  loss_mask_6: 2.586  loss_mask_7: 2.605  loss_mask_8: 2.611  time: 2.9982  data_time: 0.0548  lr: 6.2008e-05  max_mem: 27646M
[01/29 20:02:37] d2.utils.events INFO:  eta: 1 day, 4:59:35  iter: 24739  total_loss: 22.52  loss_mask: 2.308  loss_mask_0: 2.227  loss_mask_1: 2.232  loss_mask_2: 2.245  loss_mask_3: 2.259  loss_mask_4: 2.241  loss_mask_5: 2.244  loss_mask_6: 2.278  loss_mask_7: 2.252  loss_mask_8: 2.232  time: 2.9982  data_time: 0.0513  lr: 6.1977e-05  max_mem: 27646M
[01/29 20:03:36] d2.utils.events INFO:  eta: 1 day, 4:57:54  iter: 24759  total_loss: 22.83  loss_mask: 2.281  loss_mask_0: 2.379  loss_mask_1: 2.242  loss_mask_2: 2.273  loss_mask_3: 2.281  loss_mask_4: 2.282  loss_mask_5: 2.26  loss_mask_6: 2.245  loss_mask_7: 2.271  loss_mask_8: 2.285  time: 2.9981  data_time: 0.0537  lr: 6.1945e-05  max_mem: 27646M
[01/29 20:04:35] d2.utils.events INFO:  eta: 1 day, 4:56:41  iter: 24779  total_loss: 21.55  loss_mask: 2.162  loss_mask_0: 2.178  loss_mask_1: 2.143  loss_mask_2: 2.156  loss_mask_3: 2.156  loss_mask_4: 2.148  loss_mask_5: 2.145  loss_mask_6: 2.151  loss_mask_7: 2.152  loss_mask_8: 2.16  time: 2.9981  data_time: 0.0522  lr: 6.1914e-05  max_mem: 27646M
[01/29 20:05:34] d2.utils.events INFO:  eta: 1 day, 4:55:49  iter: 24799  total_loss: 22.79  loss_mask: 2.253  loss_mask_0: 2.319  loss_mask_1: 2.256  loss_mask_2: 2.279  loss_mask_3: 2.282  loss_mask_4: 2.294  loss_mask_5: 2.246  loss_mask_6: 2.269  loss_mask_7: 2.294  loss_mask_8: 2.279  time: 2.9981  data_time: 0.0562  lr: 6.1882e-05  max_mem: 27646M
[01/29 20:06:33] d2.utils.events INFO:  eta: 1 day, 4:54:45  iter: 24819  total_loss: 23.86  loss_mask: 2.387  loss_mask_0: 2.389  loss_mask_1: 2.371  loss_mask_2: 2.375  loss_mask_3: 2.383  loss_mask_4: 2.399  loss_mask_5: 2.376  loss_mask_6: 2.373  loss_mask_7: 2.395  loss_mask_8: 2.386  time: 2.9980  data_time: 0.0567  lr: 6.185e-05  max_mem: 27646M
[01/29 20:07:32] d2.utils.events INFO:  eta: 1 day, 4:54:09  iter: 24839  total_loss: 23.05  loss_mask: 2.321  loss_mask_0: 2.285  loss_mask_1: 2.282  loss_mask_2: 2.302  loss_mask_3: 2.309  loss_mask_4: 2.316  loss_mask_5: 2.295  loss_mask_6: 2.286  loss_mask_7: 2.314  loss_mask_8: 2.309  time: 2.9980  data_time: 0.0586  lr: 6.1819e-05  max_mem: 27646M
[01/29 20:08:32] d2.utils.events INFO:  eta: 1 day, 4:53:28  iter: 24859  total_loss: 22.43  loss_mask: 2.265  loss_mask_0: 2.29  loss_mask_1: 2.246  loss_mask_2: 2.258  loss_mask_3: 2.221  loss_mask_4: 2.248  loss_mask_5: 2.248  loss_mask_6: 2.258  loss_mask_7: 2.23  loss_mask_8: 2.215  time: 2.9980  data_time: 0.0576  lr: 6.1787e-05  max_mem: 27646M
[01/29 20:09:31] d2.utils.events INFO:  eta: 1 day, 4:52:29  iter: 24879  total_loss: 21.67  loss_mask: 2.183  loss_mask_0: 2.212  loss_mask_1: 2.129  loss_mask_2: 2.17  loss_mask_3: 2.156  loss_mask_4: 2.173  loss_mask_5: 2.175  loss_mask_6: 2.141  loss_mask_7: 2.156  loss_mask_8: 2.179  time: 2.9979  data_time: 0.0577  lr: 6.1755e-05  max_mem: 27646M
[01/29 20:10:30] d2.utils.events INFO:  eta: 1 day, 4:52:00  iter: 24899  total_loss: 24.05  loss_mask: 2.391  loss_mask_0: 2.415  loss_mask_1: 2.394  loss_mask_2: 2.409  loss_mask_3: 2.406  loss_mask_4: 2.412  loss_mask_5: 2.386  loss_mask_6: 2.385  loss_mask_7: 2.409  loss_mask_8: 2.408  time: 2.9979  data_time: 0.0536  lr: 6.1724e-05  max_mem: 27646M
[01/29 20:11:29] d2.utils.events INFO:  eta: 1 day, 4:50:41  iter: 24919  total_loss: 23.86  loss_mask: 2.39  loss_mask_0: 2.459  loss_mask_1: 2.37  loss_mask_2: 2.362  loss_mask_3: 2.389  loss_mask_4: 2.382  loss_mask_5: 2.355  loss_mask_6: 2.373  loss_mask_7: 2.383  loss_mask_8: 2.382  time: 2.9979  data_time: 0.0611  lr: 6.1692e-05  max_mem: 27646M
[01/29 20:12:28] d2.utils.events INFO:  eta: 1 day, 4:50:16  iter: 24939  total_loss: 24.97  loss_mask: 2.477  loss_mask_0: 2.643  loss_mask_1: 2.463  loss_mask_2: 2.481  loss_mask_3: 2.504  loss_mask_4: 2.499  loss_mask_5: 2.45  loss_mask_6: 2.456  loss_mask_7: 2.471  loss_mask_8: 2.477  time: 2.9978  data_time: 0.0516  lr: 6.166e-05  max_mem: 27646M
[01/29 20:13:27] d2.utils.events INFO:  eta: 1 day, 4:50:13  iter: 24959  total_loss: 22.67  loss_mask: 2.282  loss_mask_0: 2.338  loss_mask_1: 2.218  loss_mask_2: 2.267  loss_mask_3: 2.25  loss_mask_4: 2.262  loss_mask_5: 2.302  loss_mask_6: 2.276  loss_mask_7: 2.296  loss_mask_8: 2.262  time: 2.9978  data_time: 0.0558  lr: 6.1629e-05  max_mem: 27646M
[01/29 20:14:27] d2.utils.events INFO:  eta: 1 day, 4:49:26  iter: 24979  total_loss: 21.09  loss_mask: 2.101  loss_mask_0: 2.157  loss_mask_1: 2.106  loss_mask_2: 2.104  loss_mask_3: 2.107  loss_mask_4: 2.102  loss_mask_5: 2.091  loss_mask_6: 2.092  loss_mask_7: 2.099  loss_mask_8: 2.103  time: 2.9978  data_time: 0.0511  lr: 6.1597e-05  max_mem: 27646M
[01/29 20:15:26] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/model_0024999.pth
[01/29 20:15:27] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 20:15:28] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 20:15:28] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 20:29:46] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.695948256361943, 'error_1pix': 0.39786616043773715, 'error_3pix': 0.17984048474540623, 'mIoU': 6.4871300541388965, 'fwIoU': 16.164988856858606, 'IoU-0': 0.0004005577397078973, 'IoU-1': 38.565354909623714, 'IoU-2': 2.692444640559569, 'IoU-3': 4.23095921754061, 'IoU-4': 3.8496644875827797, 'IoU-5': 3.678691344287971, 'IoU-6': 3.4313227075072104, 'IoU-7': 2.676271570995769, 'IoU-8': 6.5663919269187, 'IoU-9': 16.37353143619739, 'IoU-10': 20.2284186183197, 'IoU-11': 27.72132573977373, 'IoU-12': 26.461911429103512, 'IoU-13': 24.101801200219892, 'IoU-14': 24.368185133944454, 'IoU-15': 22.943876990671264, 'IoU-16': 23.12952596903133, 'IoU-17': 21.492626191433562, 'IoU-18': 20.36986748341064, 'IoU-19': 21.000167517607558, 'IoU-20': 20.57760259319779, 'IoU-21': 20.472680593310685, 'IoU-22': 21.455262113875055, 'IoU-23': 18.996091043945803, 'IoU-24': 18.834377699577946, 'IoU-25': 18.824062113440416, 'IoU-26': 18.13143435397722, 'IoU-27': 19.652630945440848, 'IoU-28': 18.153758938328405, 'IoU-29': 18.593123706524146, 'IoU-30': 17.655447823025902, 'IoU-31': 18.81392832915851, 'IoU-32': 17.5148650926582, 'IoU-33': 16.71523004561732, 'IoU-34': 16.094885488096526, 'IoU-35': 16.397562478885412, 'IoU-36': 16.114904721255254, 'IoU-37': 15.044781960141743, 'IoU-38': 14.592233429343674, 'IoU-39': 13.382933714025619, 'IoU-40': 12.999473275057163, 'IoU-41': 12.173690169814455, 'IoU-42': 12.075536177596097, 'IoU-43': 11.476931650200669, 'IoU-44': 11.230882229086788, 'IoU-45': 11.103493019796568, 'IoU-46': 10.209931052931434, 'IoU-47': 9.757853891965391, 'IoU-48': 9.400750512222693, 'IoU-49': 9.319860919479405, 'IoU-50': 9.483055611847576, 'IoU-51': 8.878818342161326, 'IoU-52': 8.708400405762335, 'IoU-53': 8.549734458438643, 'IoU-54': 8.412718475515659, 'IoU-55': 8.256954934214338, 'IoU-56': 7.97906034380064, 'IoU-57': 7.994764003404585, 'IoU-58': 7.930241667415869, 'IoU-59': 7.719703357713555, 'IoU-60': 7.517932041501559, 'IoU-61': 6.963708996719542, 'IoU-62': 6.526437129243229, 'IoU-63': 5.9349416740924905, 'IoU-64': 5.823328831471557, 'IoU-65': 5.691245841059161, 'IoU-66': 5.411165887221362, 'IoU-67': 5.151447757262847, 'IoU-68': 5.228193686988491, 'IoU-69': 5.184145456893549, 'IoU-70': 4.755359941954782, 'IoU-71': 4.771052414513506, 'IoU-72': 4.826476199058829, 'IoU-73': 4.648799941253891, 'IoU-74': 4.495475102731136, 'IoU-75': 4.335816684711155, 'IoU-76': 4.403415150080008, 'IoU-77': 4.471752375461703, 'IoU-78': 4.213867535797401, 'IoU-79': 4.16473644617735, 'IoU-80': 4.128384358669913, 'IoU-81': 4.109852683826003, 'IoU-82': 3.921780009277239, 'IoU-83': 4.190646281460033, 'IoU-84': 4.075046372179026, 'IoU-85': 4.066026458129587, 'IoU-86': 3.9939645576813088, 'IoU-87': 4.0103861756239265, 'IoU-88': 4.008849153968113, 'IoU-89': 3.866103505615958, 'IoU-90': 3.762726440300837, 'IoU-91': 3.613138088350571, 'IoU-92': 3.6133711470340923, 'IoU-93': 3.668038257716292, 'IoU-94': 3.81155571238484, 'IoU-95': 3.703072543451281, 'IoU-96': 3.630827559167614, 'IoU-97': 3.5093529149479017, 'IoU-98': 3.690632880919452, 'IoU-99': 3.3159164266482417, 'IoU-100': 3.3365658449806435, 'IoU-101': 3.1936657780803914, 'IoU-102': 3.184157900121848, 'IoU-103': 3.066431157797601, 'IoU-104': 3.036249403218145, 'IoU-105': 3.087379451587874, 'IoU-106': 2.931972069448737, 'IoU-107': 3.0635646333812065, 'IoU-108': 3.1382256013502934, 'IoU-109': 3.119961281332203, 'IoU-110': 2.9729544980987685, 'IoU-111': 2.973643485274521, 'IoU-112': 3.0279847625204503, 'IoU-113': 2.910630491868948, 'IoU-114': 2.801704805202274, 'IoU-115': 2.693364468141553, 'IoU-116': 2.676821718045212, 'IoU-117': 2.771626501821772, 'IoU-118': 2.864235792460183, 'IoU-119': 2.771749521607263, 'IoU-120': 2.624007831003284, 'IoU-121': 2.6835954196892957, 'IoU-122': 2.763617458584093, 'IoU-123': 2.6297464531200037, 'IoU-124': 2.561471840457337, 'IoU-125': 2.629430396068851, 'IoU-126': 2.428088491512291, 'IoU-127': 2.476127086888019, 'IoU-128': 2.4559794691806807, 'IoU-129': 2.3993692780180567, 'IoU-130': 2.224141850103056, 'IoU-131': 2.315957240989444, 'IoU-132': 2.3930704967556364, 'IoU-133': 2.6999268999185144, 'IoU-134': 2.7728872747017435, 'IoU-135': 2.796437601747041, 'IoU-136': 2.749578300173929, 'IoU-137': 2.801595915153412, 'IoU-138': 2.6062016628315607, 'IoU-139': 2.390946300148227, 'IoU-140': 2.596241850064944, 'IoU-141': 2.4920479643206517, 'IoU-142': 2.537253671050601, 'IoU-143': 2.578008727896476, 'IoU-144': 2.657113766097612, 'IoU-145': 2.7043041776023924, 'IoU-146': 2.7881998009224174, 'IoU-147': 2.928727943107384, 'IoU-148': 2.8344571719001177, 'IoU-149': 2.4947886985338505, 'IoU-150': 2.427882426806442, 'IoU-151': 2.5073748055142397, 'IoU-152': 2.7548044811051797, 'IoU-153': 2.809749449012434, 'IoU-154': 2.421401703337996, 'IoU-155': 2.1432352608792486, 'IoU-156': 2.4407594530763776, 'IoU-157': 2.0569468248476506, 'IoU-158': 2.331701668508869, 'IoU-159': 2.2066275437724774, 'IoU-160': 2.1458544003949327, 'IoU-161': 2.020488792279535, 'IoU-162': 2.32077826573707, 'IoU-163': 2.1153541315982154, 'IoU-164': 1.8669118001902327, 'IoU-165': 1.7368439559752604, 'IoU-166': 1.637794652744819, 'IoU-167': 1.9406994052176683, 'IoU-168': 1.6945200763621568, 'IoU-169': 1.9394994294498826, 'IoU-170': 1.6612532311257688, 'IoU-171': 1.7347850973380752, 'IoU-172': 1.4174468896448604, 'IoU-173': 1.465619535460705, 'IoU-174': 1.5932782086675732, 'IoU-175': 2.3461161747227774, 'IoU-176': 1.692618193049535, 'IoU-177': 1.5294044898152768, 'IoU-178': 2.109398358679215, 'IoU-179': 2.9193657653793537, 'IoU-180': 1.375731288973761, 'IoU-181': 1.055627647240483, 'IoU-182': 1.989351930382684, 'IoU-183': 1.3426334554871986, 'IoU-184': 1.2197373583512199, 'IoU-185': 0.6369327165307395, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 11.799604374234141, 'pACC': 25.06472659699589, 'ACC-0': 0.0023961217257752673, 'ACC-1': 39.058871010024326, 'ACC-2': 5.013656413078206, 'ACC-3': 17.50660310432558, 'ACC-4': 14.800660286401238, 'ACC-5': 14.797449036760446, 'ACC-6': 14.492176249532196, 'ACC-7': 13.16111882910181, 'ACC-8': 18.453651977032248, 'ACC-9': 31.013663232635096, 'ACC-10': 36.13203230299078, 'ACC-11': 44.26691301884526, 'ACC-12': 42.54025351513115, 'ACC-13': 37.687876774049286, 'ACC-14': 38.127983571076996, 'ACC-15': 36.27545890855654, 'ACC-16': 35.87091232746935, 'ACC-17': 36.21379375545466, 'ACC-18': 33.726470361307264, 'ACC-19': 34.871326731938034, 'ACC-20': 34.05850859736521, 'ACC-21': 33.88855904945903, 'ACC-22': 34.80049417727745, 'ACC-23': 32.4551849818198, 'ACC-24': 32.62974414690175, 'ACC-25': 33.0295293381562, 'ACC-26': 31.92178340288268, 'ACC-27': 33.89999156692009, 'ACC-28': 31.885228657359217, 'ACC-29': 31.722109543611033, 'ACC-30': 30.735936476012814, 'ACC-31': 32.3893863490279, 'ACC-32': 30.423104593231997, 'ACC-33': 29.49269851946838, 'ACC-34': 28.84091347850647, 'ACC-35': 29.1203323558352, 'ACC-36': 28.544825689565705, 'ACC-37': 27.357949625512106, 'ACC-38': 26.465746213093233, 'ACC-39': 24.211596353475358, 'ACC-40': 22.97816299929407, 'ACC-41': 22.195878209644487, 'ACC-42': 22.172342850549352, 'ACC-43': 20.961756183496135, 'ACC-44': 20.012205139265642, 'ACC-45': 19.992362289340953, 'ACC-46': 18.94217090088292, 'ACC-47': 18.02052318133039, 'ACC-48': 17.409226951246943, 'ACC-49': 17.167852992729856, 'ACC-50': 17.314989176362793, 'ACC-51': 16.314524390729506, 'ACC-52': 16.021658057516508, 'ACC-53': 15.719596452319715, 'ACC-54': 15.230430735779418, 'ACC-55': 14.88541686268119, 'ACC-56': 14.486409572124636, 'ACC-57': 14.401791264250091, 'ACC-58': 14.553543697376782, 'ACC-59': 14.4266230626612, 'ACC-60': 14.290556530695437, 'ACC-61': 13.37694886800718, 'ACC-62': 12.532807042017549, 'ACC-63': 11.475658398594, 'ACC-64': 11.25089137056301, 'ACC-65': 11.080757727805759, 'ACC-66': 10.559647445187736, 'ACC-67': 10.239077749255515, 'ACC-68': 10.367107534280784, 'ACC-69': 10.034393460296053, 'ACC-70': 9.196648054632202, 'ACC-71': 9.394154098766265, 'ACC-72': 9.507197221784192, 'ACC-73': 9.093545876390952, 'ACC-74': 8.74283219498826, 'ACC-75': 8.502892199633301, 'ACC-76': 8.527535215175726, 'ACC-77': 8.807481280315715, 'ACC-78': 8.328258765470222, 'ACC-79': 8.2050132249099, 'ACC-80': 8.020009662475722, 'ACC-81': 7.831775781705584, 'ACC-82': 7.461550872425652, 'ACC-83': 7.860587536292113, 'ACC-84': 7.6066236944416445, 'ACC-85': 7.56493507996443, 'ACC-86': 7.4146901405026835, 'ACC-87': 7.447496253752366, 'ACC-88': 7.424885432515975, 'ACC-89': 7.078608625370565, 'ACC-90': 6.812287793805924, 'ACC-91': 6.573847002545449, 'ACC-92': 6.603109408325665, 'ACC-93': 6.742162647683507, 'ACC-94': 7.003160799998054, 'ACC-95': 6.748093140973781, 'ACC-96': 6.619095270854368, 'ACC-97': 6.3265163215701055, 'ACC-98': 6.620236359126356, 'ACC-99': 5.980336422126693, 'ACC-100': 6.01690228334497, 'ACC-101': 5.810984385397484, 'ACC-102': 5.816696873584051, 'ACC-103': 5.618376310569566, 'ACC-104': 5.579006910799046, 'ACC-105': 5.68377222005281, 'ACC-106': 5.3706572140246704, 'ACC-107': 5.581455687114081, 'ACC-108': 5.677909213036494, 'ACC-109': 5.645210444475629, 'ACC-110': 5.434532238497951, 'ACC-111': 5.513618339261163, 'ACC-112': 5.701119557115297, 'ACC-113': 5.462625337889972, 'ACC-114': 5.201682071809845, 'ACC-115': 5.006427314960985, 'ACC-116': 5.028172069719584, 'ACC-117': 5.188668251994853, 'ACC-118': 5.452708719874947, 'ACC-119': 5.2166446425684, 'ACC-120': 4.931222481085962, 'ACC-121': 5.004662460989078, 'ACC-122': 5.115816090652627, 'ACC-123': 4.865306541351455, 'ACC-124': 4.778805189491668, 'ACC-125': 4.87973738338393, 'ACC-126': 4.491559577045328, 'ACC-127': 4.515157603566055, 'ACC-128': 4.540481600603007, 'ACC-129': 4.43830444934891, 'ACC-130': 4.108096882956741, 'ACC-131': 4.280018847447986, 'ACC-132': 4.436334878172198, 'ACC-133': 5.038818238107875, 'ACC-134': 5.125725205153093, 'ACC-135': 5.133900575793855, 'ACC-136': 5.033646454528513, 'ACC-137': 5.11068013924411, 'ACC-138': 4.703086529431174, 'ACC-139': 4.3547341142018094, 'ACC-140': 4.708317389640658, 'ACC-141': 4.51704062517357, 'ACC-142': 4.609798080626272, 'ACC-143': 4.683637461551526, 'ACC-144': 4.684657039711191, 'ACC-145': 4.678279925758626, 'ACC-146': 4.804733727810651, 'ACC-147': 5.115586782706877, 'ACC-148': 4.882177765146366, 'ACC-149': 4.346348987748322, 'ACC-150': 4.280447650584891, 'ACC-151': 4.5240082150054945, 'ACC-152': 4.8107803965203315, 'ACC-153': 5.042461386247457, 'ACC-154': 4.392209631229107, 'ACC-155': 3.99716020440612, 'ACC-156': 4.6440044729714876, 'ACC-157': 4.021596961072934, 'ACC-158': 4.626625324076883, 'ACC-159': 4.287512723746551, 'ACC-160': 4.191314527439714, 'ACC-161': 3.927380875484797, 'ACC-162': 4.511739030827043, 'ACC-163': 4.283921383989104, 'ACC-164': 3.8028088622807656, 'ACC-165': 3.530033955156324, 'ACC-166': 3.476005405813768, 'ACC-167': 4.402892644532343, 'ACC-168': 3.8079330473310358, 'ACC-169': 4.587001419564726, 'ACC-170': 4.134368300751025, 'ACC-171': 4.954730726347287, 'ACC-172': 3.6624439752565103, 'ACC-173': 3.8366453059796126, 'ACC-174': 4.425692615395513, 'ACC-175': 6.72257565925096, 'ACC-176': 4.612404225679128, 'ACC-177': 4.701320798938489, 'ACC-178': 7.549578819070872, 'ACC-179': 13.036006662865883, 'ACC-180': 5.227064919231942, 'ACC-181': 3.3277196273636194, 'ACC-182': 5.890463859517779, 'ACC-183': 4.079095752570329, 'ACC-184': 2.991389496175861, 'ACC-185': 0.7526941322653807, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 20:29:46] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 20:29:46] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 20:29:46] d2.evaluation.testing INFO: copypaste: 2.6959,0.3979,0.1798,6.4871,16.1650,11.7996,25.0647
[01/29 20:29:46] d2.utils.events INFO:  eta: 1 day, 4:49:23  iter: 24999  total_loss: 22.72  loss_mask: 2.268  loss_mask_0: 2.312  loss_mask_1: 2.256  loss_mask_2: 2.276  loss_mask_3: 2.268  loss_mask_4: 2.27  loss_mask_5: 2.254  loss_mask_6: 2.259  loss_mask_7: 2.283  loss_mask_8: 2.276  time: 2.9978  data_time: 0.0547  lr: 6.1565e-05  max_mem: 27646M
[01/29 20:30:46] d2.utils.events INFO:  eta: 1 day, 4:49:34  iter: 25019  total_loss: 22.85  loss_mask: 2.287  loss_mask_0: 2.344  loss_mask_1: 2.267  loss_mask_2: 2.295  loss_mask_3: 2.281  loss_mask_4: 2.292  loss_mask_5: 2.273  loss_mask_6: 2.273  loss_mask_7: 2.296  loss_mask_8: 2.294  time: 2.9977  data_time: 0.0714  lr: 6.1534e-05  max_mem: 27646M
[01/29 20:31:45] d2.utils.events INFO:  eta: 1 day, 4:48:41  iter: 25039  total_loss: 23.76  loss_mask: 2.385  loss_mask_0: 2.408  loss_mask_1: 2.359  loss_mask_2: 2.374  loss_mask_3: 2.394  loss_mask_4: 2.378  loss_mask_5: 2.383  loss_mask_6: 2.373  loss_mask_7: 2.368  loss_mask_8: 2.371  time: 2.9977  data_time: 0.0624  lr: 6.1502e-05  max_mem: 27646M
[01/29 20:32:45] d2.utils.events INFO:  eta: 1 day, 4:48:14  iter: 25059  total_loss: 25.13  loss_mask: 2.507  loss_mask_0: 2.51  loss_mask_1: 2.487  loss_mask_2: 2.509  loss_mask_3: 2.531  loss_mask_4: 2.517  loss_mask_5: 2.525  loss_mask_6: 2.5  loss_mask_7: 2.516  loss_mask_8: 2.514  time: 2.9977  data_time: 0.0607  lr: 6.147e-05  max_mem: 27646M
[01/29 20:33:45] d2.utils.events INFO:  eta: 1 day, 4:47:57  iter: 25079  total_loss: 26.49  loss_mask: 2.629  loss_mask_0: 2.66  loss_mask_1: 2.64  loss_mask_2: 2.637  loss_mask_3: 2.652  loss_mask_4: 2.657  loss_mask_5: 2.644  loss_mask_6: 2.632  loss_mask_7: 2.656  loss_mask_8: 2.648  time: 2.9977  data_time: 0.0657  lr: 6.1439e-05  max_mem: 27646M
[01/29 20:34:45] d2.utils.events INFO:  eta: 1 day, 4:47:47  iter: 25099  total_loss: 23.52  loss_mask: 2.336  loss_mask_0: 2.418  loss_mask_1: 2.345  loss_mask_2: 2.355  loss_mask_3: 2.353  loss_mask_4: 2.362  loss_mask_5: 2.323  loss_mask_6: 2.332  loss_mask_7: 2.357  loss_mask_8: 2.337  time: 2.9977  data_time: 0.0572  lr: 6.1407e-05  max_mem: 27646M
[01/29 20:35:45] d2.utils.events INFO:  eta: 1 day, 4:47:56  iter: 25119  total_loss: 24.63  loss_mask: 2.447  loss_mask_0: 2.484  loss_mask_1: 2.456  loss_mask_2: 2.465  loss_mask_3: 2.461  loss_mask_4: 2.467  loss_mask_5: 2.456  loss_mask_6: 2.455  loss_mask_7: 2.487  loss_mask_8: 2.454  time: 2.9977  data_time: 0.0630  lr: 6.1375e-05  max_mem: 27646M
[01/29 20:36:44] d2.utils.events INFO:  eta: 1 day, 4:47:11  iter: 25139  total_loss: 23.19  loss_mask: 2.312  loss_mask_0: 2.398  loss_mask_1: 2.3  loss_mask_2: 2.327  loss_mask_3: 2.312  loss_mask_4: 2.322  loss_mask_5: 2.301  loss_mask_6: 2.318  loss_mask_7: 2.348  loss_mask_8: 2.309  time: 2.9977  data_time: 0.0508  lr: 6.1344e-05  max_mem: 27646M
[01/29 20:37:44] d2.utils.events INFO:  eta: 1 day, 4:46:42  iter: 25159  total_loss: 22.56  loss_mask: 2.253  loss_mask_0: 2.248  loss_mask_1: 2.229  loss_mask_2: 2.264  loss_mask_3: 2.249  loss_mask_4: 2.251  loss_mask_5: 2.248  loss_mask_6: 2.245  loss_mask_7: 2.291  loss_mask_8: 2.251  time: 2.9977  data_time: 0.0578  lr: 6.1312e-05  max_mem: 27646M
[01/29 20:38:43] d2.utils.events INFO:  eta: 1 day, 4:45:36  iter: 25179  total_loss: 22.18  loss_mask: 2.211  loss_mask_0: 2.27  loss_mask_1: 2.19  loss_mask_2: 2.23  loss_mask_3: 2.217  loss_mask_4: 2.226  loss_mask_5: 2.184  loss_mask_6: 2.189  loss_mask_7: 2.248  loss_mask_8: 2.209  time: 2.9976  data_time: 0.0591  lr: 6.128e-05  max_mem: 27646M
[01/29 20:39:42] d2.utils.events INFO:  eta: 1 day, 4:44:04  iter: 25199  total_loss: 22.11  loss_mask: 2.189  loss_mask_0: 2.269  loss_mask_1: 2.192  loss_mask_2: 2.228  loss_mask_3: 2.202  loss_mask_4: 2.201  loss_mask_5: 2.203  loss_mask_6: 2.179  loss_mask_7: 2.219  loss_mask_8: 2.219  time: 2.9976  data_time: 0.0543  lr: 6.1249e-05  max_mem: 27646M
[01/29 20:40:40] d2.utils.events INFO:  eta: 1 day, 4:42:43  iter: 25219  total_loss: 25.4  loss_mask: 2.56  loss_mask_0: 2.569  loss_mask_1: 2.503  loss_mask_2: 2.514  loss_mask_3: 2.557  loss_mask_4: 2.546  loss_mask_5: 2.536  loss_mask_6: 2.545  loss_mask_7: 2.477  loss_mask_8: 2.535  time: 2.9975  data_time: 0.0558  lr: 6.1217e-05  max_mem: 27646M
[01/29 20:41:40] d2.utils.events INFO:  eta: 1 day, 4:41:33  iter: 25239  total_loss: 24.65  loss_mask: 2.43  loss_mask_0: 2.429  loss_mask_1: 2.369  loss_mask_2: 2.402  loss_mask_3: 2.519  loss_mask_4: 2.45  loss_mask_5: 2.56  loss_mask_6: 2.684  loss_mask_7: 2.517  loss_mask_8: 2.472  time: 2.9975  data_time: 0.0543  lr: 6.1185e-05  max_mem: 27646M
[01/29 20:42:39] d2.utils.events INFO:  eta: 1 day, 4:39:18  iter: 25259  total_loss: 23.34  loss_mask: 2.263  loss_mask_0: 2.293  loss_mask_1: 2.25  loss_mask_2: 2.277  loss_mask_3: 2.303  loss_mask_4: 2.269  loss_mask_5: 2.317  loss_mask_6: 2.729  loss_mask_7: 2.355  loss_mask_8: 2.293  time: 2.9975  data_time: 0.0578  lr: 6.1154e-05  max_mem: 27646M
[01/29 20:43:38] d2.utils.events INFO:  eta: 1 day, 4:37:54  iter: 25279  total_loss: 21.78  loss_mask: 2.135  loss_mask_0: 2.169  loss_mask_1: 2.084  loss_mask_2: 2.11  loss_mask_3: 2.173  loss_mask_4: 2.147  loss_mask_5: 2.244  loss_mask_6: 2.403  loss_mask_7: 2.207  loss_mask_8: 2.168  time: 2.9974  data_time: 0.0554  lr: 6.1122e-05  max_mem: 27646M
[01/29 20:44:36] d2.utils.events INFO:  eta: 1 day, 4:35:43  iter: 25299  total_loss: 22.39  loss_mask: 2.237  loss_mask_0: 2.258  loss_mask_1: 2.192  loss_mask_2: 2.217  loss_mask_3: 2.246  loss_mask_4: 2.23  loss_mask_5: 2.27  loss_mask_6: 2.358  loss_mask_7: 2.242  loss_mask_8: 2.222  time: 2.9974  data_time: 0.0547  lr: 6.109e-05  max_mem: 27646M
[01/29 20:45:35] d2.utils.events INFO:  eta: 1 day, 4:34:09  iter: 25319  total_loss: 20.71  loss_mask: 2.052  loss_mask_0: 2.124  loss_mask_1: 2.043  loss_mask_2: 2.072  loss_mask_3: 2.06  loss_mask_4: 2.071  loss_mask_5: 2.05  loss_mask_6: 2.153  loss_mask_7: 2.081  loss_mask_8: 2.072  time: 2.9973  data_time: 0.0588  lr: 6.1059e-05  max_mem: 27646M
[01/29 20:46:34] d2.utils.events INFO:  eta: 1 day, 4:32:25  iter: 25339  total_loss: 20.95  loss_mask: 2.084  loss_mask_0: 2.112  loss_mask_1: 2.077  loss_mask_2: 2.086  loss_mask_3: 2.086  loss_mask_4: 2.082  loss_mask_5: 2.091  loss_mask_6: 2.159  loss_mask_7: 2.094  loss_mask_8: 2.083  time: 2.9973  data_time: 0.0515  lr: 6.1027e-05  max_mem: 27646M
[01/29 20:47:33] d2.utils.events INFO:  eta: 1 day, 4:31:09  iter: 25359  total_loss: 24.85  loss_mask: 2.479  loss_mask_0: 2.391  loss_mask_1: 2.395  loss_mask_2: 2.424  loss_mask_3: 2.441  loss_mask_4: 2.428  loss_mask_5: 2.478  loss_mask_6: 2.54  loss_mask_7: 2.472  loss_mask_8: 2.467  time: 2.9973  data_time: 0.0644  lr: 6.0995e-05  max_mem: 27646M
[01/29 20:48:32] d2.utils.events INFO:  eta: 1 day, 4:30:02  iter: 25379  total_loss: 23.86  loss_mask: 2.375  loss_mask_0: 2.385  loss_mask_1: 2.367  loss_mask_2: 2.409  loss_mask_3: 2.366  loss_mask_4: 2.395  loss_mask_5: 2.375  loss_mask_6: 2.472  loss_mask_7: 2.39  loss_mask_8: 2.4  time: 2.9972  data_time: 0.0610  lr: 6.0963e-05  max_mem: 27646M
[01/29 20:49:31] d2.utils.events INFO:  eta: 1 day, 4:28:29  iter: 25399  total_loss: 24.7  loss_mask: 2.474  loss_mask_0: 2.493  loss_mask_1: 2.434  loss_mask_2: 2.43  loss_mask_3: 2.448  loss_mask_4: 2.449  loss_mask_5: 2.45  loss_mask_6: 2.47  loss_mask_7: 2.473  loss_mask_8: 2.48  time: 2.9972  data_time: 0.0540  lr: 6.0932e-05  max_mem: 27646M
[01/29 20:50:30] d2.utils.events INFO:  eta: 1 day, 4:26:58  iter: 25419  total_loss: 24.35  loss_mask: 2.433  loss_mask_0: 2.45  loss_mask_1: 2.394  loss_mask_2: 2.42  loss_mask_3: 2.445  loss_mask_4: 2.443  loss_mask_5: 2.43  loss_mask_6: 2.459  loss_mask_7: 2.438  loss_mask_8: 2.424  time: 2.9971  data_time: 0.0632  lr: 6.09e-05  max_mem: 27646M
[01/29 20:51:29] d2.utils.events INFO:  eta: 1 day, 4:25:16  iter: 25439  total_loss: 22.17  loss_mask: 2.209  loss_mask_0: 2.282  loss_mask_1: 2.198  loss_mask_2: 2.224  loss_mask_3: 2.217  loss_mask_4: 2.215  loss_mask_5: 2.214  loss_mask_6: 2.215  loss_mask_7: 2.222  loss_mask_8: 2.229  time: 2.9971  data_time: 0.0562  lr: 6.0868e-05  max_mem: 27646M
[01/29 20:52:28] d2.utils.events INFO:  eta: 1 day, 4:23:50  iter: 25459  total_loss: 22.93  loss_mask: 2.277  loss_mask_0: 2.375  loss_mask_1: 2.276  loss_mask_2: 2.281  loss_mask_3: 2.283  loss_mask_4: 2.278  loss_mask_5: 2.277  loss_mask_6: 2.329  loss_mask_7: 2.289  loss_mask_8: 2.287  time: 2.9971  data_time: 0.0591  lr: 6.0837e-05  max_mem: 27646M
[01/29 20:53:27] d2.utils.events INFO:  eta: 1 day, 4:22:31  iter: 25479  total_loss: 24.41  loss_mask: 2.429  loss_mask_0: 2.448  loss_mask_1: 2.408  loss_mask_2: 2.437  loss_mask_3: 2.437  loss_mask_4: 2.441  loss_mask_5: 2.451  loss_mask_6: 2.452  loss_mask_7: 2.454  loss_mask_8: 2.451  time: 2.9970  data_time: 0.0610  lr: 6.0805e-05  max_mem: 27646M
[01/29 20:54:26] d2.utils.events INFO:  eta: 1 day, 4:20:53  iter: 25499  total_loss: 22.93  loss_mask: 2.286  loss_mask_0: 2.333  loss_mask_1: 2.289  loss_mask_2: 2.292  loss_mask_3: 2.281  loss_mask_4: 2.275  loss_mask_5: 2.299  loss_mask_6: 2.288  loss_mask_7: 2.284  loss_mask_8: 2.298  time: 2.9970  data_time: 0.0695  lr: 6.0773e-05  max_mem: 27646M
[01/29 20:55:25] d2.utils.events INFO:  eta: 1 day, 4:18:48  iter: 25519  total_loss: 23.13  loss_mask: 2.295  loss_mask_0: 2.364  loss_mask_1: 2.307  loss_mask_2: 2.332  loss_mask_3: 2.299  loss_mask_4: 2.302  loss_mask_5: 2.299  loss_mask_6: 2.298  loss_mask_7: 2.311  loss_mask_8: 2.301  time: 2.9969  data_time: 0.0502  lr: 6.0742e-05  max_mem: 27646M
[01/29 20:56:24] d2.utils.events INFO:  eta: 1 day, 4:17:34  iter: 25539  total_loss: 23.28  loss_mask: 2.315  loss_mask_0: 2.39  loss_mask_1: 2.31  loss_mask_2: 2.325  loss_mask_3: 2.328  loss_mask_4: 2.325  loss_mask_5: 2.313  loss_mask_6: 2.322  loss_mask_7: 2.331  loss_mask_8: 2.323  time: 2.9969  data_time: 0.0471  lr: 6.071e-05  max_mem: 27646M
[01/29 20:57:22] d2.utils.events INFO:  eta: 1 day, 4:15:47  iter: 25559  total_loss: 23.16  loss_mask: 2.321  loss_mask_0: 2.332  loss_mask_1: 2.292  loss_mask_2: 2.346  loss_mask_3: 2.307  loss_mask_4: 2.306  loss_mask_5: 2.31  loss_mask_6: 2.339  loss_mask_7: 2.339  loss_mask_8: 2.317  time: 2.9968  data_time: 0.0546  lr: 6.0678e-05  max_mem: 27646M
[01/29 20:58:21] d2.utils.events INFO:  eta: 1 day, 4:14:16  iter: 25579  total_loss: 21.26  loss_mask: 2.122  loss_mask_0: 2.164  loss_mask_1: 2.086  loss_mask_2: 2.109  loss_mask_3: 2.117  loss_mask_4: 2.128  loss_mask_5: 2.126  loss_mask_6: 2.13  loss_mask_7: 2.13  loss_mask_8: 2.129  time: 2.9968  data_time: 0.0527  lr: 6.0646e-05  max_mem: 27646M
[01/29 20:59:20] d2.utils.events INFO:  eta: 1 day, 4:13:04  iter: 25599  total_loss: 23.29  loss_mask: 2.311  loss_mask_0: 2.393  loss_mask_1: 2.347  loss_mask_2: 2.38  loss_mask_3: 2.313  loss_mask_4: 2.307  loss_mask_5: 2.317  loss_mask_6: 2.329  loss_mask_7: 2.324  loss_mask_8: 2.338  time: 2.9967  data_time: 0.0524  lr: 6.0615e-05  max_mem: 27646M
[01/29 21:00:18] d2.utils.events INFO:  eta: 1 day, 4:11:18  iter: 25619  total_loss: 23.42  loss_mask: 2.335  loss_mask_0: 2.406  loss_mask_1: 2.329  loss_mask_2: 2.329  loss_mask_3: 2.338  loss_mask_4: 2.378  loss_mask_5: 2.315  loss_mask_6: 2.335  loss_mask_7: 2.334  loss_mask_8: 2.315  time: 2.9967  data_time: 0.0576  lr: 6.0583e-05  max_mem: 27646M
[01/29 21:01:17] d2.utils.events INFO:  eta: 1 day, 4:09:39  iter: 25639  total_loss: 23.41  loss_mask: 2.337  loss_mask_0: 2.425  loss_mask_1: 2.328  loss_mask_2: 2.435  loss_mask_3: 2.34  loss_mask_4: 2.566  loss_mask_5: 2.32  loss_mask_6: 2.312  loss_mask_7: 2.329  loss_mask_8: 2.321  time: 2.9966  data_time: 0.0598  lr: 6.0551e-05  max_mem: 27646M
[01/29 21:02:17] d2.utils.events INFO:  eta: 1 day, 4:08:47  iter: 25659  total_loss: 22.01  loss_mask: 2.203  loss_mask_0: 2.165  loss_mask_1: 2.128  loss_mask_2: 2.174  loss_mask_3: 2.22  loss_mask_4: 2.244  loss_mask_5: 2.222  loss_mask_6: 2.23  loss_mask_7: 2.186  loss_mask_8: 2.173  time: 2.9966  data_time: 0.0655  lr: 6.052e-05  max_mem: 27646M
[01/29 21:03:18] d2.utils.events INFO:  eta: 1 day, 4:08:11  iter: 25679  total_loss: 24.16  loss_mask: 2.402  loss_mask_0: 2.47  loss_mask_1: 2.41  loss_mask_2: 2.451  loss_mask_3: 2.369  loss_mask_4: 2.386  loss_mask_5: 2.413  loss_mask_6: 2.403  loss_mask_7: 2.379  loss_mask_8: 2.4  time: 2.9967  data_time: 0.0731  lr: 6.0488e-05  max_mem: 27646M
[01/29 21:04:17] d2.utils.events INFO:  eta: 1 day, 4:07:02  iter: 25699  total_loss: 22.57  loss_mask: 2.256  loss_mask_0: 2.272  loss_mask_1: 2.217  loss_mask_2: 2.248  loss_mask_3: 2.307  loss_mask_4: 2.318  loss_mask_5: 2.241  loss_mask_6: 2.248  loss_mask_7: 2.28  loss_mask_8: 2.25  time: 2.9966  data_time: 0.0594  lr: 6.0456e-05  max_mem: 27646M
[01/29 21:05:16] d2.utils.events INFO:  eta: 1 day, 4:05:58  iter: 25719  total_loss: 21.75  loss_mask: 2.143  loss_mask_0: 2.22  loss_mask_1: 2.154  loss_mask_2: 2.188  loss_mask_3: 2.158  loss_mask_4: 2.18  loss_mask_5: 2.165  loss_mask_6: 2.155  loss_mask_7: 2.17  loss_mask_8: 2.169  time: 2.9966  data_time: 0.0577  lr: 6.0424e-05  max_mem: 27646M
[01/29 21:06:16] d2.utils.events INFO:  eta: 1 day, 4:04:44  iter: 25739  total_loss: 23.06  loss_mask: 2.309  loss_mask_0: 2.304  loss_mask_1: 2.298  loss_mask_2: 2.331  loss_mask_3: 2.329  loss_mask_4: 2.343  loss_mask_5: 2.298  loss_mask_6: 2.293  loss_mask_7: 2.277  loss_mask_8: 2.304  time: 2.9966  data_time: 0.0509  lr: 6.0393e-05  max_mem: 27646M
[01/29 21:07:15] d2.utils.events INFO:  eta: 1 day, 4:04:17  iter: 25759  total_loss: 22.92  loss_mask: 2.291  loss_mask_0: 2.311  loss_mask_1: 2.273  loss_mask_2: 2.284  loss_mask_3: 2.297  loss_mask_4: 2.308  loss_mask_5: 2.283  loss_mask_6: 2.282  loss_mask_7: 2.291  loss_mask_8: 2.287  time: 2.9966  data_time: 0.0614  lr: 6.0361e-05  max_mem: 27646M
[01/29 21:08:14] d2.utils.events INFO:  eta: 1 day, 4:03:11  iter: 25779  total_loss: 20.94  loss_mask: 2.072  loss_mask_0: 2.135  loss_mask_1: 2.069  loss_mask_2: 2.096  loss_mask_3: 2.099  loss_mask_4: 2.107  loss_mask_5: 2.069  loss_mask_6: 2.074  loss_mask_7: 2.087  loss_mask_8: 2.098  time: 2.9965  data_time: 0.0547  lr: 6.0329e-05  max_mem: 27646M
[01/29 21:09:13] d2.utils.events INFO:  eta: 1 day, 4:01:37  iter: 25799  total_loss: 23.88  loss_mask: 2.373  loss_mask_0: 2.457  loss_mask_1: 2.358  loss_mask_2: 2.382  loss_mask_3: 2.392  loss_mask_4: 2.387  loss_mask_5: 2.37  loss_mask_6: 2.378  loss_mask_7: 2.39  loss_mask_8: 2.388  time: 2.9965  data_time: 0.0581  lr: 6.0297e-05  max_mem: 27646M
[01/29 21:10:12] d2.utils.events INFO:  eta: 1 day, 4:00:48  iter: 25819  total_loss: 25.65  loss_mask: 2.572  loss_mask_0: 2.595  loss_mask_1: 2.54  loss_mask_2: 2.571  loss_mask_3: 2.577  loss_mask_4: 2.557  loss_mask_5: 2.549  loss_mask_6: 2.55  loss_mask_7: 2.575  loss_mask_8: 2.56  time: 2.9965  data_time: 0.0679  lr: 6.0266e-05  max_mem: 27646M
[01/29 21:11:12] d2.utils.events INFO:  eta: 1 day, 3:59:49  iter: 25839  total_loss: 23.09  loss_mask: 2.303  loss_mask_0: 2.353  loss_mask_1: 2.3  loss_mask_2: 2.326  loss_mask_3: 2.299  loss_mask_4: 2.336  loss_mask_5: 2.309  loss_mask_6: 2.317  loss_mask_7: 2.331  loss_mask_8: 2.32  time: 2.9964  data_time: 0.0631  lr: 6.0234e-05  max_mem: 27646M
[01/29 21:12:11] d2.utils.events INFO:  eta: 1 day, 3:58:53  iter: 25859  total_loss: 21.68  loss_mask: 2.157  loss_mask_0: 2.155  loss_mask_1: 2.141  loss_mask_2: 2.152  loss_mask_3: 2.166  loss_mask_4: 2.202  loss_mask_5: 2.147  loss_mask_6: 2.139  loss_mask_7: 2.181  loss_mask_8: 2.161  time: 2.9964  data_time: 0.0675  lr: 6.0202e-05  max_mem: 27646M
[01/29 21:13:12] d2.utils.events INFO:  eta: 1 day, 3:58:29  iter: 25879  total_loss: 25.26  loss_mask: 2.516  loss_mask_0: 2.631  loss_mask_1: 2.527  loss_mask_2: 2.503  loss_mask_3: 2.517  loss_mask_4: 2.558  loss_mask_5: 2.512  loss_mask_6: 2.524  loss_mask_7: 2.517  loss_mask_8: 2.51  time: 2.9964  data_time: 0.0662  lr: 6.017e-05  max_mem: 27646M
[01/29 21:14:11] d2.utils.events INFO:  eta: 1 day, 3:57:24  iter: 25899  total_loss: 21.98  loss_mask: 2.184  loss_mask_0: 2.295  loss_mask_1: 2.177  loss_mask_2: 2.175  loss_mask_3: 2.212  loss_mask_4: 2.224  loss_mask_5: 2.19  loss_mask_6: 2.173  loss_mask_7: 2.202  loss_mask_8: 2.182  time: 2.9964  data_time: 0.0606  lr: 6.0139e-05  max_mem: 27646M
[01/29 21:15:10] d2.utils.events INFO:  eta: 1 day, 3:56:39  iter: 25919  total_loss: 21.41  loss_mask: 2.13  loss_mask_0: 2.178  loss_mask_1: 2.15  loss_mask_2: 2.152  loss_mask_3: 2.139  loss_mask_4: 2.125  loss_mask_5: 2.162  loss_mask_6: 2.123  loss_mask_7: 2.129  loss_mask_8: 2.163  time: 2.9964  data_time: 0.0703  lr: 6.0107e-05  max_mem: 27646M
[01/29 21:16:09] d2.utils.events INFO:  eta: 1 day, 3:55:33  iter: 25939  total_loss: 22.03  loss_mask: 2.196  loss_mask_0: 2.234  loss_mask_1: 2.184  loss_mask_2: 2.196  loss_mask_3: 2.208  loss_mask_4: 2.218  loss_mask_5: 2.185  loss_mask_6: 2.19  loss_mask_7: 2.202  loss_mask_8: 2.216  time: 2.9963  data_time: 0.0508  lr: 6.0075e-05  max_mem: 27646M
[01/29 21:17:08] d2.utils.events INFO:  eta: 1 day, 3:54:33  iter: 25959  total_loss: 22.99  loss_mask: 2.301  loss_mask_0: 2.38  loss_mask_1: 2.267  loss_mask_2: 2.294  loss_mask_3: 2.311  loss_mask_4: 2.308  loss_mask_5: 2.261  loss_mask_6: 2.302  loss_mask_7: 2.289  loss_mask_8: 2.312  time: 2.9963  data_time: 0.0608  lr: 6.0043e-05  max_mem: 27646M
[01/29 21:18:08] d2.utils.events INFO:  eta: 1 day, 3:53:28  iter: 25979  total_loss: 21.88  loss_mask: 2.189  loss_mask_0: 2.266  loss_mask_1: 2.194  loss_mask_2: 2.181  loss_mask_3: 2.202  loss_mask_4: 2.185  loss_mask_5: 2.177  loss_mask_6: 2.183  loss_mask_7: 2.176  loss_mask_8: 2.197  time: 2.9963  data_time: 0.0670  lr: 6.0012e-05  max_mem: 27646M
[01/29 21:19:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 21:19:07] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 21:19:07] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 21:33:19] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.685355567257337, 'error_1pix': 0.4346367758997963, 'error_3pix': 0.18164814741441415, 'mIoU': 5.559313723778783, 'fwIoU': 15.390446738995657, 'IoU-0': 0.0003522969276135601, 'IoU-1': 60.10371581419305, 'IoU-2': 2.7631366286340984, 'IoU-3': 4.464146706476681, 'IoU-4': 4.102140951604027, 'IoU-5': 4.305572920810648, 'IoU-6': 4.4159705620775105, 'IoU-7': 3.631386390295526, 'IoU-8': 3.95001008635844, 'IoU-9': 9.365596446258373, 'IoU-10': 12.050963796048565, 'IoU-11': 17.139173504629596, 'IoU-12': 17.17023151841997, 'IoU-13': 16.65296292626254, 'IoU-14': 15.276884673969338, 'IoU-15': 13.56950501880071, 'IoU-16': 12.039900117918311, 'IoU-17': 9.711503408685301, 'IoU-18': 11.056018924233193, 'IoU-19': 11.574856102441547, 'IoU-20': 10.899146167980184, 'IoU-21': 10.522786558152267, 'IoU-22': 10.141238647179234, 'IoU-23': 9.756210726893677, 'IoU-24': 9.159382048359003, 'IoU-25': 10.085626890059448, 'IoU-26': 10.709963363095104, 'IoU-27': 11.606693106653996, 'IoU-28': 12.05427849576003, 'IoU-29': 12.1631430704978, 'IoU-30': 12.299817598872732, 'IoU-31': 13.06999236515784, 'IoU-32': 13.606063984474801, 'IoU-33': 13.452669136092252, 'IoU-34': 13.442984500412312, 'IoU-35': 14.550139473745109, 'IoU-36': 15.343142521509067, 'IoU-37': 15.422725259717412, 'IoU-38': 16.20693388285907, 'IoU-39': 16.39841306922373, 'IoU-40': 17.075235436799144, 'IoU-41': 15.748804480106465, 'IoU-42': 15.67845371855667, 'IoU-43': 15.224460128151973, 'IoU-44': 14.959997484499068, 'IoU-45': 14.382376526932509, 'IoU-46': 13.341543611914705, 'IoU-47': 12.702103880626744, 'IoU-48': 11.731751979635705, 'IoU-49': 11.130690108902948, 'IoU-50': 11.024557359872196, 'IoU-51': 9.48586319368083, 'IoU-52': 9.10841674744973, 'IoU-53': 8.54232491970042, 'IoU-54': 8.01730763946678, 'IoU-55': 7.384916677075608, 'IoU-56': 6.938050457293087, 'IoU-57': 6.6828188408363705, 'IoU-58': 6.178298063835622, 'IoU-59': 5.782613210555961, 'IoU-60': 5.360540927848141, 'IoU-61': 5.062577246393066, 'IoU-62': 4.633831384672496, 'IoU-63': 4.191612630645953, 'IoU-64': 3.9944571008270495, 'IoU-65': 3.9085229013200165, 'IoU-66': 3.6829359506793153, 'IoU-67': 3.818013362573707, 'IoU-68': 3.5570329326437324, 'IoU-69': 3.581658053996928, 'IoU-70': 3.475160490576052, 'IoU-71': 3.459495904163653, 'IoU-72': 3.529387117203015, 'IoU-73': 3.4833487229315363, 'IoU-74': 3.4234785945236337, 'IoU-75': 3.2340434263822075, 'IoU-76': 3.429455176252494, 'IoU-77': 3.5355987985798176, 'IoU-78': 3.462315444719418, 'IoU-79': 3.532395634345374, 'IoU-80': 3.4831282272182045, 'IoU-81': 3.5401033326135347, 'IoU-82': 3.4331986126330643, 'IoU-83': 3.6499749862949042, 'IoU-84': 3.5778162574063987, 'IoU-85': 3.6280410622220267, 'IoU-86': 3.5031986828012855, 'IoU-87': 3.37350200458483, 'IoU-88': 3.334708395029039, 'IoU-89': 3.4575499185786533, 'IoU-90': 3.4919472013233115, 'IoU-91': 3.4480492964173806, 'IoU-92': 3.493875029881155, 'IoU-93': 3.552407457616306, 'IoU-94': 3.5588522978630888, 'IoU-95': 3.479063934487683, 'IoU-96': 3.221768090039396, 'IoU-97': 3.4653594829254097, 'IoU-98': 3.3847130843446704, 'IoU-99': 3.1552037298552147, 'IoU-100': 3.1071264912127496, 'IoU-101': 3.162979774113063, 'IoU-102': 3.1536305824021844, 'IoU-103': 3.0879168198179987, 'IoU-104': 3.023109006306207, 'IoU-105': 3.101365433279157, 'IoU-106': 2.978418736687834, 'IoU-107': 3.047518646639823, 'IoU-108': 3.28294055830315, 'IoU-109': 3.3303527599348364, 'IoU-110': 3.3390232671365263, 'IoU-111': 3.0691394145292037, 'IoU-112': 3.2636185790922037, 'IoU-113': 2.946457806221164, 'IoU-114': 3.0671659622548786, 'IoU-115': 3.0014677324889267, 'IoU-116': 3.020385372604741, 'IoU-117': 3.349760093876216, 'IoU-118': 3.267880992299167, 'IoU-119': 3.248551471844959, 'IoU-120': 3.1639092496283223, 'IoU-121': 3.1010388244619485, 'IoU-122': 3.184425728066973, 'IoU-123': 3.1092311105029875, 'IoU-124': 3.118470238535092, 'IoU-125': 2.9730285778704695, 'IoU-126': 3.0479703310027513, 'IoU-127': 2.9217204616767893, 'IoU-128': 2.990087183489804, 'IoU-129': 3.0690760068790137, 'IoU-130': 3.056155090830703, 'IoU-131': 3.1285397740090177, 'IoU-132': 3.1155148849792393, 'IoU-133': 3.31630985384481, 'IoU-134': 3.310636813528136, 'IoU-135': 3.2246642564598895, 'IoU-136': 3.0580453504991856, 'IoU-137': 3.1409071195416463, 'IoU-138': 3.0164620384724348, 'IoU-139': 2.9195696865698406, 'IoU-140': 2.723251089785384, 'IoU-141': 2.631495035255954, 'IoU-142': 2.5488195498921904, 'IoU-143': 2.5691087697923227, 'IoU-144': 2.6683416165554608, 'IoU-145': 2.542436323831626, 'IoU-146': 2.3168457714681634, 'IoU-147': 2.6967461973104734, 'IoU-148': 2.782308589044781, 'IoU-149': 2.657662900562701, 'IoU-150': 2.573901315050017, 'IoU-151': 2.8156343416070633, 'IoU-152': 2.7067615745172104, 'IoU-153': 2.499512597271659, 'IoU-154': 2.7464692910694066, 'IoU-155': 2.666339703439812, 'IoU-156': 2.549174748526648, 'IoU-157': 2.65303621421798, 'IoU-158': 2.404397188239403, 'IoU-159': 2.1381858185593026, 'IoU-160': 2.5271142449223247, 'IoU-161': 2.0510264511132728, 'IoU-162': 1.9188845090938746, 'IoU-163': 2.1087598250168935, 'IoU-164': 2.611765027467844, 'IoU-165': 2.7033766474766114, 'IoU-166': 1.987574886792592, 'IoU-167': 1.7738367473317842, 'IoU-168': 1.734650814209002, 'IoU-169': 2.7267450762552836, 'IoU-170': 1.761352990337058, 'IoU-171': 1.807404521468103, 'IoU-172': 1.8633535852253376, 'IoU-173': 1.9988110828532226, 'IoU-174': 1.5595921469948364, 'IoU-175': 1.4917154105867834, 'IoU-176': 1.616991568659041, 'IoU-177': 1.6779343756881744, 'IoU-178': 1.946261487093508, 'IoU-179': 3.072735618133609, 'IoU-180': 1.139667793787305, 'IoU-181': 1.0383196014512486, 'IoU-182': 0.9276734461569699, 'IoU-183': 0.7540284427593442, 'IoU-184': 0.3975355371593447, 'IoU-185': 0.10114912033428955, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 10.341201102869157, 'pACC': 22.87827311714117, 'ACC-0': 0.0013841674046954214, 'ACC-1': 61.10179281894253, 'ACC-2': 5.310525311512656, 'ACC-3': 17.525436105289184, 'ACC-4': 14.67286724408203, 'ACC-5': 15.543137066139767, 'ACC-6': 16.193171529240114, 'ACC-7': 13.850633179095063, 'ACC-8': 7.762220911936592, 'ACC-9': 12.911100032925685, 'ACC-10': 16.204105576966477, 'ACC-11': 22.189611906307714, 'ACC-12': 26.018309302865823, 'ACC-13': 27.031942664228385, 'ACC-14': 25.624253471631224, 'ACC-15': 24.271127258276202, 'ACC-16': 21.629303039160128, 'ACC-17': 18.415762863230533, 'ACC-18': 19.783179527190313, 'ACC-19': 20.613220557027727, 'ACC-20': 19.940677949401113, 'ACC-21': 18.716026089760142, 'ACC-22': 17.614013819242576, 'ACC-23': 18.380924084450392, 'ACC-24': 17.29723545849284, 'ACC-25': 18.75735926219459, 'ACC-26': 19.88816860312626, 'ACC-27': 20.779494562200234, 'ACC-28': 22.375581070864673, 'ACC-29': 21.621087521754397, 'ACC-30': 22.380011034712485, 'ACC-31': 23.285440608009036, 'ACC-32': 24.950991301785034, 'ACC-33': 25.07778917493243, 'ACC-34': 24.71311972037999, 'ACC-35': 26.357727610574454, 'ACC-36': 27.91765109539484, 'ACC-37': 28.592932429716367, 'ACC-38': 29.97121511193692, 'ACC-39': 30.493289547238156, 'ACC-40': 31.03338269301439, 'ACC-41': 29.248171242033717, 'ACC-42': 29.31269940068042, 'ACC-43': 28.34538053097474, 'ACC-44': 27.03512917571787, 'ACC-45': 26.24344476189615, 'ACC-46': 25.079038932018662, 'ACC-47': 23.90586265057644, 'ACC-48': 22.304502804730287, 'ACC-49': 21.15250738667168, 'ACC-50': 20.878736363549883, 'ACC-51': 18.081042799665838, 'ACC-52': 17.31125460740679, 'ACC-53': 16.261734066551792, 'ACC-54': 15.053267242785518, 'ACC-55': 13.70388569723002, 'ACC-56': 13.028706125759504, 'ACC-57': 12.420083058288652, 'ACC-58': 11.6141241421042, 'ACC-59': 11.049198797246586, 'ACC-60': 10.328294286164455, 'ACC-61': 9.74738670723108, 'ACC-62': 8.92535556734802, 'ACC-63': 8.171832551976118, 'ACC-64': 7.812423777653883, 'ACC-65': 7.661160094505775, 'ACC-66': 7.292303327308608, 'ACC-67': 7.557234915229204, 'ACC-68': 7.00479305859229, 'ACC-69': 6.912311240320054, 'ACC-70': 6.685844927200413, 'ACC-71': 6.778770907218506, 'ACC-72': 6.90397853974397, 'ACC-73': 6.793041449785619, 'ACC-74': 6.654530517401036, 'ACC-75': 6.367938899620961, 'ACC-76': 6.708622830439739, 'ACC-77': 6.978020622491042, 'ACC-78': 6.851132477167772, 'ACC-79': 6.937388875838662, 'ACC-80': 6.709781050600166, 'ACC-81': 6.726388533401587, 'ACC-82': 6.496269455212422, 'ACC-83': 6.797313635194527, 'ACC-84': 6.667076480436175, 'ACC-85': 6.741717366277318, 'ACC-86': 6.496836510657321, 'ACC-87': 6.255634053023964, 'ACC-88': 6.119390491684353, 'ACC-89': 6.287065352386476, 'ACC-90': 6.3244480294134195, 'ACC-91': 6.27702311206643, 'ACC-92': 6.428304196050309, 'ACC-93': 6.562829123717149, 'ACC-94': 6.6154199843815, 'ACC-95': 6.427444919082441, 'ACC-96': 5.9395800308050015, 'ACC-97': 6.28333751938295, 'ACC-98': 6.108085302586168, 'ACC-99': 5.711902203551817, 'ACC-100': 5.597487566364756, 'ACC-101': 5.72713821700188, 'ACC-102': 5.727050294517444, 'ACC-103': 5.667752904505526, 'ACC-104': 5.5861390521630065, 'ACC-105': 5.727674087248513, 'ACC-106': 5.479322738969099, 'ACC-107': 5.610311171451075, 'ACC-108': 5.97698944873007, 'ACC-109': 6.03538285118139, 'ACC-110': 6.170146716412203, 'ACC-111': 5.70315846940077, 'ACC-112': 6.110117921522229, 'ACC-113': 5.4921706623943845, 'ACC-114': 5.777338677848409, 'ACC-115': 5.614879797934239, 'ACC-116': 5.659371064831919, 'ACC-117': 6.258322772068757, 'ACC-118': 6.1804671207126685, 'ACC-119': 6.154824049543284, 'ACC-120': 6.005009189077121, 'ACC-121': 5.922619953334511, 'ACC-122': 6.0409295479634295, 'ACC-123': 5.920087868016397, 'ACC-124': 6.092639660838708, 'ACC-125': 5.737070123552939, 'ACC-126': 5.8552445832840005, 'ACC-127': 5.579846087712249, 'ACC-128': 5.770523154907177, 'ACC-129': 5.942108199319887, 'ACC-130': 5.924845798840686, 'ACC-131': 6.073782840980306, 'ACC-132': 6.102012982008157, 'ACC-133': 6.523777446637681, 'ACC-134': 6.56882378285222, 'ACC-135': 6.35361438914543, 'ACC-136': 6.038453922847559, 'ACC-137': 6.196225510736008, 'ACC-138': 6.013227530014976, 'ACC-139': 5.859874909100449, 'ACC-140': 5.441727252698833, 'ACC-141': 5.2087979412225085, 'ACC-142': 5.10287224872736, 'ACC-143': 5.047746647580588, 'ACC-144': 5.262364620938628, 'ACC-145': 4.981953979292918, 'ACC-146': 4.553151630074707, 'ACC-147': 5.271763806856747, 'ACC-148': 5.456009261908405, 'ACC-149': 5.233305174384348, 'ACC-150': 5.012460796177646, 'ACC-151': 5.527223662796832, 'ACC-152': 5.378291691954954, 'ACC-153': 5.138423203063449, 'ACC-154': 5.73545763778566, 'ACC-155': 5.789534663008458, 'ACC-156': 5.664514210733839, 'ACC-157': 6.069687900230424, 'ACC-158': 5.518727656865914, 'ACC-159': 4.83856790865555, 'ACC-160': 5.470552639913134, 'ACC-161': 4.299070144940561, 'ACC-162': 4.060535374783175, 'ACC-163': 4.531870302231693, 'ACC-164': 5.756613890835524, 'ACC-165': 5.922935453439508, 'ACC-166': 4.517044262198755, 'ACC-167': 4.129991818186555, 'ACC-168': 3.9819959209508404, 'ACC-169': 6.718454165957469, 'ACC-170': 4.203934011953945, 'ACC-171': 4.771963725801741, 'ACC-172': 4.741823165536911, 'ACC-173': 5.048296726659718, 'ACC-174': 3.99268566827157, 'ACC-175': 3.5508866123476786, 'ACC-176': 4.36934060831205, 'ACC-177': 5.624606685379677, 'ACC-178': 7.381531394928831, 'ACC-179': 10.281792156727485, 'ACC-180': 4.165396728639642, 'ACC-181': 3.7933966710960463, 'ACC-182': 2.7494201459881684, 'ACC-183': 2.121949094881472, 'ACC-184': 0.6553982505418414, 'ACC-185': 0.12679628064243448, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 21:33:19] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 21:33:19] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 21:33:19] d2.evaluation.testing INFO: copypaste: 2.6854,0.4346,0.1816,5.5593,15.3904,10.3412,22.8783
[01/29 21:33:19] d2.utils.events INFO:  eta: 1 day, 3:52:11  iter: 25999  total_loss: 22.13  loss_mask: 2.214  loss_mask_0: 2.237  loss_mask_1: 2.222  loss_mask_2: 2.213  loss_mask_3: 2.192  loss_mask_4: 2.203  loss_mask_5: 2.208  loss_mask_6: 2.207  loss_mask_7: 2.215  loss_mask_8: 2.214  time: 2.9963  data_time: 0.0610  lr: 5.998e-05  max_mem: 27646M
[01/29 21:34:19] d2.utils.events INFO:  eta: 1 day, 3:51:21  iter: 26019  total_loss: 23.35  loss_mask: 2.327  loss_mask_0: 2.403  loss_mask_1: 2.324  loss_mask_2: 2.327  loss_mask_3: 2.327  loss_mask_4: 2.331  loss_mask_5: 2.32  loss_mask_6: 2.322  loss_mask_7: 2.336  loss_mask_8: 2.333  time: 2.9963  data_time: 0.0663  lr: 5.9948e-05  max_mem: 27646M
[01/29 21:35:19] d2.utils.events INFO:  eta: 1 day, 3:50:24  iter: 26039  total_loss: 21.08  loss_mask: 2.101  loss_mask_0: 2.144  loss_mask_1: 2.11  loss_mask_2: 2.111  loss_mask_3: 2.097  loss_mask_4: 2.111  loss_mask_5: 2.111  loss_mask_6: 2.11  loss_mask_7: 2.114  loss_mask_8: 2.11  time: 2.9963  data_time: 0.0648  lr: 5.9916e-05  max_mem: 27646M
[01/29 21:36:18] d2.utils.events INFO:  eta: 1 day, 3:49:03  iter: 26059  total_loss: 23.07  loss_mask: 2.304  loss_mask_0: 2.35  loss_mask_1: 2.29  loss_mask_2: 2.295  loss_mask_3: 2.304  loss_mask_4: 2.306  loss_mask_5: 2.306  loss_mask_6: 2.298  loss_mask_7: 2.309  loss_mask_8: 2.298  time: 2.9962  data_time: 0.0526  lr: 5.9885e-05  max_mem: 27646M
[01/29 21:37:17] d2.utils.events INFO:  eta: 1 day, 3:47:49  iter: 26079  total_loss: 21.94  loss_mask: 2.199  loss_mask_0: 2.228  loss_mask_1: 2.187  loss_mask_2: 2.181  loss_mask_3: 2.183  loss_mask_4: 2.19  loss_mask_5: 2.201  loss_mask_6: 2.197  loss_mask_7: 2.187  loss_mask_8: 2.19  time: 2.9962  data_time: 0.0537  lr: 5.9853e-05  max_mem: 27646M
[01/29 21:38:16] d2.utils.events INFO:  eta: 1 day, 3:46:44  iter: 26099  total_loss: 21.18  loss_mask: 2.107  loss_mask_0: 2.18  loss_mask_1: 2.097  loss_mask_2: 2.116  loss_mask_3: 2.122  loss_mask_4: 2.123  loss_mask_5: 2.106  loss_mask_6: 2.113  loss_mask_7: 2.126  loss_mask_8: 2.12  time: 2.9962  data_time: 0.0612  lr: 5.9821e-05  max_mem: 27646M
[01/29 21:39:15] d2.utils.events INFO:  eta: 1 day, 3:45:10  iter: 26119  total_loss: 22.63  loss_mask: 2.249  loss_mask_0: 2.336  loss_mask_1: 2.253  loss_mask_2: 2.262  loss_mask_3: 2.263  loss_mask_4: 2.262  loss_mask_5: 2.259  loss_mask_6: 2.251  loss_mask_7: 2.257  loss_mask_8: 2.27  time: 2.9961  data_time: 0.0618  lr: 5.9789e-05  max_mem: 27646M
[01/29 21:40:14] d2.utils.events INFO:  eta: 1 day, 3:43:58  iter: 26139  total_loss: 23.35  loss_mask: 2.33  loss_mask_0: 2.447  loss_mask_1: 2.318  loss_mask_2: 2.327  loss_mask_3: 2.333  loss_mask_4: 2.327  loss_mask_5: 2.307  loss_mask_6: 2.342  loss_mask_7: 2.347  loss_mask_8: 2.316  time: 2.9961  data_time: 0.0583  lr: 5.9758e-05  max_mem: 27646M
[01/29 21:41:13] d2.utils.events INFO:  eta: 1 day, 3:42:24  iter: 26159  total_loss: 22.06  loss_mask: 2.204  loss_mask_0: 2.243  loss_mask_1: 2.192  loss_mask_2: 2.194  loss_mask_3: 2.201  loss_mask_4: 2.199  loss_mask_5: 2.204  loss_mask_6: 2.202  loss_mask_7: 2.222  loss_mask_8: 2.215  time: 2.9960  data_time: 0.0450  lr: 5.9726e-05  max_mem: 27646M
[01/29 21:42:12] d2.utils.events INFO:  eta: 1 day, 3:41:34  iter: 26179  total_loss: 21.54  loss_mask: 2.15  loss_mask_0: 2.204  loss_mask_1: 2.132  loss_mask_2: 2.156  loss_mask_3: 2.147  loss_mask_4: 2.159  loss_mask_5: 2.14  loss_mask_6: 2.149  loss_mask_7: 2.156  loss_mask_8: 2.156  time: 2.9960  data_time: 0.0601  lr: 5.9694e-05  max_mem: 27646M
[01/29 21:43:11] d2.utils.events INFO:  eta: 1 day, 3:40:54  iter: 26199  total_loss: 24.09  loss_mask: 2.392  loss_mask_0: 2.473  loss_mask_1: 2.387  loss_mask_2: 2.402  loss_mask_3: 2.411  loss_mask_4: 2.416  loss_mask_5: 2.39  loss_mask_6: 2.387  loss_mask_7: 2.413  loss_mask_8: 2.417  time: 2.9960  data_time: 0.0512  lr: 5.9662e-05  max_mem: 27646M
[01/29 21:44:10] d2.utils.events INFO:  eta: 1 day, 3:39:59  iter: 26219  total_loss: 22.07  loss_mask: 2.225  loss_mask_0: 2.348  loss_mask_1: 2.211  loss_mask_2: 2.217  loss_mask_3: 2.207  loss_mask_4: 2.196  loss_mask_5: 2.211  loss_mask_6: 2.199  loss_mask_7: 2.205  loss_mask_8: 2.204  time: 2.9959  data_time: 0.0571  lr: 5.9631e-05  max_mem: 27646M
[01/29 21:45:09] d2.utils.events INFO:  eta: 1 day, 3:38:56  iter: 26239  total_loss: 23.47  loss_mask: 2.336  loss_mask_0: 2.395  loss_mask_1: 2.348  loss_mask_2: 2.35  loss_mask_3: 2.339  loss_mask_4: 2.368  loss_mask_5: 2.324  loss_mask_6: 2.34  loss_mask_7: 2.35  loss_mask_8: 2.35  time: 2.9959  data_time: 0.0621  lr: 5.9599e-05  max_mem: 27646M
[01/29 21:46:09] d2.utils.events INFO:  eta: 1 day, 3:38:04  iter: 26259  total_loss: 22.64  loss_mask: 2.253  loss_mask_0: 2.299  loss_mask_1: 2.249  loss_mask_2: 2.244  loss_mask_3: 2.268  loss_mask_4: 2.256  loss_mask_5: 2.244  loss_mask_6: 2.244  loss_mask_7: 2.269  loss_mask_8: 2.242  time: 2.9959  data_time: 0.0592  lr: 5.9567e-05  max_mem: 27646M
[01/29 21:47:08] d2.utils.events INFO:  eta: 1 day, 3:37:02  iter: 26279  total_loss: 24.83  loss_mask: 2.478  loss_mask_0: 2.517  loss_mask_1: 2.463  loss_mask_2: 2.472  loss_mask_3: 2.49  loss_mask_4: 2.474  loss_mask_5: 2.485  loss_mask_6: 2.493  loss_mask_7: 2.487  loss_mask_8: 2.47  time: 2.9959  data_time: 0.0652  lr: 5.9535e-05  max_mem: 27646M
[01/29 21:48:07] d2.utils.events INFO:  eta: 1 day, 3:36:21  iter: 26299  total_loss: 22.07  loss_mask: 2.204  loss_mask_0: 2.227  loss_mask_1: 2.193  loss_mask_2: 2.2  loss_mask_3: 2.208  loss_mask_4: 2.213  loss_mask_5: 2.194  loss_mask_6: 2.202  loss_mask_7: 2.222  loss_mask_8: 2.2  time: 2.9958  data_time: 0.0554  lr: 5.9503e-05  max_mem: 27646M
[01/29 21:49:06] d2.utils.events INFO:  eta: 1 day, 3:35:48  iter: 26319  total_loss: 25.1  loss_mask: 2.509  loss_mask_0: 2.547  loss_mask_1: 2.484  loss_mask_2: 2.512  loss_mask_3: 2.505  loss_mask_4: 2.512  loss_mask_5: 2.498  loss_mask_6: 2.504  loss_mask_7: 2.517  loss_mask_8: 2.514  time: 2.9958  data_time: 0.0577  lr: 5.9472e-05  max_mem: 27646M
[01/29 21:50:05] d2.utils.events INFO:  eta: 1 day, 3:35:36  iter: 26339  total_loss: 21.41  loss_mask: 2.131  loss_mask_0: 2.183  loss_mask_1: 2.124  loss_mask_2: 2.152  loss_mask_3: 2.135  loss_mask_4: 2.148  loss_mask_5: 2.127  loss_mask_6: 2.127  loss_mask_7: 2.141  loss_mask_8: 2.141  time: 2.9958  data_time: 0.0646  lr: 5.944e-05  max_mem: 27646M
[01/29 21:51:06] d2.utils.events INFO:  eta: 1 day, 3:34:59  iter: 26359  total_loss: 24.85  loss_mask: 2.499  loss_mask_0: 2.493  loss_mask_1: 2.448  loss_mask_2: 2.481  loss_mask_3: 2.497  loss_mask_4: 2.48  loss_mask_5: 2.471  loss_mask_6: 2.518  loss_mask_7: 2.499  loss_mask_8: 2.478  time: 2.9958  data_time: 0.0789  lr: 5.9408e-05  max_mem: 27646M
[01/29 21:52:05] d2.utils.events INFO:  eta: 1 day, 3:34:07  iter: 26379  total_loss: 23.72  loss_mask: 2.366  loss_mask_0: 2.409  loss_mask_1: 2.362  loss_mask_2: 2.363  loss_mask_3: 2.381  loss_mask_4: 2.364  loss_mask_5: 2.346  loss_mask_6: 2.366  loss_mask_7: 2.376  loss_mask_8: 2.368  time: 2.9958  data_time: 0.0572  lr: 5.9376e-05  max_mem: 27646M
[01/29 21:53:05] d2.utils.events INFO:  eta: 1 day, 3:33:44  iter: 26399  total_loss: 22.85  loss_mask: 2.258  loss_mask_0: 2.399  loss_mask_1: 2.284  loss_mask_2: 2.269  loss_mask_3: 2.28  loss_mask_4: 2.278  loss_mask_5: 2.256  loss_mask_6: 2.264  loss_mask_7: 2.284  loss_mask_8: 2.273  time: 2.9957  data_time: 0.0642  lr: 5.9345e-05  max_mem: 27646M
[01/29 21:54:04] d2.utils.events INFO:  eta: 1 day, 3:32:48  iter: 26419  total_loss: 21.96  loss_mask: 2.18  loss_mask_0: 2.244  loss_mask_1: 2.166  loss_mask_2: 2.19  loss_mask_3: 2.196  loss_mask_4: 2.193  loss_mask_5: 2.169  loss_mask_6: 2.173  loss_mask_7: 2.193  loss_mask_8: 2.197  time: 2.9957  data_time: 0.0601  lr: 5.9313e-05  max_mem: 27646M
[01/29 21:55:03] d2.utils.events INFO:  eta: 1 day, 3:31:57  iter: 26439  total_loss: 22.39  loss_mask: 2.233  loss_mask_0: 2.303  loss_mask_1: 2.228  loss_mask_2: 2.234  loss_mask_3: 2.255  loss_mask_4: 2.25  loss_mask_5: 2.25  loss_mask_6: 2.229  loss_mask_7: 2.25  loss_mask_8: 2.238  time: 2.9957  data_time: 0.0549  lr: 5.9281e-05  max_mem: 27646M
[01/29 21:56:02] d2.utils.events INFO:  eta: 1 day, 3:30:50  iter: 26459  total_loss: 24.34  loss_mask: 2.419  loss_mask_0: 2.508  loss_mask_1: 2.398  loss_mask_2: 2.413  loss_mask_3: 2.437  loss_mask_4: 2.428  loss_mask_5: 2.422  loss_mask_6: 2.408  loss_mask_7: 2.433  loss_mask_8: 2.43  time: 2.9956  data_time: 0.0561  lr: 5.9249e-05  max_mem: 27646M
[01/29 21:57:01] d2.utils.events INFO:  eta: 1 day, 3:30:04  iter: 26479  total_loss: 23.29  loss_mask: 2.337  loss_mask_0: 2.392  loss_mask_1: 2.319  loss_mask_2: 2.309  loss_mask_3: 2.318  loss_mask_4: 2.346  loss_mask_5: 2.332  loss_mask_6: 2.333  loss_mask_7: 2.33  loss_mask_8: 2.329  time: 2.9956  data_time: 0.0642  lr: 5.9217e-05  max_mem: 27646M
[01/29 21:58:00] d2.utils.events INFO:  eta: 1 day, 3:29:09  iter: 26499  total_loss: 21.88  loss_mask: 2.176  loss_mask_0: 2.212  loss_mask_1: 2.174  loss_mask_2: 2.182  loss_mask_3: 2.202  loss_mask_4: 2.21  loss_mask_5: 2.181  loss_mask_6: 2.178  loss_mask_7: 2.198  loss_mask_8: 2.188  time: 2.9956  data_time: 0.0566  lr: 5.9186e-05  max_mem: 27646M
[01/29 21:58:59] d2.utils.events INFO:  eta: 1 day, 3:27:55  iter: 26519  total_loss: 22.63  loss_mask: 2.26  loss_mask_0: 2.313  loss_mask_1: 2.257  loss_mask_2: 2.257  loss_mask_3: 2.257  loss_mask_4: 2.255  loss_mask_5: 2.271  loss_mask_6: 2.261  loss_mask_7: 2.253  loss_mask_8: 2.271  time: 2.9955  data_time: 0.0537  lr: 5.9154e-05  max_mem: 27646M
[01/29 21:59:57] d2.utils.events INFO:  eta: 1 day, 3:26:56  iter: 26539  total_loss: 23.7  loss_mask: 2.376  loss_mask_0: 2.391  loss_mask_1: 2.351  loss_mask_2: 2.357  loss_mask_3: 2.358  loss_mask_4: 2.366  loss_mask_5: 2.364  loss_mask_6: 2.357  loss_mask_7: 2.366  loss_mask_8: 2.38  time: 2.9955  data_time: 0.0491  lr: 5.9122e-05  max_mem: 27646M
[01/29 22:00:56] d2.utils.events INFO:  eta: 1 day, 3:26:02  iter: 26559  total_loss: 22.84  loss_mask: 2.274  loss_mask_0: 2.318  loss_mask_1: 2.281  loss_mask_2: 2.282  loss_mask_3: 2.284  loss_mask_4: 2.281  loss_mask_5: 2.277  loss_mask_6: 2.269  loss_mask_7: 2.278  loss_mask_8: 2.28  time: 2.9954  data_time: 0.0658  lr: 5.909e-05  max_mem: 27646M
[01/29 22:01:55] d2.utils.events INFO:  eta: 1 day, 3:25:19  iter: 26579  total_loss: 23.09  loss_mask: 2.304  loss_mask_0: 2.322  loss_mask_1: 2.275  loss_mask_2: 2.314  loss_mask_3: 2.321  loss_mask_4: 2.316  loss_mask_5: 2.322  loss_mask_6: 2.299  loss_mask_7: 2.304  loss_mask_8: 2.331  time: 2.9954  data_time: 0.0617  lr: 5.9058e-05  max_mem: 27646M
[01/29 22:02:56] d2.utils.events INFO:  eta: 1 day, 3:24:58  iter: 26599  total_loss: 20.84  loss_mask: 2.077  loss_mask_0: 2.13  loss_mask_1: 2.059  loss_mask_2: 2.074  loss_mask_3: 2.076  loss_mask_4: 2.082  loss_mask_5: 2.077  loss_mask_6: 2.088  loss_mask_7: 2.075  loss_mask_8: 2.074  time: 2.9954  data_time: 0.0743  lr: 5.9027e-05  max_mem: 27646M
[01/29 22:03:55] d2.utils.events INFO:  eta: 1 day, 3:24:19  iter: 26619  total_loss: 19.98  loss_mask: 1.992  loss_mask_0: 2.008  loss_mask_1: 1.976  loss_mask_2: 1.985  loss_mask_3: 1.985  loss_mask_4: 1.976  loss_mask_5: 2.031  loss_mask_6: 2.023  loss_mask_7: 2.025  loss_mask_8: 1.975  time: 2.9954  data_time: 0.0548  lr: 5.8995e-05  max_mem: 27646M
[01/29 22:04:54] d2.utils.events INFO:  eta: 1 day, 3:23:37  iter: 26639  total_loss: 22.53  loss_mask: 2.23  loss_mask_0: 2.33  loss_mask_1: 2.222  loss_mask_2: 2.253  loss_mask_3: 2.253  loss_mask_4: 2.239  loss_mask_5: 2.249  loss_mask_6: 2.273  loss_mask_7: 2.252  loss_mask_8: 2.248  time: 2.9954  data_time: 0.0520  lr: 5.8963e-05  max_mem: 27646M
[01/29 22:05:54] d2.utils.events INFO:  eta: 1 day, 3:22:52  iter: 26659  total_loss: 22.03  loss_mask: 2.219  loss_mask_0: 2.232  loss_mask_1: 2.165  loss_mask_2: 2.194  loss_mask_3: 2.201  loss_mask_4: 2.204  loss_mask_5: 2.196  loss_mask_6: 2.175  loss_mask_7: 2.212  loss_mask_8: 2.197  time: 2.9954  data_time: 0.0587  lr: 5.8931e-05  max_mem: 27646M
[01/29 22:06:55] d2.utils.events INFO:  eta: 1 day, 3:21:41  iter: 26679  total_loss: 21.29  loss_mask: 2.109  loss_mask_0: 2.188  loss_mask_1: 2.104  loss_mask_2: 2.125  loss_mask_3: 2.132  loss_mask_4: 2.132  loss_mask_5: 2.113  loss_mask_6: 2.114  loss_mask_7: 2.141  loss_mask_8: 2.131  time: 2.9954  data_time: 0.0851  lr: 5.8899e-05  max_mem: 27646M
[01/29 22:07:54] d2.utils.events INFO:  eta: 1 day, 3:20:40  iter: 26699  total_loss: 19.75  loss_mask: 1.968  loss_mask_0: 2.007  loss_mask_1: 1.962  loss_mask_2: 1.971  loss_mask_3: 1.973  loss_mask_4: 1.981  loss_mask_5: 1.969  loss_mask_6: 1.969  loss_mask_7: 1.977  loss_mask_8: 1.969  time: 2.9954  data_time: 0.0616  lr: 5.8867e-05  max_mem: 27646M
[01/29 22:08:53] d2.utils.events INFO:  eta: 1 day, 3:19:08  iter: 26719  total_loss: 21.2  loss_mask: 2.118  loss_mask_0: 2.135  loss_mask_1: 2.102  loss_mask_2: 2.117  loss_mask_3: 2.129  loss_mask_4: 2.126  loss_mask_5: 2.109  loss_mask_6: 2.141  loss_mask_7: 2.132  loss_mask_8: 2.112  time: 2.9953  data_time: 0.0576  lr: 5.8836e-05  max_mem: 27646M
[01/29 22:09:51] d2.utils.events INFO:  eta: 1 day, 3:18:01  iter: 26739  total_loss: 22.2  loss_mask: 2.202  loss_mask_0: 2.274  loss_mask_1: 2.212  loss_mask_2: 2.213  loss_mask_3: 2.219  loss_mask_4: 2.222  loss_mask_5: 2.204  loss_mask_6: 2.219  loss_mask_7: 2.22  loss_mask_8: 2.218  time: 2.9953  data_time: 0.0540  lr: 5.8804e-05  max_mem: 27646M
[01/29 22:10:50] d2.utils.events INFO:  eta: 1 day, 3:16:51  iter: 26759  total_loss: 21.44  loss_mask: 2.139  loss_mask_0: 2.199  loss_mask_1: 2.153  loss_mask_2: 2.147  loss_mask_3: 2.124  loss_mask_4: 2.138  loss_mask_5: 2.133  loss_mask_6: 2.129  loss_mask_7: 2.134  loss_mask_8: 2.14  time: 2.9952  data_time: 0.0539  lr: 5.8772e-05  max_mem: 27646M
[01/29 22:11:49] d2.utils.events INFO:  eta: 1 day, 3:16:03  iter: 26779  total_loss: 22.34  loss_mask: 2.229  loss_mask_0: 2.281  loss_mask_1: 2.225  loss_mask_2: 2.242  loss_mask_3: 2.234  loss_mask_4: 2.224  loss_mask_5: 2.226  loss_mask_6: 2.186  loss_mask_7: 2.246  loss_mask_8: 2.242  time: 2.9952  data_time: 0.0516  lr: 5.874e-05  max_mem: 27646M
[01/29 22:12:48] d2.utils.events INFO:  eta: 1 day, 3:15:17  iter: 26799  total_loss: 22.43  loss_mask: 2.255  loss_mask_0: 2.285  loss_mask_1: 2.223  loss_mask_2: 2.235  loss_mask_3: 2.249  loss_mask_4: 2.249  loss_mask_5: 2.244  loss_mask_6: 2.24  loss_mask_7: 2.231  loss_mask_8: 2.243  time: 2.9951  data_time: 0.0547  lr: 5.8708e-05  max_mem: 27646M
[01/29 22:13:47] d2.utils.events INFO:  eta: 1 day, 3:14:05  iter: 26819  total_loss: 23.73  loss_mask: 2.364  loss_mask_0: 2.418  loss_mask_1: 2.382  loss_mask_2: 2.369  loss_mask_3: 2.363  loss_mask_4: 2.36  loss_mask_5: 2.375  loss_mask_6: 2.365  loss_mask_7: 2.366  loss_mask_8: 2.372  time: 2.9951  data_time: 0.0591  lr: 5.8677e-05  max_mem: 27646M
[01/29 22:14:46] d2.utils.events INFO:  eta: 1 day, 3:13:00  iter: 26839  total_loss: 23.33  loss_mask: 2.342  loss_mask_0: 2.361  loss_mask_1: 2.31  loss_mask_2: 2.338  loss_mask_3: 2.331  loss_mask_4: 2.326  loss_mask_5: 2.326  loss_mask_6: 2.326  loss_mask_7: 2.334  loss_mask_8: 2.344  time: 2.9951  data_time: 0.0553  lr: 5.8645e-05  max_mem: 27646M
[01/29 22:15:45] d2.utils.events INFO:  eta: 1 day, 3:11:43  iter: 26859  total_loss: 21.41  loss_mask: 2.299  loss_mask_0: 2.124  loss_mask_1: 2.103  loss_mask_2: 2.117  loss_mask_3: 2.128  loss_mask_4: 2.123  loss_mask_5: 2.132  loss_mask_6: 2.125  loss_mask_7: 2.138  loss_mask_8: 2.14  time: 2.9950  data_time: 0.0545  lr: 5.8613e-05  max_mem: 27646M
[01/29 22:16:44] d2.utils.events INFO:  eta: 1 day, 3:10:22  iter: 26879  total_loss: 23.15  loss_mask: 2.325  loss_mask_0: 2.336  loss_mask_1: 2.288  loss_mask_2: 2.307  loss_mask_3: 2.313  loss_mask_4: 2.31  loss_mask_5: 2.294  loss_mask_6: 2.296  loss_mask_7: 2.316  loss_mask_8: 2.322  time: 2.9950  data_time: 0.0564  lr: 5.8581e-05  max_mem: 27646M
[01/29 22:17:43] d2.utils.events INFO:  eta: 1 day, 3:09:11  iter: 26899  total_loss: 23.51  loss_mask: 2.388  loss_mask_0: 2.364  loss_mask_1: 2.327  loss_mask_2: 2.332  loss_mask_3: 2.349  loss_mask_4: 2.351  loss_mask_5: 2.332  loss_mask_6: 2.346  loss_mask_7: 2.352  loss_mask_8: 2.36  time: 2.9950  data_time: 0.0602  lr: 5.8549e-05  max_mem: 27646M
[01/29 22:18:43] d2.utils.events INFO:  eta: 1 day, 3:08:37  iter: 26919  total_loss: 21.16  loss_mask: 2.111  loss_mask_0: 2.114  loss_mask_1: 2.084  loss_mask_2: 2.107  loss_mask_3: 2.112  loss_mask_4: 2.125  loss_mask_5: 2.111  loss_mask_6: 2.101  loss_mask_7: 2.127  loss_mask_8: 2.122  time: 2.9950  data_time: 0.0670  lr: 5.8517e-05  max_mem: 27646M
[01/29 22:19:42] d2.utils.events INFO:  eta: 1 day, 3:07:46  iter: 26939  total_loss: 21.75  loss_mask: 2.175  loss_mask_0: 2.257  loss_mask_1: 2.145  loss_mask_2: 2.157  loss_mask_3: 2.157  loss_mask_4: 2.165  loss_mask_5: 2.173  loss_mask_6: 2.154  loss_mask_7: 2.196  loss_mask_8: 2.197  time: 2.9949  data_time: 0.0552  lr: 5.8486e-05  max_mem: 27646M
[01/29 22:20:41] d2.utils.events INFO:  eta: 1 day, 3:06:52  iter: 26959  total_loss: 22.16  loss_mask: 2.214  loss_mask_0: 2.244  loss_mask_1: 2.198  loss_mask_2: 2.206  loss_mask_3: 2.214  loss_mask_4: 2.209  loss_mask_5: 2.195  loss_mask_6: 2.202  loss_mask_7: 2.222  loss_mask_8: 2.218  time: 2.9949  data_time: 0.0611  lr: 5.8454e-05  max_mem: 27646M
[01/29 22:21:40] d2.utils.events INFO:  eta: 1 day, 3:05:45  iter: 26979  total_loss: 23.81  loss_mask: 2.428  loss_mask_0: 2.426  loss_mask_1: 2.344  loss_mask_2: 2.383  loss_mask_3: 2.385  loss_mask_4: 2.34  loss_mask_5: 2.354  loss_mask_6: 2.378  loss_mask_7: 2.371  loss_mask_8: 2.376  time: 2.9949  data_time: 0.0466  lr: 5.8422e-05  max_mem: 27646M
[01/29 22:22:39] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 22:22:40] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 22:22:40] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 22:36:59] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.3877401544412153, 'error_1pix': 0.3546146181784336, 'error_3pix': 0.14556643564340074, 'mIoU': 7.731291609604489, 'fwIoU': 18.545926158616826, 'IoU-0': 8.850448404211133e-05, 'IoU-1': 53.03010429143755, 'IoU-2': 2.7591517196143687, 'IoU-3': 5.0138760571282806, 'IoU-4': 5.03027225499004, 'IoU-5': 4.704964579968494, 'IoU-6': 3.8796908405475965, 'IoU-7': 2.964425071158236, 'IoU-8': 7.935442042732825, 'IoU-9': 16.72739824222861, 'IoU-10': 18.698975069692146, 'IoU-11': 24.050108760592114, 'IoU-12': 22.777624281130624, 'IoU-13': 20.262717600471795, 'IoU-14': 20.66278746761022, 'IoU-15': 20.34036615327841, 'IoU-16': 21.17363199179165, 'IoU-17': 21.138732093527207, 'IoU-18': 20.411534273611995, 'IoU-19': 20.931403266780745, 'IoU-20': 20.94019747884789, 'IoU-21': 21.1480234878744, 'IoU-22': 22.110576128449626, 'IoU-23': 20.214395490993073, 'IoU-24': 19.19584987351092, 'IoU-25': 19.260297865609868, 'IoU-26': 18.595535222905703, 'IoU-27': 20.11846888270563, 'IoU-28': 18.99005385541904, 'IoU-29': 19.3889791150519, 'IoU-30': 18.248377947990168, 'IoU-31': 18.80704634343216, 'IoU-32': 17.86564999655986, 'IoU-33': 16.898330998246507, 'IoU-34': 16.280102372598428, 'IoU-35': 17.182857126686656, 'IoU-36': 17.065459903935274, 'IoU-37': 16.780108743155907, 'IoU-38': 17.07907441936899, 'IoU-39': 16.278900353393645, 'IoU-40': 16.957093122512997, 'IoU-41': 15.242241052180583, 'IoU-42': 15.140243688465333, 'IoU-43': 14.884795314548096, 'IoU-44': 14.951035740897428, 'IoU-45': 14.529838893292393, 'IoU-46': 13.628289183259637, 'IoU-47': 13.126801189388509, 'IoU-48': 12.615207338326442, 'IoU-49': 12.290700985368302, 'IoU-50': 12.163981485544673, 'IoU-51': 11.311709298619594, 'IoU-52': 10.91251785553638, 'IoU-53': 10.989699612331066, 'IoU-54': 10.715753573655437, 'IoU-55': 10.281959476696969, 'IoU-56': 9.605611188616729, 'IoU-57': 9.644180577117282, 'IoU-58': 9.737727403470986, 'IoU-59': 9.586986538089182, 'IoU-60': 9.649169806329141, 'IoU-61': 9.300217816020549, 'IoU-62': 9.165157980901647, 'IoU-63': 8.82625584382708, 'IoU-64': 8.427053440449274, 'IoU-65': 8.302852033245353, 'IoU-66': 8.068699258644024, 'IoU-67': 7.640776901255898, 'IoU-68': 7.971435968762607, 'IoU-69': 8.075549532903766, 'IoU-70': 7.728273107339392, 'IoU-71': 7.333282119627568, 'IoU-72': 7.6266797871789525, 'IoU-73': 7.557304581977228, 'IoU-74': 7.610858560096985, 'IoU-75': 7.464865424321476, 'IoU-76': 7.690142087769586, 'IoU-77': 7.383075734727533, 'IoU-78': 7.420500833518358, 'IoU-79': 7.108882185701772, 'IoU-80': 7.151621411229649, 'IoU-81': 7.256587835445644, 'IoU-82': 7.048956636589134, 'IoU-83': 7.138675331956603, 'IoU-84': 6.9793806192119865, 'IoU-85': 6.8784880141761064, 'IoU-86': 6.713990252706968, 'IoU-87': 6.8422941239882, 'IoU-88': 6.748653123174973, 'IoU-89': 6.684451437814995, 'IoU-90': 6.484150498182917, 'IoU-91': 6.175562599926302, 'IoU-92': 5.924495852186972, 'IoU-93': 5.893328060864387, 'IoU-94': 6.042231236774918, 'IoU-95': 5.861461530427508, 'IoU-96': 5.841092218383668, 'IoU-97': 5.718091656356751, 'IoU-98': 5.538806599987117, 'IoU-99': 5.159996994692455, 'IoU-100': 5.171210036367569, 'IoU-101': 5.281645956546922, 'IoU-102': 5.2481725396989924, 'IoU-103': 5.028021307782482, 'IoU-104': 4.980372192760642, 'IoU-105': 5.026740363336491, 'IoU-106': 5.009038440931459, 'IoU-107': 4.833015068156643, 'IoU-108': 4.862114668528689, 'IoU-109': 4.8260755928785155, 'IoU-110': 4.69524274371576, 'IoU-111': 4.422243609056392, 'IoU-112': 4.364536552023968, 'IoU-113': 4.202354669753118, 'IoU-114': 4.305780483705865, 'IoU-115': 4.269686270489687, 'IoU-116': 4.051162912109426, 'IoU-117': 4.0837668159504386, 'IoU-118': 4.062042133841158, 'IoU-119': 4.1945770086696195, 'IoU-120': 4.149722744400834, 'IoU-121': 4.275134164154762, 'IoU-122': 4.310621456840304, 'IoU-123': 4.619692451354478, 'IoU-124': 4.017441438248521, 'IoU-125': 3.615622343478357, 'IoU-126': 3.6877651342300513, 'IoU-127': 3.5441541103611853, 'IoU-128': 3.5168784084720586, 'IoU-129': 3.439894411607633, 'IoU-130': 3.4213259370055917, 'IoU-131': 3.3357983696428373, 'IoU-132': 3.358958431925903, 'IoU-133': 3.6350848020929805, 'IoU-134': 3.572890899616585, 'IoU-135': 3.5195024833414177, 'IoU-136': 3.675672077125037, 'IoU-137': 3.456499109457837, 'IoU-138': 3.2775579097940746, 'IoU-139': 3.106097012136052, 'IoU-140': 3.013790976326163, 'IoU-141': 3.1059840624148864, 'IoU-142': 3.1537012614178526, 'IoU-143': 3.3241569991268825, 'IoU-144': 3.233897276312688, 'IoU-145': 3.3257670468434615, 'IoU-146': 3.1118740830954175, 'IoU-147': 3.1971390313944905, 'IoU-148': 2.9249548220944885, 'IoU-149': 2.882342458888728, 'IoU-150': 3.2038452737924072, 'IoU-151': 3.061455430838561, 'IoU-152': 2.566793136002306, 'IoU-153': 2.4026769907200247, 'IoU-154': 2.3785766030979922, 'IoU-155': 2.4893947305454156, 'IoU-156': 2.8386644822593827, 'IoU-157': 2.583275096210917, 'IoU-158': 2.509516896254123, 'IoU-159': 2.586045997617849, 'IoU-160': 2.2796614324379707, 'IoU-161': 2.629797955157579, 'IoU-162': 1.928860359619768, 'IoU-163': 2.289376791337405, 'IoU-164': 2.028073931781529, 'IoU-165': 2.0980237263706414, 'IoU-166': 2.0453463724760126, 'IoU-167': 2.182231047400879, 'IoU-168': 2.169503080919604, 'IoU-169': 2.169087357385945, 'IoU-170': 2.2959087244668988, 'IoU-171': 1.7268079713858975, 'IoU-172': 2.0139215900696525, 'IoU-173': 1.6743256083405977, 'IoU-174': 1.665283719157, 'IoU-175': 1.8290407346120978, 'IoU-176': 1.8361442634590588, 'IoU-177': 1.635694447306817, 'IoU-178': 1.4185597164063783, 'IoU-179': 2.549771227947299, 'IoU-180': 1.7066889361816762, 'IoU-181': 1.1683690267807816, 'IoU-182': 1.1402875379744877, 'IoU-183': 1.2101390024529846, 'IoU-184': 0.3986910645118205, 'IoU-185': 0.010416584775276924, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 14.12490603759692, 'pACC': 28.083555280108484, 'ACC-0': 0.0004109852798255313, 'ACC-1': 53.76169009146663, 'ACC-2': 4.968430869632102, 'ACC-3': 19.57580687277441, 'ACC-4': 18.995704920099175, 'ACC-5': 18.25602113492929, 'ACC-6': 15.629392398208461, 'ACC-7': 14.191561744533294, 'ACC-8': 23.002897063738732, 'ACC-9': 35.10109667858292, 'ACC-10': 37.05612999996259, 'ACC-11': 40.65477311810092, 'ACC-12': 37.57374662107554, 'ACC-13': 32.1578975733368, 'ACC-14': 32.627876201590865, 'ACC-15': 32.12588716225569, 'ACC-16': 32.45724068699214, 'ACC-17': 34.93706309005062, 'ACC-18': 33.058234815769154, 'ACC-19': 34.02195780600209, 'ACC-20': 34.15978759641496, 'ACC-21': 34.28917627421282, 'ACC-22': 34.91892875683316, 'ACC-23': 33.503474469655245, 'ACC-24': 32.24108675525068, 'ACC-25': 32.95396702161824, 'ACC-26': 31.63895564223988, 'ACC-27': 33.58370924117226, 'ACC-28': 32.271232197763396, 'ACC-29': 32.02753002253387, 'ACC-30': 30.815174143111324, 'ACC-31': 31.287912163900096, 'ACC-32': 30.610009213543233, 'ACC-33': 29.495774979966587, 'ACC-34': 28.49406657562245, 'ACC-35': 29.796816366763828, 'ACC-36': 29.646042191747068, 'ACC-37': 29.814731112879418, 'ACC-38': 30.41188798348023, 'ACC-39': 29.39180716779135, 'ACC-40': 30.116840144544042, 'ACC-41': 27.820593335215765, 'ACC-42': 27.576000759909498, 'ACC-43': 27.00011690346566, 'ACC-44': 26.349212108140602, 'ACC-45': 25.889417347191955, 'ACC-46': 24.977026796241162, 'ACC-47': 23.963769169526458, 'ACC-48': 22.99903609792905, 'ACC-49': 22.306193426303746, 'ACC-50': 22.087759668630834, 'ACC-51': 20.75105451629005, 'ACC-52': 19.721568377417338, 'ACC-53': 19.87014948155295, 'ACC-54': 19.149851623403976, 'ACC-55': 18.32803546759272, 'ACC-56': 17.234476696719845, 'ACC-57': 16.933664419271626, 'ACC-58': 17.336276313168298, 'ACC-59': 17.329859724929644, 'ACC-60': 17.556717303423007, 'ACC-61': 17.126024015449378, 'ACC-62': 17.003616485678815, 'ACC-63': 16.431862920874117, 'ACC-64': 15.585365271508692, 'ACC-65': 15.416855640300373, 'ACC-66': 14.980922155115778, 'ACC-67': 14.360292127608293, 'ACC-68': 14.995403051967896, 'ACC-69': 14.92334689010394, 'ACC-70': 14.065574485768591, 'ACC-71': 13.461902953128247, 'ACC-72': 14.006596747997902, 'ACC-73': 13.909520549428548, 'ACC-74': 13.95338729606166, 'ACC-75': 13.759575599597701, 'ACC-76': 14.03068086838753, 'ACC-77': 13.770836612748532, 'ACC-78': 14.03497913492982, 'ACC-79': 13.573891141955682, 'ACC-80': 13.610998104549138, 'ACC-81': 13.739608228986269, 'ACC-82': 13.308268764841676, 'ACC-83': 13.201609023137136, 'ACC-84': 12.942739224723837, 'ACC-85': 12.848989456425183, 'ACC-86': 12.654419843150693, 'ACC-87': 12.945304295142652, 'ACC-88': 12.804133906017837, 'ACC-89': 12.619232155489302, 'ACC-90': 12.128007361692106, 'ACC-91': 11.569110176053185, 'ACC-92': 11.19596598543399, 'ACC-93': 11.175500091265192, 'ACC-94': 11.434393177488925, 'ACC-95': 11.103491369947966, 'ACC-96': 11.217313816504573, 'ACC-97': 10.812300788124425, 'ACC-98': 10.44734085198961, 'ACC-99': 9.774071722846298, 'ACC-100': 9.731787856597794, 'ACC-101': 9.88804462395821, 'ACC-102': 9.772972360670593, 'ACC-103': 9.384906016813073, 'ACC-104': 9.366518285334841, 'ACC-105': 9.51498269336806, 'ACC-106': 9.401639475374173, 'ACC-107': 9.074818653751594, 'ACC-108': 9.067641823366895, 'ACC-109': 8.967048107466798, 'ACC-110': 8.886328879981717, 'ACC-111': 8.376683430062105, 'ACC-112': 8.353970100210939, 'ACC-113': 8.041703294893201, 'ACC-114': 8.216517729429004, 'ACC-115': 8.077932133567874, 'ACC-116': 7.624498695941304, 'ACC-117': 7.623076570708504, 'ACC-118': 7.600043162501359, 'ACC-119': 7.761618194349908, 'ACC-120': 7.722163070100535, 'ACC-121': 7.984231661403135, 'ACC-122': 8.060988611810881, 'ACC-123': 8.641243099538357, 'ACC-124': 7.633046916495171, 'ACC-125': 6.821462251580714, 'ACC-126': 6.9553798304173995, 'ACC-127': 6.637876253399247, 'ACC-128': 6.710770090170523, 'ACC-129': 6.5763489145993335, 'ACC-130': 6.5925348839009095, 'ACC-131': 6.457244670578375, 'ACC-132': 6.483765787683512, 'ACC-133': 6.973334149843162, 'ACC-134': 6.839465747522619, 'ACC-135': 6.79949831822587, 'ACC-136': 7.073908637718971, 'ACC-137': 6.708278094391998, 'ACC-138': 6.4120523136279415, 'ACC-139': 6.009085445987835, 'ACC-140': 5.754140804754782, 'ACC-141': 5.950122782715829, 'ACC-142': 6.154344615701697, 'ACC-143': 6.486481143511318, 'ACC-144': 6.328068592057762, 'ACC-145': 6.388962186095395, 'ACC-146': 6.00333554179708, 'ACC-147': 6.283014680825974, 'ACC-148': 5.85551460908264, 'ACC-149': 5.938022592739453, 'ACC-150': 6.684219139074159, 'ACC-151': 6.19919576503038, 'ACC-152': 5.010557859599434, 'ACC-153': 4.808397002510123, 'ACC-154': 4.842150746712036, 'ACC-155': 5.2062919221126895, 'ACC-156': 6.202434278991901, 'ACC-157': 5.876284310082711, 'ACC-158': 5.823292889290962, 'ACC-159': 5.971442100219174, 'ACC-160': 5.127697597611184, 'ACC-161': 5.903779238760156, 'ACC-162': 4.485407660197381, 'ACC-163': 5.147920943734551, 'ACC-164': 4.673562511296649, 'ACC-165': 4.808513882227381, 'ACC-166': 4.804794721776867, 'ACC-167': 5.305324084931045, 'ACC-168': 5.013010760250369, 'ACC-169': 5.229578183974887, 'ACC-170': 5.928347317460993, 'ACC-171': 4.610504234867535, 'ACC-172': 5.013890432270252, 'ACC-173': 4.578499584200366, 'ACC-174': 4.42923421332722, 'ACC-175': 5.282697239123723, 'ACC-176': 5.40381210819596, 'ACC-177': 4.979985937560554, 'ACC-178': 4.631541535721667, 'ACC-179': 10.399670508702911, 'ACC-180': 6.704637813674692, 'ACC-181': 4.463251543769141, 'ACC-182': 5.323995650206473, 'ACC-183': 2.822359452950081, 'ACC-184': 0.7039812083006106, 'ACC-185': 0.012240806692256882, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 22:36:59] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 22:36:59] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 22:36:59] d2.evaluation.testing INFO: copypaste: 2.3877,0.3546,0.1456,7.7313,18.5459,14.1249,28.0836
[01/29 22:36:59] d2.utils.events INFO:  eta: 1 day, 3:04:43  iter: 26999  total_loss: 21.12  loss_mask: 2.141  loss_mask_0: 2.131  loss_mask_1: 2.091  loss_mask_2: 2.126  loss_mask_3: 2.121  loss_mask_4: 2.098  loss_mask_5: 2.122  loss_mask_6: 2.156  loss_mask_7: 2.098  loss_mask_8: 2.114  time: 2.9949  data_time: 0.0663  lr: 5.839e-05  max_mem: 27646M
[01/29 22:37:59] d2.utils.events INFO:  eta: 1 day, 3:03:44  iter: 27019  total_loss: 21.84  loss_mask: 2.196  loss_mask_0: 2.235  loss_mask_1: 2.182  loss_mask_2: 2.177  loss_mask_3: 2.178  loss_mask_4: 2.176  loss_mask_5: 2.179  loss_mask_6: 2.183  loss_mask_7: 2.174  loss_mask_8: 2.176  time: 2.9948  data_time: 0.0645  lr: 5.8358e-05  max_mem: 27646M
[01/29 22:38:59] d2.utils.events INFO:  eta: 1 day, 3:02:44  iter: 27039  total_loss: 20.34  loss_mask: 2.038  loss_mask_0: 2.103  loss_mask_1: 2.016  loss_mask_2: 2.034  loss_mask_3: 2.027  loss_mask_4: 2.028  loss_mask_5: 2.038  loss_mask_6: 2.031  loss_mask_7: 2.031  loss_mask_8: 2.034  time: 2.9948  data_time: 0.0632  lr: 5.8326e-05  max_mem: 27646M
[01/29 22:39:58] d2.utils.events INFO:  eta: 1 day, 3:01:53  iter: 27059  total_loss: 23.73  loss_mask: 2.363  loss_mask_0: 2.428  loss_mask_1: 2.354  loss_mask_2: 2.379  loss_mask_3: 2.36  loss_mask_4: 2.364  loss_mask_5: 2.383  loss_mask_6: 2.391  loss_mask_7: 2.361  loss_mask_8: 2.376  time: 2.9948  data_time: 0.0710  lr: 5.8294e-05  max_mem: 27646M
[01/29 22:40:57] d2.utils.events INFO:  eta: 1 day, 3:00:54  iter: 27079  total_loss: 20.98  loss_mask: 2.106  loss_mask_0: 2.124  loss_mask_1: 2.08  loss_mask_2: 2.087  loss_mask_3: 2.086  loss_mask_4: 2.088  loss_mask_5: 2.093  loss_mask_6: 2.083  loss_mask_7: 2.095  loss_mask_8: 2.094  time: 2.9948  data_time: 0.0522  lr: 5.8263e-05  max_mem: 27646M
[01/29 22:41:56] d2.utils.events INFO:  eta: 1 day, 2:59:50  iter: 27099  total_loss: 20.42  loss_mask: 2.038  loss_mask_0: 2.074  loss_mask_1: 2.024  loss_mask_2: 2.041  loss_mask_3: 2.054  loss_mask_4: 2.03  loss_mask_5: 2.034  loss_mask_6: 2.021  loss_mask_7: 2.03  loss_mask_8: 2.049  time: 2.9948  data_time: 0.0568  lr: 5.8231e-05  max_mem: 27646M
[01/29 22:42:56] d2.utils.events INFO:  eta: 1 day, 2:58:48  iter: 27119  total_loss: 21.5  loss_mask: 2.173  loss_mask_0: 2.189  loss_mask_1: 2.126  loss_mask_2: 2.133  loss_mask_3: 2.149  loss_mask_4: 2.137  loss_mask_5: 2.146  loss_mask_6: 2.15  loss_mask_7: 2.137  loss_mask_8: 2.157  time: 2.9947  data_time: 0.0500  lr: 5.8199e-05  max_mem: 27646M
[01/29 22:43:55] d2.utils.events INFO:  eta: 1 day, 2:58:01  iter: 27139  total_loss: 23.34  loss_mask: 2.339  loss_mask_0: 2.397  loss_mask_1: 2.314  loss_mask_2: 2.341  loss_mask_3: 2.326  loss_mask_4: 2.325  loss_mask_5: 2.312  loss_mask_6: 2.32  loss_mask_7: 2.338  loss_mask_8: 2.329  time: 2.9947  data_time: 0.0639  lr: 5.8167e-05  max_mem: 27646M
[01/29 22:44:55] d2.utils.events INFO:  eta: 1 day, 2:57:26  iter: 27159  total_loss: 20.28  loss_mask: 2.029  loss_mask_0: 2.051  loss_mask_1: 2.009  loss_mask_2: 2.023  loss_mask_3: 2.033  loss_mask_4: 2.029  loss_mask_5: 2.018  loss_mask_6: 2.02  loss_mask_7: 2.039  loss_mask_8: 2.032  time: 2.9947  data_time: 0.0628  lr: 5.8135e-05  max_mem: 27646M
[01/29 22:45:54] d2.utils.events INFO:  eta: 1 day, 2:56:23  iter: 27179  total_loss: 20.34  loss_mask: 2.029  loss_mask_0: 2.069  loss_mask_1: 2.022  loss_mask_2: 2.024  loss_mask_3: 2.031  loss_mask_4: 2.035  loss_mask_5: 2.026  loss_mask_6: 2.025  loss_mask_7: 2.045  loss_mask_8: 2.03  time: 2.9947  data_time: 0.0521  lr: 5.8103e-05  max_mem: 27646M
[01/29 22:46:54] d2.utils.events INFO:  eta: 1 day, 2:55:28  iter: 27199  total_loss: 23.21  loss_mask: 2.33  loss_mask_0: 2.336  loss_mask_1: 2.301  loss_mask_2: 2.323  loss_mask_3: 2.334  loss_mask_4: 2.328  loss_mask_5: 2.306  loss_mask_6: 2.32  loss_mask_7: 2.315  loss_mask_8: 2.321  time: 2.9947  data_time: 0.0550  lr: 5.8071e-05  max_mem: 27646M
[01/29 22:47:54] d2.utils.events INFO:  eta: 1 day, 2:55:05  iter: 27219  total_loss: 24.95  loss_mask: 2.491  loss_mask_0: 2.538  loss_mask_1: 2.497  loss_mask_2: 2.502  loss_mask_3: 2.492  loss_mask_4: 2.493  loss_mask_5: 2.49  loss_mask_6: 2.487  loss_mask_7: 2.482  loss_mask_8: 2.474  time: 2.9947  data_time: 0.0694  lr: 5.804e-05  max_mem: 27646M
[01/29 22:48:53] d2.utils.events INFO:  eta: 1 day, 2:54:15  iter: 27239  total_loss: 22.3  loss_mask: 2.251  loss_mask_0: 2.263  loss_mask_1: 2.193  loss_mask_2: 2.21  loss_mask_3: 2.223  loss_mask_4: 2.228  loss_mask_5: 2.243  loss_mask_6: 2.226  loss_mask_7: 2.233  loss_mask_8: 2.235  time: 2.9947  data_time: 0.0572  lr: 5.8008e-05  max_mem: 27646M
[01/29 22:49:52] d2.utils.events INFO:  eta: 1 day, 2:53:05  iter: 27259  total_loss: 22.66  loss_mask: 2.256  loss_mask_0: 2.324  loss_mask_1: 2.256  loss_mask_2: 2.261  loss_mask_3: 2.278  loss_mask_4: 2.259  loss_mask_5: 2.25  loss_mask_6: 2.247  loss_mask_7: 2.273  loss_mask_8: 2.263  time: 2.9946  data_time: 0.0645  lr: 5.7976e-05  max_mem: 27646M
[01/29 22:50:51] d2.utils.events INFO:  eta: 1 day, 2:51:57  iter: 27279  total_loss: 22.53  loss_mask: 2.236  loss_mask_0: 2.293  loss_mask_1: 2.243  loss_mask_2: 2.249  loss_mask_3: 2.256  loss_mask_4: 2.253  loss_mask_5: 2.244  loss_mask_6: 2.252  loss_mask_7: 2.255  loss_mask_8: 2.248  time: 2.9946  data_time: 0.0575  lr: 5.7944e-05  max_mem: 27646M
[01/29 22:51:50] d2.utils.events INFO:  eta: 1 day, 2:50:32  iter: 27299  total_loss: 21.73  loss_mask: 2.142  loss_mask_0: 2.226  loss_mask_1: 2.152  loss_mask_2: 2.19  loss_mask_3: 2.18  loss_mask_4: 2.173  loss_mask_5: 2.155  loss_mask_6: 2.139  loss_mask_7: 2.18  loss_mask_8: 2.182  time: 2.9946  data_time: 0.0604  lr: 5.7912e-05  max_mem: 27646M
[01/29 22:52:49] d2.utils.events INFO:  eta: 1 day, 2:49:29  iter: 27319  total_loss: 22.49  loss_mask: 2.247  loss_mask_0: 2.288  loss_mask_1: 2.231  loss_mask_2: 2.25  loss_mask_3: 2.254  loss_mask_4: 2.255  loss_mask_5: 2.249  loss_mask_6: 2.244  loss_mask_7: 2.245  loss_mask_8: 2.25  time: 2.9945  data_time: 0.0562  lr: 5.788e-05  max_mem: 27646M
[01/29 22:53:48] d2.utils.events INFO:  eta: 1 day, 2:48:17  iter: 27339  total_loss: 25.38  loss_mask: 2.524  loss_mask_0: 2.545  loss_mask_1: 2.531  loss_mask_2: 2.555  loss_mask_3: 2.546  loss_mask_4: 2.533  loss_mask_5: 2.536  loss_mask_6: 2.523  loss_mask_7: 2.534  loss_mask_8: 2.552  time: 2.9945  data_time: 0.0535  lr: 5.7848e-05  max_mem: 27646M
[01/29 22:54:48] d2.utils.events INFO:  eta: 1 day, 2:47:18  iter: 27359  total_loss: 22.29  loss_mask: 2.216  loss_mask_0: 2.26  loss_mask_1: 2.216  loss_mask_2: 2.224  loss_mask_3: 2.223  loss_mask_4: 2.232  loss_mask_5: 2.224  loss_mask_6: 2.219  loss_mask_7: 2.229  loss_mask_8: 2.227  time: 2.9945  data_time: 0.0629  lr: 5.7816e-05  max_mem: 27646M
[01/29 22:55:47] d2.utils.events INFO:  eta: 1 day, 2:46:08  iter: 27379  total_loss: 21.35  loss_mask: 2.13  loss_mask_0: 2.202  loss_mask_1: 2.112  loss_mask_2: 2.127  loss_mask_3: 2.146  loss_mask_4: 2.133  loss_mask_5: 2.125  loss_mask_6: 2.135  loss_mask_7: 2.129  loss_mask_8: 2.145  time: 2.9945  data_time: 0.0578  lr: 5.7785e-05  max_mem: 27646M
[01/29 22:56:45] d2.utils.events INFO:  eta: 1 day, 2:44:43  iter: 27399  total_loss: 25.27  loss_mask: 2.516  loss_mask_0: 2.5  loss_mask_1: 2.489  loss_mask_2: 2.499  loss_mask_3: 2.531  loss_mask_4: 2.497  loss_mask_5: 2.532  loss_mask_6: 2.505  loss_mask_7: 2.49  loss_mask_8: 2.54  time: 2.9944  data_time: 0.0547  lr: 5.7753e-05  max_mem: 27646M
[01/29 22:57:44] d2.utils.events INFO:  eta: 1 day, 2:43:12  iter: 27419  total_loss: 23.13  loss_mask: 2.314  loss_mask_0: 2.322  loss_mask_1: 2.306  loss_mask_2: 2.329  loss_mask_3: 2.316  loss_mask_4: 2.327  loss_mask_5: 2.309  loss_mask_6: 2.31  loss_mask_7: 2.324  loss_mask_8: 2.328  time: 2.9944  data_time: 0.0458  lr: 5.7721e-05  max_mem: 27646M
[01/29 22:58:44] d2.utils.events INFO:  eta: 1 day, 2:42:38  iter: 27439  total_loss: 24.44  loss_mask: 2.415  loss_mask_0: 2.554  loss_mask_1: 2.462  loss_mask_2: 2.471  loss_mask_3: 2.426  loss_mask_4: 2.437  loss_mask_5: 2.413  loss_mask_6: 2.418  loss_mask_7: 2.442  loss_mask_8: 2.439  time: 2.9944  data_time: 0.0616  lr: 5.7689e-05  max_mem: 27646M
[01/29 22:59:43] d2.utils.events INFO:  eta: 1 day, 2:41:55  iter: 27459  total_loss: 21.75  loss_mask: 2.171  loss_mask_0: 2.222  loss_mask_1: 2.163  loss_mask_2: 2.173  loss_mask_3: 2.175  loss_mask_4: 2.183  loss_mask_5: 2.164  loss_mask_6: 2.166  loss_mask_7: 2.184  loss_mask_8: 2.176  time: 2.9943  data_time: 0.0580  lr: 5.7657e-05  max_mem: 27646M
[01/29 23:00:41] d2.utils.events INFO:  eta: 1 day, 2:40:11  iter: 27479  total_loss: 21.54  loss_mask: 2.149  loss_mask_0: 2.224  loss_mask_1: 2.135  loss_mask_2: 2.141  loss_mask_3: 2.14  loss_mask_4: 2.147  loss_mask_5: 2.143  loss_mask_6: 2.14  loss_mask_7: 2.142  loss_mask_8: 2.144  time: 2.9943  data_time: 0.0537  lr: 5.7625e-05  max_mem: 27646M
[01/29 23:01:40] d2.utils.events INFO:  eta: 1 day, 2:39:13  iter: 27499  total_loss: 22.71  loss_mask: 2.263  loss_mask_0: 2.327  loss_mask_1: 2.254  loss_mask_2: 2.279  loss_mask_3: 2.276  loss_mask_4: 2.282  loss_mask_5: 2.269  loss_mask_6: 2.261  loss_mask_7: 2.286  loss_mask_8: 2.281  time: 2.9942  data_time: 0.0569  lr: 5.7593e-05  max_mem: 27646M
[01/29 23:02:39] d2.utils.events INFO:  eta: 1 day, 2:38:17  iter: 27519  total_loss: 23.23  loss_mask: 2.31  loss_mask_0: 2.38  loss_mask_1: 2.296  loss_mask_2: 2.321  loss_mask_3: 2.317  loss_mask_4: 2.331  loss_mask_5: 2.313  loss_mask_6: 2.31  loss_mask_7: 2.325  loss_mask_8: 2.318  time: 2.9942  data_time: 0.0592  lr: 5.7561e-05  max_mem: 27646M
[01/29 23:03:39] d2.utils.events INFO:  eta: 1 day, 2:38:20  iter: 27539  total_loss: 22.95  loss_mask: 2.286  loss_mask_0: 2.361  loss_mask_1: 2.285  loss_mask_2: 2.303  loss_mask_3: 2.297  loss_mask_4: 2.297  loss_mask_5: 2.289  loss_mask_6: 2.289  loss_mask_7: 2.297  loss_mask_8: 2.295  time: 2.9942  data_time: 0.0585  lr: 5.7529e-05  max_mem: 27646M
[01/29 23:04:38] d2.utils.events INFO:  eta: 1 day, 2:37:33  iter: 27559  total_loss: 22.16  loss_mask: 2.215  loss_mask_0: 2.244  loss_mask_1: 2.191  loss_mask_2: 2.22  loss_mask_3: 2.222  loss_mask_4: 2.218  loss_mask_5: 2.219  loss_mask_6: 2.216  loss_mask_7: 2.219  loss_mask_8: 2.217  time: 2.9942  data_time: 0.0566  lr: 5.7497e-05  max_mem: 27646M
[01/29 23:05:37] d2.utils.events INFO:  eta: 1 day, 2:36:17  iter: 27579  total_loss: 23.52  loss_mask: 2.337  loss_mask_0: 2.359  loss_mask_1: 2.365  loss_mask_2: 2.357  loss_mask_3: 2.348  loss_mask_4: 2.356  loss_mask_5: 2.345  loss_mask_6: 2.354  loss_mask_7: 2.361  loss_mask_8: 2.348  time: 2.9941  data_time: 0.0610  lr: 5.7466e-05  max_mem: 27646M
[01/29 23:06:36] d2.utils.events INFO:  eta: 1 day, 2:34:23  iter: 27599  total_loss: 23.02  loss_mask: 2.299  loss_mask_0: 2.306  loss_mask_1: 2.293  loss_mask_2: 2.305  loss_mask_3: 2.307  loss_mask_4: 2.31  loss_mask_5: 2.297  loss_mask_6: 2.293  loss_mask_7: 2.307  loss_mask_8: 2.301  time: 2.9941  data_time: 0.0542  lr: 5.7434e-05  max_mem: 27646M
[01/29 23:07:35] d2.utils.events INFO:  eta: 1 day, 2:33:30  iter: 27619  total_loss: 23.42  loss_mask: 2.36  loss_mask_0: 2.328  loss_mask_1: 2.316  loss_mask_2: 2.352  loss_mask_3: 2.343  loss_mask_4: 2.337  loss_mask_5: 2.341  loss_mask_6: 2.357  loss_mask_7: 2.348  loss_mask_8: 2.336  time: 2.9941  data_time: 0.0543  lr: 5.7402e-05  max_mem: 27646M
[01/29 23:08:34] d2.utils.events INFO:  eta: 1 day, 2:32:24  iter: 27639  total_loss: 24.48  loss_mask: 2.447  loss_mask_0: 2.475  loss_mask_1: 2.447  loss_mask_2: 2.449  loss_mask_3: 2.435  loss_mask_4: 2.439  loss_mask_5: 2.443  loss_mask_6: 2.448  loss_mask_7: 2.464  loss_mask_8: 2.428  time: 2.9940  data_time: 0.0492  lr: 5.737e-05  max_mem: 27646M
[01/29 23:09:33] d2.utils.events INFO:  eta: 1 day, 2:31:21  iter: 27659  total_loss: 22.8  loss_mask: 2.276  loss_mask_0: 2.409  loss_mask_1: 2.255  loss_mask_2: 2.308  loss_mask_3: 2.273  loss_mask_4: 2.275  loss_mask_5: 2.256  loss_mask_6: 2.263  loss_mask_7: 2.324  loss_mask_8: 2.272  time: 2.9940  data_time: 0.0620  lr: 5.7338e-05  max_mem: 27646M
[01/29 23:10:32] d2.utils.events INFO:  eta: 1 day, 2:29:31  iter: 27679  total_loss: 21.89  loss_mask: 2.153  loss_mask_0: 2.175  loss_mask_1: 2.153  loss_mask_2: 2.181  loss_mask_3: 2.161  loss_mask_4: 2.209  loss_mask_5: 2.174  loss_mask_6: 2.149  loss_mask_7: 2.193  loss_mask_8: 2.218  time: 2.9940  data_time: 0.0499  lr: 5.7306e-05  max_mem: 27646M
[01/29 23:11:31] d2.utils.events INFO:  eta: 1 day, 2:28:02  iter: 27699  total_loss: 22.46  loss_mask: 2.179  loss_mask_0: 2.246  loss_mask_1: 2.196  loss_mask_2: 2.287  loss_mask_3: 2.222  loss_mask_4: 2.353  loss_mask_5: 2.267  loss_mask_6: 2.15  loss_mask_7: 2.224  loss_mask_8: 2.328  time: 2.9939  data_time: 0.0552  lr: 5.7274e-05  max_mem: 27646M
[01/29 23:12:30] d2.utils.events INFO:  eta: 1 day, 2:27:35  iter: 27719  total_loss: 21.62  loss_mask: 2.128  loss_mask_0: 2.142  loss_mask_1: 2.091  loss_mask_2: 2.111  loss_mask_3: 2.127  loss_mask_4: 2.284  loss_mask_5: 2.196  loss_mask_6: 2.141  loss_mask_7: 2.122  loss_mask_8: 2.207  time: 2.9939  data_time: 0.0569  lr: 5.7242e-05  max_mem: 27646M
[01/29 23:13:29] d2.utils.events INFO:  eta: 1 day, 2:26:45  iter: 27739  total_loss: 23  loss_mask: 2.265  loss_mask_0: 2.338  loss_mask_1: 2.279  loss_mask_2: 2.31  loss_mask_3: 2.283  loss_mask_4: 2.338  loss_mask_5: 2.277  loss_mask_6: 2.28  loss_mask_7: 2.321  loss_mask_8: 2.305  time: 2.9939  data_time: 0.0605  lr: 5.721e-05  max_mem: 27646M
[01/29 23:14:28] d2.utils.events INFO:  eta: 1 day, 2:25:05  iter: 27759  total_loss: 23.79  loss_mask: 2.355  loss_mask_0: 2.404  loss_mask_1: 2.348  loss_mask_2: 2.392  loss_mask_3: 2.428  loss_mask_4: 2.436  loss_mask_5: 2.345  loss_mask_6: 2.36  loss_mask_7: 2.401  loss_mask_8: 2.382  time: 2.9938  data_time: 0.0599  lr: 5.7178e-05  max_mem: 27646M
[01/29 23:15:27] d2.utils.events INFO:  eta: 1 day, 2:24:36  iter: 27779  total_loss: 21.4  loss_mask: 2.122  loss_mask_0: 2.169  loss_mask_1: 2.113  loss_mask_2: 2.125  loss_mask_3: 2.132  loss_mask_4: 2.144  loss_mask_5: 2.128  loss_mask_6: 2.129  loss_mask_7: 2.118  loss_mask_8: 2.149  time: 2.9938  data_time: 0.0637  lr: 5.7146e-05  max_mem: 27646M
[01/29 23:16:26] d2.utils.events INFO:  eta: 1 day, 2:23:20  iter: 27799  total_loss: 21.76  loss_mask: 2.177  loss_mask_0: 2.166  loss_mask_1: 2.163  loss_mask_2: 2.17  loss_mask_3: 2.178  loss_mask_4: 2.157  loss_mask_5: 2.167  loss_mask_6: 2.171  loss_mask_7: 2.176  loss_mask_8: 2.156  time: 2.9938  data_time: 0.0545  lr: 5.7114e-05  max_mem: 27646M
[01/29 23:17:25] d2.utils.events INFO:  eta: 1 day, 2:22:32  iter: 27819  total_loss: 21.02  loss_mask: 2.112  loss_mask_0: 2.128  loss_mask_1: 2.074  loss_mask_2: 2.09  loss_mask_3: 2.111  loss_mask_4: 2.108  loss_mask_5: 2.096  loss_mask_6: 2.116  loss_mask_7: 2.092  loss_mask_8: 2.092  time: 2.9937  data_time: 0.0570  lr: 5.7083e-05  max_mem: 27646M
[01/29 23:18:24] d2.utils.events INFO:  eta: 1 day, 2:21:39  iter: 27839  total_loss: 22.1  loss_mask: 2.212  loss_mask_0: 2.219  loss_mask_1: 2.2  loss_mask_2: 2.199  loss_mask_3: 2.205  loss_mask_4: 2.21  loss_mask_5: 2.203  loss_mask_6: 2.204  loss_mask_7: 2.222  loss_mask_8: 2.221  time: 2.9937  data_time: 0.0557  lr: 5.7051e-05  max_mem: 27646M
[01/29 23:19:23] d2.utils.events INFO:  eta: 1 day, 2:20:43  iter: 27859  total_loss: 21.62  loss_mask: 2.167  loss_mask_0: 2.229  loss_mask_1: 2.144  loss_mask_2: 2.165  loss_mask_3: 2.161  loss_mask_4: 2.15  loss_mask_5: 2.156  loss_mask_6: 2.165  loss_mask_7: 2.16  loss_mask_8: 2.17  time: 2.9937  data_time: 0.0576  lr: 5.7019e-05  max_mem: 27646M
[01/29 23:20:24] d2.utils.events INFO:  eta: 1 day, 2:20:30  iter: 27879  total_loss: 22.29  loss_mask: 2.238  loss_mask_0: 2.252  loss_mask_1: 2.218  loss_mask_2: 2.221  loss_mask_3: 2.229  loss_mask_4: 2.223  loss_mask_5: 2.229  loss_mask_6: 2.232  loss_mask_7: 2.238  loss_mask_8: 2.225  time: 2.9937  data_time: 0.0671  lr: 5.6987e-05  max_mem: 27646M
[01/29 23:21:24] d2.utils.events INFO:  eta: 1 day, 2:20:21  iter: 27899  total_loss: 20.56  loss_mask: 2.043  loss_mask_0: 2.088  loss_mask_1: 2.042  loss_mask_2: 2.053  loss_mask_3: 2.047  loss_mask_4: 2.059  loss_mask_5: 2.053  loss_mask_6: 2.05  loss_mask_7: 2.085  loss_mask_8: 2.06  time: 2.9937  data_time: 0.0743  lr: 5.6955e-05  max_mem: 27646M
[01/29 23:22:24] d2.utils.events INFO:  eta: 1 day, 2:18:47  iter: 27919  total_loss: 21.55  loss_mask: 2.133  loss_mask_0: 2.199  loss_mask_1: 2.115  loss_mask_2: 2.153  loss_mask_3: 2.156  loss_mask_4: 2.156  loss_mask_5: 2.157  loss_mask_6: 2.143  loss_mask_7: 2.17  loss_mask_8: 2.164  time: 2.9937  data_time: 0.0514  lr: 5.6923e-05  max_mem: 27646M
[01/29 23:23:23] d2.utils.events INFO:  eta: 1 day, 2:17:43  iter: 27939  total_loss: 21.79  loss_mask: 2.177  loss_mask_0: 2.2  loss_mask_1: 2.191  loss_mask_2: 2.183  loss_mask_3: 2.193  loss_mask_4: 2.18  loss_mask_5: 2.182  loss_mask_6: 2.175  loss_mask_7: 2.19  loss_mask_8: 2.181  time: 2.9937  data_time: 0.0553  lr: 5.6891e-05  max_mem: 27646M
[01/29 23:24:21] d2.utils.events INFO:  eta: 1 day, 2:16:34  iter: 27959  total_loss: 21.45  loss_mask: 2.138  loss_mask_0: 2.164  loss_mask_1: 2.146  loss_mask_2: 2.146  loss_mask_3: 2.136  loss_mask_4: 2.14  loss_mask_5: 2.147  loss_mask_6: 2.146  loss_mask_7: 2.146  loss_mask_8: 2.142  time: 2.9936  data_time: 0.0546  lr: 5.6859e-05  max_mem: 27646M
[01/29 23:25:21] d2.utils.events INFO:  eta: 1 day, 2:15:50  iter: 27979  total_loss: 24.31  loss_mask: 2.43  loss_mask_0: 2.447  loss_mask_1: 2.447  loss_mask_2: 2.423  loss_mask_3: 2.415  loss_mask_4: 2.426  loss_mask_5: 2.442  loss_mask_6: 2.436  loss_mask_7: 2.417  loss_mask_8: 2.426  time: 2.9936  data_time: 0.0560  lr: 5.6827e-05  max_mem: 27646M
[01/29 23:26:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 23:26:21] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 23:26:21] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 23:40:36] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.5024523945397545, 'error_1pix': 0.38966813702538267, 'error_3pix': 0.16400674689821104, 'mIoU': 6.827591241134193, 'fwIoU': 18.5195523930702, 'IoU-0': 0.00017324060409202457, 'IoU-1': 65.06232169607568, 'IoU-2': 2.8456708478462502, 'IoU-3': 5.178887739762287, 'IoU-4': 5.062279953394549, 'IoU-5': 4.627840585638202, 'IoU-6': 4.694236549160115, 'IoU-7': 3.9525407315732197, 'IoU-8': 4.452510804567937, 'IoU-9': 11.785031214258069, 'IoU-10': 14.241424940643546, 'IoU-11': 21.57111500400161, 'IoU-12': 22.415719422015183, 'IoU-13': 21.930591626307088, 'IoU-14': 21.228504415978353, 'IoU-15': 19.860134988649783, 'IoU-16': 18.52959992811707, 'IoU-17': 15.779740441004067, 'IoU-18': 17.033199504578523, 'IoU-19': 18.443720660965635, 'IoU-20': 18.075392879385024, 'IoU-21': 17.49450274455581, 'IoU-22': 17.878173655429034, 'IoU-23': 16.929990956688094, 'IoU-24': 17.066246381806334, 'IoU-25': 17.969249036064234, 'IoU-26': 18.24541396941224, 'IoU-27': 20.360937361395152, 'IoU-28': 19.57398695346904, 'IoU-29': 20.5838174775539, 'IoU-30': 19.911536961977365, 'IoU-31': 21.119964309387893, 'IoU-32': 19.969823177948783, 'IoU-33': 18.595100867236543, 'IoU-34': 17.759333917816488, 'IoU-35': 17.97264039119148, 'IoU-36': 17.60486585133355, 'IoU-37': 16.71059038570584, 'IoU-38': 15.7955344138926, 'IoU-39': 14.275608339237241, 'IoU-40': 13.907720093789418, 'IoU-41': 12.641874423546543, 'IoU-42': 11.955474853123002, 'IoU-43': 11.822190546835627, 'IoU-44': 11.540038294441544, 'IoU-45': 11.18795135794447, 'IoU-46': 10.479891332190094, 'IoU-47': 9.845954032133903, 'IoU-48': 9.384482892197745, 'IoU-49': 9.122965280093505, 'IoU-50': 9.24161616080981, 'IoU-51': 8.440913548024495, 'IoU-52': 8.358027621239984, 'IoU-53': 8.172374530871771, 'IoU-54': 8.094780066987184, 'IoU-55': 7.899407080514842, 'IoU-56': 7.524026854478675, 'IoU-57': 7.53820944067017, 'IoU-58': 7.2439797281122775, 'IoU-59': 7.182819073684262, 'IoU-60': 7.002219290949009, 'IoU-61': 6.678501811951873, 'IoU-62': 6.3730162973152416, 'IoU-63': 6.051110834054082, 'IoU-64': 5.675156346935024, 'IoU-65': 5.543025192546934, 'IoU-66': 5.286319109325429, 'IoU-67': 5.202130887481758, 'IoU-68': 5.408479490563079, 'IoU-69': 5.284498219390485, 'IoU-70': 5.053677014886404, 'IoU-71': 5.162388723796323, 'IoU-72': 5.0942554018691935, 'IoU-73': 4.948998864441942, 'IoU-74': 4.997510947465408, 'IoU-75': 4.665214076275873, 'IoU-76': 4.944965483818482, 'IoU-77': 5.102194616198883, 'IoU-78': 5.156768610457065, 'IoU-79': 5.095127939982824, 'IoU-80': 5.104407510835592, 'IoU-81': 5.210374972327788, 'IoU-82': 5.062233508846302, 'IoU-83': 5.424724989841252, 'IoU-84': 5.5573891828927104, 'IoU-85': 5.271928084497367, 'IoU-86': 5.281750969224676, 'IoU-87': 5.185165763208308, 'IoU-88': 5.300924229726724, 'IoU-89': 5.349657908693739, 'IoU-90': 5.124557378593978, 'IoU-91': 5.062501505153646, 'IoU-92': 4.918032274547736, 'IoU-93': 5.164329387889429, 'IoU-94': 5.291874676889243, 'IoU-95': 5.396788919057143, 'IoU-96': 5.488788514636148, 'IoU-97': 5.364649507507723, 'IoU-98': 5.443280579908156, 'IoU-99': 5.216505861082423, 'IoU-100': 5.29864886027739, 'IoU-101': 5.322031867626921, 'IoU-102': 5.240757316276084, 'IoU-103': 5.049597143470148, 'IoU-104': 4.953571689698033, 'IoU-105': 4.977158409195217, 'IoU-106': 5.020138069598761, 'IoU-107': 5.0838210480531645, 'IoU-108': 5.077805383573127, 'IoU-109': 4.944441983684653, 'IoU-110': 5.163334718694485, 'IoU-111': 4.94033395925695, 'IoU-112': 4.62994240729217, 'IoU-113': 4.820141206523579, 'IoU-114': 4.775438688483622, 'IoU-115': 4.504655944003369, 'IoU-116': 4.278253915393557, 'IoU-117': 4.587321234037575, 'IoU-118': 4.170302357214128, 'IoU-119': 4.139743357637003, 'IoU-120': 3.9177231507325327, 'IoU-121': 3.7020380256109187, 'IoU-122': 3.692796437108629, 'IoU-123': 3.6942986442541494, 'IoU-124': 3.4544793482647163, 'IoU-125': 3.2768304920301845, 'IoU-126': 3.359035062951138, 'IoU-127': 3.156447528065092, 'IoU-128': 3.291173599297972, 'IoU-129': 3.040058763313168, 'IoU-130': 3.1439988045122, 'IoU-131': 3.0919657359053256, 'IoU-132': 3.0070744282474937, 'IoU-133': 2.945925806015736, 'IoU-134': 2.909011336590784, 'IoU-135': 2.7696656247202065, 'IoU-136': 2.816620420256114, 'IoU-137': 2.5120657047337445, 'IoU-138': 2.356824632847067, 'IoU-139': 2.4354739012245035, 'IoU-140': 2.411022882720996, 'IoU-141': 2.326701723939657, 'IoU-142': 2.1914100353681496, 'IoU-143': 2.0432984675261494, 'IoU-144': 2.1064118532672818, 'IoU-145': 2.212176668967666, 'IoU-146': 2.1043927883797084, 'IoU-147': 2.08543823970277, 'IoU-148': 2.302658351538912, 'IoU-149': 1.9098933660776567, 'IoU-150': 2.1167734765836497, 'IoU-151': 2.391507569873131, 'IoU-152': 2.535354061646542, 'IoU-153': 2.4420887938902345, 'IoU-154': 2.447000672037588, 'IoU-155': 2.5543088462333308, 'IoU-156': 2.113563252226822, 'IoU-157': 1.9731339402901258, 'IoU-158': 2.1645102377644365, 'IoU-159': 2.0212493799380176, 'IoU-160': 2.071641641877852, 'IoU-161': 1.968563418343422, 'IoU-162': 1.732915448526605, 'IoU-163': 1.8420654953295639, 'IoU-164': 2.0695134150129832, 'IoU-165': 1.72614249627683, 'IoU-166': 1.7879153102057586, 'IoU-167': 1.7627819770130406, 'IoU-168': 1.7327409715948177, 'IoU-169': 2.2821901030790475, 'IoU-170': 2.551668750698913, 'IoU-171': 1.9358737093332523, 'IoU-172': 1.737170065115004, 'IoU-173': 1.5242373814015044, 'IoU-174': 1.533672490847572, 'IoU-175': 1.7279059196558741, 'IoU-176': 1.6650323969929437, 'IoU-177': 1.555371024223466, 'IoU-178': 1.853310299273411, 'IoU-179': 3.051197304948996, 'IoU-180': 1.172445865566609, 'IoU-181': 1.0543483426844735, 'IoU-182': 1.136643221365587, 'IoU-183': 1.90960124644739, 'IoU-184': 1.5449643222078158, 'IoU-185': 0.6650712965775195, 'IoU-186': 0.008207586271991201, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 12.41932397758096, 'pACC': 27.44733513786479, 'ACC-0': 0.0005932146020123235, 'ACC-1': 66.1016486782708, 'ACC-2': 5.912139674819837, 'ACC-3': 21.430337538214815, 'ACC-4': 18.75446705742105, 'ACC-5': 17.31984729571699, 'ACC-6': 18.004025269170473, 'ACC-7': 15.924645671301107, 'ACC-8': 9.202813338707726, 'ACC-9': 16.778601640601014, 'ACC-10': 19.70001782973476, 'ACC-11': 28.67128555357504, 'ACC-12': 34.311807583981754, 'ACC-13': 34.76477860395195, 'ACC-14': 34.65548311237485, 'ACC-15': 34.1228129490694, 'ACC-16': 31.499948266989158, 'ACC-17': 28.397209401899726, 'ACC-18': 29.470544421065636, 'ACC-19': 32.27705626606152, 'ACC-20': 31.59278548090225, 'ACC-21': 29.930497863586314, 'ACC-22': 30.094808089450463, 'ACC-23': 30.641500713401026, 'ACC-24': 30.575257652689203, 'ACC-25': 32.15715855610316, 'ACC-26': 32.2896243118872, 'ACC-27': 35.28295928635451, 'ACC-28': 34.784592710106644, 'ACC-29': 35.071844555167765, 'ACC-30': 34.69760384999429, 'ACC-31': 36.22204504224643, 'ACC-32': 35.0367109810721, 'ACC-33': 32.80312998005614, 'ACC-34': 31.76600265668498, 'ACC-35': 31.94732982429126, 'ACC-36': 31.121537757669838, 'ACC-37': 30.24919580984352, 'ACC-38': 28.4471907794104, 'ACC-39': 25.788497255662396, 'ACC-40': 24.705785491264365, 'ACC-41': 23.116056686764917, 'ACC-42': 21.91146863434301, 'ACC-43': 21.65542224741761, 'ACC-44': 20.4501618460836, 'ACC-45': 19.937974251636607, 'ACC-46': 19.32854047625416, 'ACC-47': 18.125051413175942, 'ACC-48': 17.292787156372096, 'ACC-49': 16.85944558907064, 'ACC-50': 17.010177317766786, 'ACC-51': 15.597162710646845, 'ACC-52': 15.399876036599514, 'ACC-53': 15.103021437960354, 'ACC-54': 14.675362897515734, 'ACC-55': 14.145520471963918, 'ACC-56': 13.565799265769908, 'ACC-57': 13.480664243431356, 'ACC-58': 13.092035030935644, 'ACC-59': 13.279553504672931, 'ACC-60': 13.122480515884256, 'ACC-61': 12.652191666844736, 'ACC-62': 12.075112003101248, 'ACC-63': 11.544322285134143, 'ACC-64': 10.763962222148896, 'ACC-65': 10.572391038668332, 'ACC-66': 10.131423109519053, 'ACC-67': 10.09479355944663, 'ACC-68': 10.43623165252488, 'ACC-69': 9.917626651049742, 'ACC-70': 9.43732237481144, 'ACC-71': 9.882072234133283, 'ACC-72': 9.753300155820273, 'ACC-73': 9.392254998632085, 'ACC-74': 9.414259053121105, 'ACC-75': 8.800422391096154, 'ACC-76': 9.1702113778982, 'ACC-77': 9.600337442272286, 'ACC-78': 9.820303728692638, 'ACC-79': 9.75835399186, 'ACC-80': 9.64518101992529, 'ACC-81': 9.685490688818051, 'ACC-82': 9.294656219896135, 'ACC-83': 9.798745230843268, 'ACC-84': 10.10996581268509, 'ACC-85': 9.62049703903164, 'ACC-86': 9.705612577352962, 'ACC-87': 9.532854420474331, 'ACC-88': 9.701442076022385, 'ACC-89': 9.695684367747491, 'ACC-90': 9.209488287364444, 'ACC-91': 9.153723287142585, 'ACC-92': 8.950800430976685, 'ACC-93': 9.441373052769842, 'ACC-94': 9.694843218967963, 'ACC-95': 9.935530379105295, 'ACC-96': 10.249649076441134, 'ACC-97': 9.90876466337227, 'ACC-98': 10.04638035210506, 'ACC-99': 9.70626894177523, 'ACC-100': 9.863767255647543, 'ACC-101': 9.967635078090208, 'ACC-102': 9.794721341187133, 'ACC-103': 9.481368659676964, 'ACC-104': 9.364132707016552, 'ACC-105': 9.339119832687661, 'ACC-106': 9.392828757135437, 'ACC-107': 9.48556736246187, 'ACC-108': 9.396983827502945, 'ACC-109': 9.177343748892602, 'ACC-110': 9.733349913840579, 'ACC-111': 9.367412949589784, 'ACC-112': 8.894830231311964, 'ACC-113': 9.338715298548223, 'ACC-114': 9.35948545133249, 'ACC-115': 8.783132620690692, 'ACC-116': 8.401745976597688, 'ACC-117': 8.871381879522023, 'ACC-118': 8.165270393337188, 'ACC-119': 8.091014639699049, 'ACC-120': 7.675954135436102, 'ACC-121': 7.186140068231358, 'ACC-122': 7.272542859029881, 'ACC-123': 7.288140778299048, 'ACC-124': 6.909111443657001, 'ACC-125': 6.432551668927291, 'ACC-126': 6.6024053042377435, 'ACC-127': 6.173604556626079, 'ACC-128': 6.507023494586475, 'ACC-129': 6.030589391418831, 'ACC-130': 6.350108218128536, 'ACC-131': 6.206765011002098, 'ACC-132': 6.035796027652951, 'ACC-133': 5.993182142930046, 'ACC-134': 5.9292373976734165, 'ACC-135': 5.5331081466279, 'ACC-136': 5.508787970555348, 'ACC-137': 4.9228486578940736, 'ACC-138': 4.648513846231946, 'ACC-139': 4.913207837980313, 'ACC-140': 4.934096642796681, 'ACC-141': 4.682321813582344, 'ACC-142': 4.516615272024809, 'ACC-143': 4.181684373407808, 'ACC-144': 4.226353790613718, 'ACC-145': 4.305463002303272, 'ACC-146': 4.056201594663133, 'ACC-147': 4.0266188045679465, 'ACC-148': 4.437237358264952, 'ACC-149': 3.6957859946920553, 'ACC-150': 4.111697930705257, 'ACC-151': 4.675987948198998, 'ACC-152': 4.922154224829725, 'ACC-153': 4.9546299858920095, 'ACC-154': 4.985046972584355, 'ACC-155': 5.179668838420068, 'ACC-156': 4.381055802258463, 'ACC-157': 4.523956321548099, 'ACC-158': 4.586543523331418, 'ACC-159': 4.222724398687788, 'ACC-160': 4.220156766049858, 'ACC-161': 3.878795878419555, 'ACC-162': 3.5254283682583507, 'ACC-163': 3.764023559733218, 'ACC-164': 4.41512688713498, 'ACC-165': 3.659470121685878, 'ACC-166': 3.73320126583341, 'ACC-167': 3.6420361076803083, 'ACC-168': 3.675539770729306, 'ACC-169': 4.688774910377913, 'ACC-170': 5.3452020954895865, 'ACC-171': 4.219437959328372, 'ACC-172': 4.1786124384190835, 'ACC-173': 3.8722046411517463, 'ACC-174': 3.7919329855111363, 'ACC-175': 4.6104581616221, 'ACC-176': 4.241278732296262, 'ACC-177': 4.362308971356545, 'ACC-178': 5.6363492373158, 'ACC-179': 12.14654247171224, 'ACC-180': 4.119467303328931, 'ACC-181': 2.9951608433349675, 'ACC-182': 4.301462487769167, 'ACC-183': 5.167968998307244, 'ACC-184': 3.394675213493799, 'ACC-185': 1.3806706114398422, 'ACC-186': 0.009442580846196882, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 23:40:36] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 23:40:36] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 23:40:36] d2.evaluation.testing INFO: copypaste: 2.5025,0.3897,0.1640,6.8276,18.5196,12.4193,27.4473
[01/29 23:40:36] d2.utils.events INFO:  eta: 1 day, 2:15:56  iter: 27999  total_loss: 21.41  loss_mask: 2.145  loss_mask_0: 2.173  loss_mask_1: 2.119  loss_mask_2: 2.135  loss_mask_3: 2.135  loss_mask_4: 2.121  loss_mask_5: 2.152  loss_mask_6: 2.14  loss_mask_7: 2.135  loss_mask_8: 2.137  time: 2.9936  data_time: 0.0611  lr: 5.6795e-05  max_mem: 27646M
[01/29 23:41:36] d2.utils.events INFO:  eta: 1 day, 2:14:42  iter: 28019  total_loss: 21.8  loss_mask: 2.167  loss_mask_0: 2.194  loss_mask_1: 2.17  loss_mask_2: 2.186  loss_mask_3: 2.183  loss_mask_4: 2.181  loss_mask_5: 2.177  loss_mask_6: 2.164  loss_mask_7: 2.168  loss_mask_8: 2.195  time: 2.9936  data_time: 0.0557  lr: 5.6763e-05  max_mem: 27646M
[01/29 23:42:35] d2.utils.events INFO:  eta: 1 day, 2:12:44  iter: 28039  total_loss: 21.08  loss_mask: 2.099  loss_mask_0: 2.154  loss_mask_1: 2.069  loss_mask_2: 2.101  loss_mask_3: 2.126  loss_mask_4: 2.12  loss_mask_5: 2.096  loss_mask_6: 2.096  loss_mask_7: 2.102  loss_mask_8: 2.113  time: 2.9936  data_time: 0.0677  lr: 5.6731e-05  max_mem: 27646M
[01/29 23:43:34] d2.utils.events INFO:  eta: 1 day, 2:11:45  iter: 28059  total_loss: 21.57  loss_mask: 2.145  loss_mask_0: 2.19  loss_mask_1: 2.124  loss_mask_2: 2.148  loss_mask_3: 2.179  loss_mask_4: 2.161  loss_mask_5: 2.138  loss_mask_6: 2.142  loss_mask_7: 2.18  loss_mask_8: 2.155  time: 2.9936  data_time: 0.0585  lr: 5.6699e-05  max_mem: 27646M
[01/29 23:44:34] d2.utils.events INFO:  eta: 1 day, 2:10:55  iter: 28079  total_loss: 21.34  loss_mask: 2.139  loss_mask_0: 2.136  loss_mask_1: 2.131  loss_mask_2: 2.133  loss_mask_3: 2.142  loss_mask_4: 2.138  loss_mask_5: 2.131  loss_mask_6: 2.137  loss_mask_7: 2.135  loss_mask_8: 2.126  time: 2.9935  data_time: 0.0578  lr: 5.6667e-05  max_mem: 27646M
[01/29 23:45:32] d2.utils.events INFO:  eta: 1 day, 2:09:44  iter: 28099  total_loss: 21.72  loss_mask: 2.165  loss_mask_0: 2.202  loss_mask_1: 2.153  loss_mask_2: 2.163  loss_mask_3: 2.18  loss_mask_4: 2.17  loss_mask_5: 2.177  loss_mask_6: 2.181  loss_mask_7: 2.153  loss_mask_8: 2.174  time: 2.9935  data_time: 0.0616  lr: 5.6635e-05  max_mem: 27646M
[01/29 23:46:31] d2.utils.events INFO:  eta: 1 day, 2:08:36  iter: 28119  total_loss: 22.23  loss_mask: 2.23  loss_mask_0: 2.202  loss_mask_1: 2.213  loss_mask_2: 2.24  loss_mask_3: 2.239  loss_mask_4: 2.217  loss_mask_5: 2.21  loss_mask_6: 2.224  loss_mask_7: 2.232  loss_mask_8: 2.226  time: 2.9935  data_time: 0.0624  lr: 5.6603e-05  max_mem: 27646M
[01/29 23:47:31] d2.utils.events INFO:  eta: 1 day, 2:07:46  iter: 28139  total_loss: 21.46  loss_mask: 2.144  loss_mask_0: 2.153  loss_mask_1: 2.141  loss_mask_2: 2.135  loss_mask_3: 2.147  loss_mask_4: 2.144  loss_mask_5: 2.125  loss_mask_6: 2.157  loss_mask_7: 2.155  loss_mask_8: 2.154  time: 2.9935  data_time: 0.0847  lr: 5.6571e-05  max_mem: 27646M
[01/29 23:48:30] d2.utils.events INFO:  eta: 1 day, 2:06:17  iter: 28159  total_loss: 22.62  loss_mask: 2.24  loss_mask_0: 2.333  loss_mask_1: 2.25  loss_mask_2: 2.26  loss_mask_3: 2.258  loss_mask_4: 2.26  loss_mask_5: 2.24  loss_mask_6: 2.243  loss_mask_7: 2.269  loss_mask_8: 2.264  time: 2.9934  data_time: 0.0678  lr: 5.6539e-05  max_mem: 27646M
[01/29 23:49:29] d2.utils.events INFO:  eta: 1 day, 2:04:58  iter: 28179  total_loss: 22.93  loss_mask: 2.281  loss_mask_0: 2.334  loss_mask_1: 2.265  loss_mask_2: 2.284  loss_mask_3: 2.292  loss_mask_4: 2.288  loss_mask_5: 2.293  loss_mask_6: 2.277  loss_mask_7: 2.296  loss_mask_8: 2.302  time: 2.9934  data_time: 0.0539  lr: 5.6508e-05  max_mem: 27646M
[01/29 23:50:28] d2.utils.events INFO:  eta: 1 day, 2:03:58  iter: 28199  total_loss: 21.55  loss_mask: 2.139  loss_mask_0: 2.191  loss_mask_1: 2.089  loss_mask_2: 2.151  loss_mask_3: 2.149  loss_mask_4: 2.148  loss_mask_5: 2.168  loss_mask_6: 2.134  loss_mask_7: 2.171  loss_mask_8: 2.165  time: 2.9933  data_time: 0.0620  lr: 5.6476e-05  max_mem: 27646M
[01/29 23:51:27] d2.utils.events INFO:  eta: 1 day, 2:02:18  iter: 28219  total_loss: 20.68  loss_mask: 2.052  loss_mask_0: 2.111  loss_mask_1: 2.032  loss_mask_2: 2.076  loss_mask_3: 2.072  loss_mask_4: 2.069  loss_mask_5: 2.043  loss_mask_6: 2.049  loss_mask_7: 2.073  loss_mask_8: 2.082  time: 2.9933  data_time: 0.0540  lr: 5.6444e-05  max_mem: 27646M
[01/29 23:52:25] d2.utils.events INFO:  eta: 1 day, 2:01:09  iter: 28239  total_loss: 21.71  loss_mask: 2.171  loss_mask_0: 2.206  loss_mask_1: 2.144  loss_mask_2: 2.166  loss_mask_3: 2.17  loss_mask_4: 2.168  loss_mask_5: 2.165  loss_mask_6: 2.168  loss_mask_7: 2.186  loss_mask_8: 2.168  time: 2.9933  data_time: 0.0560  lr: 5.6412e-05  max_mem: 27646M
[01/29 23:53:25] d2.utils.events INFO:  eta: 1 day, 2:00:20  iter: 28259  total_loss: 22.44  loss_mask: 2.245  loss_mask_0: 2.274  loss_mask_1: 2.243  loss_mask_2: 2.248  loss_mask_3: 2.248  loss_mask_4: 2.251  loss_mask_5: 2.232  loss_mask_6: 2.239  loss_mask_7: 2.251  loss_mask_8: 2.239  time: 2.9932  data_time: 0.0620  lr: 5.638e-05  max_mem: 27646M
[01/29 23:54:23] d2.utils.events INFO:  eta: 1 day, 1:59:11  iter: 28279  total_loss: 22.57  loss_mask: 2.264  loss_mask_0: 2.304  loss_mask_1: 2.243  loss_mask_2: 2.258  loss_mask_3: 2.26  loss_mask_4: 2.248  loss_mask_5: 2.248  loss_mask_6: 2.259  loss_mask_7: 2.259  loss_mask_8: 2.26  time: 2.9932  data_time: 0.0563  lr: 5.6348e-05  max_mem: 27646M
[01/29 23:55:22] d2.utils.events INFO:  eta: 1 day, 1:58:20  iter: 28299  total_loss: 21.64  loss_mask: 2.167  loss_mask_0: 2.157  loss_mask_1: 2.135  loss_mask_2: 2.157  loss_mask_3: 2.165  loss_mask_4: 2.164  loss_mask_5: 2.163  loss_mask_6: 2.17  loss_mask_7: 2.176  loss_mask_8: 2.164  time: 2.9932  data_time: 0.0589  lr: 5.6316e-05  max_mem: 27646M
[01/29 23:56:21] d2.utils.events INFO:  eta: 1 day, 1:57:26  iter: 28319  total_loss: 21.89  loss_mask: 2.171  loss_mask_0: 2.253  loss_mask_1: 2.155  loss_mask_2: 2.185  loss_mask_3: 2.194  loss_mask_4: 2.201  loss_mask_5: 2.163  loss_mask_6: 2.187  loss_mask_7: 2.196  loss_mask_8: 2.181  time: 2.9931  data_time: 0.0597  lr: 5.6284e-05  max_mem: 27646M
[01/29 23:57:20] d2.utils.events INFO:  eta: 1 day, 1:56:27  iter: 28339  total_loss: 22.16  loss_mask: 2.191  loss_mask_0: 2.284  loss_mask_1: 2.191  loss_mask_2: 2.215  loss_mask_3: 2.216  loss_mask_4: 2.22  loss_mask_5: 2.191  loss_mask_6: 2.191  loss_mask_7: 2.216  loss_mask_8: 2.214  time: 2.9931  data_time: 0.0539  lr: 5.6252e-05  max_mem: 27646M
[01/29 23:58:19] d2.utils.events INFO:  eta: 1 day, 1:55:23  iter: 28359  total_loss: 20.62  loss_mask: 2.062  loss_mask_0: 2.061  loss_mask_1: 2.043  loss_mask_2: 2.07  loss_mask_3: 2.057  loss_mask_4: 2.062  loss_mask_5: 2.059  loss_mask_6: 2.063  loss_mask_7: 2.08  loss_mask_8: 2.063  time: 2.9931  data_time: 0.0620  lr: 5.622e-05  max_mem: 27646M
[01/29 23:59:18] d2.utils.events INFO:  eta: 1 day, 1:54:24  iter: 28379  total_loss: 21.24  loss_mask: 2.13  loss_mask_0: 2.133  loss_mask_1: 2.112  loss_mask_2: 2.128  loss_mask_3: 2.126  loss_mask_4: 2.129  loss_mask_5: 2.132  loss_mask_6: 2.111  loss_mask_7: 2.137  loss_mask_8: 2.131  time: 2.9930  data_time: 0.0553  lr: 5.6188e-05  max_mem: 27646M
[01/30 00:00:19] d2.utils.events INFO:  eta: 1 day, 1:53:58  iter: 28399  total_loss: 19.85  loss_mask: 2.009  loss_mask_0: 1.989  loss_mask_1: 1.958  loss_mask_2: 1.983  loss_mask_3: 1.993  loss_mask_4: 1.992  loss_mask_5: 1.991  loss_mask_6: 1.988  loss_mask_7: 1.993  loss_mask_8: 1.981  time: 2.9931  data_time: 0.0777  lr: 5.6156e-05  max_mem: 27646M
[01/30 00:01:18] d2.utils.events INFO:  eta: 1 day, 1:53:03  iter: 28419  total_loss: 20.93  loss_mask: 2.092  loss_mask_0: 2.139  loss_mask_1: 2.068  loss_mask_2: 2.092  loss_mask_3: 2.092  loss_mask_4: 2.087  loss_mask_5: 2.079  loss_mask_6: 2.086  loss_mask_7: 2.103  loss_mask_8: 2.092  time: 2.9930  data_time: 0.0644  lr: 5.6124e-05  max_mem: 27646M
[01/30 00:02:17] d2.utils.events INFO:  eta: 1 day, 1:52:09  iter: 28439  total_loss: 23.02  loss_mask: 2.251  loss_mask_0: 2.311  loss_mask_1: 2.323  loss_mask_2: 2.298  loss_mask_3: 2.407  loss_mask_4: 2.273  loss_mask_5: 2.271  loss_mask_6: 2.25  loss_mask_7: 2.263  loss_mask_8: 2.266  time: 2.9930  data_time: 0.0578  lr: 5.6092e-05  max_mem: 27646M
[01/30 00:03:16] d2.utils.events INFO:  eta: 1 day, 1:51:27  iter: 28459  total_loss: 22.44  loss_mask: 2.21  loss_mask_0: 2.316  loss_mask_1: 2.239  loss_mask_2: 2.248  loss_mask_3: 2.317  loss_mask_4: 2.241  loss_mask_5: 2.218  loss_mask_6: 2.212  loss_mask_7: 2.227  loss_mask_8: 2.228  time: 2.9930  data_time: 0.0572  lr: 5.606e-05  max_mem: 27646M
[01/30 00:04:15] d2.utils.events INFO:  eta: 1 day, 1:50:41  iter: 28479  total_loss: 22.64  loss_mask: 2.241  loss_mask_0: 2.365  loss_mask_1: 2.242  loss_mask_2: 2.274  loss_mask_3: 2.34  loss_mask_4: 2.27  loss_mask_5: 2.243  loss_mask_6: 2.242  loss_mask_7: 2.251  loss_mask_8: 2.249  time: 2.9930  data_time: 0.0553  lr: 5.6028e-05  max_mem: 27646M
[01/30 00:05:14] d2.utils.events INFO:  eta: 1 day, 1:49:39  iter: 28499  total_loss: 22.53  loss_mask: 2.244  loss_mask_0: 2.302  loss_mask_1: 2.236  loss_mask_2: 2.25  loss_mask_3: 2.28  loss_mask_4: 2.238  loss_mask_5: 2.28  loss_mask_6: 2.25  loss_mask_7: 2.237  loss_mask_8: 2.236  time: 2.9929  data_time: 0.0574  lr: 5.5996e-05  max_mem: 27646M
[01/30 00:06:13] d2.utils.events INFO:  eta: 1 day, 1:48:43  iter: 28519  total_loss: 22.09  loss_mask: 2.18  loss_mask_0: 2.263  loss_mask_1: 2.199  loss_mask_2: 2.222  loss_mask_3: 2.225  loss_mask_4: 2.234  loss_mask_5: 2.182  loss_mask_6: 2.183  loss_mask_7: 2.233  loss_mask_8: 2.224  time: 2.9929  data_time: 0.0613  lr: 5.5964e-05  max_mem: 27646M
[01/30 00:07:13] d2.utils.events INFO:  eta: 1 day, 1:47:48  iter: 28539  total_loss: 21.3  loss_mask: 2.119  loss_mask_0: 2.147  loss_mask_1: 2.109  loss_mask_2: 2.127  loss_mask_3: 2.153  loss_mask_4: 2.127  loss_mask_5: 2.118  loss_mask_6: 2.123  loss_mask_7: 2.122  loss_mask_8: 2.128  time: 2.9929  data_time: 0.0676  lr: 5.5932e-05  max_mem: 27646M
[01/30 00:08:13] d2.utils.events INFO:  eta: 1 day, 1:46:55  iter: 28559  total_loss: 21.63  loss_mask: 2.16  loss_mask_0: 2.156  loss_mask_1: 2.149  loss_mask_2: 2.175  loss_mask_3: 2.231  loss_mask_4: 2.156  loss_mask_5: 2.143  loss_mask_6: 2.157  loss_mask_7: 2.151  loss_mask_8: 2.149  time: 2.9929  data_time: 0.0638  lr: 5.59e-05  max_mem: 27646M
[01/30 00:09:12] d2.utils.events INFO:  eta: 1 day, 1:45:56  iter: 28579  total_loss: 21.77  loss_mask: 2.156  loss_mask_0: 2.232  loss_mask_1: 2.169  loss_mask_2: 2.194  loss_mask_3: 2.224  loss_mask_4: 2.182  loss_mask_5: 2.161  loss_mask_6: 2.159  loss_mask_7: 2.178  loss_mask_8: 2.172  time: 2.9928  data_time: 0.0510  lr: 5.5868e-05  max_mem: 27646M
[01/30 00:10:11] d2.utils.events INFO:  eta: 1 day, 1:44:49  iter: 28599  total_loss: 20.71  loss_mask: 2.058  loss_mask_0: 2.112  loss_mask_1: 2.062  loss_mask_2: 2.061  loss_mask_3: 2.086  loss_mask_4: 2.072  loss_mask_5: 2.064  loss_mask_6: 2.064  loss_mask_7: 2.068  loss_mask_8: 2.064  time: 2.9928  data_time: 0.0578  lr: 5.5836e-05  max_mem: 27646M
[01/30 00:11:09] d2.utils.events INFO:  eta: 1 day, 1:43:35  iter: 28619  total_loss: 23.33  loss_mask: 2.327  loss_mask_0: 2.352  loss_mask_1: 2.332  loss_mask_2: 2.326  loss_mask_3: 2.344  loss_mask_4: 2.324  loss_mask_5: 2.338  loss_mask_6: 2.325  loss_mask_7: 2.332  loss_mask_8: 2.328  time: 2.9928  data_time: 0.0512  lr: 5.5804e-05  max_mem: 27646M
[01/30 00:12:08] d2.utils.events INFO:  eta: 1 day, 1:42:47  iter: 28639  total_loss: 23.49  loss_mask: 2.32  loss_mask_0: 2.447  loss_mask_1: 2.334  loss_mask_2: 2.346  loss_mask_3: 2.36  loss_mask_4: 2.353  loss_mask_5: 2.323  loss_mask_6: 2.33  loss_mask_7: 2.342  loss_mask_8: 2.351  time: 2.9927  data_time: 0.0616  lr: 5.5772e-05  max_mem: 27646M
[01/30 00:13:08] d2.utils.events INFO:  eta: 1 day, 1:41:50  iter: 28659  total_loss: 21.73  loss_mask: 2.16  loss_mask_0: 2.229  loss_mask_1: 2.157  loss_mask_2: 2.169  loss_mask_3: 2.179  loss_mask_4: 2.178  loss_mask_5: 2.165  loss_mask_6: 2.156  loss_mask_7: 2.166  loss_mask_8: 2.172  time: 2.9927  data_time: 0.0640  lr: 5.574e-05  max_mem: 27646M
[01/30 00:14:07] d2.utils.events INFO:  eta: 1 day, 1:40:56  iter: 28679  total_loss: 22.4  loss_mask: 2.232  loss_mask_0: 2.295  loss_mask_1: 2.227  loss_mask_2: 2.235  loss_mask_3: 2.262  loss_mask_4: 2.241  loss_mask_5: 2.235  loss_mask_6: 2.232  loss_mask_7: 2.241  loss_mask_8: 2.233  time: 2.9927  data_time: 0.0614  lr: 5.5708e-05  max_mem: 27646M
[01/30 00:15:06] d2.utils.events INFO:  eta: 1 day, 1:40:06  iter: 28699  total_loss: 22.31  loss_mask: 2.215  loss_mask_0: 2.27  loss_mask_1: 2.232  loss_mask_2: 2.236  loss_mask_3: 2.248  loss_mask_4: 2.238  loss_mask_5: 2.222  loss_mask_6: 2.21  loss_mask_7: 2.241  loss_mask_8: 2.236  time: 2.9927  data_time: 0.0566  lr: 5.5676e-05  max_mem: 27646M
[01/30 00:16:05] d2.utils.events INFO:  eta: 1 day, 1:39:05  iter: 28719  total_loss: 19.87  loss_mask: 1.994  loss_mask_0: 2.01  loss_mask_1: 1.971  loss_mask_2: 2.001  loss_mask_3: 1.998  loss_mask_4: 1.989  loss_mask_5: 1.972  loss_mask_6: 1.99  loss_mask_7: 1.972  loss_mask_8: 1.974  time: 2.9927  data_time: 0.0593  lr: 5.5644e-05  max_mem: 27646M
[01/30 00:17:06] d2.utils.events INFO:  eta: 1 day, 1:38:10  iter: 28739  total_loss: 22.53  loss_mask: 2.237  loss_mask_0: 2.283  loss_mask_1: 2.229  loss_mask_2: 2.253  loss_mask_3: 2.258  loss_mask_4: 2.257  loss_mask_5: 2.256  loss_mask_6: 2.232  loss_mask_7: 2.272  loss_mask_8: 2.252  time: 2.9927  data_time: 0.0712  lr: 5.5612e-05  max_mem: 27646M
[01/30 00:18:05] d2.utils.events INFO:  eta: 1 day, 1:38:17  iter: 28759  total_loss: 22.4  loss_mask: 2.227  loss_mask_0: 2.267  loss_mask_1: 2.237  loss_mask_2: 2.23  loss_mask_3: 2.266  loss_mask_4: 2.26  loss_mask_5: 2.229  loss_mask_6: 2.22  loss_mask_7: 2.251  loss_mask_8: 2.24  time: 2.9927  data_time: 0.0614  lr: 5.558e-05  max_mem: 27646M
[01/30 00:19:04] d2.utils.events INFO:  eta: 1 day, 1:37:06  iter: 28779  total_loss: 22.37  loss_mask: 2.229  loss_mask_0: 2.214  loss_mask_1: 2.219  loss_mask_2: 2.215  loss_mask_3: 2.269  loss_mask_4: 2.239  loss_mask_5: 2.217  loss_mask_6: 2.231  loss_mask_7: 2.24  loss_mask_8: 2.233  time: 2.9926  data_time: 0.0567  lr: 5.5548e-05  max_mem: 27646M
[01/30 00:20:03] d2.utils.events INFO:  eta: 1 day, 1:36:21  iter: 28799  total_loss: 20.03  loss_mask: 2.006  loss_mask_0: 2.044  loss_mask_1: 1.973  loss_mask_2: 1.996  loss_mask_3: 2.006  loss_mask_4: 2.006  loss_mask_5: 1.998  loss_mask_6: 1.995  loss_mask_7: 2.003  loss_mask_8: 2  time: 2.9926  data_time: 0.0548  lr: 5.5516e-05  max_mem: 27646M
[01/30 00:21:03] d2.utils.events INFO:  eta: 1 day, 1:35:41  iter: 28819  total_loss: 22.52  loss_mask: 2.225  loss_mask_0: 2.293  loss_mask_1: 2.198  loss_mask_2: 2.234  loss_mask_3: 2.257  loss_mask_4: 2.253  loss_mask_5: 2.231  loss_mask_6: 2.231  loss_mask_7: 2.254  loss_mask_8: 2.247  time: 2.9926  data_time: 0.0682  lr: 5.5484e-05  max_mem: 27646M
[01/30 00:22:02] d2.utils.events INFO:  eta: 1 day, 1:34:44  iter: 28839  total_loss: 19.78  loss_mask: 1.96  loss_mask_0: 2.065  loss_mask_1: 1.961  loss_mask_2: 1.973  loss_mask_3: 1.975  loss_mask_4: 1.983  loss_mask_5: 1.96  loss_mask_6: 1.963  loss_mask_7: 1.977  loss_mask_8: 1.97  time: 2.9926  data_time: 0.0559  lr: 5.5452e-05  max_mem: 27646M
[01/30 00:23:01] d2.utils.events INFO:  eta: 1 day, 1:33:49  iter: 28859  total_loss: 21.31  loss_mask: 2.116  loss_mask_0: 2.136  loss_mask_1: 2.114  loss_mask_2: 2.126  loss_mask_3: 2.158  loss_mask_4: 2.137  loss_mask_5: 2.155  loss_mask_6: 2.133  loss_mask_7: 2.145  loss_mask_8: 2.146  time: 2.9925  data_time: 0.0608  lr: 5.542e-05  max_mem: 27646M
[01/30 00:24:01] d2.utils.events INFO:  eta: 1 day, 1:32:44  iter: 28879  total_loss: 21.91  loss_mask: 2.181  loss_mask_0: 2.27  loss_mask_1: 2.165  loss_mask_2: 2.203  loss_mask_3: 2.194  loss_mask_4: 2.19  loss_mask_5: 2.198  loss_mask_6: 2.192  loss_mask_7: 2.191  loss_mask_8: 2.208  time: 2.9925  data_time: 0.0522  lr: 5.5388e-05  max_mem: 27646M
[01/30 00:25:01] d2.utils.events INFO:  eta: 1 day, 1:31:25  iter: 28899  total_loss: 22.15  loss_mask: 2.219  loss_mask_0: 2.276  loss_mask_1: 2.208  loss_mask_2: 2.194  loss_mask_3: 2.208  loss_mask_4: 2.212  loss_mask_5: 2.211  loss_mask_6: 2.2  loss_mask_7: 2.214  loss_mask_8: 2.225  time: 2.9925  data_time: 0.0554  lr: 5.5356e-05  max_mem: 27646M
[01/30 00:26:01] d2.utils.events INFO:  eta: 1 day, 1:30:32  iter: 28919  total_loss: 20.25  loss_mask: 1.999  loss_mask_0: 2.082  loss_mask_1: 1.993  loss_mask_2: 2.03  loss_mask_3: 2.035  loss_mask_4: 2.036  loss_mask_5: 2.001  loss_mask_6: 1.999  loss_mask_7: 2.029  loss_mask_8: 2.036  time: 2.9925  data_time: 0.0568  lr: 5.5323e-05  max_mem: 27646M
[01/30 00:27:01] d2.utils.events INFO:  eta: 1 day, 1:29:47  iter: 28939  total_loss: 22.3  loss_mask: 2.231  loss_mask_0: 2.283  loss_mask_1: 2.209  loss_mask_2: 2.263  loss_mask_3: 2.242  loss_mask_4: 2.226  loss_mask_5: 2.204  loss_mask_6: 2.207  loss_mask_7: 2.221  loss_mask_8: 2.218  time: 2.9925  data_time: 0.0731  lr: 5.5291e-05  max_mem: 27646M
[01/30 00:28:00] d2.utils.events INFO:  eta: 1 day, 1:29:04  iter: 28959  total_loss: 21.21  loss_mask: 2.122  loss_mask_0: 2.138  loss_mask_1: 2.107  loss_mask_2: 2.114  loss_mask_3: 2.125  loss_mask_4: 2.123  loss_mask_5: 2.115  loss_mask_6: 2.124  loss_mask_7: 2.121  loss_mask_8: 2.117  time: 2.9925  data_time: 0.0641  lr: 5.5259e-05  max_mem: 27646M
[01/30 00:29:00] d2.utils.events INFO:  eta: 1 day, 1:28:05  iter: 28979  total_loss: 23.61  loss_mask: 2.349  loss_mask_0: 2.382  loss_mask_1: 2.336  loss_mask_2: 2.356  loss_mask_3: 2.373  loss_mask_4: 2.375  loss_mask_5: 2.348  loss_mask_6: 2.345  loss_mask_7: 2.372  loss_mask_8: 2.356  time: 2.9925  data_time: 0.0695  lr: 5.5227e-05  max_mem: 27646M
[01/30 00:29:59] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 00:30:00] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 00:30:00] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 00:44:16] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.642553367994006, 'error_1pix': 0.40337453332577194, 'error_3pix': 0.17333543531061796, 'mIoU': 6.41538180427358, 'fwIoU': 16.673718135657168, 'IoU-0': 0.00018749215873883998, 'IoU-1': 51.068788360419106, 'IoU-2': 2.742985424982734, 'IoU-3': 4.85214645660808, 'IoU-4': 4.670416480019121, 'IoU-5': 4.314176245210728, 'IoU-6': 3.6692407679530676, 'IoU-7': 2.8205657448639334, 'IoU-8': 7.795511378124119, 'IoU-9': 16.131274270954183, 'IoU-10': 19.025943319053244, 'IoU-11': 25.580209352995926, 'IoU-12': 23.69243576726638, 'IoU-13': 22.25787151065113, 'IoU-14': 22.53497039949637, 'IoU-15': 21.827022973257073, 'IoU-16': 22.70175160717133, 'IoU-17': 21.625783378561376, 'IoU-18': 20.545177837706337, 'IoU-19': 20.089073448227072, 'IoU-20': 19.79595926544212, 'IoU-21': 20.39084811263111, 'IoU-22': 21.360534255250705, 'IoU-23': 19.531213609830704, 'IoU-24': 19.41864339074648, 'IoU-25': 18.86565382511097, 'IoU-26': 17.558459374763334, 'IoU-27': 18.245515317062136, 'IoU-28': 16.956975842423187, 'IoU-29': 17.212940955222006, 'IoU-30': 16.308596927160536, 'IoU-31': 17.022871508342018, 'IoU-32': 15.93986336883327, 'IoU-33': 15.458596455860699, 'IoU-34': 15.217027725054052, 'IoU-35': 15.204097784373502, 'IoU-36': 14.829055266764355, 'IoU-37': 13.91626838197793, 'IoU-38': 13.355417039571286, 'IoU-39': 12.1863251434848, 'IoU-40': 11.48220172645957, 'IoU-41': 10.677971459250093, 'IoU-42': 10.096242603225821, 'IoU-43': 10.08542905847046, 'IoU-44': 9.585148150600755, 'IoU-45': 9.488578712206607, 'IoU-46': 8.968925728034618, 'IoU-47': 8.526817902102993, 'IoU-48': 7.900375993350488, 'IoU-49': 7.601170470550792, 'IoU-50': 7.758938752800565, 'IoU-51': 7.15976290443779, 'IoU-52': 6.9281017734292805, 'IoU-53': 6.61833780534172, 'IoU-54': 6.68094745712927, 'IoU-55': 6.464867429457945, 'IoU-56': 6.320320477998082, 'IoU-57': 6.399309611937129, 'IoU-58': 6.260300926760448, 'IoU-59': 6.058149805312294, 'IoU-60': 5.825386784613456, 'IoU-61': 5.701981256941548, 'IoU-62': 5.526834704860674, 'IoU-63': 5.093461065191733, 'IoU-64': 4.811671466903241, 'IoU-65': 4.76617172485847, 'IoU-66': 4.522438559269824, 'IoU-67': 4.634403559062499, 'IoU-68': 4.8044889264772666, 'IoU-69': 4.619315033166688, 'IoU-70': 4.573687106631718, 'IoU-71': 4.707095689857029, 'IoU-72': 4.607610283352141, 'IoU-73': 4.551029229193185, 'IoU-74': 4.4174907964326815, 'IoU-75': 4.24645406101368, 'IoU-76': 4.476817553204639, 'IoU-77': 4.500702642397657, 'IoU-78': 4.594361433469516, 'IoU-79': 4.526763446132413, 'IoU-80': 4.57708734626347, 'IoU-81': 4.59014410326421, 'IoU-82': 4.623629234485636, 'IoU-83': 4.972679620191691, 'IoU-84': 4.9113871726941465, 'IoU-85': 4.77790492399499, 'IoU-86': 4.64172053772798, 'IoU-87': 4.482512497638812, 'IoU-88': 4.374544376380472, 'IoU-89': 4.455687179599622, 'IoU-90': 4.42996842240995, 'IoU-91': 4.427964111630654, 'IoU-92': 4.235653952413565, 'IoU-93': 4.417301209591088, 'IoU-94': 4.51336837998234, 'IoU-95': 4.577515177388781, 'IoU-96': 4.392040799499586, 'IoU-97': 4.300143005631652, 'IoU-98': 4.283257536747052, 'IoU-99': 3.9874751326986932, 'IoU-100': 3.935588768724315, 'IoU-101': 4.082655866239928, 'IoU-102': 4.009619488484614, 'IoU-103': 4.017343543496453, 'IoU-104': 3.8465564348592793, 'IoU-105': 3.8066910650741645, 'IoU-106': 3.95908247262011, 'IoU-107': 4.0333133290778385, 'IoU-108': 4.145694466914435, 'IoU-109': 4.264677155546956, 'IoU-110': 4.334509963431214, 'IoU-111': 4.223777533157064, 'IoU-112': 4.22120557830452, 'IoU-113': 3.958971813355203, 'IoU-114': 3.7426108805176037, 'IoU-115': 3.5114013551538896, 'IoU-116': 3.475129631634482, 'IoU-117': 3.654253711263839, 'IoU-118': 3.4149069920619723, 'IoU-119': 3.458994566486028, 'IoU-120': 3.3959478434939023, 'IoU-121': 3.4698320600814325, 'IoU-122': 3.466231826444339, 'IoU-123': 3.3996451257132234, 'IoU-124': 3.402924557024355, 'IoU-125': 3.0852123099507125, 'IoU-126': 3.2239283026645498, 'IoU-127': 2.8923358908041346, 'IoU-128': 2.8701518748346984, 'IoU-129': 2.9071647192224126, 'IoU-130': 3.089459763515868, 'IoU-131': 3.0058713359636826, 'IoU-132': 2.8211922603813435, 'IoU-133': 2.744335795806502, 'IoU-134': 2.755507893728, 'IoU-135': 2.733535343789174, 'IoU-136': 2.9362603141741905, 'IoU-137': 2.806682625399438, 'IoU-138': 2.742668936453792, 'IoU-139': 2.500037912843788, 'IoU-140': 2.4123580943206084, 'IoU-141': 2.384278364053843, 'IoU-142': 2.448760214105898, 'IoU-143': 2.2895946932442612, 'IoU-144': 2.5471120542235037, 'IoU-145': 2.635361923803198, 'IoU-146': 2.5858583881087904, 'IoU-147': 2.7648688925143032, 'IoU-148': 2.7061018077668977, 'IoU-149': 2.746102972648322, 'IoU-150': 2.5085649983143354, 'IoU-151': 2.796994264409168, 'IoU-152': 2.6451073056115133, 'IoU-153': 2.553008131927632, 'IoU-154': 2.2709609832750663, 'IoU-155': 2.1154563871230265, 'IoU-156': 2.287928026803672, 'IoU-157': 2.1246519128371713, 'IoU-158': 2.2344159245678363, 'IoU-159': 2.1512562710269725, 'IoU-160': 1.9299621393031097, 'IoU-161': 2.1155998460590713, 'IoU-162': 1.8539741979875672, 'IoU-163': 1.8816899277582357, 'IoU-164': 1.8520643707129008, 'IoU-165': 2.2081940216577673, 'IoU-166': 2.0914911554247637, 'IoU-167': 2.0047789984106124, 'IoU-168': 2.003553552896047, 'IoU-169': 2.3547578940026423, 'IoU-170': 2.26108389181107, 'IoU-171': 1.9787628518456093, 'IoU-172': 2.0002438654550514, 'IoU-173': 2.021811174697044, 'IoU-174': 2.041060098298323, 'IoU-175': 1.7565370744906612, 'IoU-176': 1.7769358461087785, 'IoU-177': 1.9509930727466187, 'IoU-178': 1.4327139334979766, 'IoU-179': 2.522136874393061, 'IoU-180': 2.5325001199134336, 'IoU-181': 1.4758404060391221, 'IoU-182': 1.732394096956721, 'IoU-183': 0.7855211885943266, 'IoU-184': 0.4504358603951139, 'IoU-185': 0.3365542882593288, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 11.731308304075831, 'pACC': 25.238902518518657, 'ACC-0': 0.000911146610933961, 'ACC-1': 51.860539036149824, 'ACC-2': 4.901017815092241, 'ACC-3': 18.31619106599407, 'ACC-4': 17.084709488733964, 'ACC-5': 16.88174571485837, 'ACC-6': 15.5933477856708, 'ACC-7': 14.748897907391404, 'ACC-8': 24.18798379243299, 'ACC-9': 34.15574960912332, 'ACC-10': 37.299948505731074, 'ACC-11': 43.279483294594606, 'ACC-12': 38.47150318762916, 'ACC-13': 34.950871842691875, 'ACC-14': 35.31258650844065, 'ACC-15': 34.262190546554876, 'ACC-16': 35.01078580973708, 'ACC-17': 36.41608633383573, 'ACC-18': 34.40923562149974, 'ACC-19': 33.68808138112757, 'ACC-20': 33.43091119280627, 'ACC-21': 34.45240189551716, 'ACC-22': 34.929340373802944, 'ACC-23': 33.34385380905431, 'ACC-24': 33.827271135075584, 'ACC-25': 33.2923147962712, 'ACC-26': 31.529465786510748, 'ACC-27': 31.924848318755185, 'ACC-28': 30.198379029116072, 'ACC-29': 29.686620001717284, 'ACC-30': 28.711102241007403, 'ACC-31': 29.465260181285846, 'ACC-32': 27.62436699861372, 'ACC-33': 27.292675056101128, 'ACC-34': 27.534658197158645, 'ACC-35': 27.160375091365808, 'ACC-36': 26.442593206817865, 'ACC-37': 25.407819949431776, 'ACC-38': 24.355276841541734, 'ACC-39': 22.197760685178473, 'ACC-40': 20.555099224034485, 'ACC-41': 19.70840574306171, 'ACC-42': 18.745209690797505, 'ACC-43': 18.664470197025118, 'ACC-44': 17.223307772831966, 'ACC-45': 17.184618156280713, 'ACC-46': 16.732327711259853, 'ACC-47': 15.886881172270254, 'ACC-48': 14.760305673927165, 'ACC-49': 14.264256990295138, 'ACC-50': 14.461383355305871, 'ACC-51': 13.43068327668086, 'ACC-52': 12.939976001689079, 'ACC-53': 12.332148523925703, 'ACC-54': 12.240335355306154, 'ACC-55': 11.710839612011368, 'ACC-56': 11.621633099325516, 'ACC-57': 11.651128494145114, 'ACC-58': 11.546908278052026, 'ACC-59': 11.373600625767711, 'ACC-60': 11.078586275566636, 'ACC-61': 10.89882814169409, 'ACC-62': 10.632741287732479, 'ACC-63': 9.831939949857379, 'ACC-64': 9.271176249694635, 'ACC-65': 9.190157511275359, 'ACC-66': 8.77812873181084, 'ACC-67': 9.093554177618207, 'ACC-68': 9.39053519521145, 'ACC-69': 8.805344411775017, 'ACC-70': 8.665166026220435, 'ACC-71': 9.123080731261304, 'ACC-72': 8.989466763241383, 'ACC-73': 8.817476947664359, 'ACC-74': 8.47185932204516, 'ACC-75': 8.180704327324708, 'ACC-76': 8.476996338579125, 'ACC-77': 8.630563003149222, 'ACC-78': 8.891386056928777, 'ACC-79': 8.786971634303034, 'ACC-80': 8.766269489300893, 'ACC-81': 8.64402554190115, 'ACC-82': 8.621297217432357, 'ACC-83': 9.141922959163743, 'ACC-84': 9.066573906605333, 'ACC-85': 8.8497264003207, 'ACC-86': 8.632000602399994, 'ACC-87': 8.352798650078448, 'ACC-88': 8.08504198985326, 'ACC-89': 8.175765478606472, 'ACC-90': 8.042302112838982, 'ACC-91': 8.076146288878105, 'ACC-92': 7.75676977372871, 'ACC-93': 8.097115592705915, 'ACC-94': 8.28779458023457, 'ACC-95': 8.418023162474148, 'ACC-96': 8.107887116271813, 'ACC-97': 7.779958594911543, 'ACC-98': 7.745560323794108, 'ACC-99': 7.277112820279434, 'ACC-100': 7.139538108595326, 'ACC-101': 7.4611053508514, 'ACC-102': 7.3513366560942455, 'ACC-103': 7.40474166430528, 'ACC-104': 7.148840412188584, 'ACC-105': 7.0640377305773825, 'ACC-106': 7.3274757790471154, 'ACC-107': 7.4666081398030535, 'ACC-108': 7.627071100232229, 'ACC-109': 7.897397952891849, 'ACC-110': 8.098624309693363, 'ACC-111': 7.946112688000587, 'ACC-112': 8.091247541772354, 'ACC-113': 7.633305071080433, 'ACC-114': 7.291370945376398, 'ACC-115': 6.76916542630764, 'ACC-116': 6.762082783752639, 'ACC-117': 7.072658553579565, 'ACC-118': 6.6110844494492795, 'ACC-119': 6.609759999519631, 'ACC-120': 6.524640079837794, 'ACC-121': 6.726616270603512, 'ACC-122': 6.65959032711559, 'ACC-123': 6.505134515827887, 'ACC-124': 6.597460658749848, 'ACC-125': 5.929975428639177, 'ACC-126': 6.152549203544659, 'ACC-127': 5.452520348755712, 'ACC-128': 5.439930429776641, 'ACC-129': 5.563521651849728, 'ACC-130': 6.003913394540853, 'ACC-131': 5.8503515288297505, 'ACC-132': 5.433744508449699, 'ACC-133': 5.2482530091789314, 'ACC-134': 5.232434295562258, 'ACC-135': 5.087580525625677, 'ACC-136': 5.397773597651883, 'ACC-137': 5.13029521064068, 'ACC-138': 5.092630784069853, 'ACC-139': 4.730383938387526, 'ACC-140': 4.546230082807813, 'ACC-141': 4.507362755180186, 'ACC-142': 4.643333411931766, 'ACC-143': 4.382519524142003, 'ACC-144': 4.866335740072202, 'ACC-145': 4.9259598828238556, 'ACC-146': 4.828219597450366, 'ACC-147': 5.090609601080054, 'ACC-148': 4.867634743943022, 'ACC-149': 5.042547732460913, 'ACC-150': 4.591368227731864, 'ACC-151': 5.128196929924127, 'ACC-152': 4.823003068312091, 'ACC-153': 4.8918769123655625, 'ACC-154': 4.378002200390528, 'ACC-155': 4.177852059468081, 'ACC-156': 4.6999812548882725, 'ACC-157': 4.4902025633801665, 'ACC-158': 4.8160259459093275, 'ACC-159': 4.577004539435817, 'ACC-160': 4.004971044654572, 'ACC-161': 4.368998840138509, 'ACC-162': 3.82399933353367, 'ACC-163': 3.802545833097665, 'ACC-164': 3.9149033323926066, 'ACC-165': 4.638261648460901, 'ACC-166': 4.2440674551544095, 'ACC-167': 4.178457337314802, 'ACC-168': 4.290386103101484, 'ACC-169': 5.09464057287947, 'ACC-170': 4.809084713999744, 'ACC-171': 4.312933842019511, 'ACC-172': 4.739600696373671, 'ACC-173': 4.579816596614149, 'ACC-174': 4.5546813400660975, 'ACC-175': 3.649799677931663, 'ACC-176': 4.126095600185744, 'ACC-177': 5.336345131387844, 'ACC-178': 4.014981331283283, 'ACC-179': 7.308660711206154, 'ACC-180': 7.487342950997325, 'ACC-181': 3.1517287608869182, 'ACC-182': 5.1529416781768775, 'ACC-183': 1.2553237073014543, 'ACC-184': 0.4919614072077299, 'ACC-185': 0.4014060760592917, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 00:44:16] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 00:44:16] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 00:44:16] d2.evaluation.testing INFO: copypaste: 2.6426,0.4034,0.1733,6.4154,16.6737,11.7313,25.2389
[01/30 00:44:16] d2.utils.events INFO:  eta: 1 day, 1:26:48  iter: 28999  total_loss: 20.22  loss_mask: 2.006  loss_mask_0: 2.079  loss_mask_1: 2.003  loss_mask_2: 2.028  loss_mask_3: 2.038  loss_mask_4: 2.027  loss_mask_5: 2.009  loss_mask_6: 2.007  loss_mask_7: 2.033  loss_mask_8: 2.027  time: 2.9925  data_time: 0.0517  lr: 5.5195e-05  max_mem: 27646M
[01/30 00:45:15] d2.utils.events INFO:  eta: 1 day, 1:25:28  iter: 29019  total_loss: 20.32  loss_mask: 2.02  loss_mask_0: 2.08  loss_mask_1: 2.009  loss_mask_2: 2.039  loss_mask_3: 2.034  loss_mask_4: 2.031  loss_mask_5: 2.031  loss_mask_6: 2.021  loss_mask_7: 2.038  loss_mask_8: 2.041  time: 2.9925  data_time: 0.0563  lr: 5.5163e-05  max_mem: 27646M
[01/30 00:46:15] d2.utils.events INFO:  eta: 1 day, 1:24:32  iter: 29039  total_loss: 21.44  loss_mask: 2.15  loss_mask_0: 2.169  loss_mask_1: 2.129  loss_mask_2: 2.142  loss_mask_3: 2.14  loss_mask_4: 2.149  loss_mask_5: 2.143  loss_mask_6: 2.141  loss_mask_7: 2.136  loss_mask_8: 2.139  time: 2.9925  data_time: 0.0579  lr: 5.5131e-05  max_mem: 27646M
[01/30 00:47:15] d2.utils.events INFO:  eta: 1 day, 1:23:30  iter: 29059  total_loss: 20.36  loss_mask: 2.031  loss_mask_0: 2.081  loss_mask_1: 2.014  loss_mask_2: 2.032  loss_mask_3: 2.041  loss_mask_4: 2.036  loss_mask_5: 2.02  loss_mask_6: 2.028  loss_mask_7: 2.041  loss_mask_8: 2.04  time: 2.9925  data_time: 0.0550  lr: 5.5099e-05  max_mem: 27646M
[01/30 00:48:15] d2.utils.events INFO:  eta: 1 day, 1:22:53  iter: 29079  total_loss: 21.52  loss_mask: 2.133  loss_mask_0: 2.184  loss_mask_1: 2.151  loss_mask_2: 2.153  loss_mask_3: 2.176  loss_mask_4: 2.146  loss_mask_5: 2.137  loss_mask_6: 2.14  loss_mask_7: 2.15  loss_mask_8: 2.152  time: 2.9925  data_time: 0.0521  lr: 5.5067e-05  max_mem: 27646M
[01/30 00:49:15] d2.utils.events INFO:  eta: 1 day, 1:22:29  iter: 29099  total_loss: 22.68  loss_mask: 2.256  loss_mask_0: 2.29  loss_mask_1: 2.263  loss_mask_2: 2.281  loss_mask_3: 2.255  loss_mask_4: 2.29  loss_mask_5: 2.264  loss_mask_6: 2.249  loss_mask_7: 2.256  loss_mask_8: 2.278  time: 2.9925  data_time: 0.0789  lr: 5.5035e-05  max_mem: 27646M
[01/30 00:50:15] d2.utils.events INFO:  eta: 1 day, 1:22:08  iter: 29119  total_loss: 22.84  loss_mask: 2.288  loss_mask_0: 2.374  loss_mask_1: 2.254  loss_mask_2: 2.29  loss_mask_3: 2.276  loss_mask_4: 2.289  loss_mask_5: 2.28  loss_mask_6: 2.275  loss_mask_7: 2.288  loss_mask_8: 2.286  time: 2.9925  data_time: 0.0663  lr: 5.5003e-05  max_mem: 27646M
[01/30 00:51:15] d2.utils.events INFO:  eta: 1 day, 1:20:47  iter: 29139  total_loss: 23.28  loss_mask: 2.304  loss_mask_0: 2.411  loss_mask_1: 2.273  loss_mask_2: 2.328  loss_mask_3: 2.344  loss_mask_4: 2.333  loss_mask_5: 2.287  loss_mask_6: 2.303  loss_mask_7: 2.339  loss_mask_8: 2.338  time: 2.9925  data_time: 0.0615  lr: 5.4971e-05  max_mem: 27646M
[01/30 00:52:14] d2.utils.events INFO:  eta: 1 day, 1:19:53  iter: 29159  total_loss: 23.85  loss_mask: 2.378  loss_mask_0: 2.422  loss_mask_1: 2.339  loss_mask_2: 2.365  loss_mask_3: 2.386  loss_mask_4: 2.379  loss_mask_5: 2.376  loss_mask_6: 2.375  loss_mask_7: 2.383  loss_mask_8: 2.389  time: 2.9925  data_time: 0.0599  lr: 5.4939e-05  max_mem: 27646M
[01/30 00:53:14] d2.utils.events INFO:  eta: 1 day, 1:20:40  iter: 29179  total_loss: 21.33  loss_mask: 2.121  loss_mask_0: 2.159  loss_mask_1: 2.121  loss_mask_2: 2.128  loss_mask_3: 2.141  loss_mask_4: 2.142  loss_mask_5: 2.121  loss_mask_6: 2.119  loss_mask_7: 2.142  loss_mask_8: 2.136  time: 2.9925  data_time: 0.0708  lr: 5.4907e-05  max_mem: 27646M
[01/30 00:54:14] d2.utils.events INFO:  eta: 1 day, 1:20:09  iter: 29199  total_loss: 20.9  loss_mask: 2.09  loss_mask_0: 2.105  loss_mask_1: 2.06  loss_mask_2: 2.107  loss_mask_3: 2.104  loss_mask_4: 2.082  loss_mask_5: 2.083  loss_mask_6: 2.086  loss_mask_7: 2.086  loss_mask_8: 2.093  time: 2.9925  data_time: 0.0630  lr: 5.4875e-05  max_mem: 27646M
[01/30 00:55:14] d2.utils.events INFO:  eta: 1 day, 1:20:07  iter: 29219  total_loss: 22.76  loss_mask: 2.283  loss_mask_0: 2.286  loss_mask_1: 2.259  loss_mask_2: 2.273  loss_mask_3: 2.286  loss_mask_4: 2.274  loss_mask_5: 2.267  loss_mask_6: 2.295  loss_mask_7: 2.267  loss_mask_8: 2.267  time: 2.9925  data_time: 0.0564  lr: 5.4843e-05  max_mem: 27646M
[01/30 00:56:12] d2.utils.events INFO:  eta: 1 day, 1:18:50  iter: 29239  total_loss: 21  loss_mask: 2.1  loss_mask_0: 2.127  loss_mask_1: 2.081  loss_mask_2: 2.09  loss_mask_3: 2.109  loss_mask_4: 2.126  loss_mask_5: 2.097  loss_mask_6: 2.093  loss_mask_7: 2.109  loss_mask_8: 2.105  time: 2.9924  data_time: 0.0611  lr: 5.4811e-05  max_mem: 27646M
[01/30 00:57:11] d2.utils.events INFO:  eta: 1 day, 1:17:21  iter: 29259  total_loss: 22.12  loss_mask: 2.206  loss_mask_0: 2.234  loss_mask_1: 2.198  loss_mask_2: 2.209  loss_mask_3: 2.212  loss_mask_4: 2.215  loss_mask_5: 2.205  loss_mask_6: 2.203  loss_mask_7: 2.22  loss_mask_8: 2.214  time: 2.9924  data_time: 0.0532  lr: 5.4778e-05  max_mem: 27646M
[01/30 00:58:10] d2.utils.events INFO:  eta: 1 day, 1:17:15  iter: 29279  total_loss: 20.88  loss_mask: 2.076  loss_mask_0: 2.149  loss_mask_1: 2.079  loss_mask_2: 2.077  loss_mask_3: 2.087  loss_mask_4: 2.091  loss_mask_5: 2.069  loss_mask_6: 2.059  loss_mask_7: 2.087  loss_mask_8: 2.09  time: 2.9924  data_time: 0.0624  lr: 5.4746e-05  max_mem: 27646M
[01/30 00:59:09] d2.utils.events INFO:  eta: 1 day, 1:16:14  iter: 29299  total_loss: 25.39  loss_mask: 2.544  loss_mask_0: 2.6  loss_mask_1: 2.512  loss_mask_2: 2.526  loss_mask_3: 2.532  loss_mask_4: 2.538  loss_mask_5: 2.539  loss_mask_6: 2.531  loss_mask_7: 2.534  loss_mask_8: 2.539  time: 2.9923  data_time: 0.0619  lr: 5.4714e-05  max_mem: 27646M
[01/30 01:00:09] d2.utils.events INFO:  eta: 1 day, 1:15:16  iter: 29319  total_loss: 20.82  loss_mask: 2.1  loss_mask_0: 2.115  loss_mask_1: 2.084  loss_mask_2: 2.083  loss_mask_3: 2.086  loss_mask_4: 2.086  loss_mask_5: 2.081  loss_mask_6: 2.078  loss_mask_7: 2.078  loss_mask_8: 2.09  time: 2.9923  data_time: 0.0601  lr: 5.4682e-05  max_mem: 27646M
[01/30 01:01:08] d2.utils.events INFO:  eta: 1 day, 1:14:33  iter: 29339  total_loss: 20.66  loss_mask: 2.028  loss_mask_0: 2.164  loss_mask_1: 2.03  loss_mask_2: 2.059  loss_mask_3: 2.062  loss_mask_4: 2.072  loss_mask_5: 2.032  loss_mask_6: 2.024  loss_mask_7: 2.06  loss_mask_8: 2.063  time: 2.9923  data_time: 0.0615  lr: 5.465e-05  max_mem: 27646M
[01/30 01:02:07] d2.utils.events INFO:  eta: 1 day, 1:13:17  iter: 29359  total_loss: 21.43  loss_mask: 2.137  loss_mask_0: 2.19  loss_mask_1: 2.121  loss_mask_2: 2.141  loss_mask_3: 2.145  loss_mask_4: 2.144  loss_mask_5: 2.127  loss_mask_6: 2.139  loss_mask_7: 2.142  loss_mask_8: 2.136  time: 2.9923  data_time: 0.0565  lr: 5.4618e-05  max_mem: 27646M
[01/30 01:03:06] d2.utils.events INFO:  eta: 1 day, 1:12:18  iter: 29379  total_loss: 20.62  loss_mask: 2.065  loss_mask_0: 2.086  loss_mask_1: 2.049  loss_mask_2: 2.05  loss_mask_3: 2.049  loss_mask_4: 2.067  loss_mask_5: 2.058  loss_mask_6: 2.069  loss_mask_7: 2.068  loss_mask_8: 2.051  time: 2.9922  data_time: 0.0587  lr: 5.4586e-05  max_mem: 27646M
[01/30 01:04:06] d2.utils.events INFO:  eta: 1 day, 1:11:18  iter: 29399  total_loss: 20.01  loss_mask: 1.984  loss_mask_0: 2.065  loss_mask_1: 1.988  loss_mask_2: 1.996  loss_mask_3: 1.993  loss_mask_4: 2  loss_mask_5: 1.99  loss_mask_6: 1.983  loss_mask_7: 2.003  loss_mask_8: 2.003  time: 2.9922  data_time: 0.0642  lr: 5.4554e-05  max_mem: 27646M
[01/30 01:05:06] d2.utils.events INFO:  eta: 1 day, 1:10:19  iter: 29419  total_loss: 23.99  loss_mask: 2.399  loss_mask_0: 2.493  loss_mask_1: 2.371  loss_mask_2: 2.376  loss_mask_3: 2.385  loss_mask_4: 2.367  loss_mask_5: 2.412  loss_mask_6: 2.386  loss_mask_7: 2.368  loss_mask_8: 2.373  time: 2.9922  data_time: 0.0576  lr: 5.4522e-05  max_mem: 27646M
[01/30 01:06:05] d2.utils.events INFO:  eta: 1 day, 1:09:19  iter: 29439  total_loss: 22.25  loss_mask: 2.231  loss_mask_0: 2.24  loss_mask_1: 2.202  loss_mask_2: 2.214  loss_mask_3: 2.231  loss_mask_4: 2.229  loss_mask_5: 2.218  loss_mask_6: 2.228  loss_mask_7: 2.233  loss_mask_8: 2.223  time: 2.9922  data_time: 0.0590  lr: 5.449e-05  max_mem: 27646M
[01/30 01:07:04] d2.utils.events INFO:  eta: 1 day, 1:07:38  iter: 29459  total_loss: 19.53  loss_mask: 1.956  loss_mask_0: 2.005  loss_mask_1: 1.925  loss_mask_2: 1.947  loss_mask_3: 1.95  loss_mask_4: 1.948  loss_mask_5: 1.95  loss_mask_6: 1.952  loss_mask_7: 1.958  loss_mask_8: 1.955  time: 2.9922  data_time: 0.0531  lr: 5.4458e-05  max_mem: 27646M
[01/30 01:08:03] d2.utils.events INFO:  eta: 1 day, 1:06:38  iter: 29479  total_loss: 22.22  loss_mask: 2.204  loss_mask_0: 2.237  loss_mask_1: 2.209  loss_mask_2: 2.224  loss_mask_3: 2.22  loss_mask_4: 2.225  loss_mask_5: 2.218  loss_mask_6: 2.203  loss_mask_7: 2.221  loss_mask_8: 2.22  time: 2.9921  data_time: 0.0573  lr: 5.4426e-05  max_mem: 27646M
[01/30 01:09:02] d2.utils.events INFO:  eta: 1 day, 1:05:33  iter: 29499  total_loss: 21.06  loss_mask: 2.096  loss_mask_0: 2.139  loss_mask_1: 2.103  loss_mask_2: 2.104  loss_mask_3: 2.103  loss_mask_4: 2.119  loss_mask_5: 2.093  loss_mask_6: 2.091  loss_mask_7: 2.108  loss_mask_8: 2.114  time: 2.9921  data_time: 0.0553  lr: 5.4393e-05  max_mem: 27646M
[01/30 01:10:01] d2.utils.events INFO:  eta: 1 day, 1:04:39  iter: 29519  total_loss: 24.5  loss_mask: 2.456  loss_mask_0: 2.514  loss_mask_1: 2.467  loss_mask_2: 2.441  loss_mask_3: 2.442  loss_mask_4: 2.458  loss_mask_5: 2.455  loss_mask_6: 2.48  loss_mask_7: 2.466  loss_mask_8: 2.446  time: 2.9921  data_time: 0.0606  lr: 5.4361e-05  max_mem: 27646M
[01/30 01:11:00] d2.utils.events INFO:  eta: 1 day, 1:03:15  iter: 29539  total_loss: 21.64  loss_mask: 2.147  loss_mask_0: 2.21  loss_mask_1: 2.137  loss_mask_2: 2.166  loss_mask_3: 2.172  loss_mask_4: 2.168  loss_mask_5: 2.144  loss_mask_6: 2.14  loss_mask_7: 2.166  loss_mask_8: 2.155  time: 2.9921  data_time: 0.0589  lr: 5.4329e-05  max_mem: 27646M
[01/30 01:11:58] d2.utils.events INFO:  eta: 1 day, 1:02:08  iter: 29559  total_loss: 22.65  loss_mask: 2.242  loss_mask_0: 2.285  loss_mask_1: 2.236  loss_mask_2: 2.263  loss_mask_3: 2.268  loss_mask_4: 2.266  loss_mask_5: 2.247  loss_mask_6: 2.232  loss_mask_7: 2.269  loss_mask_8: 2.268  time: 2.9920  data_time: 0.0534  lr: 5.4297e-05  max_mem: 27646M
[01/30 01:12:57] d2.utils.events INFO:  eta: 1 day, 1:01:09  iter: 29579  total_loss: 19.61  loss_mask: 1.95  loss_mask_0: 2.01  loss_mask_1: 1.945  loss_mask_2: 1.966  loss_mask_3: 1.964  loss_mask_4: 1.971  loss_mask_5: 1.948  loss_mask_6: 1.948  loss_mask_7: 1.969  loss_mask_8: 1.971  time: 2.9920  data_time: 0.0653  lr: 5.4265e-05  max_mem: 27646M
[01/30 01:13:56] d2.utils.events INFO:  eta: 1 day, 1:00:15  iter: 29599  total_loss: 21.83  loss_mask: 2.171  loss_mask_0: 2.243  loss_mask_1: 2.156  loss_mask_2: 2.183  loss_mask_3: 2.184  loss_mask_4: 2.182  loss_mask_5: 2.172  loss_mask_6: 2.167  loss_mask_7: 2.18  loss_mask_8: 2.197  time: 2.9919  data_time: 0.0531  lr: 5.4233e-05  max_mem: 27646M
[01/30 01:14:55] d2.utils.events INFO:  eta: 1 day, 0:59:25  iter: 29619  total_loss: 21.89  loss_mask: 2.168  loss_mask_0: 2.25  loss_mask_1: 2.155  loss_mask_2: 2.196  loss_mask_3: 2.212  loss_mask_4: 2.207  loss_mask_5: 2.166  loss_mask_6: 2.16  loss_mask_7: 2.209  loss_mask_8: 2.187  time: 2.9919  data_time: 0.0598  lr: 5.4201e-05  max_mem: 27646M
[01/30 01:15:55] d2.utils.events INFO:  eta: 1 day, 0:58:26  iter: 29639  total_loss: 21.99  loss_mask: 2.181  loss_mask_0: 2.259  loss_mask_1: 2.193  loss_mask_2: 2.218  loss_mask_3: 2.188  loss_mask_4: 2.191  loss_mask_5: 2.199  loss_mask_6: 2.183  loss_mask_7: 2.171  loss_mask_8: 2.206  time: 2.9919  data_time: 0.0694  lr: 5.4169e-05  max_mem: 27646M
[01/30 01:16:56] d2.utils.events INFO:  eta: 1 day, 0:57:44  iter: 29659  total_loss: 22.58  loss_mask: 2.237  loss_mask_0: 2.273  loss_mask_1: 2.247  loss_mask_2: 2.255  loss_mask_3: 2.262  loss_mask_4: 2.275  loss_mask_5: 2.241  loss_mask_6: 2.238  loss_mask_7: 2.278  loss_mask_8: 2.261  time: 2.9919  data_time: 0.0713  lr: 5.4137e-05  max_mem: 27646M
[01/30 01:17:55] d2.utils.events INFO:  eta: 1 day, 0:56:40  iter: 29679  total_loss: 24.37  loss_mask: 2.427  loss_mask_0: 2.453  loss_mask_1: 2.41  loss_mask_2: 2.457  loss_mask_3: 2.434  loss_mask_4: 2.444  loss_mask_5: 2.433  loss_mask_6: 2.422  loss_mask_7: 2.437  loss_mask_8: 2.451  time: 2.9919  data_time: 0.0541  lr: 5.4104e-05  max_mem: 27646M
[01/30 01:18:54] d2.utils.events INFO:  eta: 1 day, 0:55:21  iter: 29699  total_loss: 20.63  loss_mask: 2.047  loss_mask_0: 2.113  loss_mask_1: 2.049  loss_mask_2: 2.058  loss_mask_3: 2.065  loss_mask_4: 2.065  loss_mask_5: 2.044  loss_mask_6: 2.045  loss_mask_7: 2.064  loss_mask_8: 2.061  time: 2.9919  data_time: 0.0530  lr: 5.4072e-05  max_mem: 27646M
[01/30 01:19:53] d2.utils.events INFO:  eta: 1 day, 0:54:22  iter: 29719  total_loss: 19.87  loss_mask: 1.98  loss_mask_0: 2.017  loss_mask_1: 1.964  loss_mask_2: 1.977  loss_mask_3: 1.977  loss_mask_4: 1.988  loss_mask_5: 1.971  loss_mask_6: 1.982  loss_mask_7: 1.986  loss_mask_8: 1.974  time: 2.9919  data_time: 0.0517  lr: 5.404e-05  max_mem: 27646M
[01/30 01:20:52] d2.utils.events INFO:  eta: 1 day, 0:53:21  iter: 29739  total_loss: 21.24  loss_mask: 2.125  loss_mask_0: 2.146  loss_mask_1: 2.106  loss_mask_2: 2.123  loss_mask_3: 2.127  loss_mask_4: 2.133  loss_mask_5: 2.116  loss_mask_6: 2.135  loss_mask_7: 2.132  loss_mask_8: 2.124  time: 2.9918  data_time: 0.0544  lr: 5.4008e-05  max_mem: 27646M
[01/30 01:21:51] d2.utils.events INFO:  eta: 1 day, 0:52:15  iter: 29759  total_loss: 21.5  loss_mask: 2.128  loss_mask_0: 2.175  loss_mask_1: 2.131  loss_mask_2: 2.168  loss_mask_3: 2.149  loss_mask_4: 2.157  loss_mask_5: 2.135  loss_mask_6: 2.14  loss_mask_7: 2.161  loss_mask_8: 2.157  time: 2.9918  data_time: 0.0578  lr: 5.3976e-05  max_mem: 27646M
[01/30 01:22:51] d2.utils.events INFO:  eta: 1 day, 0:51:56  iter: 29779  total_loss: 22.2  loss_mask: 2.206  loss_mask_0: 2.285  loss_mask_1: 2.202  loss_mask_2: 2.225  loss_mask_3: 2.225  loss_mask_4: 2.221  loss_mask_5: 2.206  loss_mask_6: 2.203  loss_mask_7: 2.223  loss_mask_8: 2.224  time: 2.9918  data_time: 0.0739  lr: 5.3944e-05  max_mem: 27646M
[01/30 01:23:50] d2.utils.events INFO:  eta: 1 day, 0:50:49  iter: 29799  total_loss: 22.83  loss_mask: 2.299  loss_mask_0: 2.298  loss_mask_1: 2.28  loss_mask_2: 2.28  loss_mask_3: 2.271  loss_mask_4: 2.274  loss_mask_5: 2.283  loss_mask_6: 2.288  loss_mask_7: 2.296  loss_mask_8: 2.271  time: 2.9918  data_time: 0.0533  lr: 5.3912e-05  max_mem: 27646M
[01/30 01:24:49] d2.utils.events INFO:  eta: 1 day, 0:49:26  iter: 29819  total_loss: 19.81  loss_mask: 1.965  loss_mask_0: 2.026  loss_mask_1: 1.956  loss_mask_2: 1.982  loss_mask_3: 1.988  loss_mask_4: 1.989  loss_mask_5: 1.968  loss_mask_6: 1.96  loss_mask_7: 1.985  loss_mask_8: 1.996  time: 2.9917  data_time: 0.0563  lr: 5.388e-05  max_mem: 27646M
[01/30 01:25:48] d2.utils.events INFO:  eta: 1 day, 0:48:18  iter: 29839  total_loss: 19.63  loss_mask: 1.965  loss_mask_0: 1.989  loss_mask_1: 1.948  loss_mask_2: 1.953  loss_mask_3: 1.965  loss_mask_4: 1.975  loss_mask_5: 1.969  loss_mask_6: 1.968  loss_mask_7: 1.958  loss_mask_8: 1.965  time: 2.9917  data_time: 0.0633  lr: 5.3847e-05  max_mem: 27646M
[01/30 01:26:47] d2.utils.events INFO:  eta: 1 day, 0:46:44  iter: 29859  total_loss: 21.8  loss_mask: 2.169  loss_mask_0: 2.261  loss_mask_1: 2.158  loss_mask_2: 2.188  loss_mask_3: 2.176  loss_mask_4: 2.178  loss_mask_5: 2.17  loss_mask_6: 2.168  loss_mask_7: 2.179  loss_mask_8: 2.196  time: 2.9917  data_time: 0.0599  lr: 5.3815e-05  max_mem: 27646M
[01/30 01:27:46] d2.utils.events INFO:  eta: 1 day, 0:44:43  iter: 29879  total_loss: 20.44  loss_mask: 2.06  loss_mask_0: 2.064  loss_mask_1: 2.035  loss_mask_2: 2.047  loss_mask_3: 2.085  loss_mask_4: 2.064  loss_mask_5: 2.036  loss_mask_6: 2.034  loss_mask_7: 2.069  loss_mask_8: 2.048  time: 2.9917  data_time: 0.0537  lr: 5.3783e-05  max_mem: 27646M
[01/30 01:28:44] d2.utils.events INFO:  eta: 1 day, 0:43:22  iter: 29899  total_loss: 22.54  loss_mask: 2.235  loss_mask_0: 2.282  loss_mask_1: 2.264  loss_mask_2: 2.274  loss_mask_3: 2.239  loss_mask_4: 2.25  loss_mask_5: 2.254  loss_mask_6: 2.226  loss_mask_7: 2.238  loss_mask_8: 2.275  time: 2.9916  data_time: 0.0503  lr: 5.3751e-05  max_mem: 27646M
[01/30 01:29:44] d2.utils.events INFO:  eta: 1 day, 0:41:36  iter: 29919  total_loss: 20.58  loss_mask: 2.052  loss_mask_0: 2.079  loss_mask_1: 2.043  loss_mask_2: 2.058  loss_mask_3: 2.069  loss_mask_4: 2.073  loss_mask_5: 2.037  loss_mask_6: 2.045  loss_mask_7: 2.073  loss_mask_8: 2.057  time: 2.9916  data_time: 0.0538  lr: 5.3719e-05  max_mem: 27646M
[01/30 01:30:43] d2.utils.events INFO:  eta: 1 day, 0:40:27  iter: 29939  total_loss: 22.47  loss_mask: 2.227  loss_mask_0: 2.286  loss_mask_1: 2.217  loss_mask_2: 2.246  loss_mask_3: 2.248  loss_mask_4: 2.255  loss_mask_5: 2.232  loss_mask_6: 2.224  loss_mask_7: 2.259  loss_mask_8: 2.254  time: 2.9916  data_time: 0.0588  lr: 5.3687e-05  max_mem: 27646M
[01/30 01:31:42] d2.utils.events INFO:  eta: 1 day, 0:39:08  iter: 29959  total_loss: 23.21  loss_mask: 2.314  loss_mask_0: 2.333  loss_mask_1: 2.304  loss_mask_2: 2.318  loss_mask_3: 2.31  loss_mask_4: 2.331  loss_mask_5: 2.311  loss_mask_6: 2.305  loss_mask_7: 2.325  loss_mask_8: 2.326  time: 2.9915  data_time: 0.0590  lr: 5.3655e-05  max_mem: 27646M
[01/30 01:32:41] d2.utils.events INFO:  eta: 1 day, 0:38:05  iter: 29979  total_loss: 22.95  loss_mask: 2.291  loss_mask_0: 2.316  loss_mask_1: 2.278  loss_mask_2: 2.302  loss_mask_3: 2.293  loss_mask_4: 2.311  loss_mask_5: 2.286  loss_mask_6: 2.288  loss_mask_7: 2.297  loss_mask_8: 2.303  time: 2.9915  data_time: 0.0558  lr: 5.3622e-05  max_mem: 27646M
[01/30 01:33:40] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/model_0029999.pth
[01/30 01:33:41] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 01:33:42] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 01:33:42] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 01:48:03] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.4422962507571375, 'error_1pix': 0.3679007813427267, 'error_3pix': 0.1543402552790062, 'mIoU': 7.172865766658811, 'fwIoU': 17.54084265190609, 'IoU-0': 0.0008859110840342251, 'IoU-1': 43.383254685143015, 'IoU-2': 2.2609033539371524, 'IoU-3': 3.5440076509522105, 'IoU-4': 3.6444405170768754, 'IoU-5': 3.6270607850241126, 'IoU-6': 3.5969753756184537, 'IoU-7': 3.268275231197762, 'IoU-8': 7.573062920951208, 'IoU-9': 18.292541527486588, 'IoU-10': 21.855575191908592, 'IoU-11': 29.60586619543493, 'IoU-12': 29.75643409983304, 'IoU-13': 27.4929697844361, 'IoU-14': 27.213790351612577, 'IoU-15': 25.54332536400174, 'IoU-16': 23.15901315187467, 'IoU-17': 19.923029137826738, 'IoU-18': 19.643672993151153, 'IoU-19': 20.227026479011847, 'IoU-20': 18.50387495540623, 'IoU-21': 17.929286179658536, 'IoU-22': 17.45316609275765, 'IoU-23': 16.141632656572746, 'IoU-24': 15.318432890621652, 'IoU-25': 15.801924675238437, 'IoU-26': 15.61078851819589, 'IoU-27': 17.14966768935029, 'IoU-28': 16.63065229798038, 'IoU-29': 16.802871890801587, 'IoU-30': 16.310754514827913, 'IoU-31': 17.218101792779116, 'IoU-32': 17.17840771081004, 'IoU-33': 16.36327118845541, 'IoU-34': 15.748092273153375, 'IoU-35': 16.70541182269456, 'IoU-36': 16.794091677764104, 'IoU-37': 16.64588714142554, 'IoU-38': 17.12017376205563, 'IoU-39': 16.569560080322248, 'IoU-40': 17.136464055816287, 'IoU-41': 15.821594975284011, 'IoU-42': 15.871013253947893, 'IoU-43': 15.661316943792386, 'IoU-44': 15.66408160185984, 'IoU-45': 14.990589351760914, 'IoU-46': 13.964355300522541, 'IoU-47': 13.599317922059978, 'IoU-48': 13.325500863584372, 'IoU-49': 12.958715147267682, 'IoU-50': 13.009690979855812, 'IoU-51': 12.196523112285602, 'IoU-52': 11.628425667895321, 'IoU-53': 11.555222370714361, 'IoU-54': 11.360176530485312, 'IoU-55': 10.981420259657515, 'IoU-56': 10.330391775154913, 'IoU-57': 10.3697240735814, 'IoU-58': 10.043426910846541, 'IoU-59': 10.01909112786233, 'IoU-60': 9.583096140088733, 'IoU-61': 9.171124929022707, 'IoU-62': 8.76579627436101, 'IoU-63': 8.254337826300574, 'IoU-64': 7.964703271391081, 'IoU-65': 7.883411523175586, 'IoU-66': 7.571926620232594, 'IoU-67': 7.057719818352994, 'IoU-68': 7.1916525426684235, 'IoU-69': 7.306137986929623, 'IoU-70': 6.868340559753186, 'IoU-71': 6.6182372770194435, 'IoU-72': 6.629497316220776, 'IoU-73': 6.682480606445511, 'IoU-74': 6.503677123419803, 'IoU-75': 6.139040653247131, 'IoU-76': 6.111044729497536, 'IoU-77': 6.071296608089141, 'IoU-78': 5.990131574821456, 'IoU-79': 5.774334698268697, 'IoU-80': 5.756166731685269, 'IoU-81': 5.621956831994909, 'IoU-82': 5.566527953797722, 'IoU-83': 5.682737479897024, 'IoU-84': 5.679926439433308, 'IoU-85': 5.399080767537205, 'IoU-86': 5.334704072346866, 'IoU-87': 5.280963120715547, 'IoU-88': 5.1895072630510315, 'IoU-89': 5.132050205212805, 'IoU-90': 4.966886970687114, 'IoU-91': 4.89112846484188, 'IoU-92': 4.925990598896391, 'IoU-93': 4.989051494717445, 'IoU-94': 5.0694397699776035, 'IoU-95': 4.985930866706809, 'IoU-96': 4.864030106873352, 'IoU-97': 4.879299706672569, 'IoU-98': 4.914728686773972, 'IoU-99': 4.754126924647347, 'IoU-100': 4.623258638949986, 'IoU-101': 4.4978713322189225, 'IoU-102': 4.598103922973258, 'IoU-103': 4.385388752578008, 'IoU-104': 4.1401369508056165, 'IoU-105': 4.217104250652418, 'IoU-106': 4.218073212192553, 'IoU-107': 4.361005036419993, 'IoU-108': 4.362012581754577, 'IoU-109': 4.435338202064134, 'IoU-110': 4.335980031637118, 'IoU-111': 4.0837729628786805, 'IoU-112': 3.739803617499183, 'IoU-113': 3.6286571479924077, 'IoU-114': 3.5510695627768527, 'IoU-115': 3.4248210730290407, 'IoU-116': 3.196124299463807, 'IoU-117': 3.20600239519635, 'IoU-118': 3.4057225284141257, 'IoU-119': 3.3415400392018832, 'IoU-120': 3.421205495605322, 'IoU-121': 3.121453873833116, 'IoU-122': 3.168056064715189, 'IoU-123': 2.931286170270706, 'IoU-124': 2.6038347077620583, 'IoU-125': 2.478943608156337, 'IoU-126': 2.7023812746243676, 'IoU-127': 2.481681929769387, 'IoU-128': 2.4842361649353153, 'IoU-129': 2.391967642172331, 'IoU-130': 2.449854805592727, 'IoU-131': 2.4407709967846314, 'IoU-132': 2.4932235927778277, 'IoU-133': 2.4611204279321943, 'IoU-134': 2.4793749306532376, 'IoU-135': 2.292246675594399, 'IoU-136': 2.145416497297623, 'IoU-137': 2.0681495559682315, 'IoU-138': 2.0590677546588316, 'IoU-139': 2.059712612093238, 'IoU-140': 2.115862786837823, 'IoU-141': 2.108604963824773, 'IoU-142': 2.1741338399978987, 'IoU-143': 2.076707059258436, 'IoU-144': 1.99026898007895, 'IoU-145': 2.1893450416715456, 'IoU-146': 2.283524697387605, 'IoU-147': 2.1673215585857375, 'IoU-148': 2.254751557109676, 'IoU-149': 1.819063300586506, 'IoU-150': 1.7664086118219815, 'IoU-151': 2.08563923388845, 'IoU-152': 2.2953355933309676, 'IoU-153': 2.189106836792992, 'IoU-154': 2.323993775533388, 'IoU-155': 2.419307700081669, 'IoU-156': 2.152557234628739, 'IoU-157': 1.9833779701251288, 'IoU-158': 2.079243769259748, 'IoU-159': 1.7849612979501088, 'IoU-160': 2.4305508451060316, 'IoU-161': 2.1283122389176383, 'IoU-162': 1.9275975252833886, 'IoU-163': 1.8806203570963118, 'IoU-164': 1.976743091318201, 'IoU-165': 1.695231048271846, 'IoU-166': 1.5215400734593523, 'IoU-167': 1.6586345070586108, 'IoU-168': 1.5266720944604273, 'IoU-169': 1.3860419648974271, 'IoU-170': 1.2553328736985068, 'IoU-171': 1.4638607998542406, 'IoU-172': 1.3731929683913615, 'IoU-173': 1.35771674094415, 'IoU-174': 1.555517365801623, 'IoU-175': 1.1381492819916639, 'IoU-176': 1.4221571641047914, 'IoU-177': 1.4664225507807103, 'IoU-178': 1.297723345220608, 'IoU-179': 1.161842317215806, 'IoU-180': 0.869420392208294, 'IoU-181': 0.93935432431125, 'IoU-182': 0.9741330861000381, 'IoU-183': 0.45884753107981363, 'IoU-184': 0.4548897281203948, 'IoU-185': 0.1637425345948681, 'IoU-186': 0.016133807773658634, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 12.910527839571845, 'pACC': 26.82549671447835, 'ACC-0': 0.004912437259801398, 'ACC-1': 43.98825212106999, 'ACC-2': 4.124695291514312, 'ACC-3': 13.392690022668924, 'ACC-4': 12.830662820806799, 'ACC-5': 13.01884499631496, 'ACC-6': 13.304256196137882, 'ACC-7': 13.607243000025523, 'ACC-8': 18.154451584390724, 'ACC-9': 31.11367577281154, 'ACC-10': 35.55176171494618, 'ACC-11': 41.67572942156721, 'ACC-12': 43.92727885486699, 'ACC-13': 40.30838203975437, 'ACC-14': 40.7187739453758, 'ACC-15': 39.986590043091105, 'ACC-16': 35.971727479238005, 'ACC-17': 33.244424234042704, 'ACC-18': 32.21358322373119, 'ACC-19': 33.58808928470896, 'ACC-20': 30.969364479093176, 'ACC-21': 29.835089862986734, 'ACC-22': 28.613384527635468, 'ACC-23': 28.47882211473693, 'ACC-24': 26.96729527575493, 'ACC-25': 28.084791875800246, 'ACC-26': 27.56913818361788, 'ACC-27': 29.470080611895916, 'ACC-28': 29.485388964624164, 'ACC-29': 28.654455188266237, 'ACC-30': 28.60734038304248, 'ACC-31': 29.50593503443572, 'ACC-32': 30.33258243777069, 'ACC-33': 29.26741420181575, 'ACC-34': 27.98991176146115, 'ACC-35': 29.380387356081528, 'ACC-36': 29.482577985265763, 'ACC-37': 29.846217193623502, 'ACC-38': 30.60435908436642, 'ACC-39': 29.84678918131558, 'ACC-40': 30.29011150245784, 'ACC-41': 28.7822013718466, 'ACC-42': 28.67666860697653, 'ACC-43': 28.25021215375904, 'ACC-44': 27.57871748379388, 'ACC-45': 26.388880637574776, 'ACC-46': 25.40310410883928, 'ACC-47': 24.722688351783997, 'ACC-48': 24.193588060426237, 'ACC-49': 23.43928936125409, 'ACC-50': 23.588375518188165, 'ACC-51': 22.297378420415644, 'ACC-52': 20.92315105347986, 'ACC-53': 20.809261168398905, 'ACC-54': 20.355316237983335, 'ACC-55': 19.69629672498047, 'ACC-56': 18.664538120751896, 'ACC-57': 18.402274079912857, 'ACC-58': 18.09782290974871, 'ACC-59': 18.37549368328119, 'ACC-60': 17.787948597235236, 'ACC-61': 17.205396063934355, 'ACC-62': 16.515068456660003, 'ACC-63': 15.652636176765283, 'ACC-64': 15.02260008906336, 'ACC-65': 14.877438749049773, 'ACC-66': 14.307964616965199, 'ACC-67': 13.527301421173348, 'ACC-68': 13.90314921413925, 'ACC-69': 13.864130844073411, 'ACC-70': 12.868240697644248, 'ACC-71': 12.617228997958549, 'ACC-72': 12.741436789443064, 'ACC-73': 12.926014632039951, 'ACC-74': 12.467594967346882, 'ACC-75': 11.765535813152, 'ACC-76': 11.569685400788542, 'ACC-77': 11.69293364530442, 'ACC-78': 11.653958617703243, 'ACC-79': 11.258186974953478, 'ACC-80': 11.215803289775524, 'ACC-81': 10.822710264737395, 'ACC-82': 10.568579265160198, 'ACC-83': 10.533997530795222, 'ACC-84': 10.553042232447908, 'ACC-85': 10.070498034276223, 'ACC-86': 9.994361393749626, 'ACC-87': 9.95193987602881, 'ACC-88': 9.7122634905082, 'ACC-89': 9.482990026301065, 'ACC-90': 9.116242619028265, 'ACC-91': 9.024382477579339, 'ACC-92': 9.091193488879115, 'ACC-93': 9.251741809814536, 'ACC-94': 9.378504735422124, 'ACC-95': 9.21559862624304, 'ACC-96': 8.998630944322015, 'ACC-97': 8.904643501804282, 'ACC-98': 8.964635500548003, 'ACC-99': 8.73431337535203, 'ACC-100': 8.496756672156685, 'ACC-101': 8.254538138937464, 'ACC-102': 8.44870865428183, 'ACC-103': 8.132214036081988, 'ACC-104': 7.697892329258996, 'ACC-105': 7.781893276323052, 'ACC-106': 7.817860427209701, 'ACC-107': 8.105426680417215, 'ACC-108': 8.020916271075802, 'ACC-109': 8.165441265062375, 'ACC-110': 8.134485176755533, 'ACC-111': 7.68809617155889, 'ACC-112': 7.177490876113335, 'ACC-113': 7.008067746180695, 'ACC-114': 6.8795629149740325, 'ACC-115': 6.523536752213853, 'ACC-116': 6.12648190274662, 'ACC-117': 6.063679402600764, 'ACC-118': 6.479287667574843, 'ACC-119': 6.356193360860239, 'ACC-120': 6.555519244352144, 'ACC-121': 6.079685614320682, 'ACC-122': 6.147876626378706, 'ACC-123': 5.6564542136977005, 'ACC-124': 5.105852055909618, 'ACC-125': 4.879846154348174, 'ACC-126': 5.3418633138735325, 'ACC-127': 4.940705921931801, 'ACC-128': 4.978466649835161, 'ACC-129': 4.773905453139796, 'ACC-130': 4.82550955389366, 'ACC-131': 4.78396877012427, 'ACC-132': 4.86828656928485, 'ACC-133': 4.791075547571904, 'ACC-134': 4.7753209823352005, 'ACC-135': 4.449789065617696, 'ACC-136': 4.149535268356318, 'ACC-137': 4.026432262747316, 'ACC-138': 4.09120618321192, 'ACC-139': 4.138788754772483, 'ACC-140': 4.222386766652255, 'ACC-141': 4.207769562341472, 'ACC-142': 4.337061518993311, 'ACC-143': 4.129296501874012, 'ACC-144': 3.9133574007220213, 'ACC-145': 4.298307207227353, 'ACC-146': 4.484247561170638, 'ACC-147': 4.234421527545003, 'ACC-148': 4.381061374401051, 'ACC-149': 3.668100305353885, 'ACC-150': 3.6108687744225874, 'ACC-151': 4.357960231614555, 'ACC-152': 4.742923494504012, 'ACC-153': 4.7387731545099765, 'ACC-154': 5.092365912968331, 'ACC-155': 5.458594942107118, 'ACC-156': 4.960344392949252, 'ACC-157': 4.62943681582289, 'ACC-158': 4.806146628824178, 'ACC-159': 4.158786686211854, 'ACC-160': 5.572772926752025, 'ACC-161': 4.793345259592729, 'ACC-162': 4.500135375973294, 'ACC-163': 4.411717497214014, 'ACC-164': 4.660561455357228, 'ACC-165': 4.031579248285566, 'ACC-166': 3.713055376014639, 'ACC-167': 4.0935123951868, 'ACC-168': 3.830965609395879, 'ACC-169': 3.4931118648588417, 'ACC-170': 3.1116458679387256, 'ACC-171': 3.689505500460132, 'ACC-172': 3.4514946105122792, 'ACC-173': 3.6242300180995133, 'ACC-174': 4.23481912686563, 'ACC-175': 3.1295354413833776, 'ACC-176': 4.056804330160204, 'ACC-177': 4.387038195578636, 'ACC-178': 3.5784443444315457, 'ACC-179': 3.7023135401851563, 'ACC-180': 3.17103525347963, 'ACC-181': 3.8175569246365892, 'ACC-182': 3.5397747868340566, 'ACC-183': 1.6112969716375005, 'ACC-184': 1.4348481310890837, 'ACC-185': 0.455219433781855, 'ACC-186': 0.021481871425097908, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 01:48:03] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 01:48:03] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 01:48:03] d2.evaluation.testing INFO: copypaste: 2.4423,0.3679,0.1543,7.1729,17.5408,12.9105,26.8255
[01/30 01:48:03] d2.utils.events INFO:  eta: 1 day, 0:37:13  iter: 29999  total_loss: 20.15  loss_mask: 2.019  loss_mask_0: 2.035  loss_mask_1: 2.002  loss_mask_2: 2.012  loss_mask_3: 2.021  loss_mask_4: 2.018  loss_mask_5: 2.014  loss_mask_6: 2.011  loss_mask_7: 2.019  loss_mask_8: 2.013  time: 2.9915  data_time: 0.0568  lr: 5.359e-05  max_mem: 27646M
[01/30 01:49:03] d2.utils.events INFO:  eta: 1 day, 0:36:23  iter: 30019  total_loss: 21.05  loss_mask: 2.093  loss_mask_0: 2.154  loss_mask_1: 2.076  loss_mask_2: 2.101  loss_mask_3: 2.109  loss_mask_4: 2.105  loss_mask_5: 2.101  loss_mask_6: 2.094  loss_mask_7: 2.112  loss_mask_8: 2.104  time: 2.9915  data_time: 0.0527  lr: 5.3558e-05  max_mem: 27646M
[01/30 01:50:02] d2.utils.events INFO:  eta: 1 day, 0:35:27  iter: 30039  total_loss: 20.71  loss_mask: 2.06  loss_mask_0: 2.144  loss_mask_1: 2.062  loss_mask_2: 2.064  loss_mask_3: 2.07  loss_mask_4: 2.071  loss_mask_5: 2.073  loss_mask_6: 2.061  loss_mask_7: 2.069  loss_mask_8: 2.072  time: 2.9915  data_time: 0.0532  lr: 5.3526e-05  max_mem: 27646M
[01/30 01:51:02] d2.utils.events INFO:  eta: 1 day, 0:34:53  iter: 30059  total_loss: 22.61  loss_mask: 2.255  loss_mask_0: 2.292  loss_mask_1: 2.247  loss_mask_2: 2.253  loss_mask_3: 2.257  loss_mask_4: 2.254  loss_mask_5: 2.267  loss_mask_6: 2.255  loss_mask_7: 2.261  loss_mask_8: 2.266  time: 2.9915  data_time: 0.0744  lr: 5.3494e-05  max_mem: 27646M
[01/30 01:52:02] d2.utils.events INFO:  eta: 1 day, 0:33:25  iter: 30079  total_loss: 20.2  loss_mask: 2.026  loss_mask_0: 2.017  loss_mask_1: 2.011  loss_mask_2: 2.022  loss_mask_3: 2.021  loss_mask_4: 2.023  loss_mask_5: 2.025  loss_mask_6: 2.01  loss_mask_7: 2.023  loss_mask_8: 2.024  time: 2.9915  data_time: 0.0531  lr: 5.3462e-05  max_mem: 27646M
[01/30 01:53:00] d2.utils.events INFO:  eta: 1 day, 0:32:10  iter: 30099  total_loss: 20.34  loss_mask: 2.014  loss_mask_0: 2.085  loss_mask_1: 2.008  loss_mask_2: 2.036  loss_mask_3: 2.031  loss_mask_4: 2.047  loss_mask_5: 2.017  loss_mask_6: 2.016  loss_mask_7: 2.045  loss_mask_8: 2.039  time: 2.9914  data_time: 0.0512  lr: 5.3429e-05  max_mem: 27646M
[01/30 01:54:00] d2.utils.events INFO:  eta: 1 day, 0:30:55  iter: 30119  total_loss: 20.66  loss_mask: 2.057  loss_mask_0: 2.133  loss_mask_1: 2.045  loss_mask_2: 2.061  loss_mask_3: 2.061  loss_mask_4: 2.066  loss_mask_5: 2.051  loss_mask_6: 2.058  loss_mask_7: 2.067  loss_mask_8: 2.063  time: 2.9914  data_time: 0.0558  lr: 5.3397e-05  max_mem: 27646M
[01/30 01:54:58] d2.utils.events INFO:  eta: 1 day, 0:29:48  iter: 30139  total_loss: 20.81  loss_mask: 2.068  loss_mask_0: 2.14  loss_mask_1: 2.066  loss_mask_2: 2.092  loss_mask_3: 2.088  loss_mask_4: 2.1  loss_mask_5: 2.059  loss_mask_6: 2.071  loss_mask_7: 2.087  loss_mask_8: 2.094  time: 2.9914  data_time: 0.0578  lr: 5.3365e-05  max_mem: 27646M
[01/30 01:55:58] d2.utils.events INFO:  eta: 1 day, 0:28:49  iter: 30159  total_loss: 21.8  loss_mask: 2.158  loss_mask_0: 2.193  loss_mask_1: 2.147  loss_mask_2: 2.198  loss_mask_3: 2.164  loss_mask_4: 2.178  loss_mask_5: 2.18  loss_mask_6: 2.157  loss_mask_7: 2.203  loss_mask_8: 2.188  time: 2.9913  data_time: 0.0779  lr: 5.3333e-05  max_mem: 27646M
[01/30 01:56:57] d2.utils.events INFO:  eta: 1 day, 0:27:42  iter: 30179  total_loss: 21.23  loss_mask: 2.107  loss_mask_0: 2.164  loss_mask_1: 2.108  loss_mask_2: 2.128  loss_mask_3: 2.132  loss_mask_4: 2.126  loss_mask_5: 2.117  loss_mask_6: 2.099  loss_mask_7: 2.13  loss_mask_8: 2.137  time: 2.9913  data_time: 0.0586  lr: 5.3301e-05  max_mem: 27646M
[01/30 01:57:56] d2.utils.events INFO:  eta: 1 day, 0:25:55  iter: 30199  total_loss: 21.33  loss_mask: 2.107  loss_mask_0: 2.176  loss_mask_1: 2.094  loss_mask_2: 2.145  loss_mask_3: 2.134  loss_mask_4: 2.141  loss_mask_5: 2.111  loss_mask_6: 2.106  loss_mask_7: 2.142  loss_mask_8: 2.152  time: 2.9913  data_time: 0.0511  lr: 5.3269e-05  max_mem: 27646M
[01/30 01:58:55] d2.utils.events INFO:  eta: 1 day, 0:24:47  iter: 30219  total_loss: 23.54  loss_mask: 2.348  loss_mask_0: 2.365  loss_mask_1: 2.337  loss_mask_2: 2.36  loss_mask_3: 2.349  loss_mask_4: 2.355  loss_mask_5: 2.349  loss_mask_6: 2.355  loss_mask_7: 2.363  loss_mask_8: 2.358  time: 2.9913  data_time: 0.0606  lr: 5.3236e-05  max_mem: 27646M
[01/30 01:59:54] d2.utils.events INFO:  eta: 1 day, 0:24:04  iter: 30239  total_loss: 20.94  loss_mask: 2.085  loss_mask_0: 2.145  loss_mask_1: 2.085  loss_mask_2: 2.087  loss_mask_3: 2.082  loss_mask_4: 2.086  loss_mask_5: 2.091  loss_mask_6: 2.087  loss_mask_7: 2.096  loss_mask_8: 2.099  time: 2.9912  data_time: 0.0578  lr: 5.3204e-05  max_mem: 27646M
[01/30 02:00:53] d2.utils.events INFO:  eta: 1 day, 0:23:05  iter: 30259  total_loss: 20.51  loss_mask: 2.035  loss_mask_0: 2.116  loss_mask_1: 2.014  loss_mask_2: 2.052  loss_mask_3: 2.056  loss_mask_4: 2.056  loss_mask_5: 2.041  loss_mask_6: 2.033  loss_mask_7: 2.063  loss_mask_8: 2.06  time: 2.9912  data_time: 0.0656  lr: 5.3172e-05  max_mem: 27646M
[01/30 02:01:52] d2.utils.events INFO:  eta: 1 day, 0:21:43  iter: 30279  total_loss: 20.76  loss_mask: 2.086  loss_mask_0: 2.116  loss_mask_1: 2.074  loss_mask_2: 2.051  loss_mask_3: 2.072  loss_mask_4: 2.1  loss_mask_5: 2.08  loss_mask_6: 2.074  loss_mask_7: 2.077  loss_mask_8: 2.061  time: 2.9912  data_time: 0.0552  lr: 5.314e-05  max_mem: 27646M
[01/30 02:02:52] d2.utils.events INFO:  eta: 1 day, 0:21:00  iter: 30299  total_loss: 23.08  loss_mask: 2.296  loss_mask_0: 2.348  loss_mask_1: 2.277  loss_mask_2: 2.314  loss_mask_3: 2.308  loss_mask_4: 2.332  loss_mask_5: 2.304  loss_mask_6: 2.295  loss_mask_7: 2.322  loss_mask_8: 2.296  time: 2.9912  data_time: 0.0647  lr: 5.3108e-05  max_mem: 27646M
[01/30 02:03:51] d2.utils.events INFO:  eta: 1 day, 0:19:38  iter: 30319  total_loss: 21.42  loss_mask: 2.126  loss_mask_0: 2.232  loss_mask_1: 2.119  loss_mask_2: 2.138  loss_mask_3: 2.139  loss_mask_4: 2.145  loss_mask_5: 2.129  loss_mask_6: 2.129  loss_mask_7: 2.157  loss_mask_8: 2.146  time: 2.9912  data_time: 0.0607  lr: 5.3076e-05  max_mem: 27646M
[01/30 02:04:50] d2.utils.events INFO:  eta: 1 day, 0:18:38  iter: 30339  total_loss: 20.44  loss_mask: 2.049  loss_mask_0: 2.043  loss_mask_1: 2.022  loss_mask_2: 2.036  loss_mask_3: 2.042  loss_mask_4: 2.041  loss_mask_5: 2.025  loss_mask_6: 2.043  loss_mask_7: 2.036  loss_mask_8: 2.039  time: 2.9911  data_time: 0.0586  lr: 5.3043e-05  max_mem: 27646M
[01/30 02:05:48] d2.utils.events INFO:  eta: 1 day, 0:17:32  iter: 30359  total_loss: 22.49  loss_mask: 2.248  loss_mask_0: 2.278  loss_mask_1: 2.247  loss_mask_2: 2.252  loss_mask_3: 2.252  loss_mask_4: 2.258  loss_mask_5: 2.245  loss_mask_6: 2.241  loss_mask_7: 2.253  loss_mask_8: 2.249  time: 2.9911  data_time: 0.0612  lr: 5.3011e-05  max_mem: 27646M
[01/30 02:06:47] d2.utils.events INFO:  eta: 1 day, 0:16:40  iter: 30379  total_loss: 20.83  loss_mask: 2.087  loss_mask_0: 2.097  loss_mask_1: 2.077  loss_mask_2: 2.072  loss_mask_3: 2.085  loss_mask_4: 2.078  loss_mask_5: 2.085  loss_mask_6: 2.087  loss_mask_7: 2.079  loss_mask_8: 2.079  time: 2.9911  data_time: 0.0545  lr: 5.2979e-05  max_mem: 27646M
[01/30 02:07:46] d2.utils.events INFO:  eta: 1 day, 0:15:07  iter: 30399  total_loss: 21.8  loss_mask: 2.173  loss_mask_0: 2.226  loss_mask_1: 2.149  loss_mask_2: 2.187  loss_mask_3: 2.188  loss_mask_4: 2.177  loss_mask_5: 2.171  loss_mask_6: 2.167  loss_mask_7: 2.178  loss_mask_8: 2.185  time: 2.9910  data_time: 0.0602  lr: 5.2947e-05  max_mem: 27646M
[01/30 02:08:45] d2.utils.events INFO:  eta: 1 day, 0:13:50  iter: 30419  total_loss: 21.64  loss_mask: 2.152  loss_mask_0: 2.212  loss_mask_1: 2.183  loss_mask_2: 2.212  loss_mask_3: 2.149  loss_mask_4: 2.137  loss_mask_5: 2.118  loss_mask_6: 2.112  loss_mask_7: 2.195  loss_mask_8: 2.139  time: 2.9910  data_time: 0.0559  lr: 5.2915e-05  max_mem: 27646M
[01/30 02:09:44] d2.utils.events INFO:  eta: 1 day, 0:12:49  iter: 30439  total_loss: 19.66  loss_mask: 1.932  loss_mask_0: 2.037  loss_mask_1: 1.928  loss_mask_2: 1.977  loss_mask_3: 1.979  loss_mask_4: 1.98  loss_mask_5: 1.933  loss_mask_6: 1.93  loss_mask_7: 1.981  loss_mask_8: 1.983  time: 2.9910  data_time: 0.0628  lr: 5.2882e-05  max_mem: 27646M
[01/30 02:10:43] d2.utils.events INFO:  eta: 1 day, 0:11:52  iter: 30459  total_loss: 20.4  loss_mask: 2.027  loss_mask_0: 2.076  loss_mask_1: 2.024  loss_mask_2: 2.042  loss_mask_3: 2.031  loss_mask_4: 2.027  loss_mask_5: 2.031  loss_mask_6: 2.043  loss_mask_7: 2.026  loss_mask_8: 2.032  time: 2.9909  data_time: 0.0554  lr: 5.285e-05  max_mem: 27646M
[01/30 02:11:43] d2.utils.events INFO:  eta: 1 day, 0:10:51  iter: 30479  total_loss: 21.14  loss_mask: 2.1  loss_mask_0: 2.165  loss_mask_1: 2.086  loss_mask_2: 2.12  loss_mask_3: 2.123  loss_mask_4: 2.119  loss_mask_5: 2.091  loss_mask_6: 2.096  loss_mask_7: 2.115  loss_mask_8: 2.119  time: 2.9909  data_time: 0.0580  lr: 5.2818e-05  max_mem: 27646M
[01/30 02:12:41] d2.utils.events INFO:  eta: 1 day, 0:09:53  iter: 30499  total_loss: 22.05  loss_mask: 2.193  loss_mask_0: 2.253  loss_mask_1: 2.194  loss_mask_2: 2.203  loss_mask_3: 2.21  loss_mask_4: 2.205  loss_mask_5: 2.181  loss_mask_6: 2.19  loss_mask_7: 2.21  loss_mask_8: 2.207  time: 2.9909  data_time: 0.0510  lr: 5.2786e-05  max_mem: 27646M
[01/30 02:13:40] d2.utils.events INFO:  eta: 1 day, 0:08:38  iter: 30519  total_loss: 23.37  loss_mask: 2.329  loss_mask_0: 2.39  loss_mask_1: 2.323  loss_mask_2: 2.335  loss_mask_3: 2.334  loss_mask_4: 2.332  loss_mask_5: 2.326  loss_mask_6: 2.33  loss_mask_7: 2.338  loss_mask_8: 2.331  time: 2.9909  data_time: 0.0543  lr: 5.2754e-05  max_mem: 27646M
[01/30 02:14:40] d2.utils.events INFO:  eta: 1 day, 0:07:46  iter: 30539  total_loss: 19.54  loss_mask: 1.952  loss_mask_0: 1.975  loss_mask_1: 1.945  loss_mask_2: 1.96  loss_mask_3: 1.959  loss_mask_4: 1.957  loss_mask_5: 1.942  loss_mask_6: 1.947  loss_mask_7: 1.958  loss_mask_8: 1.951  time: 2.9908  data_time: 0.0611  lr: 5.2721e-05  max_mem: 27646M
[01/30 02:15:39] d2.utils.events INFO:  eta: 1 day, 0:06:40  iter: 30559  total_loss: 20.24  loss_mask: 2.019  loss_mask_0: 2.065  loss_mask_1: 2.017  loss_mask_2: 2.024  loss_mask_3: 2.021  loss_mask_4: 2.029  loss_mask_5: 2.007  loss_mask_6: 2.017  loss_mask_7: 2.023  loss_mask_8: 2.023  time: 2.9908  data_time: 0.0583  lr: 5.2689e-05  max_mem: 27646M
[01/30 02:16:38] d2.utils.events INFO:  eta: 1 day, 0:05:57  iter: 30579  total_loss: 20.64  loss_mask: 2.048  loss_mask_0: 2.117  loss_mask_1: 2.044  loss_mask_2: 2.05  loss_mask_3: 2.047  loss_mask_4: 2.052  loss_mask_5: 2.045  loss_mask_6: 2.055  loss_mask_7: 2.056  loss_mask_8: 2.048  time: 2.9908  data_time: 0.0549  lr: 5.2657e-05  max_mem: 27646M
[01/30 02:17:37] d2.utils.events INFO:  eta: 1 day, 0:04:42  iter: 30599  total_loss: 21.73  loss_mask: 2.134  loss_mask_0: 2.192  loss_mask_1: 2.146  loss_mask_2: 2.193  loss_mask_3: 2.172  loss_mask_4: 2.19  loss_mask_5: 2.134  loss_mask_6: 2.13  loss_mask_7: 2.176  loss_mask_8: 2.171  time: 2.9908  data_time: 0.0533  lr: 5.2625e-05  max_mem: 27646M
[01/30 02:18:36] d2.utils.events INFO:  eta: 1 day, 0:03:43  iter: 30619  total_loss: 20.47  loss_mask: 2.049  loss_mask_0: 2.112  loss_mask_1: 2.023  loss_mask_2: 2.039  loss_mask_3: 2.038  loss_mask_4: 2.054  loss_mask_5: 2.051  loss_mask_6: 2.041  loss_mask_7: 2.048  loss_mask_8: 2.049  time: 2.9907  data_time: 0.0685  lr: 5.2592e-05  max_mem: 27646M
[01/30 02:19:34] d2.utils.events INFO:  eta: 1 day, 0:02:22  iter: 30639  total_loss: 20.3  loss_mask: 2.052  loss_mask_0: 2.056  loss_mask_1: 1.995  loss_mask_2: 2.016  loss_mask_3: 2.018  loss_mask_4: 2.04  loss_mask_5: 2.028  loss_mask_6: 2.031  loss_mask_7: 2.027  loss_mask_8: 2.011  time: 2.9907  data_time: 0.0558  lr: 5.256e-05  max_mem: 27646M
[01/30 02:20:34] d2.utils.events INFO:  eta: 1 day, 0:01:16  iter: 30659  total_loss: 20.96  loss_mask: 2.069  loss_mask_0: 2.103  loss_mask_1: 2.066  loss_mask_2: 2.082  loss_mask_3: 2.087  loss_mask_4: 2.089  loss_mask_5: 2.067  loss_mask_6: 2.08  loss_mask_7: 2.102  loss_mask_8: 2.105  time: 2.9907  data_time: 0.0582  lr: 5.2528e-05  max_mem: 27646M
[01/30 02:21:33] d2.utils.events INFO:  eta: 1 day, 0:00:07  iter: 30679  total_loss: 21.75  loss_mask: 2.154  loss_mask_0: 2.194  loss_mask_1: 2.156  loss_mask_2: 2.161  loss_mask_3: 2.167  loss_mask_4: 2.173  loss_mask_5: 2.162  loss_mask_6: 2.16  loss_mask_7: 2.18  loss_mask_8: 2.23  time: 2.9906  data_time: 0.0490  lr: 5.2496e-05  max_mem: 27646M
[01/30 02:22:32] d2.utils.events INFO:  eta: 23:59:15  iter: 30699  total_loss: 21.74  loss_mask: 2.171  loss_mask_0: 2.181  loss_mask_1: 2.135  loss_mask_2: 2.152  loss_mask_3: 2.182  loss_mask_4: 2.187  loss_mask_5: 2.161  loss_mask_6: 2.166  loss_mask_7: 2.181  loss_mask_8: 2.188  time: 2.9906  data_time: 0.0603  lr: 5.2464e-05  max_mem: 27646M
[01/30 02:23:31] d2.utils.events INFO:  eta: 23:58:16  iter: 30719  total_loss: 20.63  loss_mask: 2.04  loss_mask_0: 2.043  loss_mask_1: 2.038  loss_mask_2: 2.081  loss_mask_3: 2.058  loss_mask_4: 2.046  loss_mask_5: 2.044  loss_mask_6: 2.053  loss_mask_7: 2.047  loss_mask_8: 2.18  time: 2.9906  data_time: 0.0537  lr: 5.2431e-05  max_mem: 27646M
[01/30 02:24:30] d2.utils.events INFO:  eta: 23:57:17  iter: 30739  total_loss: 21.09  loss_mask: 2.108  loss_mask_0: 2.147  loss_mask_1: 2.087  loss_mask_2: 2.108  loss_mask_3: 2.116  loss_mask_4: 2.108  loss_mask_5: 2.103  loss_mask_6: 2.103  loss_mask_7: 2.119  loss_mask_8: 2.149  time: 2.9906  data_time: 0.0632  lr: 5.2399e-05  max_mem: 27646M
[01/30 02:25:30] d2.utils.events INFO:  eta: 23:56:21  iter: 30759  total_loss: 20.22  loss_mask: 2.019  loss_mask_0: 2.041  loss_mask_1: 1.993  loss_mask_2: 2.024  loss_mask_3: 2.031  loss_mask_4: 2.028  loss_mask_5: 2.006  loss_mask_6: 2.018  loss_mask_7: 2.026  loss_mask_8: 2.029  time: 2.9906  data_time: 0.0585  lr: 5.2367e-05  max_mem: 27646M
[01/30 02:26:28] d2.utils.events INFO:  eta: 23:54:51  iter: 30779  total_loss: 20.77  loss_mask: 2.067  loss_mask_0: 2.146  loss_mask_1: 2.063  loss_mask_2: 2.062  loss_mask_3: 2.07  loss_mask_4: 2.074  loss_mask_5: 2.078  loss_mask_6: 2.066  loss_mask_7: 2.073  loss_mask_8: 2.074  time: 2.9905  data_time: 0.0541  lr: 5.2335e-05  max_mem: 27646M
[01/30 02:27:27] d2.utils.events INFO:  eta: 23:54:02  iter: 30799  total_loss: 22.29  loss_mask: 2.234  loss_mask_0: 2.296  loss_mask_1: 2.214  loss_mask_2: 2.207  loss_mask_3: 2.219  loss_mask_4: 2.219  loss_mask_5: 2.217  loss_mask_6: 2.226  loss_mask_7: 2.225  loss_mask_8: 2.224  time: 2.9905  data_time: 0.0566  lr: 5.2302e-05  max_mem: 27646M
[01/30 02:28:27] d2.utils.events INFO:  eta: 23:53:06  iter: 30819  total_loss: 20.76  loss_mask: 2.06  loss_mask_0: 2.131  loss_mask_1: 2.061  loss_mask_2: 2.07  loss_mask_3: 2.071  loss_mask_4: 2.072  loss_mask_5: 2.066  loss_mask_6: 2.063  loss_mask_7: 2.075  loss_mask_8: 2.083  time: 2.9905  data_time: 0.0762  lr: 5.227e-05  max_mem: 27646M
[01/30 02:29:26] d2.utils.events INFO:  eta: 23:51:57  iter: 30839  total_loss: 21.73  loss_mask: 2.165  loss_mask_0: 2.2  loss_mask_1: 2.126  loss_mask_2: 2.144  loss_mask_3: 2.183  loss_mask_4: 2.155  loss_mask_5: 2.223  loss_mask_6: 2.169  loss_mask_7: 2.175  loss_mask_8: 2.168  time: 2.9905  data_time: 0.0652  lr: 5.2238e-05  max_mem: 27646M
[01/30 02:30:25] d2.utils.events INFO:  eta: 23:51:02  iter: 30859  total_loss: 21.95  loss_mask: 2.179  loss_mask_0: 2.212  loss_mask_1: 2.168  loss_mask_2: 2.195  loss_mask_3: 2.205  loss_mask_4: 2.202  loss_mask_5: 2.188  loss_mask_6: 2.18  loss_mask_7: 2.202  loss_mask_8: 2.207  time: 2.9904  data_time: 0.0523  lr: 5.2206e-05  max_mem: 27646M
[01/30 02:31:24] d2.utils.events INFO:  eta: 23:49:54  iter: 30879  total_loss: 23.62  loss_mask: 2.35  loss_mask_0: 2.422  loss_mask_1: 2.354  loss_mask_2: 2.351  loss_mask_3: 2.346  loss_mask_4: 2.36  loss_mask_5: 2.35  loss_mask_6: 2.347  loss_mask_7: 2.348  loss_mask_8: 2.367  time: 2.9904  data_time: 0.0550  lr: 5.2173e-05  max_mem: 27646M
[01/30 02:32:22] d2.utils.events INFO:  eta: 23:49:04  iter: 30899  total_loss: 20.78  loss_mask: 2.083  loss_mask_0: 2.148  loss_mask_1: 2.07  loss_mask_2: 2.09  loss_mask_3: 2.084  loss_mask_4: 2.076  loss_mask_5: 2.063  loss_mask_6: 2.057  loss_mask_7: 2.092  loss_mask_8: 2.09  time: 2.9904  data_time: 0.0508  lr: 5.2141e-05  max_mem: 27646M
[01/30 02:33:22] d2.utils.events INFO:  eta: 23:48:12  iter: 30919  total_loss: 21.78  loss_mask: 2.166  loss_mask_0: 2.232  loss_mask_1: 2.183  loss_mask_2: 2.169  loss_mask_3: 2.177  loss_mask_4: 2.181  loss_mask_5: 2.172  loss_mask_6: 2.16  loss_mask_7: 2.179  loss_mask_8: 2.175  time: 2.9904  data_time: 0.0673  lr: 5.2109e-05  max_mem: 27646M
[01/30 02:34:22] d2.utils.events INFO:  eta: 23:47:20  iter: 30939  total_loss: 19.23  loss_mask: 1.923  loss_mask_0: 1.945  loss_mask_1: 1.908  loss_mask_2: 1.928  loss_mask_3: 1.915  loss_mask_4: 1.929  loss_mask_5: 1.924  loss_mask_6: 1.92  loss_mask_7: 1.929  loss_mask_8: 1.922  time: 2.9904  data_time: 0.0694  lr: 5.2077e-05  max_mem: 27646M
[01/30 02:35:21] d2.utils.events INFO:  eta: 23:46:38  iter: 30959  total_loss: 21.83  loss_mask: 2.188  loss_mask_0: 2.219  loss_mask_1: 2.167  loss_mask_2: 2.187  loss_mask_3: 2.185  loss_mask_4: 2.191  loss_mask_5: 2.164  loss_mask_6: 2.179  loss_mask_7: 2.182  loss_mask_8: 2.196  time: 2.9904  data_time: 0.0539  lr: 5.2044e-05  max_mem: 27646M
[01/30 02:36:22] d2.utils.events INFO:  eta: 23:45:39  iter: 30979  total_loss: 20.77  loss_mask: 2.066  loss_mask_0: 2.151  loss_mask_1: 2.044  loss_mask_2: 2.078  loss_mask_3: 2.076  loss_mask_4: 2.088  loss_mask_5: 2.067  loss_mask_6: 2.046  loss_mask_7: 2.082  loss_mask_8: 2.085  time: 2.9904  data_time: 0.0606  lr: 5.2012e-05  max_mem: 27646M
[01/30 02:37:22] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 02:37:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 02:37:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 02:51:38] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.450866901070462, 'error_1pix': 0.3572524624411342, 'error_3pix': 0.15907867691831717, 'mIoU': 7.544872610190939, 'fwIoU': 20.204842098756423, 'IoU-0': 0.00015748621521743654, 'IoU-1': 58.391666478765615, 'IoU-2': 3.0340536585135016, 'IoU-3': 5.72565557588349, 'IoU-4': 5.230036368300034, 'IoU-5': 4.611051990056512, 'IoU-6': 4.291737726204041, 'IoU-7': 3.6459236809117184, 'IoU-8': 8.457942002923277, 'IoU-9': 17.897343204703027, 'IoU-10': 21.535600297217254, 'IoU-11': 28.87438565247195, 'IoU-12': 29.370097232587213, 'IoU-13': 27.865818171475272, 'IoU-14': 28.54253981401948, 'IoU-15': 27.194173244721153, 'IoU-16': 26.246627240994545, 'IoU-17': 24.36671918139478, 'IoU-18': 23.176969931672428, 'IoU-19': 23.63975670202483, 'IoU-20': 22.344556235490483, 'IoU-21': 22.458856104738352, 'IoU-22': 23.13346164978879, 'IoU-23': 21.70671076809147, 'IoU-24': 20.83547163869919, 'IoU-25': 20.70279254575206, 'IoU-26': 20.12077547947666, 'IoU-27': 21.52276196165533, 'IoU-28': 20.308311808819262, 'IoU-29': 21.14074456896977, 'IoU-30': 20.504863412925385, 'IoU-31': 21.376015360375348, 'IoU-32': 20.240609451287455, 'IoU-33': 19.5671001733751, 'IoU-34': 18.996055260492277, 'IoU-35': 19.48912464843095, 'IoU-36': 19.23603664550004, 'IoU-37': 18.73082825748599, 'IoU-38': 19.005564052989193, 'IoU-39': 17.729385675922586, 'IoU-40': 17.941805831098268, 'IoU-41': 16.50116035206536, 'IoU-42': 16.329727459278082, 'IoU-43': 16.117057810441672, 'IoU-44': 16.132466615588804, 'IoU-45': 15.596574157146852, 'IoU-46': 14.343372713879832, 'IoU-47': 14.02175028742757, 'IoU-48': 13.580475647004189, 'IoU-49': 13.235113583426958, 'IoU-50': 13.000416318042928, 'IoU-51': 11.824288369051066, 'IoU-52': 11.274863803925387, 'IoU-53': 10.757159772207654, 'IoU-54': 10.280747941007206, 'IoU-55': 9.9071635620016, 'IoU-56': 9.090116618586713, 'IoU-57': 8.90986934655222, 'IoU-58': 8.566769392712255, 'IoU-59': 8.01850975515607, 'IoU-60': 7.273240347230452, 'IoU-61': 6.890889796103082, 'IoU-62': 6.2821861422776, 'IoU-63': 5.553895389788435, 'IoU-64': 5.157159395344748, 'IoU-65': 4.936887986262044, 'IoU-66': 4.500074577807321, 'IoU-67': 4.595735446947292, 'IoU-68': 4.66986172355925, 'IoU-69': 4.4489126401259425, 'IoU-70': 4.2730441336408305, 'IoU-71': 4.201483553571235, 'IoU-72': 4.234955578044045, 'IoU-73': 4.134853999415594, 'IoU-74': 4.065356874996922, 'IoU-75': 3.8762065094384783, 'IoU-76': 4.139827313179213, 'IoU-77': 4.040792644555333, 'IoU-78': 4.004882015488638, 'IoU-79': 4.098836152304457, 'IoU-80': 4.126485275519422, 'IoU-81': 4.187687795520395, 'IoU-82': 4.040822838917796, 'IoU-83': 4.345508072475574, 'IoU-84': 4.336285891145937, 'IoU-85': 4.336014500552069, 'IoU-86': 4.245351267889599, 'IoU-87': 4.204405829511315, 'IoU-88': 3.992104783547389, 'IoU-89': 4.170200956156365, 'IoU-90': 4.187603873302864, 'IoU-91': 4.147231450026455, 'IoU-92': 4.108491886281169, 'IoU-93': 4.204689294643484, 'IoU-94': 4.4283930769438715, 'IoU-95': 4.363344600408683, 'IoU-96': 4.416888306955801, 'IoU-97': 4.486305715652795, 'IoU-98': 4.581384377097064, 'IoU-99': 4.358005206115494, 'IoU-100': 4.215838134009807, 'IoU-101': 4.195109983162633, 'IoU-102': 4.1445117213558635, 'IoU-103': 4.0416058581048215, 'IoU-104': 4.001902891573609, 'IoU-105': 4.0056283263755414, 'IoU-106': 4.017697632635658, 'IoU-107': 4.042448563506082, 'IoU-108': 4.014842057794762, 'IoU-109': 4.217922208911896, 'IoU-110': 4.3286989656841275, 'IoU-111': 4.144404594842007, 'IoU-112': 4.183081959799311, 'IoU-113': 3.989282884779273, 'IoU-114': 4.066262362680096, 'IoU-115': 3.898406114757254, 'IoU-116': 3.8333077197879484, 'IoU-117': 3.6157482349068655, 'IoU-118': 3.395104137747328, 'IoU-119': 3.899230153283501, 'IoU-120': 3.838704380348016, 'IoU-121': 3.5627213019132324, 'IoU-122': 3.4348188600654748, 'IoU-123': 3.3573410024708807, 'IoU-124': 3.063984153072045, 'IoU-125': 2.9376849855479934, 'IoU-126': 3.1422938582113162, 'IoU-127': 2.8594119479974762, 'IoU-128': 2.9127544922093205, 'IoU-129': 2.9617349393952543, 'IoU-130': 3.038072000602629, 'IoU-131': 3.0284381659082587, 'IoU-132': 3.0657981713767315, 'IoU-133': 3.087805216731609, 'IoU-134': 3.014656195561054, 'IoU-135': 2.939115606657371, 'IoU-136': 2.7634828512893015, 'IoU-137': 2.6650086455770445, 'IoU-138': 2.6025950542915077, 'IoU-139': 2.6591519568667437, 'IoU-140': 2.560607055371211, 'IoU-141': 2.30426508526263, 'IoU-142': 2.3218836491251604, 'IoU-143': 2.3496302200965413, 'IoU-144': 2.6023569884053717, 'IoU-145': 2.7345048833869843, 'IoU-146': 2.5653819618189813, 'IoU-147': 2.714889441388838, 'IoU-148': 2.69657345233888, 'IoU-149': 2.5376725030541696, 'IoU-150': 2.4492763933548423, 'IoU-151': 2.5582504485534745, 'IoU-152': 2.696349343120989, 'IoU-153': 2.472514096524094, 'IoU-154': 2.538795805030539, 'IoU-155': 2.5459566213717135, 'IoU-156': 2.3752965987372825, 'IoU-157': 2.3393465316674433, 'IoU-158': 2.186096487109088, 'IoU-159': 2.248584249297797, 'IoU-160': 1.9535430970846388, 'IoU-161': 1.9987332376096596, 'IoU-162': 1.9847962887779715, 'IoU-163': 2.063762175462675, 'IoU-164': 1.9572912771732442, 'IoU-165': 2.1178955700275424, 'IoU-166': 1.9883539036005038, 'IoU-167': 1.8806606143967384, 'IoU-168': 1.871007967238319, 'IoU-169': 2.105048874287507, 'IoU-170': 2.207497156831049, 'IoU-171': 2.017882594224022, 'IoU-172': 1.9821122592948346, 'IoU-173': 1.8122655295025298, 'IoU-174': 1.5609332087100178, 'IoU-175': 1.9890563769605, 'IoU-176': 1.8963833809934334, 'IoU-177': 1.7745782571211435, 'IoU-178': 1.664780006371715, 'IoU-179': 1.8616769618202251, 'IoU-180': 2.9935564516914837, 'IoU-181': 1.4755929110912196, 'IoU-182': 1.2479043775225085, 'IoU-183': 1.246306835513644, 'IoU-184': 0.7902293738850233, 'IoU-185': 1.1862868314481219, 'IoU-186': 0.22346024473699472, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 13.426259051674394, 'pACC': 29.987028914879794, 'ACC-0': 0.0006474956767062617, 'ACC-1': 59.368822072151985, 'ACC-2': 5.808782852308092, 'ACC-3': 22.400757017314806, 'ACC-4': 19.139321235234405, 'ACC-5': 17.403174973920645, 'ACC-6': 16.713490170513438, 'ACC-7': 16.247160447910854, 'ACC-8': 22.373682357892307, 'ACC-9': 33.1371228140403, 'ACC-10': 37.54812469842188, 'ACC-11': 42.952658668283256, 'ACC-12': 44.61177721910656, 'ACC-13': 41.27149819538125, 'ACC-14': 42.78150769880965, 'ACC-15': 41.7248728811674, 'ACC-16': 39.46595802372642, 'ACC-17': 39.848440738856866, 'ACC-18': 37.19848416990872, 'ACC-19': 38.685593899717155, 'ACC-20': 36.3407357392569, 'ACC-21': 36.60001575566932, 'ACC-22': 37.185957410276934, 'ACC-23': 36.643981249555765, 'ACC-24': 35.09772965301523, 'ACC-25': 35.41747193292022, 'ACC-26': 34.37171965670574, 'ACC-27': 36.250524776647445, 'ACC-28': 34.719746612309415, 'ACC-29': 34.92584028066285, 'ACC-30': 34.61518388139136, 'ACC-31': 35.55968063600394, 'ACC-32': 34.122399856515806, 'ACC-33': 33.36463400989089, 'ACC-34': 32.84806270716476, 'ACC-35': 33.487587350270495, 'ACC-36': 32.837708038161146, 'ACC-37': 32.614962223100406, 'ACC-38': 33.13242341630672, 'ACC-39': 31.13644078623236, 'ACC-40': 30.77074195038387, 'ACC-41': 29.062093068274812, 'ACC-42': 28.8944557609543, 'ACC-43': 28.608549855650978, 'ACC-44': 28.01894714863511, 'ACC-45': 27.267679016506257, 'ACC-46': 25.9039261236088, 'ACC-47': 25.489041277554215, 'ACC-48': 24.784475779372425, 'ACC-49': 24.121881978246407, 'ACC-50': 23.82099682953094, 'ACC-51': 22.002838858005212, 'ACC-52': 20.837400991289115, 'ACC-53': 19.861801870485234, 'ACC-54': 18.904017461025933, 'ACC-55': 18.10815599122754, 'ACC-56': 16.71929755187552, 'ACC-57': 16.24309289173798, 'ACC-58': 15.944220807161122, 'ACC-59': 15.224750881940249, 'ACC-60': 13.977332970852844, 'ACC-61': 13.370772054895507, 'ACC-62': 12.236684932524748, 'ACC-63': 10.882852492448356, 'ACC-64': 10.129430952075525, 'ACC-65': 9.71346074236592, 'ACC-66': 8.886937655328163, 'ACC-67': 9.1738061083728, 'ACC-68': 9.173626991457972, 'ACC-69': 8.591988657180634, 'ACC-70': 8.17528071610512, 'ACC-71': 8.243189976112337, 'ACC-72': 8.383536149145572, 'ACC-73': 8.044506046003459, 'ACC-74': 7.823927509020143, 'ACC-75': 7.498774214050073, 'ACC-76': 7.881046396213779, 'ACC-77': 7.81838418510071, 'ACC-78': 7.792107100335353, 'ACC-79': 7.94777711579902, 'ACC-80': 7.892676854102257, 'ACC-81': 7.901701574596379, 'ACC-82': 7.559582168182684, 'ACC-83': 8.000074345478765, 'ACC-84': 8.011817607618363, 'ACC-85': 8.024460334411437, 'ACC-86': 7.859932514599009, 'ACC-87': 7.793149383031431, 'ACC-88': 7.339570959194595, 'ACC-89': 7.550956631239392, 'ACC-90': 7.495138406898147, 'ACC-91': 7.481151349566908, 'ACC-92': 7.447558080819931, 'ACC-93': 7.6517502954885535, 'ACC-94': 8.045199987349502, 'ACC-95': 8.0211635381482, 'ACC-96': 8.183842145432315, 'ACC-97': 8.15324331528966, 'ACC-98': 8.300911377258698, 'ACC-99': 8.000901722992856, 'ACC-100': 7.726593017701863, 'ACC-101': 7.710430024880884, 'ACC-102': 7.656819211599457, 'ACC-103': 7.455039199017663, 'ACC-104': 7.4272644548830575, 'ACC-105': 7.46888496663688, 'ACC-106': 7.47169884545502, 'ACC-107': 7.532042913898063, 'ACC-108': 7.428200154376475, 'ACC-109': 7.8197773723817585, 'ACC-110': 8.176187360534799, 'ACC-111': 7.8531603027502435, 'ACC-112': 7.999491504725603, 'ACC-113': 7.660249574765795, 'ACC-114': 7.859520254577538, 'ACC-115': 7.551606452873874, 'ACC-116': 7.460331933638425, 'ACC-117': 6.973930486118199, 'ACC-118': 6.587697763401473, 'ACC-119': 7.656708857719178, 'ACC-120': 7.516375181409601, 'ACC-121': 7.0522390940881445, 'ACC-122': 6.733986243595913, 'ACC-123': 6.568292119707343, 'ACC-124': 6.135738034341253, 'ACC-125': 5.896202044241502, 'ACC-126': 6.2528461097095605, 'ACC-127': 5.606304142642208, 'ACC-128': 5.8032714104679775, 'ACC-129': 5.909225827220705, 'ACC-130': 6.060408674992197, 'ACC-131': 6.122230618064707, 'ACC-132': 6.151541655356837, 'ACC-133': 6.203501466315568, 'ACC-134': 6.033950883239983, 'ACC-135': 5.900533036885013, 'ACC-136': 5.543948588333954, 'ACC-137': 5.340565723082513, 'ACC-138': 5.201538188186918, 'ACC-139': 5.37936779003618, 'ACC-140': 5.200708314076666, 'ACC-141': 4.66490164759425, 'ACC-142': 4.715993296427003, 'ACC-143': 4.767655746086859, 'ACC-144': 5.183303249097473, 'ACC-145': 5.355307587378967, 'ACC-146': 4.947476639784332, 'ACC-147': 5.1841115412221, 'ACC-148': 5.1131551607289, 'ACC-149': 4.8640612370939555, 'ACC-150': 4.700914834028032, 'ACC-151': 4.8764605135124475, 'ACC-152': 5.130466484591004, 'ACC-153': 4.8847771120760735, 'ACC-154': 4.979645800530019, 'ACC-155': 4.9955258428794345, 'ACC-156': 4.654992986742681, 'ACC-157': 4.687417061708131, 'ACC-158': 4.46799171830962, 'ACC-159': 4.565804807095243, 'ACC-160': 3.924947970863683, 'ACC-161': 3.9171302836184307, 'ACC-162': 3.956400010711066, 'ACC-163': 4.082290913482337, 'ACC-164': 3.909037002273599, 'ACC-165': 4.181502857124706, 'ACC-166': 4.052345737045774, 'ACC-167': 3.6601021076420914, 'ACC-168': 3.7143962303959492, 'ACC-169': 4.191488577680372, 'ACC-170': 4.447059074066187, 'ACC-171': 4.366386301475545, 'ACC-172': 4.17342667703819, 'ACC-173': 3.7963823550439693, 'ACC-174': 3.333948452974103, 'ACC-175': 4.484736882001335, 'ACC-176': 4.153666995588576, 'ACC-177': 4.231650085168186, 'ACC-178': 4.269563520960536, 'ACC-179': 4.55059131920281, 'ACC-180': 9.10355074672356, 'ACC-181': 4.88866149826733, 'ACC-182': 3.8091492552518544, 'ACC-183': 3.366678359791972, 'ACC-184': 1.833417056391607, 'ACC-185': 2.746790830019077, 'ACC-186': 0.2910675545840189, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 02:51:38] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 02:51:38] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 02:51:38] d2.evaluation.testing INFO: copypaste: 2.4509,0.3573,0.1591,7.5449,20.2048,13.4263,29.9870
[01/30 02:51:38] d2.utils.events INFO:  eta: 23:45:01  iter: 30999  total_loss: 20.86  loss_mask: 2.082  loss_mask_0: 2.091  loss_mask_1: 2.075  loss_mask_2: 2.084  loss_mask_3: 2.086  loss_mask_4: 2.093  loss_mask_5: 2.084  loss_mask_6: 2.082  loss_mask_7: 2.091  loss_mask_8: 2.093  time: 2.9904  data_time: 0.0692  lr: 5.198e-05  max_mem: 27646M
[01/30 02:52:38] d2.utils.events INFO:  eta: 23:44:01  iter: 31019  total_loss: 20.74  loss_mask: 2.056  loss_mask_0: 2.128  loss_mask_1: 2.071  loss_mask_2: 2.067  loss_mask_3: 2.08  loss_mask_4: 2.079  loss_mask_5: 2.065  loss_mask_6: 2.066  loss_mask_7: 2.086  loss_mask_8: 2.07  time: 2.9903  data_time: 0.0624  lr: 5.1948e-05  max_mem: 27646M
[01/30 02:53:37] d2.utils.events INFO:  eta: 23:42:52  iter: 31039  total_loss: 20.74  loss_mask: 2.058  loss_mask_0: 2.143  loss_mask_1: 2.072  loss_mask_2: 2.07  loss_mask_3: 2.079  loss_mask_4: 2.077  loss_mask_5: 2.058  loss_mask_6: 2.063  loss_mask_7: 2.078  loss_mask_8: 2.077  time: 2.9903  data_time: 0.0519  lr: 5.1915e-05  max_mem: 27646M
[01/30 02:54:37] d2.utils.events INFO:  eta: 23:41:38  iter: 31059  total_loss: 21.27  loss_mask: 2.119  loss_mask_0: 2.153  loss_mask_1: 2.104  loss_mask_2: 2.126  loss_mask_3: 2.124  loss_mask_4: 2.127  loss_mask_5: 2.117  loss_mask_6: 2.128  loss_mask_7: 2.14  loss_mask_8: 2.13  time: 2.9903  data_time: 0.0536  lr: 5.1883e-05  max_mem: 27646M
[01/30 02:55:36] d2.utils.events INFO:  eta: 23:40:54  iter: 31079  total_loss: 21.42  loss_mask: 2.139  loss_mask_0: 2.146  loss_mask_1: 2.138  loss_mask_2: 2.144  loss_mask_3: 2.135  loss_mask_4: 2.143  loss_mask_5: 2.138  loss_mask_6: 2.146  loss_mask_7: 2.142  loss_mask_8: 2.146  time: 2.9903  data_time: 0.0614  lr: 5.1851e-05  max_mem: 27646M
[01/30 02:56:36] d2.utils.events INFO:  eta: 23:40:05  iter: 31099  total_loss: 20.71  loss_mask: 2.063  loss_mask_0: 2.093  loss_mask_1: 2.049  loss_mask_2: 2.077  loss_mask_3: 2.076  loss_mask_4: 2.074  loss_mask_5: 2.065  loss_mask_6: 2.072  loss_mask_7: 2.094  loss_mask_8: 2.067  time: 2.9903  data_time: 0.0518  lr: 5.1819e-05  max_mem: 27646M
[01/30 02:57:35] d2.utils.events INFO:  eta: 23:39:03  iter: 31119  total_loss: 19  loss_mask: 1.909  loss_mask_0: 1.925  loss_mask_1: 1.887  loss_mask_2: 1.896  loss_mask_3: 1.914  loss_mask_4: 1.891  loss_mask_5: 1.9  loss_mask_6: 1.903  loss_mask_7: 1.904  loss_mask_8: 1.905  time: 2.9903  data_time: 0.0541  lr: 5.1786e-05  max_mem: 27646M
[01/30 02:58:34] d2.utils.events INFO:  eta: 23:38:07  iter: 31139  total_loss: 21.42  loss_mask: 2.133  loss_mask_0: 2.174  loss_mask_1: 2.127  loss_mask_2: 2.132  loss_mask_3: 2.125  loss_mask_4: 2.144  loss_mask_5: 2.142  loss_mask_6: 2.126  loss_mask_7: 2.141  loss_mask_8: 2.137  time: 2.9903  data_time: 0.0656  lr: 5.1754e-05  max_mem: 27646M
[01/30 02:59:33] d2.utils.events INFO:  eta: 23:37:10  iter: 31159  total_loss: 20.83  loss_mask: 2.077  loss_mask_0: 2.108  loss_mask_1: 2.072  loss_mask_2: 2.078  loss_mask_3: 2.087  loss_mask_4: 2.079  loss_mask_5: 2.075  loss_mask_6: 2.081  loss_mask_7: 2.074  loss_mask_8: 2.081  time: 2.9902  data_time: 0.0642  lr: 5.1722e-05  max_mem: 27646M
[01/30 03:00:32] d2.utils.events INFO:  eta: 23:35:33  iter: 31179  total_loss: 20.26  loss_mask: 2.029  loss_mask_0: 2.088  loss_mask_1: 2.011  loss_mask_2: 2.017  loss_mask_3: 2.013  loss_mask_4: 2.017  loss_mask_5: 2.021  loss_mask_6: 2.015  loss_mask_7: 2.022  loss_mask_8: 2.022  time: 2.9902  data_time: 0.0542  lr: 5.1689e-05  max_mem: 27646M
[01/30 03:01:31] d2.utils.events INFO:  eta: 23:35:07  iter: 31199  total_loss: 20.32  loss_mask: 2.016  loss_mask_0: 2.096  loss_mask_1: 2.01  loss_mask_2: 2.019  loss_mask_3: 2.01  loss_mask_4: 2.018  loss_mask_5: 2.024  loss_mask_6: 2.01  loss_mask_7: 2.021  loss_mask_8: 2.038  time: 2.9902  data_time: 0.0605  lr: 5.1657e-05  max_mem: 27646M
[01/30 03:02:31] d2.utils.events INFO:  eta: 23:34:02  iter: 31219  total_loss: 21.12  loss_mask: 2.123  loss_mask_0: 2.115  loss_mask_1: 2.083  loss_mask_2: 2.11  loss_mask_3: 2.101  loss_mask_4: 2.116  loss_mask_5: 2.119  loss_mask_6: 2.109  loss_mask_7: 2.126  loss_mask_8: 2.107  time: 2.9902  data_time: 0.0714  lr: 5.1625e-05  max_mem: 27646M
[01/30 03:03:30] d2.utils.events INFO:  eta: 23:33:11  iter: 31239  total_loss: 22  loss_mask: 2.192  loss_mask_0: 2.232  loss_mask_1: 2.19  loss_mask_2: 2.196  loss_mask_3: 2.194  loss_mask_4: 2.201  loss_mask_5: 2.202  loss_mask_6: 2.197  loss_mask_7: 2.191  loss_mask_8: 2.201  time: 2.9902  data_time: 0.0564  lr: 5.1593e-05  max_mem: 27646M
[01/30 03:04:30] d2.utils.events INFO:  eta: 23:32:24  iter: 31259  total_loss: 20.73  loss_mask: 2.076  loss_mask_0: 2.121  loss_mask_1: 2.078  loss_mask_2: 2.078  loss_mask_3: 2.065  loss_mask_4: 2.07  loss_mask_5: 2.07  loss_mask_6: 2.069  loss_mask_7: 2.069  loss_mask_8: 2.068  time: 2.9902  data_time: 0.0650  lr: 5.156e-05  max_mem: 27646M
[01/30 03:05:29] d2.utils.events INFO:  eta: 23:31:47  iter: 31279  total_loss: 21.68  loss_mask: 2.133  loss_mask_0: 2.255  loss_mask_1: 2.135  loss_mask_2: 2.17  loss_mask_3: 2.189  loss_mask_4: 2.188  loss_mask_5: 2.146  loss_mask_6: 2.136  loss_mask_7: 2.188  loss_mask_8: 2.179  time: 2.9901  data_time: 0.0528  lr: 5.1528e-05  max_mem: 27646M
[01/30 03:06:29] d2.utils.events INFO:  eta: 23:31:18  iter: 31299  total_loss: 21.37  loss_mask: 2.126  loss_mask_0: 2.18  loss_mask_1: 2.108  loss_mask_2: 2.152  loss_mask_3: 2.134  loss_mask_4: 2.148  loss_mask_5: 2.121  loss_mask_6: 2.114  loss_mask_7: 2.144  loss_mask_8: 2.15  time: 2.9901  data_time: 0.0817  lr: 5.1496e-05  max_mem: 27646M
[01/30 03:07:29] d2.utils.events INFO:  eta: 23:30:41  iter: 31319  total_loss: 21.84  loss_mask: 2.172  loss_mask_0: 2.205  loss_mask_1: 2.173  loss_mask_2: 2.185  loss_mask_3: 2.189  loss_mask_4: 2.188  loss_mask_5: 2.179  loss_mask_6: 2.172  loss_mask_7: 2.184  loss_mask_8: 2.197  time: 2.9901  data_time: 0.0639  lr: 5.1463e-05  max_mem: 27646M
[01/30 03:08:28] d2.utils.events INFO:  eta: 23:29:56  iter: 31339  total_loss: 20.56  loss_mask: 2.044  loss_mask_0: 2.096  loss_mask_1: 2.047  loss_mask_2: 2.062  loss_mask_3: 2.06  loss_mask_4: 2.061  loss_mask_5: 2.039  loss_mask_6: 2.035  loss_mask_7: 2.061  loss_mask_8: 2.053  time: 2.9901  data_time: 0.0547  lr: 5.1431e-05  max_mem: 27646M
[01/30 03:09:27] d2.utils.events INFO:  eta: 23:29:02  iter: 31359  total_loss: 21.34  loss_mask: 2.12  loss_mask_0: 2.188  loss_mask_1: 2.121  loss_mask_2: 2.132  loss_mask_3: 2.127  loss_mask_4: 2.141  loss_mask_5: 2.126  loss_mask_6: 2.118  loss_mask_7: 2.14  loss_mask_8: 2.127  time: 2.9901  data_time: 0.0477  lr: 5.1399e-05  max_mem: 27646M
[01/30 03:10:26] d2.utils.events INFO:  eta: 23:27:48  iter: 31379  total_loss: 21.97  loss_mask: 2.19  loss_mask_0: 2.223  loss_mask_1: 2.179  loss_mask_2: 2.196  loss_mask_3: 2.195  loss_mask_4: 2.198  loss_mask_5: 2.184  loss_mask_6: 2.193  loss_mask_7: 2.195  loss_mask_8: 2.194  time: 2.9901  data_time: 0.0553  lr: 5.1367e-05  max_mem: 27646M
[01/30 03:11:26] d2.utils.events INFO:  eta: 23:27:14  iter: 31399  total_loss: 21.03  loss_mask: 2.102  loss_mask_0: 2.11  loss_mask_1: 2.091  loss_mask_2: 2.109  loss_mask_3: 2.101  loss_mask_4: 2.103  loss_mask_5: 2.101  loss_mask_6: 2.095  loss_mask_7: 2.106  loss_mask_8: 2.115  time: 2.9900  data_time: 0.0661  lr: 5.1334e-05  max_mem: 27646M
[01/30 03:12:25] d2.utils.events INFO:  eta: 23:26:40  iter: 31419  total_loss: 19.62  loss_mask: 1.945  loss_mask_0: 1.987  loss_mask_1: 1.949  loss_mask_2: 1.964  loss_mask_3: 1.968  loss_mask_4: 1.957  loss_mask_5: 1.95  loss_mask_6: 1.944  loss_mask_7: 1.961  loss_mask_8: 1.957  time: 2.9900  data_time: 0.0615  lr: 5.1302e-05  max_mem: 27646M
[01/30 03:13:25] d2.utils.events INFO:  eta: 23:26:45  iter: 31439  total_loss: 21.53  loss_mask: 2.159  loss_mask_0: 2.223  loss_mask_1: 2.13  loss_mask_2: 2.181  loss_mask_3: 2.165  loss_mask_4: 2.163  loss_mask_5: 2.14  loss_mask_6: 2.155  loss_mask_7: 2.159  loss_mask_8: 2.151  time: 2.9900  data_time: 0.0632  lr: 5.127e-05  max_mem: 27646M
[01/30 03:14:24] d2.utils.events INFO:  eta: 23:25:29  iter: 31459  total_loss: 20.36  loss_mask: 2.01  loss_mask_0: 2.096  loss_mask_1: 2.008  loss_mask_2: 2.027  loss_mask_3: 2.041  loss_mask_4: 2.024  loss_mask_5: 2.015  loss_mask_6: 2.01  loss_mask_7: 2.028  loss_mask_8: 2.028  time: 2.9900  data_time: 0.0549  lr: 5.1237e-05  max_mem: 27646M
[01/30 03:15:24] d2.utils.events INFO:  eta: 23:24:30  iter: 31479  total_loss: 22.65  loss_mask: 2.263  loss_mask_0: 2.291  loss_mask_1: 2.251  loss_mask_2: 2.259  loss_mask_3: 2.27  loss_mask_4: 2.296  loss_mask_5: 2.254  loss_mask_6: 2.254  loss_mask_7: 2.265  loss_mask_8: 2.262  time: 2.9900  data_time: 0.0579  lr: 5.1205e-05  max_mem: 27646M
[01/30 03:16:23] d2.utils.events INFO:  eta: 23:23:47  iter: 31499  total_loss: 21.02  loss_mask: 2.092  loss_mask_0: 2.142  loss_mask_1: 2.084  loss_mask_2: 2.108  loss_mask_3: 2.109  loss_mask_4: 2.113  loss_mask_5: 2.092  loss_mask_6: 2.09  loss_mask_7: 2.102  loss_mask_8: 2.106  time: 2.9900  data_time: 0.0637  lr: 5.1173e-05  max_mem: 27646M
[01/30 03:17:22] d2.utils.events INFO:  eta: 23:22:50  iter: 31519  total_loss: 21.5  loss_mask: 2.148  loss_mask_0: 2.185  loss_mask_1: 2.136  loss_mask_2: 2.151  loss_mask_3: 2.149  loss_mask_4: 2.152  loss_mask_5: 2.13  loss_mask_6: 2.142  loss_mask_7: 2.158  loss_mask_8: 2.152  time: 2.9900  data_time: 0.0664  lr: 5.114e-05  max_mem: 27646M
[01/30 03:18:23] d2.utils.events INFO:  eta: 23:22:43  iter: 31539  total_loss: 21.64  loss_mask: 2.164  loss_mask_0: 2.194  loss_mask_1: 2.148  loss_mask_2: 2.156  loss_mask_3: 2.167  loss_mask_4: 2.177  loss_mask_5: 2.157  loss_mask_6: 2.15  loss_mask_7: 2.165  loss_mask_8: 2.16  time: 2.9900  data_time: 0.0726  lr: 5.1108e-05  max_mem: 27646M
[01/30 03:19:22] d2.utils.events INFO:  eta: 23:21:54  iter: 31559  total_loss: 21.1  loss_mask: 2.112  loss_mask_0: 2.159  loss_mask_1: 2.105  loss_mask_2: 2.105  loss_mask_3: 2.089  loss_mask_4: 2.098  loss_mask_5: 2.114  loss_mask_6: 2.106  loss_mask_7: 2.097  loss_mask_8: 2.109  time: 2.9900  data_time: 0.0564  lr: 5.1076e-05  max_mem: 27646M
[01/30 03:20:22] d2.utils.events INFO:  eta: 23:21:26  iter: 31579  total_loss: 22.44  loss_mask: 2.216  loss_mask_0: 2.274  loss_mask_1: 2.231  loss_mask_2: 2.253  loss_mask_3: 2.242  loss_mask_4: 2.258  loss_mask_5: 2.234  loss_mask_6: 2.227  loss_mask_7: 2.254  loss_mask_8: 2.255  time: 2.9900  data_time: 0.0676  lr: 5.1043e-05  max_mem: 27646M
[01/30 03:21:23] d2.utils.events INFO:  eta: 23:21:43  iter: 31599  total_loss: 21.09  loss_mask: 2.092  loss_mask_0: 2.156  loss_mask_1: 2.089  loss_mask_2: 2.112  loss_mask_3: 2.104  loss_mask_4: 2.11  loss_mask_5: 2.111  loss_mask_6: 2.093  loss_mask_7: 2.118  loss_mask_8: 2.105  time: 2.9900  data_time: 0.0786  lr: 5.1011e-05  max_mem: 27646M
[01/30 03:22:23] d2.utils.events INFO:  eta: 23:20:51  iter: 31619  total_loss: 20.94  loss_mask: 2.076  loss_mask_0: 2.134  loss_mask_1: 2.082  loss_mask_2: 2.105  loss_mask_3: 2.104  loss_mask_4: 2.118  loss_mask_5: 2.066  loss_mask_6: 2.071  loss_mask_7: 2.091  loss_mask_8: 2.098  time: 2.9900  data_time: 0.0648  lr: 5.0979e-05  max_mem: 27646M
[01/30 03:23:22] d2.utils.events INFO:  eta: 23:20:40  iter: 31639  total_loss: 22.18  loss_mask: 2.219  loss_mask_0: 2.263  loss_mask_1: 2.225  loss_mask_2: 2.212  loss_mask_3: 2.213  loss_mask_4: 2.216  loss_mask_5: 2.222  loss_mask_6: 2.206  loss_mask_7: 2.214  loss_mask_8: 2.219  time: 2.9900  data_time: 0.0609  lr: 5.0946e-05  max_mem: 27646M
[01/30 03:24:22] d2.utils.events INFO:  eta: 23:19:30  iter: 31659  total_loss: 21.05  loss_mask: 2.094  loss_mask_0: 2.143  loss_mask_1: 2.094  loss_mask_2: 2.105  loss_mask_3: 2.107  loss_mask_4: 2.103  loss_mask_5: 2.098  loss_mask_6: 2.094  loss_mask_7: 2.104  loss_mask_8: 2.109  time: 2.9900  data_time: 0.0579  lr: 5.0914e-05  max_mem: 27646M
[01/30 03:25:21] d2.utils.events INFO:  eta: 23:18:59  iter: 31679  total_loss: 21.47  loss_mask: 2.134  loss_mask_0: 2.195  loss_mask_1: 2.13  loss_mask_2: 2.146  loss_mask_3: 2.144  loss_mask_4: 2.139  loss_mask_5: 2.158  loss_mask_6: 2.14  loss_mask_7: 2.144  loss_mask_8: 2.144  time: 2.9900  data_time: 0.0614  lr: 5.0882e-05  max_mem: 27646M
[01/30 03:26:21] d2.utils.events INFO:  eta: 23:18:31  iter: 31699  total_loss: 20.98  loss_mask: 2.095  loss_mask_0: 2.128  loss_mask_1: 2.077  loss_mask_2: 2.095  loss_mask_3: 2.09  loss_mask_4: 2.088  loss_mask_5: 2.097  loss_mask_6: 2.089  loss_mask_7: 2.083  loss_mask_8: 2.092  time: 2.9900  data_time: 0.0719  lr: 5.0849e-05  max_mem: 27646M
[01/30 03:27:22] d2.utils.events INFO:  eta: 23:17:49  iter: 31719  total_loss: 18.19  loss_mask: 1.81  loss_mask_0: 1.877  loss_mask_1: 1.803  loss_mask_2: 1.817  loss_mask_3: 1.823  loss_mask_4: 1.82  loss_mask_5: 1.806  loss_mask_6: 1.806  loss_mask_7: 1.819  loss_mask_8: 1.813  time: 2.9900  data_time: 0.0683  lr: 5.0817e-05  max_mem: 27646M
[01/30 03:28:22] d2.utils.events INFO:  eta: 23:17:07  iter: 31739  total_loss: 21.62  loss_mask: 2.136  loss_mask_0: 2.236  loss_mask_1: 2.128  loss_mask_2: 2.17  loss_mask_3: 2.17  loss_mask_4: 2.166  loss_mask_5: 2.126  loss_mask_6: 2.138  loss_mask_7: 2.175  loss_mask_8: 2.173  time: 2.9900  data_time: 0.0644  lr: 5.0785e-05  max_mem: 27646M
[01/30 03:29:21] d2.utils.events INFO:  eta: 23:16:31  iter: 31759  total_loss: 19.71  loss_mask: 1.966  loss_mask_0: 2.003  loss_mask_1: 1.971  loss_mask_2: 1.968  loss_mask_3: 1.963  loss_mask_4: 1.97  loss_mask_5: 1.961  loss_mask_6: 1.972  loss_mask_7: 1.972  loss_mask_8: 1.967  time: 2.9900  data_time: 0.0577  lr: 5.0752e-05  max_mem: 27646M
[01/30 03:30:21] d2.utils.events INFO:  eta: 23:16:33  iter: 31779  total_loss: 20.36  loss_mask: 2.02  loss_mask_0: 2.119  loss_mask_1: 2.024  loss_mask_2: 2.028  loss_mask_3: 2.032  loss_mask_4: 2.035  loss_mask_5: 2.022  loss_mask_6: 2.017  loss_mask_7: 2.034  loss_mask_8: 2.034  time: 2.9900  data_time: 0.0764  lr: 5.072e-05  max_mem: 27646M
[01/30 03:31:20] d2.utils.events INFO:  eta: 23:15:42  iter: 31799  total_loss: 20.33  loss_mask: 2.027  loss_mask_0: 2.058  loss_mask_1: 2.032  loss_mask_2: 2.033  loss_mask_3: 2.032  loss_mask_4: 2.03  loss_mask_5: 2.031  loss_mask_6: 2.023  loss_mask_7: 2.025  loss_mask_8: 2.034  time: 2.9900  data_time: 0.0537  lr: 5.0688e-05  max_mem: 27646M
[01/30 03:32:20] d2.utils.events INFO:  eta: 23:14:22  iter: 31819  total_loss: 20.67  loss_mask: 2.065  loss_mask_0: 2.093  loss_mask_1: 2.052  loss_mask_2: 2.061  loss_mask_3: 2.059  loss_mask_4: 2.065  loss_mask_5: 2.07  loss_mask_6: 2.058  loss_mask_7: 2.069  loss_mask_8: 2.076  time: 2.9900  data_time: 0.0531  lr: 5.0655e-05  max_mem: 27646M
[01/30 03:33:19] d2.utils.events INFO:  eta: 23:13:48  iter: 31839  total_loss: 20.2  loss_mask: 2.044  loss_mask_0: 2.058  loss_mask_1: 2.015  loss_mask_2: 2.008  loss_mask_3: 2.015  loss_mask_4: 2.022  loss_mask_5: 2.013  loss_mask_6: 2.024  loss_mask_7: 2.024  loss_mask_8: 2.009  time: 2.9899  data_time: 0.0584  lr: 5.0623e-05  max_mem: 27646M
[01/30 03:34:18] d2.utils.events INFO:  eta: 23:12:44  iter: 31859  total_loss: 19.45  loss_mask: 1.92  loss_mask_0: 2.019  loss_mask_1: 1.946  loss_mask_2: 1.939  loss_mask_3: 1.93  loss_mask_4: 1.942  loss_mask_5: 1.927  loss_mask_6: 1.915  loss_mask_7: 1.972  loss_mask_8: 1.937  time: 2.9899  data_time: 0.0529  lr: 5.0591e-05  max_mem: 27646M
[01/30 03:35:17] d2.utils.events INFO:  eta: 23:12:05  iter: 31879  total_loss: 21.56  loss_mask: 2.158  loss_mask_0: 2.195  loss_mask_1: 2.124  loss_mask_2: 2.14  loss_mask_3: 2.141  loss_mask_4: 2.15  loss_mask_5: 2.127  loss_mask_6: 2.16  loss_mask_7: 2.162  loss_mask_8: 2.147  time: 2.9899  data_time: 0.0610  lr: 5.0558e-05  max_mem: 27646M
[01/30 03:36:17] d2.utils.events INFO:  eta: 23:11:26  iter: 31899  total_loss: 20.93  loss_mask: 2.077  loss_mask_0: 2.16  loss_mask_1: 2.082  loss_mask_2: 2.089  loss_mask_3: 2.094  loss_mask_4: 2.095  loss_mask_5: 2.079  loss_mask_6: 2.073  loss_mask_7: 2.091  loss_mask_8: 2.1  time: 2.9899  data_time: 0.0626  lr: 5.0526e-05  max_mem: 27646M
[01/30 03:37:16] d2.utils.events INFO:  eta: 23:10:06  iter: 31919  total_loss: 19.2  loss_mask: 1.92  loss_mask_0: 1.941  loss_mask_1: 1.905  loss_mask_2: 1.922  loss_mask_3: 1.918  loss_mask_4: 1.924  loss_mask_5: 1.911  loss_mask_6: 1.912  loss_mask_7: 1.928  loss_mask_8: 1.917  time: 2.9899  data_time: 0.0555  lr: 5.0493e-05  max_mem: 27646M
[01/30 03:38:17] d2.utils.events INFO:  eta: 23:09:12  iter: 31939  total_loss: 21.13  loss_mask: 2.094  loss_mask_0: 2.137  loss_mask_1: 2.086  loss_mask_2: 2.113  loss_mask_3: 2.118  loss_mask_4: 2.121  loss_mask_5: 2.083  loss_mask_6: 2.084  loss_mask_7: 2.106  loss_mask_8: 2.117  time: 2.9899  data_time: 0.0832  lr: 5.0461e-05  max_mem: 27646M
[01/30 03:39:16] d2.utils.events INFO:  eta: 23:08:30  iter: 31959  total_loss: 23  loss_mask: 2.292  loss_mask_0: 2.353  loss_mask_1: 2.261  loss_mask_2: 2.297  loss_mask_3: 2.31  loss_mask_4: 2.305  loss_mask_5: 2.289  loss_mask_6: 2.285  loss_mask_7: 2.305  loss_mask_8: 2.305  time: 2.9899  data_time: 0.0677  lr: 5.0429e-05  max_mem: 27646M
[01/30 03:40:16] d2.utils.events INFO:  eta: 23:07:28  iter: 31979  total_loss: 20.54  loss_mask: 2.045  loss_mask_0: 2.093  loss_mask_1: 2.054  loss_mask_2: 2.054  loss_mask_3: 2.055  loss_mask_4: 2.053  loss_mask_5: 2.042  loss_mask_6: 2.04  loss_mask_7: 2.053  loss_mask_8: 2.049  time: 2.9899  data_time: 0.0637  lr: 5.0396e-05  max_mem: 27646M
[01/30 03:41:16] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 03:41:17] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 03:41:17] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 03:55:47] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.4617937448008917, 'error_1pix': 0.38954080887782105, 'error_3pix': 0.14503418915283475, 'mIoU': 6.919280654188137, 'fwIoU': 17.339106879286316, 'IoU-0': 5.949224853184285e-05, 'IoU-1': 70.60236374590599, 'IoU-2': 2.480428463541818, 'IoU-3': 3.3910761428011424, 'IoU-4': 4.541648059690076, 'IoU-5': 4.86692387364258, 'IoU-6': 4.793083269386601, 'IoU-7': 3.9418869631910303, 'IoU-8': 3.0950527943678363, 'IoU-9': 5.333485882423958, 'IoU-10': 7.143640331655722, 'IoU-11': 10.608108477508546, 'IoU-12': 10.696857047512083, 'IoU-13': 11.3239228886609, 'IoU-14': 10.891298310536254, 'IoU-15': 10.260170431843056, 'IoU-16': 9.937451764279292, 'IoU-17': 9.564665232662312, 'IoU-18': 11.518687273664547, 'IoU-19': 12.911094920178279, 'IoU-20': 13.619089134213954, 'IoU-21': 13.11848505892314, 'IoU-22': 13.436649727734403, 'IoU-23': 12.577025868950601, 'IoU-24': 12.354142002095339, 'IoU-25': 13.145490682478341, 'IoU-26': 13.20207931861942, 'IoU-27': 14.140682552198008, 'IoU-28': 14.216329576328496, 'IoU-29': 14.219354194713594, 'IoU-30': 13.984227470505529, 'IoU-31': 14.523851490181489, 'IoU-32': 14.458369668686924, 'IoU-33': 13.91874101538742, 'IoU-34': 13.751606395224636, 'IoU-35': 13.967607704429982, 'IoU-36': 14.456114601928341, 'IoU-37': 14.062772416852024, 'IoU-38': 14.457835169795926, 'IoU-39': 14.80817441245818, 'IoU-40': 15.748022965630462, 'IoU-41': 14.550558081102036, 'IoU-42': 14.560122353657967, 'IoU-43': 14.377126306167428, 'IoU-44': 15.019730322948547, 'IoU-45': 14.483744273762833, 'IoU-46': 13.891537841671909, 'IoU-47': 13.935314881863828, 'IoU-48': 13.867315708909128, 'IoU-49': 13.710067785460522, 'IoU-50': 14.017689088534693, 'IoU-51': 13.318101651655661, 'IoU-52': 12.844267723102659, 'IoU-53': 12.867516117683339, 'IoU-54': 12.670540479291608, 'IoU-55': 12.335892131683492, 'IoU-56': 11.354047104476994, 'IoU-57': 11.363370657032272, 'IoU-58': 11.205125405791348, 'IoU-59': 11.182583613559096, 'IoU-60': 10.977539541292291, 'IoU-61': 10.694003008810153, 'IoU-62': 10.411426175369112, 'IoU-63': 10.399934120714832, 'IoU-64': 9.998723515942402, 'IoU-65': 9.711675149063574, 'IoU-66': 9.005145468661734, 'IoU-67': 8.618262783436556, 'IoU-68': 8.775093369747859, 'IoU-69': 8.803370229103722, 'IoU-70': 8.470718098766087, 'IoU-71': 8.17669138400041, 'IoU-72': 8.098328122944388, 'IoU-73': 7.999571358080482, 'IoU-74': 8.172789295303492, 'IoU-75': 7.871659704507607, 'IoU-76': 8.026413744944414, 'IoU-77': 7.849608388905346, 'IoU-78': 7.803596063717191, 'IoU-79': 7.639655335819834, 'IoU-80': 7.674352667468398, 'IoU-81': 7.6370924207557325, 'IoU-82': 7.302946886970182, 'IoU-83': 7.193770690355124, 'IoU-84': 7.064030984975286, 'IoU-85': 6.910751560573666, 'IoU-86': 6.7407759114599, 'IoU-87': 6.761385389539541, 'IoU-88': 6.717836699425052, 'IoU-89': 6.5847293763427235, 'IoU-90': 6.5829567476642685, 'IoU-91': 6.37172532330379, 'IoU-92': 6.307321119053219, 'IoU-93': 6.288269542352697, 'IoU-94': 6.256648467406205, 'IoU-95': 6.169568948014616, 'IoU-96': 6.38998329694996, 'IoU-97': 6.435833492322432, 'IoU-98': 6.275278955406255, 'IoU-99': 5.855458317122969, 'IoU-100': 5.631079116103903, 'IoU-101': 5.481048785164388, 'IoU-102': 5.26591544973473, 'IoU-103': 5.106494760332378, 'IoU-104': 4.962601814360836, 'IoU-105': 5.029608075070162, 'IoU-106': 5.042177001766927, 'IoU-107': 5.125867509819063, 'IoU-108': 4.991495767199491, 'IoU-109': 5.124851120565238, 'IoU-110': 5.2577180511264014, 'IoU-111': 4.963473603959303, 'IoU-112': 4.7508501465740105, 'IoU-113': 4.791975212322507, 'IoU-114': 4.828416023417325, 'IoU-115': 4.6820358683272385, 'IoU-116': 4.366826940148426, 'IoU-117': 4.208615169973965, 'IoU-118': 4.0121462927562215, 'IoU-119': 4.185108333906095, 'IoU-120': 4.245212677904235, 'IoU-121': 3.99956501301453, 'IoU-122': 3.9752299718312596, 'IoU-123': 3.7992414552092417, 'IoU-124': 3.5796653658011093, 'IoU-125': 3.3319633598070957, 'IoU-126': 3.4645426422694157, 'IoU-127': 3.4991631341487714, 'IoU-128': 3.5029628243512976, 'IoU-129': 3.309251396720085, 'IoU-130': 3.1844058256257814, 'IoU-131': 3.100015911784254, 'IoU-132': 3.321679475031241, 'IoU-133': 3.326299005485934, 'IoU-134': 3.359772294788615, 'IoU-135': 3.1618804054751473, 'IoU-136': 2.9333979483210246, 'IoU-137': 2.855477459418638, 'IoU-138': 2.9720094186316453, 'IoU-139': 2.7899339827464944, 'IoU-140': 3.151657878886001, 'IoU-141': 3.011203738119259, 'IoU-142': 2.956072810622024, 'IoU-143': 3.00566037043021, 'IoU-144': 3.101336688114108, 'IoU-145': 2.810876393153685, 'IoU-146': 3.027697848422591, 'IoU-147': 3.3965621832191824, 'IoU-148': 2.9753664360708587, 'IoU-149': 3.0797862341219755, 'IoU-150': 3.111704903890073, 'IoU-151': 2.8585660002282487, 'IoU-152': 3.102019638298492, 'IoU-153': 2.6566708338784344, 'IoU-154': 2.496660548342767, 'IoU-155': 2.4294717942365733, 'IoU-156': 2.4829286427048074, 'IoU-157': 2.5549493783769606, 'IoU-158': 2.4200519145526846, 'IoU-159': 2.300974589278301, 'IoU-160': 2.347134078775058, 'IoU-161': 2.313790486840529, 'IoU-162': 2.054996110003567, 'IoU-163': 1.8128062868619244, 'IoU-164': 1.8398844033118806, 'IoU-165': 1.9915251740918356, 'IoU-166': 2.0318242919680154, 'IoU-167': 2.002547713975372, 'IoU-168': 1.9433174714517731, 'IoU-169': 2.1195186330118236, 'IoU-170': 1.8619798316290654, 'IoU-171': 1.646511517510651, 'IoU-172': 1.723390321386587, 'IoU-173': 1.5977227375870102, 'IoU-174': 1.7627551262465722, 'IoU-175': 1.5798413628701404, 'IoU-176': 1.7347780421663512, 'IoU-177': 1.6849753691071463, 'IoU-178': 1.6884447153280229, 'IoU-179': 2.010190970887647, 'IoU-180': 1.3643145645082968, 'IoU-181': 1.97998123240538, 'IoU-182': 1.6273278409753031, 'IoU-183': 1.5669925159535505, 'IoU-184': 1.7748278807915352, 'IoU-185': 1.6784580420630402, 'IoU-186': 2.231259168106805, 'IoU-187': 0.35174695456823063, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 12.974869323161956, 'pACC': 25.62429447587366, 'ACC-0': 7.754439241991158e-05, 'ACC-1': 71.68159408454143, 'ACC-2': 21.507981587324128, 'ACC-3': 22.588393787651558, 'ACC-4': 20.22469047398748, 'ACC-5': 20.089545690554463, 'ACC-6': 19.23937244432487, 'ACC-7': 15.62947810582277, 'ACC-8': 5.994667803728096, 'ACC-9': 7.040876650994535, 'ACC-10': 9.272777486157018, 'ACC-11': 13.701470432151709, 'ACC-12': 16.536813016034326, 'ACC-13': 19.582738711859456, 'ACC-14': 19.831302519254248, 'ACC-15': 19.669405227560762, 'ACC-16': 19.134267726580326, 'ACC-17': 19.095098013937363, 'ACC-18': 21.513839269657982, 'ACC-19': 23.80421141759712, 'ACC-20': 25.15594762554144, 'ACC-21': 23.416588157698925, 'ACC-22': 23.37552808882449, 'ACC-23': 23.55929933448822, 'ACC-24': 22.983119702778605, 'ACC-25': 24.09285989400394, 'ACC-26': 23.923267392595104, 'ACC-27': 24.70367071572909, 'ACC-28': 26.029487639744698, 'ACC-29': 24.81519683223603, 'ACC-30': 24.862219877841724, 'ACC-31': 25.267321452612705, 'ACC-32': 25.87173658588715, 'ACC-33': 25.40858723249469, 'ACC-34': 24.58758260097108, 'ACC-35': 24.607302394310864, 'ACC-36': 25.66897535800463, 'ACC-37': 25.44476221483794, 'ACC-38': 26.170308145143423, 'ACC-39': 27.017163250264982, 'ACC-40': 28.241138609406867, 'ACC-41': 26.669098768963227, 'ACC-42': 26.391806099772623, 'ACC-43': 25.94436683848794, 'ACC-44': 26.49079516532507, 'ACC-45': 25.694429439666227, 'ACC-46': 25.20345842909788, 'ACC-47': 25.282259667178735, 'ACC-48': 25.168430694166986, 'ACC-49': 24.68398048539344, 'ACC-50': 25.21516588284815, 'ACC-51': 24.32502711958076, 'ACC-52': 23.225698051914115, 'ACC-53': 23.214690054126148, 'ACC-54': 22.66259807374823, 'ACC-55': 22.060856163033904, 'ACC-56': 20.446685671934457, 'ACC-57': 19.93124217740793, 'ACC-58': 20.01226980436748, 'ACC-59': 20.211028336895442, 'ACC-60': 19.975422054538157, 'ACC-61': 19.666463777832384, 'ACC-62': 19.246543869254122, 'ACC-63': 19.486386750424618, 'ACC-64': 18.703410168152498, 'ACC-65': 18.132516802373228, 'ACC-66': 16.79792692733657, 'ACC-67': 16.246968995140023, 'ACC-68': 16.564492489494114, 'ACC-69': 16.371185417198255, 'ACC-70': 15.499485525016532, 'ACC-71': 15.21308424301797, 'ACC-72': 15.095089122248087, 'ACC-73': 14.896628566907793, 'ACC-74': 15.169264316028464, 'ACC-75': 14.602228364195474, 'ACC-76': 14.660055097118946, 'ACC-77': 14.66206977256487, 'ACC-78': 14.660964516181272, 'ACC-79': 14.526806408414755, 'ACC-80': 14.561366396589893, 'ACC-81': 14.448015937649927, 'ACC-82': 13.772086294543035, 'ACC-83': 13.284357321733065, 'ACC-84': 13.034051327813625, 'ACC-85': 12.791751320319236, 'ACC-86': 12.5606802376634, 'ACC-87': 12.661619631805765, 'ACC-88': 12.605980107198617, 'ACC-89': 12.256677993708092, 'ACC-90': 12.067068099820544, 'ACC-91': 11.725924851424763, 'ACC-92': 11.64311069380449, 'ACC-93': 11.611967216423432, 'ACC-94': 11.61788622336401, 'ACC-95': 11.54585433265443, 'ACC-96': 12.121263594592987, 'ACC-97': 12.18030865139178, 'ACC-98': 11.815571168322352, 'ACC-99': 11.092928378202217, 'ACC-100': 10.532179050834978, 'ACC-101': 10.248361764943576, 'ACC-102': 9.827548708654282, 'ACC-103': 9.557240011334656, 'ACC-104': 9.356557881016208, 'ACC-105': 9.468373672057904, 'ACC-106': 9.41876268671315, 'ACC-107': 9.557012562606339, 'ACC-108': 9.212677221345077, 'ACC-109': 9.44759831207839, 'ACC-110': 9.880828106007252, 'ACC-111': 9.379384564952439, 'ACC-112': 9.157385960592283, 'ACC-113': 9.318428896159627, 'ACC-114': 9.502780068637101, 'ACC-115': 9.125584472208441, 'ACC-116': 8.506762397204174, 'ACC-117': 8.145487480380961, 'ACC-118': 7.914230903427262, 'ACC-119': 8.122110007261304, 'ACC-120': 8.177927239376338, 'ACC-121': 7.767937075626344, 'ACC-122': 7.719390113881891, 'ACC-123': 7.305755828756051, 'ACC-124': 7.010224809426877, 'ACC-125': 6.499010728080204, 'ACC-126': 6.738961648102442, 'ACC-127': 6.819636666074816, 'ACC-128': 6.849630011794251, 'ACC-129': 6.441556290040093, 'ACC-130': 6.256529848339838, 'ACC-131': 6.072453683858649, 'ACC-132': 6.411583945739629, 'ACC-133': 6.450019392108433, 'ACC-134': 6.449495906936666, 'ACC-135': 6.0686391881876744, 'ACC-136': 5.578526835631756, 'ACC-137': 5.451387060311384, 'ACC-138': 5.68666395918471, 'ACC-139': 5.385516575896923, 'ACC-140': 6.054213524558256, 'ACC-141': 5.726942685129237, 'ACC-142': 5.6945437841302775, 'ACC-143': 5.884245268692271, 'ACC-144': 5.947202166064982, 'ACC-145': 5.300923544801986, 'ACC-146': 5.648214571291494, 'ACC-147': 6.337425938942396, 'ACC-148': 5.5689315441932, 'ACC-149': 5.815110301611753, 'ACC-150': 5.872365174810743, 'ACC-151': 5.419153922643808, 'ACC-152': 5.8332701126171695, 'ACC-153': 5.1857170340240755, 'ACC-154': 4.880780868578916, 'ACC-155': 4.883240522305461, 'ACC-156': 5.085613449940856, 'ACC-157': 5.303150940545749, 'ACC-158': 5.243518109493882, 'ACC-159': 4.824532801038881, 'ACC-160': 4.941354114826042, 'ACC-161': 4.881107176256821, 'ACC-162': 4.310609013362055, 'ACC-163': 3.834494861403892, 'ACC-164': 3.948832917405243, 'ACC-165': 4.294898468047531, 'ACC-166': 4.430584818393197, 'ACC-167': 4.374751375361103, 'ACC-168': 4.325374498909909, 'ACC-169': 4.807569140171927, 'ACC-170': 4.205708647443815, 'ACC-171': 3.822677435531007, 'ACC-172': 3.923398896173649, 'ACC-173': 3.9980733989832666, 'ACC-174': 4.1554127732389405, 'ACC-175': 3.6231763481296184, 'ACC-176': 4.242367076851637, 'ACC-177': 4.36433898230015, 'ACC-178': 4.607203632914889, 'ACC-179': 7.427756395559983, 'ACC-180': 4.58489959023333, 'ACC-181': 8.396398701031075, 'ACC-182': 6.980755243562377, 'ACC-183': 6.250014714503322, 'ACC-184': 6.477334635167929, 'ACC-185': 6.0672828642563825, 'ACC-186': 5.281943660841381, 'ACC-187': 0.5122072023097646, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 03:55:47] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 03:55:47] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 03:55:47] d2.evaluation.testing INFO: copypaste: 2.4618,0.3895,0.1450,6.9193,17.3391,12.9749,25.6243
[01/30 03:55:47] d2.utils.events INFO:  eta: 23:06:26  iter: 31999  total_loss: 21.63  loss_mask: 2.164  loss_mask_0: 2.186  loss_mask_1: 2.151  loss_mask_2: 2.175  loss_mask_3: 2.164  loss_mask_4: 2.168  loss_mask_5: 2.166  loss_mask_6: 2.159  loss_mask_7: 2.161  loss_mask_8: 2.171  time: 2.9899  data_time: 0.0591  lr: 5.0364e-05  max_mem: 27646M
[01/30 03:56:46] d2.utils.events INFO:  eta: 23:05:16  iter: 32019  total_loss: 19.54  loss_mask: 1.96  loss_mask_0: 1.957  loss_mask_1: 1.936  loss_mask_2: 1.957  loss_mask_3: 1.955  loss_mask_4: 1.959  loss_mask_5: 1.944  loss_mask_6: 1.941  loss_mask_7: 1.95  loss_mask_8: 1.954  time: 2.9899  data_time: 0.0574  lr: 5.0332e-05  max_mem: 27646M
[01/30 03:57:46] d2.utils.events INFO:  eta: 23:04:17  iter: 32039  total_loss: 21.65  loss_mask: 2.146  loss_mask_0: 2.201  loss_mask_1: 2.14  loss_mask_2: 2.165  loss_mask_3: 2.162  loss_mask_4: 2.165  loss_mask_5: 2.159  loss_mask_6: 2.152  loss_mask_7: 2.165  loss_mask_8: 2.172  time: 2.9899  data_time: 0.0605  lr: 5.0299e-05  max_mem: 27646M
[01/30 03:58:45] d2.utils.events INFO:  eta: 23:03:16  iter: 32059  total_loss: 19.5  loss_mask: 1.951  loss_mask_0: 2.055  loss_mask_1: 1.913  loss_mask_2: 1.946  loss_mask_3: 1.943  loss_mask_4: 1.983  loss_mask_5: 1.924  loss_mask_6: 1.944  loss_mask_7: 1.959  loss_mask_8: 1.937  time: 2.9898  data_time: 0.0677  lr: 5.0267e-05  max_mem: 27646M
[01/30 03:59:45] d2.utils.events INFO:  eta: 23:02:36  iter: 32079  total_loss: 19.77  loss_mask: 1.971  loss_mask_0: 2.009  loss_mask_1: 1.966  loss_mask_2: 1.971  loss_mask_3: 1.969  loss_mask_4: 1.978  loss_mask_5: 1.965  loss_mask_6: 1.964  loss_mask_7: 1.974  loss_mask_8: 1.978  time: 2.9898  data_time: 0.0736  lr: 5.0234e-05  max_mem: 27646M
[01/30 04:00:44] d2.utils.events INFO:  eta: 23:01:32  iter: 32099  total_loss: 19.82  loss_mask: 1.985  loss_mask_0: 2.028  loss_mask_1: 1.975  loss_mask_2: 1.97  loss_mask_3: 1.968  loss_mask_4: 1.986  loss_mask_5: 1.985  loss_mask_6: 1.98  loss_mask_7: 1.977  loss_mask_8: 1.981  time: 2.9898  data_time: 0.0561  lr: 5.0202e-05  max_mem: 27646M
[01/30 04:01:44] d2.utils.events INFO:  eta: 23:01:32  iter: 32119  total_loss: 20.18  loss_mask: 2.001  loss_mask_0: 2.051  loss_mask_1: 1.995  loss_mask_2: 2.011  loss_mask_3: 2.01  loss_mask_4: 2.02  loss_mask_5: 2.003  loss_mask_6: 2.002  loss_mask_7: 2.016  loss_mask_8: 2.014  time: 2.9898  data_time: 0.0662  lr: 5.017e-05  max_mem: 27646M
[01/30 04:02:43] d2.utils.events INFO:  eta: 23:00:33  iter: 32139  total_loss: 20.39  loss_mask: 2.032  loss_mask_0: 2.066  loss_mask_1: 2.025  loss_mask_2: 2.034  loss_mask_3: 2.043  loss_mask_4: 2.038  loss_mask_5: 2.034  loss_mask_6: 2.033  loss_mask_7: 2.038  loss_mask_8: 2.049  time: 2.9898  data_time: 0.0579  lr: 5.0137e-05  max_mem: 27646M
[01/30 04:03:42] d2.utils.events INFO:  eta: 22:59:45  iter: 32159  total_loss: 20.71  loss_mask: 2.064  loss_mask_0: 2.116  loss_mask_1: 2.064  loss_mask_2: 2.071  loss_mask_3: 2.069  loss_mask_4: 2.076  loss_mask_5: 2.063  loss_mask_6: 2.065  loss_mask_7: 2.063  loss_mask_8: 2.069  time: 2.9898  data_time: 0.0668  lr: 5.0105e-05  max_mem: 27646M
[01/30 04:04:42] d2.utils.events INFO:  eta: 22:59:03  iter: 32179  total_loss: 19.94  loss_mask: 1.987  loss_mask_0: 2.056  loss_mask_1: 1.991  loss_mask_2: 1.997  loss_mask_3: 1.999  loss_mask_4: 2.006  loss_mask_5: 1.983  loss_mask_6: 1.978  loss_mask_7: 1.997  loss_mask_8: 1.999  time: 2.9898  data_time: 0.0576  lr: 5.0073e-05  max_mem: 27646M
[01/30 04:05:41] d2.utils.events INFO:  eta: 22:58:03  iter: 32199  total_loss: 20.43  loss_mask: 2.045  loss_mask_0: 2.103  loss_mask_1: 2.028  loss_mask_2: 2.073  loss_mask_3: 2.058  loss_mask_4: 2.043  loss_mask_5: 2.034  loss_mask_6: 2.04  loss_mask_7: 2.057  loss_mask_8: 2.057  time: 2.9898  data_time: 0.0568  lr: 5.004e-05  max_mem: 27646M
[01/30 04:06:41] d2.utils.events INFO:  eta: 22:57:09  iter: 32219  total_loss: 19.85  loss_mask: 1.971  loss_mask_0: 1.967  loss_mask_1: 1.938  loss_mask_2: 1.982  loss_mask_3: 1.984  loss_mask_4: 1.99  loss_mask_5: 1.976  loss_mask_6: 1.964  loss_mask_7: 1.981  loss_mask_8: 1.983  time: 2.9898  data_time: 0.0634  lr: 5.0008e-05  max_mem: 27646M
[01/30 04:07:40] d2.utils.events INFO:  eta: 22:56:04  iter: 32239  total_loss: 19.77  loss_mask: 1.968  loss_mask_0: 2.006  loss_mask_1: 1.963  loss_mask_2: 1.979  loss_mask_3: 1.979  loss_mask_4: 1.976  loss_mask_5: 1.969  loss_mask_6: 1.965  loss_mask_7: 1.985  loss_mask_8: 1.985  time: 2.9897  data_time: 0.0558  lr: 4.9975e-05  max_mem: 27646M
[01/30 04:08:40] d2.utils.events INFO:  eta: 22:55:05  iter: 32259  total_loss: 19.43  loss_mask: 1.931  loss_mask_0: 2.004  loss_mask_1: 1.935  loss_mask_2: 1.961  loss_mask_3: 1.935  loss_mask_4: 1.926  loss_mask_5: 1.954  loss_mask_6: 1.939  loss_mask_7: 1.926  loss_mask_8: 1.958  time: 2.9898  data_time: 0.0680  lr: 4.9943e-05  max_mem: 27646M
[01/30 04:09:40] d2.utils.events INFO:  eta: 22:54:15  iter: 32279  total_loss: 19.98  loss_mask: 1.988  loss_mask_0: 2.009  loss_mask_1: 1.981  loss_mask_2: 1.993  loss_mask_3: 2.007  loss_mask_4: 2.002  loss_mask_5: 1.985  loss_mask_6: 1.984  loss_mask_7: 1.997  loss_mask_8: 1.997  time: 2.9898  data_time: 0.0608  lr: 4.991e-05  max_mem: 27646M
[01/30 04:10:39] d2.utils.events INFO:  eta: 22:53:06  iter: 32299  total_loss: 18.09  loss_mask: 1.797  loss_mask_0: 1.856  loss_mask_1: 1.783  loss_mask_2: 1.802  loss_mask_3: 1.815  loss_mask_4: 1.831  loss_mask_5: 1.787  loss_mask_6: 1.793  loss_mask_7: 1.823  loss_mask_8: 1.809  time: 2.9897  data_time: 0.0583  lr: 4.9878e-05  max_mem: 27646M
[01/30 04:11:40] d2.utils.events INFO:  eta: 22:52:25  iter: 32319  total_loss: 19.7  loss_mask: 1.946  loss_mask_0: 2.024  loss_mask_1: 1.967  loss_mask_2: 1.966  loss_mask_3: 1.97  loss_mask_4: 1.974  loss_mask_5: 1.945  loss_mask_6: 1.952  loss_mask_7: 1.978  loss_mask_8: 1.963  time: 2.9898  data_time: 0.0775  lr: 4.9846e-05  max_mem: 27646M
[01/30 04:12:40] d2.utils.events INFO:  eta: 22:51:50  iter: 32339  total_loss: 20.51  loss_mask: 2.027  loss_mask_0: 2.111  loss_mask_1: 2.035  loss_mask_2: 2.049  loss_mask_3: 2.055  loss_mask_4: 2.064  loss_mask_5: 2.031  loss_mask_6: 2.035  loss_mask_7: 2.054  loss_mask_8: 2.049  time: 2.9898  data_time: 0.0636  lr: 4.9813e-05  max_mem: 27646M
[01/30 04:13:39] d2.utils.events INFO:  eta: 22:50:59  iter: 32359  total_loss: 20.28  loss_mask: 2.016  loss_mask_0: 2.034  loss_mask_1: 2.012  loss_mask_2: 2.042  loss_mask_3: 2.029  loss_mask_4: 2.025  loss_mask_5: 2.01  loss_mask_6: 2.012  loss_mask_7: 2.049  loss_mask_8: 2.026  time: 2.9898  data_time: 0.0616  lr: 4.9781e-05  max_mem: 27646M
[01/30 04:14:38] d2.utils.events INFO:  eta: 22:49:53  iter: 32379  total_loss: 20.2  loss_mask: 2.015  loss_mask_0: 2.038  loss_mask_1: 2.013  loss_mask_2: 2.02  loss_mask_3: 2.024  loss_mask_4: 2.015  loss_mask_5: 2.018  loss_mask_6: 2.019  loss_mask_7: 2.02  loss_mask_8: 2.015  time: 2.9897  data_time: 0.0605  lr: 4.9748e-05  max_mem: 27646M
[01/30 04:15:37] d2.utils.events INFO:  eta: 22:48:27  iter: 32399  total_loss: 19.94  loss_mask: 1.98  loss_mask_0: 2.09  loss_mask_1: 1.97  loss_mask_2: 1.986  loss_mask_3: 1.991  loss_mask_4: 1.993  loss_mask_5: 1.971  loss_mask_6: 1.972  loss_mask_7: 1.98  loss_mask_8: 1.986  time: 2.9897  data_time: 0.0559  lr: 4.9716e-05  max_mem: 27646M
[01/30 04:16:37] d2.utils.events INFO:  eta: 22:46:57  iter: 32419  total_loss: 21.35  loss_mask: 2.118  loss_mask_0: 2.165  loss_mask_1: 2.125  loss_mask_2: 2.155  loss_mask_3: 2.124  loss_mask_4: 2.157  loss_mask_5: 2.122  loss_mask_6: 2.129  loss_mask_7: 2.161  loss_mask_8: 2.165  time: 2.9897  data_time: 0.0620  lr: 4.9684e-05  max_mem: 27646M
[01/30 04:17:36] d2.utils.events INFO:  eta: 22:45:52  iter: 32439  total_loss: 21.58  loss_mask: 2.156  loss_mask_0: 2.196  loss_mask_1: 2.146  loss_mask_2: 2.144  loss_mask_3: 2.153  loss_mask_4: 2.144  loss_mask_5: 2.135  loss_mask_6: 2.14  loss_mask_7: 2.143  loss_mask_8: 2.149  time: 2.9897  data_time: 0.0617  lr: 4.9651e-05  max_mem: 27646M
[01/30 04:18:36] d2.utils.events INFO:  eta: 22:45:46  iter: 32459  total_loss: 21.35  loss_mask: 2.11  loss_mask_0: 2.176  loss_mask_1: 2.115  loss_mask_2: 2.131  loss_mask_3: 2.132  loss_mask_4: 2.137  loss_mask_5: 2.121  loss_mask_6: 2.138  loss_mask_7: 2.134  loss_mask_8: 2.138  time: 2.9897  data_time: 0.0647  lr: 4.9619e-05  max_mem: 27646M
[01/30 04:19:36] d2.utils.events INFO:  eta: 22:44:49  iter: 32479  total_loss: 20.52  loss_mask: 2.059  loss_mask_0: 2.125  loss_mask_1: 2.039  loss_mask_2: 2.042  loss_mask_3: 2.039  loss_mask_4: 2.039  loss_mask_5: 2.047  loss_mask_6: 2.045  loss_mask_7: 2.042  loss_mask_8: 2.042  time: 2.9897  data_time: 0.0623  lr: 4.9586e-05  max_mem: 27646M
[01/30 04:20:37] d2.utils.events INFO:  eta: 22:44:06  iter: 32499  total_loss: 20.08  loss_mask: 2.019  loss_mask_0: 2.093  loss_mask_1: 1.987  loss_mask_2: 2.004  loss_mask_3: 2.003  loss_mask_4: 2.006  loss_mask_5: 1.996  loss_mask_6: 1.994  loss_mask_7: 1.999  loss_mask_8: 2.005  time: 2.9897  data_time: 0.0817  lr: 4.9554e-05  max_mem: 27646M
[01/30 04:21:37] d2.utils.events INFO:  eta: 22:43:39  iter: 32519  total_loss: 20.57  loss_mask: 2.04  loss_mask_0: 2.052  loss_mask_1: 2.04  loss_mask_2: 2.077  loss_mask_3: 2.063  loss_mask_4: 2.056  loss_mask_5: 2.06  loss_mask_6: 2.075  loss_mask_7: 2.079  loss_mask_8: 2.069  time: 2.9897  data_time: 0.0671  lr: 4.9521e-05  max_mem: 27646M
[01/30 04:22:36] d2.utils.events INFO:  eta: 22:42:07  iter: 32539  total_loss: 19.27  loss_mask: 1.923  loss_mask_0: 1.975  loss_mask_1: 1.919  loss_mask_2: 1.933  loss_mask_3: 1.93  loss_mask_4: 1.929  loss_mask_5: 1.92  loss_mask_6: 1.924  loss_mask_7: 1.93  loss_mask_8: 1.932  time: 2.9897  data_time: 0.0666  lr: 4.9489e-05  max_mem: 27646M
[01/30 04:23:36] d2.utils.events INFO:  eta: 22:41:26  iter: 32559  total_loss: 19.07  loss_mask: 1.913  loss_mask_0: 1.936  loss_mask_1: 1.882  loss_mask_2: 1.888  loss_mask_3: 1.908  loss_mask_4: 1.927  loss_mask_5: 1.92  loss_mask_6: 1.907  loss_mask_7: 1.896  loss_mask_8: 1.924  time: 2.9897  data_time: 0.0703  lr: 4.9457e-05  max_mem: 27646M
[01/30 04:24:36] d2.utils.events INFO:  eta: 22:40:19  iter: 32579  total_loss: 22.2  loss_mask: 2.218  loss_mask_0: 2.254  loss_mask_1: 2.212  loss_mask_2: 2.213  loss_mask_3: 2.221  loss_mask_4: 2.208  loss_mask_5: 2.218  loss_mask_6: 2.224  loss_mask_7: 2.226  loss_mask_8: 2.205  time: 2.9897  data_time: 0.0644  lr: 4.9424e-05  max_mem: 27646M
[01/30 04:25:36] d2.utils.events INFO:  eta: 22:39:05  iter: 32599  total_loss: 19.78  loss_mask: 1.972  loss_mask_0: 2.022  loss_mask_1: 1.959  loss_mask_2: 1.988  loss_mask_3: 1.979  loss_mask_4: 1.973  loss_mask_5: 1.974  loss_mask_6: 1.971  loss_mask_7: 1.986  loss_mask_8: 1.968  time: 2.9897  data_time: 0.0562  lr: 4.9392e-05  max_mem: 27646M
[01/30 04:26:35] d2.utils.events INFO:  eta: 22:37:43  iter: 32619  total_loss: 19.54  loss_mask: 1.943  loss_mask_0: 1.997  loss_mask_1: 1.943  loss_mask_2: 1.969  loss_mask_3: 1.954  loss_mask_4: 1.958  loss_mask_5: 1.94  loss_mask_6: 1.942  loss_mask_7: 1.962  loss_mask_8: 1.951  time: 2.9897  data_time: 0.0532  lr: 4.9359e-05  max_mem: 27646M
[01/30 04:27:34] d2.utils.events INFO:  eta: 22:36:44  iter: 32639  total_loss: 19.48  loss_mask: 1.924  loss_mask_0: 2.02  loss_mask_1: 1.936  loss_mask_2: 1.94  loss_mask_3: 1.946  loss_mask_4: 1.948  loss_mask_5: 1.944  loss_mask_6: 1.928  loss_mask_7: 1.945  loss_mask_8: 1.949  time: 2.9897  data_time: 0.0670  lr: 4.9327e-05  max_mem: 27646M
[01/30 04:28:34] d2.utils.events INFO:  eta: 22:36:05  iter: 32659  total_loss: 21.42  loss_mask: 2.133  loss_mask_0: 2.182  loss_mask_1: 2.128  loss_mask_2: 2.141  loss_mask_3: 2.139  loss_mask_4: 2.14  loss_mask_5: 2.134  loss_mask_6: 2.126  loss_mask_7: 2.146  loss_mask_8: 2.14  time: 2.9897  data_time: 0.0634  lr: 4.9294e-05  max_mem: 27646M
[01/30 04:29:34] d2.utils.events INFO:  eta: 22:35:01  iter: 32679  total_loss: 20.68  loss_mask: 2.047  loss_mask_0: 2.133  loss_mask_1: 2.04  loss_mask_2: 2.071  loss_mask_3: 2.082  loss_mask_4: 2.082  loss_mask_5: 2.042  loss_mask_6: 2.044  loss_mask_7: 2.079  loss_mask_8: 2.072  time: 2.9897  data_time: 0.0581  lr: 4.9262e-05  max_mem: 27646M
[01/30 04:30:33] d2.utils.events INFO:  eta: 22:33:26  iter: 32699  total_loss: 19.59  loss_mask: 1.945  loss_mask_0: 2.014  loss_mask_1: 1.939  loss_mask_2: 1.953  loss_mask_3: 1.965  loss_mask_4: 1.964  loss_mask_5: 1.944  loss_mask_6: 1.952  loss_mask_7: 1.955  loss_mask_8: 1.954  time: 2.9896  data_time: 0.0517  lr: 4.9229e-05  max_mem: 27646M
[01/30 04:31:32] d2.utils.events INFO:  eta: 22:32:02  iter: 32719  total_loss: 20.89  loss_mask: 2.081  loss_mask_0: 2.135  loss_mask_1: 2.087  loss_mask_2: 2.095  loss_mask_3: 2.088  loss_mask_4: 2.087  loss_mask_5: 2.093  loss_mask_6: 2.088  loss_mask_7: 2.094  loss_mask_8: 2.093  time: 2.9896  data_time: 0.0634  lr: 4.9197e-05  max_mem: 27646M
[01/30 04:32:32] d2.utils.events INFO:  eta: 22:30:15  iter: 32739  total_loss: 22.96  loss_mask: 2.296  loss_mask_0: 2.308  loss_mask_1: 2.288  loss_mask_2: 2.296  loss_mask_3: 2.292  loss_mask_4: 2.294  loss_mask_5: 2.297  loss_mask_6: 2.293  loss_mask_7: 2.292  loss_mask_8: 2.304  time: 2.9896  data_time: 0.0589  lr: 4.9164e-05  max_mem: 27646M
[01/30 04:33:31] d2.utils.events INFO:  eta: 22:28:36  iter: 32759  total_loss: 23.28  loss_mask: 2.325  loss_mask_0: 2.363  loss_mask_1: 2.298  loss_mask_2: 2.322  loss_mask_3: 2.324  loss_mask_4: 2.327  loss_mask_5: 2.318  loss_mask_6: 2.317  loss_mask_7: 2.316  loss_mask_8: 2.319  time: 2.9896  data_time: 0.0583  lr: 4.9132e-05  max_mem: 27646M
[01/30 04:34:30] d2.utils.events INFO:  eta: 22:27:03  iter: 32779  total_loss: 20.66  loss_mask: 2.068  loss_mask_0: 2.121  loss_mask_1: 2.049  loss_mask_2: 2.06  loss_mask_3: 2.066  loss_mask_4: 2.063  loss_mask_5: 2.063  loss_mask_6: 2.064  loss_mask_7: 2.065  loss_mask_8: 2.063  time: 2.9896  data_time: 0.0641  lr: 4.91e-05  max_mem: 27646M
[01/30 04:35:30] d2.utils.events INFO:  eta: 22:26:26  iter: 32799  total_loss: 21.76  loss_mask: 2.143  loss_mask_0: 2.264  loss_mask_1: 2.16  loss_mask_2: 2.178  loss_mask_3: 2.18  loss_mask_4: 2.18  loss_mask_5: 2.161  loss_mask_6: 2.156  loss_mask_7: 2.187  loss_mask_8: 2.184  time: 2.9896  data_time: 0.0677  lr: 4.9067e-05  max_mem: 27646M
[01/30 04:36:30] d2.utils.events INFO:  eta: 22:25:51  iter: 32819  total_loss: 22.02  loss_mask: 2.204  loss_mask_0: 2.273  loss_mask_1: 2.184  loss_mask_2: 2.175  loss_mask_3: 2.202  loss_mask_4: 2.191  loss_mask_5: 2.187  loss_mask_6: 2.173  loss_mask_7: 2.188  loss_mask_8: 2.197  time: 2.9896  data_time: 0.0659  lr: 4.9035e-05  max_mem: 27646M
[01/30 04:37:30] d2.utils.events INFO:  eta: 22:25:02  iter: 32839  total_loss: 21.82  loss_mask: 2.171  loss_mask_0: 2.212  loss_mask_1: 2.19  loss_mask_2: 2.184  loss_mask_3: 2.18  loss_mask_4: 2.18  loss_mask_5: 2.173  loss_mask_6: 2.163  loss_mask_7: 2.183  loss_mask_8: 2.18  time: 2.9896  data_time: 0.0640  lr: 4.9002e-05  max_mem: 27646M
[01/30 04:38:30] d2.utils.events INFO:  eta: 22:24:35  iter: 32859  total_loss: 20.8  loss_mask: 2.105  loss_mask_0: 2.146  loss_mask_1: 2.043  loss_mask_2: 2.068  loss_mask_3: 2.118  loss_mask_4: 2.071  loss_mask_5: 2.072  loss_mask_6: 2.103  loss_mask_7: 2.066  loss_mask_8: 2.063  time: 2.9896  data_time: 0.0677  lr: 4.897e-05  max_mem: 27646M
[01/30 04:39:31] d2.utils.events INFO:  eta: 22:23:52  iter: 32879  total_loss: 19.72  loss_mask: 1.938  loss_mask_0: 2.039  loss_mask_1: 1.955  loss_mask_2: 1.955  loss_mask_3: 1.971  loss_mask_4: 1.956  loss_mask_5: 2.029  loss_mask_6: 1.942  loss_mask_7: 1.969  loss_mask_8: 1.963  time: 2.9896  data_time: 0.0840  lr: 4.8937e-05  max_mem: 27646M
[01/30 04:40:30] d2.utils.events INFO:  eta: 22:22:25  iter: 32899  total_loss: 21.05  loss_mask: 2.072  loss_mask_0: 2.14  loss_mask_1: 2.076  loss_mask_2: 2.115  loss_mask_3: 2.084  loss_mask_4: 2.108  loss_mask_5: 2.138  loss_mask_6: 2.071  loss_mask_7: 2.126  loss_mask_8: 2.126  time: 2.9896  data_time: 0.0578  lr: 4.8905e-05  max_mem: 27646M
[01/30 04:41:29] d2.utils.events INFO:  eta: 22:21:46  iter: 32919  total_loss: 19.48  loss_mask: 1.964  loss_mask_0: 1.956  loss_mask_1: 1.943  loss_mask_2: 1.934  loss_mask_3: 1.979  loss_mask_4: 1.928  loss_mask_5: 1.945  loss_mask_6: 1.959  loss_mask_7: 1.949  loss_mask_8: 1.934  time: 2.9896  data_time: 0.0776  lr: 4.8872e-05  max_mem: 27646M
[01/30 04:42:29] d2.utils.events INFO:  eta: 22:20:37  iter: 32939  total_loss: 20.02  loss_mask: 2.002  loss_mask_0: 2.041  loss_mask_1: 1.98  loss_mask_2: 2.002  loss_mask_3: 2.01  loss_mask_4: 2.01  loss_mask_5: 1.99  loss_mask_6: 1.995  loss_mask_7: 1.994  loss_mask_8: 2  time: 2.9896  data_time: 0.0594  lr: 4.884e-05  max_mem: 27646M
[01/30 04:43:29] d2.utils.events INFO:  eta: 22:19:21  iter: 32959  total_loss: 21.56  loss_mask: 2.158  loss_mask_0: 2.184  loss_mask_1: 2.145  loss_mask_2: 2.142  loss_mask_3: 2.149  loss_mask_4: 2.16  loss_mask_5: 2.156  loss_mask_6: 2.161  loss_mask_7: 2.153  loss_mask_8: 2.155  time: 2.9896  data_time: 0.0571  lr: 4.8807e-05  max_mem: 27646M
[01/30 04:44:30] d2.utils.events INFO:  eta: 22:18:45  iter: 32979  total_loss: 21.08  loss_mask: 2.078  loss_mask_0: 2.155  loss_mask_1: 2.085  loss_mask_2: 2.125  loss_mask_3: 2.103  loss_mask_4: 2.112  loss_mask_5: 2.084  loss_mask_6: 2.079  loss_mask_7: 2.121  loss_mask_8: 2.135  time: 2.9896  data_time: 0.0668  lr: 4.8775e-05  max_mem: 27646M
[01/30 04:45:30] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 04:45:30] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 04:45:30] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 04:59:55] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.4042064314433573, 'error_1pix': 0.3549900037842158, 'error_3pix': 0.15163176188139574, 'mIoU': 7.978113578748508, 'fwIoU': 20.401057187148446, 'IoU-0': 0.00017216412711585654, 'IoU-1': 64.05006644543482, 'IoU-2': 2.92740035836131, 'IoU-3': 6.0889385534952805, 'IoU-4': 6.248708666085753, 'IoU-5': 4.979750505103005, 'IoU-6': 4.186055618837463, 'IoU-7': 3.10111647171626, 'IoU-8': 9.127903675947673, 'IoU-9': 17.36945063006809, 'IoU-10': 19.759196829138816, 'IoU-11': 25.964731653114132, 'IoU-12': 25.54733099018811, 'IoU-13': 24.58562708477586, 'IoU-14': 25.73979438448729, 'IoU-15': 25.333926905002553, 'IoU-16': 25.495788136162773, 'IoU-17': 23.95587015930966, 'IoU-18': 23.29732327595584, 'IoU-19': 23.369310725590132, 'IoU-20': 22.369608651630656, 'IoU-21': 22.70621701044166, 'IoU-22': 23.296906929408966, 'IoU-23': 21.89561449460703, 'IoU-24': 21.347481354321175, 'IoU-25': 21.469994078924454, 'IoU-26': 20.732078222893637, 'IoU-27': 21.885913322256243, 'IoU-28': 20.533015386836066, 'IoU-29': 21.05114472898197, 'IoU-30': 20.213732903314067, 'IoU-31': 21.108967091092982, 'IoU-32': 19.702081466542076, 'IoU-33': 18.771071064313364, 'IoU-34': 18.198319309830094, 'IoU-35': 18.54160581438789, 'IoU-36': 18.26686453608387, 'IoU-37': 17.932843075428984, 'IoU-38': 17.784016090591383, 'IoU-39': 16.250842659407468, 'IoU-40': 16.050998665949244, 'IoU-41': 14.655863700992052, 'IoU-42': 14.039802351076741, 'IoU-43': 13.787875342066187, 'IoU-44': 13.782522932604694, 'IoU-45': 13.401653655480173, 'IoU-46': 12.534919492177698, 'IoU-47': 11.982651848871111, 'IoU-48': 11.796794570529112, 'IoU-49': 11.55658922106517, 'IoU-50': 11.678511427162611, 'IoU-51': 10.822645878146098, 'IoU-52': 10.477772975872913, 'IoU-53': 10.327193099566713, 'IoU-54': 10.094974540131, 'IoU-55': 9.902653803323723, 'IoU-56': 9.108671214550439, 'IoU-57': 9.249406539260963, 'IoU-58': 8.987062192117824, 'IoU-59': 8.918088893865619, 'IoU-60': 8.770698912917586, 'IoU-61': 8.48010762174193, 'IoU-62': 7.824193843341572, 'IoU-63': 7.534714257749584, 'IoU-64': 7.232547048048748, 'IoU-65': 6.928006969788972, 'IoU-66': 6.487149634145142, 'IoU-67': 6.195232232831375, 'IoU-68': 6.38216788044165, 'IoU-69': 6.4000862984624955, 'IoU-70': 6.002839248114268, 'IoU-71': 5.945433259888718, 'IoU-72': 5.9139743056293685, 'IoU-73': 5.758472026259021, 'IoU-74': 5.780615801919105, 'IoU-75': 5.607444828722427, 'IoU-76': 5.856835670501149, 'IoU-77': 5.808708379205683, 'IoU-78': 5.698071999831383, 'IoU-79': 5.514106811475585, 'IoU-80': 5.646896508806573, 'IoU-81': 5.493867584433713, 'IoU-82': 5.399225367045378, 'IoU-83': 5.482804370170078, 'IoU-84': 5.5749333422245755, 'IoU-85': 5.526744933753021, 'IoU-86': 5.3448297407704235, 'IoU-87': 5.379527213141729, 'IoU-88': 5.3180192363732814, 'IoU-89': 5.392338478328383, 'IoU-90': 5.12685215628874, 'IoU-91': 5.118316044259502, 'IoU-92': 5.024552402120857, 'IoU-93': 5.129712017171241, 'IoU-94': 5.25053610698991, 'IoU-95': 5.494578875590486, 'IoU-96': 5.546848653603817, 'IoU-97': 5.546782274155189, 'IoU-98': 5.421426591718172, 'IoU-99': 5.164428326880141, 'IoU-100': 5.276089520073352, 'IoU-101': 5.243718890492389, 'IoU-102': 5.055175515314228, 'IoU-103': 5.04881998325228, 'IoU-104': 4.89517336193272, 'IoU-105': 4.936765082069057, 'IoU-106': 5.343695630102406, 'IoU-107': 5.292350852019449, 'IoU-108': 5.154040175932587, 'IoU-109': 5.371445535464184, 'IoU-110': 5.386132560083203, 'IoU-111': 5.241520455979362, 'IoU-112': 5.352257031701492, 'IoU-113': 5.522659058617661, 'IoU-114': 5.186237617349885, 'IoU-115': 5.526007437058713, 'IoU-116': 4.966352528220494, 'IoU-117': 5.195221001470724, 'IoU-118': 4.991120493344357, 'IoU-119': 5.412346316056963, 'IoU-120': 5.201513260876417, 'IoU-121': 4.993142101290959, 'IoU-122': 4.99560755099322, 'IoU-123': 4.827289992740703, 'IoU-124': 4.474168045346183, 'IoU-125': 4.286994385995101, 'IoU-126': 4.325015313323923, 'IoU-127': 4.265605858117681, 'IoU-128': 3.9821349907877517, 'IoU-129': 3.8349248454169946, 'IoU-130': 3.9246326617820606, 'IoU-131': 4.00401876206762, 'IoU-132': 4.031507304560072, 'IoU-133': 4.034582959950246, 'IoU-134': 4.194855769040062, 'IoU-135': 3.963948475397245, 'IoU-136': 3.760097699797206, 'IoU-137': 3.69811585418582, 'IoU-138': 3.4300878106465635, 'IoU-139': 3.6116245776002565, 'IoU-140': 3.535170905599046, 'IoU-141': 3.537698130348258, 'IoU-142': 3.488737539898666, 'IoU-143': 3.3991469315234135, 'IoU-144': 3.4140667919685246, 'IoU-145': 3.4766925034454434, 'IoU-146': 3.321408504455349, 'IoU-147': 3.630278719060947, 'IoU-148': 3.5976038964068593, 'IoU-149': 3.3302662116186257, 'IoU-150': 3.118365863298601, 'IoU-151': 3.2062350348669715, 'IoU-152': 3.4665574184225036, 'IoU-153': 2.8183052730851728, 'IoU-154': 2.6123297630183324, 'IoU-155': 2.562699210651023, 'IoU-156': 2.843839290598201, 'IoU-157': 2.6386783747733973, 'IoU-158': 2.485707553764972, 'IoU-159': 2.4097940350355085, 'IoU-160': 2.6446229095995757, 'IoU-161': 2.375464602557676, 'IoU-162': 2.4764967300863554, 'IoU-163': 2.4460747900164983, 'IoU-164': 2.4612062839431554, 'IoU-165': 2.7659914242773844, 'IoU-166': 2.783349419483839, 'IoU-167': 2.560315389983949, 'IoU-168': 2.611366764064527, 'IoU-169': 2.1583803997094515, 'IoU-170': 2.014465999036835, 'IoU-171': 2.013508895399004, 'IoU-172': 2.208054467147288, 'IoU-173': 1.7191175327570762, 'IoU-174': 1.8594309535250195, 'IoU-175': 1.7825675289826715, 'IoU-176': 2.0605615389053775, 'IoU-177': 1.7826439315829494, 'IoU-178': 2.3678419644489095, 'IoU-179': 3.227070606816096, 'IoU-180': 1.0718912644130516, 'IoU-181': 1.2511692958520082, 'IoU-182': 1.2752915353132606, 'IoU-183': 1.1866793960215345, 'IoU-184': 0.8468461706763228, 'IoU-185': 0.5080963278751177, 'IoU-186': 0.33877433384861266, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 14.371849020644564, 'pACC': 30.216602069222496, 'ACC-0': 0.000616477919738297, 'ACC-1': 65.16401436771316, 'ACC-2': 5.760617463642065, 'ACC-3': 24.068459691600943, 'ACC-4': 23.31921307377802, 'ACC-5': 19.052052969889985, 'ACC-6': 16.960283665926802, 'ACC-7': 15.230938082267704, 'ACC-8': 27.136348544861182, 'ACC-9': 36.67445640188362, 'ACC-10': 38.5632101502311, 'ACC-11': 41.94209149201097, 'ACC-12': 39.993096642061275, 'ACC-13': 37.37028040101631, 'ACC-14': 39.04335607682388, 'ACC-15': 38.67097240351439, 'ACC-16': 37.96491418742138, 'ACC-17': 39.00299293140135, 'ACC-18': 37.52555198663553, 'ACC-19': 38.072122992062496, 'ACC-20': 36.28233004954261, 'ACC-21': 37.07196749160047, 'ACC-22': 37.31053481599883, 'ACC-23': 36.851777662714625, 'ACC-24': 36.312724038784104, 'ACC-25': 36.93027506429571, 'ACC-26': 35.703469662217486, 'ACC-27': 37.19881626741349, 'ACC-28': 35.46105731157548, 'ACC-29': 35.16084974484669, 'ACC-30': 34.498021054095815, 'ACC-31': 35.524074096386485, 'ACC-32': 33.65720497835583, 'ACC-33': 32.40560386563403, 'ACC-34': 31.882874794851023, 'ACC-35': 32.23283860873015, 'ACC-36': 31.565901833193287, 'ACC-37': 31.74666402927381, 'ACC-38': 31.590326990236356, 'ACC-39': 29.024722648754654, 'ACC-40': 27.962970662824365, 'ACC-41': 26.304561082342858, 'ACC-42': 25.292694719473875, 'ACC-43': 24.809336491098243, 'ACC-44': 24.021427039051282, 'ACC-45': 23.512282073702014, 'ACC-46': 22.662652957504203, 'ACC-47': 21.735311785474003, 'ACC-48': 21.359809760733917, 'ACC-49': 20.927555385224966, 'ACC-50': 21.092237469931593, 'ACC-51': 19.785498897720267, 'ACC-52': 19.107024523012665, 'ACC-53': 18.82855916913517, 'ACC-54': 18.27198290465, 'ACC-55': 17.785461349841512, 'ACC-56': 16.43837628166992, 'ACC-57': 16.439607677935257, 'ACC-58': 16.20393420603131, 'ACC-59': 16.35997487041721, 'ACC-60': 16.33693729876886, 'ACC-61': 15.96287167720843, 'ACC-62': 14.831341660807432, 'ACC-63': 14.384397130153895, 'ACC-64': 13.723916326846744, 'ACC-65': 13.134581705110126, 'ACC-66': 12.401008000307437, 'ACC-67': 12.043026884872917, 'ACC-68': 12.46131589754399, 'ACC-69': 12.153725876992988, 'ACC-70': 11.282029721361704, 'ACC-71': 11.332863261457176, 'ACC-72': 11.326759749012648, 'ACC-73': 11.032746404640035, 'ACC-74': 11.002564516773822, 'ACC-75': 10.687499385742006, 'ACC-76': 10.918843799286524, 'ACC-77': 10.993858751502891, 'ACC-78': 10.885064531865291, 'ACC-79': 10.553586140904796, 'ACC-80': 10.716534831411472, 'ACC-81': 10.272371600756552, 'ACC-82': 9.958215468130097, 'ACC-83': 9.901025911959149, 'ACC-84': 10.126649467342284, 'ACC-85': 10.140477615560625, 'ACC-86': 9.839421269107374, 'ACC-87': 9.935936963205046, 'ACC-88': 9.807607567499359, 'ACC-89': 9.844493529287178, 'ACC-90': 9.144758233444009, 'ACC-91': 9.166487272347249, 'ACC-92': 9.048206735709961, 'ACC-93': 9.245701659906855, 'ACC-94': 9.48398130645589, 'ACC-95': 9.920483270322254, 'ACC-96': 10.112843427558536, 'ACC-97': 10.075128034051332, 'ACC-98': 9.806472018788275, 'ACC-99': 9.331733784220543, 'ACC-100': 9.5087406448704, 'ACC-101': 9.460689236567848, 'ACC-102': 9.121930222020842, 'ACC-103': 9.093440068007935, 'ACC-104': 8.816433437446202, 'ACC-105': 8.970333932567856, 'ACC-106': 9.716203094397668, 'ACC-107': 9.56552506646824, 'ACC-108': 9.19308307173255, 'ACC-109': 9.633031554268493, 'ACC-110': 9.845689876064723, 'ACC-111': 9.641099119647519, 'ACC-112': 9.9595339193708, 'ACC-113': 10.272340617365506, 'ACC-114': 9.746912988607495, 'ACC-115': 10.399921819794626, 'ACC-116': 9.277603361783141, 'ACC-117': 9.512893315020891, 'ACC-118': 9.330489982562854, 'ACC-119': 10.149099070698856, 'ACC-120': 9.786674608278252, 'ACC-121': 9.426710337400477, 'ACC-122': 9.499372564559804, 'ACC-123': 9.216717423011868, 'ACC-124': 8.749502557401014, 'ACC-125': 8.29231761556643, 'ACC-126': 8.319747902986366, 'ACC-127': 8.055280396975956, 'ACC-128': 7.5524673401708275, 'ACC-129': 7.221508585499501, 'ACC-130': 7.457248034918727, 'ACC-131': 7.68877520164975, 'ACC-132': 7.691353928950817, 'ACC-133': 7.649472330523179, 'ACC-134': 8.019095217578629, 'ACC-135': 7.558006955133687, 'ACC-136': 7.084828084234067, 'ACC-137': 7.082872531801984, 'ACC-138': 6.55260870117014, 'ACC-139': 6.93271506608305, 'ACC-140': 6.793503918421301, 'ACC-141': 6.757509606337911, 'ACC-142': 6.708463566569815, 'ACC-143': 6.608240261741667, 'ACC-144': 6.657581227436824, 'ACC-145': 6.717502627518504, 'ACC-146': 6.314957391880468, 'ACC-147': 6.7552598323279005, 'ACC-148': 6.7430191121913285, 'ACC-149': 6.34620903810991, 'ACC-150': 5.937405215085537, 'ACC-151': 6.089527360082193, 'ACC-152': 6.339141209791624, 'ACC-153': 5.413712233642976, 'ACC-154': 5.1515439719984455, 'ACC-155': 5.2056756470272125, 'ACC-156': 5.981759067139819, 'ACC-157': 5.608431906556532, 'ACC-158': 5.419652219811982, 'ACC-159': 5.188736755253241, 'ACC-160': 5.5972322761616065, 'ACC-161': 4.871277841590443, 'ACC-162': 5.263298829816038, 'ACC-163': 5.375997260638338, 'ACC-164': 5.4363439762302646, 'ACC-165': 5.8867250902876815, 'ACC-166': 5.945219967934459, 'ACC-167': 5.58882131510057, 'ACC-168': 5.821787748786835, 'ACC-169': 4.78651255586575, 'ACC-170': 4.632153555659667, 'ACC-171': 4.556317033700765, 'ACC-172': 4.987776419602178, 'ACC-173': 3.9532949769146537, 'ACC-174': 4.335102268300275, 'ACC-175': 4.236067586280851, 'ACC-176': 5.311846993266775, 'ACC-177': 4.473405933906535, 'ACC-178': 6.355862633786032, 'ACC-179': 9.974212842450815, 'ACC-180': 3.435817332114193, 'ACC-181': 4.888424633036541, 'ACC-182': 4.0358786890916365, 'ACC-183': 3.608231646305718, 'ACC-184': 2.8206416252178568, 'ACC-185': 1.0316921414021036, 'ACC-186': 0.6104628517066285, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 04:59:55] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 04:59:55] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 04:59:55] d2.evaluation.testing INFO: copypaste: 2.4042,0.3550,0.1516,7.9781,20.4011,14.3718,30.2166
[01/30 04:59:55] d2.utils.events INFO:  eta: 22:18:05  iter: 32999  total_loss: 21.73  loss_mask: 2.165  loss_mask_0: 2.199  loss_mask_1: 2.151  loss_mask_2: 2.172  loss_mask_3: 2.18  loss_mask_4: 2.169  loss_mask_5: 2.154  loss_mask_6: 2.157  loss_mask_7: 2.171  loss_mask_8: 2.168  time: 2.9896  data_time: 0.0635  lr: 4.8742e-05  max_mem: 27646M
[01/30 05:00:54] d2.utils.events INFO:  eta: 22:17:35  iter: 33019  total_loss: 19.31  loss_mask: 1.921  loss_mask_0: 1.975  loss_mask_1: 1.91  loss_mask_2: 1.928  loss_mask_3: 1.939  loss_mask_4: 1.943  loss_mask_5: 1.914  loss_mask_6: 1.915  loss_mask_7: 1.937  loss_mask_8: 1.929  time: 2.9896  data_time: 0.0654  lr: 4.871e-05  max_mem: 27646M
[01/30 05:01:55] d2.utils.events INFO:  eta: 22:16:28  iter: 33039  total_loss: 20.79  loss_mask: 2.063  loss_mask_0: 2.099  loss_mask_1: 2.05  loss_mask_2: 2.075  loss_mask_3: 2.076  loss_mask_4: 2.076  loss_mask_5: 2.069  loss_mask_6: 2.055  loss_mask_7: 2.076  loss_mask_8: 2.078  time: 2.9896  data_time: 0.0658  lr: 4.8677e-05  max_mem: 27646M
[01/30 05:02:54] d2.utils.events INFO:  eta: 22:15:18  iter: 33059  total_loss: 19.83  loss_mask: 1.976  loss_mask_0: 2.033  loss_mask_1: 1.987  loss_mask_2: 1.974  loss_mask_3: 1.984  loss_mask_4: 1.997  loss_mask_5: 1.968  loss_mask_6: 1.979  loss_mask_7: 1.981  loss_mask_8: 1.974  time: 2.9896  data_time: 0.0677  lr: 4.8645e-05  max_mem: 27646M
[01/30 05:03:54] d2.utils.events INFO:  eta: 22:14:07  iter: 33079  total_loss: 21.98  loss_mask: 2.173  loss_mask_0: 2.25  loss_mask_1: 2.184  loss_mask_2: 2.202  loss_mask_3: 2.203  loss_mask_4: 2.209  loss_mask_5: 2.172  loss_mask_6: 2.171  loss_mask_7: 2.206  loss_mask_8: 2.206  time: 2.9896  data_time: 0.0610  lr: 4.8612e-05  max_mem: 27646M
[01/30 05:04:53] d2.utils.events INFO:  eta: 22:13:25  iter: 33099  total_loss: 20.24  loss_mask: 2.017  loss_mask_0: 2.029  loss_mask_1: 2.022  loss_mask_2: 2.033  loss_mask_3: 2.023  loss_mask_4: 2.027  loss_mask_5: 2.007  loss_mask_6: 2.016  loss_mask_7: 2.032  loss_mask_8: 2.034  time: 2.9896  data_time: 0.0589  lr: 4.858e-05  max_mem: 27646M
[01/30 05:05:52] d2.utils.events INFO:  eta: 22:11:49  iter: 33119  total_loss: 20.84  loss_mask: 2.07  loss_mask_0: 2.142  loss_mask_1: 2.068  loss_mask_2: 2.085  loss_mask_3: 2.085  loss_mask_4: 2.093  loss_mask_5: 2.079  loss_mask_6: 2.061  loss_mask_7: 2.079  loss_mask_8: 2.089  time: 2.9896  data_time: 0.0574  lr: 4.8547e-05  max_mem: 27646M
[01/30 05:06:52] d2.utils.events INFO:  eta: 22:11:20  iter: 33139  total_loss: 20.9  loss_mask: 2.086  loss_mask_0: 2.174  loss_mask_1: 2.075  loss_mask_2: 2.091  loss_mask_3: 2.078  loss_mask_4: 2.073  loss_mask_5: 2.081  loss_mask_6: 2.09  loss_mask_7: 2.09  loss_mask_8: 2.079  time: 2.9896  data_time: 0.0758  lr: 4.8515e-05  max_mem: 27646M
[01/30 05:07:53] d2.utils.events INFO:  eta: 22:10:54  iter: 33159  total_loss: 22.61  loss_mask: 2.24  loss_mask_0: 2.36  loss_mask_1: 2.235  loss_mask_2: 2.238  loss_mask_3: 2.242  loss_mask_4: 2.246  loss_mask_5: 2.245  loss_mask_6: 2.24  loss_mask_7: 2.247  loss_mask_8: 2.248  time: 2.9896  data_time: 0.0812  lr: 4.8482e-05  max_mem: 27646M
[01/30 05:08:52] d2.utils.events INFO:  eta: 22:09:48  iter: 33179  total_loss: 23.06  loss_mask: 2.301  loss_mask_0: 2.382  loss_mask_1: 2.271  loss_mask_2: 2.285  loss_mask_3: 2.315  loss_mask_4: 2.322  loss_mask_5: 2.288  loss_mask_6: 2.273  loss_mask_7: 2.306  loss_mask_8: 2.32  time: 2.9896  data_time: 0.0657  lr: 4.845e-05  max_mem: 27646M
[01/30 05:09:51] d2.utils.events INFO:  eta: 22:08:49  iter: 33199  total_loss: 22  loss_mask: 2.185  loss_mask_0: 2.253  loss_mask_1: 2.175  loss_mask_2: 2.205  loss_mask_3: 2.197  loss_mask_4: 2.209  loss_mask_5: 2.191  loss_mask_6: 2.179  loss_mask_7: 2.2  loss_mask_8: 2.208  time: 2.9896  data_time: 0.0543  lr: 4.8417e-05  max_mem: 27646M
[01/30 05:10:51] d2.utils.events INFO:  eta: 22:07:45  iter: 33219  total_loss: 20.99  loss_mask: 2.092  loss_mask_0: 2.114  loss_mask_1: 2.094  loss_mask_2: 2.094  loss_mask_3: 2.097  loss_mask_4: 2.099  loss_mask_5: 2.096  loss_mask_6: 2.092  loss_mask_7: 2.097  loss_mask_8: 2.101  time: 2.9896  data_time: 0.0567  lr: 4.8385e-05  max_mem: 27646M
[01/30 05:11:51] d2.utils.events INFO:  eta: 22:07:11  iter: 33239  total_loss: 21.3  loss_mask: 2.101  loss_mask_0: 2.175  loss_mask_1: 2.101  loss_mask_2: 2.16  loss_mask_3: 2.135  loss_mask_4: 2.12  loss_mask_5: 2.115  loss_mask_6: 2.105  loss_mask_7: 2.161  loss_mask_8: 2.131  time: 2.9896  data_time: 0.0661  lr: 4.8352e-05  max_mem: 27646M
[01/30 05:12:51] d2.utils.events INFO:  eta: 22:06:12  iter: 33259  total_loss: 21.67  loss_mask: 2.133  loss_mask_0: 2.238  loss_mask_1: 2.141  loss_mask_2: 2.176  loss_mask_3: 2.172  loss_mask_4: 2.181  loss_mask_5: 2.139  loss_mask_6: 2.136  loss_mask_7: 2.182  loss_mask_8: 2.174  time: 2.9896  data_time: 0.0717  lr: 4.832e-05  max_mem: 27646M
[01/30 05:13:51] d2.utils.events INFO:  eta: 22:05:16  iter: 33279  total_loss: 20.64  loss_mask: 2.062  loss_mask_0: 2.087  loss_mask_1: 2.053  loss_mask_2: 2.059  loss_mask_3: 2.06  loss_mask_4: 2.065  loss_mask_5: 2.056  loss_mask_6: 2.066  loss_mask_7: 2.06  loss_mask_8: 2.061  time: 2.9896  data_time: 0.0777  lr: 4.8287e-05  max_mem: 27646M
[01/30 05:14:51] d2.utils.events INFO:  eta: 22:04:35  iter: 33299  total_loss: 19.24  loss_mask: 1.916  loss_mask_0: 1.959  loss_mask_1: 1.913  loss_mask_2: 1.923  loss_mask_3: 1.925  loss_mask_4: 1.929  loss_mask_5: 1.914  loss_mask_6: 1.915  loss_mask_7: 1.924  loss_mask_8: 1.921  time: 2.9896  data_time: 0.0727  lr: 4.8255e-05  max_mem: 27646M
[01/30 05:15:51] d2.utils.events INFO:  eta: 22:03:35  iter: 33319  total_loss: 20.47  loss_mask: 2.04  loss_mask_0: 2.095  loss_mask_1: 2.029  loss_mask_2: 2.04  loss_mask_3: 2.048  loss_mask_4: 2.046  loss_mask_5: 2.038  loss_mask_6: 2.036  loss_mask_7: 2.044  loss_mask_8: 2.042  time: 2.9896  data_time: 0.0540  lr: 4.8222e-05  max_mem: 27646M
[01/30 05:16:51] d2.utils.events INFO:  eta: 22:02:21  iter: 33339  total_loss: 18.81  loss_mask: 1.859  loss_mask_0: 1.943  loss_mask_1: 1.869  loss_mask_2: 1.879  loss_mask_3: 1.877  loss_mask_4: 1.882  loss_mask_5: 1.87  loss_mask_6: 1.862  loss_mask_7: 1.881  loss_mask_8: 1.878  time: 2.9896  data_time: 0.0547  lr: 4.819e-05  max_mem: 27646M
[01/30 05:17:50] d2.utils.events INFO:  eta: 22:01:26  iter: 33359  total_loss: 20.52  loss_mask: 2.043  loss_mask_0: 2.113  loss_mask_1: 2.037  loss_mask_2: 2.055  loss_mask_3: 2.049  loss_mask_4: 2.046  loss_mask_5: 2.037  loss_mask_6: 2.035  loss_mask_7: 2.045  loss_mask_8: 2.057  time: 2.9896  data_time: 0.0569  lr: 4.8157e-05  max_mem: 27646M
[01/30 05:18:51] d2.utils.events INFO:  eta: 22:01:13  iter: 33379  total_loss: 18.13  loss_mask: 1.808  loss_mask_0: 1.878  loss_mask_1: 1.803  loss_mask_2: 1.804  loss_mask_3: 1.818  loss_mask_4: 1.82  loss_mask_5: 1.797  loss_mask_6: 1.804  loss_mask_7: 1.824  loss_mask_8: 1.824  time: 2.9896  data_time: 0.0762  lr: 4.8124e-05  max_mem: 27646M
[01/30 05:19:51] d2.utils.events INFO:  eta: 22:00:29  iter: 33399  total_loss: 19.82  loss_mask: 1.982  loss_mask_0: 2.03  loss_mask_1: 1.971  loss_mask_2: 1.975  loss_mask_3: 1.975  loss_mask_4: 1.982  loss_mask_5: 1.979  loss_mask_6: 1.974  loss_mask_7: 1.982  loss_mask_8: 1.978  time: 2.9896  data_time: 0.0526  lr: 4.8092e-05  max_mem: 27646M
[01/30 05:20:51] d2.utils.events INFO:  eta: 21:59:49  iter: 33419  total_loss: 20.12  loss_mask: 2.009  loss_mask_0: 2.038  loss_mask_1: 2.003  loss_mask_2: 2.012  loss_mask_3: 2.009  loss_mask_4: 2.015  loss_mask_5: 2.004  loss_mask_6: 2.006  loss_mask_7: 2.014  loss_mask_8: 2.012  time: 2.9896  data_time: 0.0790  lr: 4.8059e-05  max_mem: 27646M
[01/30 05:21:51] d2.utils.events INFO:  eta: 21:58:46  iter: 33439  total_loss: 22.59  loss_mask: 2.251  loss_mask_0: 2.286  loss_mask_1: 2.257  loss_mask_2: 2.26  loss_mask_3: 2.261  loss_mask_4: 2.258  loss_mask_5: 2.252  loss_mask_6: 2.251  loss_mask_7: 2.253  loss_mask_8: 2.26  time: 2.9896  data_time: 0.0705  lr: 4.8027e-05  max_mem: 27646M
[01/30 05:22:51] d2.utils.events INFO:  eta: 21:57:50  iter: 33459  total_loss: 20.31  loss_mask: 2.036  loss_mask_0: 2.062  loss_mask_1: 2.029  loss_mask_2: 2.033  loss_mask_3: 2.028  loss_mask_4: 2.021  loss_mask_5: 2.019  loss_mask_6: 2.031  loss_mask_7: 2.033  loss_mask_8: 2.027  time: 2.9896  data_time: 0.0722  lr: 4.7994e-05  max_mem: 27646M
[01/30 05:23:50] d2.utils.events INFO:  eta: 21:56:46  iter: 33479  total_loss: 18.78  loss_mask: 1.868  loss_mask_0: 1.928  loss_mask_1: 1.871  loss_mask_2: 1.869  loss_mask_3: 1.884  loss_mask_4: 1.882  loss_mask_5: 1.866  loss_mask_6: 1.858  loss_mask_7: 1.881  loss_mask_8: 1.876  time: 2.9896  data_time: 0.0581  lr: 4.7962e-05  max_mem: 27646M
[01/30 05:24:51] d2.utils.events INFO:  eta: 21:55:45  iter: 33499  total_loss: 19.76  loss_mask: 1.958  loss_mask_0: 2.032  loss_mask_1: 1.972  loss_mask_2: 1.983  loss_mask_3: 1.975  loss_mask_4: 1.962  loss_mask_5: 1.954  loss_mask_6: 1.95  loss_mask_7: 1.975  loss_mask_8: 1.972  time: 2.9896  data_time: 0.0642  lr: 4.7929e-05  max_mem: 27646M
[01/30 05:25:50] d2.utils.events INFO:  eta: 21:54:35  iter: 33519  total_loss: 21.33  loss_mask: 2.114  loss_mask_0: 2.221  loss_mask_1: 2.107  loss_mask_2: 2.128  loss_mask_3: 2.134  loss_mask_4: 2.134  loss_mask_5: 2.102  loss_mask_6: 2.11  loss_mask_7: 2.135  loss_mask_8: 2.131  time: 2.9896  data_time: 0.0497  lr: 4.7897e-05  max_mem: 27646M
[01/30 05:26:49] d2.utils.events INFO:  eta: 21:53:41  iter: 33539  total_loss: 19.39  loss_mask: 1.944  loss_mask_0: 1.961  loss_mask_1: 1.92  loss_mask_2: 1.943  loss_mask_3: 1.941  loss_mask_4: 1.945  loss_mask_5: 1.924  loss_mask_6: 1.928  loss_mask_7: 1.94  loss_mask_8: 1.945  time: 2.9896  data_time: 0.0582  lr: 4.7864e-05  max_mem: 27646M
[01/30 05:27:49] d2.utils.events INFO:  eta: 21:52:36  iter: 33559  total_loss: 19.91  loss_mask: 1.982  loss_mask_0: 2.037  loss_mask_1: 1.973  loss_mask_2: 1.997  loss_mask_3: 1.983  loss_mask_4: 1.984  loss_mask_5: 1.974  loss_mask_6: 1.984  loss_mask_7: 1.995  loss_mask_8: 1.979  time: 2.9896  data_time: 0.0629  lr: 4.7831e-05  max_mem: 27646M
[01/30 05:28:49] d2.utils.events INFO:  eta: 21:50:54  iter: 33579  total_loss: 20.44  loss_mask: 2.035  loss_mask_0: 2.075  loss_mask_1: 2.029  loss_mask_2: 2.042  loss_mask_3: 2.042  loss_mask_4: 2.043  loss_mask_5: 2.033  loss_mask_6: 2.035  loss_mask_7: 2.043  loss_mask_8: 2.044  time: 2.9896  data_time: 0.0525  lr: 4.7799e-05  max_mem: 27646M
[01/30 05:29:48] d2.utils.events INFO:  eta: 21:49:30  iter: 33599  total_loss: 20.41  loss_mask: 2.037  loss_mask_0: 2.054  loss_mask_1: 2.037  loss_mask_2: 2.044  loss_mask_3: 2.042  loss_mask_4: 2.051  loss_mask_5: 2.01  loss_mask_6: 2.029  loss_mask_7: 2.045  loss_mask_8: 2.033  time: 2.9896  data_time: 0.0619  lr: 4.7766e-05  max_mem: 27646M
[01/30 05:30:49] d2.utils.events INFO:  eta: 21:49:13  iter: 33619  total_loss: 21.26  loss_mask: 2.114  loss_mask_0: 2.148  loss_mask_1: 2.105  loss_mask_2: 2.134  loss_mask_3: 2.131  loss_mask_4: 2.129  loss_mask_5: 2.108  loss_mask_6: 2.116  loss_mask_7: 2.123  loss_mask_8: 2.133  time: 2.9896  data_time: 0.0699  lr: 4.7734e-05  max_mem: 27646M
[01/30 05:31:48] d2.utils.events INFO:  eta: 21:48:01  iter: 33639  total_loss: 19.28  loss_mask: 1.925  loss_mask_0: 1.96  loss_mask_1: 1.924  loss_mask_2: 1.928  loss_mask_3: 1.937  loss_mask_4: 1.935  loss_mask_5: 1.921  loss_mask_6: 1.919  loss_mask_7: 1.922  loss_mask_8: 1.919  time: 2.9896  data_time: 0.0568  lr: 4.7701e-05  max_mem: 27646M
[01/30 05:32:48] d2.utils.events INFO:  eta: 21:47:14  iter: 33659  total_loss: 19.74  loss_mask: 1.967  loss_mask_0: 2.025  loss_mask_1: 1.953  loss_mask_2: 1.977  loss_mask_3: 1.985  loss_mask_4: 1.981  loss_mask_5: 1.967  loss_mask_6: 1.96  loss_mask_7: 1.974  loss_mask_8: 1.977  time: 2.9896  data_time: 0.0576  lr: 4.7669e-05  max_mem: 27646M
[01/30 05:33:48] d2.utils.events INFO:  eta: 21:46:30  iter: 33679  total_loss: 21.84  loss_mask: 2.177  loss_mask_0: 2.23  loss_mask_1: 2.157  loss_mask_2: 2.198  loss_mask_3: 2.181  loss_mask_4: 2.183  loss_mask_5: 2.163  loss_mask_6: 2.181  loss_mask_7: 2.195  loss_mask_8: 2.178  time: 2.9896  data_time: 0.0723  lr: 4.7636e-05  max_mem: 27646M
[01/30 05:34:48] d2.utils.events INFO:  eta: 21:45:57  iter: 33699  total_loss: 22.91  loss_mask: 2.291  loss_mask_0: 2.304  loss_mask_1: 2.271  loss_mask_2: 2.287  loss_mask_3: 2.289  loss_mask_4: 2.299  loss_mask_5: 2.292  loss_mask_6: 2.285  loss_mask_7: 2.294  loss_mask_8: 2.292  time: 2.9896  data_time: 0.0668  lr: 4.7604e-05  max_mem: 27646M
[01/30 05:35:47] d2.utils.events INFO:  eta: 21:44:58  iter: 33719  total_loss: 19.72  loss_mask: 1.957  loss_mask_0: 2.001  loss_mask_1: 1.964  loss_mask_2: 1.968  loss_mask_3: 1.961  loss_mask_4: 1.972  loss_mask_5: 1.965  loss_mask_6: 1.958  loss_mask_7: 1.969  loss_mask_8: 1.986  time: 2.9896  data_time: 0.0682  lr: 4.7571e-05  max_mem: 27646M
[01/30 05:36:46] d2.utils.events INFO:  eta: 21:43:56  iter: 33739  total_loss: 20.3  loss_mask: 2.025  loss_mask_0: 2.049  loss_mask_1: 2.019  loss_mask_2: 2.026  loss_mask_3: 2.03  loss_mask_4: 2.028  loss_mask_5: 2.032  loss_mask_6: 2.03  loss_mask_7: 2.037  loss_mask_8: 2.028  time: 2.9895  data_time: 0.0635  lr: 4.7538e-05  max_mem: 27646M
[01/30 05:37:45] d2.utils.events INFO:  eta: 21:42:58  iter: 33759  total_loss: 19.64  loss_mask: 1.944  loss_mask_0: 2.032  loss_mask_1: 1.937  loss_mask_2: 1.979  loss_mask_3: 1.97  loss_mask_4: 1.978  loss_mask_5: 1.941  loss_mask_6: 1.938  loss_mask_7: 1.972  loss_mask_8: 1.975  time: 2.9895  data_time: 0.0679  lr: 4.7506e-05  max_mem: 27646M
[01/30 05:38:44] d2.utils.events INFO:  eta: 21:42:01  iter: 33779  total_loss: 21.5  loss_mask: 2.143  loss_mask_0: 2.195  loss_mask_1: 2.147  loss_mask_2: 2.146  loss_mask_3: 2.141  loss_mask_4: 2.145  loss_mask_5: 2.15  loss_mask_6: 2.15  loss_mask_7: 2.142  loss_mask_8: 2.141  time: 2.9895  data_time: 0.0535  lr: 4.7473e-05  max_mem: 27646M
[01/30 05:39:43] d2.utils.events INFO:  eta: 21:40:33  iter: 33799  total_loss: 20.48  loss_mask: 2.027  loss_mask_0: 2.089  loss_mask_1: 2.022  loss_mask_2: 2.047  loss_mask_3: 2.045  loss_mask_4: 2.047  loss_mask_5: 2.03  loss_mask_6: 2.025  loss_mask_7: 2.052  loss_mask_8: 2.046  time: 2.9895  data_time: 0.0601  lr: 4.7441e-05  max_mem: 27646M
[01/30 05:40:42] d2.utils.events INFO:  eta: 21:38:53  iter: 33819  total_loss: 20.71  loss_mask: 2.06  loss_mask_0: 2.103  loss_mask_1: 2.061  loss_mask_2: 2.118  loss_mask_3: 2.085  loss_mask_4: 2.065  loss_mask_5: 2.062  loss_mask_6: 2.058  loss_mask_7: 2.063  loss_mask_8: 2.063  time: 2.9894  data_time: 0.0629  lr: 4.7408e-05  max_mem: 27646M
[01/30 05:41:41] d2.utils.events INFO:  eta: 21:37:26  iter: 33839  total_loss: 20.31  loss_mask: 2.011  loss_mask_0: 2.071  loss_mask_1: 2.008  loss_mask_2: 2.053  loss_mask_3: 2.025  loss_mask_4: 2.03  loss_mask_5: 2.009  loss_mask_6: 2.01  loss_mask_7: 2.023  loss_mask_8: 2.021  time: 2.9894  data_time: 0.0629  lr: 4.7375e-05  max_mem: 27646M
[01/30 05:42:40] d2.utils.events INFO:  eta: 21:36:11  iter: 33859  total_loss: 20.69  loss_mask: 2.064  loss_mask_0: 2.085  loss_mask_1: 2.068  loss_mask_2: 2.087  loss_mask_3: 2.061  loss_mask_4: 2.061  loss_mask_5: 2.071  loss_mask_6: 2.06  loss_mask_7: 2.067  loss_mask_8: 2.067  time: 2.9894  data_time: 0.0572  lr: 4.7343e-05  max_mem: 27646M
[01/30 05:43:39] d2.utils.events INFO:  eta: 21:34:48  iter: 33879  total_loss: 21.72  loss_mask: 2.15  loss_mask_0: 2.233  loss_mask_1: 2.153  loss_mask_2: 2.206  loss_mask_3: 2.168  loss_mask_4: 2.172  loss_mask_5: 2.153  loss_mask_6: 2.148  loss_mask_7: 2.173  loss_mask_8: 2.165  time: 2.9894  data_time: 0.0550  lr: 4.731e-05  max_mem: 27646M
[01/30 05:44:38] d2.utils.events INFO:  eta: 21:33:42  iter: 33899  total_loss: 20.64  loss_mask: 2.06  loss_mask_0: 2.078  loss_mask_1: 2.056  loss_mask_2: 2.092  loss_mask_3: 2.06  loss_mask_4: 2.054  loss_mask_5: 2.062  loss_mask_6: 2.051  loss_mask_7: 2.07  loss_mask_8: 2.069  time: 2.9893  data_time: 0.0599  lr: 4.7278e-05  max_mem: 27646M
[01/30 05:45:36] d2.utils.events INFO:  eta: 21:32:11  iter: 33919  total_loss: 22  loss_mask: 2.205  loss_mask_0: 2.171  loss_mask_1: 2.197  loss_mask_2: 2.224  loss_mask_3: 2.203  loss_mask_4: 2.185  loss_mask_5: 2.208  loss_mask_6: 2.206  loss_mask_7: 2.209  loss_mask_8: 2.196  time: 2.9893  data_time: 0.0532  lr: 4.7245e-05  max_mem: 27646M
[01/30 05:46:36] d2.utils.events INFO:  eta: 21:31:02  iter: 33939  total_loss: 18.12  loss_mask: 1.802  loss_mask_0: 1.839  loss_mask_1: 1.793  loss_mask_2: 1.82  loss_mask_3: 1.81  loss_mask_4: 1.819  loss_mask_5: 1.801  loss_mask_6: 1.805  loss_mask_7: 1.813  loss_mask_8: 1.816  time: 2.9893  data_time: 0.0545  lr: 4.7212e-05  max_mem: 27646M
[01/30 05:47:35] d2.utils.events INFO:  eta: 21:30:06  iter: 33959  total_loss: 20.28  loss_mask: 2.04  loss_mask_0: 2.07  loss_mask_1: 2.023  loss_mask_2: 2.021  loss_mask_3: 2.029  loss_mask_4: 2.032  loss_mask_5: 2.021  loss_mask_6: 2.024  loss_mask_7: 2.025  loss_mask_8: 2.023  time: 2.9893  data_time: 0.0597  lr: 4.718e-05  max_mem: 27646M
[01/30 05:48:35] d2.utils.events INFO:  eta: 21:28:24  iter: 33979  total_loss: 22.26  loss_mask: 2.228  loss_mask_0: 2.234  loss_mask_1: 2.218  loss_mask_2: 2.225  loss_mask_3: 2.234  loss_mask_4: 2.229  loss_mask_5: 2.222  loss_mask_6: 2.227  loss_mask_7: 2.224  loss_mask_8: 2.227  time: 2.9893  data_time: 0.0639  lr: 4.7147e-05  max_mem: 27646M
[01/30 05:49:34] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 05:49:35] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 05:49:35] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 06:03:52] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.555292278224389, 'error_1pix': 0.40631962689680234, 'error_3pix': 0.16934746848562515, 'mIoU': 6.664734729370209, 'fwIoU': 17.290880060535578, 'IoU-0': 8.530433720797936e-05, 'IoU-1': 52.21793844479306, 'IoU-2': 3.0475989471890554, 'IoU-3': 6.3042736380373565, 'IoU-4': 6.177393258862397, 'IoU-5': 5.694256345428639, 'IoU-6': 5.263052740413672, 'IoU-7': 4.44458903470817, 'IoU-8': 7.328834751897617, 'IoU-9': 18.74361097745075, 'IoU-10': 23.7196416549208, 'IoU-11': 32.31105428678244, 'IoU-12': 30.781312940524597, 'IoU-13': 28.791723827717803, 'IoU-14': 27.75523803688848, 'IoU-15': 26.222667449128558, 'IoU-16': 25.99448474150859, 'IoU-17': 23.325362657560557, 'IoU-18': 22.57662681581693, 'IoU-19': 22.288474975733703, 'IoU-20': 21.25599857323102, 'IoU-21': 21.845352751462993, 'IoU-22': 22.51776402887804, 'IoU-23': 20.510076508267655, 'IoU-24': 19.88387965749764, 'IoU-25': 19.595461561963308, 'IoU-26': 18.66303613916941, 'IoU-27': 19.401151421068754, 'IoU-28': 18.068460135785998, 'IoU-29': 18.056405201620326, 'IoU-30': 16.873447848995447, 'IoU-31': 16.776371646410976, 'IoU-32': 15.253460230330331, 'IoU-33': 14.39929953828947, 'IoU-34': 14.17414927868278, 'IoU-35': 13.838663852053445, 'IoU-36': 13.198890494155268, 'IoU-37': 12.460719365108838, 'IoU-38': 11.454240758955365, 'IoU-39': 10.401938961376034, 'IoU-40': 9.798478495667597, 'IoU-41': 9.13514656237287, 'IoU-42': 8.557455963642509, 'IoU-43': 8.478718020534437, 'IoU-44': 8.120450785989746, 'IoU-45': 7.957543073047682, 'IoU-46': 7.66046579650042, 'IoU-47': 7.143335619301534, 'IoU-48': 6.759870899064103, 'IoU-49': 6.33911392572402, 'IoU-50': 6.076404744790038, 'IoU-51': 5.612782771586526, 'IoU-52': 5.419974692110419, 'IoU-53': 5.159812764419187, 'IoU-54': 5.075696964981746, 'IoU-55': 5.04064499441377, 'IoU-56': 5.061725242458927, 'IoU-57': 4.9508587554472925, 'IoU-58': 4.969643500024183, 'IoU-59': 4.690116912121442, 'IoU-60': 4.5515584098679, 'IoU-61': 4.514575942373407, 'IoU-62': 4.5628124991621695, 'IoU-63': 4.235837391311984, 'IoU-64': 4.11820730932145, 'IoU-65': 4.227014520387634, 'IoU-66': 4.056279094128562, 'IoU-67': 4.3717157621612195, 'IoU-68': 4.6439709896444175, 'IoU-69': 4.69954122937309, 'IoU-70': 4.472476141098714, 'IoU-71': 4.6448083937479385, 'IoU-72': 4.643483342050084, 'IoU-73': 4.647527669092855, 'IoU-74': 4.795860322947151, 'IoU-75': 4.518415499401963, 'IoU-76': 4.851558046403426, 'IoU-77': 4.897581162019274, 'IoU-78': 4.938169940656841, 'IoU-79': 5.119910888447768, 'IoU-80': 5.135649117823317, 'IoU-81': 5.040911920644524, 'IoU-82': 4.851327416582517, 'IoU-83': 5.185707497843177, 'IoU-84': 5.045034361952502, 'IoU-85': 5.121036715608924, 'IoU-86': 5.090647352269773, 'IoU-87': 5.009515759105059, 'IoU-88': 4.871116648603854, 'IoU-89': 4.692569148565308, 'IoU-90': 4.710143531973894, 'IoU-91': 4.741683267021404, 'IoU-92': 4.629402068267805, 'IoU-93': 4.900383996305899, 'IoU-94': 4.943281257771798, 'IoU-95': 4.885262298858229, 'IoU-96': 5.026602980473935, 'IoU-97': 5.096545114744765, 'IoU-98': 4.953587550013671, 'IoU-99': 4.496159444847627, 'IoU-100': 4.371573186453771, 'IoU-101': 4.466674406183228, 'IoU-102': 4.382180732984714, 'IoU-103': 4.323972474144768, 'IoU-104': 4.388842662809032, 'IoU-105': 4.423334601510271, 'IoU-106': 4.564167701818553, 'IoU-107': 4.732749373017981, 'IoU-108': 4.654201966234452, 'IoU-109': 4.680884673951995, 'IoU-110': 4.595409933885173, 'IoU-111': 4.325040594317637, 'IoU-112': 3.849149258868135, 'IoU-113': 4.12937911928847, 'IoU-114': 3.990314573279473, 'IoU-115': 3.792939036789066, 'IoU-116': 3.6157431908672404, 'IoU-117': 3.886091012166446, 'IoU-118': 3.7790360571161354, 'IoU-119': 4.164924632924551, 'IoU-120': 4.1804921466186515, 'IoU-121': 3.857304076608117, 'IoU-122': 3.8402522154821357, 'IoU-123': 3.5416222766563443, 'IoU-124': 3.387133484075909, 'IoU-125': 3.105803432325801, 'IoU-126': 3.118682533080554, 'IoU-127': 3.069778774336098, 'IoU-128': 3.01210356481083, 'IoU-129': 3.0088471115021664, 'IoU-130': 2.963365206995889, 'IoU-131': 2.9495312665069875, 'IoU-132': 3.0424349821501817, 'IoU-133': 3.3852788598276673, 'IoU-134': 3.2860306616702943, 'IoU-135': 3.1126673294149363, 'IoU-136': 2.764011798273711, 'IoU-137': 2.773157270005955, 'IoU-138': 2.704789950086743, 'IoU-139': 2.7553188890788736, 'IoU-140': 2.654320448169479, 'IoU-141': 2.5529786767799934, 'IoU-142': 2.5297754576054756, 'IoU-143': 2.534804175299525, 'IoU-144': 2.4617817300295126, 'IoU-145': 2.6742708889033877, 'IoU-146': 2.6965945887698126, 'IoU-147': 2.7882049681310606, 'IoU-148': 2.8463955234523777, 'IoU-149': 2.777537926087303, 'IoU-150': 2.703410526124843, 'IoU-151': 3.009450171821306, 'IoU-152': 2.9139680032907957, 'IoU-153': 2.4493107017254627, 'IoU-154': 2.244078456549588, 'IoU-155': 2.2074771637129653, 'IoU-156': 2.485209897551486, 'IoU-157': 2.3091663759312087, 'IoU-158': 2.640825378459165, 'IoU-159': 2.5901369597831874, 'IoU-160': 2.2132004984620153, 'IoU-161': 2.182848150635956, 'IoU-162': 2.146393098068773, 'IoU-163': 2.105166896597054, 'IoU-164': 2.409771965950357, 'IoU-165': 3.1528781553470693, 'IoU-166': 2.5065588746956373, 'IoU-167': 2.1300770705163745, 'IoU-168': 1.9461811121798296, 'IoU-169': 2.2766728733212798, 'IoU-170': 2.2318671344713374, 'IoU-171': 1.8234901618153962, 'IoU-172': 2.32799885558763, 'IoU-173': 2.156386052811616, 'IoU-174': 1.8769446249408805, 'IoU-175': 1.960752475381498, 'IoU-176': 1.7902307565892754, 'IoU-177': 1.8481753760375708, 'IoU-178': 1.7822411667832931, 'IoU-179': 1.8673305593114455, 'IoU-180': 1.460320479292473, 'IoU-181': 1.9474947195457664, 'IoU-182': 1.2320175139426186, 'IoU-183': 0.7879428958752944, 'IoU-184': 1.0365285546875829, 'IoU-185': 2.121961827965929, 'IoU-186': 0.36435661126179725, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 12.099591877303832, 'pACC': 25.872374998234314, 'ACC-0': 0.0004032308405835402, 'ACC-1': 53.031942323156514, 'ACC-2': 5.5853731051865525, 'ACC-3': 23.457022629641525, 'ACC-4': 21.375230141457376, 'ACC-5': 20.629755240727036, 'ACC-6': 19.98958327943888, 'ACC-7': 18.68069760912449, 'ACC-8': 17.143477387023953, 'ACC-9': 32.23884773693057, 'ACC-10': 40.526039517175775, 'ACC-11': 49.11546186474715, 'ACC-12': 47.594974724100375, 'ACC-13': 44.18039896872216, 'ACC-14': 42.61746896186874, 'ACC-15': 40.54784321278062, 'ACC-16': 39.67271263624671, 'ACC-17': 38.88146990043512, 'ACC-18': 37.18972694254718, 'ACC-19': 36.97739835749429, 'ACC-20': 35.25283431406939, 'ACC-21': 36.396960975625525, 'ACC-22': 36.33413733070367, 'ACC-23': 34.87492287185761, 'ACC-24': 34.54967368363188, 'ACC-25': 34.367252994238754, 'ACC-26': 33.01005570283106, 'ACC-27': 33.89163929651593, 'ACC-28': 32.35576469590073, 'ACC-29': 31.356925461983053, 'ACC-30': 30.167567585153428, 'ACC-31': 29.477570813638504, 'ACC-32': 26.9473645687914, 'ACC-33': 25.90295758115136, 'ACC-34': 26.08688640759611, 'ACC-35': 25.2028505244059, 'ACC-36': 23.989387612205622, 'ACC-37': 23.27089769193153, 'ACC-38': 21.234313356711056, 'ACC-39': 19.106992005274446, 'ACC-40': 17.72275670988614, 'ACC-41': 17.111925476358465, 'ACC-42': 16.165939828219305, 'ACC-43': 15.965296235966896, 'ACC-44': 14.7453240162609, 'ACC-45': 14.552184911608748, 'ACC-46': 14.440069053355858, 'ACC-47': 13.492146494930294, 'ACC-48': 12.884235839071708, 'ACC-49': 12.126672684940116, 'ACC-50': 11.474086800644361, 'ACC-51': 10.642640548207694, 'ACC-52': 10.290890675987265, 'ACC-53': 9.687451619635171, 'ACC-54': 9.322579727212922, 'ACC-55': 9.203409995870825, 'ACC-56': 9.375566206902954, 'ACC-57': 9.058650699972567, 'ACC-58': 9.145603525591207, 'ACC-59': 8.75292286263413, 'ACC-60': 8.557523412040226, 'ACC-61': 8.555303511902219, 'ACC-62': 8.64939611909517, 'ACC-63': 8.052304819328668, 'ACC-64': 7.750975194342318, 'ACC-65': 7.953995450784341, 'ACC-66': 7.725382466534561, 'ACC-67': 8.379370185809936, 'ACC-68': 8.858307531346677, 'ACC-69': 8.796521230343398, 'ACC-70': 8.355410501897985, 'ACC-71': 8.809977578784359, 'ACC-72': 8.853179704698752, 'ACC-73': 8.80061558343635, 'ACC-74': 9.03872613132901, 'ACC-75': 8.541047176105856, 'ACC-76': 9.026855503293923, 'ACC-77': 9.286954524545017, 'ACC-78': 9.485060583130517, 'ACC-79': 9.87152896933026, 'ACC-80': 9.739848512108116, 'ACC-81': 9.427689450725028, 'ACC-82': 9.011329686009574, 'ACC-83': 9.411180469309173, 'ACC-84': 9.245239856173514, 'ACC-85': 9.43898062883719, 'ACC-86': 9.439287745014042, 'ACC-87': 9.3881920036332, 'ACC-88': 9.147451010162074, 'ACC-89': 8.683964012629945, 'ACC-90': 8.60214087260646, 'ACC-91': 8.65214493464377, 'ACC-92': 8.48831245212338, 'ACC-93': 9.017796491438972, 'ACC-94': 9.096924712505261, 'ACC-95': 9.05275617073117, 'ACC-96': 9.402653080358622, 'ACC-97': 9.360674657655617, 'ACC-98': 9.066401116840177, 'ACC-99': 8.248354876207857, 'ACC-100': 7.950329522757628, 'ACC-101': 8.1207840487232, 'ACC-102': 7.906955142727684, 'ACC-103': 7.825894965523755, 'ACC-104': 8.088143429822187, 'ACC-105': 8.260625388355304, 'ACC-106': 8.46235397742306, 'ACC-107': 8.771088164519231, 'ACC-108': 8.53730087687274, 'ACC-109': 8.602078292460625, 'ACC-110': 8.570566568578714, 'ACC-111': 8.055298834397146, 'ACC-112': 7.3102868860937225, 'ACC-113': 7.879585463839055, 'ACC-114': 7.59002287538944, 'ACC-115': 7.09241050621683, 'ACC-116': 6.772065632118675, 'ACC-117': 7.2331067315906505, 'ACC-118': 7.156074009414295, 'ACC-119': 7.870216084925952, 'ACC-120': 7.940864862585522, 'ACC-121': 7.360284008144885, 'ACC-122': 7.259994150225971, 'ACC-123': 6.610380741667638, 'ACC-124': 6.429701971284444, 'ACC-125': 5.8708584095727145, 'ACC-126': 5.872947385677465, 'ACC-127': 5.695665785120878, 'ACC-128': 5.655507866289543, 'ACC-129': 5.738162189162748, 'ACC-130': 5.676808300420748, 'ACC-131': 5.659152276879379, 'ACC-132': 5.8362738888721335, 'ACC-133': 6.459613382596093, 'ACC-134': 6.231245152951314, 'ACC-135': 5.981985063565362, 'ACC-136': 5.223353638650765, 'ACC-137': 5.295916630603938, 'ACC-138': 5.231124831839988, 'ACC-139': 5.2712311426985625, 'ACC-140': 5.030918340133215, 'ACC-141': 4.7943326393318735, 'ACC-142': 4.706037494945684, 'ACC-143': 4.7393501208155975, 'ACC-144': 4.586281588447654, 'ACC-145': 4.98615800890002, 'ACC-146': 5.053939823170593, 'ACC-147': 5.142235299907241, 'ACC-148': 5.160016006828566, 'ACC-149': 5.088994786368906, 'ACC-150': 4.970768462668163, 'ACC-151': 5.600122777456269, 'ACC-152': 5.478707262795873, 'ACC-153': 4.712549698602026, 'ACC-154': 4.432483588069045, 'ACC-155': 4.448273566975543, 'ACC-156': 5.165635685521663, 'ACC-157': 4.900555712074999, 'ACC-158': 5.798030064173221, 'ACC-159': 5.690598179121998, 'ACC-160': 4.723199339456182, 'ACC-161': 4.526689452000551, 'ACC-162': 4.609328743443191, 'ACC-163': 4.504354392685659, 'ACC-164': 5.210093892991797, 'ACC-165': 6.69288212256255, 'ACC-166': 5.532061344234498, 'ACC-167': 4.878341124295817, 'ACC-168': 4.610556297911246, 'ACC-169': 5.329421487893341, 'ACC-170': 5.162414640032937, 'ACC-171': 4.477699670652028, 'ACC-172': 5.877319702189132, 'ACC-173': 5.5922228535519825, 'ACC-174': 4.985824288278615, 'ACC-175': 5.358130006896182, 'ACC-176': 4.8609095658230785, 'ACC-177': 4.887712712851261, 'ACC-178': 5.21970752021881, 'ACC-179': 5.718824625010905, 'ACC-180': 4.875292085746215, 'ACC-181': 7.445147934179889, 'ACC-182': 3.594502581209176, 'ACC-183': 2.3044089360590085, 'ACC-184': 3.460710301709601, 'ACC-185': 5.600053582399106, 'ACC-186': 0.6982788535762594, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 06:03:52] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 06:03:52] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 06:03:52] d2.evaluation.testing INFO: copypaste: 2.5553,0.4063,0.1693,6.6647,17.2909,12.0996,25.8724
[01/30 06:03:52] d2.utils.events INFO:  eta: 21:27:01  iter: 33999  total_loss: 20.68  loss_mask: 2.049  loss_mask_0: 2.105  loss_mask_1: 2.048  loss_mask_2: 2.072  loss_mask_3: 2.066  loss_mask_4: 2.076  loss_mask_5: 2.05  loss_mask_6: 2.048  loss_mask_7: 2.067  loss_mask_8: 2.073  time: 2.9892  data_time: 0.0517  lr: 4.7115e-05  max_mem: 27646M
[01/30 06:04:51] d2.utils.events INFO:  eta: 21:25:31  iter: 34019  total_loss: 21.53  loss_mask: 2.134  loss_mask_0: 2.177  loss_mask_1: 2.144  loss_mask_2: 2.152  loss_mask_3: 2.164  loss_mask_4: 2.154  loss_mask_5: 2.146  loss_mask_6: 2.144  loss_mask_7: 2.144  loss_mask_8: 2.167  time: 2.9892  data_time: 0.0578  lr: 4.7082e-05  max_mem: 27646M
[01/30 06:05:49] d2.utils.events INFO:  eta: 21:23:48  iter: 34039  total_loss: 21.1  loss_mask: 2.129  loss_mask_0: 2.113  loss_mask_1: 2.083  loss_mask_2: 2.103  loss_mask_3: 2.12  loss_mask_4: 2.078  loss_mask_5: 2.137  loss_mask_6: 2.116  loss_mask_7: 2.127  loss_mask_8: 2.084  time: 2.9892  data_time: 0.0519  lr: 4.7049e-05  max_mem: 27646M
[01/30 06:06:48] d2.utils.events INFO:  eta: 21:22:39  iter: 34059  total_loss: 20.39  loss_mask: 2.038  loss_mask_0: 2.098  loss_mask_1: 2.029  loss_mask_2: 2.051  loss_mask_3: 2.05  loss_mask_4: 2.068  loss_mask_5: 2.025  loss_mask_6: 2.028  loss_mask_7: 2.043  loss_mask_8: 2.042  time: 2.9892  data_time: 0.0535  lr: 4.7017e-05  max_mem: 27646M
[01/30 06:07:47] d2.utils.events INFO:  eta: 21:21:15  iter: 34079  total_loss: 20.27  loss_mask: 2.012  loss_mask_0: 2.066  loss_mask_1: 2.004  loss_mask_2: 2.029  loss_mask_3: 2.03  loss_mask_4: 2.025  loss_mask_5: 2.023  loss_mask_6: 2.01  loss_mask_7: 2.027  loss_mask_8: 2.032  time: 2.9891  data_time: 0.0557  lr: 4.6984e-05  max_mem: 27646M
[01/30 06:08:46] d2.utils.events INFO:  eta: 21:20:08  iter: 34099  total_loss: 22.07  loss_mask: 2.189  loss_mask_0: 2.237  loss_mask_1: 2.195  loss_mask_2: 2.204  loss_mask_3: 2.212  loss_mask_4: 2.21  loss_mask_5: 2.201  loss_mask_6: 2.192  loss_mask_7: 2.218  loss_mask_8: 2.211  time: 2.9891  data_time: 0.0502  lr: 4.6951e-05  max_mem: 27646M
[01/30 06:09:45] d2.utils.events INFO:  eta: 21:19:11  iter: 34119  total_loss: 22.89  loss_mask: 2.285  loss_mask_0: 2.312  loss_mask_1: 2.276  loss_mask_2: 2.289  loss_mask_3: 2.298  loss_mask_4: 2.294  loss_mask_5: 2.287  loss_mask_6: 2.275  loss_mask_7: 2.292  loss_mask_8: 2.303  time: 2.9891  data_time: 0.0524  lr: 4.6919e-05  max_mem: 27646M
[01/30 06:10:44] d2.utils.events INFO:  eta: 21:17:44  iter: 34139  total_loss: 19.4  loss_mask: 1.939  loss_mask_0: 1.964  loss_mask_1: 1.937  loss_mask_2: 1.947  loss_mask_3: 1.944  loss_mask_4: 1.938  loss_mask_5: 1.935  loss_mask_6: 1.937  loss_mask_7: 1.938  loss_mask_8: 1.936  time: 2.9890  data_time: 0.0496  lr: 4.6886e-05  max_mem: 27646M
[01/30 06:11:42] d2.utils.events INFO:  eta: 21:15:55  iter: 34159  total_loss: 20.42  loss_mask: 2.028  loss_mask_0: 2.085  loss_mask_1: 2.021  loss_mask_2: 2.042  loss_mask_3: 2.045  loss_mask_4: 2.047  loss_mask_5: 2.024  loss_mask_6: 2.027  loss_mask_7: 2.045  loss_mask_8: 2.044  time: 2.9890  data_time: 0.0456  lr: 4.6854e-05  max_mem: 27646M
[01/30 06:12:41] d2.utils.events INFO:  eta: 21:14:30  iter: 34179  total_loss: 20.24  loss_mask: 2.019  loss_mask_0: 2.053  loss_mask_1: 2.02  loss_mask_2: 2.022  loss_mask_3: 2.024  loss_mask_4: 2.017  loss_mask_5: 2.03  loss_mask_6: 2.024  loss_mask_7: 2.028  loss_mask_8: 2.025  time: 2.9890  data_time: 0.0485  lr: 4.6821e-05  max_mem: 27646M
[01/30 06:13:40] d2.utils.events INFO:  eta: 21:13:23  iter: 34199  total_loss: 19.72  loss_mask: 1.963  loss_mask_0: 1.998  loss_mask_1: 1.965  loss_mask_2: 1.97  loss_mask_3: 1.971  loss_mask_4: 1.968  loss_mask_5: 1.975  loss_mask_6: 1.971  loss_mask_7: 1.97  loss_mask_8: 1.972  time: 2.9889  data_time: 0.0528  lr: 4.6788e-05  max_mem: 27646M
[01/30 06:14:39] d2.utils.events INFO:  eta: 21:12:11  iter: 34219  total_loss: 18.95  loss_mask: 1.899  loss_mask_0: 1.924  loss_mask_1: 1.866  loss_mask_2: 1.897  loss_mask_3: 1.909  loss_mask_4: 1.903  loss_mask_5: 1.896  loss_mask_6: 1.89  loss_mask_7: 1.895  loss_mask_8: 1.89  time: 2.9889  data_time: 0.0557  lr: 4.6756e-05  max_mem: 27646M
[01/30 06:15:37] d2.utils.events INFO:  eta: 21:10:53  iter: 34239  total_loss: 20.28  loss_mask: 2.032  loss_mask_0: 2.062  loss_mask_1: 2.006  loss_mask_2: 2.025  loss_mask_3: 2.031  loss_mask_4: 2.023  loss_mask_5: 2.02  loss_mask_6: 2.02  loss_mask_7: 2.023  loss_mask_8: 2.033  time: 2.9889  data_time: 0.0545  lr: 4.6723e-05  max_mem: 27646M
[01/30 06:16:36] d2.utils.events INFO:  eta: 21:09:39  iter: 34259  total_loss: 19.43  loss_mask: 1.939  loss_mask_0: 1.995  loss_mask_1: 1.94  loss_mask_2: 1.937  loss_mask_3: 1.936  loss_mask_4: 1.94  loss_mask_5: 1.936  loss_mask_6: 1.932  loss_mask_7: 1.942  loss_mask_8: 1.94  time: 2.9889  data_time: 0.0479  lr: 4.669e-05  max_mem: 27646M
[01/30 06:17:35] d2.utils.events INFO:  eta: 21:08:23  iter: 34279  total_loss: 18.66  loss_mask: 1.855  loss_mask_0: 1.898  loss_mask_1: 1.856  loss_mask_2: 1.868  loss_mask_3: 1.865  loss_mask_4: 1.871  loss_mask_5: 1.855  loss_mask_6: 1.857  loss_mask_7: 1.876  loss_mask_8: 1.87  time: 2.9888  data_time: 0.0549  lr: 4.6658e-05  max_mem: 27646M
[01/30 06:18:34] d2.utils.events INFO:  eta: 21:06:44  iter: 34299  total_loss: 19.26  loss_mask: 1.903  loss_mask_0: 1.99  loss_mask_1: 1.896  loss_mask_2: 1.913  loss_mask_3: 1.937  loss_mask_4: 1.951  loss_mask_5: 1.904  loss_mask_6: 1.898  loss_mask_7: 1.953  loss_mask_8: 1.919  time: 2.9888  data_time: 0.0594  lr: 4.6625e-05  max_mem: 27646M
[01/30 06:19:33] d2.utils.events INFO:  eta: 21:05:33  iter: 34319  total_loss: 19.71  loss_mask: 1.973  loss_mask_0: 2.013  loss_mask_1: 1.956  loss_mask_2: 1.962  loss_mask_3: 1.972  loss_mask_4: 1.971  loss_mask_5: 1.966  loss_mask_6: 1.969  loss_mask_7: 1.967  loss_mask_8: 1.955  time: 2.9888  data_time: 0.0572  lr: 4.6592e-05  max_mem: 27646M
[01/30 06:20:33] d2.utils.events INFO:  eta: 21:04:34  iter: 34339  total_loss: 19.89  loss_mask: 1.987  loss_mask_0: 2.019  loss_mask_1: 1.991  loss_mask_2: 2.006  loss_mask_3: 1.968  loss_mask_4: 1.988  loss_mask_5: 1.99  loss_mask_6: 1.985  loss_mask_7: 1.977  loss_mask_8: 1.986  time: 2.9888  data_time: 0.0642  lr: 4.656e-05  max_mem: 27646M
[01/30 06:21:33] d2.utils.events INFO:  eta: 21:03:23  iter: 34359  total_loss: 19.26  loss_mask: 1.897  loss_mask_0: 1.931  loss_mask_1: 1.911  loss_mask_2: 1.945  loss_mask_3: 1.894  loss_mask_4: 1.906  loss_mask_5: 1.923  loss_mask_6: 1.911  loss_mask_7: 1.902  loss_mask_8: 1.95  time: 2.9888  data_time: 0.0915  lr: 4.6527e-05  max_mem: 27646M
[01/30 06:22:31] d2.utils.events INFO:  eta: 21:01:27  iter: 34379  total_loss: 18.84  loss_mask: 1.881  loss_mask_0: 1.91  loss_mask_1: 1.875  loss_mask_2: 1.884  loss_mask_3: 1.884  loss_mask_4: 1.884  loss_mask_5: 1.887  loss_mask_6: 1.882  loss_mask_7: 1.879  loss_mask_8: 1.882  time: 2.9887  data_time: 0.0503  lr: 4.6494e-05  max_mem: 27646M
[01/30 06:23:30] d2.utils.events INFO:  eta: 21:00:23  iter: 34399  total_loss: 19.91  loss_mask: 1.985  loss_mask_0: 2.022  loss_mask_1: 1.988  loss_mask_2: 2.01  loss_mask_3: 1.967  loss_mask_4: 1.984  loss_mask_5: 2.003  loss_mask_6: 1.992  loss_mask_7: 1.982  loss_mask_8: 1.987  time: 2.9887  data_time: 0.0513  lr: 4.6462e-05  max_mem: 27646M
[01/30 06:24:29] d2.utils.events INFO:  eta: 20:58:51  iter: 34419  total_loss: 21.84  loss_mask: 2.177  loss_mask_0: 2.219  loss_mask_1: 2.177  loss_mask_2: 2.189  loss_mask_3: 2.185  loss_mask_4: 2.186  loss_mask_5: 2.176  loss_mask_6: 2.173  loss_mask_7: 2.183  loss_mask_8: 2.181  time: 2.9887  data_time: 0.0518  lr: 4.6429e-05  max_mem: 27646M
[01/30 06:25:28] d2.utils.events INFO:  eta: 20:57:38  iter: 34439  total_loss: 20.37  loss_mask: 2.002  loss_mask_0: 2.062  loss_mask_1: 2.026  loss_mask_2: 2.061  loss_mask_3: 2.033  loss_mask_4: 2.046  loss_mask_5: 2.029  loss_mask_6: 2.021  loss_mask_7: 2.049  loss_mask_8: 2.041  time: 2.9887  data_time: 0.0564  lr: 4.6396e-05  max_mem: 27646M
[01/30 06:26:27] d2.utils.events INFO:  eta: 20:56:00  iter: 34459  total_loss: 21.53  loss_mask: 2.131  loss_mask_0: 2.18  loss_mask_1: 2.132  loss_mask_2: 2.152  loss_mask_3: 2.153  loss_mask_4: 2.155  loss_mask_5: 2.14  loss_mask_6: 2.14  loss_mask_7: 2.151  loss_mask_8: 2.152  time: 2.9886  data_time: 0.0474  lr: 4.6364e-05  max_mem: 27646M
[01/30 06:27:26] d2.utils.events INFO:  eta: 20:54:40  iter: 34479  total_loss: 21.43  loss_mask: 2.133  loss_mask_0: 2.18  loss_mask_1: 2.132  loss_mask_2: 2.149  loss_mask_3: 2.142  loss_mask_4: 2.145  loss_mask_5: 2.132  loss_mask_6: 2.129  loss_mask_7: 2.147  loss_mask_8: 2.145  time: 2.9886  data_time: 0.0574  lr: 4.6331e-05  max_mem: 27646M
[01/30 06:28:25] d2.utils.events INFO:  eta: 20:53:10  iter: 34499  total_loss: 19.69  loss_mask: 1.974  loss_mask_0: 1.981  loss_mask_1: 1.966  loss_mask_2: 1.968  loss_mask_3: 1.963  loss_mask_4: 1.967  loss_mask_5: 1.969  loss_mask_6: 1.977  loss_mask_7: 1.962  loss_mask_8: 1.964  time: 2.9886  data_time: 0.0661  lr: 4.6298e-05  max_mem: 27646M
[01/30 06:29:24] d2.utils.events INFO:  eta: 20:52:09  iter: 34519  total_loss: 21.19  loss_mask: 2.091  loss_mask_0: 2.154  loss_mask_1: 2.098  loss_mask_2: 2.128  loss_mask_3: 2.124  loss_mask_4: 2.128  loss_mask_5: 2.097  loss_mask_6: 2.092  loss_mask_7: 2.132  loss_mask_8: 2.13  time: 2.9886  data_time: 0.0528  lr: 4.6266e-05  max_mem: 27646M
[01/30 06:30:23] d2.utils.events INFO:  eta: 20:50:55  iter: 34539  total_loss: 20.4  loss_mask: 2.036  loss_mask_0: 2.083  loss_mask_1: 2.025  loss_mask_2: 2.039  loss_mask_3: 2.038  loss_mask_4: 2.041  loss_mask_5: 2.031  loss_mask_6: 2.032  loss_mask_7: 2.038  loss_mask_8: 2.033  time: 2.9885  data_time: 0.0523  lr: 4.6233e-05  max_mem: 27646M
[01/30 06:31:21] d2.utils.events INFO:  eta: 20:49:42  iter: 34559  total_loss: 20.56  loss_mask: 2.062  loss_mask_0: 2.084  loss_mask_1: 2.041  loss_mask_2: 2.053  loss_mask_3: 2.056  loss_mask_4: 2.052  loss_mask_5: 2.067  loss_mask_6: 2.064  loss_mask_7: 2.065  loss_mask_8: 2.07  time: 2.9885  data_time: 0.0513  lr: 4.62e-05  max_mem: 27646M
[01/30 06:32:20] d2.utils.events INFO:  eta: 20:48:34  iter: 34579  total_loss: 20.26  loss_mask: 2.012  loss_mask_0: 2.096  loss_mask_1: 1.997  loss_mask_2: 2.023  loss_mask_3: 2.034  loss_mask_4: 2.034  loss_mask_5: 2.006  loss_mask_6: 2.007  loss_mask_7: 2.03  loss_mask_8: 2.024  time: 2.9885  data_time: 0.0606  lr: 4.6168e-05  max_mem: 27646M
[01/30 06:33:19] d2.utils.events INFO:  eta: 20:47:06  iter: 34599  total_loss: 22.56  loss_mask: 2.248  loss_mask_0: 2.275  loss_mask_1: 2.228  loss_mask_2: 2.256  loss_mask_3: 2.251  loss_mask_4: 2.256  loss_mask_5: 2.248  loss_mask_6: 2.251  loss_mask_7: 2.262  loss_mask_8: 2.26  time: 2.9885  data_time: 0.0510  lr: 4.6135e-05  max_mem: 27646M
[01/30 06:34:19] d2.utils.events INFO:  eta: 20:45:54  iter: 34619  total_loss: 20.19  loss_mask: 2.018  loss_mask_0: 2.062  loss_mask_1: 2.014  loss_mask_2: 2.018  loss_mask_3: 2.02  loss_mask_4: 2.017  loss_mask_5: 2.011  loss_mask_6: 2.012  loss_mask_7: 2.023  loss_mask_8: 2.021  time: 2.9884  data_time: 0.0555  lr: 4.6102e-05  max_mem: 27646M
[01/30 06:35:18] d2.utils.events INFO:  eta: 20:44:55  iter: 34639  total_loss: 19  loss_mask: 1.892  loss_mask_0: 1.939  loss_mask_1: 1.886  loss_mask_2: 1.9  loss_mask_3: 1.896  loss_mask_4: 1.898  loss_mask_5: 1.895  loss_mask_6: 1.889  loss_mask_7: 1.903  loss_mask_8: 1.898  time: 2.9884  data_time: 0.0523  lr: 4.607e-05  max_mem: 27646M
[01/30 06:36:18] d2.utils.events INFO:  eta: 20:43:47  iter: 34659  total_loss: 20.38  loss_mask: 2.032  loss_mask_0: 2.068  loss_mask_1: 2.054  loss_mask_2: 2.051  loss_mask_3: 2.028  loss_mask_4: 2.032  loss_mask_5: 2.036  loss_mask_6: 2.028  loss_mask_7: 2.039  loss_mask_8: 2.045  time: 2.9884  data_time: 0.0660  lr: 4.6037e-05  max_mem: 27646M
[01/30 06:37:16] d2.utils.events INFO:  eta: 20:42:24  iter: 34679  total_loss: 22.35  loss_mask: 2.23  loss_mask_0: 2.244  loss_mask_1: 2.259  loss_mask_2: 2.233  loss_mask_3: 2.245  loss_mask_4: 2.248  loss_mask_5: 2.22  loss_mask_6: 2.237  loss_mask_7: 2.24  loss_mask_8: 2.226  time: 2.9884  data_time: 0.0530  lr: 4.6004e-05  max_mem: 27646M
[01/30 06:38:16] d2.utils.events INFO:  eta: 20:41:25  iter: 34699  total_loss: 21.54  loss_mask: 2.134  loss_mask_0: 2.208  loss_mask_1: 2.128  loss_mask_2: 2.168  loss_mask_3: 2.157  loss_mask_4: 2.166  loss_mask_5: 2.13  loss_mask_6: 2.134  loss_mask_7: 2.165  loss_mask_8: 2.155  time: 2.9884  data_time: 0.0678  lr: 4.5971e-05  max_mem: 27646M
[01/30 06:39:15] d2.utils.events INFO:  eta: 20:40:01  iter: 34719  total_loss: 19.76  loss_mask: 1.946  loss_mask_0: 2.021  loss_mask_1: 1.972  loss_mask_2: 1.989  loss_mask_3: 1.98  loss_mask_4: 1.977  loss_mask_5: 1.949  loss_mask_6: 1.947  loss_mask_7: 1.981  loss_mask_8: 1.971  time: 2.9884  data_time: 0.0550  lr: 4.5939e-05  max_mem: 27646M
[01/30 06:40:14] d2.utils.events INFO:  eta: 20:39:01  iter: 34739  total_loss: 21.58  loss_mask: 2.157  loss_mask_0: 2.181  loss_mask_1: 2.166  loss_mask_2: 2.164  loss_mask_3: 2.151  loss_mask_4: 2.158  loss_mask_5: 2.15  loss_mask_6: 2.155  loss_mask_7: 2.158  loss_mask_8: 2.15  time: 2.9883  data_time: 0.0562  lr: 4.5906e-05  max_mem: 27646M
[01/30 06:41:14] d2.utils.events INFO:  eta: 20:38:04  iter: 34759  total_loss: 19.57  loss_mask: 1.95  loss_mask_0: 2.016  loss_mask_1: 1.953  loss_mask_2: 1.956  loss_mask_3: 1.954  loss_mask_4: 1.969  loss_mask_5: 1.95  loss_mask_6: 1.948  loss_mask_7: 1.961  loss_mask_8: 1.958  time: 2.9883  data_time: 0.0626  lr: 4.5873e-05  max_mem: 27646M
[01/30 06:42:12] d2.utils.events INFO:  eta: 20:37:05  iter: 34779  total_loss: 20.17  loss_mask: 2.013  loss_mask_0: 2.065  loss_mask_1: 2.007  loss_mask_2: 2.013  loss_mask_3: 2.017  loss_mask_4: 2.028  loss_mask_5: 2.014  loss_mask_6: 2.001  loss_mask_7: 2.022  loss_mask_8: 2.024  time: 2.9883  data_time: 0.0542  lr: 4.5841e-05  max_mem: 27646M
[01/30 06:43:12] d2.utils.events INFO:  eta: 20:36:36  iter: 34799  total_loss: 19.29  loss_mask: 1.909  loss_mask_0: 2.006  loss_mask_1: 1.906  loss_mask_2: 1.927  loss_mask_3: 1.923  loss_mask_4: 1.92  loss_mask_5: 1.919  loss_mask_6: 1.9  loss_mask_7: 1.944  loss_mask_8: 1.933  time: 2.9883  data_time: 0.0736  lr: 4.5808e-05  max_mem: 27646M
[01/30 06:44:12] d2.utils.events INFO:  eta: 20:35:37  iter: 34819  total_loss: 19.18  loss_mask: 1.904  loss_mask_0: 1.946  loss_mask_1: 1.909  loss_mask_2: 1.917  loss_mask_3: 1.917  loss_mask_4: 1.922  loss_mask_5: 1.905  loss_mask_6: 1.903  loss_mask_7: 1.918  loss_mask_8: 1.919  time: 2.9883  data_time: 0.0607  lr: 4.5775e-05  max_mem: 27646M
[01/30 06:45:11] d2.utils.events INFO:  eta: 20:34:56  iter: 34839  total_loss: 19.53  loss_mask: 1.943  loss_mask_0: 1.954  loss_mask_1: 1.937  loss_mask_2: 1.949  loss_mask_3: 1.956  loss_mask_4: 1.953  loss_mask_5: 1.939  loss_mask_6: 1.944  loss_mask_7: 1.969  loss_mask_8: 1.947  time: 2.9883  data_time: 0.0584  lr: 4.5742e-05  max_mem: 27646M
[01/30 06:46:10] d2.utils.events INFO:  eta: 20:33:57  iter: 34859  total_loss: 19.19  loss_mask: 1.909  loss_mask_0: 1.959  loss_mask_1: 1.898  loss_mask_2: 1.918  loss_mask_3: 1.918  loss_mask_4: 1.91  loss_mask_5: 1.901  loss_mask_6: 1.916  loss_mask_7: 1.944  loss_mask_8: 1.92  time: 2.9883  data_time: 0.0593  lr: 4.571e-05  max_mem: 27646M
[01/30 06:47:10] d2.utils.events INFO:  eta: 20:33:35  iter: 34879  total_loss: 18.94  loss_mask: 1.893  loss_mask_0: 1.894  loss_mask_1: 1.895  loss_mask_2: 1.895  loss_mask_3: 1.894  loss_mask_4: 1.889  loss_mask_5: 1.903  loss_mask_6: 1.899  loss_mask_7: 1.897  loss_mask_8: 1.884  time: 2.9883  data_time: 0.0694  lr: 4.5677e-05  max_mem: 27646M
[01/30 06:48:09] d2.utils.events INFO:  eta: 20:32:54  iter: 34899  total_loss: 20.62  loss_mask: 2.051  loss_mask_0: 2.117  loss_mask_1: 2.069  loss_mask_2: 2.057  loss_mask_3: 2.056  loss_mask_4: 2.057  loss_mask_5: 2.053  loss_mask_6: 2.054  loss_mask_7: 2.055  loss_mask_8: 2.049  time: 2.9882  data_time: 0.0592  lr: 4.5644e-05  max_mem: 27646M
[01/30 06:49:08] d2.utils.events INFO:  eta: 20:31:57  iter: 34919  total_loss: 21.59  loss_mask: 2.142  loss_mask_0: 2.181  loss_mask_1: 2.145  loss_mask_2: 2.159  loss_mask_3: 2.158  loss_mask_4: 2.164  loss_mask_5: 2.145  loss_mask_6: 2.14  loss_mask_7: 2.171  loss_mask_8: 2.167  time: 2.9882  data_time: 0.0613  lr: 4.5611e-05  max_mem: 27646M
[01/30 06:50:07] d2.utils.events INFO:  eta: 20:30:58  iter: 34939  total_loss: 20.02  loss_mask: 1.973  loss_mask_0: 2.024  loss_mask_1: 1.993  loss_mask_2: 2.016  loss_mask_3: 2.003  loss_mask_4: 2.001  loss_mask_5: 1.979  loss_mask_6: 1.996  loss_mask_7: 2.003  loss_mask_8: 1.994  time: 2.9882  data_time: 0.0541  lr: 4.5579e-05  max_mem: 27646M
[01/30 06:51:06] d2.utils.events INFO:  eta: 20:29:55  iter: 34959  total_loss: 20.13  loss_mask: 1.996  loss_mask_0: 2.06  loss_mask_1: 1.988  loss_mask_2: 2.033  loss_mask_3: 2.022  loss_mask_4: 2.025  loss_mask_5: 1.995  loss_mask_6: 1.991  loss_mask_7: 2.019  loss_mask_8: 2.023  time: 2.9882  data_time: 0.0648  lr: 4.5546e-05  max_mem: 27646M
[01/30 06:52:05] d2.utils.events INFO:  eta: 20:28:25  iter: 34979  total_loss: 18.83  loss_mask: 1.881  loss_mask_0: 1.896  loss_mask_1: 1.881  loss_mask_2: 1.886  loss_mask_3: 1.883  loss_mask_4: 1.879  loss_mask_5: 1.88  loss_mask_6: 1.88  loss_mask_7: 1.885  loss_mask_8: 1.882  time: 2.9881  data_time: 0.0564  lr: 4.5513e-05  max_mem: 27646M
[01/30 06:53:04] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_fixclasses/model_0034999.pth
[01/30 06:53:05] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 06:53:06] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 06:53:06] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 07:07:16] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.2624424251874045, 'error_1pix': 0.3331084222397599, 'error_3pix': 0.13927449966775898, 'mIoU': 8.260696917747854, 'fwIoU': 20.780293753340544, 'IoU-0': 6.775246835181044e-05, 'IoU-1': 58.15353107048716, 'IoU-2': 2.574971648508588, 'IoU-3': 5.401463654438065, 'IoU-4': 5.863604328427962, 'IoU-5': 5.5509835822593265, 'IoU-6': 5.039370736306073, 'IoU-7': 3.94797221931002, 'IoU-8': 8.99420630197899, 'IoU-9': 19.106647706730957, 'IoU-10': 21.362042510468722, 'IoU-11': 28.17941274612895, 'IoU-12': 27.780858848926705, 'IoU-13': 26.9089794778746, 'IoU-14': 28.142225099606883, 'IoU-15': 27.03008882058307, 'IoU-16': 26.443017639916544, 'IoU-17': 23.73802318275637, 'IoU-18': 23.44622087165014, 'IoU-19': 23.668577575461452, 'IoU-20': 22.29791531644311, 'IoU-21': 22.425081801430796, 'IoU-22': 23.07501621675009, 'IoU-23': 21.555393272384045, 'IoU-24': 20.809171636624953, 'IoU-25': 20.93040603462802, 'IoU-26': 19.964955183192227, 'IoU-27': 21.734849866480435, 'IoU-28': 20.763819634892933, 'IoU-29': 21.444349476592357, 'IoU-30': 20.62190179434131, 'IoU-31': 22.0770303754542, 'IoU-32': 20.645592394754832, 'IoU-33': 19.969504734358704, 'IoU-34': 19.14444560850098, 'IoU-35': 19.514023872203097, 'IoU-36': 19.512537976670696, 'IoU-37': 19.186806292674525, 'IoU-38': 19.443292324749425, 'IoU-39': 18.404069947286793, 'IoU-40': 18.613556453913624, 'IoU-41': 17.352977290315494, 'IoU-42': 17.04674238328264, 'IoU-43': 16.716285345737685, 'IoU-44': 16.588372422766398, 'IoU-45': 16.07384523170093, 'IoU-46': 15.076168567307985, 'IoU-47': 14.638365820195432, 'IoU-48': 14.417356361698078, 'IoU-49': 14.079849741786651, 'IoU-50': 14.407804936221172, 'IoU-51': 13.199776586320919, 'IoU-52': 12.73518214828219, 'IoU-53': 12.224550736912205, 'IoU-54': 12.258126699753129, 'IoU-55': 11.847096201045373, 'IoU-56': 10.890477633459614, 'IoU-57': 10.94453668400133, 'IoU-58': 10.432061740235483, 'IoU-59': 10.252704772653983, 'IoU-60': 9.81872042352538, 'IoU-61': 9.47155891230817, 'IoU-62': 9.00285634305946, 'IoU-63': 8.520008850105311, 'IoU-64': 8.07411491211514, 'IoU-65': 7.770749291559737, 'IoU-66': 7.388686325851659, 'IoU-67': 7.237134125188207, 'IoU-68': 7.430060058114369, 'IoU-69': 7.437390131806533, 'IoU-70': 6.995918672153281, 'IoU-71': 7.0028405924295445, 'IoU-72': 7.0257161475032515, 'IoU-73': 6.979964039788363, 'IoU-74': 6.953999410907892, 'IoU-75': 6.566395054250039, 'IoU-76': 6.899128415056153, 'IoU-77': 6.857062800508978, 'IoU-78': 6.683760700737001, 'IoU-79': 6.560214009379448, 'IoU-80': 6.636312864397722, 'IoU-81': 6.54762150879188, 'IoU-82': 6.326400456742469, 'IoU-83': 6.348931226119419, 'IoU-84': 6.381940729911426, 'IoU-85': 6.3595295889566446, 'IoU-86': 6.055247700572123, 'IoU-87': 6.186080987801203, 'IoU-88': 6.072467181936921, 'IoU-89': 6.015493695930114, 'IoU-90': 5.920309475239237, 'IoU-91': 5.875014874151933, 'IoU-92': 5.722213215640034, 'IoU-93': 5.800026916434085, 'IoU-94': 5.985102187440678, 'IoU-95': 5.962873466948558, 'IoU-96': 6.0503670687529505, 'IoU-97': 6.074153987100939, 'IoU-98': 6.141514236704465, 'IoU-99': 5.634515387014186, 'IoU-100': 5.742219651219302, 'IoU-101': 5.6540414402976085, 'IoU-102': 5.457189611266094, 'IoU-103': 5.35180734138235, 'IoU-104': 5.147247646943437, 'IoU-105': 5.111466371544021, 'IoU-106': 5.137621607644532, 'IoU-107': 5.277780082887877, 'IoU-108': 5.273359437729443, 'IoU-109': 5.310364309677138, 'IoU-110': 5.20892339237339, 'IoU-111': 4.939290869168338, 'IoU-112': 4.554834013661503, 'IoU-113': 4.531527248598202, 'IoU-114': 4.498799675389246, 'IoU-115': 4.434622006744688, 'IoU-116': 4.186720015630216, 'IoU-117': 4.463984777223639, 'IoU-118': 4.1766234125592705, 'IoU-119': 4.396151179879655, 'IoU-120': 4.128909233042481, 'IoU-121': 3.984946952198254, 'IoU-122': 3.957456703294996, 'IoU-123': 3.512302290528945, 'IoU-124': 3.440335302690909, 'IoU-125': 3.1773688692297526, 'IoU-126': 3.0402203950127094, 'IoU-127': 2.9855174593477187, 'IoU-128': 2.993231367539582, 'IoU-129': 2.9443484113750746, 'IoU-130': 2.9332832719654918, 'IoU-131': 2.9383435020379465, 'IoU-132': 2.982396168664611, 'IoU-133': 2.995237788157976, 'IoU-134': 2.8962367892489085, 'IoU-135': 2.8933386536423944, 'IoU-136': 2.8327165394070866, 'IoU-137': 2.57462384201747, 'IoU-138': 2.4977460548561914, 'IoU-139': 2.4107627272831578, 'IoU-140': 2.3127159964015704, 'IoU-141': 2.3160952884024213, 'IoU-142': 2.2958123421359504, 'IoU-143': 2.224996245682535, 'IoU-144': 2.3680506603029032, 'IoU-145': 2.4100996802708297, 'IoU-146': 2.2684003021827044, 'IoU-147': 2.443295781491245, 'IoU-148': 2.547085475978132, 'IoU-149': 2.2905383232292027, 'IoU-150': 2.306322360864072, 'IoU-151': 2.4668289936793157, 'IoU-152': 2.560287497832299, 'IoU-153': 2.4933876278382314, 'IoU-154': 2.4401205207763694, 'IoU-155': 2.3949268779808364, 'IoU-156': 2.2748927299352224, 'IoU-157': 2.5263286694195357, 'IoU-158': 2.927438128957824, 'IoU-159': 2.3103163330826355, 'IoU-160': 2.4470504614974553, 'IoU-161': 2.2407794484525656, 'IoU-162': 2.119795953348623, 'IoU-163': 2.059044841341288, 'IoU-164': 2.077818882379619, 'IoU-165': 1.9279316039279242, 'IoU-166': 1.9950035547047211, 'IoU-167': 1.690053009042719, 'IoU-168': 1.8290992919642175, 'IoU-169': 1.886182534798763, 'IoU-170': 1.7486435391718322, 'IoU-171': 1.6731109467879923, 'IoU-172': 1.7762660920633584, 'IoU-173': 1.7975222940843287, 'IoU-174': 1.5945500759084283, 'IoU-175': 1.5239911376966957, 'IoU-176': 2.1766685455186603, 'IoU-177': 1.6984554873844964, 'IoU-178': 2.2407833584984433, 'IoU-179': 3.1445981964018292, 'IoU-180': 2.05817163508132, 'IoU-181': 1.1731781638350698, 'IoU-182': 1.2486420734696924, 'IoU-183': 1.4567964902726964, 'IoU-184': 1.272109436263832, 'IoU-185': 0.5284440966539351, 'IoU-186': 0.33557771450931706, 'IoU-187': 0.021736745243275582, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 14.759417110337026, 'pACC': 30.96805340625973, 'ACC-0': 0.00027915981271168166, 'ACC-1': 59.095873375523034, 'ACC-2': 4.897208959021146, 'ACC-3': 20.6167056806339, 'ACC-4': 20.929630687494384, 'ACC-5': 20.332111299264728, 'ACC-6': 18.73267832166626, 'ACC-7': 16.75180765065579, 'ACC-8': 23.79900662582573, 'ACC-9': 36.66244130672345, 'ACC-10': 39.04039245365827, 'ACC-11': 43.6507430836753, 'ACC-12': 42.12593469281721, 'ACC-13': 39.4501868739943, 'ACC-14': 41.55180914907916, 'ACC-15': 40.66330711236206, 'ACC-16': 39.31056567101211, 'ACC-17': 38.26963228267893, 'ACC-18': 37.33035297088341, 'ACC-19': 38.42059110927521, 'ACC-20': 36.21483773022335, 'ACC-21': 36.47888806159653, 'ACC-22': 36.90035219334119, 'ACC-23': 36.27233058600076, 'ACC-24': 35.07798295023597, 'ACC-25': 35.62560157059741, 'ACC-26': 33.65729720771218, 'ACC-27': 36.370386723383426, 'ACC-28': 35.253691589123065, 'ACC-29': 35.24447644358094, 'ACC-30': 34.80380359392838, 'ACC-31': 36.76347974953364, 'ACC-32': 34.966806828665284, 'ACC-33': 34.18439504403638, 'ACC-34': 33.01536970125886, 'ACC-35': 33.480268105061, 'ACC-36': 33.3398944406166, 'ACC-37': 33.429042602794, 'ACC-38': 33.94127675935667, 'ACC-39': 32.2404194093525, 'ACC-40': 31.81720206760554, 'ACC-41': 30.54993966189873, 'ACC-42': 30.131747930779092, 'ACC-43': 29.540803114066584, 'ACC-44': 28.521385595210987, 'ACC-45': 27.739462038621674, 'ACC-46': 26.857393297544657, 'ACC-47': 26.135453201261765, 'ACC-48': 25.847860436465194, 'ACC-49': 25.299204640805286, 'ACC-50': 25.89976340865595, 'ACC-51': 24.234487740581955, 'ACC-52': 23.16233665783802, 'ACC-53': 22.264237805699285, 'ACC-54': 22.11333915009025, 'ACC-55': 21.312681302338838, 'ACC-56': 19.683478500571596, 'ACC-57': 19.58022249172015, 'ACC-58': 18.91016929476262, 'ACC-59': 18.93720895152787, 'ACC-60': 18.271897942165417, 'ACC-61': 17.700192182358222, 'ACC-62': 16.883508012138606, 'ACC-63': 16.134593022826845, 'ACC-64': 15.246703890193608, 'ACC-65': 14.659266319037611, 'ACC-66': 14.002663907366669, 'ACC-67': 13.867956848267035, 'ACC-68': 14.250625196798241, 'ACC-69': 13.948199980955486, 'ACC-70': 12.996688636520565, 'ACC-71': 13.161490638715215, 'ACC-72': 13.268989538036093, 'ACC-73': 13.196846151432288, 'ACC-74': 13.04123716393616, 'ACC-75': 12.372673873232438, 'ACC-76': 12.832913729332757, 'ACC-77': 12.956476906674036, 'ACC-78': 12.690490404019899, 'ACC-79': 12.5039136755938, 'ACC-80': 12.593120755181417, 'ACC-81': 12.282161998056546, 'ACC-82': 11.779102063483956, 'ACC-83': 11.58196828319484, 'ACC-84': 11.664653324204014, 'ACC-85': 11.715753055285143, 'ACC-86': 11.267797036263175, 'ACC-87': 11.582854469412904, 'ACC-88': 11.392134126216655, 'ACC-89': 11.238371801752987, 'ACC-90': 10.904779993371976, 'ACC-91': 10.823451223750483, 'ACC-92': 10.580315479824169, 'ACC-93': 10.666344918193534, 'ACC-94': 11.02104726664088, 'ACC-95': 11.018623158067046, 'ACC-96': 11.257631099029803, 'ACC-97': 11.187744068521779, 'ACC-98': 11.283580893194124, 'ACC-99': 10.407649758139225, 'ACC-100': 10.561210463959284, 'ACC-101': 10.394668062884842, 'ACC-102': 10.06812415043045, 'ACC-103': 9.801761594408237, 'ACC-104': 9.518850987432675, 'ACC-105': 9.56856391348242, 'ACC-106': 9.596996174417608, 'ACC-107': 9.859274440948788, 'ACC-108': 9.772174483553213, 'ACC-109': 9.954995371965023, 'ACC-110': 9.87351140517089, 'ACC-111': 9.406461726400952, 'ACC-112': 8.815185991155387, 'ACC-113': 8.719754621225126, 'ACC-114': 8.697276272532369, 'ACC-115': 8.549268564040112, 'ACC-116': 8.085203217778588, 'ACC-117': 8.589502598593457, 'ACC-118': 8.112031043411482, 'ACC-119': 8.499672104710326, 'ACC-120': 8.027177178760054, 'ACC-121': 7.76711949844365, 'ACC-122': 7.6917452140356835, 'ACC-123': 6.804491689840902, 'ACC-124': 6.862337189101705, 'ACC-125': 6.197497615196609, 'ACC-126': 5.92235585023543, 'ACC-127': 5.765461316337879, 'ACC-128': 5.850228871886628, 'ACC-129': 5.797588918891613, 'ACC-130': 5.764001929610492, 'ACC-131': 5.804296234564332, 'ACC-132': 5.829772831612564, 'ACC-133': 5.815114957779638, 'ACC-134': 5.588418785006462, 'ACC-135': 5.637435151929764, 'ACC-136': 5.577143705739843, 'ACC-137': 5.140904140306529, 'ACC-138': 5.021321420412722, 'ACC-139': 4.823189612979021, 'ACC-140': 4.543828175859344, 'ACC-141': 4.5017243439666474, 'ACC-142': 4.3705968502988055, 'ACC-143': 4.260400969400272, 'ACC-144': 4.562996389891697, 'ACC-145': 4.58489680001789, 'ACC-146': 4.288867058097828, 'ACC-147': 4.519755650739148, 'ACC-148': 4.593218389602786, 'ACC-149': 4.225870603375626, 'ACC-150': 4.2734641847220525, 'ACC-151': 4.595415242522778, 'ACC-152': 4.775798266909434, 'ACC-153': 4.937682075523552, 'ACC-154': 4.8515440894152295, 'ACC-155': 4.7768714425520695, 'ACC-156': 4.5990162048258965, 'ACC-157': 5.226796673077159, 'ACC-158': 6.037674070038713, 'ACC-159': 4.764281076421869, 'ACC-160': 5.140139347599873, 'ACC-161': 4.666546842396448, 'ACC-162': 4.452233108500123, 'ACC-163': 4.388023241771596, 'ACC-164': 4.394674006449792, 'ACC-165': 3.9771048861755824, 'ACC-166': 4.2163668566536, 'ACC-167': 3.7189903190559823, 'ACC-168': 3.910260918489345, 'ACC-169': 4.249043241450588, 'ACC-170': 4.14306401465139, 'ACC-171': 4.39302068848972, 'ACC-172': 4.1328666148090525, 'ACC-173': 4.107949863218853, 'ACC-174': 3.45548118199899, 'ACC-175': 3.77958841071663, 'ACC-176': 5.687870037148827, 'ACC-177': 5.0556499818221745, 'ACC-178': 6.759369609685713, 'ACC-179': 9.189439235839888, 'ACC-180': 6.468217684310338, 'ACC-181': 4.135666929587073, 'ACC-182': 5.231124241569906, 'ACC-183': 3.8041111145117963, 'ACC-184': 3.994179478652979, 'ACC-185': 1.4146215281145924, 'ACC-186': 0.5870924641122911, 'ACC-187': 0.025368752944587396, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 07:07:16] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 07:07:16] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 07:07:16] d2.evaluation.testing INFO: copypaste: 2.2624,0.3331,0.1393,8.2607,20.7803,14.7594,30.9681
[01/30 07:07:16] d2.utils.events INFO:  eta: 20:27:43  iter: 34999  total_loss: 19.68  loss_mask: 1.963  loss_mask_0: 2.001  loss_mask_1: 1.98  loss_mask_2: 1.971  loss_mask_3: 1.959  loss_mask_4: 1.96  loss_mask_5: 1.964  loss_mask_6: 1.951  loss_mask_7: 1.953  loss_mask_8: 1.974  time: 2.9881  data_time: 0.0557  lr: 4.5481e-05  max_mem: 27646M
[01/30 07:08:15] d2.utils.events INFO:  eta: 20:26:21  iter: 35019  total_loss: 19.32  loss_mask: 1.923  loss_mask_0: 1.961  loss_mask_1: 1.924  loss_mask_2: 1.935  loss_mask_3: 1.928  loss_mask_4: 1.929  loss_mask_5: 1.926  loss_mask_6: 1.921  loss_mask_7: 1.934  loss_mask_8: 1.936  time: 2.9881  data_time: 0.0524  lr: 4.5448e-05  max_mem: 27646M
[01/30 07:09:14] d2.utils.events INFO:  eta: 20:25:52  iter: 35039  total_loss: 19.51  loss_mask: 1.932  loss_mask_0: 2.009  loss_mask_1: 1.927  loss_mask_2: 1.95  loss_mask_3: 1.957  loss_mask_4: 1.958  loss_mask_5: 1.929  loss_mask_6: 1.939  loss_mask_7: 1.953  loss_mask_8: 1.951  time: 2.9881  data_time: 0.0625  lr: 4.5415e-05  max_mem: 27646M
[01/30 07:10:13] d2.utils.events INFO:  eta: 20:24:47  iter: 35059  total_loss: 18.31  loss_mask: 1.811  loss_mask_0: 1.871  loss_mask_1: 1.82  loss_mask_2: 1.826  loss_mask_3: 1.826  loss_mask_4: 1.823  loss_mask_5: 1.824  loss_mask_6: 1.812  loss_mask_7: 1.829  loss_mask_8: 1.836  time: 2.9881  data_time: 0.0651  lr: 4.5382e-05  max_mem: 27646M
[01/30 07:11:13] d2.utils.events INFO:  eta: 20:24:13  iter: 35079  total_loss: 21.11  loss_mask: 2.108  loss_mask_0: 2.155  loss_mask_1: 2.108  loss_mask_2: 2.119  loss_mask_3: 2.115  loss_mask_4: 2.111  loss_mask_5: 2.108  loss_mask_6: 2.111  loss_mask_7: 2.111  loss_mask_8: 2.121  time: 2.9881  data_time: 0.0735  lr: 4.535e-05  max_mem: 27646M
[01/30 07:12:12] d2.utils.events INFO:  eta: 20:23:19  iter: 35099  total_loss: 18.67  loss_mask: 1.846  loss_mask_0: 1.937  loss_mask_1: 1.834  loss_mask_2: 1.869  loss_mask_3: 1.88  loss_mask_4: 1.867  loss_mask_5: 1.861  loss_mask_6: 1.859  loss_mask_7: 1.874  loss_mask_8: 1.862  time: 2.9880  data_time: 0.0621  lr: 4.5317e-05  max_mem: 27646M
[01/30 07:13:12] d2.utils.events INFO:  eta: 20:22:27  iter: 35119  total_loss: 19.83  loss_mask: 1.974  loss_mask_0: 2.022  loss_mask_1: 1.972  loss_mask_2: 1.99  loss_mask_3: 1.998  loss_mask_4: 1.997  loss_mask_5: 1.97  loss_mask_6: 1.962  loss_mask_7: 1.992  loss_mask_8: 1.993  time: 2.9880  data_time: 0.0613  lr: 4.5284e-05  max_mem: 27646M
[01/30 07:14:11] d2.utils.events INFO:  eta: 20:21:28  iter: 35139  total_loss: 19.11  loss_mask: 1.895  loss_mask_0: 1.966  loss_mask_1: 1.883  loss_mask_2: 1.917  loss_mask_3: 1.911  loss_mask_4: 1.922  loss_mask_5: 1.91  loss_mask_6: 1.896  loss_mask_7: 1.921  loss_mask_8: 1.917  time: 2.9880  data_time: 0.0581  lr: 4.5251e-05  max_mem: 27646M
[01/30 07:15:10] d2.utils.events INFO:  eta: 20:20:38  iter: 35159  total_loss: 20.04  loss_mask: 1.98  loss_mask_0: 2.044  loss_mask_1: 1.982  loss_mask_2: 2.009  loss_mask_3: 2.014  loss_mask_4: 2.017  loss_mask_5: 1.986  loss_mask_6: 1.977  loss_mask_7: 2.013  loss_mask_8: 2.014  time: 2.9880  data_time: 0.0607  lr: 4.5218e-05  max_mem: 27646M
[01/30 07:16:10] d2.utils.events INFO:  eta: 20:19:55  iter: 35179  total_loss: 20.33  loss_mask: 2.023  loss_mask_0: 2.11  loss_mask_1: 2.014  loss_mask_2: 2.033  loss_mask_3: 2.034  loss_mask_4: 2.04  loss_mask_5: 2.015  loss_mask_6: 2.016  loss_mask_7: 2.037  loss_mask_8: 2.031  time: 2.9880  data_time: 0.0722  lr: 4.5186e-05  max_mem: 27646M
[01/30 07:17:09] d2.utils.events INFO:  eta: 20:19:19  iter: 35199  total_loss: 19.98  loss_mask: 2.004  loss_mask_0: 2.033  loss_mask_1: 1.991  loss_mask_2: 1.998  loss_mask_3: 2.001  loss_mask_4: 2  loss_mask_5: 1.988  loss_mask_6: 1.986  loss_mask_7: 2  loss_mask_8: 1.995  time: 2.9880  data_time: 0.0606  lr: 4.5153e-05  max_mem: 27646M
[01/30 07:18:08] d2.utils.events INFO:  eta: 20:18:17  iter: 35219  total_loss: 19.77  loss_mask: 1.988  loss_mask_0: 1.991  loss_mask_1: 1.973  loss_mask_2: 1.963  loss_mask_3: 1.961  loss_mask_4: 1.973  loss_mask_5: 1.994  loss_mask_6: 1.99  loss_mask_7: 1.965  loss_mask_8: 1.974  time: 2.9880  data_time: 0.0532  lr: 4.512e-05  max_mem: 27646M
[01/30 07:19:07] d2.utils.events INFO:  eta: 20:17:13  iter: 35239  total_loss: 21.12  loss_mask: 2.107  loss_mask_0: 2.149  loss_mask_1: 2.095  loss_mask_2: 2.107  loss_mask_3: 2.105  loss_mask_4: 2.109  loss_mask_5: 2.107  loss_mask_6: 2.105  loss_mask_7: 2.106  loss_mask_8: 2.107  time: 2.9879  data_time: 0.0520  lr: 4.5087e-05  max_mem: 27646M
[01/30 07:20:06] d2.utils.events INFO:  eta: 20:16:16  iter: 35259  total_loss: 19.88  loss_mask: 1.962  loss_mask_0: 2.083  loss_mask_1: 1.962  loss_mask_2: 1.998  loss_mask_3: 1.999  loss_mask_4: 2.003  loss_mask_5: 1.96  loss_mask_6: 1.96  loss_mask_7: 1.996  loss_mask_8: 2  time: 2.9879  data_time: 0.0609  lr: 4.5055e-05  max_mem: 27646M
[01/30 07:21:05] d2.utils.events INFO:  eta: 20:15:15  iter: 35279  total_loss: 19.57  loss_mask: 1.949  loss_mask_0: 1.994  loss_mask_1: 1.941  loss_mask_2: 1.959  loss_mask_3: 1.957  loss_mask_4: 1.959  loss_mask_5: 1.953  loss_mask_6: 1.947  loss_mask_7: 1.959  loss_mask_8: 1.953  time: 2.9879  data_time: 0.0540  lr: 4.5022e-05  max_mem: 27646M
[01/30 07:22:04] d2.utils.events INFO:  eta: 20:14:04  iter: 35299  total_loss: 20.58  loss_mask: 2.043  loss_mask_0: 2.15  loss_mask_1: 2.035  loss_mask_2: 2.063  loss_mask_3: 2.068  loss_mask_4: 2.057  loss_mask_5: 2.029  loss_mask_6: 2.038  loss_mask_7: 2.065  loss_mask_8: 2.059  time: 2.9879  data_time: 0.0500  lr: 4.4989e-05  max_mem: 27646M
[01/30 07:23:03] d2.utils.events INFO:  eta: 20:13:00  iter: 35319  total_loss: 18.08  loss_mask: 1.799  loss_mask_0: 1.842  loss_mask_1: 1.803  loss_mask_2: 1.811  loss_mask_3: 1.81  loss_mask_4: 1.815  loss_mask_5: 1.798  loss_mask_6: 1.798  loss_mask_7: 1.805  loss_mask_8: 1.806  time: 2.9878  data_time: 0.0509  lr: 4.4956e-05  max_mem: 27646M
[01/30 07:24:01] d2.utils.events INFO:  eta: 20:11:46  iter: 35339  total_loss: 20.67  loss_mask: 2.059  loss_mask_0: 2.134  loss_mask_1: 2.053  loss_mask_2: 2.071  loss_mask_3: 2.068  loss_mask_4: 2.074  loss_mask_5: 2.056  loss_mask_6: 2.051  loss_mask_7: 2.061  loss_mask_8: 2.069  time: 2.9878  data_time: 0.0532  lr: 4.4923e-05  max_mem: 27646M
[01/30 07:25:00] d2.utils.events INFO:  eta: 20:10:34  iter: 35359  total_loss: 19.57  loss_mask: 1.943  loss_mask_0: 2.007  loss_mask_1: 1.948  loss_mask_2: 1.958  loss_mask_3: 1.946  loss_mask_4: 1.947  loss_mask_5: 1.959  loss_mask_6: 1.944  loss_mask_7: 1.951  loss_mask_8: 1.953  time: 2.9878  data_time: 0.0569  lr: 4.4891e-05  max_mem: 27646M
[01/30 07:26:00] d2.utils.events INFO:  eta: 20:09:56  iter: 35379  total_loss: 19.83  loss_mask: 1.977  loss_mask_0: 2.023  loss_mask_1: 1.952  loss_mask_2: 1.971  loss_mask_3: 1.99  loss_mask_4: 1.996  loss_mask_5: 1.971  loss_mask_6: 1.982  loss_mask_7: 1.999  loss_mask_8: 1.972  time: 2.9878  data_time: 0.0626  lr: 4.4858e-05  max_mem: 27646M
[01/30 07:26:59] d2.utils.events INFO:  eta: 20:09:02  iter: 35399  total_loss: 20.92  loss_mask: 2.089  loss_mask_0: 2.107  loss_mask_1: 2.078  loss_mask_2: 2.087  loss_mask_3: 2.09  loss_mask_4: 2.094  loss_mask_5: 2.095  loss_mask_6: 2.093  loss_mask_7: 2.096  loss_mask_8: 2.092  time: 2.9878  data_time: 0.0543  lr: 4.4825e-05  max_mem: 27646M
[01/30 07:27:59] d2.utils.events INFO:  eta: 20:08:18  iter: 35419  total_loss: 17.34  loss_mask: 1.723  loss_mask_0: 1.759  loss_mask_1: 1.719  loss_mask_2: 1.734  loss_mask_3: 1.739  loss_mask_4: 1.74  loss_mask_5: 1.727  loss_mask_6: 1.731  loss_mask_7: 1.741  loss_mask_8: 1.736  time: 2.9877  data_time: 0.0641  lr: 4.4792e-05  max_mem: 27646M
[01/30 07:28:58] d2.utils.events INFO:  eta: 20:07:21  iter: 35439  total_loss: 19.97  loss_mask: 1.992  loss_mask_0: 2.045  loss_mask_1: 1.99  loss_mask_2: 1.99  loss_mask_3: 1.993  loss_mask_4: 1.998  loss_mask_5: 1.986  loss_mask_6: 1.987  loss_mask_7: 1.994  loss_mask_8: 1.991  time: 2.9877  data_time: 0.0628  lr: 4.476e-05  max_mem: 27646M
[01/30 07:29:56] d2.utils.events INFO:  eta: 20:06:22  iter: 35459  total_loss: 21.28  loss_mask: 2.124  loss_mask_0: 2.18  loss_mask_1: 2.108  loss_mask_2: 2.12  loss_mask_3: 2.129  loss_mask_4: 2.126  loss_mask_5: 2.13  loss_mask_6: 2.126  loss_mask_7: 2.125  loss_mask_8: 2.12  time: 2.9877  data_time: 0.0505  lr: 4.4727e-05  max_mem: 27646M
[01/30 07:30:55] d2.utils.events INFO:  eta: 20:05:30  iter: 35479  total_loss: 19.87  loss_mask: 1.962  loss_mask_0: 2.058  loss_mask_1: 1.967  loss_mask_2: 1.996  loss_mask_3: 1.988  loss_mask_4: 1.994  loss_mask_5: 1.972  loss_mask_6: 1.963  loss_mask_7: 1.991  loss_mask_8: 1.988  time: 2.9877  data_time: 0.0508  lr: 4.4694e-05  max_mem: 27646M
[01/30 07:31:54] d2.utils.events INFO:  eta: 20:04:38  iter: 35499  total_loss: 19.09  loss_mask: 1.893  loss_mask_0: 1.939  loss_mask_1: 1.894  loss_mask_2: 1.906  loss_mask_3: 1.909  loss_mask_4: 1.913  loss_mask_5: 1.898  loss_mask_6: 1.89  loss_mask_7: 1.908  loss_mask_8: 1.91  time: 2.9876  data_time: 0.0581  lr: 4.4661e-05  max_mem: 27646M
[01/30 07:32:54] d2.utils.events INFO:  eta: 20:03:39  iter: 35519  total_loss: 19.09  loss_mask: 1.905  loss_mask_0: 1.928  loss_mask_1: 1.891  loss_mask_2: 1.909  loss_mask_3: 1.921  loss_mask_4: 1.913  loss_mask_5: 1.9  loss_mask_6: 1.907  loss_mask_7: 1.909  loss_mask_8: 1.903  time: 2.9876  data_time: 0.0714  lr: 4.4628e-05  max_mem: 27646M
[01/30 07:33:53] d2.utils.events INFO:  eta: 20:03:07  iter: 35539  total_loss: 20.14  loss_mask: 2.025  loss_mask_0: 2.011  loss_mask_1: 2.006  loss_mask_2: 2.015  loss_mask_3: 2.016  loss_mask_4: 2.012  loss_mask_5: 2.017  loss_mask_6: 2.012  loss_mask_7: 2.016  loss_mask_8: 2.012  time: 2.9876  data_time: 0.0616  lr: 4.4595e-05  max_mem: 27646M
[01/30 07:34:52] d2.utils.events INFO:  eta: 20:02:13  iter: 35559  total_loss: 19.82  loss_mask: 1.991  loss_mask_0: 2.011  loss_mask_1: 1.988  loss_mask_2: 1.974  loss_mask_3: 1.974  loss_mask_4: 1.995  loss_mask_5: 1.993  loss_mask_6: 1.987  loss_mask_7: 1.972  loss_mask_8: 1.971  time: 2.9876  data_time: 0.0565  lr: 4.4563e-05  max_mem: 27646M
[01/30 07:35:52] d2.utils.events INFO:  eta: 20:01:14  iter: 35579  total_loss: 21.54  loss_mask: 2.154  loss_mask_0: 2.171  loss_mask_1: 2.132  loss_mask_2: 2.148  loss_mask_3: 2.163  loss_mask_4: 2.165  loss_mask_5: 2.13  loss_mask_6: 2.143  loss_mask_7: 2.156  loss_mask_8: 2.158  time: 2.9876  data_time: 0.0502  lr: 4.453e-05  max_mem: 27646M
[01/30 07:36:50] d2.utils.events INFO:  eta: 20:00:11  iter: 35599  total_loss: 20.08  loss_mask: 2.013  loss_mask_0: 2.03  loss_mask_1: 1.967  loss_mask_2: 1.99  loss_mask_3: 2.027  loss_mask_4: 2.054  loss_mask_5: 1.989  loss_mask_6: 2.01  loss_mask_7: 2.01  loss_mask_8: 2.021  time: 2.9876  data_time: 0.0514  lr: 4.4497e-05  max_mem: 27646M
[01/30 07:37:49] d2.utils.events INFO:  eta: 19:59:08  iter: 35619  total_loss: 21.53  loss_mask: 2.135  loss_mask_0: 2.148  loss_mask_1: 2.151  loss_mask_2: 2.157  loss_mask_3: 2.152  loss_mask_4: 2.158  loss_mask_5: 2.142  loss_mask_6: 2.138  loss_mask_7: 2.15  loss_mask_8: 2.159  time: 2.9875  data_time: 0.0516  lr: 4.4464e-05  max_mem: 27646M
[01/30 07:38:48] d2.utils.events INFO:  eta: 19:58:07  iter: 35639  total_loss: 19.52  loss_mask: 1.946  loss_mask_0: 1.986  loss_mask_1: 1.936  loss_mask_2: 1.947  loss_mask_3: 1.954  loss_mask_4: 1.954  loss_mask_5: 1.94  loss_mask_6: 1.95  loss_mask_7: 1.952  loss_mask_8: 1.958  time: 2.9875  data_time: 0.0542  lr: 4.4431e-05  max_mem: 27646M
[01/30 07:39:47] d2.utils.events INFO:  eta: 19:56:51  iter: 35659  total_loss: 18.57  loss_mask: 1.842  loss_mask_0: 1.901  loss_mask_1: 1.841  loss_mask_2: 1.855  loss_mask_3: 1.85  loss_mask_4: 1.856  loss_mask_5: 1.848  loss_mask_6: 1.872  loss_mask_7: 1.872  loss_mask_8: 1.856  time: 2.9875  data_time: 0.0540  lr: 4.4399e-05  max_mem: 27646M
[01/30 07:40:45] d2.utils.events INFO:  eta: 19:55:47  iter: 35679  total_loss: 21.37  loss_mask: 2.121  loss_mask_0: 2.156  loss_mask_1: 2.119  loss_mask_2: 2.133  loss_mask_3: 2.133  loss_mask_4: 2.143  loss_mask_5: 2.135  loss_mask_6: 2.13  loss_mask_7: 2.15  loss_mask_8: 2.144  time: 2.9874  data_time: 0.0557  lr: 4.4366e-05  max_mem: 27646M
[01/30 07:41:44] d2.utils.events INFO:  eta: 19:54:41  iter: 35699  total_loss: 19.74  loss_mask: 1.956  loss_mask_0: 2.038  loss_mask_1: 1.959  loss_mask_2: 1.98  loss_mask_3: 1.978  loss_mask_4: 1.982  loss_mask_5: 1.956  loss_mask_6: 1.983  loss_mask_7: 1.975  loss_mask_8: 1.98  time: 2.9874  data_time: 0.0557  lr: 4.4333e-05  max_mem: 27646M
[01/30 07:42:43] d2.utils.events INFO:  eta: 19:53:52  iter: 35719  total_loss: 18.15  loss_mask: 1.806  loss_mask_0: 1.858  loss_mask_1: 1.803  loss_mask_2: 1.815  loss_mask_3: 1.813  loss_mask_4: 1.82  loss_mask_5: 1.806  loss_mask_6: 1.808  loss_mask_7: 1.818  loss_mask_8: 1.81  time: 2.9874  data_time: 0.0513  lr: 4.43e-05  max_mem: 27646M
[01/30 07:43:42] d2.utils.events INFO:  eta: 19:52:53  iter: 35739  total_loss: 19.5  loss_mask: 1.921  loss_mask_0: 2.018  loss_mask_1: 1.913  loss_mask_2: 1.956  loss_mask_3: 1.968  loss_mask_4: 1.963  loss_mask_5: 1.921  loss_mask_6: 1.924  loss_mask_7: 1.962  loss_mask_8: 1.953  time: 2.9874  data_time: 0.0563  lr: 4.4267e-05  max_mem: 27646M
[01/30 07:44:41] d2.utils.events INFO:  eta: 19:51:38  iter: 35759  total_loss: 19.63  loss_mask: 1.957  loss_mask_0: 1.958  loss_mask_1: 1.95  loss_mask_2: 1.967  loss_mask_3: 1.963  loss_mask_4: 1.974  loss_mask_5: 1.958  loss_mask_6: 1.968  loss_mask_7: 1.971  loss_mask_8: 1.968  time: 2.9873  data_time: 0.0534  lr: 4.4234e-05  max_mem: 27646M
[01/30 07:45:40] d2.utils.events INFO:  eta: 19:50:52  iter: 35779  total_loss: 20.05  loss_mask: 1.985  loss_mask_0: 2.061  loss_mask_1: 1.992  loss_mask_2: 2.007  loss_mask_3: 2.004  loss_mask_4: 2.008  loss_mask_5: 1.978  loss_mask_6: 1.987  loss_mask_7: 2.016  loss_mask_8: 2.006  time: 2.9873  data_time: 0.0525  lr: 4.4201e-05  max_mem: 27646M
[01/30 07:46:39] d2.utils.events INFO:  eta: 19:49:16  iter: 35799  total_loss: 20.22  loss_mask: 2.007  loss_mask_0: 2.097  loss_mask_1: 2.006  loss_mask_2: 2.02  loss_mask_3: 2.023  loss_mask_4: 2.028  loss_mask_5: 2.016  loss_mask_6: 2.004  loss_mask_7: 2.037  loss_mask_8: 2.023  time: 2.9873  data_time: 0.0541  lr: 4.4169e-05  max_mem: 27646M
[01/30 07:47:37] d2.utils.events INFO:  eta: 19:48:00  iter: 35819  total_loss: 20.06  loss_mask: 2  loss_mask_0: 2.01  loss_mask_1: 1.989  loss_mask_2: 2.02  loss_mask_3: 2.003  loss_mask_4: 2.007  loss_mask_5: 1.994  loss_mask_6: 2.001  loss_mask_7: 2.027  loss_mask_8: 2.003  time: 2.9873  data_time: 0.0523  lr: 4.4136e-05  max_mem: 27646M
[01/30 07:48:36] d2.utils.events INFO:  eta: 19:46:55  iter: 35839  total_loss: 19.89  loss_mask: 1.991  loss_mask_0: 2.008  loss_mask_1: 1.982  loss_mask_2: 1.991  loss_mask_3: 1.983  loss_mask_4: 1.99  loss_mask_5: 1.993  loss_mask_6: 1.985  loss_mask_7: 1.992  loss_mask_8: 1.983  time: 2.9872  data_time: 0.0509  lr: 4.4103e-05  max_mem: 27646M
[01/30 07:49:35] d2.utils.events INFO:  eta: 19:45:50  iter: 35859  total_loss: 19.82  loss_mask: 1.97  loss_mask_0: 2.024  loss_mask_1: 1.964  loss_mask_2: 1.985  loss_mask_3: 1.989  loss_mask_4: 1.99  loss_mask_5: 1.966  loss_mask_6: 1.966  loss_mask_7: 1.983  loss_mask_8: 1.986  time: 2.9872  data_time: 0.0538  lr: 4.407e-05  max_mem: 27646M
[01/30 07:50:34] d2.utils.events INFO:  eta: 19:44:39  iter: 35879  total_loss: 22.72  loss_mask: 2.252  loss_mask_0: 2.336  loss_mask_1: 2.252  loss_mask_2: 2.275  loss_mask_3: 2.263  loss_mask_4: 2.27  loss_mask_5: 2.257  loss_mask_6: 2.27  loss_mask_7: 2.276  loss_mask_8: 2.255  time: 2.9872  data_time: 0.0500  lr: 4.4037e-05  max_mem: 27646M
[01/30 07:51:33] d2.utils.events INFO:  eta: 19:43:40  iter: 35899  total_loss: 20.07  loss_mask: 1.982  loss_mask_0: 2.049  loss_mask_1: 1.997  loss_mask_2: 2.009  loss_mask_3: 2.009  loss_mask_4: 2.012  loss_mask_5: 1.99  loss_mask_6: 1.986  loss_mask_7: 2.008  loss_mask_8: 2.012  time: 2.9872  data_time: 0.0558  lr: 4.4004e-05  max_mem: 27646M
[01/30 07:52:32] d2.utils.events INFO:  eta: 19:42:31  iter: 35919  total_loss: 20.66  loss_mask: 2.046  loss_mask_0: 2.113  loss_mask_1: 2.05  loss_mask_2: 2.069  loss_mask_3: 2.064  loss_mask_4: 2.065  loss_mask_5: 2.051  loss_mask_6: 2.049  loss_mask_7: 2.067  loss_mask_8: 2.07  time: 2.9871  data_time: 0.0491  lr: 4.3971e-05  max_mem: 27646M
[01/30 07:53:30] d2.utils.events INFO:  eta: 19:41:11  iter: 35939  total_loss: 21.02  loss_mask: 2.072  loss_mask_0: 2.146  loss_mask_1: 2.061  loss_mask_2: 2.089  loss_mask_3: 2.109  loss_mask_4: 2.111  loss_mask_5: 2.086  loss_mask_6: 2.075  loss_mask_7: 2.109  loss_mask_8: 2.101  time: 2.9871  data_time: 0.0628  lr: 4.3939e-05  max_mem: 27646M
[01/30 07:54:30] d2.utils.events INFO:  eta: 19:40:01  iter: 35959  total_loss: 18.37  loss_mask: 1.83  loss_mask_0: 1.872  loss_mask_1: 1.827  loss_mask_2: 1.834  loss_mask_3: 1.834  loss_mask_4: 1.832  loss_mask_5: 1.833  loss_mask_6: 1.831  loss_mask_7: 1.836  loss_mask_8: 1.824  time: 2.9871  data_time: 0.0521  lr: 4.3906e-05  max_mem: 27646M
[01/30 07:55:28] d2.utils.events INFO:  eta: 19:38:56  iter: 35979  total_loss: 18.83  loss_mask: 1.876  loss_mask_0: 1.92  loss_mask_1: 1.873  loss_mask_2: 1.883  loss_mask_3: 1.883  loss_mask_4: 1.885  loss_mask_5: 1.87  loss_mask_6: 1.873  loss_mask_7: 1.883  loss_mask_8: 1.884  time: 2.9871  data_time: 0.0526  lr: 4.3873e-05  max_mem: 27646M
[01/30 07:56:27] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 07:56:28] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 07:56:28] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 08:10:43] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.3357939795243254, 'error_1pix': 0.3402417711560749, 'error_3pix': 0.14686884037717013, 'mIoU': 7.815169924359886, 'fwIoU': 20.26749445846107, 'IoU-0': 8.017887974887708e-05, 'IoU-1': 53.58343410253551, 'IoU-2': 2.9519507107161287, 'IoU-3': 6.178770823017112, 'IoU-4': 5.756186034065356, 'IoU-5': 4.7839984531525905, 'IoU-6': 4.386352868268446, 'IoU-7': 3.6179064763495616, 'IoU-8': 8.814860216239602, 'IoU-9': 19.44914002147019, 'IoU-10': 22.726586375597307, 'IoU-11': 30.578455562937744, 'IoU-12': 30.470146819057987, 'IoU-13': 28.673953377947576, 'IoU-14': 29.409084155874755, 'IoU-15': 28.30135258681977, 'IoU-16': 26.242441300711366, 'IoU-17': 23.21445591744039, 'IoU-18': 22.901139793087697, 'IoU-19': 23.043143586513487, 'IoU-20': 21.92516437733941, 'IoU-21': 21.536473026455823, 'IoU-22': 22.212781305597847, 'IoU-23': 20.882473951593404, 'IoU-24': 20.256027265623505, 'IoU-25': 20.71632414386184, 'IoU-26': 19.876051840810582, 'IoU-27': 21.67942515154064, 'IoU-28': 20.83264597553816, 'IoU-29': 21.088321984504777, 'IoU-30': 20.57032171048482, 'IoU-31': 21.960592202119727, 'IoU-32': 20.752625730475348, 'IoU-33': 19.825554617922315, 'IoU-34': 18.78714424495697, 'IoU-35': 19.33975670139069, 'IoU-36': 19.206847455326468, 'IoU-37': 18.78453749376692, 'IoU-38': 18.9692620759258, 'IoU-39': 18.097749144902863, 'IoU-40': 18.498440948997278, 'IoU-41': 17.10874730875667, 'IoU-42': 16.810865472868922, 'IoU-43': 16.46527336262823, 'IoU-44': 16.687286711748744, 'IoU-45': 16.33565341332946, 'IoU-46': 15.273709515851758, 'IoU-47': 14.738363723012924, 'IoU-48': 14.698962988445755, 'IoU-49': 14.32042413424803, 'IoU-50': 14.699236106954237, 'IoU-51': 13.60382100692283, 'IoU-52': 13.260465150447272, 'IoU-53': 12.830913209816098, 'IoU-54': 12.567638413030584, 'IoU-55': 12.34063618976661, 'IoU-56': 11.081309638293778, 'IoU-57': 11.040192553942754, 'IoU-58': 10.702204958653855, 'IoU-59': 10.441613662179831, 'IoU-60': 10.028367780124954, 'IoU-61': 9.503623370734582, 'IoU-62': 9.154868079610896, 'IoU-63': 8.46970497315023, 'IoU-64': 7.9490189434420975, 'IoU-65': 7.716940625377097, 'IoU-66': 7.232171181725184, 'IoU-67': 6.935366597656321, 'IoU-68': 7.019990735813522, 'IoU-69': 6.920267548556961, 'IoU-70': 6.379197070799933, 'IoU-71': 6.297175780623316, 'IoU-72': 6.4383762062247465, 'IoU-73': 6.328182100786209, 'IoU-74': 6.051277036655576, 'IoU-75': 5.556967549162038, 'IoU-76': 5.788272531475802, 'IoU-77': 5.630763216396898, 'IoU-78': 5.597583673106381, 'IoU-79': 5.559717171826168, 'IoU-80': 5.556174952947063, 'IoU-81': 5.490460241034164, 'IoU-82': 5.401246452067152, 'IoU-83': 5.578039281803006, 'IoU-84': 5.554932640219336, 'IoU-85': 5.417549638354724, 'IoU-86': 5.3815487599783465, 'IoU-87': 5.311695083946886, 'IoU-88': 5.18432491793887, 'IoU-89': 5.0185824352635295, 'IoU-90': 4.937939615012123, 'IoU-91': 4.760566710610276, 'IoU-92': 4.642152306205899, 'IoU-93': 4.756335215283548, 'IoU-94': 4.7415136128496504, 'IoU-95': 4.565871723283133, 'IoU-96': 4.460943239140017, 'IoU-97': 4.5714645556860445, 'IoU-98': 4.726502763450751, 'IoU-99': 4.512605587791933, 'IoU-100': 4.439258805894306, 'IoU-101': 4.365716775218647, 'IoU-102': 4.346230893068386, 'IoU-103': 4.228360722175559, 'IoU-104': 4.324188919630241, 'IoU-105': 4.267288928576661, 'IoU-106': 4.46175122223538, 'IoU-107': 4.540152303364168, 'IoU-108': 4.674293421790948, 'IoU-109': 4.677885602785416, 'IoU-110': 4.63515715784713, 'IoU-111': 4.255952292632969, 'IoU-112': 4.20860725432233, 'IoU-113': 4.011335412583934, 'IoU-114': 4.030469419854524, 'IoU-115': 3.807428668170669, 'IoU-116': 3.926808757761898, 'IoU-117': 4.12039731858393, 'IoU-118': 3.943752629872593, 'IoU-119': 4.269932097184874, 'IoU-120': 4.140437988047135, 'IoU-121': 4.016732073025222, 'IoU-122': 3.495376294758191, 'IoU-123': 3.528367432336002, 'IoU-124': 3.0185378614521885, 'IoU-125': 2.879301098578216, 'IoU-126': 3.087177647461444, 'IoU-127': 2.6376193450949135, 'IoU-128': 2.5541777363261615, 'IoU-129': 2.618427945677224, 'IoU-130': 2.607257322120784, 'IoU-131': 2.456012740910744, 'IoU-132': 2.4987960032292706, 'IoU-133': 2.47097000011599, 'IoU-134': 2.533195284669908, 'IoU-135': 2.521485824270422, 'IoU-136': 2.4063534783413494, 'IoU-137': 2.222542239026509, 'IoU-138': 2.100707543584381, 'IoU-139': 2.106007730940529, 'IoU-140': 1.9787586574658937, 'IoU-141': 1.9095971916108199, 'IoU-142': 1.9322841708675673, 'IoU-143': 1.8558003911407333, 'IoU-144': 1.9032381647196193, 'IoU-145': 1.8484423389789488, 'IoU-146': 1.7318605085864545, 'IoU-147': 1.6705883605802718, 'IoU-148': 2.0249063678645034, 'IoU-149': 1.8233711928691974, 'IoU-150': 1.6729961907566764, 'IoU-151': 1.6740047995941805, 'IoU-152': 1.7880865025582793, 'IoU-153': 1.6892643448359512, 'IoU-154': 1.5881829385987027, 'IoU-155': 1.5761056575639691, 'IoU-156': 1.491975688420591, 'IoU-157': 1.4541861784658667, 'IoU-158': 1.8182364020586663, 'IoU-159': 1.5621935902775272, 'IoU-160': 1.2982722349687317, 'IoU-161': 1.1319845857418112, 'IoU-162': 1.2724533790452444, 'IoU-163': 1.2989406057139086, 'IoU-164': 1.363579339698479, 'IoU-165': 1.2483702783487725, 'IoU-166': 1.1943161392764143, 'IoU-167': 1.0855627451221195, 'IoU-168': 1.119161584789718, 'IoU-169': 1.1229025645914767, 'IoU-170': 1.0578417591169942, 'IoU-171': 1.0375540005330326, 'IoU-172': 0.8559391737171145, 'IoU-173': 0.943065198766347, 'IoU-174': 1.0527008088704557, 'IoU-175': 0.9638519326510272, 'IoU-176': 0.9626973773719297, 'IoU-177': 0.9775645557053138, 'IoU-178': 1.0221885824324304, 'IoU-179': 1.2256146813692494, 'IoU-180': 0.5726257199419867, 'IoU-181': 0.45098523930028167, 'IoU-182': 0.5055553285611355, 'IoU-183': 0.5472656023782407, 'IoU-184': 0.5002980675288546, 'IoU-185': 0.0704119477502247, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 13.836906393957927, 'pACC': 30.335591866895502, 'ACC-0': 0.00037221308361557555, 'ACC-1': 54.42397386685167, 'ACC-2': 5.1750335771001215, 'ACC-3': 22.66337917185633, 'ACC-4': 20.249229956405543, 'ACC-5': 17.4150112918473, 'ACC-6': 16.79661698028929, 'ACC-7': 16.102949487877893, 'ACC-8': 23.07618422615974, 'ACC-9': 36.166486594674936, 'ACC-10': 39.56828975438606, 'ACC-11': 45.67854379283604, 'ACC-12': 45.67789327847287, 'ACC-13': 41.94573276987423, 'ACC-14': 43.337503936702745, 'ACC-15': 42.551565163995605, 'ACC-16': 39.352563818898815, 'ACC-17': 37.88479914741274, 'ACC-18': 36.77534353985098, 'ACC-19': 37.70489974273752, 'ACC-20': 35.964067075646085, 'ACC-21': 35.290197040448376, 'ACC-22': 35.848511557855524, 'ACC-23': 35.57297751753511, 'ACC-24': 34.33542835050925, 'ACC-25': 35.58277557041128, 'ACC-26': 33.80958557002462, 'ACC-27': 36.4416943187659, 'ACC-28': 35.6190182673714, 'ACC-29': 34.77702135580337, 'ACC-30': 34.77478833115653, 'ACC-31': 36.53797253838429, 'ACC-32': 35.123132273381565, 'ACC-33': 33.946784888825945, 'ACC-34': 32.17375784081453, 'ACC-35': 32.917310023237775, 'ACC-36': 32.47747831190044, 'ACC-37': 32.343389801006204, 'ACC-38': 32.86463516296638, 'ACC-39': 31.711551554816573, 'ACC-40': 31.62858707859436, 'ACC-41': 29.930153132713787, 'ACC-42': 29.392522421236546, 'ACC-43': 28.780861413617387, 'ACC-44': 28.404579214523068, 'ACC-45': 28.235689972973237, 'ACC-46': 27.25594391781087, 'ACC-47': 26.306816964322422, 'ACC-48': 26.425830062666904, 'ACC-49': 25.617899506940773, 'ACC-50': 26.309533889903975, 'ACC-51': 24.849042378140872, 'ACC-52': 24.055651832170696, 'ACC-53': 23.33659020766451, 'ACC-54': 22.702151348609267, 'ACC-55': 22.28006105356815, 'ACC-56': 20.137486638311767, 'ACC-57': 19.68356266645381, 'ACC-58': 19.434908805582964, 'ACC-59': 19.297959032942895, 'ACC-60': 18.71054511950647, 'ACC-61': 17.876014332877475, 'ACC-62': 17.334324437811375, 'ACC-63': 16.117484693809793, 'ACC-64': 15.022115118814384, 'ACC-65': 14.5872939486727, 'ACC-66': 13.775254688104935, 'ACC-67': 13.356799131903701, 'ACC-68': 13.534562760287416, 'ACC-69': 13.020293635054362, 'ACC-70': 11.94869737645293, 'ACC-71': 11.988166978792188, 'ACC-72': 12.398825957929418, 'ACC-73': 12.11917735989488, 'ACC-74': 11.540412625444063, 'ACC-75': 10.663005507027657, 'ACC-76': 10.931086662099952, 'ACC-77': 10.785992041200444, 'ACC-78': 10.834762531298715, 'ACC-79': 10.788868910718966, 'ACC-80': 10.674315407844828, 'ACC-81': 10.383084196751973, 'ACC-82': 10.163965302344359, 'ACC-83': 10.251262120232889, 'ACC-84': 10.237741511779557, 'ACC-85': 10.046878334358667, 'ACC-86': 10.058977093977365, 'ACC-87': 10.039674499774392, 'ACC-88': 9.788176781442367, 'ACC-89': 9.366956294003543, 'ACC-90': 9.099412023402344, 'ACC-91': 8.79978804708577, 'ACC-92': 8.649637200619589, 'ACC-93': 8.921154092916069, 'ACC-94': 8.804077839489503, 'ACC-95': 8.473379523969918, 'ACC-96': 8.342963018843543, 'ACC-97': 8.401889526298408, 'ACC-98': 8.635183534659072, 'ACC-99': 8.29384599126663, 'ACC-100': 8.125774948161087, 'ACC-101': 7.995025542882985, 'ACC-102': 7.970684186678749, 'ACC-103': 7.778006045149712, 'ACC-104': 8.045080052138413, 'ACC-105': 7.959773732994411, 'ACC-106': 8.299303245254995, 'ACC-107': 8.52218581517695, 'ACC-108': 8.757507060388395, 'ACC-109': 8.768715901021002, 'ACC-110': 8.714612234427095, 'ACC-111': 8.090273501268145, 'ACC-112': 8.157645546762547, 'ACC-113': 7.730610447323842, 'ACC-114': 7.760321895395658, 'ACC-115': 7.269593913971704, 'ACC-116': 7.568649768665176, 'ACC-117': 7.930190376002449, 'ACC-118': 7.681539675281952, 'ACC-119': 8.332572032955085, 'ACC-120': 8.121088492745374, 'ACC-121': 7.935812923805894, 'ACC-122': 6.829516827535452, 'ACC-123': 6.889853138834229, 'ACC-124': 6.011930098593523, 'ACC-125': 5.670556678917903, 'ACC-126': 6.064262880354102, 'ACC-127': 5.149099608444149, 'ACC-128': 5.072076654091824, 'ACC-129': 5.303851316455807, 'ACC-130': 5.249546618925145, 'ACC-131': 4.972642623543493, 'ACC-132': 5.038788524628619, 'ACC-133': 4.928385283771187, 'ACC-134': 5.037966393795778, 'ACC-135': 4.990807251582008, 'ACC-136': 4.7696142377935145, 'ACC-137': 4.4290373274045445, 'ACC-138': 4.165133131964363, 'ACC-139': 4.191094426494544, 'ACC-140': 3.8724537715736798, 'ACC-141': 3.7688991969892567, 'ACC-142': 3.8904477578050427, 'ACC-143': 3.7791154806609675, 'ACC-144': 3.842509025270758, 'ACC-145': 3.6890807039513405, 'ACC-146': 3.3783098398483014, 'ACC-147': 3.20450740633789, 'ACC-148': 3.940113169418593, 'ACC-149': 3.5872743185314615, 'ACC-150': 3.3275693682256478, 'ACC-151': 3.2919705461998143, 'ACC-152': 3.4775608604760944, 'ACC-153': 3.365190824309716, 'ACC-154': 3.1804684225172513, 'ACC-155': 3.2518371160298076, 'ACC-156': 3.1318557014226895, 'ACC-157': 3.1009904278152747, 'ACC-158': 3.9319681998896336, 'ACC-159': 3.3767901850649444, 'ACC-160': 2.811269963353391, 'ACC-161': 2.408889088596006, 'ACC-162': 2.7331070124754167, 'ACC-163': 2.887947573020345, 'ACC-164': 3.084738345821746, 'ACC-165': 2.8375901685687697, 'ACC-166': 2.774256910459914, 'ACC-167': 2.610363282939616, 'ACC-168': 2.6552500175821083, 'ACC-169': 2.645408874999342, 'ACC-170': 2.5267260104774483, 'ACC-171': 2.4599152475436665, 'ACC-172': 2.052635478016076, 'ACC-173': 2.209758685696869, 'ACC-174': 2.41667458866204, 'ACC-175': 2.2152829006117822, 'ACC-176': 2.1819494427675874, 'ACC-177': 2.2968651094637265, 'ACC-178': 2.5981677036029756, 'ACC-179': 3.250886116527113, 'ACC-180': 1.5660452436587762, 'ACC-181': 1.3136545699593303, 'ACC-182': 1.201879224523738, 'ACC-183': 1.3348997412601735, 'ACC-184': 1.140048630125679, 'ACC-185': 0.15035405955960812, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 08:10:43] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 08:10:43] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 08:10:43] d2.evaluation.testing INFO: copypaste: 2.3358,0.3402,0.1469,7.8152,20.2675,13.8369,30.3356
[01/30 08:10:43] d2.utils.events INFO:  eta: 19:37:54  iter: 35999  total_loss: 20.15  loss_mask: 2.005  loss_mask_0: 2.058  loss_mask_1: 2.006  loss_mask_2: 2.006  loss_mask_3: 2.012  loss_mask_4: 2.024  loss_mask_5: 2.006  loss_mask_6: 2.008  loss_mask_7: 2.012  loss_mask_8: 2.012  time: 2.9870  data_time: 0.0509  lr: 4.384e-05  max_mem: 27646M
[01/30 08:11:43] d2.utils.events INFO:  eta: 19:37:05  iter: 36019  total_loss: 19.02  loss_mask: 1.899  loss_mask_0: 1.921  loss_mask_1: 1.891  loss_mask_2: 1.903  loss_mask_3: 1.908  loss_mask_4: 1.905  loss_mask_5: 1.894  loss_mask_6: 1.901  loss_mask_7: 1.9  loss_mask_8: 1.9  time: 2.9870  data_time: 0.0796  lr: 4.3807e-05  max_mem: 27646M
[01/30 08:12:42] d2.utils.events INFO:  eta: 19:35:56  iter: 36039  total_loss: 20.37  loss_mask: 2.026  loss_mask_0: 2.079  loss_mask_1: 2.022  loss_mask_2: 2.028  loss_mask_3: 2.04  loss_mask_4: 2.032  loss_mask_5: 2.034  loss_mask_6: 2.031  loss_mask_7: 2.033  loss_mask_8: 2.036  time: 2.9870  data_time: 0.0506  lr: 4.3774e-05  max_mem: 27646M
[01/30 08:13:41] d2.utils.events INFO:  eta: 19:35:00  iter: 36059  total_loss: 19.96  loss_mask: 1.992  loss_mask_0: 2.028  loss_mask_1: 1.982  loss_mask_2: 1.987  loss_mask_3: 1.994  loss_mask_4: 1.999  loss_mask_5: 1.996  loss_mask_6: 1.99  loss_mask_7: 1.994  loss_mask_8: 1.994  time: 2.9870  data_time: 0.0574  lr: 4.3741e-05  max_mem: 27646M
[01/30 08:14:40] d2.utils.events INFO:  eta: 19:33:50  iter: 36079  total_loss: 17.99  loss_mask: 1.794  loss_mask_0: 1.848  loss_mask_1: 1.789  loss_mask_2: 1.799  loss_mask_3: 1.801  loss_mask_4: 1.802  loss_mask_5: 1.801  loss_mask_6: 1.787  loss_mask_7: 1.791  loss_mask_8: 1.801  time: 2.9870  data_time: 0.0730  lr: 4.3708e-05  max_mem: 27646M
[01/30 08:15:40] d2.utils.events INFO:  eta: 19:33:05  iter: 36099  total_loss: 19.63  loss_mask: 1.951  loss_mask_0: 2.029  loss_mask_1: 1.936  loss_mask_2: 1.955  loss_mask_3: 1.964  loss_mask_4: 1.977  loss_mask_5: 1.943  loss_mask_6: 1.946  loss_mask_7: 1.96  loss_mask_8: 1.971  time: 2.9870  data_time: 0.0715  lr: 4.3676e-05  max_mem: 27646M
[01/30 08:16:41] d2.utils.events INFO:  eta: 19:32:11  iter: 36119  total_loss: 18.11  loss_mask: 1.811  loss_mask_0: 1.835  loss_mask_1: 1.796  loss_mask_2: 1.799  loss_mask_3: 1.825  loss_mask_4: 1.816  loss_mask_5: 1.805  loss_mask_6: 1.809  loss_mask_7: 1.81  loss_mask_8: 1.803  time: 2.9870  data_time: 0.0913  lr: 4.3643e-05  max_mem: 27646M
[01/30 08:17:41] d2.utils.events INFO:  eta: 19:31:46  iter: 36139  total_loss: 20.47  loss_mask: 2.037  loss_mask_0: 2.085  loss_mask_1: 2.034  loss_mask_2: 2.042  loss_mask_3: 2.044  loss_mask_4: 2.05  loss_mask_5: 2.044  loss_mask_6: 2.047  loss_mask_7: 2.045  loss_mask_8: 2.047  time: 2.9870  data_time: 0.0659  lr: 4.361e-05  max_mem: 27646M
[01/30 08:18:40] d2.utils.events INFO:  eta: 19:30:33  iter: 36159  total_loss: 20.49  loss_mask: 2.043  loss_mask_0: 2.053  loss_mask_1: 2.027  loss_mask_2: 2.055  loss_mask_3: 2.049  loss_mask_4: 2.058  loss_mask_5: 2.039  loss_mask_6: 2.041  loss_mask_7: 2.04  loss_mask_8: 2.057  time: 2.9870  data_time: 0.0602  lr: 4.3577e-05  max_mem: 27646M
[01/30 08:19:39] d2.utils.events INFO:  eta: 19:29:34  iter: 36179  total_loss: 19.74  loss_mask: 1.966  loss_mask_0: 2.002  loss_mask_1: 1.977  loss_mask_2: 1.973  loss_mask_3: 1.965  loss_mask_4: 1.976  loss_mask_5: 1.978  loss_mask_6: 1.98  loss_mask_7: 1.968  loss_mask_8: 1.964  time: 2.9870  data_time: 0.0654  lr: 4.3544e-05  max_mem: 27646M
[01/30 08:20:38] d2.utils.events INFO:  eta: 19:28:00  iter: 36199  total_loss: 18.41  loss_mask: 1.831  loss_mask_0: 1.903  loss_mask_1: 1.824  loss_mask_2: 1.83  loss_mask_3: 1.835  loss_mask_4: 1.838  loss_mask_5: 1.841  loss_mask_6: 1.836  loss_mask_7: 1.837  loss_mask_8: 1.836  time: 2.9869  data_time: 0.0544  lr: 4.3511e-05  max_mem: 27646M
[01/30 08:21:37] d2.utils.events INFO:  eta: 19:27:04  iter: 36219  total_loss: 21.25  loss_mask: 2.093  loss_mask_0: 2.213  loss_mask_1: 2.103  loss_mask_2: 2.124  loss_mask_3: 2.128  loss_mask_4: 2.127  loss_mask_5: 2.109  loss_mask_6: 2.09  loss_mask_7: 2.134  loss_mask_8: 2.125  time: 2.9869  data_time: 0.0598  lr: 4.3478e-05  max_mem: 27646M
[01/30 08:22:37] d2.utils.events INFO:  eta: 19:26:37  iter: 36239  total_loss: 21.33  loss_mask: 2.132  loss_mask_0: 2.166  loss_mask_1: 2.131  loss_mask_2: 2.127  loss_mask_3: 2.125  loss_mask_4: 2.129  loss_mask_5: 2.133  loss_mask_6: 2.131  loss_mask_7: 2.127  loss_mask_8: 2.131  time: 2.9869  data_time: 0.0704  lr: 4.3445e-05  max_mem: 27646M
[01/30 08:23:37] d2.utils.events INFO:  eta: 19:25:49  iter: 36259  total_loss: 20.47  loss_mask: 2.044  loss_mask_0: 2.073  loss_mask_1: 2.026  loss_mask_2: 2.048  loss_mask_3: 2.053  loss_mask_4: 2.054  loss_mask_5: 2.033  loss_mask_6: 2.035  loss_mask_7: 2.038  loss_mask_8: 2.043  time: 2.9869  data_time: 0.0711  lr: 4.3412e-05  max_mem: 27646M
[01/30 08:24:36] d2.utils.events INFO:  eta: 19:24:54  iter: 36279  total_loss: 18.27  loss_mask: 1.817  loss_mask_0: 1.895  loss_mask_1: 1.827  loss_mask_2: 1.828  loss_mask_3: 1.831  loss_mask_4: 1.828  loss_mask_5: 1.825  loss_mask_6: 1.813  loss_mask_7: 1.829  loss_mask_8: 1.825  time: 2.9869  data_time: 0.0667  lr: 4.3379e-05  max_mem: 27646M
[01/30 08:25:34] d2.utils.events INFO:  eta: 19:23:25  iter: 36299  total_loss: 18.5  loss_mask: 1.821  loss_mask_0: 1.95  loss_mask_1: 1.83  loss_mask_2: 1.849  loss_mask_3: 1.853  loss_mask_4: 1.856  loss_mask_5: 1.832  loss_mask_6: 1.815  loss_mask_7: 1.861  loss_mask_8: 1.854  time: 2.9869  data_time: 0.0597  lr: 4.3346e-05  max_mem: 27646M
[01/30 08:26:34] d2.utils.events INFO:  eta: 19:23:05  iter: 36319  total_loss: 18.62  loss_mask: 1.854  loss_mask_0: 1.895  loss_mask_1: 1.845  loss_mask_2: 1.86  loss_mask_3: 1.87  loss_mask_4: 1.867  loss_mask_5: 1.856  loss_mask_6: 1.864  loss_mask_7: 1.858  loss_mask_8: 1.85  time: 2.9869  data_time: 0.0526  lr: 4.3314e-05  max_mem: 27646M
[01/30 08:27:33] d2.utils.events INFO:  eta: 19:22:15  iter: 36339  total_loss: 19.16  loss_mask: 1.897  loss_mask_0: 1.966  loss_mask_1: 1.895  loss_mask_2: 1.921  loss_mask_3: 1.917  loss_mask_4: 1.91  loss_mask_5: 1.901  loss_mask_6: 1.898  loss_mask_7: 1.925  loss_mask_8: 1.923  time: 2.9868  data_time: 0.0660  lr: 4.3281e-05  max_mem: 27646M
[01/30 08:28:32] d2.utils.events INFO:  eta: 19:21:16  iter: 36359  total_loss: 21.2  loss_mask: 2.126  loss_mask_0: 2.17  loss_mask_1: 2.124  loss_mask_2: 2.12  loss_mask_3: 2.123  loss_mask_4: 2.104  loss_mask_5: 2.109  loss_mask_6: 2.121  loss_mask_7: 2.127  loss_mask_8: 2.121  time: 2.9868  data_time: 0.0590  lr: 4.3248e-05  max_mem: 27646M
[01/30 08:29:31] d2.utils.events INFO:  eta: 19:20:08  iter: 36379  total_loss: 21.99  loss_mask: 2.172  loss_mask_0: 2.244  loss_mask_1: 2.178  loss_mask_2: 2.206  loss_mask_3: 2.204  loss_mask_4: 2.21  loss_mask_5: 2.178  loss_mask_6: 2.175  loss_mask_7: 2.219  loss_mask_8: 2.2  time: 2.9868  data_time: 0.0486  lr: 4.3215e-05  max_mem: 27646M
[01/30 08:30:30] d2.utils.events INFO:  eta: 19:18:50  iter: 36399  total_loss: 18.95  loss_mask: 1.906  loss_mask_0: 1.944  loss_mask_1: 1.878  loss_mask_2: 1.886  loss_mask_3: 1.916  loss_mask_4: 1.888  loss_mask_5: 1.889  loss_mask_6: 1.882  loss_mask_7: 1.897  loss_mask_8: 1.893  time: 2.9868  data_time: 0.0555  lr: 4.3182e-05  max_mem: 27646M
[01/30 08:31:28] d2.utils.events INFO:  eta: 19:17:13  iter: 36419  total_loss: 17.97  loss_mask: 1.783  loss_mask_0: 1.839  loss_mask_1: 1.782  loss_mask_2: 1.792  loss_mask_3: 1.797  loss_mask_4: 1.804  loss_mask_5: 1.786  loss_mask_6: 1.776  loss_mask_7: 1.799  loss_mask_8: 1.806  time: 2.9867  data_time: 0.0492  lr: 4.3149e-05  max_mem: 27646M
[01/30 08:32:27] d2.utils.events INFO:  eta: 19:16:12  iter: 36439  total_loss: 19.67  loss_mask: 1.961  loss_mask_0: 2.01  loss_mask_1: 1.953  loss_mask_2: 1.967  loss_mask_3: 1.97  loss_mask_4: 1.971  loss_mask_5: 1.961  loss_mask_6: 1.959  loss_mask_7: 1.971  loss_mask_8: 1.965  time: 2.9867  data_time: 0.0548  lr: 4.3116e-05  max_mem: 27646M
[01/30 08:33:26] d2.utils.events INFO:  eta: 19:15:17  iter: 36459  total_loss: 19.8  loss_mask: 1.974  loss_mask_0: 2.048  loss_mask_1: 1.967  loss_mask_2: 1.983  loss_mask_3: 1.986  loss_mask_4: 1.982  loss_mask_5: 1.968  loss_mask_6: 1.967  loss_mask_7: 1.982  loss_mask_8: 1.979  time: 2.9867  data_time: 0.0515  lr: 4.3083e-05  max_mem: 27646M
[01/30 08:34:25] d2.utils.events INFO:  eta: 19:14:24  iter: 36479  total_loss: 19.49  loss_mask: 1.947  loss_mask_0: 1.986  loss_mask_1: 1.943  loss_mask_2: 1.942  loss_mask_3: 1.947  loss_mask_4: 1.946  loss_mask_5: 1.947  loss_mask_6: 1.953  loss_mask_7: 1.946  loss_mask_8: 1.945  time: 2.9867  data_time: 0.0472  lr: 4.305e-05  max_mem: 27646M
[01/30 08:35:24] d2.utils.events INFO:  eta: 19:13:07  iter: 36499  total_loss: 19.61  loss_mask: 1.964  loss_mask_0: 1.991  loss_mask_1: 1.962  loss_mask_2: 1.952  loss_mask_3: 1.966  loss_mask_4: 1.963  loss_mask_5: 1.966  loss_mask_6: 1.95  loss_mask_7: 1.951  loss_mask_8: 1.97  time: 2.9866  data_time: 0.0512  lr: 4.3017e-05  max_mem: 27646M
[01/30 08:36:22] d2.utils.events INFO:  eta: 19:11:56  iter: 36519  total_loss: 19.1  loss_mask: 1.892  loss_mask_0: 1.94  loss_mask_1: 1.897  loss_mask_2: 1.913  loss_mask_3: 1.909  loss_mask_4: 1.925  loss_mask_5: 1.897  loss_mask_6: 1.892  loss_mask_7: 1.919  loss_mask_8: 1.917  time: 2.9866  data_time: 0.0507  lr: 4.2984e-05  max_mem: 27646M
[01/30 08:37:21] d2.utils.events INFO:  eta: 19:10:38  iter: 36539  total_loss: 18.05  loss_mask: 1.785  loss_mask_0: 1.861  loss_mask_1: 1.787  loss_mask_2: 1.803  loss_mask_3: 1.805  loss_mask_4: 1.809  loss_mask_5: 1.794  loss_mask_6: 1.79  loss_mask_7: 1.805  loss_mask_8: 1.805  time: 2.9866  data_time: 0.0525  lr: 4.2951e-05  max_mem: 27646M
[01/30 08:38:20] d2.utils.events INFO:  eta: 19:09:33  iter: 36559  total_loss: 19.79  loss_mask: 1.983  loss_mask_0: 1.994  loss_mask_1: 1.977  loss_mask_2: 1.98  loss_mask_3: 1.975  loss_mask_4: 1.979  loss_mask_5: 1.972  loss_mask_6: 1.976  loss_mask_7: 1.977  loss_mask_8: 1.981  time: 2.9866  data_time: 0.0574  lr: 4.2918e-05  max_mem: 27646M
[01/30 08:39:18] d2.utils.events INFO:  eta: 19:08:32  iter: 36579  total_loss: 20.8  loss_mask: 2.073  loss_mask_0: 2.106  loss_mask_1: 2.072  loss_mask_2: 2.076  loss_mask_3: 2.082  loss_mask_4: 2.079  loss_mask_5: 2.075  loss_mask_6: 2.075  loss_mask_7: 2.08  loss_mask_8: 2.078  time: 2.9865  data_time: 0.0501  lr: 4.2885e-05  max_mem: 27646M
[01/30 08:40:18] d2.utils.events INFO:  eta: 19:07:41  iter: 36599  total_loss: 21.35  loss_mask: 2.132  loss_mask_0: 2.154  loss_mask_1: 2.119  loss_mask_2: 2.138  loss_mask_3: 2.131  loss_mask_4: 2.141  loss_mask_5: 2.131  loss_mask_6: 2.13  loss_mask_7: 2.136  loss_mask_8: 2.135  time: 2.9865  data_time: 0.0494  lr: 4.2852e-05  max_mem: 27646M
[01/30 08:41:16] d2.utils.events INFO:  eta: 19:06:38  iter: 36619  total_loss: 19.75  loss_mask: 1.962  loss_mask_0: 2.009  loss_mask_1: 1.97  loss_mask_2: 1.973  loss_mask_3: 1.972  loss_mask_4: 1.973  loss_mask_5: 1.967  loss_mask_6: 1.962  loss_mask_7: 1.973  loss_mask_8: 1.981  time: 2.9865  data_time: 0.0518  lr: 4.2819e-05  max_mem: 27646M
[01/30 08:42:15] d2.utils.events INFO:  eta: 19:05:38  iter: 36639  total_loss: 18.84  loss_mask: 1.882  loss_mask_0: 1.932  loss_mask_1: 1.874  loss_mask_2: 1.883  loss_mask_3: 1.876  loss_mask_4: 1.893  loss_mask_5: 1.892  loss_mask_6: 1.88  loss_mask_7: 1.889  loss_mask_8: 1.892  time: 2.9865  data_time: 0.0502  lr: 4.2786e-05  max_mem: 27646M
[01/30 08:43:14] d2.utils.events INFO:  eta: 19:04:45  iter: 36659  total_loss: 20.74  loss_mask: 2.072  loss_mask_0: 2.157  loss_mask_1: 2.054  loss_mask_2: 2.058  loss_mask_3: 2.068  loss_mask_4: 2.074  loss_mask_5: 2.063  loss_mask_6: 2.062  loss_mask_7: 2.076  loss_mask_8: 2.073  time: 2.9864  data_time: 0.0511  lr: 4.2753e-05  max_mem: 27646M
[01/30 08:44:13] d2.utils.events INFO:  eta: 19:03:55  iter: 36679  total_loss: 19.16  loss_mask: 1.911  loss_mask_0: 1.961  loss_mask_1: 1.914  loss_mask_2: 1.917  loss_mask_3: 1.927  loss_mask_4: 1.92  loss_mask_5: 1.904  loss_mask_6: 1.906  loss_mask_7: 1.916  loss_mask_8: 1.918  time: 2.9864  data_time: 0.0507  lr: 4.272e-05  max_mem: 27646M
[01/30 08:45:12] d2.utils.events INFO:  eta: 19:02:53  iter: 36699  total_loss: 18.38  loss_mask: 1.84  loss_mask_0: 1.847  loss_mask_1: 1.839  loss_mask_2: 1.846  loss_mask_3: 1.835  loss_mask_4: 1.83  loss_mask_5: 1.833  loss_mask_6: 1.84  loss_mask_7: 1.843  loss_mask_8: 1.833  time: 2.9864  data_time: 0.0518  lr: 4.2688e-05  max_mem: 27646M
[01/30 08:46:11] d2.utils.events INFO:  eta: 19:01:48  iter: 36719  total_loss: 20.46  loss_mask: 2.036  loss_mask_0: 2.082  loss_mask_1: 2.034  loss_mask_2: 2.053  loss_mask_3: 2.044  loss_mask_4: 2.051  loss_mask_5: 2.035  loss_mask_6: 2.025  loss_mask_7: 2.045  loss_mask_8: 2.05  time: 2.9864  data_time: 0.0564  lr: 4.2655e-05  max_mem: 27646M
[01/30 08:47:10] d2.utils.events INFO:  eta: 19:00:51  iter: 36739  total_loss: 17.81  loss_mask: 1.76  loss_mask_0: 1.85  loss_mask_1: 1.765  loss_mask_2: 1.782  loss_mask_3: 1.776  loss_mask_4: 1.805  loss_mask_5: 1.759  loss_mask_6: 1.756  loss_mask_7: 1.783  loss_mask_8: 1.79  time: 2.9863  data_time: 0.0495  lr: 4.2622e-05  max_mem: 27646M
[01/30 08:48:08] d2.utils.events INFO:  eta: 18:59:46  iter: 36759  total_loss: 18.21  loss_mask: 1.824  loss_mask_0: 1.866  loss_mask_1: 1.81  loss_mask_2: 1.823  loss_mask_3: 1.82  loss_mask_4: 1.829  loss_mask_5: 1.814  loss_mask_6: 1.822  loss_mask_7: 1.827  loss_mask_8: 1.816  time: 2.9863  data_time: 0.0481  lr: 4.2589e-05  max_mem: 27646M
[01/30 08:49:07] d2.utils.events INFO:  eta: 18:58:44  iter: 36779  total_loss: 19.76  loss_mask: 1.967  loss_mask_0: 2.008  loss_mask_1: 1.958  loss_mask_2: 1.978  loss_mask_3: 1.979  loss_mask_4: 1.975  loss_mask_5: 1.97  loss_mask_6: 1.967  loss_mask_7: 1.972  loss_mask_8: 1.982  time: 2.9863  data_time: 0.0491  lr: 4.2556e-05  max_mem: 27646M
[01/30 08:50:06] d2.utils.events INFO:  eta: 18:57:46  iter: 36799  total_loss: 20.36  loss_mask: 2.014  loss_mask_0: 2.01  loss_mask_1: 2.013  loss_mask_2: 2.052  loss_mask_3: 2.083  loss_mask_4: 2.041  loss_mask_5: 2.033  loss_mask_6: 2.021  loss_mask_7: 2.033  loss_mask_8: 2.012  time: 2.9863  data_time: 0.0541  lr: 4.2523e-05  max_mem: 27646M
[01/30 08:51:05] d2.utils.events INFO:  eta: 18:56:55  iter: 36819  total_loss: 19.42  loss_mask: 1.928  loss_mask_0: 1.968  loss_mask_1: 1.942  loss_mask_2: 1.957  loss_mask_3: 1.94  loss_mask_4: 1.942  loss_mask_5: 1.931  loss_mask_6: 1.941  loss_mask_7: 1.941  loss_mask_8: 1.937  time: 2.9862  data_time: 0.0552  lr: 4.249e-05  max_mem: 27646M
[01/30 08:52:04] d2.utils.events INFO:  eta: 18:55:49  iter: 36839  total_loss: 18.3  loss_mask: 1.807  loss_mask_0: 1.89  loss_mask_1: 1.822  loss_mask_2: 1.831  loss_mask_3: 1.834  loss_mask_4: 1.831  loss_mask_5: 1.81  loss_mask_6: 1.808  loss_mask_7: 1.831  loss_mask_8: 1.832  time: 2.9862  data_time: 0.0561  lr: 4.2457e-05  max_mem: 27646M
[01/30 08:53:03] d2.utils.events INFO:  eta: 18:55:17  iter: 36859  total_loss: 21.32  loss_mask: 2.118  loss_mask_0: 2.152  loss_mask_1: 2.109  loss_mask_2: 2.132  loss_mask_3: 2.231  loss_mask_4: 2.147  loss_mask_5: 2.123  loss_mask_6: 2.138  loss_mask_7: 2.135  loss_mask_8: 2.124  time: 2.9862  data_time: 0.0528  lr: 4.2424e-05  max_mem: 27646M
[01/30 08:54:02] d2.utils.events INFO:  eta: 18:54:02  iter: 36879  total_loss: 20.04  loss_mask: 1.984  loss_mask_0: 2.062  loss_mask_1: 1.997  loss_mask_2: 2  loss_mask_3: 2.008  loss_mask_4: 2  loss_mask_5: 1.992  loss_mask_6: 1.994  loss_mask_7: 2.002  loss_mask_8: 1.997  time: 2.9862  data_time: 0.0476  lr: 4.2391e-05  max_mem: 27646M
[01/30 08:55:01] d2.utils.events INFO:  eta: 18:53:03  iter: 36899  total_loss: 19.15  loss_mask: 1.896  loss_mask_0: 1.994  loss_mask_1: 1.901  loss_mask_2: 1.921  loss_mask_3: 1.921  loss_mask_4: 1.915  loss_mask_5: 1.905  loss_mask_6: 1.904  loss_mask_7: 1.919  loss_mask_8: 1.917  time: 2.9862  data_time: 0.0572  lr: 4.2358e-05  max_mem: 27646M
[01/30 08:56:00] d2.utils.events INFO:  eta: 18:52:12  iter: 36919  total_loss: 18.4  loss_mask: 1.839  loss_mask_0: 1.869  loss_mask_1: 1.843  loss_mask_2: 1.841  loss_mask_3: 1.828  loss_mask_4: 1.826  loss_mask_5: 1.842  loss_mask_6: 1.829  loss_mask_7: 1.832  loss_mask_8: 1.847  time: 2.9861  data_time: 0.0511  lr: 4.2325e-05  max_mem: 27646M
[01/30 08:56:59] d2.utils.events INFO:  eta: 18:51:13  iter: 36939  total_loss: 19.49  loss_mask: 1.944  loss_mask_0: 2.023  loss_mask_1: 1.936  loss_mask_2: 1.947  loss_mask_3: 1.945  loss_mask_4: 1.957  loss_mask_5: 1.946  loss_mask_6: 1.933  loss_mask_7: 1.945  loss_mask_8: 1.949  time: 2.9861  data_time: 0.0596  lr: 4.2292e-05  max_mem: 27646M
[01/30 08:57:57] d2.utils.events INFO:  eta: 18:49:56  iter: 36959  total_loss: 19.03  loss_mask: 1.897  loss_mask_0: 1.95  loss_mask_1: 1.893  loss_mask_2: 1.898  loss_mask_3: 1.9  loss_mask_4: 1.902  loss_mask_5: 1.9  loss_mask_6: 1.897  loss_mask_7: 1.906  loss_mask_8: 1.897  time: 2.9861  data_time: 0.0478  lr: 4.2259e-05  max_mem: 27646M
[01/30 08:58:56] d2.utils.events INFO:  eta: 18:49:03  iter: 36979  total_loss: 18.09  loss_mask: 1.796  loss_mask_0: 1.869  loss_mask_1: 1.791  loss_mask_2: 1.809  loss_mask_3: 1.806  loss_mask_4: 1.81  loss_mask_5: 1.798  loss_mask_6: 1.794  loss_mask_7: 1.81  loss_mask_8: 1.81  time: 2.9860  data_time: 0.0670  lr: 4.2226e-05  max_mem: 27646M
[01/30 08:59:54] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 08:59:55] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 08:59:55] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 09:14:06] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.4396096147105473, 'error_1pix': 0.3678321537695639, 'error_3pix': 0.16109268221568757, 'mIoU': 7.340816237554558, 'fwIoU': 21.214525947557554, 'IoU-0': 4.045073655506574e-05, 'IoU-1': 70.19973576495116, 'IoU-2': 3.198107209182019, 'IoU-3': 6.975695998143847, 'IoU-4': 7.111927443334834, 'IoU-5': 6.17592261591841, 'IoU-6': 5.180274812374496, 'IoU-7': 3.980310534110518, 'IoU-8': 7.764911993964417, 'IoU-9': 18.758710706553387, 'IoU-10': 23.61246870780217, 'IoU-11': 32.376930843147804, 'IoU-12': 32.289443543671595, 'IoU-13': 30.17368155131843, 'IoU-14': 30.106944765661687, 'IoU-15': 28.521445358472725, 'IoU-16': 27.19948500025579, 'IoU-17': 24.7798794653296, 'IoU-18': 24.396093570422938, 'IoU-19': 24.478364012545445, 'IoU-20': 22.925031314494582, 'IoU-21': 22.922797749856436, 'IoU-22': 23.32354082001232, 'IoU-23': 21.597276202613457, 'IoU-24': 20.92469622685094, 'IoU-25': 20.774699326606857, 'IoU-26': 19.96584475567017, 'IoU-27': 21.699677341018543, 'IoU-28': 20.725289089679553, 'IoU-29': 21.33836553668812, 'IoU-30': 20.631310508524, 'IoU-31': 22.092270403393492, 'IoU-32': 20.535167673984056, 'IoU-33': 19.86462534261994, 'IoU-34': 18.934550707637, 'IoU-35': 19.55212857944464, 'IoU-36': 19.310143658493338, 'IoU-37': 18.717155948320336, 'IoU-38': 18.569882819465917, 'IoU-39': 17.33515405359881, 'IoU-40': 17.303620997057088, 'IoU-41': 15.857088810062644, 'IoU-42': 15.08150742589417, 'IoU-43': 14.49352459654504, 'IoU-44': 13.880954881087415, 'IoU-45': 13.223975866228077, 'IoU-46': 12.226129042137337, 'IoU-47': 11.180881742438654, 'IoU-48': 10.43144669646206, 'IoU-49': 9.514314999738668, 'IoU-50': 9.026802258871758, 'IoU-51': 8.129704106928436, 'IoU-52': 7.560830761564348, 'IoU-53': 6.960701384201677, 'IoU-54': 6.635159480485112, 'IoU-55': 6.308947430572314, 'IoU-56': 6.179265930334592, 'IoU-57': 5.946753919282125, 'IoU-58': 5.858057638289543, 'IoU-59': 5.210400442363054, 'IoU-60': 5.0316413560513755, 'IoU-61': 4.65372997682205, 'IoU-62': 4.521888799758427, 'IoU-63': 4.169432108527927, 'IoU-64': 3.941418569938608, 'IoU-65': 3.953626245234479, 'IoU-66': 3.926575718855837, 'IoU-67': 4.051412073384546, 'IoU-68': 4.196548176414749, 'IoU-69': 4.135457263625052, 'IoU-70': 3.8922178288251534, 'IoU-71': 3.9603962107174056, 'IoU-72': 4.101822466746794, 'IoU-73': 4.371695155191432, 'IoU-74': 4.464414012005126, 'IoU-75': 4.088458345067983, 'IoU-76': 4.387581404262348, 'IoU-77': 4.514304964882072, 'IoU-78': 4.453364818083809, 'IoU-79': 4.431973236694687, 'IoU-80': 4.589783828561397, 'IoU-81': 4.659109355314368, 'IoU-82': 4.505069809288721, 'IoU-83': 4.826327802745572, 'IoU-84': 4.993913866974335, 'IoU-85': 4.794538686091082, 'IoU-86': 4.828125221784225, 'IoU-87': 4.662262305784088, 'IoU-88': 4.730999848231223, 'IoU-89': 4.62183832000822, 'IoU-90': 4.509529144969345, 'IoU-91': 4.5276334265556875, 'IoU-92': 4.5331666055958, 'IoU-93': 4.607637653498073, 'IoU-94': 4.797643881469139, 'IoU-95': 4.696867747144847, 'IoU-96': 4.65506498508585, 'IoU-97': 4.825361119241965, 'IoU-98': 4.842682563338301, 'IoU-99': 4.632289264245043, 'IoU-100': 4.502589876175973, 'IoU-101': 4.480270749564314, 'IoU-102': 4.403510422783903, 'IoU-103': 4.400080316202952, 'IoU-104': 4.109319002804551, 'IoU-105': 4.207947533446158, 'IoU-106': 4.070151869771934, 'IoU-107': 3.9709348076664623, 'IoU-108': 4.061622586874454, 'IoU-109': 4.259509915879661, 'IoU-110': 3.994105868944243, 'IoU-111': 3.594745305379211, 'IoU-112': 3.4584729874796363, 'IoU-113': 3.278580996362071, 'IoU-114': 3.264741656216933, 'IoU-115': 3.2062953247955566, 'IoU-116': 2.875957776254764, 'IoU-117': 2.972584023895089, 'IoU-118': 2.880667443657677, 'IoU-119': 2.812747904279634, 'IoU-120': 2.837633254593158, 'IoU-121': 2.909539616292371, 'IoU-122': 2.7584368982692675, 'IoU-123': 2.613652004498156, 'IoU-124': 2.5600795443055038, 'IoU-125': 2.564583230273833, 'IoU-126': 2.692616910692952, 'IoU-127': 2.2977083145120005, 'IoU-128': 2.3996854123331857, 'IoU-129': 2.425182723948393, 'IoU-130': 2.3245993856878275, 'IoU-131': 2.262134700813105, 'IoU-132': 2.416248060062393, 'IoU-133': 2.420919170211044, 'IoU-134': 2.324266812248673, 'IoU-135': 2.2948577765010763, 'IoU-136': 2.287625965408744, 'IoU-137': 2.3970285230510124, 'IoU-138': 2.1970707969373446, 'IoU-139': 2.220552575565554, 'IoU-140': 2.076466361006293, 'IoU-141': 1.9880691568007425, 'IoU-142': 2.0841734209323826, 'IoU-143': 2.1360910135240223, 'IoU-144': 2.0634835367329147, 'IoU-145': 2.034285328344667, 'IoU-146': 2.2211507651315516, 'IoU-147': 2.5043740407975195, 'IoU-148': 2.4591014585731266, 'IoU-149': 2.4389986303319224, 'IoU-150': 2.5277666527780505, 'IoU-151': 2.590945697192821, 'IoU-152': 2.626361113455837, 'IoU-153': 2.3012512736135635, 'IoU-154': 2.2054337933239863, 'IoU-155': 2.001014249580526, 'IoU-156': 2.134896758098333, 'IoU-157': 2.217192670831704, 'IoU-158': 2.114845604487295, 'IoU-159': 1.8752860838636833, 'IoU-160': 1.921319369275455, 'IoU-161': 2.5394360637432474, 'IoU-162': 1.7168228460632249, 'IoU-163': 1.625937208826932, 'IoU-164': 1.6611976711862881, 'IoU-165': 1.788687214778199, 'IoU-166': 1.8996027222860632, 'IoU-167': 2.1528600822697386, 'IoU-168': 2.2599130321761205, 'IoU-169': 2.3168484967533547, 'IoU-170': 2.5439617223057422, 'IoU-171': 1.844687198691495, 'IoU-172': 1.8655687816061164, 'IoU-173': 1.8459706906829385, 'IoU-174': 1.578993939223536, 'IoU-175': 2.386183879769957, 'IoU-176': 2.0886477627022564, 'IoU-177': 1.2748480586985516, 'IoU-178': 1.2404354859866205, 'IoU-179': 1.6956936636204105, 'IoU-180': 2.414982338935998, 'IoU-181': 1.416974741964853, 'IoU-182': 1.3191609808419986, 'IoU-183': 1.306709231698841, 'IoU-184': 1.014112938411509, 'IoU-185': 1.645248286550371, 'IoU-186': 1.508834214002642, 'IoU-187': 0.17559458650379114, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 13.026956353831052, 'pACC': 30.816193639291466, 'ACC-0': 0.00012019380825086293, 'ACC-1': 71.5050125455296, 'ACC-2': 6.666219218526276, 'ACC-3': 27.234021411851156, 'ACC-4': 25.981813963904166, 'ACC-5': 23.175194865247466, 'ACC-6': 20.029766986239235, 'ACC-7': 17.09073075394438, 'ACC-8': 18.411400817484985, 'ACC-9': 31.79680651743239, 'ACC-10': 38.78481006345142, 'ACC-11': 47.322669164818876, 'ACC-12': 48.73126368574283, 'ACC-13': 44.63976070277641, 'ACC-14': 45.26732004692143, 'ACC-15': 43.37017294478244, 'ACC-16': 40.73306590001708, 'ACC-17': 40.383332981734846, 'ACC-18': 38.92666359337931, 'ACC-19': 39.71845350798374, 'ACC-20': 37.005433010078, 'ACC-21': 37.049576123408556, 'ACC-22': 37.10806381265839, 'ACC-23': 36.11988782602452, 'ACC-24': 35.15323432002511, 'ACC-25': 35.2409382007642, 'ACC-26': 33.91149126521527, 'ACC-27': 36.54903775205843, 'ACC-28': 35.416050355915765, 'ACC-29': 35.253530638799816, 'ACC-30': 34.97920199196764, 'ACC-31': 36.91532223211148, 'ACC-32': 34.79643558929891, 'ACC-33': 34.36851134989688, 'ACC-34': 33.054300203559386, 'ACC-35': 33.85790788857436, 'ACC-36': 33.42746234163736, 'ACC-37': 33.209501540426785, 'ACC-38': 32.961133648146195, 'ACC-39': 30.852754579633903, 'ACC-40': 30.16609886052964, 'ACC-41': 28.505006425239994, 'ACC-42': 27.273539386315104, 'ACC-43': 26.393755265161346, 'ACC-44': 24.729356665402797, 'ACC-45': 23.818093223435163, 'ACC-46': 22.638327904675094, 'ACC-47': 20.93779251727472, 'ACC-48': 19.696384119664717, 'ACC-49': 17.992664111193285, 'ACC-50': 16.995017726690513, 'ACC-51': 15.508282482862477, 'ACC-52': 14.40619858811331, 'ACC-53': 13.23014184136655, 'ACC-54': 12.347847889565868, 'ACC-55': 11.634120267292209, 'ACC-56': 11.534225057683967, 'ACC-57': 10.937893397256088, 'ACC-58': 10.893326816774708, 'ACC-59': 9.859095052095936, 'ACC-60': 9.596355239721799, 'ACC-61': 8.929584998290526, 'ACC-62': 8.69449703930466, 'ACC-63': 8.035445506421295, 'ACC-64': 7.501538829618445, 'ACC-65': 7.576862604092118, 'ACC-66': 7.6114734441223355, 'ACC-67': 7.919188580504695, 'ACC-68': 8.123259694069683, 'ACC-69': 7.836372670423245, 'ACC-70': 7.317469401552702, 'ACC-71': 7.580002723403129, 'ACC-72': 7.85387862411321, 'ACC-73': 8.383169750845168, 'ACC-74': 8.498024081382205, 'ACC-75': 7.821781097015634, 'ACC-76': 8.251350633472834, 'ACC-77': 8.598260958413777, 'ACC-78': 8.618923357498259, 'ACC-79': 8.613227271193242, 'ACC-80': 8.75708029574828, 'ACC-81': 8.729708138461657, 'ACC-82': 8.349210585354735, 'ACC-83': 8.795749041271646, 'ACC-84': 9.15602596933905, 'ACC-85': 8.862838169064743, 'ACC-86': 8.994851733115457, 'ACC-87': 8.711310388973553, 'ACC-88': 8.764302554180597, 'ACC-89': 8.477496746481286, 'ACC-90': 8.19739891742274, 'ACC-91': 8.21893146665266, 'ACC-92': 8.301619404701013, 'ACC-93': 8.480414666603615, 'ACC-94': 8.835035068641117, 'ACC-95': 8.632365764364796, 'ACC-96': 8.58216890326833, 'ACC-97': 8.817138799988838, 'ACC-98': 8.799395002779283, 'ACC-99': 8.464567840192162, 'ACC-100': 8.21493706751912, 'ACC-101': 8.170670477035479, 'ACC-102': 8.099841413683734, 'ACC-103': 8.14496552375555, 'ACC-104': 7.654263298984285, 'ACC-105': 7.8684455904162665, 'ACC-106': 7.626777975407083, 'ACC-107': 7.4410706282173456, 'ACC-108': 7.544327963504584, 'ACC-109': 7.853456426306517, 'ACC-110': 7.501214180910397, 'ACC-111': 6.799250739842695, 'ACC-112': 6.613074467865034, 'ACC-113': 6.292009758279712, 'ACC-114': 6.31906667536444, 'ACC-115': 6.170297535820065, 'ACC-116': 5.6107538072382726, 'ACC-117': 5.770950883489629, 'ACC-118': 5.581104565358229, 'ACC-119': 5.375810034324997, 'ACC-120': 5.4248059400443465, 'ACC-121': 5.532726479099321, 'ACC-122': 5.200401936086501, 'ACC-123': 4.900289932875309, 'ACC-124': 4.855679049768765, 'ACC-125': 4.821327375585051, 'ACC-126': 5.107286951611581, 'ACC-127': 4.367272846209198, 'ACC-128': 4.599757772679539, 'ACC-129': 4.655365756774616, 'ACC-130': 4.469898850230754, 'ACC-131': 4.349400849198485, 'ACC-132': 4.627747450680768, 'ACC-133': 4.579735586900461, 'ACC-134': 4.308418785006463, 'ACC-135': 4.235576648993786, 'ACC-136': 4.19233949869549, 'ACC-137': 4.468878056077734, 'ACC-138': 4.1370535827601085, 'ACC-139': 4.177239162355002, 'ACC-140': 3.891337729651293, 'ACC-141': 3.720594002413577, 'ACC-142': 3.931493606017496, 'ACC-143': 3.9617092284425706, 'ACC-144': 3.7788808664259923, 'ACC-145': 3.6640354211856256, 'ACC-146': 4.01617509309817, 'ACC-147': 4.501556663382802, 'ACC-148': 4.45957467841388, 'ACC-149': 4.449688612054532, 'ACC-150': 4.565518980955984, 'ACC-151': 4.800364069262685, 'ACC-152': 4.819315193202509, 'ACC-153': 4.45890360761465, 'ACC-154': 4.2109181170574885, 'ACC-155': 3.939353601388344, 'ACC-156': 4.297930927495201, 'ACC-157': 4.529264372227734, 'ACC-158': 4.382041659668817, 'ACC-159': 3.9204733942560965, 'ACC-160': 3.8044892096095553, 'ACC-161': 4.905118836656117, 'ACC-162': 3.36684508525711, 'ACC-163': 3.246418727939502, 'ACC-164': 3.392007204487584, 'ACC-165': 3.7044154408611716, 'ACC-166': 4.1156374075597455, 'ACC-167': 4.423911740641725, 'ACC-168': 4.830156832407343, 'ACC-169': 5.132717896166474, 'ACC-170': 5.68770674503457, 'ACC-171': 4.1784761089548486, 'ACC-172': 4.436974478645776, 'ACC-173': 4.090076123317517, 'ACC-174': 3.5591195214741993, 'ACC-175': 5.993392237450521, 'ACC-176': 4.91895460877641, 'ACC-177': 3.1769671267409647, 'ACC-178': 3.287934774420478, 'ACC-179': 5.7756334693364115, 'ACC-180': 9.802651630600428, 'ACC-181': 5.540751478631203, 'ACC-182': 3.7762178118832757, 'ACC-183': 4.403991985892911, 'ACC-184': 3.2890190723485144, 'ACC-185': 6.095228856893422, 'ACC-186': 4.141515959141953, 'ACC-187': 0.3798064726561084, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 09:14:06] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 09:14:06] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 09:14:06] d2.evaluation.testing INFO: copypaste: 2.4396,0.3678,0.1611,7.3408,21.2145,13.0270,30.8162
[01/30 09:14:07] d2.utils.events INFO:  eta: 18:47:52  iter: 36999  total_loss: 19.46  loss_mask: 1.93  loss_mask_0: 1.994  loss_mask_1: 1.931  loss_mask_2: 1.952  loss_mask_3: 1.947  loss_mask_4: 1.95  loss_mask_5: 1.936  loss_mask_6: 1.931  loss_mask_7: 1.953  loss_mask_8: 1.956  time: 2.9860  data_time: 0.0543  lr: 4.2193e-05  max_mem: 27646M
[01/30 09:15:06] d2.utils.events INFO:  eta: 18:46:53  iter: 37019  total_loss: 19.71  loss_mask: 1.967  loss_mask_0: 1.989  loss_mask_1: 1.962  loss_mask_2: 1.962  loss_mask_3: 1.965  loss_mask_4: 1.968  loss_mask_5: 1.965  loss_mask_6: 1.965  loss_mask_7: 1.965  loss_mask_8: 1.96  time: 2.9860  data_time: 0.0573  lr: 4.216e-05  max_mem: 27646M
[01/30 09:16:06] d2.utils.events INFO:  eta: 18:45:58  iter: 37039  total_loss: 19.2  loss_mask: 1.919  loss_mask_0: 1.95  loss_mask_1: 1.909  loss_mask_2: 1.925  loss_mask_3: 1.921  loss_mask_4: 1.92  loss_mask_5: 1.913  loss_mask_6: 1.911  loss_mask_7: 1.922  loss_mask_8: 1.923  time: 2.9860  data_time: 0.0532  lr: 4.2127e-05  max_mem: 27646M
[01/30 09:17:04] d2.utils.events INFO:  eta: 18:44:42  iter: 37059  total_loss: 20.57  loss_mask: 2.043  loss_mask_0: 2.068  loss_mask_1: 2.034  loss_mask_2: 2.057  loss_mask_3: 2.055  loss_mask_4: 2.055  loss_mask_5: 2.041  loss_mask_6: 2.04  loss_mask_7: 2.057  loss_mask_8: 2.063  time: 2.9860  data_time: 0.0531  lr: 4.2093e-05  max_mem: 27646M
[01/30 09:18:03] d2.utils.events INFO:  eta: 18:43:57  iter: 37079  total_loss: 19.94  loss_mask: 1.994  loss_mask_0: 2.001  loss_mask_1: 1.983  loss_mask_2: 1.978  loss_mask_3: 1.994  loss_mask_4: 2.008  loss_mask_5: 1.991  loss_mask_6: 1.993  loss_mask_7: 1.993  loss_mask_8: 1.986  time: 2.9859  data_time: 0.0474  lr: 4.206e-05  max_mem: 27646M
[01/30 09:19:02] d2.utils.events INFO:  eta: 18:42:13  iter: 37099  total_loss: 18.59  loss_mask: 1.855  loss_mask_0: 1.89  loss_mask_1: 1.841  loss_mask_2: 1.863  loss_mask_3: 1.869  loss_mask_4: 1.861  loss_mask_5: 1.853  loss_mask_6: 1.846  loss_mask_7: 1.859  loss_mask_8: 1.856  time: 2.9859  data_time: 0.0524  lr: 4.2027e-05  max_mem: 27646M
[01/30 09:20:01] d2.utils.events INFO:  eta: 18:40:48  iter: 37119  total_loss: 18.76  loss_mask: 1.868  loss_mask_0: 1.911  loss_mask_1: 1.869  loss_mask_2: 1.87  loss_mask_3: 1.876  loss_mask_4: 1.879  loss_mask_5: 1.866  loss_mask_6: 1.863  loss_mask_7: 1.874  loss_mask_8: 1.876  time: 2.9859  data_time: 0.0506  lr: 4.1994e-05  max_mem: 27646M
[01/30 09:21:00] d2.utils.events INFO:  eta: 18:39:20  iter: 37139  total_loss: 19.61  loss_mask: 1.949  loss_mask_0: 2.022  loss_mask_1: 1.945  loss_mask_2: 1.962  loss_mask_3: 1.962  loss_mask_4: 1.96  loss_mask_5: 1.948  loss_mask_6: 1.943  loss_mask_7: 1.957  loss_mask_8: 1.962  time: 2.9859  data_time: 0.0491  lr: 4.1961e-05  max_mem: 27646M
[01/30 09:21:59] d2.utils.events INFO:  eta: 18:38:57  iter: 37159  total_loss: 17.95  loss_mask: 1.778  loss_mask_0: 1.848  loss_mask_1: 1.777  loss_mask_2: 1.797  loss_mask_3: 1.791  loss_mask_4: 1.79  loss_mask_5: 1.776  loss_mask_6: 1.775  loss_mask_7: 1.797  loss_mask_8: 1.801  time: 2.9858  data_time: 0.0516  lr: 4.1928e-05  max_mem: 27646M
[01/30 09:22:58] d2.utils.events INFO:  eta: 18:37:43  iter: 37179  total_loss: 18.83  loss_mask: 1.869  loss_mask_0: 1.917  loss_mask_1: 1.855  loss_mask_2: 1.875  loss_mask_3: 1.879  loss_mask_4: 1.877  loss_mask_5: 1.888  loss_mask_6: 1.871  loss_mask_7: 1.877  loss_mask_8: 1.895  time: 2.9858  data_time: 0.0497  lr: 4.1895e-05  max_mem: 27646M
[01/30 09:23:57] d2.utils.events INFO:  eta: 18:36:36  iter: 37199  total_loss: 19.88  loss_mask: 1.981  loss_mask_0: 2.03  loss_mask_1: 1.986  loss_mask_2: 1.993  loss_mask_3: 1.98  loss_mask_4: 1.98  loss_mask_5: 1.976  loss_mask_6: 1.979  loss_mask_7: 1.985  loss_mask_8: 1.99  time: 2.9858  data_time: 0.0521  lr: 4.1862e-05  max_mem: 27646M
[01/30 09:24:55] d2.utils.events INFO:  eta: 18:35:23  iter: 37219  total_loss: 19.13  loss_mask: 1.903  loss_mask_0: 1.947  loss_mask_1: 1.907  loss_mask_2: 1.915  loss_mask_3: 1.907  loss_mask_4: 1.912  loss_mask_5: 1.906  loss_mask_6: 1.906  loss_mask_7: 1.91  loss_mask_8: 1.914  time: 2.9858  data_time: 0.0468  lr: 4.1829e-05  max_mem: 27646M
[01/30 09:25:54] d2.utils.events INFO:  eta: 18:34:24  iter: 37239  total_loss: 20.02  loss_mask: 1.998  loss_mask_0: 2.047  loss_mask_1: 1.975  loss_mask_2: 1.991  loss_mask_3: 2.013  loss_mask_4: 2.005  loss_mask_5: 1.993  loss_mask_6: 2.001  loss_mask_7: 1.999  loss_mask_8: 1.993  time: 2.9857  data_time: 0.0475  lr: 4.1796e-05  max_mem: 27646M
[01/30 09:26:53] d2.utils.events INFO:  eta: 18:33:17  iter: 37259  total_loss: 19.65  loss_mask: 1.954  loss_mask_0: 2.005  loss_mask_1: 1.948  loss_mask_2: 1.968  loss_mask_3: 1.971  loss_mask_4: 1.967  loss_mask_5: 1.957  loss_mask_6: 1.95  loss_mask_7: 1.966  loss_mask_8: 1.971  time: 2.9857  data_time: 0.0478  lr: 4.1763e-05  max_mem: 27646M
[01/30 09:27:52] d2.utils.events INFO:  eta: 18:32:23  iter: 37279  total_loss: 19.27  loss_mask: 1.918  loss_mask_0: 1.951  loss_mask_1: 1.915  loss_mask_2: 1.929  loss_mask_3: 1.927  loss_mask_4: 1.937  loss_mask_5: 1.923  loss_mask_6: 1.912  loss_mask_7: 1.917  loss_mask_8: 1.941  time: 2.9857  data_time: 0.0629  lr: 4.173e-05  max_mem: 27646M
[01/30 09:28:52] d2.utils.events INFO:  eta: 18:32:18  iter: 37299  total_loss: 20.06  loss_mask: 1.965  loss_mask_0: 2.05  loss_mask_1: 1.981  loss_mask_2: 2.019  loss_mask_3: 2.018  loss_mask_4: 1.998  loss_mask_5: 1.974  loss_mask_6: 1.963  loss_mask_7: 2.015  loss_mask_8: 2.029  time: 2.9857  data_time: 0.0832  lr: 4.1697e-05  max_mem: 27646M
[01/30 09:29:52] d2.utils.events INFO:  eta: 18:31:34  iter: 37319  total_loss: 18.51  loss_mask: 1.837  loss_mask_0: 1.894  loss_mask_1: 1.835  loss_mask_2: 1.854  loss_mask_3: 1.851  loss_mask_4: 1.854  loss_mask_5: 1.84  loss_mask_6: 1.84  loss_mask_7: 1.859  loss_mask_8: 1.849  time: 2.9857  data_time: 0.0591  lr: 4.1664e-05  max_mem: 27646M
[01/30 09:30:51] d2.utils.events INFO:  eta: 18:30:45  iter: 37339  total_loss: 18.63  loss_mask: 1.855  loss_mask_0: 1.876  loss_mask_1: 1.851  loss_mask_2: 1.863  loss_mask_3: 1.865  loss_mask_4: 1.86  loss_mask_5: 1.861  loss_mask_6: 1.859  loss_mask_7: 1.87  loss_mask_8: 1.865  time: 2.9857  data_time: 0.0613  lr: 4.1631e-05  max_mem: 27646M
[01/30 09:31:50] d2.utils.events INFO:  eta: 18:29:47  iter: 37359  total_loss: 20.49  loss_mask: 2.046  loss_mask_0: 2.093  loss_mask_1: 2.037  loss_mask_2: 2.046  loss_mask_3: 2.05  loss_mask_4: 2.05  loss_mask_5: 2.043  loss_mask_6: 2.039  loss_mask_7: 2.044  loss_mask_8: 2.044  time: 2.9857  data_time: 0.0479  lr: 4.1598e-05  max_mem: 27646M
[01/30 09:32:49] d2.utils.events INFO:  eta: 18:28:47  iter: 37379  total_loss: 19.26  loss_mask: 1.914  loss_mask_0: 1.987  loss_mask_1: 1.908  loss_mask_2: 1.926  loss_mask_3: 1.926  loss_mask_4: 1.93  loss_mask_5: 1.909  loss_mask_6: 1.912  loss_mask_7: 1.924  loss_mask_8: 1.92  time: 2.9856  data_time: 0.0502  lr: 4.1565e-05  max_mem: 27646M
[01/30 09:33:47] d2.utils.events INFO:  eta: 18:27:45  iter: 37399  total_loss: 20.38  loss_mask: 2.024  loss_mask_0: 2.067  loss_mask_1: 2.034  loss_mask_2: 2.041  loss_mask_3: 2.036  loss_mask_4: 2.047  loss_mask_5: 2.026  loss_mask_6: 2.026  loss_mask_7: 2.044  loss_mask_8: 2.037  time: 2.9856  data_time: 0.0504  lr: 4.1532e-05  max_mem: 27646M
[01/30 09:34:46] d2.utils.events INFO:  eta: 18:26:50  iter: 37419  total_loss: 19.93  loss_mask: 1.984  loss_mask_0: 2.02  loss_mask_1: 1.979  loss_mask_2: 1.994  loss_mask_3: 1.996  loss_mask_4: 2.005  loss_mask_5: 1.975  loss_mask_6: 1.97  loss_mask_7: 2.005  loss_mask_8: 2.002  time: 2.9856  data_time: 0.0527  lr: 4.1499e-05  max_mem: 27646M
[01/30 09:35:45] d2.utils.events INFO:  eta: 18:25:52  iter: 37439  total_loss: 19.93  loss_mask: 1.97  loss_mask_0: 2.056  loss_mask_1: 1.971  loss_mask_2: 1.998  loss_mask_3: 1.999  loss_mask_4: 1.991  loss_mask_5: 1.985  loss_mask_6: 1.968  loss_mask_7: 1.997  loss_mask_8: 1.998  time: 2.9856  data_time: 0.0520  lr: 4.1465e-05  max_mem: 27646M
[01/30 09:36:44] d2.utils.events INFO:  eta: 18:24:52  iter: 37459  total_loss: 19.09  loss_mask: 1.891  loss_mask_0: 1.968  loss_mask_1: 1.9  loss_mask_2: 1.909  loss_mask_3: 1.914  loss_mask_4: 1.916  loss_mask_5: 1.888  loss_mask_6: 1.889  loss_mask_7: 1.92  loss_mask_8: 1.914  time: 2.9855  data_time: 0.0541  lr: 4.1432e-05  max_mem: 27646M
[01/30 09:37:42] d2.utils.events INFO:  eta: 18:23:54  iter: 37479  total_loss: 19.07  loss_mask: 1.908  loss_mask_0: 1.922  loss_mask_1: 1.9  loss_mask_2: 1.908  loss_mask_3: 1.906  loss_mask_4: 1.907  loss_mask_5: 1.909  loss_mask_6: 1.904  loss_mask_7: 1.907  loss_mask_8: 1.902  time: 2.9855  data_time: 0.0499  lr: 4.1399e-05  max_mem: 27646M
[01/30 09:38:41] d2.utils.events INFO:  eta: 18:22:55  iter: 37499  total_loss: 20.02  loss_mask: 1.999  loss_mask_0: 2.045  loss_mask_1: 1.994  loss_mask_2: 2.009  loss_mask_3: 2  loss_mask_4: 2.011  loss_mask_5: 2.001  loss_mask_6: 1.994  loss_mask_7: 2.016  loss_mask_8: 2.003  time: 2.9855  data_time: 0.0541  lr: 4.1366e-05  max_mem: 27646M
[01/30 09:39:40] d2.utils.events INFO:  eta: 18:21:56  iter: 37519  total_loss: 18.43  loss_mask: 1.831  loss_mask_0: 1.905  loss_mask_1: 1.822  loss_mask_2: 1.844  loss_mask_3: 1.845  loss_mask_4: 1.841  loss_mask_5: 1.82  loss_mask_6: 1.824  loss_mask_7: 1.85  loss_mask_8: 1.841  time: 2.9855  data_time: 0.0517  lr: 4.1333e-05  max_mem: 27646M
[01/30 09:40:38] d2.utils.events INFO:  eta: 18:20:57  iter: 37539  total_loss: 18.05  loss_mask: 1.784  loss_mask_0: 1.885  loss_mask_1: 1.796  loss_mask_2: 1.801  loss_mask_3: 1.801  loss_mask_4: 1.805  loss_mask_5: 1.783  loss_mask_6: 1.789  loss_mask_7: 1.815  loss_mask_8: 1.813  time: 2.9854  data_time: 0.0483  lr: 4.13e-05  max_mem: 27646M
[01/30 09:41:37] d2.utils.events INFO:  eta: 18:19:58  iter: 37559  total_loss: 18.99  loss_mask: 1.884  loss_mask_0: 1.935  loss_mask_1: 1.883  loss_mask_2: 1.903  loss_mask_3: 1.902  loss_mask_4: 1.902  loss_mask_5: 1.881  loss_mask_6: 1.881  loss_mask_7: 1.901  loss_mask_8: 1.901  time: 2.9854  data_time: 0.0505  lr: 4.1267e-05  max_mem: 27646M
[01/30 09:42:36] d2.utils.events INFO:  eta: 18:19:00  iter: 37579  total_loss: 17.71  loss_mask: 1.761  loss_mask_0: 1.82  loss_mask_1: 1.754  loss_mask_2: 1.772  loss_mask_3: 1.774  loss_mask_4: 1.777  loss_mask_5: 1.759  loss_mask_6: 1.756  loss_mask_7: 1.776  loss_mask_8: 1.774  time: 2.9854  data_time: 0.0496  lr: 4.1234e-05  max_mem: 27646M
[01/30 09:43:35] d2.utils.events INFO:  eta: 18:17:57  iter: 37599  total_loss: 20.73  loss_mask: 2.059  loss_mask_0: 2.094  loss_mask_1: 2.061  loss_mask_2: 2.075  loss_mask_3: 2.074  loss_mask_4: 2.073  loss_mask_5: 2.066  loss_mask_6: 2.063  loss_mask_7: 2.07  loss_mask_8: 2.071  time: 2.9853  data_time: 0.0557  lr: 4.1201e-05  max_mem: 27646M
[01/30 09:44:33] d2.utils.events INFO:  eta: 18:16:54  iter: 37619  total_loss: 21.74  loss_mask: 2.177  loss_mask_0: 2.186  loss_mask_1: 2.137  loss_mask_2: 2.169  loss_mask_3: 2.176  loss_mask_4: 2.165  loss_mask_5: 2.159  loss_mask_6: 2.171  loss_mask_7: 2.172  loss_mask_8: 2.168  time: 2.9853  data_time: 0.0526  lr: 4.1168e-05  max_mem: 27646M
[01/30 09:45:32] d2.utils.events INFO:  eta: 18:15:53  iter: 37639  total_loss: 22.2  loss_mask: 2.214  loss_mask_0: 2.291  loss_mask_1: 2.223  loss_mask_2: 2.214  loss_mask_3: 2.206  loss_mask_4: 2.203  loss_mask_5: 2.222  loss_mask_6: 2.214  loss_mask_7: 2.207  loss_mask_8: 2.21  time: 2.9853  data_time: 0.0537  lr: 4.1134e-05  max_mem: 27646M
[01/30 09:46:31] d2.utils.events INFO:  eta: 18:14:47  iter: 37659  total_loss: 20.42  loss_mask: 2.029  loss_mask_0: 2.051  loss_mask_1: 2.029  loss_mask_2: 2.041  loss_mask_3: 2.044  loss_mask_4: 2.05  loss_mask_5: 2.034  loss_mask_6: 2.041  loss_mask_7: 2.042  loss_mask_8: 2.04  time: 2.9853  data_time: 0.0437  lr: 4.1101e-05  max_mem: 27646M
[01/30 09:47:29] d2.utils.events INFO:  eta: 18:13:00  iter: 37679  total_loss: 19.01  loss_mask: 1.878  loss_mask_0: 1.959  loss_mask_1: 1.885  loss_mask_2: 1.906  loss_mask_3: 1.901  loss_mask_4: 1.904  loss_mask_5: 1.885  loss_mask_6: 1.882  loss_mask_7: 1.902  loss_mask_8: 1.912  time: 2.9852  data_time: 0.0472  lr: 4.1068e-05  max_mem: 27646M
[01/30 09:48:28] d2.utils.events INFO:  eta: 18:12:18  iter: 37699  total_loss: 18.93  loss_mask: 1.872  loss_mask_0: 1.916  loss_mask_1: 1.877  loss_mask_2: 1.896  loss_mask_3: 1.893  loss_mask_4: 1.898  loss_mask_5: 1.878  loss_mask_6: 1.873  loss_mask_7: 1.901  loss_mask_8: 1.902  time: 2.9852  data_time: 0.0469  lr: 4.1035e-05  max_mem: 27646M
[01/30 09:49:27] d2.utils.events INFO:  eta: 18:11:25  iter: 37719  total_loss: 19.16  loss_mask: 1.892  loss_mask_0: 2.011  loss_mask_1: 1.919  loss_mask_2: 1.928  loss_mask_3: 1.907  loss_mask_4: 1.903  loss_mask_5: 1.895  loss_mask_6: 1.889  loss_mask_7: 1.91  loss_mask_8: 1.906  time: 2.9852  data_time: 0.0459  lr: 4.1002e-05  max_mem: 27646M
[01/30 09:50:25] d2.utils.events INFO:  eta: 18:10:04  iter: 37739  total_loss: 20.24  loss_mask: 2.015  loss_mask_0: 2.046  loss_mask_1: 2.015  loss_mask_2: 2.028  loss_mask_3: 2.026  loss_mask_4: 2.027  loss_mask_5: 2.016  loss_mask_6: 2.015  loss_mask_7: 2.029  loss_mask_8: 2.028  time: 2.9851  data_time: 0.0553  lr: 4.0969e-05  max_mem: 27646M
[01/30 09:51:24] d2.utils.events INFO:  eta: 18:09:38  iter: 37759  total_loss: 19.64  loss_mask: 1.952  loss_mask_0: 1.993  loss_mask_1: 1.963  loss_mask_2: 1.965  loss_mask_3: 1.965  loss_mask_4: 1.96  loss_mask_5: 1.952  loss_mask_6: 1.953  loss_mask_7: 1.961  loss_mask_8: 1.963  time: 2.9851  data_time: 0.0482  lr: 4.0936e-05  max_mem: 27646M
[01/30 09:52:22] d2.utils.events INFO:  eta: 18:08:02  iter: 37779  total_loss: 18.1  loss_mask: 1.804  loss_mask_0: 1.842  loss_mask_1: 1.8  loss_mask_2: 1.816  loss_mask_3: 1.808  loss_mask_4: 1.811  loss_mask_5: 1.808  loss_mask_6: 1.798  loss_mask_7: 1.817  loss_mask_8: 1.816  time: 2.9851  data_time: 0.0556  lr: 4.0903e-05  max_mem: 27646M
[01/30 09:53:22] d2.utils.events INFO:  eta: 18:07:36  iter: 37799  total_loss: 19.13  loss_mask: 1.891  loss_mask_0: 1.943  loss_mask_1: 1.892  loss_mask_2: 1.917  loss_mask_3: 1.917  loss_mask_4: 1.915  loss_mask_5: 1.902  loss_mask_6: 1.888  loss_mask_7: 1.903  loss_mask_8: 1.909  time: 2.9851  data_time: 0.0442  lr: 4.0869e-05  max_mem: 27646M
[01/30 09:54:21] d2.utils.events INFO:  eta: 18:06:04  iter: 37819  total_loss: 19.12  loss_mask: 1.904  loss_mask_0: 1.939  loss_mask_1: 1.904  loss_mask_2: 1.914  loss_mask_3: 1.913  loss_mask_4: 1.913  loss_mask_5: 1.907  loss_mask_6: 1.899  loss_mask_7: 1.912  loss_mask_8: 1.919  time: 2.9850  data_time: 0.0525  lr: 4.0836e-05  max_mem: 27646M
[01/30 09:55:19] d2.utils.events INFO:  eta: 18:05:08  iter: 37839  total_loss: 19.02  loss_mask: 1.879  loss_mask_0: 1.952  loss_mask_1: 1.888  loss_mask_2: 1.914  loss_mask_3: 1.909  loss_mask_4: 1.908  loss_mask_5: 1.876  loss_mask_6: 1.882  loss_mask_7: 1.907  loss_mask_8: 1.908  time: 2.9850  data_time: 0.0456  lr: 4.0803e-05  max_mem: 27646M
[01/30 09:56:18] d2.utils.events INFO:  eta: 18:03:57  iter: 37859  total_loss: 18.04  loss_mask: 1.792  loss_mask_0: 1.851  loss_mask_1: 1.789  loss_mask_2: 1.804  loss_mask_3: 1.808  loss_mask_4: 1.812  loss_mask_5: 1.795  loss_mask_6: 1.79  loss_mask_7: 1.809  loss_mask_8: 1.804  time: 2.9850  data_time: 0.0543  lr: 4.077e-05  max_mem: 27646M
[01/30 09:57:17] d2.utils.events INFO:  eta: 18:02:59  iter: 37879  total_loss: 19.19  loss_mask: 1.917  loss_mask_0: 1.976  loss_mask_1: 1.905  loss_mask_2: 1.918  loss_mask_3: 1.918  loss_mask_4: 1.923  loss_mask_5: 1.914  loss_mask_6: 1.914  loss_mask_7: 1.918  loss_mask_8: 1.919  time: 2.9850  data_time: 0.0549  lr: 4.0737e-05  max_mem: 27646M
[01/30 09:58:16] d2.utils.events INFO:  eta: 18:01:48  iter: 37899  total_loss: 18.8  loss_mask: 1.856  loss_mask_0: 1.943  loss_mask_1: 1.859  loss_mask_2: 1.886  loss_mask_3: 1.884  loss_mask_4: 1.886  loss_mask_5: 1.859  loss_mask_6: 1.854  loss_mask_7: 1.906  loss_mask_8: 1.885  time: 2.9850  data_time: 0.0574  lr: 4.0704e-05  max_mem: 27646M
[01/30 09:59:15] d2.utils.events INFO:  eta: 18:00:58  iter: 37919  total_loss: 21.35  loss_mask: 2.122  loss_mask_0: 2.151  loss_mask_1: 2.127  loss_mask_2: 2.131  loss_mask_3: 2.146  loss_mask_4: 2.133  loss_mask_5: 2.13  loss_mask_6: 2.124  loss_mask_7: 2.13  loss_mask_8: 2.134  time: 2.9849  data_time: 0.0566  lr: 4.0671e-05  max_mem: 27646M
[01/30 10:00:14] d2.utils.events INFO:  eta: 18:00:09  iter: 37939  total_loss: 18.71  loss_mask: 1.85  loss_mask_0: 1.888  loss_mask_1: 1.853  loss_mask_2: 1.878  loss_mask_3: 1.874  loss_mask_4: 1.884  loss_mask_5: 1.86  loss_mask_6: 1.849  loss_mask_7: 1.873  loss_mask_8: 1.883  time: 2.9849  data_time: 0.0473  lr: 4.0637e-05  max_mem: 27646M
[01/30 10:01:13] d2.utils.events INFO:  eta: 17:59:27  iter: 37959  total_loss: 20.62  loss_mask: 2.06  loss_mask_0: 2.07  loss_mask_1: 2.04  loss_mask_2: 2.056  loss_mask_3: 2.065  loss_mask_4: 2.064  loss_mask_5: 2.059  loss_mask_6: 2.059  loss_mask_7: 2.064  loss_mask_8: 2.055  time: 2.9849  data_time: 0.0610  lr: 4.0604e-05  max_mem: 27646M
[01/30 10:02:12] d2.utils.events INFO:  eta: 17:58:29  iter: 37979  total_loss: 17.57  loss_mask: 1.741  loss_mask_0: 1.789  loss_mask_1: 1.742  loss_mask_2: 1.756  loss_mask_3: 1.77  loss_mask_4: 1.756  loss_mask_5: 1.741  loss_mask_6: 1.741  loss_mask_7: 1.759  loss_mask_8: 1.766  time: 2.9849  data_time: 0.0584  lr: 4.0571e-05  max_mem: 27646M
[01/30 10:03:12] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 10:03:12] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 10:03:12] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 10:17:24] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.2975829665977954, 'error_1pix': 0.34867389079260935, 'error_3pix': 0.14408576240832352, 'mIoU': 7.937771206043319, 'fwIoU': 21.793741345582283, 'IoU-0': 6.09048137128254e-05, 'IoU-1': 79.00139999713957, 'IoU-2': 2.7830625071009365, 'IoU-3': 5.804118310767247, 'IoU-4': 5.972964886545152, 'IoU-5': 5.796120073620493, 'IoU-6': 5.16042049044787, 'IoU-7': 4.274766314982875, 'IoU-8': 9.11057723061627, 'IoU-9': 20.904286026320786, 'IoU-10': 23.224439707015744, 'IoU-11': 29.547965187128323, 'IoU-12': 29.086481515107394, 'IoU-13': 27.542995098407978, 'IoU-14': 28.739690483804004, 'IoU-15': 28.133501788873183, 'IoU-16': 25.712812097183026, 'IoU-17': 22.132358210059227, 'IoU-18': 20.81977153827919, 'IoU-19': 20.41377385219528, 'IoU-20': 18.93984802860687, 'IoU-21': 18.13181313611298, 'IoU-22': 17.52233285803433, 'IoU-23': 16.611432462697177, 'IoU-24': 14.910409558977362, 'IoU-25': 15.573381685526241, 'IoU-26': 15.186672558397449, 'IoU-27': 16.87058149336863, 'IoU-28': 16.920602342172483, 'IoU-29': 17.083589070668996, 'IoU-30': 16.635786092791065, 'IoU-31': 18.366100764286962, 'IoU-32': 18.40427923138982, 'IoU-33': 18.022944603070073, 'IoU-34': 17.557741154105464, 'IoU-35': 18.437801063196886, 'IoU-36': 18.713226647430208, 'IoU-37': 18.67331360769009, 'IoU-38': 18.982938539406, 'IoU-39': 18.66019583576553, 'IoU-40': 19.354364186592342, 'IoU-41': 17.74331710914573, 'IoU-42': 17.33690223728947, 'IoU-43': 16.88137815156436, 'IoU-44': 17.18424320279356, 'IoU-45': 16.746286093442368, 'IoU-46': 15.516355460117595, 'IoU-47': 14.912454343394218, 'IoU-48': 14.477082504359679, 'IoU-49': 14.296628373466081, 'IoU-50': 14.42179658368283, 'IoU-51': 13.0745943193507, 'IoU-52': 12.419127697109914, 'IoU-53': 12.10368561952393, 'IoU-54': 11.62492829938493, 'IoU-55': 11.20130338300985, 'IoU-56': 10.083240964790505, 'IoU-57': 10.101461838930302, 'IoU-58': 9.630574496870187, 'IoU-59': 9.284278723247276, 'IoU-60': 8.820857645997506, 'IoU-61': 8.441046921225738, 'IoU-62': 7.913606560027765, 'IoU-63': 7.335071122704933, 'IoU-64': 6.922738962848183, 'IoU-65': 6.957118048416594, 'IoU-66': 6.310373355777231, 'IoU-67': 6.20332459871064, 'IoU-68': 6.324769792922974, 'IoU-69': 6.305965758218631, 'IoU-70': 5.870402834774676, 'IoU-71': 5.873222671794332, 'IoU-72': 5.892929592046111, 'IoU-73': 5.770800061498062, 'IoU-74': 5.729475385171183, 'IoU-75': 5.5295558403990475, 'IoU-76': 5.708809711919035, 'IoU-77': 5.720678004417629, 'IoU-78': 5.654437273400189, 'IoU-79': 5.575116699538548, 'IoU-80': 5.804281282954004, 'IoU-81': 5.723091331458842, 'IoU-82': 5.60839076960757, 'IoU-83': 5.8151328567226, 'IoU-84': 5.681914918411388, 'IoU-85': 5.515543885580598, 'IoU-86': 5.380575987803677, 'IoU-87': 5.445933215207916, 'IoU-88': 5.510294908713418, 'IoU-89': 5.315835598701373, 'IoU-90': 5.195682312168413, 'IoU-91': 5.085541636053911, 'IoU-92': 4.963515399813968, 'IoU-93': 5.044786327745531, 'IoU-94': 5.298458804939409, 'IoU-95': 5.256511967226122, 'IoU-96': 5.251579039938681, 'IoU-97': 5.028735672489356, 'IoU-98': 5.179439503973446, 'IoU-99': 5.149105965879566, 'IoU-100': 4.845062211737689, 'IoU-101': 4.75614712876392, 'IoU-102': 4.591953229904973, 'IoU-103': 4.484799131166799, 'IoU-104': 4.345915385417514, 'IoU-105': 4.501370330950915, 'IoU-106': 4.774500334137341, 'IoU-107': 4.681356449367247, 'IoU-108': 4.74162946369334, 'IoU-109': 4.937514639197233, 'IoU-110': 5.017171143390408, 'IoU-111': 4.925759798192613, 'IoU-112': 4.809568413624788, 'IoU-113': 4.629007845628114, 'IoU-114': 4.544570597719291, 'IoU-115': 4.546568728382846, 'IoU-116': 4.252383973050004, 'IoU-117': 4.151937798672107, 'IoU-118': 4.075771906025541, 'IoU-119': 4.065974985514677, 'IoU-120': 4.015359145166693, 'IoU-121': 4.009550080122206, 'IoU-122': 4.161534220545931, 'IoU-123': 3.8848438275704633, 'IoU-124': 3.453820661674914, 'IoU-125': 3.2955046492491835, 'IoU-126': 3.2428193747048377, 'IoU-127': 3.2785327436010987, 'IoU-128': 3.19711951998771, 'IoU-129': 3.000377801689644, 'IoU-130': 3.104184447728446, 'IoU-131': 3.1212633884184826, 'IoU-132': 3.139416271129986, 'IoU-133': 3.195838358596931, 'IoU-134': 3.258868355502171, 'IoU-135': 3.403790836822313, 'IoU-136': 3.278230909110244, 'IoU-137': 3.164769942524231, 'IoU-138': 2.8924012062743096, 'IoU-139': 2.746519144231245, 'IoU-140': 2.927216534285427, 'IoU-141': 3.089759572573464, 'IoU-142': 3.135863556824017, 'IoU-143': 3.0346653623849544, 'IoU-144': 3.0257219427371607, 'IoU-145': 2.926957304986647, 'IoU-146': 3.00787275581578, 'IoU-147': 3.157437221858622, 'IoU-148': 3.188882597069714, 'IoU-149': 3.1022015431655747, 'IoU-150': 3.4517288161268547, 'IoU-151': 3.1860891545545895, 'IoU-152': 3.2933312779833774, 'IoU-153': 2.930059689768369, 'IoU-154': 2.795691408937236, 'IoU-155': 2.5878103501242795, 'IoU-156': 2.8054931173196533, 'IoU-157': 2.7103699519318782, 'IoU-158': 2.5541236865302395, 'IoU-159': 2.5271813447788936, 'IoU-160': 2.3905021547983933, 'IoU-161': 2.734852527115559, 'IoU-162': 3.2119529788410444, 'IoU-163': 2.6909723450842074, 'IoU-164': 2.587027472700553, 'IoU-165': 2.6009974162227523, 'IoU-166': 2.569920109974682, 'IoU-167': 2.2024922960050475, 'IoU-168': 2.0670498593429993, 'IoU-169': 2.178973334974684, 'IoU-170': 1.9862606216395209, 'IoU-171': 2.0940999889274834, 'IoU-172': 1.8678822145763478, 'IoU-173': 1.8541600123599993, 'IoU-174': 1.946518208111303, 'IoU-175': 2.3846405977092004, 'IoU-176': 2.4307933398084036, 'IoU-177': 1.8027285165398663, 'IoU-178': 1.4774350833029386, 'IoU-179': 1.6593150009032303, 'IoU-180': 1.316207283018265, 'IoU-181': 1.4897473070565013, 'IoU-182': 1.6214697035836656, 'IoU-183': 1.7274352730335074, 'IoU-184': 1.0489276213434608, 'IoU-185': 2.066906051647181, 'IoU-186': 1.1429645664298793, 'IoU-187': 0.00023254299720018234, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 14.225818190739478, 'pACC': 31.527664655341407, 'ACC-0': 0.0001240710278718585, 'ACC-1': 80.5897256988922, 'ACC-2': 7.0382668003834, 'ACC-3': 23.29850190987427, 'ACC-4': 21.49618431162729, 'ACC-5': 21.127354046363646, 'ACC-6': 19.090192588606797, 'ACC-7': 17.412333956849746, 'ACC-8': 22.140829055472828, 'ACC-9': 38.502526876439724, 'ACC-10': 41.633559051956844, 'ACC-11': 45.330421455776985, 'ACC-12': 44.15617394379648, 'ACC-13': 40.227533839879975, 'ACC-14': 41.8654607885138, 'ACC-15': 41.49208469311626, 'ACC-16': 38.240604658926394, 'ACC-17': 35.909359473508616, 'ACC-18': 33.09560973090927, 'ACC-19': 33.458847285331444, 'ACC-20': 31.36433880620839, 'ACC-21': 30.01633992210043, 'ACC-22': 28.720636156201433, 'ACC-23': 29.282975580263926, 'ACC-24': 26.06478396474192, 'ACC-25': 27.494376018931444, 'ACC-26': 26.650767500929394, 'ACC-27': 29.011420887929134, 'ACC-28': 30.01844630986048, 'ACC-29': 29.10500086751449, 'ACC-30': 29.101961350292083, 'ACC-31': 31.565404294262876, 'ACC-32': 32.48466669673064, 'ACC-33': 31.86010200080479, 'ACC-34': 30.592316692883347, 'ACC-35': 31.96309392590534, 'ACC-36': 32.395366278038665, 'ACC-37': 32.85876184072393, 'ACC-38': 33.36269677360399, 'ACC-39': 33.12575383215751, 'ACC-40': 33.540253595496175, 'ACC-41': 31.35136861116451, 'ACC-42': 30.766312663236402, 'ACC-43': 29.847318831211457, 'ACC-44': 29.724397027974735, 'ACC-45': 29.212506395504224, 'ACC-46': 27.811251417178156, 'ACC-47': 26.874196905424164, 'ACC-48': 26.263641638658296, 'ACC-49': 25.970614583523933, 'ACC-50': 26.293455963860364, 'ACC-51': 24.264774791841884, 'ACC-52': 22.81829641258699, 'ACC-53': 22.254774640349382, 'ACC-54': 21.140729666894316, 'ACC-55': 20.501256357010252, 'ACC-56': 18.625090386488623, 'ACC-57': 18.265029257255613, 'ACC-58': 17.615391158370937, 'ACC-59': 17.323270580355473, 'ACC-60': 16.630908029416492, 'ACC-61': 16.070189631501346, 'ACC-62': 15.052885582636943, 'ACC-63': 14.048880202223216, 'ACC-64': 13.173513131140044, 'ACC-65': 13.254707112712035, 'ACC-66': 12.063226099750985, 'ACC-67': 12.028161497567684, 'ACC-68': 12.260944409344226, 'ACC-69': 11.930614840167486, 'ACC-70': 11.06334078746655, 'ACC-71': 11.18717773292677, 'ACC-72': 11.258048264194212, 'ACC-73': 10.998824787221958, 'ACC-74': 10.828212669168186, 'ACC-75': 10.523107566675657, 'ACC-76': 10.73434300943124, 'ACC-77': 10.917052209454365, 'ACC-78': 10.906594009946819, 'ACC-79': 10.801900573315187, 'ACC-80': 11.16018157669532, 'ACC-81': 10.857823176737945, 'ACC-82': 10.542577850665246, 'ACC-83': 10.672248958523348, 'ACC-84': 10.423983723285879, 'ACC-85': 10.216347656060137, 'ACC-86': 10.05942770814669, 'ACC-87': 10.237569847575925, 'ACC-88': 10.365344024203772, 'ACC-89': 9.822173436347438, 'ACC-90': 9.468278235278179, 'ACC-91': 9.28906507482444, 'ACC-92': 9.09346867263931, 'ACC-93': 9.27319170802328, 'ACC-94': 9.730331516040588, 'ACC-95': 9.666382303592732, 'ACC-96': 9.725907426123701, 'ACC-97': 9.207306017690298, 'ACC-98': 9.41818483141696, 'ACC-99': 9.439840266212695, 'ACC-100': 8.862710609521816, 'ACC-101': 8.664397812132998, 'ACC-102': 8.337811508835523, 'ACC-103': 8.130655520921886, 'ACC-104': 7.98460441209021, 'ACC-105': 8.285704872698632, 'ACC-106': 8.79965239618758, 'ACC-107': 8.603856898554888, 'ACC-108': 8.641158160714586, 'ACC-109': 9.035795334543852, 'ACC-110': 9.307957529412084, 'ACC-111': 9.186585146860695, 'ACC-112': 9.09892902353559, 'ACC-113': 8.83020281200747, 'ACC-114': 8.789003778065355, 'ACC-115': 8.714612181077383, 'ACC-116': 8.20181389140862, 'ACC-117': 7.961974625641009, 'ACC-118': 7.915952365057352, 'ACC-119': 7.816388931421633, 'ACC-120': 7.730113466654016, 'ACC-121': 7.782744306823999, 'ACC-122': 7.951494051157218, 'ACC-123': 7.498287836832331, 'ACC-124': 6.759199425070895, 'ACC-125': 6.381918785071838, 'ACC-126': 6.273338099618393, 'ACC-127': 6.287088001943762, 'ACC-128': 6.142767758153218, 'ACC-129': 5.7760020181242115, 'ACC-130': 5.983662803146194, 'ACC-131': 6.054443604860196, 'ACC-132': 6.064280041419107, 'ACC-133': 6.164445079507645, 'ACC-134': 6.1607927617406295, 'ACC-135': 6.4643549398551965, 'ACC-136': 6.283559098956393, 'ACC-137': 6.101279406388407, 'ACC-138': 5.5605439500469585, 'ACC-139': 5.327554021182977, 'ACC-140': 5.564141682693183, 'ACC-141': 5.840047530964976, 'ACC-142': 5.967455008947121, 'ACC-143': 5.798339942472187, 'ACC-144': 5.699097472924188, 'ACC-145': 5.476061629285091, 'ACC-146': 5.634506865276096, 'ACC-147': 5.814390756400055, 'ACC-148': 5.855989871213468, 'ACC-149': 5.808214232472576, 'ACC-150': 6.460018615626913, 'ACC-151': 5.900032293028863, 'ACC-152': 5.9879501314990895, 'ACC-153': 5.535782993459023, 'ACC-154': 5.353853090468458, 'ACC-155': 5.139364447829848, 'ACC-156': 5.790946757418863, 'ACC-157': 5.642185664724464, 'ACC-158': 5.242530177785368, 'ACC-159': 5.135289931298857, 'ACC-160': 4.888193910328915, 'ACC-161': 5.56340342117014, 'ACC-162': 6.758087598668258, 'ACC-163': 5.812735891599545, 'ACC-164': 5.989681600969055, 'ACC-165': 5.493334434467183, 'ACC-166': 5.611637609018643, 'ACC-167': 4.814762701353387, 'ACC-168': 4.512623953864548, 'ACC-169': 4.783178596683939, 'ACC-170': 4.396304499055894, 'ACC-171': 4.689856339627008, 'ACC-172': 4.2621402378042, 'ACC-173': 4.357805932576491, 'ACC-174': 4.6253268988090905, 'ACC-175': 5.891521024110753, 'ACC-176': 6.341965114929185, 'ACC-177': 4.311189604867597, 'ACC-178': 4.060759767515081, 'ACC-179': 4.994511859860697, 'ACC-180': 4.009406007653493, 'ACC-181': 5.761273008496356, 'ACC-182': 6.424237542319274, 'ACC-183': 4.901695346214606, 'ACC-184': 3.3597709525797312, 'ACC-185': 4.966765055037438, 'ACC-186': 2.4255629548668245, 'ACC-187': 0.00024160717090083232, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 10:17:24] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 10:17:24] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 10:17:24] d2.evaluation.testing INFO: copypaste: 2.2976,0.3487,0.1441,7.9378,21.7937,14.2258,31.5277
[01/30 10:17:24] d2.utils.events INFO:  eta: 17:57:55  iter: 37999  total_loss: 19.63  loss_mask: 1.955  loss_mask_0: 1.991  loss_mask_1: 1.948  loss_mask_2: 1.957  loss_mask_3: 1.968  loss_mask_4: 1.964  loss_mask_5: 1.959  loss_mask_6: 1.96  loss_mask_7: 1.968  loss_mask_8: 1.963  time: 2.9849  data_time: 0.0539  lr: 4.0538e-05  max_mem: 27646M
[01/30 10:18:23] d2.utils.events INFO:  eta: 17:56:57  iter: 38019  total_loss: 17.6  loss_mask: 1.753  loss_mask_0: 1.792  loss_mask_1: 1.757  loss_mask_2: 1.768  loss_mask_3: 1.763  loss_mask_4: 1.763  loss_mask_5: 1.759  loss_mask_6: 1.755  loss_mask_7: 1.76  loss_mask_8: 1.764  time: 2.9848  data_time: 0.0513  lr: 4.0505e-05  max_mem: 27646M
[01/30 10:19:22] d2.utils.events INFO:  eta: 17:55:58  iter: 38039  total_loss: 19.36  loss_mask: 1.925  loss_mask_0: 1.969  loss_mask_1: 1.925  loss_mask_2: 1.934  loss_mask_3: 1.938  loss_mask_4: 1.936  loss_mask_5: 1.929  loss_mask_6: 1.926  loss_mask_7: 1.933  loss_mask_8: 1.936  time: 2.9848  data_time: 0.0489  lr: 4.0472e-05  max_mem: 27646M
[01/30 10:20:21] d2.utils.events INFO:  eta: 17:54:59  iter: 38059  total_loss: 19.5  loss_mask: 1.952  loss_mask_0: 2.007  loss_mask_1: 1.936  loss_mask_2: 1.95  loss_mask_3: 1.956  loss_mask_4: 1.959  loss_mask_5: 1.953  loss_mask_6: 1.948  loss_mask_7: 1.956  loss_mask_8: 1.948  time: 2.9848  data_time: 0.0503  lr: 4.0438e-05  max_mem: 27646M
[01/30 10:21:20] d2.utils.events INFO:  eta: 17:53:29  iter: 38079  total_loss: 19.39  loss_mask: 1.936  loss_mask_0: 1.992  loss_mask_1: 1.929  loss_mask_2: 1.943  loss_mask_3: 1.941  loss_mask_4: 1.945  loss_mask_5: 1.93  loss_mask_6: 1.932  loss_mask_7: 1.946  loss_mask_8: 1.945  time: 2.9848  data_time: 0.0515  lr: 4.0405e-05  max_mem: 27646M
[01/30 10:22:19] d2.utils.events INFO:  eta: 17:52:52  iter: 38099  total_loss: 20.11  loss_mask: 1.997  loss_mask_0: 2.065  loss_mask_1: 1.994  loss_mask_2: 2.009  loss_mask_3: 2.017  loss_mask_4: 2.019  loss_mask_5: 2.002  loss_mask_6: 1.988  loss_mask_7: 2.016  loss_mask_8: 2.015  time: 2.9848  data_time: 0.0487  lr: 4.0372e-05  max_mem: 27646M
[01/30 10:23:18] d2.utils.events INFO:  eta: 17:52:04  iter: 38119  total_loss: 20.82  loss_mask: 2.076  loss_mask_0: 2.083  loss_mask_1: 2.076  loss_mask_2: 2.093  loss_mask_3: 2.083  loss_mask_4: 2.089  loss_mask_5: 2.072  loss_mask_6: 2.075  loss_mask_7: 2.087  loss_mask_8: 2.087  time: 2.9847  data_time: 0.0503  lr: 4.0339e-05  max_mem: 27646M
[01/30 10:24:16] d2.utils.events INFO:  eta: 17:50:58  iter: 38139  total_loss: 19.25  loss_mask: 1.928  loss_mask_0: 1.97  loss_mask_1: 1.934  loss_mask_2: 2.027  loss_mask_3: 1.943  loss_mask_4: 1.916  loss_mask_5: 1.918  loss_mask_6: 2.06  loss_mask_7: 1.935  loss_mask_8: 1.997  time: 2.9847  data_time: 0.0520  lr: 4.0306e-05  max_mem: 27646M
[01/30 10:25:15] d2.utils.events INFO:  eta: 17:49:52  iter: 38159  total_loss: 20.18  loss_mask: 2.007  loss_mask_0: 2.028  loss_mask_1: 2.006  loss_mask_2: 2.03  loss_mask_3: 2  loss_mask_4: 2.008  loss_mask_5: 2.025  loss_mask_6: 2.001  loss_mask_7: 2.016  loss_mask_8: 2.039  time: 2.9847  data_time: 0.0469  lr: 4.0273e-05  max_mem: 27646M
[01/30 10:26:15] d2.utils.events INFO:  eta: 17:48:52  iter: 38179  total_loss: 20.65  loss_mask: 2.063  loss_mask_0: 2.069  loss_mask_1: 2.061  loss_mask_2: 2.063  loss_mask_3: 2.06  loss_mask_4: 2.061  loss_mask_5: 2.064  loss_mask_6: 2.077  loss_mask_7: 2.061  loss_mask_8: 2.065  time: 2.9847  data_time: 0.0495  lr: 4.0239e-05  max_mem: 27646M
[01/30 10:27:13] d2.utils.events INFO:  eta: 17:47:49  iter: 38199  total_loss: 17.91  loss_mask: 1.764  loss_mask_0: 1.859  loss_mask_1: 1.755  loss_mask_2: 1.798  loss_mask_3: 1.797  loss_mask_4: 1.785  loss_mask_5: 1.809  loss_mask_6: 1.802  loss_mask_7: 1.8  loss_mask_8: 1.8  time: 2.9846  data_time: 0.0498  lr: 4.0206e-05  max_mem: 27646M
[01/30 10:28:12] d2.utils.events INFO:  eta: 17:46:45  iter: 38219  total_loss: 20.91  loss_mask: 2.084  loss_mask_0: 2.116  loss_mask_1: 2.076  loss_mask_2: 2.098  loss_mask_3: 2.092  loss_mask_4: 2.097  loss_mask_5: 2.088  loss_mask_6: 2.073  loss_mask_7: 2.094  loss_mask_8: 2.091  time: 2.9846  data_time: 0.0491  lr: 4.0173e-05  max_mem: 27646M
[01/30 10:29:10] d2.utils.events INFO:  eta: 17:45:29  iter: 38239  total_loss: 17.8  loss_mask: 1.776  loss_mask_0: 1.791  loss_mask_1: 1.775  loss_mask_2: 1.772  loss_mask_3: 1.776  loss_mask_4: 1.778  loss_mask_5: 1.772  loss_mask_6: 1.782  loss_mask_7: 1.778  loss_mask_8: 1.774  time: 2.9846  data_time: 0.0498  lr: 4.014e-05  max_mem: 27646M
[01/30 10:30:09] d2.utils.events INFO:  eta: 17:44:36  iter: 38259  total_loss: 19.72  loss_mask: 1.946  loss_mask_0: 2.028  loss_mask_1: 1.948  loss_mask_2: 1.976  loss_mask_3: 1.978  loss_mask_4: 1.977  loss_mask_5: 1.943  loss_mask_6: 1.954  loss_mask_7: 1.981  loss_mask_8: 1.975  time: 2.9846  data_time: 0.0541  lr: 4.0107e-05  max_mem: 27646M
[01/30 10:31:08] d2.utils.events INFO:  eta: 17:43:14  iter: 38279  total_loss: 17.71  loss_mask: 1.771  loss_mask_0: 1.798  loss_mask_1: 1.775  loss_mask_2: 1.767  loss_mask_3: 1.764  loss_mask_4: 1.772  loss_mask_5: 1.777  loss_mask_6: 1.775  loss_mask_7: 1.769  loss_mask_8: 1.769  time: 2.9845  data_time: 0.0588  lr: 4.0073e-05  max_mem: 27646M
[01/30 10:32:06] d2.utils.events INFO:  eta: 17:41:53  iter: 38299  total_loss: 18.28  loss_mask: 1.807  loss_mask_0: 1.872  loss_mask_1: 1.798  loss_mask_2: 1.825  loss_mask_3: 1.844  loss_mask_4: 1.875  loss_mask_5: 1.799  loss_mask_6: 1.806  loss_mask_7: 1.879  loss_mask_8: 1.819  time: 2.9845  data_time: 0.0543  lr: 4.004e-05  max_mem: 27646M
[01/30 10:33:05] d2.utils.events INFO:  eta: 17:40:20  iter: 38319  total_loss: 19.85  loss_mask: 1.974  loss_mask_0: 2.017  loss_mask_1: 1.971  loss_mask_2: 1.981  loss_mask_3: 1.985  loss_mask_4: 1.991  loss_mask_5: 1.977  loss_mask_6: 1.973  loss_mask_7: 2  loss_mask_8: 1.976  time: 2.9845  data_time: 0.0531  lr: 4.0007e-05  max_mem: 27646M
[01/30 10:34:04] d2.utils.events INFO:  eta: 17:38:52  iter: 38339  total_loss: 20.73  loss_mask: 2.068  loss_mask_0: 2.1  loss_mask_1: 2.064  loss_mask_2: 2.076  loss_mask_3: 2.072  loss_mask_4: 2.076  loss_mask_5: 2.062  loss_mask_6: 2.058  loss_mask_7: 2.076  loss_mask_8: 2.07  time: 2.9844  data_time: 0.0472  lr: 3.9974e-05  max_mem: 27646M
[01/30 10:35:03] d2.utils.events INFO:  eta: 17:38:10  iter: 38359  total_loss: 19.34  loss_mask: 1.924  loss_mask_0: 1.97  loss_mask_1: 1.922  loss_mask_2: 1.929  loss_mask_3: 1.937  loss_mask_4: 1.938  loss_mask_5: 1.924  loss_mask_6: 1.927  loss_mask_7: 1.938  loss_mask_8: 1.931  time: 2.9844  data_time: 0.0601  lr: 3.994e-05  max_mem: 27646M
[01/30 10:36:02] d2.utils.events INFO:  eta: 17:37:12  iter: 38379  total_loss: 18.25  loss_mask: 1.813  loss_mask_0: 1.883  loss_mask_1: 1.816  loss_mask_2: 1.824  loss_mask_3: 1.83  loss_mask_4: 1.839  loss_mask_5: 1.805  loss_mask_6: 1.816  loss_mask_7: 1.825  loss_mask_8: 1.823  time: 2.9844  data_time: 0.0536  lr: 3.9907e-05  max_mem: 27646M
[01/30 10:37:00] d2.utils.events INFO:  eta: 17:36:31  iter: 38399  total_loss: 18.53  loss_mask: 1.836  loss_mask_0: 1.868  loss_mask_1: 1.842  loss_mask_2: 1.863  loss_mask_3: 1.857  loss_mask_4: 1.859  loss_mask_5: 1.843  loss_mask_6: 1.844  loss_mask_7: 1.86  loss_mask_8: 1.858  time: 2.9844  data_time: 0.0477  lr: 3.9874e-05  max_mem: 27646M
[01/30 10:37:59] d2.utils.events INFO:  eta: 17:35:32  iter: 38419  total_loss: 20.33  loss_mask: 2.017  loss_mask_0: 2.073  loss_mask_1: 2.017  loss_mask_2: 2.031  loss_mask_3: 2.034  loss_mask_4: 2.018  loss_mask_5: 2.022  loss_mask_6: 2.03  loss_mask_7: 2.033  loss_mask_8: 2.033  time: 2.9844  data_time: 0.0478  lr: 3.9841e-05  max_mem: 27646M
[01/30 10:38:58] d2.utils.events INFO:  eta: 17:34:35  iter: 38439  total_loss: 20.94  loss_mask: 2.089  loss_mask_0: 2.183  loss_mask_1: 2.088  loss_mask_2: 2.09  loss_mask_3: 2.088  loss_mask_4: 2.084  loss_mask_5: 2.086  loss_mask_6: 2.082  loss_mask_7: 2.088  loss_mask_8: 2.085  time: 2.9843  data_time: 0.0560  lr: 3.9808e-05  max_mem: 27646M
[01/30 10:39:57] d2.utils.events INFO:  eta: 17:33:38  iter: 38459  total_loss: 19.14  loss_mask: 1.905  loss_mask_0: 1.972  loss_mask_1: 1.905  loss_mask_2: 1.919  loss_mask_3: 1.92  loss_mask_4: 1.915  loss_mask_5: 1.899  loss_mask_6: 1.899  loss_mask_7: 1.916  loss_mask_8: 1.922  time: 2.9843  data_time: 0.0540  lr: 3.9774e-05  max_mem: 27646M
[01/30 10:40:57] d2.utils.events INFO:  eta: 17:32:42  iter: 38479  total_loss: 18.85  loss_mask: 1.865  loss_mask_0: 1.906  loss_mask_1: 1.874  loss_mask_2: 1.884  loss_mask_3: 1.887  loss_mask_4: 1.883  loss_mask_5: 1.865  loss_mask_6: 1.867  loss_mask_7: 1.887  loss_mask_8: 1.887  time: 2.9843  data_time: 0.0462  lr: 3.9741e-05  max_mem: 27646M
[01/30 10:41:55] d2.utils.events INFO:  eta: 17:31:38  iter: 38499  total_loss: 20.07  loss_mask: 2.008  loss_mask_0: 2.019  loss_mask_1: 1.995  loss_mask_2: 2.004  loss_mask_3: 2.004  loss_mask_4: 2.012  loss_mask_5: 2.01  loss_mask_6: 2.006  loss_mask_7: 2.008  loss_mask_8: 2.002  time: 2.9843  data_time: 0.0490  lr: 3.9708e-05  max_mem: 27646M
[01/30 10:42:54] d2.utils.events INFO:  eta: 17:30:39  iter: 38519  total_loss: 18.33  loss_mask: 1.828  loss_mask_0: 1.865  loss_mask_1: 1.819  loss_mask_2: 1.832  loss_mask_3: 1.834  loss_mask_4: 1.836  loss_mask_5: 1.83  loss_mask_6: 1.825  loss_mask_7: 1.833  loss_mask_8: 1.832  time: 2.9843  data_time: 0.0484  lr: 3.9675e-05  max_mem: 27646M
[01/30 10:43:52] d2.utils.events INFO:  eta: 17:29:44  iter: 38539  total_loss: 19.25  loss_mask: 1.915  loss_mask_0: 1.965  loss_mask_1: 1.925  loss_mask_2: 1.924  loss_mask_3: 1.926  loss_mask_4: 1.927  loss_mask_5: 1.909  loss_mask_6: 1.908  loss_mask_7: 1.923  loss_mask_8: 1.924  time: 2.9842  data_time: 0.0489  lr: 3.9641e-05  max_mem: 27646M
[01/30 10:44:51] d2.utils.events INFO:  eta: 17:28:53  iter: 38559  total_loss: 18.53  loss_mask: 1.845  loss_mask_0: 1.901  loss_mask_1: 1.843  loss_mask_2: 1.853  loss_mask_3: 1.856  loss_mask_4: 1.854  loss_mask_5: 1.842  loss_mask_6: 1.844  loss_mask_7: 1.853  loss_mask_8: 1.851  time: 2.9842  data_time: 0.0491  lr: 3.9608e-05  max_mem: 27646M
[01/30 10:45:50] d2.utils.events INFO:  eta: 17:27:57  iter: 38579  total_loss: 18.64  loss_mask: 1.85  loss_mask_0: 1.937  loss_mask_1: 1.84  loss_mask_2: 1.862  loss_mask_3: 1.868  loss_mask_4: 1.861  loss_mask_5: 1.844  loss_mask_6: 1.847  loss_mask_7: 1.865  loss_mask_8: 1.866  time: 2.9842  data_time: 0.0571  lr: 3.9575e-05  max_mem: 27646M
[01/30 10:46:49] d2.utils.events INFO:  eta: 17:26:48  iter: 38599  total_loss: 19.54  loss_mask: 1.95  loss_mask_0: 1.989  loss_mask_1: 1.945  loss_mask_2: 1.957  loss_mask_3: 1.954  loss_mask_4: 1.948  loss_mask_5: 1.95  loss_mask_6: 1.945  loss_mask_7: 1.948  loss_mask_8: 1.951  time: 2.9842  data_time: 0.0459  lr: 3.9542e-05  max_mem: 27646M
[01/30 10:47:48] d2.utils.events INFO:  eta: 17:25:55  iter: 38619  total_loss: 22.26  loss_mask: 2.209  loss_mask_0: 2.261  loss_mask_1: 2.218  loss_mask_2: 2.228  loss_mask_3: 2.223  loss_mask_4: 2.229  loss_mask_5: 2.215  loss_mask_6: 2.218  loss_mask_7: 2.23  loss_mask_8: 2.229  time: 2.9841  data_time: 0.0528  lr: 3.9508e-05  max_mem: 27646M
[01/30 10:48:47] d2.utils.events INFO:  eta: 17:24:58  iter: 38639  total_loss: 18.96  loss_mask: 1.881  loss_mask_0: 1.945  loss_mask_1: 1.877  loss_mask_2: 1.896  loss_mask_3: 1.897  loss_mask_4: 1.896  loss_mask_5: 1.885  loss_mask_6: 1.876  loss_mask_7: 1.905  loss_mask_8: 1.902  time: 2.9841  data_time: 0.0513  lr: 3.9475e-05  max_mem: 27646M
[01/30 10:49:45] d2.utils.events INFO:  eta: 17:24:00  iter: 38659  total_loss: 19.51  loss_mask: 1.942  loss_mask_0: 2.009  loss_mask_1: 1.94  loss_mask_2: 1.95  loss_mask_3: 1.95  loss_mask_4: 1.954  loss_mask_5: 1.952  loss_mask_6: 1.945  loss_mask_7: 1.951  loss_mask_8: 1.946  time: 2.9841  data_time: 0.0476  lr: 3.9442e-05  max_mem: 27646M
[01/30 10:50:44] d2.utils.events INFO:  eta: 17:23:22  iter: 38679  total_loss: 20.36  loss_mask: 2.029  loss_mask_0: 2.042  loss_mask_1: 2.028  loss_mask_2: 2.033  loss_mask_3: 2.028  loss_mask_4: 2.036  loss_mask_5: 2.03  loss_mask_6: 2.03  loss_mask_7: 2.035  loss_mask_8: 2.036  time: 2.9841  data_time: 0.0469  lr: 3.9409e-05  max_mem: 27646M
[01/30 10:51:43] d2.utils.events INFO:  eta: 17:22:19  iter: 38699  total_loss: 19.78  loss_mask: 1.975  loss_mask_0: 2.025  loss_mask_1: 1.968  loss_mask_2: 1.968  loss_mask_3: 1.967  loss_mask_4: 1.975  loss_mask_5: 1.982  loss_mask_6: 1.971  loss_mask_7: 1.964  loss_mask_8: 1.974  time: 2.9841  data_time: 0.0504  lr: 3.9375e-05  max_mem: 27646M
[01/30 10:52:42] d2.utils.events INFO:  eta: 17:21:13  iter: 38719  total_loss: 19.77  loss_mask: 1.948  loss_mask_0: 2.073  loss_mask_1: 1.956  loss_mask_2: 1.978  loss_mask_3: 1.976  loss_mask_4: 1.977  loss_mask_5: 1.953  loss_mask_6: 1.945  loss_mask_7: 1.978  loss_mask_8: 1.975  time: 2.9840  data_time: 0.0509  lr: 3.9342e-05  max_mem: 27646M
[01/30 10:53:41] d2.utils.events INFO:  eta: 17:20:33  iter: 38739  total_loss: 20.12  loss_mask: 1.997  loss_mask_0: 2.048  loss_mask_1: 1.991  loss_mask_2: 2.014  loss_mask_3: 2.013  loss_mask_4: 2.016  loss_mask_5: 2.002  loss_mask_6: 1.996  loss_mask_7: 2.012  loss_mask_8: 2.01  time: 2.9840  data_time: 0.0527  lr: 3.9309e-05  max_mem: 27646M
[01/30 10:54:40] d2.utils.events INFO:  eta: 17:19:39  iter: 38759  total_loss: 18.73  loss_mask: 1.857  loss_mask_0: 1.931  loss_mask_1: 1.87  loss_mask_2: 1.875  loss_mask_3: 1.864  loss_mask_4: 1.87  loss_mask_5: 1.86  loss_mask_6: 1.858  loss_mask_7: 1.871  loss_mask_8: 1.871  time: 2.9840  data_time: 0.0548  lr: 3.9275e-05  max_mem: 27646M
[01/30 10:55:39] d2.utils.events INFO:  eta: 17:18:49  iter: 38779  total_loss: 19.38  loss_mask: 1.922  loss_mask_0: 1.975  loss_mask_1: 1.924  loss_mask_2: 1.945  loss_mask_3: 1.932  loss_mask_4: 1.936  loss_mask_5: 1.923  loss_mask_6: 1.92  loss_mask_7: 1.943  loss_mask_8: 1.942  time: 2.9840  data_time: 0.0487  lr: 3.9242e-05  max_mem: 27646M
[01/30 10:56:38] d2.utils.events INFO:  eta: 17:17:46  iter: 38799  total_loss: 19.58  loss_mask: 1.975  loss_mask_0: 2.018  loss_mask_1: 1.915  loss_mask_2: 1.944  loss_mask_3: 1.962  loss_mask_4: 1.969  loss_mask_5: 1.966  loss_mask_6: 1.95  loss_mask_7: 1.946  loss_mask_8: 1.948  time: 2.9839  data_time: 0.0549  lr: 3.9209e-05  max_mem: 27646M
[01/30 10:57:36] d2.utils.events INFO:  eta: 17:16:44  iter: 38819  total_loss: 18.91  loss_mask: 1.889  loss_mask_0: 1.875  loss_mask_1: 1.89  loss_mask_2: 1.895  loss_mask_3: 1.901  loss_mask_4: 1.892  loss_mask_5: 1.882  loss_mask_6: 1.886  loss_mask_7: 1.902  loss_mask_8: 1.898  time: 2.9839  data_time: 0.0535  lr: 3.9176e-05  max_mem: 27646M
[01/30 10:58:35] d2.utils.events INFO:  eta: 17:15:46  iter: 38839  total_loss: 19.51  loss_mask: 1.94  loss_mask_0: 2.003  loss_mask_1: 1.93  loss_mask_2: 1.954  loss_mask_3: 1.947  loss_mask_4: 1.956  loss_mask_5: 1.944  loss_mask_6: 1.932  loss_mask_7: 1.955  loss_mask_8: 1.954  time: 2.9839  data_time: 0.0488  lr: 3.9142e-05  max_mem: 27646M
[01/30 10:59:34] d2.utils.events INFO:  eta: 17:14:45  iter: 38859  total_loss: 18.59  loss_mask: 1.868  loss_mask_0: 1.91  loss_mask_1: 1.846  loss_mask_2: 1.835  loss_mask_3: 1.862  loss_mask_4: 1.854  loss_mask_5: 1.857  loss_mask_6: 1.849  loss_mask_7: 1.878  loss_mask_8: 1.839  time: 2.9839  data_time: 0.0514  lr: 3.9109e-05  max_mem: 27646M
[01/30 11:00:32] d2.utils.events INFO:  eta: 17:13:46  iter: 38879  total_loss: 19.77  loss_mask: 1.947  loss_mask_0: 2.007  loss_mask_1: 1.945  loss_mask_2: 1.983  loss_mask_3: 1.981  loss_mask_4: 1.986  loss_mask_5: 1.942  loss_mask_6: 1.959  loss_mask_7: 1.985  loss_mask_8: 1.985  time: 2.9838  data_time: 0.0538  lr: 3.9076e-05  max_mem: 27646M
[01/30 11:01:31] d2.utils.events INFO:  eta: 17:12:46  iter: 38899  total_loss: 19.27  loss_mask: 1.909  loss_mask_0: 1.979  loss_mask_1: 1.912  loss_mask_2: 1.922  loss_mask_3: 1.926  loss_mask_4: 1.93  loss_mask_5: 1.91  loss_mask_6: 1.914  loss_mask_7: 1.944  loss_mask_8: 1.925  time: 2.9838  data_time: 0.0551  lr: 3.9042e-05  max_mem: 27646M
[01/30 11:02:29] d2.utils.events INFO:  eta: 17:11:24  iter: 38919  total_loss: 18.87  loss_mask: 1.869  loss_mask_0: 1.928  loss_mask_1: 1.866  loss_mask_2: 1.884  loss_mask_3: 1.888  loss_mask_4: 1.888  loss_mask_5: 1.878  loss_mask_6: 1.874  loss_mask_7: 1.898  loss_mask_8: 1.885  time: 2.9838  data_time: 0.0494  lr: 3.9009e-05  max_mem: 27646M
[01/30 11:03:28] d2.utils.events INFO:  eta: 17:10:34  iter: 38939  total_loss: 19.38  loss_mask: 1.929  loss_mask_0: 1.959  loss_mask_1: 1.936  loss_mask_2: 1.935  loss_mask_3: 1.937  loss_mask_4: 1.939  loss_mask_5: 1.936  loss_mask_6: 1.935  loss_mask_7: 1.943  loss_mask_8: 1.933  time: 2.9837  data_time: 0.0550  lr: 3.8976e-05  max_mem: 27646M
[01/30 11:04:27] d2.utils.events INFO:  eta: 17:09:31  iter: 38959  total_loss: 18.56  loss_mask: 1.841  loss_mask_0: 1.901  loss_mask_1: 1.839  loss_mask_2: 1.862  loss_mask_3: 1.856  loss_mask_4: 1.859  loss_mask_5: 1.844  loss_mask_6: 1.837  loss_mask_7: 1.86  loss_mask_8: 1.861  time: 2.9837  data_time: 0.0554  lr: 3.8942e-05  max_mem: 27646M
[01/30 11:05:25] d2.utils.events INFO:  eta: 17:08:20  iter: 38979  total_loss: 18.46  loss_mask: 1.813  loss_mask_0: 1.946  loss_mask_1: 1.812  loss_mask_2: 1.86  loss_mask_3: 1.859  loss_mask_4: 1.859  loss_mask_5: 1.815  loss_mask_6: 1.809  loss_mask_7: 1.865  loss_mask_8: 1.866  time: 2.9837  data_time: 0.0525  lr: 3.8909e-05  max_mem: 27646M
[01/30 11:06:24] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/30 11:06:25] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/30 11:06:25] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/30 11:20:36] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.382170780024109, 'error_1pix': 0.3526845594488522, 'error_3pix': 0.15878645948035858, 'mIoU': 7.638497918522051, 'fwIoU': 22.03810072802586, 'IoU-0': 0.00014786808827588376, 'IoU-1': 75.9417370566899, 'IoU-2': 2.3978813229496345, 'IoU-3': 5.3691451141077415, 'IoU-4': 5.729448798329095, 'IoU-5': 5.45225780591893, 'IoU-6': 4.867184355638397, 'IoU-7': 3.920567576324953, 'IoU-8': 9.163194295287598, 'IoU-9': 18.3508520746394, 'IoU-10': 20.55949056566193, 'IoU-11': 26.528723805727555, 'IoU-12': 26.48650227183758, 'IoU-13': 25.995766217940634, 'IoU-14': 27.44983465803326, 'IoU-15': 27.630980878772593, 'IoU-16': 27.45748408817047, 'IoU-17': 24.962817874775432, 'IoU-18': 24.302341988618064, 'IoU-19': 24.638932439964577, 'IoU-20': 23.180674921134468, 'IoU-21': 23.049530384327586, 'IoU-22': 23.9619808068991, 'IoU-23': 22.64075174612352, 'IoU-24': 22.247264336520757, 'IoU-25': 22.315412669831012, 'IoU-26': 21.77728212722116, 'IoU-27': 23.146088994515186, 'IoU-28': 21.584591802992414, 'IoU-29': 22.353648895455986, 'IoU-30': 21.430556058884285, 'IoU-31': 22.576963510184022, 'IoU-32': 20.869338157606858, 'IoU-33': 19.466256991068178, 'IoU-34': 19.09580122665379, 'IoU-35': 19.34508897882525, 'IoU-36': 18.768597668487004, 'IoU-37': 18.408926571317856, 'IoU-38': 17.958275653936173, 'IoU-39': 16.506944969107323, 'IoU-40': 16.4586482182364, 'IoU-41': 15.374227886193022, 'IoU-42': 14.65358950145707, 'IoU-43': 14.723191259285914, 'IoU-44': 14.421608982768072, 'IoU-45': 14.322908330516748, 'IoU-46': 13.719480276826534, 'IoU-47': 13.276976141113977, 'IoU-48': 13.050100197412945, 'IoU-49': 12.709230557717532, 'IoU-50': 12.876527984934713, 'IoU-51': 11.923514646752631, 'IoU-52': 11.59316541761919, 'IoU-53': 11.498090660294407, 'IoU-54': 11.54896695420939, 'IoU-55': 11.318226896142944, 'IoU-56': 10.16603808349136, 'IoU-57': 10.14015619275904, 'IoU-58': 9.76221147522276, 'IoU-59': 9.480668301394493, 'IoU-60': 8.833424050231665, 'IoU-61': 8.338843504655793, 'IoU-62': 8.012066787830909, 'IoU-63': 7.787576656114867, 'IoU-64': 6.93391309257929, 'IoU-65': 6.645552221753192, 'IoU-66': 6.269816173548675, 'IoU-67': 6.266242291509363, 'IoU-68': 6.185024863869983, 'IoU-69': 5.9956386258234895, 'IoU-70': 5.6186888674309845, 'IoU-71': 5.34622848561337, 'IoU-72': 5.103046436240233, 'IoU-73': 5.150698867038719, 'IoU-74': 4.903635543350596, 'IoU-75': 4.3703597451822045, 'IoU-76': 4.4676300122225285, 'IoU-77': 4.559397505915967, 'IoU-78': 4.5012489256229165, 'IoU-79': 4.311150852249538, 'IoU-80': 4.326953474323929, 'IoU-81': 4.167120079930131, 'IoU-82': 3.9457919011591507, 'IoU-83': 4.091052712341739, 'IoU-84': 4.120850137135958, 'IoU-85': 4.112426771927161, 'IoU-86': 3.930372289590542, 'IoU-87': 3.7598310094976037, 'IoU-88': 3.5402063460948527, 'IoU-89': 3.5456558107682334, 'IoU-90': 3.4958308628768404, 'IoU-91': 3.442950154837428, 'IoU-92': 3.2217511441673197, 'IoU-93': 3.2042014041202425, 'IoU-94': 3.5222794172484075, 'IoU-95': 3.4100141279258587, 'IoU-96': 3.2618338546790158, 'IoU-97': 3.2956525011650974, 'IoU-98': 3.386965957254595, 'IoU-99': 3.08390773185208, 'IoU-100': 2.9581874701180557, 'IoU-101': 3.081040179976482, 'IoU-102': 3.127705861843254, 'IoU-103': 2.988060912299383, 'IoU-104': 2.9846970399767954, 'IoU-105': 3.1920811152104087, 'IoU-106': 3.152575916612467, 'IoU-107': 3.3784517779811707, 'IoU-108': 3.3955347403909966, 'IoU-109': 3.4711723970116584, 'IoU-110': 3.5667035454330156, 'IoU-111': 3.5470159220217283, 'IoU-112': 3.559992785977016, 'IoU-113': 3.4329525520584507, 'IoU-114': 3.5064529322545384, 'IoU-115': 3.2171090550340438, 'IoU-116': 3.353858567755572, 'IoU-117': 3.3573369962422377, 'IoU-118': 3.296304422315772, 'IoU-119': 3.2779525941232035, 'IoU-120': 3.307313501685712, 'IoU-121': 3.2037610431746244, 'IoU-122': 3.2927803792410697, 'IoU-123': 3.1462988850169555, 'IoU-124': 3.1338655279476573, 'IoU-125': 2.71847798179104, 'IoU-126': 2.7911472584192407, 'IoU-127': 2.610609787472439, 'IoU-128': 2.8889775999653797, 'IoU-129': 2.7700640378240906, 'IoU-130': 2.7190962999618216, 'IoU-131': 2.7926502017158183, 'IoU-132': 2.7380239597566156, 'IoU-133': 2.8233923854413785, 'IoU-134': 2.9067294003439565, 'IoU-135': 2.6590770780819373, 'IoU-136': 2.536695623245096, 'IoU-137': 2.558044636613797, 'IoU-138': 2.2595802613344294, 'IoU-139': 2.4230355234240077, 'IoU-140': 2.2657517493934054, 'IoU-141': 2.274463769726606, 'IoU-142': 2.1865124394499555, 'IoU-143': 2.244978777800476, 'IoU-144': 2.093218787919565, 'IoU-145': 2.230226369252731, 'IoU-146': 2.2971946434643367, 'IoU-147': 2.6245784689787053, 'IoU-148': 2.6244119957441145, 'IoU-149': 2.5595979242819418, 'IoU-150': 2.6462376242563193, 'IoU-151': 2.5548223718844736, 'IoU-152': 2.4733374451215795, 'IoU-153': 2.5100623697217177, 'IoU-154': 2.4125421589192015, 'IoU-155': 2.266724259485438, 'IoU-156': 2.4565615413529276, 'IoU-157': 2.3029201841064806, 'IoU-158': 2.423715896349609, 'IoU-159': 2.1504559058566257, 'IoU-160': 2.2918420176690204, 'IoU-161': 2.1478213556308927, 'IoU-162': 2.251173336156398, 'IoU-163': 2.304089020077077, 'IoU-164': 1.8764718467433426, 'IoU-165': 1.871841601596263, 'IoU-166': 1.9749126916237176, 'IoU-167': 2.364197681364362, 'IoU-168': 2.4477695143736775, 'IoU-169': 2.7309048979920774, 'IoU-170': 2.7348672566371683, 'IoU-171': 1.6923062796391504, 'IoU-172': 1.8918734372806247, 'IoU-173': 1.8455274413172011, 'IoU-174': 1.8353707128572934, 'IoU-175': 1.6586420001503437, 'IoU-176': 2.075181293473435, 'IoU-177': 1.9336469649901675, 'IoU-178': 2.1313285713455423, 'IoU-179': 3.171929872122011, 'IoU-180': 1.8657887866880485, 'IoU-181': 1.2747215882013596, 'IoU-182': 1.5534258362233913, 'IoU-183': 1.315815082127507, 'IoU-184': 0.6751308285368558, 'IoU-185': 1.2123144106665757, 'IoU-186': 0.0054544185153509155, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 13.624748743594543, 'pACC': 31.96754019584993, 'ACC-0': 0.00035282698551059765, 'ACC-1': 77.47972037030625, 'ACC-2': 5.587628835481084, 'ACC-3': 20.820286954853945, 'ACC-4': 20.352885802903707, 'ACC-5': 20.071870122450655, 'ACC-6': 19.166593370205764, 'ACC-7': 18.816704405818026, 'ACC-8': 27.23911713398337, 'ACC-9': 39.30336848906935, 'ACC-10': 40.73372475627501, 'ACC-11': 43.08496312089814, 'ACC-12': 41.23705588383037, 'ACC-13': 38.74095095702707, 'ACC-14': 40.741446784021626, 'ACC-15': 41.30195343766864, 'ACC-16': 40.465142662748256, 'ACC-17': 40.007547647454544, 'ACC-18': 38.339239885200925, 'ACC-19': 39.913820727302436, 'ACC-20': 37.34914224187198, 'ACC-21': 37.45626335146313, 'ACC-22': 38.54294836553625, 'ACC-23': 38.26937798477225, 'ACC-24': 37.60123615045373, 'ACC-25': 38.10472731363178, 'ACC-26': 37.14418951886651, 'ACC-27': 39.07763367389892, 'ACC-28': 36.992979727618724, 'ACC-29': 36.98535247352925, 'ACC-30': 36.21475789041953, 'ACC-31': 38.00423433367261, 'ACC-32': 35.470815090808266, 'ACC-33': 33.42195843818983, 'ACC-34': 33.20519297595714, 'ACC-35': 33.37678395858771, 'ACC-36': 32.264162400805155, 'ACC-37': 32.3136779043315, 'ACC-38': 31.315139207419872, 'ACC-39': 28.93188615785633, 'ACC-40': 28.222004198861907, 'ACC-41': 27.13447366515051, 'ACC-42': 25.942315530077707, 'ACC-43': 26.092737032698782, 'ACC-44': 24.778304135263518, 'ACC-45': 24.550392410846168, 'ACC-46': 24.246176448196607, 'ACC-47': 23.54225248222068, 'ACC-48': 23.233804737542403, 'ACC-49': 22.72731214503352, 'ACC-50': 22.997118500342985, 'ACC-51': 21.560851029940743, 'ACC-52': 20.85837338277933, 'ACC-53': 20.7084858037555, 'ACC-54': 20.66916007464091, 'ACC-55': 20.281198144912636, 'ACC-56': 18.352332031801804, 'ACC-57': 18.143372927413992, 'ACC-58': 17.669619620826058, 'ACC-59': 17.465022810352803, 'ACC-60': 16.509131319293214, 'ACC-61': 15.721625389973932, 'ACC-62': 15.256790461843236, 'ACC-63': 15.012729334614198, 'ACC-64': 13.26518201741728, 'ACC-65': 12.73370865928709, 'ACC-66': 12.12674737155825, 'ACC-67': 12.293844586978175, 'ACC-68': 12.156718874001768, 'ACC-69': 11.55010587288115, 'ACC-70': 10.806802253099663, 'ACC-71': 10.466115407239732, 'ACC-72': 10.04066338989725, 'ACC-73': 10.130442430705981, 'ACC-74': 9.599482020551209, 'ACC-75': 8.610717682658485, 'ACC-76': 8.640432202711306, 'ACC-77': 8.923946458984805, 'ACC-78': 8.889367321735145, 'ACC-79': 8.541720199511413, 'ACC-80': 8.468157011581368, 'ACC-81': 8.040524444414897, 'ACC-82': 7.5394538555338455, 'ACC-83': 7.631663561333184, 'ACC-84': 7.730452478634205, 'ACC-85': 7.762664718764711, 'ACC-86': 7.43467132143198, 'ACC-87': 7.088238201644531, 'ACC-88': 6.589411905767978, 'ACC-89': 6.479886867111009, 'ACC-90': 6.356519953895631, 'ACC-91': 6.275934499255797, 'ACC-92': 5.938599331465691, 'ACC-93': 5.919626818913802, 'ACC-94': 6.506142181870376, 'ACC-95': 6.286637978524817, 'ACC-96': 6.041547284378726, 'ACC-97': 5.982181638942007, 'ACC-98': 6.118574183740284, 'ACC-99': 5.577337981050704, 'ACC-100': 5.3372996082381094, 'ACC-101': 5.5442714647050835, 'ACC-102': 5.633507023108292, 'ACC-103': 5.4813214319448385, 'ACC-104': 5.524556700523844, 'ACC-105': 5.8638235078536844, 'ACC-106': 5.776920480907881, 'ACC-107': 6.182906239529348, 'ACC-108': 6.151264071376872, 'ACC-109': 6.292625052623521, 'ACC-110': 6.543388788706627, 'ACC-111': 6.5572486093965905, 'ACC-112': 6.704730407416824, 'ACC-113': 6.453884846057416, 'ACC-114': 6.589292918323161, 'ACC-115': 6.02540104941891, 'ACC-116': 6.3546725232710415, 'ACC-117': 6.414350890079537, 'ACC-118': 6.333341310838449, 'ACC-119': 6.254200555256039, 'ACC-120': 6.285908559019175, 'ACC-121': 6.071055632947815, 'ACC-122': 6.239916216139715, 'ACC-123': 6.034709050682004, 'ACC-124': 6.058491258595035, 'ACC-125': 5.205506421293874, 'ACC-126': 5.397817830763485, 'ACC-127': 5.073171415488416, 'ACC-128': 5.618185832019134, 'ACC-129': 5.430297842753234, 'ACC-130': 5.351057545215572, 'ACC-131': 5.490083491004597, 'ACC-132': 5.378854138392094, 'ACC-133': 5.423258282471576, 'ACC-134': 5.5483670831538126, 'ACC-135': 5.153212473633202, 'ACC-136': 4.906835282333209, 'ACC-137': 4.961544538042172, 'ACC-138': 4.403729979440059, 'ACC-139': 4.726366731625173, 'ACC-140': 4.425472140364129, 'ACC-141': 4.409069258203888, 'ACC-142': 4.225451744492215, 'ACC-143': 4.335073904639696, 'ACC-144': 4.015252707581228, 'ACC-145': 4.220309040899841, 'ACC-146': 4.352562198716045, 'ACC-147': 4.962473873775167, 'ACC-148': 4.909552863882074, 'ACC-149': 4.799055644179059, 'ACC-150': 4.975875773523075, 'ACC-151': 4.799831180997631, 'ACC-152': 4.576126171690606, 'ACC-153': 4.911802158339288, 'ACC-154': 4.887356208471151, 'ACC-155': 4.501766244394978, 'ACC-156': 4.976374695391934, 'ACC-157': 4.733556271461878, 'ACC-158': 5.0673839991757825, 'ACC-159': 4.372006906974173, 'ACC-160': 4.585067637877211, 'ACC-161': 4.251468081341956, 'ACC-162': 4.555327118931512, 'ACC-163': 4.665628195858244, 'ACC-164': 3.851959195710285, 'ACC-165': 3.8349633290664396, 'ACC-166': 4.174396252864494, 'ACC-167': 5.3902690270590465, 'ACC-168': 5.434981362965047, 'ACC-169': 6.183967867652348, 'ACC-170': 6.169875207632352, 'ACC-171': 3.7238546754370336, 'ACC-172': 4.566988924695337, 'ACC-173': 4.649430109914094, 'ACC-174': 4.550580542460962, 'ACC-175': 4.038611223582354, 'ACC-176': 5.086922451822614, 'ACC-177': 5.0646927578436856, 'ACC-178': 7.0832955065664045, 'ACC-179': 11.394636839318213, 'ACC-180': 5.823935791933354, 'ACC-181': 3.852139248331877, 'ACC-182': 3.4987881702674084, 'ACC-183': 3.979272562042232, 'ACC-184': 1.6329533957364917, 'ACC-185': 2.6262304320311887, 'ACC-186': 0.0059016130288730515, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/30 11:20:36] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/30 11:20:36] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/30 11:20:36] d2.evaluation.testing INFO: copypaste: 2.3822,0.3527,0.1588,7.6385,22.0381,13.6247,31.9675
[01/30 11:20:37] d2.utils.events INFO:  eta: 17:07:22  iter: 38999  total_loss: 20.1  loss_mask: 1.997  loss_mask_0: 2.058  loss_mask_1: 2.005  loss_mask_2: 2.018  loss_mask_3: 2.006  loss_mask_4: 2.01  loss_mask_5: 1.997  loss_mask_6: 1.985  loss_mask_7: 2.005  loss_mask_8: 2.015  time: 2.9837  data_time: 0.0605  lr: 3.8876e-05  max_mem: 27646M
[01/30 11:21:23] d2.engine.hooks INFO: Overall training speed: 39014 iterations in 1 day, 8:20:04 (2.9837 s / it)
[01/30 11:21:23] d2.engine.hooks INFO: Total training time: 1 day, 17:29:50 (9:09:45 on hooks)
[01/30 11:21:23] d2.utils.events INFO:  eta: 17:06:19  iter: 39016  total_loss: 19.53  loss_mask: 1.944  loss_mask_0: 1.991  loss_mask_1: 1.944  loss_mask_2: 1.953  loss_mask_3: 1.955  loss_mask_4: 1.957  loss_mask_5: 1.942  loss_mask_6: 1.942  loss_mask_7: 1.959  loss_mask_8: 1.952  time: 2.9836  data_time: 0.0645  lr: 3.8849e-05  max_mem: 27646M
