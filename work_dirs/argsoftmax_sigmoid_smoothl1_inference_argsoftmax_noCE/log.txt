[01/27 01:57:42] detectron2 INFO: Rank of current process: 0. World size: 4
[01/27 01:57:46] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/27 01:57:46] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/27 01:57:46] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/27 01:57:46] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/27 01:57:46] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE/config.yaml
[01/27 01:57:47] d2.utils.env INFO: Using a generated random seed 47149318
[01/27 01:57:49] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/27 01:57:49] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/27 01:57:53] d2.data.build INFO: Using training sampler TrainingSampler
[01/27 01:57:53] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/27 01:57:53] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/27 01:57:53] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/27 01:57:54] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/27 01:57:54] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/27 01:57:54] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/27 01:57:54] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/27 01:57:54] d2.engine.train_loop INFO: Starting training from iteration 0
[01/27 01:59:08] d2.utils.events INFO:  eta: 1 day, 20:27:35  iter: 19  total_loss: 8.461e+04  loss_mask: 8912  loss_mask_0: 1.024e+04  loss_mask_1: 1.183e+04  loss_mask_2: 1.032e+04  loss_mask_3: 7303  loss_mask_4: 6684  loss_mask_5: 8548  loss_mask_6: 1.035e+04  loss_mask_7: 5376  loss_mask_8: 5084  time: 2.6904  data_time: 0.8363  lr: 1.1707e-05  max_mem: 17321M
[01/27 01:59:54] d2.utils.events INFO:  eta: 1 day, 16:49:23  iter: 39  total_loss: 477.2  loss_mask: 42.86  loss_mask_0: 141.8  loss_mask_1: 43.05  loss_mask_2: 42.57  loss_mask_3: 43.35  loss_mask_4: 42.4  loss_mask_5: 43.11  loss_mask_6: 42.27  loss_mask_7: 42.23  loss_mask_8: 42.4  time: 2.5008  data_time: 0.4264  lr: 1.3502e-05  max_mem: 17380M
[01/27 02:00:40] d2.utils.events INFO:  eta: 1 day, 14:54:07  iter: 59  total_loss: 334.2  loss_mask: 31.58  loss_mask_0: 29.49  loss_mask_1: 32.64  loss_mask_2: 36.92  loss_mask_3: 37.6  loss_mask_4: 31.54  loss_mask_5: 30.65  loss_mask_6: 32.66  loss_mask_7: 33.53  loss_mask_8: 32.59  time: 2.4301  data_time: 0.4103  lr: 1.5296e-05  max_mem: 17380M
[01/27 02:01:26] d2.utils.events INFO:  eta: 1 day, 14:38:53  iter: 79  total_loss: 273.2  loss_mask: 27.33  loss_mask_0: 26.66  loss_mask_1: 27.91  loss_mask_2: 26.98  loss_mask_3: 28.09  loss_mask_4: 27.14  loss_mask_5: 27.18  loss_mask_6: 26.86  loss_mask_7: 26.8  loss_mask_8: 27.79  time: 2.3951  data_time: 0.4178  lr: 1.709e-05  max_mem: 17433M
[01/27 02:02:12] d2.utils.events INFO:  eta: 1 day, 14:21:56  iter: 99  total_loss: 226.6  loss_mask: 22.65  loss_mask_0: 22.82  loss_mask_1: 22.68  loss_mask_2: 22.16  loss_mask_3: 22.16  loss_mask_4: 22.41  loss_mask_5: 22.52  loss_mask_6: 22.42  loss_mask_7: 22.35  loss_mask_8: 22.4  time: 2.3695  data_time: 0.4170  lr: 1.8882e-05  max_mem: 17433M
[01/27 02:02:57] d2.utils.events INFO:  eta: 1 day, 14:16:39  iter: 119  total_loss: 199.4  loss_mask: 20  loss_mask_0: 20.51  loss_mask_1: 19.79  loss_mask_2: 19.94  loss_mask_3: 19.56  loss_mask_4: 20.4  loss_mask_5: 19.82  loss_mask_6: 20.1  loss_mask_7: 19.63  loss_mask_8: 20.05  time: 2.3503  data_time: 0.4335  lr: 2.0673e-05  max_mem: 17433M
[01/27 02:03:41] d2.utils.events INFO:  eta: 1 day, 13:55:52  iter: 139  total_loss: 195.8  loss_mask: 20.29  loss_mask_0: 19.76  loss_mask_1: 19.1  loss_mask_2: 19.52  loss_mask_3: 19.6  loss_mask_4: 19.69  loss_mask_5: 19.72  loss_mask_6: 20.99  loss_mask_7: 20.14  loss_mask_8: 20.96  time: 2.3300  data_time: 0.4137  lr: 2.2463e-05  max_mem: 17433M
[01/27 02:04:26] d2.utils.events INFO:  eta: 1 day, 13:51:08  iter: 159  total_loss: 190.3  loss_mask: 19.2  loss_mask_0: 19.47  loss_mask_1: 18.81  loss_mask_2: 19.11  loss_mask_3: 19.24  loss_mask_4: 18.97  loss_mask_5: 19.04  loss_mask_6: 19.31  loss_mask_7: 18.91  loss_mask_8: 18.6  time: 2.3197  data_time: 0.3895  lr: 2.4252e-05  max_mem: 17433M
[01/27 02:05:10] d2.utils.events INFO:  eta: 1 day, 13:35:06  iter: 179  total_loss: 189.1  loss_mask: 19.68  loss_mask_0: 18.61  loss_mask_1: 18.25  loss_mask_2: 18.33  loss_mask_3: 18.4  loss_mask_4: 18.17  loss_mask_5: 18.36  loss_mask_6: 18.68  loss_mask_7: 18.41  loss_mask_8: 19.2  time: 2.3062  data_time: 0.3939  lr: 2.604e-05  max_mem: 17433M
[01/27 02:05:55] d2.utils.events INFO:  eta: 1 day, 13:33:21  iter: 199  total_loss: 174.6  loss_mask: 16.98  loss_mask_0: 17.56  loss_mask_1: 16.95  loss_mask_2: 17.09  loss_mask_3: 17.51  loss_mask_4: 17.41  loss_mask_5: 17.55  loss_mask_6: 17.69  loss_mask_7: 17.27  loss_mask_8: 18  time: 2.2998  data_time: 0.4103  lr: 2.7827e-05  max_mem: 17433M
[01/27 02:06:40] d2.utils.events INFO:  eta: 1 day, 13:31:53  iter: 219  total_loss: 180.1  loss_mask: 18.07  loss_mask_0: 17.39  loss_mask_1: 17.58  loss_mask_2: 17.96  loss_mask_3: 17.63  loss_mask_4: 17.06  loss_mask_5: 18.15  loss_mask_6: 18.68  loss_mask_7: 17.88  loss_mask_8: 18.65  time: 2.2958  data_time: 0.4312  lr: 2.9612e-05  max_mem: 17433M
[01/27 02:07:24] d2.utils.events INFO:  eta: 1 day, 13:28:36  iter: 239  total_loss: 173.3  loss_mask: 16.82  loss_mask_0: 17.13  loss_mask_1: 16.85  loss_mask_2: 17.18  loss_mask_3: 16.96  loss_mask_4: 17.02  loss_mask_5: 17.31  loss_mask_6: 16.96  loss_mask_7: 16.84  loss_mask_8: 17.97  time: 2.2892  data_time: 0.3967  lr: 3.1397e-05  max_mem: 17433M
[01/27 02:08:09] d2.utils.events INFO:  eta: 1 day, 13:25:14  iter: 259  total_loss: 179.5  loss_mask: 18.28  loss_mask_0: 17.56  loss_mask_1: 17.27  loss_mask_2: 17.89  loss_mask_3: 18  loss_mask_4: 17.71  loss_mask_5: 18.2  loss_mask_6: 17.47  loss_mask_7: 17.57  loss_mask_8: 18  time: 2.2842  data_time: 0.4142  lr: 3.3181e-05  max_mem: 17433M
[01/27 02:08:53] d2.utils.events INFO:  eta: 1 day, 13:22:50  iter: 279  total_loss: 179  loss_mask: 17.47  loss_mask_0: 17.34  loss_mask_1: 17.63  loss_mask_2: 17.86  loss_mask_3: 17.64  loss_mask_4: 17.92  loss_mask_5: 18.07  loss_mask_6: 17.58  loss_mask_7: 18.02  loss_mask_8: 17.39  time: 2.2794  data_time: 0.3951  lr: 3.4963e-05  max_mem: 17433M
[01/27 02:09:38] d2.utils.events INFO:  eta: 1 day, 13:19:19  iter: 299  total_loss: 171.5  loss_mask: 17.42  loss_mask_0: 17.1  loss_mask_1: 16.77  loss_mask_2: 17.14  loss_mask_3: 17.33  loss_mask_4: 17.8  loss_mask_5: 18.18  loss_mask_6: 16.87  loss_mask_7: 17.02  loss_mask_8: 17.24  time: 2.2753  data_time: 0.4049  lr: 3.6744e-05  max_mem: 17433M
[01/27 02:10:22] d2.utils.events INFO:  eta: 1 day, 13:13:56  iter: 319  total_loss: 164.8  loss_mask: 17.03  loss_mask_0: 16.39  loss_mask_1: 16.18  loss_mask_2: 16.37  loss_mask_3: 16.63  loss_mask_4: 16.3  loss_mask_5: 16.43  loss_mask_6: 16.6  loss_mask_7: 16.47  loss_mask_8: 16.93  time: 2.2706  data_time: 0.3958  lr: 3.8525e-05  max_mem: 17433M
[01/27 02:11:07] d2.utils.events INFO:  eta: 1 day, 13:13:11  iter: 339  total_loss: 170.2  loss_mask: 16.83  loss_mask_0: 16.37  loss_mask_1: 16.59  loss_mask_2: 17.02  loss_mask_3: 17.3  loss_mask_4: 17.18  loss_mask_5: 17.76  loss_mask_6: 16.85  loss_mask_7: 16.45  loss_mask_8: 16.84  time: 2.2694  data_time: 0.4252  lr: 4.0304e-05  max_mem: 17444M
[01/27 02:11:51] d2.utils.events INFO:  eta: 1 day, 13:12:27  iter: 359  total_loss: 152.8  loss_mask: 15.97  loss_mask_0: 15.22  loss_mask_1: 15.07  loss_mask_2: 15.09  loss_mask_3: 15.92  loss_mask_4: 15.09  loss_mask_5: 16.09  loss_mask_6: 15.25  loss_mask_7: 15.38  loss_mask_8: 15.9  time: 2.2673  data_time: 0.4213  lr: 4.2082e-05  max_mem: 17444M
[01/27 02:12:36] d2.utils.events INFO:  eta: 1 day, 13:10:23  iter: 379  total_loss: 152.3  loss_mask: 14.82  loss_mask_0: 15.06  loss_mask_1: 14.99  loss_mask_2: 15.05  loss_mask_3: 14.95  loss_mask_4: 15.16  loss_mask_5: 15.55  loss_mask_6: 15.57  loss_mask_7: 15.34  loss_mask_8: 15.13  time: 2.2651  data_time: 0.4209  lr: 4.3859e-05  max_mem: 17444M
[01/27 02:13:21] d2.utils.events INFO:  eta: 1 day, 13:08:35  iter: 399  total_loss: 161.1  loss_mask: 15.77  loss_mask_0: 15.68  loss_mask_1: 16.19  loss_mask_2: 15.82  loss_mask_3: 16.41  loss_mask_4: 16.12  loss_mask_5: 16.46  loss_mask_6: 16.27  loss_mask_7: 15.75  loss_mask_8: 16.51  time: 2.2639  data_time: 0.4170  lr: 4.5635e-05  max_mem: 17444M
[01/27 02:14:06] d2.utils.events INFO:  eta: 1 day, 13:07:50  iter: 419  total_loss: 167.8  loss_mask: 16.69  loss_mask_0: 16.44  loss_mask_1: 16.46  loss_mask_2: 16.04  loss_mask_3: 16.34  loss_mask_4: 16.77  loss_mask_5: 16.94  loss_mask_6: 17.21  loss_mask_7: 16.66  loss_mask_8: 16.43  time: 2.2626  data_time: 0.4080  lr: 4.741e-05  max_mem: 17444M
[01/27 02:14:50] d2.utils.events INFO:  eta: 1 day, 13:05:06  iter: 439  total_loss: 156.4  loss_mask: 15.49  loss_mask_0: 14.55  loss_mask_1: 14.68  loss_mask_2: 15.62  loss_mask_3: 14.92  loss_mask_4: 15.06  loss_mask_5: 15.79  loss_mask_6: 14.95  loss_mask_7: 14.96  loss_mask_8: 14.3  time: 2.2598  data_time: 0.3884  lr: 4.9184e-05  max_mem: 17444M
[01/27 02:15:34] d2.utils.events INFO:  eta: 1 day, 13:02:57  iter: 459  total_loss: 143.6  loss_mask: 14.4  loss_mask_0: 14.43  loss_mask_1: 14.08  loss_mask_2: 14.02  loss_mask_3: 14.23  loss_mask_4: 14.34  loss_mask_5: 14.38  loss_mask_6: 14.18  loss_mask_7: 14.85  loss_mask_8: 14.46  time: 2.2583  data_time: 0.4125  lr: 5.0957e-05  max_mem: 17444M
[01/27 02:16:18] d2.utils.events INFO:  eta: 1 day, 12:59:49  iter: 479  total_loss: 140.6  loss_mask: 14.01  loss_mask_0: 13.87  loss_mask_1: 13.88  loss_mask_2: 14.18  loss_mask_3: 14.14  loss_mask_4: 14.12  loss_mask_5: 14.2  loss_mask_6: 13.89  loss_mask_7: 13.57  loss_mask_8: 13.72  time: 2.2561  data_time: 0.4074  lr: 5.2728e-05  max_mem: 17484M
[01/27 02:17:03] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 02:17:03] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 02:17:03] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 02:41:01] detectron2 INFO: Rank of current process: 0. World size: 4
[01/27 02:41:04] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/27 02:41:04] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/27 02:41:04] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/27 02:41:04] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/27 02:41:04] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE/config.yaml
[01/27 02:41:04] d2.utils.env INFO: Using a generated random seed 4524352
[01/27 02:41:07] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/27 02:41:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/27 02:41:11] d2.data.build INFO: Using training sampler TrainingSampler
[01/27 02:41:11] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/27 02:41:12] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/27 02:41:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/27 02:41:12] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/27 02:41:12] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/27 02:41:12] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/27 02:41:12] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/27 02:41:12] d2.engine.train_loop INFO: Starting training from iteration 0
[01/27 02:42:29] d2.utils.events INFO:  eta: 1 day, 22:24:39  iter: 19  total_loss: 1.444e+05  loss_mask: 9878  loss_mask_0: 1.596e+04  loss_mask_1: 1.567e+04  loss_mask_2: 1.416e+04  loss_mask_3: 1.419e+04  loss_mask_4: 2e+04  loss_mask_5: 1.623e+04  loss_mask_6: 1.694e+04  loss_mask_7: 9189  loss_mask_8: 1.228e+04  time: 2.8011  data_time: 0.8764  lr: 1.1707e-05  max_mem: 17323M
[01/27 02:43:17] d2.utils.events INFO:  eta: 1 day, 19:23:40  iter: 39  total_loss: 674.9  loss_mask: 46.43  loss_mask_0: 249  loss_mask_1: 48.02  loss_mask_2: 47.06  loss_mask_3: 47.04  loss_mask_4: 48.27  loss_mask_5: 48.05  loss_mask_6: 46.57  loss_mask_7: 45.63  loss_mask_8: 45.75  time: 2.5815  data_time: 0.4244  lr: 1.3502e-05  max_mem: 17379M
[01/27 02:44:04] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 02:44:05] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 02:44:05] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 02:45:04] d2.engine.hooks INFO: Overall training speed: 57 iterations in 0:02:25 (2.5515 s / it)
[01/27 02:45:04] d2.engine.hooks INFO: Total training time: 0:03:25 (0:01:00 on hooks)
[01/27 02:45:04] d2.utils.events INFO:  eta: 1 day, 15:49:22  iter: 59  total_loss: 392.7  loss_mask: 35.91  loss_mask_0: 34.4  loss_mask_1: 39.33  loss_mask_2: 36.26  loss_mask_3: 34.06  loss_mask_4: 39.52  loss_mask_5: 40.53  loss_mask_6: 40.59  loss_mask_7: 35.11  loss_mask_8: 37.36  time: 2.5075  data_time: 0.4229  lr: 1.5296e-05  max_mem: 17402M
[01/27 02:45:53] detectron2 INFO: Rank of current process: 0. World size: 4
[01/27 02:45:55] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/27 02:45:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/27 02:45:55] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/27 02:45:56] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/27 02:45:56] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE/config.yaml
[01/27 02:45:56] d2.utils.env INFO: Using a generated random seed 56236128
[01/27 02:45:57] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/27 02:45:57] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/27 02:46:02] d2.data.build INFO: Using training sampler TrainingSampler
[01/27 02:46:02] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/27 02:46:02] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/27 02:46:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/27 02:46:02] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/27 02:46:02] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/27 02:46:02] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/27 02:46:02] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/27 02:46:02] d2.engine.train_loop INFO: Starting training from iteration 0
[01/27 02:47:17] d2.utils.events INFO:  eta: 1 day, 22:02:24  iter: 19  total_loss: 1.774e+05  loss_mask: 1.621e+04  loss_mask_0: 1.675e+04  loss_mask_1: 1.684e+04  loss_mask_2: 1.868e+04  loss_mask_3: 1.602e+04  loss_mask_4: 2.031e+04  loss_mask_5: 1.657e+04  loss_mask_6: 1.862e+04  loss_mask_7: 1.814e+04  loss_mask_8: 1.918e+04  time: 2.7555  data_time: 0.8198  lr: 1.1707e-05  max_mem: 17344M
[01/27 02:48:05] d2.utils.events INFO:  eta: 1 day, 18:52:20  iter: 39  total_loss: 809.2  loss_mask: 41.73  loss_mask_0: 421  loss_mask_1: 45.17  loss_mask_2: 43.16  loss_mask_3: 42.63  loss_mask_4: 43.52  loss_mask_5: 44.08  loss_mask_6: 46.67  loss_mask_7: 44.38  loss_mask_8: 42.66  time: 2.5479  data_time: 0.4072  lr: 1.3502e-05  max_mem: 17357M
[01/27 02:48:51] d2.utils.events INFO:  eta: 1 day, 15:35:42  iter: 59  total_loss: 350  loss_mask: 31.94  loss_mask_0: 30.6  loss_mask_1: 32.06  loss_mask_2: 31.8  loss_mask_3: 32.53  loss_mask_4: 38.25  loss_mask_5: 41.84  loss_mask_6: 39.92  loss_mask_7: 39.04  loss_mask_8: 31.05  time: 2.4677  data_time: 0.4082  lr: 1.5296e-05  max_mem: 17426M
[01/27 02:49:37] d2.utils.events INFO:  eta: 1 day, 14:53:59  iter: 79  total_loss: 272.8  loss_mask: 27.03  loss_mask_0: 26.13  loss_mask_1: 27.06  loss_mask_2: 26.78  loss_mask_3: 26.44  loss_mask_4: 27.2  loss_mask_5: 27.87  loss_mask_6: 27.9  loss_mask_7: 26.92  loss_mask_8: 26.92  time: 2.4199  data_time: 0.4015  lr: 1.709e-05  max_mem: 17426M
[01/27 02:50:23] d2.utils.events INFO:  eta: 1 day, 14:47:10  iter: 99  total_loss: 248.4  loss_mask: 24.67  loss_mask_0: 24.26  loss_mask_1: 24.35  loss_mask_2: 24.35  loss_mask_3: 25.17  loss_mask_4: 24.69  loss_mask_5: 24.69  loss_mask_6: 25.7  loss_mask_7: 24.65  loss_mask_8: 24.82  time: 2.3966  data_time: 0.4324  lr: 1.8882e-05  max_mem: 17426M
[01/27 02:51:09] d2.utils.events INFO:  eta: 1 day, 14:42:52  iter: 119  total_loss: 220.8  loss_mask: 22.2  loss_mask_0: 21.74  loss_mask_1: 21.85  loss_mask_2: 22.32  loss_mask_3: 21.98  loss_mask_4: 22.23  loss_mask_5: 22.2  loss_mask_6: 22.48  loss_mask_7: 22.34  loss_mask_8: 21.7  time: 2.3830  data_time: 0.4302  lr: 2.0673e-05  max_mem: 17426M
[01/27 02:51:55] d2.utils.events INFO:  eta: 1 day, 14:37:37  iter: 139  total_loss: 211.7  loss_mask: 21.02  loss_mask_0: 21.05  loss_mask_1: 20.89  loss_mask_2: 20.98  loss_mask_3: 20.97  loss_mask_4: 21.25  loss_mask_5: 21.14  loss_mask_6: 21.72  loss_mask_7: 21.38  loss_mask_8: 21.47  time: 2.3726  data_time: 0.4317  lr: 2.2463e-05  max_mem: 17426M
[01/27 02:52:42] d2.utils.events INFO:  eta: 1 day, 14:34:28  iter: 159  total_loss: 186  loss_mask: 19.05  loss_mask_0: 18.3  loss_mask_1: 18.59  loss_mask_2: 18.53  loss_mask_3: 18.38  loss_mask_4: 18.49  loss_mask_5: 18.58  loss_mask_6: 18.52  loss_mask_7: 18.48  loss_mask_8: 18.63  time: 2.3676  data_time: 0.4262  lr: 2.4252e-05  max_mem: 17426M
[01/27 02:53:29] d2.utils.events INFO:  eta: 1 day, 14:39:53  iter: 179  total_loss: 189.8  loss_mask: 19.18  loss_mask_0: 18.39  loss_mask_1: 18.31  loss_mask_2: 18.66  loss_mask_3: 19.17  loss_mask_4: 18.7  loss_mask_5: 19.08  loss_mask_6: 19.02  loss_mask_7: 19.15  loss_mask_8: 19.16  time: 2.3650  data_time: 0.4141  lr: 2.604e-05  max_mem: 17426M
[01/27 02:54:17] d2.utils.events INFO:  eta: 1 day, 14:42:04  iter: 199  total_loss: 181.3  loss_mask: 18.56  loss_mask_0: 17.59  loss_mask_1: 17.93  loss_mask_2: 18.18  loss_mask_3: 18.18  loss_mask_4: 18.21  loss_mask_5: 18.41  loss_mask_6: 18.37  loss_mask_7: 18.53  loss_mask_8: 18.69  time: 2.3679  data_time: 0.4278  lr: 2.7827e-05  max_mem: 17426M
[01/27 02:55:05] d2.utils.events INFO:  eta: 1 day, 14:46:07  iter: 219  total_loss: 193.6  loss_mask: 18.97  loss_mask_0: 17.75  loss_mask_1: 18.27  loss_mask_2: 18.24  loss_mask_3: 18.98  loss_mask_4: 19.32  loss_mask_5: 19.46  loss_mask_6: 19.11  loss_mask_7: 19.5  loss_mask_8: 19.84  time: 2.3695  data_time: 0.4116  lr: 2.9612e-05  max_mem: 17426M
[01/27 02:55:53] d2.utils.events INFO:  eta: 1 day, 14:53:51  iter: 239  total_loss: 186.7  loss_mask: 18.78  loss_mask_0: 18.21  loss_mask_1: 18.21  loss_mask_2: 18.47  loss_mask_3: 18.21  loss_mask_4: 18.74  loss_mask_5: 18.95  loss_mask_6: 19.06  loss_mask_7: 18.82  loss_mask_8: 18.93  time: 2.3733  data_time: 0.4301  lr: 3.1397e-05  max_mem: 17426M
[01/27 02:56:41] d2.utils.events INFO:  eta: 1 day, 14:57:11  iter: 259  total_loss: 177.2  loss_mask: 17.56  loss_mask_0: 17.19  loss_mask_1: 17.15  loss_mask_2: 17.56  loss_mask_3: 17.69  loss_mask_4: 17.99  loss_mask_5: 17.71  loss_mask_6: 17.55  loss_mask_7: 17.8  loss_mask_8: 17.62  time: 2.3757  data_time: 0.4110  lr: 3.3181e-05  max_mem: 17449M
[01/27 02:57:29] d2.utils.events INFO:  eta: 1 day, 14:59:04  iter: 279  total_loss: 174.9  loss_mask: 17.98  loss_mask_0: 16.93  loss_mask_1: 16.83  loss_mask_2: 17.36  loss_mask_3: 17.13  loss_mask_4: 17.41  loss_mask_5: 17.54  loss_mask_6: 18.17  loss_mask_7: 17  loss_mask_8: 17.52  time: 2.3765  data_time: 0.3988  lr: 3.4963e-05  max_mem: 17449M
[01/27 02:58:17] d2.utils.events INFO:  eta: 1 day, 14:59:57  iter: 299  total_loss: 173.4  loss_mask: 17.27  loss_mask_0: 16.88  loss_mask_1: 16.97  loss_mask_2: 16.76  loss_mask_3: 17.1  loss_mask_4: 17.35  loss_mask_5: 17.04  loss_mask_6: 17.45  loss_mask_7: 17.57  loss_mask_8: 17.25  time: 2.3771  data_time: 0.4116  lr: 3.6744e-05  max_mem: 17449M
[01/27 02:59:04] d2.utils.events INFO:  eta: 1 day, 15:03:32  iter: 319  total_loss: 157.4  loss_mask: 15.85  loss_mask_0: 15.43  loss_mask_1: 15.35  loss_mask_2: 15.61  loss_mask_3: 15.7  loss_mask_4: 15.64  loss_mask_5: 15.54  loss_mask_6: 15.8  loss_mask_7: 15.81  loss_mask_8: 15.75  time: 2.3777  data_time: 0.4078  lr: 3.8525e-05  max_mem: 17449M
[01/27 02:59:52] d2.utils.events INFO:  eta: 1 day, 15:05:57  iter: 339  total_loss: 154.3  loss_mask: 15.99  loss_mask_0: 15.17  loss_mask_1: 15.11  loss_mask_2: 15.31  loss_mask_3: 15.24  loss_mask_4: 15.42  loss_mask_5: 15.41  loss_mask_6: 15.25  loss_mask_7: 15.99  loss_mask_8: 15.26  time: 2.3785  data_time: 0.4079  lr: 4.0304e-05  max_mem: 17449M
[01/27 03:00:40] d2.utils.events INFO:  eta: 1 day, 15:08:20  iter: 359  total_loss: 158.9  loss_mask: 16.38  loss_mask_0: 15.25  loss_mask_1: 15.64  loss_mask_2: 16.21  loss_mask_3: 15.98  loss_mask_4: 16.22  loss_mask_5: 16.37  loss_mask_6: 15.92  loss_mask_7: 16.3  loss_mask_8: 16.03  time: 2.3797  data_time: 0.4203  lr: 4.2082e-05  max_mem: 17449M
[01/27 03:01:28] d2.utils.events INFO:  eta: 1 day, 15:11:38  iter: 379  total_loss: 179.9  loss_mask: 17.71  loss_mask_0: 16.96  loss_mask_1: 17.42  loss_mask_2: 17.69  loss_mask_3: 17.83  loss_mask_4: 17.67  loss_mask_5: 19.42  loss_mask_6: 18.09  loss_mask_7: 16.8  loss_mask_8: 18.13  time: 2.3813  data_time: 0.4146  lr: 4.3859e-05  max_mem: 17449M
[01/27 03:02:16] d2.utils.events INFO:  eta: 1 day, 15:13:00  iter: 399  total_loss: 165.3  loss_mask: 17.09  loss_mask_0: 15.4  loss_mask_1: 15.71  loss_mask_2: 15.87  loss_mask_3: 16.52  loss_mask_4: 16.88  loss_mask_5: 16.04  loss_mask_6: 16.46  loss_mask_7: 15.93  loss_mask_8: 15.77  time: 2.3821  data_time: 0.4159  lr: 4.5635e-05  max_mem: 17449M
[01/27 03:03:04] d2.utils.events INFO:  eta: 1 day, 15:14:38  iter: 419  total_loss: 152.7  loss_mask: 15.64  loss_mask_0: 15.09  loss_mask_1: 14.96  loss_mask_2: 15  loss_mask_3: 14.7  loss_mask_4: 14.96  loss_mask_5: 15.2  loss_mask_6: 15.75  loss_mask_7: 15.67  loss_mask_8: 15.12  time: 2.3828  data_time: 0.4207  lr: 4.741e-05  max_mem: 17449M
[01/27 03:03:53] d2.utils.events INFO:  eta: 1 day, 15:13:53  iter: 439  total_loss: 167.2  loss_mask: 16.81  loss_mask_0: 16.4  loss_mask_1: 16.52  loss_mask_2: 16.81  loss_mask_3: 16.95  loss_mask_4: 16.53  loss_mask_5: 15.81  loss_mask_6: 16.14  loss_mask_7: 16.16  loss_mask_8: 16.3  time: 2.3837  data_time: 0.4299  lr: 4.9184e-05  max_mem: 17449M
[01/27 03:04:41] d2.utils.events INFO:  eta: 1 day, 15:15:30  iter: 459  total_loss: 169.4  loss_mask: 17.39  loss_mask_0: 15.55  loss_mask_1: 16.46  loss_mask_2: 16.48  loss_mask_3: 16.96  loss_mask_4: 17.14  loss_mask_5: 16.59  loss_mask_6: 17.02  loss_mask_7: 16.53  loss_mask_8: 16.64  time: 2.3846  data_time: 0.4220  lr: 5.0957e-05  max_mem: 17449M
[01/27 03:05:28] d2.utils.events INFO:  eta: 1 day, 15:14:56  iter: 479  total_loss: 143  loss_mask: 14.34  loss_mask_0: 14.24  loss_mask_1: 14.25  loss_mask_2: 14.1  loss_mask_3: 14.26  loss_mask_4: 14.47  loss_mask_5: 14.71  loss_mask_6: 14.59  loss_mask_7: 14.91  loss_mask_8: 14.96  time: 2.3844  data_time: 0.4206  lr: 5.2728e-05  max_mem: 17449M
[01/27 03:06:16] d2.utils.events INFO:  eta: 1 day, 15:13:21  iter: 499  total_loss: 140.7  loss_mask: 14.36  loss_mask_0: 13.68  loss_mask_1: 13.67  loss_mask_2: 13.78  loss_mask_3: 14.01  loss_mask_4: 14.19  loss_mask_5: 14.28  loss_mask_6: 13.58  loss_mask_7: 13.44  loss_mask_8: 13.87  time: 2.3844  data_time: 0.4039  lr: 5.4499e-05  max_mem: 17449M
[01/27 03:07:04] d2.utils.events INFO:  eta: 1 day, 15:13:48  iter: 519  total_loss: 179.1  loss_mask: 20.95  loss_mask_0: 15.76  loss_mask_1: 16.72  loss_mask_2: 16.62  loss_mask_3: 15.62  loss_mask_4: 15.5  loss_mask_5: 16.05  loss_mask_6: 17.28  loss_mask_7: 16.53  loss_mask_8: 17.29  time: 2.3856  data_time: 0.4391  lr: 5.6268e-05  max_mem: 17449M
[01/27 03:07:53] d2.utils.events INFO:  eta: 1 day, 15:13:53  iter: 539  total_loss: 150.6  loss_mask: 15.3  loss_mask_0: 14.57  loss_mask_1: 15.31  loss_mask_2: 15.97  loss_mask_3: 15.05  loss_mask_4: 15.28  loss_mask_5: 15.5  loss_mask_6: 15.33  loss_mask_7: 14.59  loss_mask_8: 15  time: 2.3862  data_time: 0.4253  lr: 5.8037e-05  max_mem: 17449M
[01/27 03:08:40] d2.utils.events INFO:  eta: 1 day, 15:13:02  iter: 559  total_loss: 137.2  loss_mask: 13.99  loss_mask_0: 13.6  loss_mask_1: 13.82  loss_mask_2: 14.01  loss_mask_3: 13.99  loss_mask_4: 14.21  loss_mask_5: 14.13  loss_mask_6: 13.84  loss_mask_7: 13.4  loss_mask_8: 13.38  time: 2.3860  data_time: 0.4172  lr: 5.9804e-05  max_mem: 17449M
[01/27 03:09:28] d2.utils.events INFO:  eta: 1 day, 15:12:34  iter: 579  total_loss: 149.7  loss_mask: 14.83  loss_mask_0: 14.5  loss_mask_1: 15.08  loss_mask_2: 15.15  loss_mask_3: 15.03  loss_mask_4: 14.91  loss_mask_5: 15.29  loss_mask_6: 14.79  loss_mask_7: 15.59  loss_mask_8: 14.76  time: 2.3863  data_time: 0.4202  lr: 6.157e-05  max_mem: 17449M
[01/27 03:10:16] d2.utils.events INFO:  eta: 1 day, 15:13:09  iter: 599  total_loss: 140.8  loss_mask: 13.82  loss_mask_0: 13.97  loss_mask_1: 13.89  loss_mask_2: 14.17  loss_mask_3: 14.14  loss_mask_4: 14.09  loss_mask_5: 14.36  loss_mask_6: 14.1  loss_mask_7: 13.9  loss_mask_8: 13.84  time: 2.3870  data_time: 0.4188  lr: 6.3335e-05  max_mem: 17449M
[01/27 03:11:05] d2.utils.events INFO:  eta: 1 day, 15:14:02  iter: 619  total_loss: 139.7  loss_mask: 13.89  loss_mask_0: 13.45  loss_mask_1: 14.19  loss_mask_2: 14.17  loss_mask_3: 14.21  loss_mask_4: 13.8  loss_mask_5: 13.76  loss_mask_6: 13.58  loss_mask_7: 13.91  loss_mask_8: 14.08  time: 2.3875  data_time: 0.4149  lr: 6.51e-05  max_mem: 17449M
[01/27 03:11:53] d2.utils.events INFO:  eta: 1 day, 15:13:45  iter: 639  total_loss: 139.3  loss_mask: 14  loss_mask_0: 13.77  loss_mask_1: 13.84  loss_mask_2: 14.25  loss_mask_3: 13.94  loss_mask_4: 13.93  loss_mask_5: 14.2  loss_mask_6: 14.32  loss_mask_7: 13.82  loss_mask_8: 13.85  time: 2.3879  data_time: 0.4243  lr: 6.6863e-05  max_mem: 17449M
[01/27 03:12:40] d2.utils.events INFO:  eta: 1 day, 15:13:32  iter: 659  total_loss: 133.4  loss_mask: 13.28  loss_mask_0: 13.15  loss_mask_1: 13.26  loss_mask_2: 13.11  loss_mask_3: 13.4  loss_mask_4: 13.39  loss_mask_5: 13.22  loss_mask_6: 12.63  loss_mask_7: 13.37  loss_mask_8: 13.28  time: 2.3880  data_time: 0.4157  lr: 6.8624e-05  max_mem: 17449M
[01/27 03:13:28] d2.utils.events INFO:  eta: 1 day, 15:12:45  iter: 679  total_loss: 136.6  loss_mask: 13.71  loss_mask_0: 13.52  loss_mask_1: 13.63  loss_mask_2: 13.56  loss_mask_3: 13.62  loss_mask_4: 13.46  loss_mask_5: 13.87  loss_mask_6: 13.97  loss_mask_7: 13.36  loss_mask_8: 13.62  time: 2.3877  data_time: 0.4060  lr: 7.0385e-05  max_mem: 17449M
[01/27 03:14:16] d2.utils.events INFO:  eta: 1 day, 15:12:41  iter: 699  total_loss: 128.5  loss_mask: 12.84  loss_mask_0: 12.52  loss_mask_1: 12.59  loss_mask_2: 12.88  loss_mask_3: 12.85  loss_mask_4: 12.77  loss_mask_5: 12.86  loss_mask_6: 12.71  loss_mask_7: 12.79  loss_mask_8: 12.91  time: 2.3883  data_time: 0.4244  lr: 7.2145e-05  max_mem: 17449M
[01/27 03:15:04] d2.utils.events INFO:  eta: 1 day, 15:12:10  iter: 719  total_loss: 137.8  loss_mask: 13.83  loss_mask_0: 13.4  loss_mask_1: 13.85  loss_mask_2: 13.4  loss_mask_3: 13.66  loss_mask_4: 13.96  loss_mask_5: 13.9  loss_mask_6: 13.94  loss_mask_7: 13.48  loss_mask_8: 14.04  time: 2.3883  data_time: 0.4311  lr: 7.3904e-05  max_mem: 17449M
[01/27 03:15:52] d2.utils.events INFO:  eta: 1 day, 15:11:06  iter: 739  total_loss: 133.4  loss_mask: 13.43  loss_mask_0: 13.17  loss_mask_1: 12.93  loss_mask_2: 13.76  loss_mask_3: 13.75  loss_mask_4: 13.08  loss_mask_5: 13.27  loss_mask_6: 13.01  loss_mask_7: 13.47  loss_mask_8: 13.26  time: 2.3883  data_time: 0.4084  lr: 7.5661e-05  max_mem: 17449M
[01/27 03:16:40] d2.utils.events INFO:  eta: 1 day, 15:10:46  iter: 759  total_loss: 127.5  loss_mask: 12.2  loss_mask_0: 12.22  loss_mask_1: 12.32  loss_mask_2: 12.63  loss_mask_3: 12.37  loss_mask_4: 13.08  loss_mask_5: 12.58  loss_mask_6: 12.76  loss_mask_7: 12.52  loss_mask_8: 12.33  time: 2.3890  data_time: 0.4186  lr: 7.7418e-05  max_mem: 17449M
[01/27 03:17:28] d2.utils.events INFO:  eta: 1 day, 15:09:59  iter: 779  total_loss: 122.3  loss_mask: 12.15  loss_mask_0: 12.06  loss_mask_1: 12.18  loss_mask_2: 12.09  loss_mask_3: 12.66  loss_mask_4: 12.16  loss_mask_5: 12.35  loss_mask_6: 12.18  loss_mask_7: 12.24  loss_mask_8: 12.24  time: 2.3891  data_time: 0.4204  lr: 7.9173e-05  max_mem: 17449M
[01/27 03:18:16] d2.utils.events INFO:  eta: 1 day, 15:10:34  iter: 799  total_loss: 128.3  loss_mask: 13.12  loss_mask_0: 12.8  loss_mask_1: 12.78  loss_mask_2: 13.09  loss_mask_3: 13.05  loss_mask_4: 12.97  loss_mask_5: 13.25  loss_mask_6: 12.86  loss_mask_7: 13.23  loss_mask_8: 12.68  time: 2.3894  data_time: 0.4307  lr: 8.0928e-05  max_mem: 17449M
[01/27 03:19:04] d2.utils.events INFO:  eta: 1 day, 15:10:26  iter: 819  total_loss: 117.7  loss_mask: 11.79  loss_mask_0: 11.87  loss_mask_1: 11.66  loss_mask_2: 11.78  loss_mask_3: 11.71  loss_mask_4: 11.72  loss_mask_5: 11.67  loss_mask_6: 11.93  loss_mask_7: 11.93  loss_mask_8: 11.66  time: 2.3896  data_time: 0.4357  lr: 8.2681e-05  max_mem: 17449M
[01/27 03:19:53] d2.utils.events INFO:  eta: 1 day, 15:09:55  iter: 839  total_loss: 122.7  loss_mask: 12.37  loss_mask_0: 11.85  loss_mask_1: 12.22  loss_mask_2: 12.09  loss_mask_3: 12.17  loss_mask_4: 12.58  loss_mask_5: 12.71  loss_mask_6: 12.35  loss_mask_7: 12.53  loss_mask_8: 12.38  time: 2.3902  data_time: 0.4119  lr: 8.4433e-05  max_mem: 17449M
[01/27 03:20:41] d2.utils.events INFO:  eta: 1 day, 15:10:19  iter: 859  total_loss: 128.2  loss_mask: 13.06  loss_mask_0: 12.19  loss_mask_1: 12.48  loss_mask_2: 12.63  loss_mask_3: 12.67  loss_mask_4: 12.98  loss_mask_5: 13.2  loss_mask_6: 12.94  loss_mask_7: 12.96  loss_mask_8: 12.54  time: 2.3903  data_time: 0.4450  lr: 8.6184e-05  max_mem: 17449M
[01/27 03:21:29] d2.utils.events INFO:  eta: 1 day, 15:10:04  iter: 879  total_loss: 130  loss_mask: 12.87  loss_mask_0: 12.68  loss_mask_1: 12.77  loss_mask_2: 12.66  loss_mask_3: 12.71  loss_mask_4: 12.67  loss_mask_5: 12.83  loss_mask_6: 13.17  loss_mask_7: 12.89  loss_mask_8: 13.01  time: 2.3907  data_time: 0.4101  lr: 8.7934e-05  max_mem: 17449M
[01/27 03:22:17] d2.utils.events INFO:  eta: 1 day, 15:09:32  iter: 899  total_loss: 140.6  loss_mask: 13.77  loss_mask_0: 13.27  loss_mask_1: 13.56  loss_mask_2: 13.69  loss_mask_3: 14.08  loss_mask_4: 13.51  loss_mask_5: 14.44  loss_mask_6: 14.24  loss_mask_7: 14.22  loss_mask_8: 13.54  time: 2.3912  data_time: 0.4276  lr: 8.9683e-05  max_mem: 17449M
[01/27 03:23:05] d2.utils.events INFO:  eta: 1 day, 15:08:38  iter: 919  total_loss: 120  loss_mask: 11.95  loss_mask_0: 12.06  loss_mask_1: 12.14  loss_mask_2: 12.07  loss_mask_3: 11.9  loss_mask_4: 11.95  loss_mask_5: 12.03  loss_mask_6: 12.11  loss_mask_7: 11.88  loss_mask_8: 12.07  time: 2.3908  data_time: 0.4212  lr: 9.1431e-05  max_mem: 17449M
[01/27 03:23:53] d2.utils.events INFO:  eta: 1 day, 15:07:28  iter: 939  total_loss: 131.4  loss_mask: 13.14  loss_mask_0: 12.72  loss_mask_1: 13.1  loss_mask_2: 12.93  loss_mask_3: 12.99  loss_mask_4: 13.01  loss_mask_5: 13.29  loss_mask_6: 13.19  loss_mask_7: 12.98  loss_mask_8: 13.48  time: 2.3905  data_time: 0.3983  lr: 9.3178e-05  max_mem: 17449M
[01/27 03:24:40] d2.utils.events INFO:  eta: 1 day, 15:07:03  iter: 959  total_loss: 115.3  loss_mask: 11.65  loss_mask_0: 11.25  loss_mask_1: 11.15  loss_mask_2: 11.46  loss_mask_3: 11.32  loss_mask_4: 11.24  loss_mask_5: 11.44  loss_mask_6: 12.12  loss_mask_7: 11.91  loss_mask_8: 11.06  time: 2.3905  data_time: 0.4137  lr: 9.4923e-05  max_mem: 17449M
[01/27 03:25:29] d2.utils.events INFO:  eta: 1 day, 15:06:21  iter: 979  total_loss: 109.5  loss_mask: 10.63  loss_mask_0: 10.52  loss_mask_1: 10.44  loss_mask_2: 10.82  loss_mask_3: 11.26  loss_mask_4: 11.09  loss_mask_5: 10.82  loss_mask_6: 10.94  loss_mask_7: 10.72  loss_mask_8: 11.77  time: 2.3909  data_time: 0.4270  lr: 9.6668e-05  max_mem: 17449M
[01/27 03:26:17] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 03:26:17] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 03:26:17] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 03:34:13] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 15.10321515775092, 'error_1pix': 0.8378247715859478, 'error_3pix': 0.7358520912908191, 'mIoU': 0.5400393195975258, 'fwIoU': 3.124249857607197, 'IoU-0': nan, 'IoU-1': 19.118480667648573, 'IoU-2': 1.7207223162477865, 'IoU-3': 0.591286305761567, 'IoU-4': 0.4557068905918733, 'IoU-5': 0.3176181273680979, 'IoU-6': 0.2806076318728964, 'IoU-7': 0.23311453330037993, 'IoU-8': 0.714909679324372, 'IoU-9': 1.9260084500305739, 'IoU-10': 3.19436022632694, 'IoU-11': 5.141416662506864, 'IoU-12': 5.392003598133111, 'IoU-13': 5.0044586497361525, 'IoU-14': 4.303900410035913, 'IoU-15': 3.4489932957820937, 'IoU-16': 3.2837721294054196, 'IoU-17': 2.7237413896460847, 'IoU-18': 2.35935638841452, 'IoU-19': 2.0621545972571313, 'IoU-20': 2.0411989542997584, 'IoU-21': 1.878381544966503, 'IoU-22': 1.8563214456362924, 'IoU-23': 1.5987682941273642, 'IoU-24': 1.3033257060060701, 'IoU-25': 1.246135208183496, 'IoU-26': 1.2108710159717342, 'IoU-27': 1.252757571267991, 'IoU-28': 1.1174454633969115, 'IoU-29': 0.9922911127626057, 'IoU-30': 0.9585054606900746, 'IoU-31': 1.028796502631008, 'IoU-32': 0.9719139945808593, 'IoU-33': 0.883276674045337, 'IoU-34': 0.915858935482782, 'IoU-35': 0.8930508668579789, 'IoU-36': 0.7779599096186097, 'IoU-37': 0.7291870444394672, 'IoU-38': 0.692247712741282, 'IoU-39': 0.6975504746236131, 'IoU-40': 0.6734310642943832, 'IoU-41': 0.6365849747325203, 'IoU-42': 0.6023070056200379, 'IoU-43': 0.5717149732509911, 'IoU-44': 0.5916625092934255, 'IoU-45': 0.5203198603197117, 'IoU-46': 0.5400099878377568, 'IoU-47': 0.5926079240051665, 'IoU-48': 0.5893429123115094, 'IoU-49': 0.6264229894559111, 'IoU-50': 0.6007857096104045, 'IoU-51': 0.5982778642964028, 'IoU-52': 0.6023056669377516, 'IoU-53': 0.570818526817712, 'IoU-54': 0.5506888503402032, 'IoU-55': 0.525887073848567, 'IoU-56': 0.48900594606944847, 'IoU-57': 0.5081856935266412, 'IoU-58': 0.49662432930889855, 'IoU-59': 0.5055569738400552, 'IoU-60': 0.4844690741781425, 'IoU-61': 0.4466358026418687, 'IoU-62': 0.45598743661674523, 'IoU-63': 0.4532688956603419, 'IoU-64': 0.4301612648029028, 'IoU-65': 0.41600652590626136, 'IoU-66': 0.38193531847827056, 'IoU-67': 0.364085906564098, 'IoU-68': 0.3262421809224946, 'IoU-69': 0.29827130530829443, 'IoU-70': 0.29956999145808033, 'IoU-71': 0.25850686697753184, 'IoU-72': 0.24384797084221174, 'IoU-73': 0.21201650884728565, 'IoU-74': 0.20801893796207602, 'IoU-75': 0.19652562252997205, 'IoU-76': 0.20729014287953693, 'IoU-77': 0.1526929612299238, 'IoU-78': 0.15361308588616066, 'IoU-79': 0.12980736046739555, 'IoU-80': 0.13940194451111138, 'IoU-81': 0.1336533198428995, 'IoU-82': 0.10797512193749845, 'IoU-83': 0.10425891876086085, 'IoU-84': 0.08544808495653919, 'IoU-85': 0.08289885117966155, 'IoU-86': 0.08794999852938015, 'IoU-87': 0.08260093390176408, 'IoU-88': 0.06867251313170578, 'IoU-89': 0.055245926697577386, 'IoU-90': 0.05641649517616079, 'IoU-91': 0.0636698091653902, 'IoU-92': 0.05946426304430621, 'IoU-93': 0.045015769437606434, 'IoU-94': 0.0348114643365237, 'IoU-95': 0.025457688243423825, 'IoU-96': 0.02144686280056923, 'IoU-97': 0.014962220393506396, 'IoU-98': 0.013348894202392684, 'IoU-99': 0.010333914616030485, 'IoU-100': 0.014471834854391368, 'IoU-101': 0.013992327607568035, 'IoU-102': 0.015371900720579194, 'IoU-103': 0.012363010231734771, 'IoU-104': 0.012167581897456882, 'IoU-105': 0.0083779111091347, 'IoU-106': 0.006352983449969875, 'IoU-107': 0.0036570929450171976, 'IoU-108': 0.0034376511585290422, 'IoU-109': 0.0022854116876511125, 'IoU-110': 0.003945992710891058, 'IoU-111': 0.002196318042938327, 'IoU-112': 0.001153850464935803, 'IoU-113': 0.0007203143040014488, 'IoU-114': 0.0010103834946639122, 'IoU-115': 0.00011177601279313725, 'IoU-116': 0.00027303051389023235, 'IoU-117': 7.985335729466408e-05, 'IoU-118': 0.0, 'IoU-119': 0.0012386767856593691, 'IoU-120': 0.0006566850538481744, 'IoU-121': 0.0004984990646344823, 'IoU-122': 0.00018839851372412522, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 5.4365879104419996e-05, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.3189143483075976, 'pACC': 4.58908336175271, 'ACC-0': nan, 'ACC-1': 19.458801154601694, 'ACC-2': 8.466587827043913, 'ACC-3': 10.967161254393403, 'ACC-4': 8.354688046858342, 'ACC-5': 6.396030572420116, 'ACC-6': 6.12051317870367, 'ACC-7': 5.79852033356305, 'ACC-8': 6.980602220601022, 'ACC-9': 8.174094713543452, 'ACC-10': 8.892199927434225, 'ACC-11': 10.031806150574328, 'ACC-12': 10.146837384742769, 'ACC-13': 9.715922647802747, 'ACC-14': 8.957537562727651, 'ACC-15': 7.931710575511425, 'ACC-16': 8.03484763151923, 'ACC-17': 7.526042118373052, 'ACC-18': 6.450617251708055, 'ACC-19': 5.77639625352101, 'ACC-20': 5.830032052924275, 'ACC-21': 5.300256245129481, 'ACC-22': 5.0257033835304705, 'ACC-23': 4.590561575780526, 'ACC-24': 3.7851838116200103, 'ACC-25': 3.570402579006466, 'ACC-26': 3.354920619474476, 'ACC-27': 3.218239135748899, 'ACC-28': 2.816607736671758, 'ACC-29': 2.3174169649918253, 'ACC-30': 2.1791657071690445, 'ACC-31': 2.19328845278401, 'ACC-32': 2.0141653287205887, 'ACC-33': 1.79456482266519, 'ACC-34': 1.7796702319508066, 'ACC-35': 1.6260035925849725, 'ACC-36': 1.3476512532984568, 'ACC-37': 1.228841397810253, 'ACC-38': 1.1279038124387384, 'ACC-39': 1.1136693976662082, 'ACC-40': 1.0552960906233098, 'ACC-41': 1.009882283562563, 'ACC-42': 0.9509438754019918, 'ACC-43': 0.8972368294920904, 'ACC-44': 0.911294837502861, 'ACC-45': 0.8104774980609621, 'ACC-46': 0.8625743568428872, 'ACC-47': 0.9555363731366066, 'ACC-48': 0.9634773665282308, 'ACC-49': 1.0354756834041894, 'ACC-50': 1.0106299862645345, 'ACC-51': 1.0367281779382362, 'ACC-52': 1.063811885017152, 'ACC-53': 1.0292756814880297, 'ACC-54': 1.007182888158732, 'ACC-55': 0.987061088717623, 'ACC-56': 0.949326731119793, 'ACC-57': 0.9919296182788879, 'ACC-58': 0.9948834486337531, 'ACC-59': 1.0396106612210303, 'ACC-60': 1.0133508384887342, 'ACC-61': 0.9459204987392623, 'ACC-62': 0.9699107550316398, 'ACC-63': 0.9659334894572112, 'ACC-64': 0.9045931342096207, 'ACC-65': 0.8642322741082958, 'ACC-66': 0.7784140920536167, 'ACC-67': 0.7264995155259184, 'ACC-68': 0.632224632672947, 'ACC-69': 0.5508927566129109, 'ACC-70': 0.5315570779176493, 'ACC-71': 0.44893150530870657, 'ACC-72': 0.409551631391059, 'ACC-73': 0.3423321012530447, 'ACC-74': 0.32261518621367724, 'ACC-75': 0.29501855878148686, 'ACC-76': 0.298859295615996, 'ACC-77': 0.21577005544786096, 'ACC-78': 0.21228886192805183, 'ACC-79': 0.17532598369839253, 'ACC-80': 0.18369540709509685, 'ACC-81': 0.17282776944921813, 'ACC-82': 0.1373428242059105, 'ACC-83': 0.12988199658567276, 'ACC-84': 0.10496752131362401, 'ACC-85': 0.10047341238815649, 'ACC-86': 0.10531327467838895, 'ACC-87': 0.09765691908202986, 'ACC-88': 0.08011114510172004, 'ACC-89': 0.0636289216640334, 'ACC-90': 0.06422200962522484, 'ACC-91': 0.07186205316186231, 'ACC-92': 0.06660600457966051, 'ACC-93': 0.05003011972313721, 'ACC-94': 0.03837723299541906, 'ACC-95': 0.027859186763580963, 'ACC-96': 0.023381026297159855, 'ACC-97': 0.016196331034515822, 'ACC-98': 0.01438836192741947, 'ACC-99': 0.0111076228375811, 'ACC-100': 0.015488826555147116, 'ACC-101': 0.01491649342900523, 'ACC-102': 0.016311735387403714, 'ACC-103': 0.013034854066307737, 'ACC-104': 0.012739480091488158, 'ACC-105': 0.008708863707815324, 'ACC-106': 0.006555593927632012, 'ACC-107': 0.0037531167186663707, 'ACC-108': 0.0035098124129628702, 'ACC-109': 0.0023246485032240322, 'ACC-110': 0.004004614038008906, 'ACC-111': 0.0022250908134775317, 'ACC-112': 0.0011678041078677299, 'ACC-113': 0.0007282298293341378, 'ACC-114': 0.0010204092788731183, 'ACC-115': 0.0001127599115962293, 'ACC-116': 0.00027511786835531394, 'ACC-117': 8.036472727827975e-05, 'ACC-118': 0.0, 'ACC-119': 0.0012438147024902459, 'ACC-120': 0.000658872642553685, 'ACC-121': 0.0004996305005343775, 'ACC-122': 0.0001887023880287205, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 5.438548212186046e-05, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/27 03:34:13] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 03:34:13] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 03:34:13] d2.evaluation.testing INFO: copypaste: 15.1032,0.8378,0.7359,0.5400,3.1242,1.3189,4.5891
[01/27 03:34:14] d2.utils.events INFO:  eta: 1 day, 15:05:50  iter: 999  total_loss: 129.2  loss_mask: 12.44  loss_mask_0: 11.94  loss_mask_1: 12.66  loss_mask_2: 12.81  loss_mask_3: 12.94  loss_mask_4: 12.83  loss_mask_5: 13.1  loss_mask_6: 13  loss_mask_7: 13.04  loss_mask_8: 13.7  time: 2.3909  data_time: 0.4146  lr: 9.8412e-05  max_mem: 17449M
[01/27 03:35:02] d2.utils.events INFO:  eta: 1 day, 15:04:28  iter: 1019  total_loss: 139  loss_mask: 13.8  loss_mask_0: 12.88  loss_mask_1: 13.05  loss_mask_2: 13.67  loss_mask_3: 12.63  loss_mask_4: 13.75  loss_mask_5: 13.7  loss_mask_6: 13.63  loss_mask_7: 13.17  loss_mask_8: 14.13  time: 2.3916  data_time: 0.4454  lr: 9.847e-05  max_mem: 17449M
[01/27 03:35:51] d2.utils.events INFO:  eta: 1 day, 15:04:58  iter: 1039  total_loss: 131.6  loss_mask: 13.55  loss_mask_0: 12.96  loss_mask_1: 13.2  loss_mask_2: 13.23  loss_mask_3: 13.17  loss_mask_4: 12.95  loss_mask_5: 12.7  loss_mask_6: 13.45  loss_mask_7: 12.73  loss_mask_8: 13.16  time: 2.3924  data_time: 0.4555  lr: 9.844e-05  max_mem: 17449M
[01/27 03:36:40] d2.utils.events INFO:  eta: 1 day, 15:05:41  iter: 1059  total_loss: 123.3  loss_mask: 12.31  loss_mask_0: 12.09  loss_mask_1: 11.99  loss_mask_2: 12.32  loss_mask_3: 12.29  loss_mask_4: 12.47  loss_mask_5: 12.51  loss_mask_6: 12.26  loss_mask_7: 12.38  loss_mask_8: 12.52  time: 2.3932  data_time: 0.4545  lr: 9.841e-05  max_mem: 17449M
[01/27 03:37:28] d2.utils.events INFO:  eta: 1 day, 15:08:04  iter: 1079  total_loss: 118.3  loss_mask: 12.06  loss_mask_0: 11.7  loss_mask_1: 11.63  loss_mask_2: 11.76  loss_mask_3: 11.83  loss_mask_4: 11.81  loss_mask_5: 11.66  loss_mask_6: 11.92  loss_mask_7: 11.79  loss_mask_8: 11.96  time: 2.3935  data_time: 0.4313  lr: 9.838e-05  max_mem: 17449M
[01/27 03:38:17] d2.utils.events INFO:  eta: 1 day, 15:09:17  iter: 1099  total_loss: 145  loss_mask: 14.28  loss_mask_0: 14.12  loss_mask_1: 14.3  loss_mask_2: 14.55  loss_mask_3: 14.57  loss_mask_4: 14.39  loss_mask_5: 14.38  loss_mask_6: 14.55  loss_mask_7: 14.26  loss_mask_8: 14.49  time: 2.3944  data_time: 0.4575  lr: 9.835e-05  max_mem: 17449M
[01/27 03:39:06] d2.utils.events INFO:  eta: 1 day, 15:09:59  iter: 1119  total_loss: 112.6  loss_mask: 11.24  loss_mask_0: 11.22  loss_mask_1: 11.14  loss_mask_2: 11.39  loss_mask_3: 11.28  loss_mask_4: 11.23  loss_mask_5: 11.57  loss_mask_6: 11.35  loss_mask_7: 11.29  loss_mask_8: 11.56  time: 2.3951  data_time: 0.4576  lr: 9.832e-05  max_mem: 17449M
[01/27 03:39:54] d2.utils.events INFO:  eta: 1 day, 15:11:37  iter: 1139  total_loss: 125.7  loss_mask: 12.22  loss_mask_0: 12.35  loss_mask_1: 12.63  loss_mask_2: 12.42  loss_mask_3: 12.5  loss_mask_4: 12.36  loss_mask_5: 12.43  loss_mask_6: 12.55  loss_mask_7: 12.5  loss_mask_8: 12.31  time: 2.3953  data_time: 0.4531  lr: 9.829e-05  max_mem: 17449M
[01/27 03:40:42] d2.utils.events INFO:  eta: 1 day, 15:12:23  iter: 1159  total_loss: 114.1  loss_mask: 11.29  loss_mask_0: 10.97  loss_mask_1: 11.16  loss_mask_2: 11.34  loss_mask_3: 11.45  loss_mask_4: 11.52  loss_mask_5: 11.48  loss_mask_6: 11.56  loss_mask_7: 11.41  loss_mask_8: 11.49  time: 2.3957  data_time: 0.4359  lr: 9.826e-05  max_mem: 17449M
[01/27 03:41:31] d2.utils.events INFO:  eta: 1 day, 15:12:41  iter: 1179  total_loss: 112.2  loss_mask: 11.28  loss_mask_0: 11.23  loss_mask_1: 11.21  loss_mask_2: 11.15  loss_mask_3: 11.31  loss_mask_4: 11.42  loss_mask_5: 11.26  loss_mask_6: 11.32  loss_mask_7: 11.29  loss_mask_8: 11.15  time: 2.3960  data_time: 0.4374  lr: 9.823e-05  max_mem: 17449M
[01/27 03:42:19] d2.utils.events INFO:  eta: 1 day, 15:13:00  iter: 1199  total_loss: 125.8  loss_mask: 12.54  loss_mask_0: 12.32  loss_mask_1: 12.37  loss_mask_2: 12.64  loss_mask_3: 12.5  loss_mask_4: 12.29  loss_mask_5: 12.58  loss_mask_6: 12.6  loss_mask_7: 12.39  loss_mask_8: 12.37  time: 2.3965  data_time: 0.4317  lr: 9.82e-05  max_mem: 17449M
[01/27 03:43:08] d2.utils.events INFO:  eta: 1 day, 15:13:11  iter: 1219  total_loss: 128.6  loss_mask: 12.61  loss_mask_0: 12.76  loss_mask_1: 12.78  loss_mask_2: 12.93  loss_mask_3: 12.79  loss_mask_4: 12.89  loss_mask_5: 13.24  loss_mask_6: 12.88  loss_mask_7: 12.94  loss_mask_8: 12.8  time: 2.3971  data_time: 0.4389  lr: 9.817e-05  max_mem: 17449M
[01/27 03:43:56] d2.utils.events INFO:  eta: 1 day, 15:12:11  iter: 1239  total_loss: 110  loss_mask: 10.91  loss_mask_0: 10.81  loss_mask_1: 10.83  loss_mask_2: 10.84  loss_mask_3: 10.87  loss_mask_4: 11.23  loss_mask_5: 11.24  loss_mask_6: 11.19  loss_mask_7: 10.86  loss_mask_8: 10.81  time: 2.3973  data_time: 0.4531  lr: 9.814e-05  max_mem: 17449M
[01/27 03:44:46] d2.utils.events INFO:  eta: 1 day, 15:12:28  iter: 1259  total_loss: 106.2  loss_mask: 10.71  loss_mask_0: 10.63  loss_mask_1: 10.57  loss_mask_2: 10.6  loss_mask_3: 10.6  loss_mask_4: 10.58  loss_mask_5: 10.79  loss_mask_6: 10.79  loss_mask_7: 10.64  loss_mask_8: 10.65  time: 2.3985  data_time: 0.4854  lr: 9.811e-05  max_mem: 17449M
[01/27 03:45:34] d2.utils.events INFO:  eta: 1 day, 15:11:44  iter: 1279  total_loss: 112.8  loss_mask: 11.01  loss_mask_0: 11.31  loss_mask_1: 11.28  loss_mask_2: 11.42  loss_mask_3: 11.49  loss_mask_4: 11.35  loss_mask_5: 11.25  loss_mask_6: 11.06  loss_mask_7: 11.12  loss_mask_8: 11.21  time: 2.3991  data_time: 0.4643  lr: 9.8079e-05  max_mem: 17449M
[01/27 03:46:23] d2.utils.events INFO:  eta: 1 day, 15:11:36  iter: 1299  total_loss: 102.7  loss_mask: 10.61  loss_mask_0: 10.14  loss_mask_1: 10  loss_mask_2: 9.953  loss_mask_3: 9.961  loss_mask_4: 9.895  loss_mask_5: 9.946  loss_mask_6: 10.36  loss_mask_7: 10.77  loss_mask_8: 10.62  time: 2.3997  data_time: 0.4650  lr: 9.8049e-05  max_mem: 17449M
[01/27 03:47:11] d2.utils.events INFO:  eta: 1 day, 15:11:12  iter: 1319  total_loss: 101.9  loss_mask: 10.13  loss_mask_0: 10.03  loss_mask_1: 10.19  loss_mask_2: 10.36  loss_mask_3: 10.4  loss_mask_4: 10.42  loss_mask_5: 10.55  loss_mask_6: 10.2  loss_mask_7: 9.875  loss_mask_8: 9.922  time: 2.3995  data_time: 0.4133  lr: 9.8019e-05  max_mem: 17449M
[01/27 03:47:59] d2.utils.events INFO:  eta: 1 day, 15:11:05  iter: 1339  total_loss: 110  loss_mask: 11.38  loss_mask_0: 11  loss_mask_1: 10.91  loss_mask_2: 10.77  loss_mask_3: 10.67  loss_mask_4: 10.83  loss_mask_5: 10.98  loss_mask_6: 11.22  loss_mask_7: 11.25  loss_mask_8: 11.08  time: 2.3998  data_time: 0.4484  lr: 9.7989e-05  max_mem: 17449M
[01/27 03:48:48] d2.utils.events INFO:  eta: 1 day, 15:10:28  iter: 1359  total_loss: 101.7  loss_mask: 10.1  loss_mask_0: 10.11  loss_mask_1: 10.11  loss_mask_2: 10.17  loss_mask_3: 10.05  loss_mask_4: 9.998  loss_mask_5: 10.06  loss_mask_6: 10.03  loss_mask_7: 10.2  loss_mask_8: 10.13  time: 2.4000  data_time: 0.4623  lr: 9.7959e-05  max_mem: 17449M
[01/27 03:49:36] d2.utils.events INFO:  eta: 1 day, 15:09:33  iter: 1379  total_loss: 99.08  loss_mask: 9.904  loss_mask_0: 9.842  loss_mask_1: 9.785  loss_mask_2: 9.733  loss_mask_3: 9.822  loss_mask_4: 9.697  loss_mask_5: 9.89  loss_mask_6: 9.897  loss_mask_7: 9.896  loss_mask_8: 9.831  time: 2.3999  data_time: 0.4158  lr: 9.7929e-05  max_mem: 17449M
[01/27 03:50:25] d2.utils.events INFO:  eta: 1 day, 15:08:36  iter: 1399  total_loss: 93.42  loss_mask: 9.286  loss_mask_0: 9.452  loss_mask_1: 9.39  loss_mask_2: 9.398  loss_mask_3: 9.377  loss_mask_4: 9.228  loss_mask_5: 9.351  loss_mask_6: 9.397  loss_mask_7: 9.34  loss_mask_8: 9.362  time: 2.4007  data_time: 0.4893  lr: 9.7899e-05  max_mem: 17449M
[01/27 03:51:13] d2.utils.events INFO:  eta: 1 day, 15:07:53  iter: 1419  total_loss: 98.83  loss_mask: 9.889  loss_mask_0: 10.05  loss_mask_1: 9.851  loss_mask_2: 9.851  loss_mask_3: 9.847  loss_mask_4: 9.863  loss_mask_5: 9.857  loss_mask_6: 9.934  loss_mask_7: 9.727  loss_mask_8: 9.864  time: 2.4006  data_time: 0.4118  lr: 9.7869e-05  max_mem: 17449M
[01/27 03:52:02] d2.utils.events INFO:  eta: 1 day, 15:07:26  iter: 1439  total_loss: 122.8  loss_mask: 12.25  loss_mask_0: 12.23  loss_mask_1: 12.15  loss_mask_2: 12.17  loss_mask_3: 12.65  loss_mask_4: 12.78  loss_mask_5: 12.82  loss_mask_6: 12.93  loss_mask_7: 12.07  loss_mask_8: 12.11  time: 2.4013  data_time: 0.5260  lr: 9.7839e-05  max_mem: 17449M
[01/27 03:52:50] d2.utils.events INFO:  eta: 1 day, 15:06:17  iter: 1459  total_loss: 123.7  loss_mask: 12.23  loss_mask_0: 12.33  loss_mask_1: 12.22  loss_mask_2: 12.31  loss_mask_3: 12.31  loss_mask_4: 12.31  loss_mask_5: 12.45  loss_mask_6: 12.62  loss_mask_7: 12.45  loss_mask_8: 12.13  time: 2.4011  data_time: 0.4798  lr: 9.7809e-05  max_mem: 17449M
[01/27 03:53:38] d2.utils.events INFO:  eta: 1 day, 15:05:50  iter: 1479  total_loss: 104.4  loss_mask: 10.18  loss_mask_0: 10.5  loss_mask_1: 10.37  loss_mask_2: 10.33  loss_mask_3: 10.46  loss_mask_4: 10.52  loss_mask_5: 10.55  loss_mask_6: 10.58  loss_mask_7: 10.43  loss_mask_8: 10.41  time: 2.4012  data_time: 0.4959  lr: 9.7779e-05  max_mem: 17449M
[01/27 03:54:25] d2.utils.events INFO:  eta: 1 day, 15:04:57  iter: 1499  total_loss: 113.8  loss_mask: 11.21  loss_mask_0: 11.54  loss_mask_1: 11.5  loss_mask_2: 11.51  loss_mask_3: 11.37  loss_mask_4: 11.42  loss_mask_5: 11.34  loss_mask_6: 11.37  loss_mask_7: 11.49  loss_mask_8: 11.65  time: 2.4006  data_time: 0.4556  lr: 9.7749e-05  max_mem: 17449M
[01/27 03:55:13] d2.utils.events INFO:  eta: 1 day, 15:03:51  iter: 1519  total_loss: 111.7  loss_mask: 11.23  loss_mask_0: 11.04  loss_mask_1: 11.02  loss_mask_2: 11.16  loss_mask_3: 11.24  loss_mask_4: 11.11  loss_mask_5: 11.31  loss_mask_6: 11.25  loss_mask_7: 11.06  loss_mask_8: 11.06  time: 2.4006  data_time: 0.5105  lr: 9.7719e-05  max_mem: 17449M
[01/27 03:56:00] d2.utils.events INFO:  eta: 1 day, 15:02:11  iter: 1539  total_loss: 92.86  loss_mask: 9.29  loss_mask_0: 9.189  loss_mask_1: 9.15  loss_mask_2: 9.387  loss_mask_3: 9.373  loss_mask_4: 9.377  loss_mask_5: 9.366  loss_mask_6: 9.284  loss_mask_7: 9.277  loss_mask_8: 9.169  time: 2.3997  data_time: 0.4505  lr: 9.7689e-05  max_mem: 17449M
[01/27 03:56:46] d2.utils.events INFO:  eta: 1 day, 15:01:03  iter: 1559  total_loss: 105.4  loss_mask: 10.35  loss_mask_0: 10.38  loss_mask_1: 10.56  loss_mask_2: 10.41  loss_mask_3: 10.49  loss_mask_4: 10.47  loss_mask_5: 10.64  loss_mask_6: 10.48  loss_mask_7: 10.34  loss_mask_8: 10.3  time: 2.3985  data_time: 0.5417  lr: 9.7658e-05  max_mem: 17449M
[01/27 03:57:26] d2.utils.events INFO:  eta: 1 day, 14:58:50  iter: 1579  total_loss: 97.46  loss_mask: 9.855  loss_mask_0: 9.583  loss_mask_1: 9.666  loss_mask_2: 9.773  loss_mask_3: 9.843  loss_mask_4: 9.774  loss_mask_5: 9.748  loss_mask_6: 9.831  loss_mask_7: 9.913  loss_mask_8: 9.872  time: 2.3934  data_time: 0.4568  lr: 9.7628e-05  max_mem: 17449M
[01/27 03:58:02] d2.utils.events INFO:  eta: 1 day, 14:55:53  iter: 1599  total_loss: 106.4  loss_mask: 10.67  loss_mask_0: 10.91  loss_mask_1: 10.6  loss_mask_2: 10.96  loss_mask_3: 10.79  loss_mask_4: 10.94  loss_mask_5: 10.97  loss_mask_6: 10.73  loss_mask_7: 10.6  loss_mask_8: 10.6  time: 2.3859  data_time: 0.4307  lr: 9.7598e-05  max_mem: 17449M
[01/27 03:58:37] d2.utils.events INFO:  eta: 1 day, 14:52:44  iter: 1619  total_loss: 89.75  loss_mask: 9.037  loss_mask_0: 8.858  loss_mask_1: 8.848  loss_mask_2: 8.84  loss_mask_3: 8.797  loss_mask_4: 8.801  loss_mask_5: 8.884  loss_mask_6: 8.852  loss_mask_7: 9.01  loss_mask_8: 8.89  time: 2.3785  data_time: 0.4261  lr: 9.7568e-05  max_mem: 17449M
[01/27 03:59:13] d2.utils.events INFO:  eta: 1 day, 14:48:26  iter: 1639  total_loss: 91  loss_mask: 8.856  loss_mask_0: 9.162  loss_mask_1: 8.976  loss_mask_2: 9.081  loss_mask_3: 8.979  loss_mask_4: 9.044  loss_mask_5: 8.925  loss_mask_6: 9.449  loss_mask_7: 9.367  loss_mask_8: 8.858  time: 2.3713  data_time: 0.4494  lr: 9.7538e-05  max_mem: 17450M
[01/27 03:59:49] d2.utils.events INFO:  eta: 1 day, 14:45:47  iter: 1659  total_loss: 96.34  loss_mask: 9.988  loss_mask_0: 9.949  loss_mask_1: 9.506  loss_mask_2: 9.825  loss_mask_3: 9.752  loss_mask_4: 9.973  loss_mask_5: 9.577  loss_mask_6: 10.11  loss_mask_7: 9.879  loss_mask_8: 9.927  time: 2.3643  data_time: 0.4315  lr: 9.7508e-05  max_mem: 17450M
[01/27 04:00:25] d2.utils.events INFO:  eta: 1 day, 14:42:56  iter: 1679  total_loss: 98.97  loss_mask: 10.35  loss_mask_0: 9.41  loss_mask_1: 9.775  loss_mask_2: 10.13  loss_mask_3: 10.23  loss_mask_4: 10.2  loss_mask_5: 9.876  loss_mask_6: 9.508  loss_mask_7: 9.488  loss_mask_8: 9.384  time: 2.3575  data_time: 0.4188  lr: 9.7478e-05  max_mem: 17450M
[01/27 04:01:01] d2.utils.events INFO:  eta: 1 day, 14:39:21  iter: 1699  total_loss: 94.72  loss_mask: 9.732  loss_mask_0: 9.572  loss_mask_1: 9.369  loss_mask_2: 9.626  loss_mask_3: 9.86  loss_mask_4: 9.756  loss_mask_5: 9.445  loss_mask_6: 9.41  loss_mask_7: 9.395  loss_mask_8: 9.42  time: 2.3507  data_time: 0.4160  lr: 9.7448e-05  max_mem: 17450M
[01/27 04:01:36] d2.utils.events INFO:  eta: 1 day, 14:36:40  iter: 1719  total_loss: 90.56  loss_mask: 9.064  loss_mask_0: 9.132  loss_mask_1: 8.967  loss_mask_2: 8.854  loss_mask_3: 9.008  loss_mask_4: 9.04  loss_mask_5: 9.142  loss_mask_6: 9.185  loss_mask_7: 9.089  loss_mask_8: 9.091  time: 2.3440  data_time: 0.4206  lr: 9.7418e-05  max_mem: 17450M
[01/27 04:02:12] d2.utils.events INFO:  eta: 1 day, 14:33:58  iter: 1739  total_loss: 89.19  loss_mask: 8.906  loss_mask_0: 9.019  loss_mask_1: 8.909  loss_mask_2: 8.902  loss_mask_3: 8.941  loss_mask_4: 8.941  loss_mask_5: 8.932  loss_mask_6: 8.932  loss_mask_7: 8.892  loss_mask_8: 8.873  time: 2.3373  data_time: 0.4091  lr: 9.7388e-05  max_mem: 17450M
[01/27 04:02:47] d2.utils.events INFO:  eta: 1 day, 14:29:34  iter: 1759  total_loss: 89.6  loss_mask: 9.013  loss_mask_0: 8.999  loss_mask_1: 8.995  loss_mask_2: 8.928  loss_mask_3: 8.988  loss_mask_4: 8.954  loss_mask_5: 8.953  loss_mask_6: 8.988  loss_mask_7: 8.983  loss_mask_8: 8.984  time: 2.3307  data_time: 0.3974  lr: 9.7358e-05  max_mem: 17450M
[01/27 04:03:22] d2.utils.events INFO:  eta: 1 day, 14:26:55  iter: 1779  total_loss: 87.57  loss_mask: 8.818  loss_mask_0: 8.751  loss_mask_1: 8.736  loss_mask_2: 8.725  loss_mask_3: 8.907  loss_mask_4: 8.86  loss_mask_5: 8.849  loss_mask_6: 8.877  loss_mask_7: 8.748  loss_mask_8: 8.763  time: 2.3244  data_time: 0.4073  lr: 9.7328e-05  max_mem: 17450M
[01/27 04:03:58] d2.utils.events INFO:  eta: 1 day, 14:22:54  iter: 1799  total_loss: 85.22  loss_mask: 8.489  loss_mask_0: 8.484  loss_mask_1: 8.489  loss_mask_2: 8.632  loss_mask_3: 8.475  loss_mask_4: 8.545  loss_mask_5: 8.54  loss_mask_6: 8.614  loss_mask_7: 8.423  loss_mask_8: 8.414  time: 2.3184  data_time: 0.4292  lr: 9.7297e-05  max_mem: 17450M
[01/27 04:04:33] d2.utils.events INFO:  eta: 1 day, 14:17:53  iter: 1819  total_loss: 96.96  loss_mask: 9.425  loss_mask_0: 9.647  loss_mask_1: 9.521  loss_mask_2: 9.841  loss_mask_3: 9.547  loss_mask_4: 9.583  loss_mask_5: 9.629  loss_mask_6: 9.624  loss_mask_7: 9.821  loss_mask_8: 9.69  time: 2.3123  data_time: 0.4058  lr: 9.7267e-05  max_mem: 17450M
[01/27 04:05:09] d2.utils.events INFO:  eta: 1 day, 14:12:28  iter: 1839  total_loss: 85.29  loss_mask: 8.669  loss_mask_0: 8.523  loss_mask_1: 8.504  loss_mask_2: 8.57  loss_mask_3: 8.567  loss_mask_4: 8.58  loss_mask_5: 8.484  loss_mask_6: 8.53  loss_mask_7: 8.539  loss_mask_8: 8.624  time: 2.3065  data_time: 0.4153  lr: 9.7237e-05  max_mem: 17450M
[01/27 04:05:45] d2.utils.events INFO:  eta: 1 day, 14:08:33  iter: 1859  total_loss: 84.25  loss_mask: 8.474  loss_mask_0: 8.574  loss_mask_1: 8.313  loss_mask_2: 8.253  loss_mask_3: 8.216  loss_mask_4: 8.424  loss_mask_5: 8.39  loss_mask_6: 8.26  loss_mask_7: 8.404  loss_mask_8: 8.43  time: 2.3009  data_time: 0.4227  lr: 9.7207e-05  max_mem: 17450M
[01/27 04:06:20] d2.utils.events INFO:  eta: 1 day, 14:04:27  iter: 1879  total_loss: 89.83  loss_mask: 9  loss_mask_0: 8.943  loss_mask_1: 8.908  loss_mask_2: 8.988  loss_mask_3: 8.984  loss_mask_4: 9.206  loss_mask_5: 9.1  loss_mask_6: 9.126  loss_mask_7: 8.928  loss_mask_8: 8.952  time: 2.2952  data_time: 0.4131  lr: 9.7177e-05  max_mem: 17450M
[01/27 04:06:55] d2.utils.events INFO:  eta: 1 day, 13:59:14  iter: 1899  total_loss: 77.91  loss_mask: 7.76  loss_mask_0: 8.08  loss_mask_1: 7.734  loss_mask_2: 7.702  loss_mask_3: 7.844  loss_mask_4: 7.699  loss_mask_5: 7.91  loss_mask_6: 7.823  loss_mask_7: 7.783  loss_mask_8: 7.812  time: 2.2897  data_time: 0.4346  lr: 9.7147e-05  max_mem: 17450M
[01/27 04:07:31] d2.utils.events INFO:  eta: 1 day, 13:53:37  iter: 1919  total_loss: 89.49  loss_mask: 8.988  loss_mask_0: 8.991  loss_mask_1: 8.794  loss_mask_2: 8.676  loss_mask_3: 8.733  loss_mask_4: 8.725  loss_mask_5: 8.651  loss_mask_6: 8.874  loss_mask_7: 8.907  loss_mask_8: 9.043  time: 2.2843  data_time: 0.4225  lr: 9.7117e-05  max_mem: 17450M
[01/27 04:08:06] d2.utils.events INFO:  eta: 1 day, 13:48:56  iter: 1939  total_loss: 75.67  loss_mask: 7.627  loss_mask_0: 7.531  loss_mask_1: 7.512  loss_mask_2: 7.535  loss_mask_3: 7.68  loss_mask_4: 7.629  loss_mask_5: 7.667  loss_mask_6: 7.53  loss_mask_7: 7.6  loss_mask_8: 7.844  time: 2.2788  data_time: 0.4048  lr: 9.7087e-05  max_mem: 17450M
[01/27 04:08:42] d2.utils.events INFO:  eta: 1 day, 13:39:00  iter: 1959  total_loss: 89.23  loss_mask: 8.822  loss_mask_0: 9.011  loss_mask_1: 8.897  loss_mask_2: 8.752  loss_mask_3: 9.01  loss_mask_4: 8.915  loss_mask_5: 9.001  loss_mask_6: 8.934  loss_mask_7: 8.786  loss_mask_8: 8.85  time: 2.2739  data_time: 0.4295  lr: 9.7057e-05  max_mem: 17450M
[01/27 04:09:18] d2.utils.events INFO:  eta: 1 day, 13:26:50  iter: 1979  total_loss: 85.94  loss_mask: 8.661  loss_mask_0: 8.644  loss_mask_1: 8.53  loss_mask_2: 8.56  loss_mask_3: 8.561  loss_mask_4: 8.578  loss_mask_5: 8.588  loss_mask_6: 8.636  loss_mask_7: 8.603  loss_mask_8: 8.582  time: 2.2690  data_time: 0.4037  lr: 9.7027e-05  max_mem: 17450M
[01/27 04:09:53] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 04:09:54] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 04:09:54] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 04:17:20] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 8.089227131459639, 'error_1pix': 0.7643680479924668, 'error_3pix': 0.5836035692238182, 'mIoU': 1.5176939378978944, 'fwIoU': 6.065492396499616, 'IoU-0': nan, 'IoU-1': 33.267059296656136, 'IoU-2': 1.6720663454710287, 'IoU-3': 0.6882701148099852, 'IoU-4': 0.6313422109566216, 'IoU-5': 0.5956269561010703, 'IoU-6': 0.52607014752281, 'IoU-7': 0.4068104990331422, 'IoU-8': 0.9299672376106173, 'IoU-9': 2.0833203056751946, 'IoU-10': 5.059931100346673, 'IoU-11': 8.708127081504893, 'IoU-12': 9.324262226446464, 'IoU-13': 8.086712298934485, 'IoU-14': 7.526943387037231, 'IoU-15': 5.77370292129836, 'IoU-16': 5.368189549235887, 'IoU-17': 4.174877733562706, 'IoU-18': 3.9607797171819827, 'IoU-19': 3.4544257545354164, 'IoU-20': 3.4733819522548157, 'IoU-21': 3.063995573073604, 'IoU-22': 3.4923401727344254, 'IoU-23': 3.0340364960251307, 'IoU-24': 2.9419145134532028, 'IoU-25': 2.850733565403943, 'IoU-26': 2.9162589494807305, 'IoU-27': 3.2623651607217004, 'IoU-28': 3.1749190438477064, 'IoU-29': 3.0204370787689045, 'IoU-30': 2.8805563138908323, 'IoU-31': 3.0358274192049297, 'IoU-32': 2.8969405143152134, 'IoU-33': 2.639572526324598, 'IoU-34': 2.4847601471086627, 'IoU-35': 2.466950855082584, 'IoU-36': 2.5409656346092886, 'IoU-37': 2.530866931569852, 'IoU-38': 2.4082533266038633, 'IoU-39': 2.3165157426308447, 'IoU-40': 2.2582535818641523, 'IoU-41': 2.1113030647330335, 'IoU-42': 1.9657958558319581, 'IoU-43': 1.7997761212341687, 'IoU-44': 1.8865597947910941, 'IoU-45': 1.809759872488783, 'IoU-46': 1.7165844213622643, 'IoU-47': 1.6747258998059698, 'IoU-48': 1.6478578817002927, 'IoU-49': 1.7213806082538938, 'IoU-50': 1.6626725491264365, 'IoU-51': 1.6202288462975736, 'IoU-52': 1.721677212700786, 'IoU-53': 1.7381732081075296, 'IoU-54': 1.7609779242939783, 'IoU-55': 1.6740724590415084, 'IoU-56': 1.8026500228704647, 'IoU-57': 1.8469358125379962, 'IoU-58': 1.8594828754073842, 'IoU-59': 1.9260589243450583, 'IoU-60': 1.8824418004943297, 'IoU-61': 1.937829771498731, 'IoU-62': 2.006265519592431, 'IoU-63': 2.0364864469953496, 'IoU-64': 2.0262192606770935, 'IoU-65': 2.1043804894777987, 'IoU-66': 2.0316079576735566, 'IoU-67': 2.004501027795378, 'IoU-68': 1.9889021176935953, 'IoU-69': 1.9532919815932768, 'IoU-70': 1.9744183181431847, 'IoU-71': 1.9196720099800013, 'IoU-72': 1.893081817024456, 'IoU-73': 1.8960869672229923, 'IoU-74': 1.8315232573501454, 'IoU-75': 1.8351857499950095, 'IoU-76': 1.916668646439461, 'IoU-77': 1.894999058368962, 'IoU-78': 1.802352197877368, 'IoU-79': 1.777759445405184, 'IoU-80': 1.7427466612240234, 'IoU-81': 1.7672766746996045, 'IoU-82': 1.6667634101383717, 'IoU-83': 1.6644644289627888, 'IoU-84': 1.601823737297605, 'IoU-85': 1.6526534974983205, 'IoU-86': 1.6376071883294898, 'IoU-87': 1.5782696723773117, 'IoU-88': 1.5308187825419661, 'IoU-89': 1.452342653319121, 'IoU-90': 1.3354946198217796, 'IoU-91': 1.2749253815188837, 'IoU-92': 1.2502803547436663, 'IoU-93': 1.2553070847913723, 'IoU-94': 1.2896580207718822, 'IoU-95': 1.1570108569319526, 'IoU-96': 1.1447372888593514, 'IoU-97': 1.1768510678332864, 'IoU-98': 1.2295615109324904, 'IoU-99': 1.1742351557129382, 'IoU-100': 1.0316476853592598, 'IoU-101': 0.937002243642358, 'IoU-102': 0.9365312228844249, 'IoU-103': 0.9373966581009008, 'IoU-104': 0.8923552343058823, 'IoU-105': 0.8966314193405144, 'IoU-106': 0.9426535066656422, 'IoU-107': 0.8996443899218057, 'IoU-108': 0.8194401833454755, 'IoU-109': 0.8138483507414853, 'IoU-110': 0.7492967581082277, 'IoU-111': 0.8039293467466515, 'IoU-112': 0.6858189845730875, 'IoU-113': 0.6649285821194384, 'IoU-114': 0.7186976018220395, 'IoU-115': 0.7311550972254455, 'IoU-116': 0.68799901252124, 'IoU-117': 0.7379898620923939, 'IoU-118': 0.6902150838072151, 'IoU-119': 0.640300913542363, 'IoU-120': 0.665438489775401, 'IoU-121': 0.7209720536766386, 'IoU-122': 0.6106105675202932, 'IoU-123': 0.562776500426519, 'IoU-124': 0.5154401302380434, 'IoU-125': 0.5786653303254616, 'IoU-126': 0.5340831040675155, 'IoU-127': 0.41631994342484907, 'IoU-128': 0.4026363281254415, 'IoU-129': 0.38724751586620193, 'IoU-130': 0.3996616003967443, 'IoU-131': 0.3627220137968504, 'IoU-132': 0.3563663899265019, 'IoU-133': 0.3382576188215153, 'IoU-134': 0.33963307522686914, 'IoU-135': 0.35748110501680863, 'IoU-136': 0.3428965314099735, 'IoU-137': 0.3386805373041712, 'IoU-138': 0.3806040039722081, 'IoU-139': 0.36097876556664665, 'IoU-140': 0.2998881677471277, 'IoU-141': 0.27721435616474266, 'IoU-142': 0.2667958539757718, 'IoU-143': 0.2609886503845918, 'IoU-144': 0.16895714897135572, 'IoU-145': 0.17287520146755192, 'IoU-146': 0.1437104445193424, 'IoU-147': 0.14745223262436863, 'IoU-148': 0.1298099366178021, 'IoU-149': 0.13277252027924138, 'IoU-150': 0.12212523859824688, 'IoU-151': 0.12806348890817273, 'IoU-152': 0.1706338072525094, 'IoU-153': 0.21973666873815337, 'IoU-154': 0.17455653638684043, 'IoU-155': 0.19627407326962062, 'IoU-156': 0.15084215233268744, 'IoU-157': 0.08878425928021871, 'IoU-158': 0.06080963308463417, 'IoU-159': 0.04126154529777082, 'IoU-160': 0.03806648769669896, 'IoU-161': 0.019840325063885847, 'IoU-162': 0.02640204700126112, 'IoU-163': 0.03704271777789997, 'IoU-164': 0.033956724708625756, 'IoU-165': 0.03197823066863162, 'IoU-166': 0.02825016559065989, 'IoU-167': 0.025947025099201926, 'IoU-168': 0.03254678600488201, 'IoU-169': 0.057429741195650155, 'IoU-170': 0.04871694939590983, 'IoU-171': 0.045795835774002876, 'IoU-172': 0.03165120373484204, 'IoU-173': 0.044288444575124965, 'IoU-174': 0.05725962391586312, 'IoU-175': 0.022573240151968876, 'IoU-176': 0.01665484709775858, 'IoU-177': 0.013498698470086702, 'IoU-178': 0.059993274639276103, 'IoU-179': 0.1095809032195913, 'IoU-180': 0.08563153255257525, 'IoU-181': 0.1142286504297117, 'IoU-182': 0.12034432635493553, 'IoU-183': 0.06218642787078364, 'IoU-184': 0.012942577314250484, 'IoU-185': 0.01845209950294657, 'IoU-186': 0.005659843410998963, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.950229235575696, 'pACC': 8.683597954635184, 'ACC-0': nan, 'ACC-1': 33.50066532185394, 'ACC-2': 9.102389447028058, 'ACC-3': 10.516786789631913, 'ACC-4': 7.572374711191747, 'ACC-5': 6.4102341539321035, 'ACC-6': 5.252510619363718, 'ACC-7': 3.9915989367404316, 'ACC-8': 3.579800281378287, 'ACC-9': 4.270455158985345, 'ACC-10': 8.703391764158743, 'ACC-11': 13.406532850920705, 'ACC-12': 15.76016177872967, 'ACC-13': 15.001943585135136, 'ACC-14': 14.934780798182404, 'ACC-15': 12.48316054696509, 'ACC-16': 11.949605188544249, 'ACC-17': 10.062551714277008, 'ACC-18': 9.024883927189654, 'ACC-19': 7.740484605038929, 'ACC-20': 7.681102593991038, 'ACC-21': 6.581404071978506, 'ACC-22': 7.104579443491693, 'ACC-23': 6.49197983140986, 'ACC-24': 6.433430865353023, 'ACC-25': 6.303634849774179, 'ACC-26': 6.42994192521817, 'ACC-27': 6.938679302470686, 'ACC-28': 6.915817165301871, 'ACC-29': 6.418806101129661, 'ACC-30': 6.247976033004732, 'ACC-31': 6.470447410288231, 'ACC-32': 6.2650848829949295, 'ACC-33': 5.81815524745183, 'ACC-34': 5.411273586948609, 'ACC-35': 5.15269595109613, 'ACC-36': 5.140786035084596, 'ACC-37': 5.067328437324545, 'ACC-38': 4.6981293702123965, 'ACC-39': 4.460582395639704, 'ACC-40': 4.279783877230636, 'ACC-41': 4.082755723146532, 'ACC-42': 3.75253039505431, 'ACC-43': 3.3646463022115873, 'ACC-44': 3.368903811858158, 'ACC-45': 3.186053746188476, 'ACC-46': 3.024002008226321, 'ACC-47': 2.902798031237996, 'ACC-48': 2.8199046220051036, 'ACC-49': 2.900680372427094, 'ACC-50': 2.7838500388196676, 'ACC-51': 2.7259552789365022, 'ACC-52': 2.882729159829169, 'ACC-53': 2.913615557683271, 'ACC-54': 2.9496682476773306, 'ACC-55': 2.8360594293548274, 'ACC-56': 3.106764959019494, 'ACC-57': 3.1682542611462585, 'ACC-58': 3.24867902540876, 'ACC-59': 3.442169125546806, 'ACC-60': 3.427129896525713, 'ACC-61': 3.5969586040001706, 'ACC-62': 3.7913601813640576, 'ACC-63': 3.926947158412613, 'ACC-64': 3.956881770624477, 'ACC-65': 4.177177062813104, 'ACC-66': 4.089911370706258, 'ACC-67': 4.099715113581082, 'ACC-68': 4.106962884943833, 'ACC-69': 3.9929397601259775, 'ACC-70': 4.029224466557856, 'ACC-71': 3.9948464833092325, 'ACC-72': 3.952792425833915, 'ACC-73': 3.9325651504992774, 'ACC-74': 3.7586951257624084, 'ACC-75': 3.7446477653567225, 'ACC-76': 3.8107499113557424, 'ACC-77': 3.7928633666634717, 'ACC-78': 3.6122604221641152, 'ACC-79': 3.5379627367961692, 'ACC-80': 3.4256008720776903, 'ACC-81': 3.4399573636840084, 'ACC-82': 3.2339413981447747, 'ACC-83': 3.173628189579635, 'ACC-84': 3.0371056501788076, 'ACC-85': 3.1094796815032173, 'ACC-86': 3.0609153278188437, 'ACC-87': 2.9364243913754575, 'ACC-88': 2.824112675433227, 'ACC-89': 2.643995670773248, 'ACC-90': 2.395090155716879, 'ACC-91': 2.27913338799984, 'ACC-92': 2.2266796864057343, 'ACC-93': 2.224027392227152, 'ACC-94': 2.269943389019854, 'ACC-95': 2.0259452448932693, 'ACC-96': 2.015647635277306, 'ACC-97': 2.0559410316583486, 'ACC-98': 2.1517190481872923, 'ACC-99': 2.0745414055925337, 'ACC-100': 1.8250460001930022, 'ACC-101': 1.664822523819104, 'ACC-102': 1.6666742183960126, 'ACC-103': 1.6640455275337678, 'ACC-104': 1.581146553208234, 'ACC-105': 1.582127266379623, 'ACC-106': 1.6471060855053983, 'ACC-107': 1.5644513487287268, 'ACC-108': 1.4069096875520772, 'ACC-109': 1.388382143864558, 'ACC-110': 1.289847038798688, 'ACC-111': 1.3788668395969639, 'ACC-112': 1.1827186346167835, 'ACC-113': 1.1400264590171325, 'ACC-114': 1.2337112613461312, 'ACC-115': 1.2469366890683025, 'ACC-116': 1.169801176246795, 'ACC-117': 1.243041419176792, 'ACC-118': 1.1658074053920378, 'ACC-119': 1.073412088249082, 'ACC-120': 1.1071256637043754, 'ACC-121': 1.1916641647290844, 'ACC-122': 1.0037551775217715, 'ACC-123': 0.9231865379567331, 'ACC-124': 0.8568532007601083, 'ACC-125': 0.9501687581510241, 'ACC-126': 0.8750648913013779, 'ACC-127': 0.6752936668878319, 'ACC-128': 0.651854941693469, 'ACC-129': 0.6238237806068052, 'ACC-130': 0.6361523360411512, 'ACC-131': 0.5714711044564644, 'ACC-132': 0.5507132732153089, 'ACC-133': 0.5162383392190084, 'ACC-134': 0.5106074967686342, 'ACC-135': 0.5296163274613762, 'ACC-136': 0.49829074263883716, 'ACC-137': 0.48488151199381474, 'ACC-138': 0.5341460009645405, 'ACC-139': 0.4931326260316638, 'ACC-140': 0.396894417140008, 'ACC-141': 0.3559773049740885, 'ACC-142': 0.33570263942270323, 'ACC-143': 0.32160581855824627, 'ACC-144': 0.20415162454873645, 'ACC-145': 0.20483463404816746, 'ACC-146': 0.16833062986909142, 'ACC-147': 0.17047622850128555, 'ACC-148': 0.14828178481841658, 'ACC-149': 0.15100363159170405, 'ACC-150': 0.13737623891374792, 'ACC-151': 0.14281405503456845, 'ACC-152': 0.18839773416953268, 'ACC-153': 0.24253833892156326, 'ACC-154': 0.19127194079376095, 'ACC-155': 0.21384745466064195, 'ACC-156': 0.16353494024187656, 'ACC-157': 0.09608932768774507, 'ACC-158': 0.06548575896442176, 'ACC-159': 0.04423185430707681, 'ACC-160': 0.04057707098583903, 'ACC-161': 0.021062859999382157, 'ACC-162': 0.027967783493652202, 'ACC-163': 0.03913373802102521, 'ACC-164': 0.035832178564746846, 'ACC-165': 0.03366928503590861, 'ACC-166': 0.029715187482687127, 'ACC-167': 0.027272711480769266, 'ACC-168': 0.0341092903861031, 'ACC-169': 0.059835793736719, 'ACC-170': 0.05057711146130584, 'ACC-171': 0.04739084034246311, 'ACC-172': 0.03259621439419195, 'ACC-173': 0.045342855960233755, 'ACC-174': 0.058343165927591104, 'ACC-175': 0.022925645107316053, 'ACC-176': 0.016869401807384082, 'ACC-177': 0.013656437256975396, 'ACC-178': 0.06065159905816179, 'ACC-179': 0.1107772464347378, 'ACC-180': 0.08635578583765112, 'ACC-181': 0.11487963693297425, 'ACC-182': 0.12082759797104402, 'ACC-183': 0.06238993473777392, 'ACC-184': 0.012971361592034169, 'ACC-185': 0.01847677469420938, 'ACC-186': 0.005665548507718129, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/27 04:17:20] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 04:17:20] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 04:17:20] d2.evaluation.testing INFO: copypaste: 8.0892,0.7644,0.5836,1.5177,6.0655,2.9502,8.6836
[01/27 04:17:20] d2.utils.events INFO:  eta: 1 day, 13:12:21  iter: 1999  total_loss: 74.74  loss_mask: 7.446  loss_mask_0: 7.478  loss_mask_1: 7.462  loss_mask_2: 7.45  loss_mask_3: 7.492  loss_mask_4: 7.483  loss_mask_5: 7.498  loss_mask_6: 7.481  loss_mask_7: 7.459  loss_mask_8: 7.475  time: 2.2642  data_time: 0.4434  lr: 9.6996e-05  max_mem: 17450M
[01/27 04:17:56] d2.utils.events INFO:  eta: 1 day, 12:54:42  iter: 2019  total_loss: 79.21  loss_mask: 8  loss_mask_0: 7.968  loss_mask_1: 7.926  loss_mask_2: 7.9  loss_mask_3: 7.874  loss_mask_4: 7.933  loss_mask_5: 7.854  loss_mask_6: 7.947  loss_mask_7: 7.924  loss_mask_8: 7.886  time: 2.2593  data_time: 0.4150  lr: 9.6966e-05  max_mem: 17450M
[01/27 04:18:31] d2.utils.events INFO:  eta: 1 day, 12:24:47  iter: 2039  total_loss: 85.07  loss_mask: 8.601  loss_mask_0: 8.454  loss_mask_1: 8.555  loss_mask_2: 8.494  loss_mask_3: 8.514  loss_mask_4: 8.454  loss_mask_5: 8.533  loss_mask_6: 8.493  loss_mask_7: 8.527  loss_mask_8: 8.489  time: 2.2545  data_time: 0.4182  lr: 9.6936e-05  max_mem: 17450M
[01/27 04:19:07] d2.utils.events INFO:  eta: 1 day, 11:20:51  iter: 2059  total_loss: 82.28  loss_mask: 8.291  loss_mask_0: 8.271  loss_mask_1: 8.115  loss_mask_2: 8.094  loss_mask_3: 8.307  loss_mask_4: 8.175  loss_mask_5: 8.277  loss_mask_6: 8.274  loss_mask_7: 8.245  loss_mask_8: 8.228  time: 2.2500  data_time: 0.4207  lr: 9.6906e-05  max_mem: 17450M
[01/27 04:19:43] d2.utils.events INFO:  eta: 1 day, 6:41:32  iter: 2079  total_loss: 86.98  loss_mask: 8.66  loss_mask_0: 8.667  loss_mask_1: 8.666  loss_mask_2: 8.646  loss_mask_3: 8.784  loss_mask_4: 8.57  loss_mask_5: 8.607  loss_mask_6: 8.735  loss_mask_7: 8.773  loss_mask_8: 8.693  time: 2.2456  data_time: 0.4262  lr: 9.6876e-05  max_mem: 17451M
[01/27 04:20:19] d2.utils.events INFO:  eta: 1 day, 6:11:04  iter: 2099  total_loss: 87.88  loss_mask: 8.657  loss_mask_0: 8.766  loss_mask_1: 8.779  loss_mask_2: 8.77  loss_mask_3: 8.788  loss_mask_4: 8.571  loss_mask_5: 8.582  loss_mask_6: 8.567  loss_mask_7: 8.808  loss_mask_8: 8.776  time: 2.2413  data_time: 0.4272  lr: 9.6846e-05  max_mem: 17451M
[01/27 04:20:55] d2.utils.events INFO:  eta: 1 day, 5:52:26  iter: 2119  total_loss: 81.33  loss_mask: 8.234  loss_mask_0: 8.234  loss_mask_1: 8.133  loss_mask_2: 8.18  loss_mask_3: 8.221  loss_mask_4: 8.224  loss_mask_5: 8.191  loss_mask_6: 8.032  loss_mask_7: 7.999  loss_mask_8: 7.929  time: 2.2370  data_time: 0.4147  lr: 9.6816e-05  max_mem: 17451M
[01/27 04:21:31] d2.utils.events INFO:  eta: 1 day, 5:39:17  iter: 2139  total_loss: 79.18  loss_mask: 7.882  loss_mask_0: 7.936  loss_mask_1: 7.818  loss_mask_2: 7.879  loss_mask_3: 7.938  loss_mask_4: 7.938  loss_mask_5: 7.985  loss_mask_6: 7.88  loss_mask_7: 7.799  loss_mask_8: 7.809  time: 2.2329  data_time: 0.4448  lr: 9.6786e-05  max_mem: 17451M
[01/27 04:22:06] d2.utils.events INFO:  eta: 1 day, 5:30:25  iter: 2159  total_loss: 78.28  loss_mask: 7.896  loss_mask_0: 7.765  loss_mask_1: 7.668  loss_mask_2: 7.8  loss_mask_3: 7.921  loss_mask_4: 7.831  loss_mask_5: 7.834  loss_mask_6: 7.778  loss_mask_7: 7.825  loss_mask_8: 7.792  time: 2.2285  data_time: 0.4141  lr: 9.6756e-05  max_mem: 17451M
[01/27 04:22:42] d2.utils.events INFO:  eta: 1 day, 5:23:16  iter: 2179  total_loss: 76.49  loss_mask: 7.911  loss_mask_0: 7.742  loss_mask_1: 7.75  loss_mask_2: 7.655  loss_mask_3: 7.668  loss_mask_4: 7.63  loss_mask_5: 7.732  loss_mask_6: 7.677  loss_mask_7: 7.644  loss_mask_8: 7.707  time: 2.2244  data_time: 0.4185  lr: 9.6725e-05  max_mem: 17451M
[01/27 04:23:18] d2.utils.events INFO:  eta: 1 day, 5:20:23  iter: 2199  total_loss: 82.1  loss_mask: 8.214  loss_mask_0: 8.222  loss_mask_1: 8.071  loss_mask_2: 8.093  loss_mask_3: 8.095  loss_mask_4: 8.265  loss_mask_5: 8.312  loss_mask_6: 8.341  loss_mask_7: 8.318  loss_mask_8: 8.298  time: 2.2205  data_time: 0.4218  lr: 9.6695e-05  max_mem: 17451M
[01/27 04:23:53] d2.utils.events INFO:  eta: 1 day, 5:16:03  iter: 2219  total_loss: 80.9  loss_mask: 8.078  loss_mask_0: 8.177  loss_mask_1: 8.016  loss_mask_2: 8.011  loss_mask_3: 8.184  loss_mask_4: 8.155  loss_mask_5: 8.137  loss_mask_6: 8.27  loss_mask_7: 8.109  loss_mask_8: 8.034  time: 2.2166  data_time: 0.4322  lr: 9.6665e-05  max_mem: 17451M
[01/27 04:24:29] d2.utils.events INFO:  eta: 1 day, 5:10:30  iter: 2239  total_loss: 86.68  loss_mask: 8.504  loss_mask_0: 8.584  loss_mask_1: 8.52  loss_mask_2: 8.561  loss_mask_3: 8.66  loss_mask_4: 8.764  loss_mask_5: 8.598  loss_mask_6: 8.819  loss_mask_7: 8.545  loss_mask_8: 8.419  time: 2.2126  data_time: 0.4230  lr: 9.6635e-05  max_mem: 17451M
[01/27 04:25:04] d2.utils.events INFO:  eta: 1 day, 5:03:56  iter: 2259  total_loss: 75.62  loss_mask: 7.676  loss_mask_0: 7.755  loss_mask_1: 7.489  loss_mask_2: 7.446  loss_mask_3: 7.523  loss_mask_4: 7.5  loss_mask_5: 7.558  loss_mask_6: 7.501  loss_mask_7: 7.591  loss_mask_8: 7.612  time: 2.2088  data_time: 0.4340  lr: 9.6605e-05  max_mem: 17451M
[01/27 04:25:40] d2.utils.events INFO:  eta: 1 day, 5:00:08  iter: 2279  total_loss: 74.11  loss_mask: 7.461  loss_mask_0: 7.452  loss_mask_1: 7.248  loss_mask_2: 7.308  loss_mask_3: 7.43  loss_mask_4: 7.502  loss_mask_5: 7.55  loss_mask_6: 7.48  loss_mask_7: 7.353  loss_mask_8: 7.35  time: 2.2049  data_time: 0.4185  lr: 9.6575e-05  max_mem: 17451M
[01/27 04:26:16] d2.utils.events INFO:  eta: 1 day, 4:55:55  iter: 2299  total_loss: 84.95  loss_mask: 8.416  loss_mask_0: 8.559  loss_mask_1: 8.451  loss_mask_2: 8.429  loss_mask_3: 8.567  loss_mask_4: 8.582  loss_mask_5: 8.556  loss_mask_6: 8.559  loss_mask_7: 8.371  loss_mask_8: 8.301  time: 2.2013  data_time: 0.4297  lr: 9.6545e-05  max_mem: 17451M
[01/27 04:26:52] d2.utils.events INFO:  eta: 1 day, 4:52:57  iter: 2319  total_loss: 72.94  loss_mask: 7.286  loss_mask_0: 7.288  loss_mask_1: 7.228  loss_mask_2: 7.285  loss_mask_3: 7.268  loss_mask_4: 7.269  loss_mask_5: 7.259  loss_mask_6: 7.287  loss_mask_7: 7.263  loss_mask_8: 7.266  time: 2.1978  data_time: 0.4428  lr: 9.6515e-05  max_mem: 17458M
[01/27 04:27:27] d2.utils.events INFO:  eta: 1 day, 4:50:25  iter: 2339  total_loss: 71.43  loss_mask: 7.104  loss_mask_0: 7.078  loss_mask_1: 7.068  loss_mask_2: 7.105  loss_mask_3: 7.141  loss_mask_4: 7.149  loss_mask_5: 7.182  loss_mask_6: 7.158  loss_mask_7: 7.063  loss_mask_8: 7.073  time: 2.1943  data_time: 0.4370  lr: 9.6485e-05  max_mem: 17458M
[01/27 04:28:03] d2.utils.events INFO:  eta: 1 day, 4:46:29  iter: 2359  total_loss: 82.18  loss_mask: 8.097  loss_mask_0: 8.55  loss_mask_1: 8.152  loss_mask_2: 8.035  loss_mask_3: 8.186  loss_mask_4: 8.305  loss_mask_5: 8.376  loss_mask_6: 8.225  loss_mask_7: 8.108  loss_mask_8: 8.146  time: 2.1907  data_time: 0.4000  lr: 9.6454e-05  max_mem: 17458M
[01/27 04:28:38] d2.utils.events INFO:  eta: 1 day, 4:43:36  iter: 2379  total_loss: 70.09  loss_mask: 6.992  loss_mask_0: 6.993  loss_mask_1: 7.012  loss_mask_2: 7.019  loss_mask_3: 6.977  loss_mask_4: 7.024  loss_mask_5: 6.962  loss_mask_6: 7.014  loss_mask_7: 6.974  loss_mask_8: 6.976  time: 2.1870  data_time: 0.4238  lr: 9.6424e-05  max_mem: 17458M
[01/27 04:29:14] d2.utils.events INFO:  eta: 1 day, 4:39:50  iter: 2399  total_loss: 76.32  loss_mask: 7.59  loss_mask_0: 7.695  loss_mask_1: 7.529  loss_mask_2: 7.43  loss_mask_3: 7.556  loss_mask_4: 7.732  loss_mask_5: 7.545  loss_mask_6: 7.707  loss_mask_7: 7.542  loss_mask_8: 7.565  time: 2.1837  data_time: 0.4520  lr: 9.6394e-05  max_mem: 17458M
[01/27 04:29:49] d2.utils.events INFO:  eta: 1 day, 4:36:58  iter: 2419  total_loss: 74.86  loss_mask: 7.46  loss_mask_0: 7.61  loss_mask_1: 7.404  loss_mask_2: 7.481  loss_mask_3: 7.472  loss_mask_4: 7.626  loss_mask_5: 7.427  loss_mask_6: 7.523  loss_mask_7: 7.46  loss_mask_8: 7.501  time: 2.1802  data_time: 0.3958  lr: 9.6364e-05  max_mem: 17458M
[01/27 04:30:24] d2.utils.events INFO:  eta: 1 day, 4:33:32  iter: 2439  total_loss: 76.43  loss_mask: 7.631  loss_mask_0: 7.893  loss_mask_1: 7.641  loss_mask_2: 7.613  loss_mask_3: 7.623  loss_mask_4: 7.636  loss_mask_5: 7.733  loss_mask_6: 7.625  loss_mask_7: 7.576  loss_mask_8: 7.706  time: 2.1767  data_time: 0.4128  lr: 9.6334e-05  max_mem: 17458M
[01/27 04:30:59] d2.utils.events INFO:  eta: 1 day, 4:30:27  iter: 2459  total_loss: 75.32  loss_mask: 7.502  loss_mask_0: 7.551  loss_mask_1: 7.512  loss_mask_2: 7.446  loss_mask_3: 7.537  loss_mask_4: 7.583  loss_mask_5: 7.436  loss_mask_6: 7.591  loss_mask_7: 7.451  loss_mask_8: 7.522  time: 2.1734  data_time: 0.4049  lr: 9.6304e-05  max_mem: 17458M
[01/27 04:31:35] d2.utils.events INFO:  eta: 1 day, 4:27:39  iter: 2479  total_loss: 78.85  loss_mask: 8.062  loss_mask_0: 7.894  loss_mask_1: 7.893  loss_mask_2: 7.932  loss_mask_3: 7.863  loss_mask_4: 7.578  loss_mask_5: 7.892  loss_mask_6: 7.819  loss_mask_7: 8.002  loss_mask_8: 7.978  time: 2.1701  data_time: 0.4168  lr: 9.6274e-05  max_mem: 17458M
[01/27 04:32:10] d2.utils.events INFO:  eta: 1 day, 4:24:27  iter: 2499  total_loss: 75.74  loss_mask: 7.498  loss_mask_0: 7.533  loss_mask_1: 7.456  loss_mask_2: 7.368  loss_mask_3: 7.489  loss_mask_4: 7.392  loss_mask_5: 7.743  loss_mask_6: 7.398  loss_mask_7: 7.604  loss_mask_8: 7.629  time: 2.1669  data_time: 0.4077  lr: 9.6244e-05  max_mem: 17458M
[01/27 04:32:46] d2.utils.events INFO:  eta: 1 day, 4:21:40  iter: 2519  total_loss: 69.02  loss_mask: 7.047  loss_mask_0: 7.01  loss_mask_1: 6.816  loss_mask_2: 6.897  loss_mask_3: 7.161  loss_mask_4: 7.101  loss_mask_5: 6.889  loss_mask_6: 7.069  loss_mask_7: 6.949  loss_mask_8: 6.969  time: 2.1638  data_time: 0.4258  lr: 9.6213e-05  max_mem: 17458M
[01/27 04:33:21] d2.utils.events INFO:  eta: 1 day, 4:20:14  iter: 2539  total_loss: 66.89  loss_mask: 7.031  loss_mask_0: 6.711  loss_mask_1: 6.51  loss_mask_2: 6.719  loss_mask_3: 6.707  loss_mask_4: 6.56  loss_mask_5: 6.502  loss_mask_6: 6.485  loss_mask_7: 6.67  loss_mask_8: 6.848  time: 2.1608  data_time: 0.4148  lr: 9.6183e-05  max_mem: 17458M
[01/27 04:33:57] d2.utils.events INFO:  eta: 1 day, 4:18:00  iter: 2559  total_loss: 67.65  loss_mask: 7.022  loss_mask_0: 7.015  loss_mask_1: 6.698  loss_mask_2: 7.044  loss_mask_3: 7.131  loss_mask_4: 7.114  loss_mask_5: 6.831  loss_mask_6: 6.84  loss_mask_7: 6.717  loss_mask_8: 6.793  time: 2.1577  data_time: 0.4242  lr: 9.6153e-05  max_mem: 17458M
[01/27 04:34:32] d2.utils.events INFO:  eta: 1 day, 4:16:32  iter: 2579  total_loss: 78.79  loss_mask: 8.041  loss_mask_0: 8.308  loss_mask_1: 7.726  loss_mask_2: 7.801  loss_mask_3: 7.864  loss_mask_4: 7.928  loss_mask_5: 7.804  loss_mask_6: 7.723  loss_mask_7: 7.761  loss_mask_8: 7.841  time: 2.1548  data_time: 0.3963  lr: 9.6123e-05  max_mem: 17458M
[01/27 04:35:08] d2.utils.events INFO:  eta: 1 day, 4:15:43  iter: 2599  total_loss: 70.7  loss_mask: 7.306  loss_mask_0: 7.135  loss_mask_1: 7.016  loss_mask_2: 7.086  loss_mask_3: 7.053  loss_mask_4: 7.272  loss_mask_5: 7.048  loss_mask_6: 7.067  loss_mask_7: 7.022  loss_mask_8: 6.99  time: 2.1518  data_time: 0.4089  lr: 9.6093e-05  max_mem: 17458M
[01/27 04:35:43] d2.utils.events INFO:  eta: 1 day, 4:15:11  iter: 2619  total_loss: 72.06  loss_mask: 7.361  loss_mask_0: 7.3  loss_mask_1: 7.139  loss_mask_2: 7.11  loss_mask_3: 7.163  loss_mask_4: 7.175  loss_mask_5: 7.159  loss_mask_6: 7.177  loss_mask_7: 7.166  loss_mask_8: 7.077  time: 2.1489  data_time: 0.4178  lr: 9.6063e-05  max_mem: 17458M
[01/27 04:36:19] d2.utils.events INFO:  eta: 1 day, 4:14:19  iter: 2639  total_loss: 75.52  loss_mask: 7.624  loss_mask_0: 7.675  loss_mask_1: 7.51  loss_mask_2: 7.333  loss_mask_3: 7.422  loss_mask_4: 7.341  loss_mask_5: 7.432  loss_mask_6: 7.486  loss_mask_7: 7.585  loss_mask_8: 7.39  time: 2.1460  data_time: 0.4154  lr: 9.6033e-05  max_mem: 17458M
[01/27 04:36:54] d2.utils.events INFO:  eta: 1 day, 4:13:32  iter: 2659  total_loss: 71.39  loss_mask: 6.945  loss_mask_0: 7.407  loss_mask_1: 7.118  loss_mask_2: 6.993  loss_mask_3: 7.153  loss_mask_4: 7.081  loss_mask_5: 7.13  loss_mask_6: 7.237  loss_mask_7: 7.07  loss_mask_8: 7.203  time: 2.1432  data_time: 0.4091  lr: 9.6003e-05  max_mem: 17458M
[01/27 04:37:30] d2.utils.events INFO:  eta: 1 day, 4:13:04  iter: 2679  total_loss: 62.13  loss_mask: 6.216  loss_mask_0: 6.261  loss_mask_1: 6.215  loss_mask_2: 6.191  loss_mask_3: 6.223  loss_mask_4: 6.222  loss_mask_5: 6.228  loss_mask_6: 6.23  loss_mask_7: 6.207  loss_mask_8: 6.214  time: 2.1406  data_time: 0.4285  lr: 9.5972e-05  max_mem: 17458M
[01/27 04:38:05] d2.utils.events INFO:  eta: 1 day, 4:11:39  iter: 2699  total_loss: 62.17  loss_mask: 6.201  loss_mask_0: 6.23  loss_mask_1: 6.192  loss_mask_2: 6.224  loss_mask_3: 6.229  loss_mask_4: 6.212  loss_mask_5: 6.191  loss_mask_6: 6.226  loss_mask_7: 6.24  loss_mask_8: 6.215  time: 2.1376  data_time: 0.4060  lr: 9.5942e-05  max_mem: 17458M
[01/27 04:38:40] d2.utils.events INFO:  eta: 1 day, 4:11:00  iter: 2719  total_loss: 64.57  loss_mask: 6.512  loss_mask_0: 6.458  loss_mask_1: 6.458  loss_mask_2: 6.445  loss_mask_3: 6.415  loss_mask_4: 6.497  loss_mask_5: 6.452  loss_mask_6: 6.404  loss_mask_7: 6.471  loss_mask_8: 6.461  time: 2.1348  data_time: 0.4016  lr: 9.5912e-05  max_mem: 17458M
[01/27 04:39:15] d2.utils.events INFO:  eta: 1 day, 4:10:14  iter: 2739  total_loss: 70.14  loss_mask: 7.004  loss_mask_0: 7.161  loss_mask_1: 6.972  loss_mask_2: 7.009  loss_mask_3: 7.008  loss_mask_4: 7.044  loss_mask_5: 7.028  loss_mask_6: 7.077  loss_mask_7: 7.003  loss_mask_8: 7.015  time: 2.1320  data_time: 0.4032  lr: 9.5882e-05  max_mem: 17458M
[01/27 04:39:51] d2.utils.events INFO:  eta: 1 day, 4:09:35  iter: 2759  total_loss: 65.63  loss_mask: 6.504  loss_mask_0: 6.709  loss_mask_1: 6.548  loss_mask_2: 6.569  loss_mask_3: 6.514  loss_mask_4: 6.641  loss_mask_5: 6.528  loss_mask_6: 6.494  loss_mask_7: 6.601  loss_mask_8: 6.576  time: 2.1294  data_time: 0.3935  lr: 9.5852e-05  max_mem: 17458M
[01/27 04:40:26] d2.utils.events INFO:  eta: 1 day, 4:08:22  iter: 2779  total_loss: 64.12  loss_mask: 6.361  loss_mask_0: 6.458  loss_mask_1: 6.412  loss_mask_2: 6.406  loss_mask_3: 6.379  loss_mask_4: 6.457  loss_mask_5: 6.398  loss_mask_6: 6.38  loss_mask_7: 6.429  loss_mask_8: 6.438  time: 2.1268  data_time: 0.4061  lr: 9.5822e-05  max_mem: 17458M
[01/27 04:41:01] d2.utils.events INFO:  eta: 1 day, 4:07:34  iter: 2799  total_loss: 63.59  loss_mask: 6.366  loss_mask_0: 6.428  loss_mask_1: 6.35  loss_mask_2: 6.36  loss_mask_3: 6.345  loss_mask_4: 6.34  loss_mask_5: 6.378  loss_mask_6: 6.394  loss_mask_7: 6.371  loss_mask_8: 6.345  time: 2.1241  data_time: 0.3987  lr: 9.5792e-05  max_mem: 17458M
[01/27 04:41:37] d2.utils.events INFO:  eta: 1 day, 4:07:11  iter: 2819  total_loss: 59.9  loss_mask: 5.984  loss_mask_0: 6.019  loss_mask_1: 5.992  loss_mask_2: 5.981  loss_mask_3: 6.004  loss_mask_4: 5.983  loss_mask_5: 5.983  loss_mask_6: 6.007  loss_mask_7: 5.99  loss_mask_8: 6.006  time: 2.1216  data_time: 0.4045  lr: 9.5761e-05  max_mem: 17458M
[01/27 04:42:12] d2.utils.events INFO:  eta: 1 day, 4:06:14  iter: 2839  total_loss: 64.58  loss_mask: 6.472  loss_mask_0: 6.598  loss_mask_1: 6.442  loss_mask_2: 6.437  loss_mask_3: 6.474  loss_mask_4: 6.527  loss_mask_5: 6.453  loss_mask_6: 6.47  loss_mask_7: 6.439  loss_mask_8: 6.477  time: 2.1191  data_time: 0.4168  lr: 9.5731e-05  max_mem: 17458M
[01/27 04:42:47] d2.utils.events INFO:  eta: 1 day, 4:04:36  iter: 2859  total_loss: 60.32  loss_mask: 6.004  loss_mask_0: 6.07  loss_mask_1: 6.04  loss_mask_2: 6.025  loss_mask_3: 6.017  loss_mask_4: 6.042  loss_mask_5: 6.025  loss_mask_6: 6.03  loss_mask_7: 6.019  loss_mask_8: 6.024  time: 2.1165  data_time: 0.3952  lr: 9.5701e-05  max_mem: 17458M
[01/27 04:43:23] d2.utils.events INFO:  eta: 1 day, 4:04:59  iter: 2879  total_loss: 67.11  loss_mask: 6.739  loss_mask_0: 6.999  loss_mask_1: 6.683  loss_mask_2: 6.682  loss_mask_3: 6.675  loss_mask_4: 6.679  loss_mask_5: 6.719  loss_mask_6: 6.69  loss_mask_7: 6.682  loss_mask_8: 6.7  time: 2.1145  data_time: 0.4530  lr: 9.5671e-05  max_mem: 17458M
[01/27 04:43:59] d2.utils.events INFO:  eta: 1 day, 4:04:43  iter: 2899  total_loss: 64.89  loss_mask: 6.19  loss_mask_0: 6.714  loss_mask_1: 6.44  loss_mask_2: 6.41  loss_mask_3: 6.446  loss_mask_4: 6.449  loss_mask_5: 6.515  loss_mask_6: 6.491  loss_mask_7: 6.343  loss_mask_8: 6.234  time: 2.1122  data_time: 0.4360  lr: 9.5641e-05  max_mem: 17458M
[01/27 04:44:35] d2.utils.events INFO:  eta: 1 day, 4:04:41  iter: 2919  total_loss: 61.2  loss_mask: 6.169  loss_mask_0: 6.215  loss_mask_1: 6.083  loss_mask_2: 6.095  loss_mask_3: 6.132  loss_mask_4: 6.093  loss_mask_5: 6.101  loss_mask_6: 6.145  loss_mask_7: 6.137  loss_mask_8: 6.13  time: 2.1100  data_time: 0.4205  lr: 9.5611e-05  max_mem: 17458M
[01/27 04:45:11] d2.utils.events INFO:  eta: 1 day, 4:04:31  iter: 2939  total_loss: 65.04  loss_mask: 6.386  loss_mask_0: 6.569  loss_mask_1: 6.483  loss_mask_2: 6.454  loss_mask_3: 6.47  loss_mask_4: 6.664  loss_mask_5: 6.653  loss_mask_6: 6.579  loss_mask_7: 6.507  loss_mask_8: 6.492  time: 2.1078  data_time: 0.4169  lr: 9.5581e-05  max_mem: 17458M
[01/27 04:45:46] d2.utils.events INFO:  eta: 1 day, 4:03:48  iter: 2959  total_loss: 63.45  loss_mask: 6.37  loss_mask_0: 6.399  loss_mask_1: 6.341  loss_mask_2: 6.314  loss_mask_3: 6.346  loss_mask_4: 6.322  loss_mask_5: 6.346  loss_mask_6: 6.384  loss_mask_7: 6.312  loss_mask_8: 6.317  time: 2.1056  data_time: 0.4104  lr: 9.555e-05  max_mem: 17458M
[01/27 04:46:22] d2.utils.events INFO:  eta: 1 day, 4:02:40  iter: 2979  total_loss: 59.08  loss_mask: 5.897  loss_mask_0: 5.915  loss_mask_1: 5.921  loss_mask_2: 5.92  loss_mask_3: 5.907  loss_mask_4: 5.909  loss_mask_5: 5.915  loss_mask_6: 5.892  loss_mask_7: 5.915  loss_mask_8: 5.903  time: 2.1033  data_time: 0.4309  lr: 9.552e-05  max_mem: 17458M
[01/27 04:46:58] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 04:46:58] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 04:46:58] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 04:54:20] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 5.42337332665126, 'error_1pix': 0.6810823836083395, 'error_3pix': 0.4408057220444043, 'mIoU': 2.539093371639246, 'fwIoU': 6.4104052674386045, 'IoU-0': nan, 'IoU-1': 22.626543820120943, 'IoU-2': 2.208881480797646, 'IoU-3': 1.2571044009563448, 'IoU-4': 0.9863084678771364, 'IoU-5': 0.8523532887489409, 'IoU-6': 0.8028611527650886, 'IoU-7': 0.6966650394601216, 'IoU-8': 1.8726832085371452, 'IoU-9': 3.6214291850221305, 'IoU-10': 7.10785046520372, 'IoU-11': 10.956815231692927, 'IoU-12': 11.640549137704472, 'IoU-13': 9.835026876909664, 'IoU-14': 8.5444139688934, 'IoU-15': 6.874801500898004, 'IoU-16': 6.510949535199684, 'IoU-17': 5.0056065972423065, 'IoU-18': 5.067209730006182, 'IoU-19': 4.55185454395997, 'IoU-20': 4.639974154538167, 'IoU-21': 4.371665264708205, 'IoU-22': 4.703584770399978, 'IoU-23': 4.460793693165069, 'IoU-24': 4.700841962476375, 'IoU-25': 4.755029903199145, 'IoU-26': 4.782022155703112, 'IoU-27': 5.53072767014934, 'IoU-28': 5.65371616803935, 'IoU-29': 5.440906114634235, 'IoU-30': 5.335552132879379, 'IoU-31': 5.460977645591844, 'IoU-32': 5.334241431390133, 'IoU-33': 4.895121031356072, 'IoU-34': 4.61889767871985, 'IoU-35': 4.750350481718712, 'IoU-36': 4.751644809731502, 'IoU-37': 4.401430934249272, 'IoU-38': 4.407805076936387, 'IoU-39': 4.296837111638601, 'IoU-40': 4.209818426790942, 'IoU-41': 3.8441248823484764, 'IoU-42': 3.843255527086584, 'IoU-43': 3.9283522160236855, 'IoU-44': 3.962636455345884, 'IoU-45': 3.8873658343073156, 'IoU-46': 3.5960981337005102, 'IoU-47': 3.6083436829402245, 'IoU-48': 3.5536023461910218, 'IoU-49': 3.588577758642439, 'IoU-50': 3.63704008945092, 'IoU-51': 3.523228264158542, 'IoU-52': 3.4397518485979015, 'IoU-53': 3.375860564984703, 'IoU-54': 3.3309454298260524, 'IoU-55': 3.3065707428983617, 'IoU-56': 3.338076801864863, 'IoU-57': 3.38461601519831, 'IoU-58': 3.3422356262745554, 'IoU-59': 3.1944238152421063, 'IoU-60': 3.13507001884949, 'IoU-61': 2.9302688826609393, 'IoU-62': 2.920891185982944, 'IoU-63': 2.847190919600403, 'IoU-64': 2.7810022539522246, 'IoU-65': 2.795112628905528, 'IoU-66': 2.8638178462721884, 'IoU-67': 2.7463737535121178, 'IoU-68': 2.6103176496101126, 'IoU-69': 2.665600099132084, 'IoU-70': 2.7154694324730513, 'IoU-71': 2.652382508454396, 'IoU-72': 2.651605823373461, 'IoU-73': 2.7030283643451387, 'IoU-74': 2.697759658776312, 'IoU-75': 2.7056591516129997, 'IoU-76': 2.677137237176976, 'IoU-77': 2.7142050097304953, 'IoU-78': 2.7342060154056376, 'IoU-79': 2.703055534590108, 'IoU-80': 2.66550030702423, 'IoU-81': 2.6963053755004505, 'IoU-82': 2.712230852179503, 'IoU-83': 2.689025831424477, 'IoU-84': 2.6637595766334456, 'IoU-85': 2.730484378601939, 'IoU-86': 2.6763584727314873, 'IoU-87': 2.635635134421924, 'IoU-88': 2.6802268565788454, 'IoU-89': 2.555031949381793, 'IoU-90': 2.5565736460295394, 'IoU-91': 2.4308761945177175, 'IoU-92': 2.3522292599150787, 'IoU-93': 2.378566773538164, 'IoU-94': 2.3742180055927355, 'IoU-95': 2.3659580539919793, 'IoU-96': 2.2207839481382705, 'IoU-97': 2.251877056104433, 'IoU-98': 2.273458951721147, 'IoU-99': 2.228864154983375, 'IoU-100': 2.1043741531025253, 'IoU-101': 2.055596477501886, 'IoU-102': 1.9229891173754885, 'IoU-103': 2.012703022965674, 'IoU-104': 2.036264119344529, 'IoU-105': 1.9854879126506735, 'IoU-106': 2.068117152214779, 'IoU-107': 2.0067481694215803, 'IoU-108': 1.9393114909381937, 'IoU-109': 2.0963737449437296, 'IoU-110': 2.0514652917441105, 'IoU-111': 1.990072819659129, 'IoU-112': 1.839755599439634, 'IoU-113': 1.8056132692216948, 'IoU-114': 1.8283097984851875, 'IoU-115': 1.8219946658802075, 'IoU-116': 1.8334422606037182, 'IoU-117': 1.8780156000001724, 'IoU-118': 1.9374667591487402, 'IoU-119': 1.9516937912347512, 'IoU-120': 1.8599411931382703, 'IoU-121': 1.808706511661588, 'IoU-122': 1.868103468337655, 'IoU-123': 1.7997146973565274, 'IoU-124': 1.7719203838244193, 'IoU-125': 1.6476955767720805, 'IoU-126': 1.6883848926385638, 'IoU-127': 1.6824818101673602, 'IoU-128': 1.5044537477876132, 'IoU-129': 1.4650253489537064, 'IoU-130': 1.5312614225763317, 'IoU-131': 1.6923723711006433, 'IoU-132': 1.569494605298265, 'IoU-133': 1.5600646984793847, 'IoU-134': 1.4185115909493144, 'IoU-135': 1.3231680088459283, 'IoU-136': 1.3655266344419652, 'IoU-137': 1.3514059099234008, 'IoU-138': 1.3841944920199463, 'IoU-139': 1.3267380233411872, 'IoU-140': 1.3979392557638097, 'IoU-141': 1.442956195007231, 'IoU-142': 1.4276945408139945, 'IoU-143': 1.3551401196259636, 'IoU-144': 1.3425756384237502, 'IoU-145': 1.1956019297434655, 'IoU-146': 1.2141070071347497, 'IoU-147': 1.1963074702063954, 'IoU-148': 1.2204709187684455, 'IoU-149': 1.0587718472142882, 'IoU-150': 1.0919207072840351, 'IoU-151': 1.057118233519062, 'IoU-152': 0.9659559215517884, 'IoU-153': 0.8989732119178312, 'IoU-154': 0.8861922727101487, 'IoU-155': 0.8108918121455075, 'IoU-156': 0.9307367562540523, 'IoU-157': 0.9837573301666198, 'IoU-158': 0.9407847800237812, 'IoU-159': 0.7750156944723098, 'IoU-160': 0.8068173700395226, 'IoU-161': 0.8744042212265644, 'IoU-162': 0.8464745644959563, 'IoU-163': 0.7523341933540135, 'IoU-164': 0.7881950210250661, 'IoU-165': 0.7429014369024918, 'IoU-166': 0.6949424268860276, 'IoU-167': 0.6227333489552916, 'IoU-168': 0.6353886232008422, 'IoU-169': 0.5264947456780679, 'IoU-170': 0.483634948379258, 'IoU-171': 0.4075820074641524, 'IoU-172': 0.3759439462127734, 'IoU-173': 0.30413934634647277, 'IoU-174': 0.33927794693344937, 'IoU-175': 0.3961875015913701, 'IoU-176': 0.32070178291894524, 'IoU-177': 0.28357379624839535, 'IoU-178': 0.394125418241484, 'IoU-179': 0.2778515417538817, 'IoU-180': 0.29816807187398114, 'IoU-181': 0.11498649604154351, 'IoU-182': 0.10250423209386492, 'IoU-183': 0.035847633590629334, 'IoU-184': 0.014032954053769604, 'IoU-185': 0.011029563826707169, 'IoU-186': 0.007756894233571838, 'IoU-187': 0.00771236726292906, 'IoU-188': 0.004282363965670556, 'IoU-189': 0.0020526768188641, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 4.889410328514972, 'pACC': 10.111156015184331, 'ACC-0': nan, 'ACC-1': 22.865382800260708, 'ACC-2': 6.405941223803946, 'ACC-3': 10.251622757659716, 'ACC-4': 7.218496601348733, 'ACC-5': 6.294711690967943, 'ACC-6': 6.139484027407702, 'ACC-7': 5.833342449070377, 'ACC-8': 6.951287355632618, 'ACC-9': 7.702000312577797, 'ACC-10': 12.864540148697495, 'ACC-11': 17.423488880481994, 'ACC-12': 19.719315218298533, 'ACC-13': 17.654969193168018, 'ACC-14': 15.76367323108504, 'ACC-15': 13.439500666733064, 'ACC-16': 12.863562108703727, 'ACC-17': 10.520848618100759, 'ACC-18': 10.026141845891603, 'ACC-19': 8.813373101590894, 'ACC-20': 8.82350840096011, 'ACC-21': 8.10732448262201, 'ACC-22': 8.35828682425884, 'ACC-23': 8.359236766359121, 'ACC-24': 9.023329577208845, 'ACC-25': 9.27079428060663, 'ACC-26': 9.41683309601155, 'ACC-27': 10.652451387144332, 'ACC-28': 11.231539532704051, 'ACC-29': 10.568103435900412, 'ACC-30': 10.543339433382469, 'ACC-31': 10.589773583897482, 'ACC-32': 10.529535932250168, 'ACC-33': 9.87146193831351, 'ACC-34': 9.264126251973162, 'ACC-35': 9.308774086589388, 'ACC-36': 9.228614370869188, 'ACC-37': 8.624359939640211, 'ACC-38': 8.510887078582428, 'ACC-39': 8.267428290422856, 'ACC-40': 8.073662646512938, 'ACC-41': 7.595015960078759, 'ACC-42': 7.561937343595222, 'ACC-43': 7.67464152668135, 'ACC-44': 7.5038518392747635, 'ACC-45': 7.396137408711402, 'ACC-46': 6.9869074343468425, 'ACC-47': 6.9719568096519895, 'ACC-48': 6.844483328493473, 'ACC-49': 6.841626408509584, 'ACC-50': 6.88955142963091, 'ACC-51': 6.733449011367096, 'ACC-52': 6.54676744006171, 'ACC-53': 6.407607753700852, 'ACC-54': 6.272725907960801, 'ACC-55': 6.257292479942018, 'ACC-56': 6.397742254543864, 'ACC-57': 6.420126597221206, 'ACC-58': 6.406148395228173, 'ACC-59': 6.228923113393892, 'ACC-60': 6.160502761703494, 'ACC-61': 5.816170696397282, 'ACC-62': 5.8224262770386455, 'ACC-63': 5.724769687767001, 'ACC-64': 5.588331197403907, 'ACC-65': 5.650444362123106, 'ACC-66': 5.808164328252586, 'ACC-67': 5.617825599064528, 'ACC-68': 5.358661727729721, 'ACC-69': 5.36816975335024, 'ACC-70': 5.422405353759268, 'ACC-71': 5.374211577550558, 'ACC-72': 5.366188782187488, 'ACC-73': 5.406000877763286, 'ACC-74': 5.34665201643478, 'ACC-75': 5.3466872110939905, 'ACC-76': 5.189586449650274, 'ACC-77': 5.324398477929253, 'ACC-78': 5.372885901752373, 'ACC-79': 5.297370845363952, 'ACC-80': 5.172133720790722, 'ACC-81': 5.201475429271692, 'ACC-82': 5.2370066622577145, 'ACC-83': 5.126944348513797, 'ACC-84': 5.077717363011714, 'ACC-85': 5.193730144291949, 'ACC-86': 5.087754144909216, 'ACC-87': 5.016142387752046, 'ACC-88': 5.091054473316352, 'ACC-89': 4.811210068078846, 'ACC-90': 4.757834824638742, 'ACC-91': 4.528847014792343, 'ACC-92': 4.379984696545233, 'ACC-93': 4.40203178857236, 'ACC-94': 4.367554147782149, 'ACC-95': 4.3323396365399205, 'ACC-96': 4.092445647024107, 'ACC-97': 4.11491245506417, 'ACC-98': 4.152261003802174, 'ACC-99': 4.095434535604945, 'ACC-100': 3.869449465473297, 'ACC-101': 3.801019136098602, 'ACC-102': 3.5589941096511097, 'ACC-103': 3.718475488807028, 'ACC-104': 3.7479894739430906, 'ACC-105': 3.641837381252345, 'ACC-106': 3.77460609402767, 'ACC-107': 3.662552380455074, 'ACC-108': 3.50237824336376, 'ACC-109': 3.750962106811929, 'ACC-110': 3.694211285243238, 'ACC-111': 3.5778833494574074, 'ACC-112': 3.3459255981993126, 'ACC-113': 3.2909052763718893, 'ACC-114': 3.3735824055201222, 'ACC-115': 3.3809180160269423, 'ACC-116': 3.43225261794303, 'ACC-117': 3.502455544241988, 'ACC-118': 3.650968196206318, 'ACC-119': 3.676287358939618, 'ACC-120': 3.5175892640656135, 'ACC-121': 3.4602137419281287, 'ACC-122': 3.5976110277675564, 'ACC-123': 3.493503648338461, 'ACC-124': 3.501356613203019, 'ACC-125': 3.2480641487638726, 'ACC-126': 3.355449503183089, 'ACC-127': 3.319463783420086, 'ACC-128': 2.976493216781255, 'ACC-129': 2.8758270010711873, 'ACC-130': 2.988123092639362, 'ACC-131': 3.2932526003297635, 'ACC-132': 3.0159543987694906, 'ACC-133': 2.9571944722284598, 'ACC-134': 2.663127962085308, 'ACC-135': 2.4831822587081698, 'ACC-136': 2.532583628401044, 'ACC-137': 2.5291993616324624, 'ACC-138': 2.6078286417747543, 'ACC-139': 2.5081307445031906, 'ACC-140': 2.6204804807789466, 'ACC-141': 2.6953288708534537, 'ACC-142': 2.6731326977340073, 'ACC-143': 2.536902897327859, 'ACC-144': 2.4915162454873645, 'ACC-145': 2.177061204409759, 'ACC-146': 2.201366201366201, 'ACC-147': 2.142095093423016, 'ACC-148': 2.1603515418929313, 'ACC-149': 1.9040249718833064, 'ACC-150': 1.9534942865868468, 'ACC-151': 1.8772587801334992, 'ACC-152': 1.678193910580619, 'ACC-153': 1.591500393924403, 'ACC-154': 1.5467312928644645, 'ACC-155': 1.4206373270423973, 'ACC-156': 1.6405204677228569, 'ACC-157': 1.7498873740528873, 'ACC-158': 1.6749676452365463, 'ACC-159': 1.3581447572493457, 'ACC-160': 1.3732581550015837, 'ACC-161': 1.443648424357653, 'ACC-162': 1.388421932692851, 'ACC-163': 1.1986235930580418, 'ACC-164': 1.211634993769006, 'ACC-165': 1.1050513456596798, 'ACC-166': 1.0217323786419992, 'ACC-167': 0.890966478884494, 'ACC-168': 0.8722484000281314, 'ACC-169': 0.6955691682473728, 'ACC-170': 0.6152661243380609, 'ACC-171': 0.5031208555442485, 'ACC-172': 0.4472719191021225, 'ACC-173': 0.3488201450218812, 'ACC-174': 0.37801897923691613, 'ACC-175': 0.43151980387480376, 'ACC-176': 0.3433727072208034, 'ACC-177': 0.3004416196534587, 'ACC-178': 0.41432382159158293, 'ACC-179': 0.28871827751040846, 'ACC-180': 0.3058919661550121, 'ACC-181': 0.11748515447166025, 'ACC-182': 0.10400650099860456, 'ACC-183': 0.036256536182375086, 'ACC-184': 0.014150442790939001, 'ACC-185': 0.011086372077124195, 'ACC-186': 0.007790533793210904, 'ACC-187': 0.007731616270219989, 'ACC-188': 0.004287559016988822, 'ACC-189': 0.002053804544556006, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/27 04:54:20] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 04:54:20] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 04:54:20] d2.evaluation.testing INFO: copypaste: 5.4234,0.6811,0.4408,2.5391,6.4104,4.8894,10.1112
[01/27 04:54:21] d2.utils.events INFO:  eta: 1 day, 4:02:05  iter: 2999  total_loss: 67.02  loss_mask: 6.699  loss_mask_0: 6.834  loss_mask_1: 6.701  loss_mask_2: 6.71  loss_mask_3: 6.727  loss_mask_4: 6.708  loss_mask_5: 6.695  loss_mask_6: 6.7  loss_mask_7: 6.713  loss_mask_8: 6.681  time: 2.1012  data_time: 0.4446  lr: 9.549e-05  max_mem: 17458M
[01/27 04:54:57] d2.utils.events INFO:  eta: 1 day, 4:01:44  iter: 3019  total_loss: 67.02  loss_mask: 6.776  loss_mask_0: 6.776  loss_mask_1: 6.584  loss_mask_2: 6.544  loss_mask_3: 6.846  loss_mask_4: 6.687  loss_mask_5: 6.621  loss_mask_6: 6.743  loss_mask_7: 6.71  loss_mask_8: 6.737  time: 2.0992  data_time: 0.4289  lr: 9.546e-05  max_mem: 17458M
[01/27 04:55:32] d2.utils.events INFO:  eta: 1 day, 4:01:20  iter: 3039  total_loss: 56.33  loss_mask: 5.623  loss_mask_0: 5.664  loss_mask_1: 5.61  loss_mask_2: 5.617  loss_mask_3: 5.649  loss_mask_4: 5.631  loss_mask_5: 5.592  loss_mask_6: 5.631  loss_mask_7: 5.631  loss_mask_8: 5.581  time: 2.0971  data_time: 0.4059  lr: 9.543e-05  max_mem: 17458M
[01/27 04:56:08] d2.utils.events INFO:  eta: 1 day, 4:00:14  iter: 3059  total_loss: 57.11  loss_mask: 5.704  loss_mask_0: 5.703  loss_mask_1: 5.708  loss_mask_2: 5.713  loss_mask_3: 5.683  loss_mask_4: 5.723  loss_mask_5: 5.658  loss_mask_6: 5.717  loss_mask_7: 5.705  loss_mask_8: 5.704  time: 2.0950  data_time: 0.4222  lr: 9.54e-05  max_mem: 17458M
[01/27 04:56:43] d2.utils.events INFO:  eta: 1 day, 3:59:12  iter: 3079  total_loss: 58.24  loss_mask: 5.768  loss_mask_0: 6.024  loss_mask_1: 5.784  loss_mask_2: 5.774  loss_mask_3: 5.846  loss_mask_4: 5.763  loss_mask_5: 5.853  loss_mask_6: 5.808  loss_mask_7: 5.806  loss_mask_8: 5.777  time: 2.0930  data_time: 0.4163  lr: 9.5369e-05  max_mem: 17458M
[01/27 04:57:19] d2.utils.events INFO:  eta: 1 day, 3:58:20  iter: 3099  total_loss: 63.87  loss_mask: 6.436  loss_mask_0: 6.559  loss_mask_1: 6.324  loss_mask_2: 6.327  loss_mask_3: 6.496  loss_mask_4: 6.427  loss_mask_5: 6.492  loss_mask_6: 6.419  loss_mask_7: 6.467  loss_mask_8: 6.404  time: 2.0908  data_time: 0.4090  lr: 9.5339e-05  max_mem: 17458M
[01/27 04:57:54] d2.utils.events INFO:  eta: 1 day, 3:57:30  iter: 3119  total_loss: 67.38  loss_mask: 6.826  loss_mask_0: 7.027  loss_mask_1: 6.732  loss_mask_2: 6.682  loss_mask_3: 6.714  loss_mask_4: 6.733  loss_mask_5: 6.711  loss_mask_6: 6.733  loss_mask_7: 6.665  loss_mask_8: 6.7  time: 2.0886  data_time: 0.4045  lr: 9.5309e-05  max_mem: 17458M
[01/27 04:58:29] d2.utils.events INFO:  eta: 1 day, 3:55:58  iter: 3139  total_loss: 61.52  loss_mask: 6.09  loss_mask_0: 6.33  loss_mask_1: 6.097  loss_mask_2: 6.124  loss_mask_3: 6.111  loss_mask_4: 6.143  loss_mask_5: 6.145  loss_mask_6: 6.131  loss_mask_7: 6.118  loss_mask_8: 6.132  time: 2.0865  data_time: 0.4071  lr: 9.5279e-05  max_mem: 17458M
[01/27 04:59:04] d2.utils.events INFO:  eta: 1 day, 3:55:44  iter: 3159  total_loss: 63.5  loss_mask: 6.347  loss_mask_0: 6.332  loss_mask_1: 6.326  loss_mask_2: 6.329  loss_mask_3: 6.337  loss_mask_4: 6.333  loss_mask_5: 6.354  loss_mask_6: 6.372  loss_mask_7: 6.36  loss_mask_8: 6.333  time: 2.0844  data_time: 0.4178  lr: 9.5249e-05  max_mem: 17458M
[01/27 04:59:39] d2.utils.events INFO:  eta: 1 day, 3:54:47  iter: 3179  total_loss: 61.36  loss_mask: 6.118  loss_mask_0: 6.152  loss_mask_1: 6.124  loss_mask_2: 6.07  loss_mask_3: 6.177  loss_mask_4: 6.08  loss_mask_5: 6.178  loss_mask_6: 6.19  loss_mask_7: 6.151  loss_mask_8: 6.112  time: 2.0824  data_time: 0.4253  lr: 9.5219e-05  max_mem: 17458M
[01/27 05:00:14] d2.utils.events INFO:  eta: 1 day, 3:53:38  iter: 3199  total_loss: 54.99  loss_mask: 5.409  loss_mask_0: 5.563  loss_mask_1: 5.464  loss_mask_2: 5.404  loss_mask_3: 5.455  loss_mask_4: 5.402  loss_mask_5: 5.425  loss_mask_6: 5.475  loss_mask_7: 5.439  loss_mask_8: 5.392  time: 2.0803  data_time: 0.3966  lr: 9.5188e-05  max_mem: 17458M
[01/27 05:00:49] d2.utils.events INFO:  eta: 1 day, 3:52:36  iter: 3219  total_loss: 56.64  loss_mask: 5.613  loss_mask_0: 5.905  loss_mask_1: 5.621  loss_mask_2: 5.639  loss_mask_3: 5.636  loss_mask_4: 5.63  loss_mask_5: 5.625  loss_mask_6: 5.54  loss_mask_7: 5.572  loss_mask_8: 5.611  time: 2.0782  data_time: 0.4098  lr: 9.5158e-05  max_mem: 17458M
[01/27 05:01:25] d2.utils.events INFO:  eta: 1 day, 3:52:03  iter: 3239  total_loss: 60.67  loss_mask: 6.046  loss_mask_0: 6.132  loss_mask_1: 6.058  loss_mask_2: 6.011  loss_mask_3: 6.013  loss_mask_4: 6.026  loss_mask_5: 6.019  loss_mask_6: 6.042  loss_mask_7: 6.068  loss_mask_8: 6.041  time: 2.0763  data_time: 0.4194  lr: 9.5128e-05  max_mem: 17458M
[01/27 05:02:00] d2.utils.events INFO:  eta: 1 day, 3:51:14  iter: 3259  total_loss: 62.85  loss_mask: 6.234  loss_mask_0: 6.598  loss_mask_1: 6.267  loss_mask_2: 6.237  loss_mask_3: 6.297  loss_mask_4: 6.276  loss_mask_5: 6.235  loss_mask_6: 6.298  loss_mask_7: 6.259  loss_mask_8: 6.151  time: 2.0744  data_time: 0.4109  lr: 9.5098e-05  max_mem: 17458M
[01/27 05:02:35] d2.utils.events INFO:  eta: 1 day, 3:50:13  iter: 3279  total_loss: 60.99  loss_mask: 6.109  loss_mask_0: 6.288  loss_mask_1: 6.058  loss_mask_2: 6.032  loss_mask_3: 6.104  loss_mask_4: 6.078  loss_mask_5: 6.085  loss_mask_6: 6.09  loss_mask_7: 6.086  loss_mask_8: 6.11  time: 2.0724  data_time: 0.3892  lr: 9.5068e-05  max_mem: 17458M
[01/27 05:03:10] d2.utils.events INFO:  eta: 1 day, 3:49:21  iter: 3299  total_loss: 56.8  loss_mask: 5.647  loss_mask_0: 5.89  loss_mask_1: 5.65  loss_mask_2: 5.627  loss_mask_3: 5.662  loss_mask_4: 5.634  loss_mask_5: 5.632  loss_mask_6: 5.685  loss_mask_7: 5.683  loss_mask_8: 5.678  time: 2.0704  data_time: 0.3950  lr: 9.5038e-05  max_mem: 17458M
[01/27 05:03:45] d2.utils.events INFO:  eta: 1 day, 3:47:06  iter: 3319  total_loss: 57.25  loss_mask: 5.708  loss_mask_0: 5.835  loss_mask_1: 5.7  loss_mask_2: 5.686  loss_mask_3: 5.723  loss_mask_4: 5.719  loss_mask_5: 5.716  loss_mask_6: 5.718  loss_mask_7: 5.714  loss_mask_8: 5.703  time: 2.0685  data_time: 0.4124  lr: 9.5007e-05  max_mem: 17458M
[01/27 05:04:20] d2.utils.events INFO:  eta: 1 day, 3:45:21  iter: 3339  total_loss: 57.24  loss_mask: 5.706  loss_mask_0: 5.846  loss_mask_1: 5.682  loss_mask_2: 5.684  loss_mask_3: 5.714  loss_mask_4: 5.718  loss_mask_5: 5.74  loss_mask_6: 5.741  loss_mask_7: 5.687  loss_mask_8: 5.7  time: 2.0665  data_time: 0.4004  lr: 9.4977e-05  max_mem: 17458M
[01/27 05:04:55] d2.utils.events INFO:  eta: 1 day, 3:44:35  iter: 3359  total_loss: 62.51  loss_mask: 6.23  loss_mask_0: 6.373  loss_mask_1: 6.22  loss_mask_2: 6.237  loss_mask_3: 6.24  loss_mask_4: 6.227  loss_mask_5: 6.245  loss_mask_6: 6.223  loss_mask_7: 6.248  loss_mask_8: 6.225  time: 2.0647  data_time: 0.4229  lr: 9.4947e-05  max_mem: 17458M
[01/27 05:05:30] d2.utils.events INFO:  eta: 1 day, 3:44:08  iter: 3379  total_loss: 53.54  loss_mask: 5.361  loss_mask_0: 5.423  loss_mask_1: 5.348  loss_mask_2: 5.335  loss_mask_3: 5.339  loss_mask_4: 5.346  loss_mask_5: 5.342  loss_mask_6: 5.338  loss_mask_7: 5.351  loss_mask_8: 5.334  time: 2.0628  data_time: 0.4071  lr: 9.4917e-05  max_mem: 17458M
[01/27 05:06:05] d2.utils.events INFO:  eta: 1 day, 3:42:56  iter: 3399  total_loss: 52.44  loss_mask: 5.225  loss_mask_0: 5.329  loss_mask_1: 5.234  loss_mask_2: 5.225  loss_mask_3: 5.234  loss_mask_4: 5.235  loss_mask_5: 5.242  loss_mask_6: 5.236  loss_mask_7: 5.24  loss_mask_8: 5.235  time: 2.0609  data_time: 0.3920  lr: 9.4887e-05  max_mem: 17458M
[01/27 05:06:39] d2.utils.events INFO:  eta: 1 day, 3:41:56  iter: 3419  total_loss: 52.32  loss_mask: 5.23  loss_mask_0: 5.296  loss_mask_1: 5.222  loss_mask_2: 5.228  loss_mask_3: 5.246  loss_mask_4: 5.212  loss_mask_5: 5.209  loss_mask_6: 5.232  loss_mask_7: 5.233  loss_mask_8: 5.215  time: 2.0590  data_time: 0.3932  lr: 9.4857e-05  max_mem: 17458M
[01/27 05:07:14] d2.utils.events INFO:  eta: 1 day, 3:41:12  iter: 3439  total_loss: 52.84  loss_mask: 5.27  loss_mask_0: 5.436  loss_mask_1: 5.258  loss_mask_2: 5.261  loss_mask_3: 5.257  loss_mask_4: 5.283  loss_mask_5: 5.26  loss_mask_6: 5.269  loss_mask_7: 5.278  loss_mask_8: 5.271  time: 2.0572  data_time: 0.3945  lr: 9.4826e-05  max_mem: 17458M
[01/27 05:07:50] d2.utils.events INFO:  eta: 1 day, 3:40:48  iter: 3459  total_loss: 53.04  loss_mask: 5.306  loss_mask_0: 5.427  loss_mask_1: 5.274  loss_mask_2: 5.271  loss_mask_3: 5.29  loss_mask_4: 5.285  loss_mask_5: 5.301  loss_mask_6: 5.313  loss_mask_7: 5.289  loss_mask_8: 5.281  time: 2.0555  data_time: 0.4334  lr: 9.4796e-05  max_mem: 17458M
[01/27 05:08:25] d2.utils.events INFO:  eta: 1 day, 3:40:01  iter: 3479  total_loss: 55.07  loss_mask: 5.513  loss_mask_0: 5.586  loss_mask_1: 5.485  loss_mask_2: 5.476  loss_mask_3: 5.517  loss_mask_4: 5.507  loss_mask_5: 5.505  loss_mask_6: 5.489  loss_mask_7: 5.501  loss_mask_8: 5.492  time: 2.0538  data_time: 0.4200  lr: 9.4766e-05  max_mem: 17458M
[01/27 05:09:00] d2.utils.events INFO:  eta: 1 day, 3:39:17  iter: 3499  total_loss: 66.86  loss_mask: 6.702  loss_mask_0: 6.692  loss_mask_1: 6.632  loss_mask_2: 6.644  loss_mask_3: 6.692  loss_mask_4: 6.663  loss_mask_5: 6.705  loss_mask_6: 6.72  loss_mask_7: 6.66  loss_mask_8: 6.702  time: 2.0521  data_time: 0.4111  lr: 9.4736e-05  max_mem: 17458M
[01/27 05:09:35] d2.utils.events INFO:  eta: 1 day, 3:38:51  iter: 3519  total_loss: 56.31  loss_mask: 5.614  loss_mask_0: 5.624  loss_mask_1: 5.599  loss_mask_2: 5.584  loss_mask_3: 5.612  loss_mask_4: 5.611  loss_mask_5: 5.629  loss_mask_6: 5.634  loss_mask_7: 5.598  loss_mask_8: 5.613  time: 2.0504  data_time: 0.4132  lr: 9.4706e-05  max_mem: 17458M
[01/27 05:10:10] d2.utils.events INFO:  eta: 1 day, 3:37:18  iter: 3539  total_loss: 52.11  loss_mask: 5.222  loss_mask_0: 5.196  loss_mask_1: 5.22  loss_mask_2: 5.198  loss_mask_3: 5.228  loss_mask_4: 5.219  loss_mask_5: 5.236  loss_mask_6: 5.199  loss_mask_7: 5.2  loss_mask_8: 5.195  time: 2.0487  data_time: 0.4019  lr: 9.4675e-05  max_mem: 17458M
[01/27 05:10:45] d2.utils.events INFO:  eta: 1 day, 3:36:12  iter: 3559  total_loss: 57.3  loss_mask: 5.735  loss_mask_0: 5.919  loss_mask_1: 5.718  loss_mask_2: 5.696  loss_mask_3: 5.713  loss_mask_4: 5.746  loss_mask_5: 5.725  loss_mask_6: 5.715  loss_mask_7: 5.713  loss_mask_8: 5.717  time: 2.0470  data_time: 0.4137  lr: 9.4645e-05  max_mem: 17458M
[01/27 05:11:20] d2.utils.events INFO:  eta: 1 day, 3:35:22  iter: 3579  total_loss: 56.16  loss_mask: 5.598  loss_mask_0: 5.757  loss_mask_1: 5.596  loss_mask_2: 5.608  loss_mask_3: 5.619  loss_mask_4: 5.617  loss_mask_5: 5.6  loss_mask_6: 5.597  loss_mask_7: 5.578  loss_mask_8: 5.574  time: 2.0452  data_time: 0.4021  lr: 9.4615e-05  max_mem: 17458M
[01/27 05:11:55] d2.utils.events INFO:  eta: 1 day, 3:34:43  iter: 3599  total_loss: 53.02  loss_mask: 5.263  loss_mask_0: 5.354  loss_mask_1: 5.3  loss_mask_2: 5.29  loss_mask_3: 5.296  loss_mask_4: 5.307  loss_mask_5: 5.288  loss_mask_6: 5.307  loss_mask_7: 5.3  loss_mask_8: 5.298  time: 2.0436  data_time: 0.4211  lr: 9.4585e-05  max_mem: 17458M
[01/27 05:12:30] d2.utils.events INFO:  eta: 1 day, 3:33:49  iter: 3619  total_loss: 56.54  loss_mask: 5.634  loss_mask_0: 5.723  loss_mask_1: 5.639  loss_mask_2: 5.657  loss_mask_3: 5.645  loss_mask_4: 5.651  loss_mask_5: 5.661  loss_mask_6: 5.655  loss_mask_7: 5.619  loss_mask_8: 5.626  time: 2.0419  data_time: 0.3946  lr: 9.4555e-05  max_mem: 17458M
[01/27 05:13:05] d2.utils.events INFO:  eta: 1 day, 3:33:03  iter: 3639  total_loss: 53.43  loss_mask: 5.294  loss_mask_0: 5.374  loss_mask_1: 5.329  loss_mask_2: 5.346  loss_mask_3: 5.306  loss_mask_4: 5.341  loss_mask_5: 5.347  loss_mask_6: 5.325  loss_mask_7: 5.311  loss_mask_8: 5.284  time: 2.0405  data_time: 0.4291  lr: 9.4525e-05  max_mem: 17458M
[01/27 05:13:40] d2.utils.events INFO:  eta: 1 day, 3:32:18  iter: 3659  total_loss: 51.6  loss_mask: 5.169  loss_mask_0: 5.245  loss_mask_1: 5.134  loss_mask_2: 5.148  loss_mask_3: 5.157  loss_mask_4: 5.183  loss_mask_5: 5.142  loss_mask_6: 5.16  loss_mask_7: 5.158  loss_mask_8: 5.219  time: 2.0389  data_time: 0.4079  lr: 9.4494e-05  max_mem: 17458M
[01/27 05:14:15] d2.utils.events INFO:  eta: 1 day, 3:31:25  iter: 3679  total_loss: 55.5  loss_mask: 5.341  loss_mask_0: 5.99  loss_mask_1: 5.492  loss_mask_2: 5.466  loss_mask_3: 5.421  loss_mask_4: 5.451  loss_mask_5: 5.409  loss_mask_6: 5.443  loss_mask_7: 5.414  loss_mask_8: 5.435  time: 2.0373  data_time: 0.4039  lr: 9.4464e-05  max_mem: 17458M
[01/27 05:14:50] d2.utils.events INFO:  eta: 1 day, 3:30:22  iter: 3699  total_loss: 56.53  loss_mask: 5.6  loss_mask_0: 5.403  loss_mask_1: 5.56  loss_mask_2: 5.561  loss_mask_3: 5.616  loss_mask_4: 5.597  loss_mask_5: 5.651  loss_mask_6: 5.614  loss_mask_7: 5.582  loss_mask_8: 5.481  time: 2.0356  data_time: 0.4117  lr: 9.4434e-05  max_mem: 17458M
[01/27 05:15:25] d2.utils.events INFO:  eta: 1 day, 3:29:22  iter: 3719  total_loss: 53.33  loss_mask: 5.33  loss_mask_0: 5.514  loss_mask_1: 5.274  loss_mask_2: 5.258  loss_mask_3: 5.338  loss_mask_4: 5.322  loss_mask_5: 5.339  loss_mask_6: 5.346  loss_mask_7: 5.339  loss_mask_8: 5.353  time: 2.0340  data_time: 0.4079  lr: 9.4404e-05  max_mem: 17458M
[01/27 05:16:00] d2.utils.events INFO:  eta: 1 day, 3:28:19  iter: 3739  total_loss: 54.99  loss_mask: 5.48  loss_mask_0: 5.711  loss_mask_1: 5.467  loss_mask_2: 5.474  loss_mask_3: 5.479  loss_mask_4: 5.468  loss_mask_5: 5.47  loss_mask_6: 5.499  loss_mask_7: 5.478  loss_mask_8: 5.464  time: 2.0324  data_time: 0.4113  lr: 9.4374e-05  max_mem: 17458M
[01/27 05:16:34] d2.utils.events INFO:  eta: 1 day, 3:26:57  iter: 3759  total_loss: 52.35  loss_mask: 5.235  loss_mask_0: 5.353  loss_mask_1: 5.221  loss_mask_2: 5.207  loss_mask_3: 5.23  loss_mask_4: 5.222  loss_mask_5: 5.225  loss_mask_6: 5.221  loss_mask_7: 5.224  loss_mask_8: 5.226  time: 2.0308  data_time: 0.3846  lr: 9.4343e-05  max_mem: 17458M
[01/27 05:17:09] d2.utils.events INFO:  eta: 1 day, 3:26:31  iter: 3779  total_loss: 52.89  loss_mask: 5.266  loss_mask_0: 5.541  loss_mask_1: 5.236  loss_mask_2: 5.205  loss_mask_3: 5.257  loss_mask_4: 5.273  loss_mask_5: 5.251  loss_mask_6: 5.267  loss_mask_7: 5.26  loss_mask_8: 5.255  time: 2.0293  data_time: 0.4142  lr: 9.4313e-05  max_mem: 17458M
[01/27 05:17:44] d2.utils.events INFO:  eta: 1 day, 3:25:32  iter: 3799  total_loss: 52.98  loss_mask: 5.288  loss_mask_0: 5.481  loss_mask_1: 5.264  loss_mask_2: 5.268  loss_mask_3: 5.294  loss_mask_4: 5.29  loss_mask_5: 5.292  loss_mask_6: 5.291  loss_mask_7: 5.294  loss_mask_8: 5.279  time: 2.0278  data_time: 0.3982  lr: 9.4283e-05  max_mem: 17458M
[01/27 05:18:19] d2.utils.events INFO:  eta: 1 day, 3:24:53  iter: 3819  total_loss: 52.29  loss_mask: 5.208  loss_mask_0: 5.4  loss_mask_1: 5.213  loss_mask_2: 5.212  loss_mask_3: 5.221  loss_mask_4: 5.234  loss_mask_5: 5.215  loss_mask_6: 5.228  loss_mask_7: 5.198  loss_mask_8: 5.203  time: 2.0263  data_time: 0.4088  lr: 9.4253e-05  max_mem: 17458M
[01/27 05:18:54] d2.utils.events INFO:  eta: 1 day, 3:23:55  iter: 3839  total_loss: 55.89  loss_mask: 5.558  loss_mask_0: 5.716  loss_mask_1: 5.56  loss_mask_2: 5.554  loss_mask_3: 5.591  loss_mask_4: 5.566  loss_mask_5: 5.567  loss_mask_6: 5.574  loss_mask_7: 5.567  loss_mask_8: 5.563  time: 2.0249  data_time: 0.4102  lr: 9.4223e-05  max_mem: 17458M
[01/27 05:19:29] d2.utils.events INFO:  eta: 1 day, 3:21:47  iter: 3859  total_loss: 51.28  loss_mask: 5.133  loss_mask_0: 5.186  loss_mask_1: 5.105  loss_mask_2: 5.108  loss_mask_3: 5.12  loss_mask_4: 5.129  loss_mask_5: 5.127  loss_mask_6: 5.122  loss_mask_7: 5.13  loss_mask_8: 5.123  time: 2.0233  data_time: 0.3931  lr: 9.4192e-05  max_mem: 17458M
[01/27 05:20:04] d2.utils.events INFO:  eta: 1 day, 3:20:32  iter: 3879  total_loss: 58.52  loss_mask: 5.808  loss_mask_0: 5.885  loss_mask_1: 5.826  loss_mask_2: 5.812  loss_mask_3: 5.841  loss_mask_4: 5.814  loss_mask_5: 5.82  loss_mask_6: 5.875  loss_mask_7: 5.801  loss_mask_8: 5.79  time: 2.0219  data_time: 0.4151  lr: 9.4162e-05  max_mem: 17458M
[01/27 05:20:38] d2.utils.events INFO:  eta: 1 day, 3:18:11  iter: 3899  total_loss: 50.91  loss_mask: 5.081  loss_mask_0: 5.185  loss_mask_1: 5.087  loss_mask_2: 5.079  loss_mask_3: 5.122  loss_mask_4: 5.073  loss_mask_5: 5.087  loss_mask_6: 5.107  loss_mask_7: 5.097  loss_mask_8: 5.086  time: 2.0205  data_time: 0.3966  lr: 9.4132e-05  max_mem: 17458M
[01/27 05:21:13] d2.utils.events INFO:  eta: 1 day, 3:16:49  iter: 3919  total_loss: 51.84  loss_mask: 5.185  loss_mask_0: 5.229  loss_mask_1: 5.173  loss_mask_2: 5.186  loss_mask_3: 5.209  loss_mask_4: 5.207  loss_mask_5: 5.2  loss_mask_6: 5.206  loss_mask_7: 5.197  loss_mask_8: 5.187  time: 2.0191  data_time: 0.4109  lr: 9.4102e-05  max_mem: 17458M
[01/27 05:21:48] d2.utils.events INFO:  eta: 1 day, 3:15:23  iter: 3939  total_loss: 52.66  loss_mask: 5.258  loss_mask_0: 5.528  loss_mask_1: 5.231  loss_mask_2: 5.246  loss_mask_3: 5.256  loss_mask_4: 5.292  loss_mask_5: 5.267  loss_mask_6: 5.229  loss_mask_7: 5.279  loss_mask_8: 5.257  time: 2.0177  data_time: 0.3898  lr: 9.4072e-05  max_mem: 17458M
[01/27 05:22:23] d2.utils.events INFO:  eta: 1 day, 3:14:21  iter: 3959  total_loss: 53.08  loss_mask: 5.288  loss_mask_0: 5.429  loss_mask_1: 5.279  loss_mask_2: 5.279  loss_mask_3: 5.299  loss_mask_4: 5.329  loss_mask_5: 5.314  loss_mask_6: 5.306  loss_mask_7: 5.28  loss_mask_8: 5.303  time: 2.0164  data_time: 0.4077  lr: 9.4041e-05  max_mem: 17458M
[01/27 05:22:58] d2.utils.events INFO:  eta: 1 day, 3:13:06  iter: 3979  total_loss: 53.54  loss_mask: 5.328  loss_mask_0: 5.371  loss_mask_1: 5.358  loss_mask_2: 5.35  loss_mask_3: 5.346  loss_mask_4: 5.361  loss_mask_5: 5.365  loss_mask_6: 5.349  loss_mask_7: 5.354  loss_mask_8: 5.355  time: 2.0150  data_time: 0.4120  lr: 9.4011e-05  max_mem: 17458M
[01/27 05:23:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 05:23:34] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 05:23:34] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 05:30:30] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.692452512809441, 'error_1pix': 0.6229485316414993, 'error_3pix': 0.35894224298471, 'mIoU': 3.403324832616566, 'fwIoU': 8.379934442942204, 'IoU-0': nan, 'IoU-1': 30.552393099086594, 'IoU-2': 1.8500333695962219, 'IoU-3': 1.262712274566981, 'IoU-4': 1.0591555252551, 'IoU-5': 0.8922595058401657, 'IoU-6': 0.827710616890955, 'IoU-7': 0.6683332820892451, 'IoU-8': 2.066749582617516, 'IoU-9': 4.395933434969646, 'IoU-10': 8.1069540456352, 'IoU-11': 12.853604740565721, 'IoU-12': 13.364075842145196, 'IoU-13': 11.40030170863389, 'IoU-14': 10.694869157717964, 'IoU-15': 9.37318698716634, 'IoU-16': 8.542789174510922, 'IoU-17': 6.53630229435943, 'IoU-18': 6.4324283284328585, 'IoU-19': 5.516417416913255, 'IoU-20': 5.9688103274146815, 'IoU-21': 5.7772658898942275, 'IoU-22': 6.577427198848684, 'IoU-23': 6.341919742159457, 'IoU-24': 6.1795191154983256, 'IoU-25': 5.815250706514307, 'IoU-26': 6.0640745339165765, 'IoU-27': 6.814847219226114, 'IoU-28': 6.678217375147444, 'IoU-29': 6.696619798271707, 'IoU-30': 6.287362348722936, 'IoU-31': 6.574089457561362, 'IoU-32': 6.20677916506377, 'IoU-33': 5.920578693461025, 'IoU-34': 5.632779924974415, 'IoU-35': 5.950606089596178, 'IoU-36': 5.966447144191415, 'IoU-37': 5.826919079348312, 'IoU-38': 5.58204391692215, 'IoU-39': 5.293154463483375, 'IoU-40': 5.32853454662461, 'IoU-41': 4.993980872320181, 'IoU-42': 5.087584030567496, 'IoU-43': 5.123194211594252, 'IoU-44': 5.132308175745587, 'IoU-45': 5.0871565450000755, 'IoU-46': 4.833346620917464, 'IoU-47': 4.7945575665388676, 'IoU-48': 4.899622630629031, 'IoU-49': 4.778539581106482, 'IoU-50': 4.762706206362913, 'IoU-51': 4.645432978941593, 'IoU-52': 4.690118218785521, 'IoU-53': 4.576783648160208, 'IoU-54': 4.5887129153418424, 'IoU-55': 4.573283421676353, 'IoU-56': 4.504188028999039, 'IoU-57': 4.528433910277096, 'IoU-58': 4.500575822492916, 'IoU-59': 4.268460966926944, 'IoU-60': 4.257651425101976, 'IoU-61': 4.183009147670151, 'IoU-62': 4.15598034405547, 'IoU-63': 4.227115387510214, 'IoU-64': 4.358627885775909, 'IoU-65': 4.147104246637398, 'IoU-66': 4.164579061428553, 'IoU-67': 4.186080274414624, 'IoU-68': 3.976444213609061, 'IoU-69': 4.02674871079581, 'IoU-70': 4.11335341805819, 'IoU-71': 4.034974381190109, 'IoU-72': 3.982117702769667, 'IoU-73': 3.9271593560993674, 'IoU-74': 4.0266958305700395, 'IoU-75': 3.948250282493303, 'IoU-76': 4.129644398881869, 'IoU-77': 3.942303753871141, 'IoU-78': 3.870156896896189, 'IoU-79': 3.89433562222337, 'IoU-80': 4.033711165169147, 'IoU-81': 4.05197672471815, 'IoU-82': 4.080561598033851, 'IoU-83': 4.014678782550893, 'IoU-84': 4.055196028184029, 'IoU-85': 4.1361351784480656, 'IoU-86': 4.00858062906615, 'IoU-87': 4.008409185364503, 'IoU-88': 3.8556801173590256, 'IoU-89': 3.8086005728466827, 'IoU-90': 3.8080889657961805, 'IoU-91': 3.8839792209495156, 'IoU-92': 3.720869493906483, 'IoU-93': 3.7919519570945166, 'IoU-94': 3.8729283161710213, 'IoU-95': 3.825234249394085, 'IoU-96': 3.767525332983184, 'IoU-97': 3.687589998048793, 'IoU-98': 3.56269128067162, 'IoU-99': 3.316077941361418, 'IoU-100': 3.3215998203034474, 'IoU-101': 3.282749309310826, 'IoU-102': 3.2259805522943, 'IoU-103': 3.0672726461527957, 'IoU-104': 3.074074280907531, 'IoU-105': 2.854316831437136, 'IoU-106': 2.8453507652207293, 'IoU-107': 2.9335371685485625, 'IoU-108': 2.9887366721150816, 'IoU-109': 2.915551895778433, 'IoU-110': 2.7586257406775254, 'IoU-111': 2.672712828636964, 'IoU-112': 2.768301128469079, 'IoU-113': 2.630835114033958, 'IoU-114': 2.5734511359840577, 'IoU-115': 2.65799681713794, 'IoU-116': 2.501349667688253, 'IoU-117': 2.5515364118834274, 'IoU-118': 2.4087915406121163, 'IoU-119': 2.5038657253916017, 'IoU-120': 2.3834813625816627, 'IoU-121': 2.367585258586193, 'IoU-122': 2.326289824795113, 'IoU-123': 2.2045281937489283, 'IoU-124': 2.093828042452644, 'IoU-125': 1.937145428065664, 'IoU-126': 1.9245229835402295, 'IoU-127': 1.9342111790550658, 'IoU-128': 1.9183192823868953, 'IoU-129': 1.904901924904373, 'IoU-130': 1.7824816692983394, 'IoU-131': 1.715019121340752, 'IoU-132': 1.7730839613117313, 'IoU-133': 1.8063478730099183, 'IoU-134': 1.7479129242400877, 'IoU-135': 1.6887045379155257, 'IoU-136': 1.7024031883841582, 'IoU-137': 1.5253076947674071, 'IoU-138': 1.4450066531129944, 'IoU-139': 1.4279415326462046, 'IoU-140': 1.4137440024107073, 'IoU-141': 1.4621053529593195, 'IoU-142': 1.412212467722065, 'IoU-143': 1.3645448954489545, 'IoU-144': 1.4149151026797202, 'IoU-145': 1.4427455350110676, 'IoU-146': 1.4459183344133033, 'IoU-147': 1.5573247385740925, 'IoU-148': 1.6064587471372196, 'IoU-149': 1.376605101919285, 'IoU-150': 1.2737085757508546, 'IoU-151': 1.395504220388099, 'IoU-152': 1.4192671796310792, 'IoU-153': 1.1990198836315429, 'IoU-154': 1.147425277033688, 'IoU-155': 1.1862996828831671, 'IoU-156': 1.2027926583817707, 'IoU-157': 1.23598690708727, 'IoU-158': 1.2132825408481733, 'IoU-159': 1.1930664966211224, 'IoU-160': 1.186002475861922, 'IoU-161': 1.2537767126757704, 'IoU-162': 1.1243599777545255, 'IoU-163': 1.0076606447658116, 'IoU-164': 1.0896322940982635, 'IoU-165': 1.118524351494873, 'IoU-166': 0.9602839259473944, 'IoU-167': 0.8850147610008442, 'IoU-168': 0.800147999131502, 'IoU-169': 0.8403925702148392, 'IoU-170': 0.9478007595731922, 'IoU-171': 1.0947362577607427, 'IoU-172': 0.9707981178484714, 'IoU-173': 0.8634475271914991, 'IoU-174': 0.8983001529418003, 'IoU-175': 0.9830030030910294, 'IoU-176': 1.0010082630189556, 'IoU-177': 0.9437266741887888, 'IoU-178': 0.6807382434530999, 'IoU-179': 0.8940212330042838, 'IoU-180': 1.3453879692720032, 'IoU-181': 0.5310048673664041, 'IoU-182': 0.23801390859565225, 'IoU-183': 0.22357539655389314, 'IoU-184': 0.24555503019813904, 'IoU-185': 0.19415323921186195, 'IoU-186': 0.1415566180586783, 'IoU-187': 0.09695287567457102, 'IoU-188': 0.05098559656896926, 'IoU-189': 0.02044451486444009, 'IoU-190': 0.004703558241809929, 'IoU-191': 0.0007821135837487226, 'IoU-192': 0.00537211814136022, 'mACC': 6.4154713577362275, 'pACC': 13.05987842952816, 'ACC-0': nan, 'ACC-1': 30.995580248433463, 'ACC-2': 5.245312518489593, 'ACC-3': 9.646078229744125, 'ACC-4': 7.226810524353761, 'ACC-5': 6.206018215304201, 'ACC-6': 5.983923068034637, 'ACC-7': 5.151849947675669, 'ACC-8': 6.8235345065941795, 'ACC-9': 8.54319596589319, 'ACC-10': 14.172444706002635, 'ACC-11': 20.494880121782213, 'ACC-12': 23.141834775821366, 'ACC-13': 20.84923764131296, 'ACC-14': 20.124492938770274, 'ACC-15': 18.766627684063234, 'ACC-16': 17.47818904749, 'ACC-17': 14.259437489305546, 'ACC-18': 13.101349386061353, 'ACC-19': 11.044547475216952, 'ACC-20': 11.725841327678827, 'ACC-21': 11.082317505709934, 'ACC-22': 12.076069462276322, 'ACC-23': 12.277843213680525, 'ACC-24': 12.166653565598793, 'ACC-25': 11.504225191053772, 'ACC-26': 11.990956177449286, 'ACC-27': 13.086298515230999, 'ACC-28': 13.132195057269671, 'ACC-29': 12.736521359916464, 'ACC-30': 12.211229035187698, 'ACC-31': 12.395690964362553, 'ACC-32': 11.786446428029093, 'ACC-33': 11.494596212845705, 'ACC-34': 10.9788451207027, 'ACC-35': 11.326423836474977, 'ACC-36': 11.23270701110991, 'ACC-37': 11.02397232591295, 'ACC-38': 10.397114786961081, 'ACC-39': 9.775649802688283, 'ACC-40': 9.747253528277914, 'ACC-41': 9.409293391549834, 'ACC-42': 9.583867180715606, 'ACC-43': 9.580040591824979, 'ACC-44': 9.321888428019363, 'ACC-45': 9.305462904334837, 'ACC-46': 9.036327085746738, 'ACC-47': 8.941340777244106, 'ACC-48': 9.141572386709655, 'ACC-49': 8.851769997588665, 'ACC-50': 8.787726260075665, 'ACC-51': 8.64784807081941, 'ACC-52': 8.671752023028343, 'ACC-53': 8.390410260052029, 'ACC-54': 8.264404987891465, 'ACC-55': 8.237444507918632, 'ACC-56': 8.206857942510442, 'ACC-57': 8.131990606475302, 'ACC-58': 8.15044301239005, 'ACC-59': 7.847589288865269, 'ACC-60': 7.86035628548433, 'ACC-61': 7.741708713513399, 'ACC-62': 7.717856634628394, 'ACC-63': 7.899169134692999, 'ACC-64': 8.157256643117716, 'ACC-65': 7.803146268807307, 'ACC-66': 7.8685429579592405, 'ACC-67': 7.96845067537528, 'ACC-68': 7.57001864344781, 'ACC-69': 7.495425026842914, 'ACC-70': 7.558281395152794, 'ACC-71': 7.525677997824586, 'ACC-72': 7.439415847697041, 'ACC-73': 7.301180649076337, 'ACC-74': 7.416108014923717, 'ACC-75': 7.280961059865311, 'ACC-76': 7.49368052228307, 'ACC-77': 7.249605323972745, 'ACC-78': 7.1850556804879036, 'ACC-79': 7.286370117261573, 'ACC-80': 7.549547280170107, 'ACC-81': 7.6184271321205035, 'ACC-82': 7.741985860001003, 'ACC-83': 7.570083690972555, 'ACC-84': 7.678893067300684, 'ACC-85': 7.830804254832607, 'ACC-86': 7.60634346167734, 'ACC-87': 7.635811876216734, 'ACC-88': 7.333450135902386, 'ACC-89': 7.215194268733151, 'ACC-90': 7.200772331542933, 'ACC-91': 7.3840334791983775, 'ACC-92': 7.122889358240339, 'ACC-93': 7.255000838991554, 'ACC-94': 7.376426526148823, 'ACC-95': 7.258246791471626, 'ACC-96': 7.176925924612178, 'ACC-97': 6.950229154114938, 'ACC-98': 6.724546274650901, 'ACC-99': 6.305041549451677, 'ACC-100': 6.307662427918164, 'ACC-101': 6.258565162293168, 'ACC-102': 6.147847757136384, 'ACC-103': 5.811821101350713, 'ACC-104': 5.821302968446423, 'ACC-105': 5.397758833941889, 'ACC-106': 5.349443312074853, 'ACC-107': 5.50470716986715, 'ACC-108': 5.557635956176537, 'ACC-109': 5.424283788553374, 'ACC-110': 5.216898025966158, 'ACC-111': 5.052491772648369, 'ACC-112': 5.280309688303074, 'ACC-113': 5.0157349659552555, 'ACC-114': 4.924677395784325, 'ACC-115': 5.044126712071324, 'ACC-116': 4.756434220889778, 'ACC-117': 4.816298288150945, 'ACC-118': 4.581985030001717, 'ACC-119': 4.756690543619938, 'ACC-120': 4.5350203986970135, 'ACC-121': 4.509392372095728, 'ACC-122': 4.4420070385990735, 'ACC-123': 4.243746903797153, 'ACC-124': 4.0971689855793585, 'ACC-125': 3.7536315905686872, 'ACC-126': 3.7543033178808547, 'ACC-127': 3.7802311020568364, 'ACC-128': 3.7810513836595354, 'ACC-129': 3.7888776003900704, 'ACC-130': 3.5790018135243, 'ACC-131': 3.4473683685859036, 'ACC-132': 3.5489070516364905, 'ACC-133': 3.617002456333735, 'ACC-134': 3.469194312796209, 'ACC-135': 3.3520751382475344, 'ACC-136': 3.3532892284755875, 'ACC-137': 3.021789520361894, 'ACC-138': 2.8718874533593928, 'ACC-139': 2.827621657827445, 'ACC-140': 2.7588800156372426, 'ACC-141': 2.812501577929521, 'ACC-142': 2.6999741495553025, 'ACC-143': 2.583899221190939, 'ACC-144': 2.64485559566787, 'ACC-145': 2.6625866635419637, 'ACC-146': 2.6611226611226613, 'ACC-147': 2.839057844317938, 'ACC-148': 2.9136697143932606, 'ACC-149': 2.5318715018928692, 'ACC-150': 2.3343780846133884, 'ACC-151': 2.5421281103819906, 'ACC-152': 2.5314868494394904, 'ACC-153': 2.1915932051220386, 'ACC-154': 2.0882722115959282, 'ACC-155': 2.1514375374390804, 'ACC-156': 2.1917673629111176, 'ACC-157': 2.2787962925156178, 'ACC-158': 2.238537392931692, 'ACC-159': 2.1750472096676328, 'ACC-160': 2.1279633986336695, 'ACC-161': 2.203199905637327, 'ACC-162': 1.9790182117875283, 'ACC-163': 1.7540051363580773, 'ACC-164': 1.8716853095296608, 'ACC-165': 1.8656277892302757, 'ACC-166': 1.5853242922449555, 'ACC-167': 1.4294970789897457, 'ACC-168': 1.269955693086715, 'ACC-169': 1.295506349437526, 'ACC-170': 1.4136746312307453, 'ACC-171': 1.593838456013769, 'ACC-172': 1.361077156721117, 'ACC-173': 1.1672492878725733, 'ACC-174': 1.168168117789819, 'ACC-175': 1.2400185623771676, 'ACC-176': 1.2263829231483632, 'ACC-177': 1.1237033305097728, 'ACC-178': 0.7925271048905663, 'ACC-179': 1.0225820195994888, 'ACC-180': 1.5088684121954161, 'ACC-181': 0.5882185718820625, 'ACC-182': 0.2575652384077871, 'ACC-183': 0.23851793946871483, 'ACC-184': 0.25966123760064524, 'ACC-185': 0.2023197483474911, 'ACC-186': 0.1456518095525869, 'ACC-187': 0.0985757257275396, 'ACC-188': 0.05145070820386586, 'ACC-189': 0.020538783641885768, 'ACC-190': 0.004716264299451342, 'ACC-191': 0.0007830342577487765, 'ACC-192': 0.00537696789950164})])
[01/27 05:30:30] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 05:30:30] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 05:30:30] d2.evaluation.testing INFO: copypaste: 4.6925,0.6229,0.3589,3.4033,8.3799,6.4155,13.0599
[01/27 05:30:30] d2.utils.events INFO:  eta: 1 day, 3:10:06  iter: 3999  total_loss: 51.23  loss_mask: 5.178  loss_mask_0: 5.205  loss_mask_1: 5.098  loss_mask_2: 5.09  loss_mask_3: 5.108  loss_mask_4: 5.143  loss_mask_5: 5.113  loss_mask_6: 5.108  loss_mask_7: 5.129  loss_mask_8: 5.125  time: 2.0136  data_time: 0.3923  lr: 9.3981e-05  max_mem: 17458M
[01/27 05:31:05] d2.utils.events INFO:  eta: 1 day, 3:08:58  iter: 4019  total_loss: 48.73  loss_mask: 4.964  loss_mask_0: 4.974  loss_mask_1: 4.863  loss_mask_2: 4.861  loss_mask_3: 4.87  loss_mask_4: 4.869  loss_mask_5: 4.885  loss_mask_6: 4.889  loss_mask_7: 4.866  loss_mask_8: 4.892  time: 2.0122  data_time: 0.3943  lr: 9.3951e-05  max_mem: 17458M
[01/27 05:31:40] d2.utils.events INFO:  eta: 1 day, 3:07:36  iter: 4039  total_loss: 54.66  loss_mask: 5.467  loss_mask_0: 5.571  loss_mask_1: 5.476  loss_mask_2: 5.452  loss_mask_3: 5.483  loss_mask_4: 5.442  loss_mask_5: 5.432  loss_mask_6: 5.441  loss_mask_7: 5.444  loss_mask_8: 5.441  time: 2.0108  data_time: 0.4013  lr: 9.3921e-05  max_mem: 17458M
[01/27 05:32:15] d2.utils.events INFO:  eta: 1 day, 3:06:32  iter: 4059  total_loss: 53.96  loss_mask: 5.299  loss_mask_0: 5.678  loss_mask_1: 5.375  loss_mask_2: 5.315  loss_mask_3: 5.375  loss_mask_4: 5.372  loss_mask_5: 5.374  loss_mask_6: 5.406  loss_mask_7: 5.331  loss_mask_8: 5.304  time: 2.0095  data_time: 0.4090  lr: 9.389e-05  max_mem: 17458M
[01/27 05:32:50] d2.utils.events INFO:  eta: 1 day, 3:06:05  iter: 4079  total_loss: 52.88  loss_mask: 5.245  loss_mask_0: 5.47  loss_mask_1: 5.233  loss_mask_2: 5.204  loss_mask_3: 5.241  loss_mask_4: 5.284  loss_mask_5: 5.279  loss_mask_6: 5.293  loss_mask_7: 5.283  loss_mask_8: 5.233  time: 2.0084  data_time: 0.4412  lr: 9.386e-05  max_mem: 17458M
[01/27 05:33:25] d2.utils.events INFO:  eta: 1 day, 3:05:22  iter: 4099  total_loss: 52.36  loss_mask: 5.23  loss_mask_0: 5.42  loss_mask_1: 5.2  loss_mask_2: 5.171  loss_mask_3: 5.245  loss_mask_4: 5.208  loss_mask_5: 5.22  loss_mask_6: 5.232  loss_mask_7: 5.219  loss_mask_8: 5.235  time: 2.0071  data_time: 0.4065  lr: 9.383e-05  max_mem: 17458M
[01/27 05:34:00] d2.utils.events INFO:  eta: 1 day, 3:04:47  iter: 4119  total_loss: 48.23  loss_mask: 4.827  loss_mask_0: 4.94  loss_mask_1: 4.789  loss_mask_2: 4.792  loss_mask_3: 4.834  loss_mask_4: 4.82  loss_mask_5: 4.809  loss_mask_6: 4.838  loss_mask_7: 4.812  loss_mask_8: 4.802  time: 2.0058  data_time: 0.3998  lr: 9.38e-05  max_mem: 17458M
[01/27 05:34:35] d2.utils.events INFO:  eta: 1 day, 3:04:12  iter: 4139  total_loss: 53.9  loss_mask: 5.377  loss_mask_0: 5.586  loss_mask_1: 5.362  loss_mask_2: 5.342  loss_mask_3: 5.378  loss_mask_4: 5.379  loss_mask_5: 5.384  loss_mask_6: 5.383  loss_mask_7: 5.377  loss_mask_8: 5.372  time: 2.0046  data_time: 0.4161  lr: 9.377e-05  max_mem: 17458M
[01/27 05:35:10] d2.utils.events INFO:  eta: 1 day, 3:02:21  iter: 4159  total_loss: 54.17  loss_mask: 5.402  loss_mask_0: 5.576  loss_mask_1: 5.37  loss_mask_2: 5.356  loss_mask_3: 5.39  loss_mask_4: 5.396  loss_mask_5: 5.388  loss_mask_6: 5.408  loss_mask_7: 5.384  loss_mask_8: 5.397  time: 2.0032  data_time: 0.3915  lr: 9.3739e-05  max_mem: 17458M
[01/27 05:35:44] d2.utils.events INFO:  eta: 1 day, 3:01:03  iter: 4179  total_loss: 50.11  loss_mask: 5.009  loss_mask_0: 5.168  loss_mask_1: 4.991  loss_mask_2: 4.99  loss_mask_3: 5.011  loss_mask_4: 5.012  loss_mask_5: 5.007  loss_mask_6: 5.009  loss_mask_7: 4.99  loss_mask_8: 5.003  time: 2.0019  data_time: 0.4083  lr: 9.3709e-05  max_mem: 17458M
[01/27 05:36:19] d2.utils.events INFO:  eta: 1 day, 3:00:28  iter: 4199  total_loss: 51.17  loss_mask: 5.106  loss_mask_0: 5.295  loss_mask_1: 5.109  loss_mask_2: 5.07  loss_mask_3: 5.107  loss_mask_4: 5.095  loss_mask_5: 5.112  loss_mask_6: 5.101  loss_mask_7: 5.097  loss_mask_8: 5.074  time: 2.0007  data_time: 0.4047  lr: 9.3679e-05  max_mem: 17458M
[01/27 05:36:54] d2.utils.events INFO:  eta: 1 day, 3:00:25  iter: 4219  total_loss: 52.12  loss_mask: 5.224  loss_mask_0: 5.399  loss_mask_1: 5.139  loss_mask_2: 5.166  loss_mask_3: 5.21  loss_mask_4: 5.22  loss_mask_5: 5.199  loss_mask_6: 5.19  loss_mask_7: 5.214  loss_mask_8: 5.224  time: 1.9995  data_time: 0.3942  lr: 9.3649e-05  max_mem: 17458M
[01/27 05:37:29] d2.utils.events INFO:  eta: 1 day, 2:58:42  iter: 4239  total_loss: 50.11  loss_mask: 4.991  loss_mask_0: 5.362  loss_mask_1: 4.997  loss_mask_2: 4.964  loss_mask_3: 4.981  loss_mask_4: 4.971  loss_mask_5: 4.993  loss_mask_6: 4.991  loss_mask_7: 4.984  loss_mask_8: 4.989  time: 1.9983  data_time: 0.3953  lr: 9.3618e-05  max_mem: 17458M
[01/27 05:38:04] d2.utils.events INFO:  eta: 1 day, 2:58:03  iter: 4259  total_loss: 48.7  loss_mask: 4.875  loss_mask_0: 4.973  loss_mask_1: 4.826  loss_mask_2: 4.829  loss_mask_3: 4.862  loss_mask_4: 4.848  loss_mask_5: 4.856  loss_mask_6: 4.847  loss_mask_7: 4.878  loss_mask_8: 4.876  time: 1.9970  data_time: 0.3946  lr: 9.3588e-05  max_mem: 17458M
[01/27 05:38:39] d2.utils.events INFO:  eta: 1 day, 2:57:28  iter: 4279  total_loss: 50.15  loss_mask: 5.009  loss_mask_0: 5.297  loss_mask_1: 4.992  loss_mask_2: 4.983  loss_mask_3: 5.014  loss_mask_4: 4.966  loss_mask_5: 4.978  loss_mask_6: 5.012  loss_mask_7: 5.01  loss_mask_8: 4.977  time: 1.9958  data_time: 0.4028  lr: 9.3558e-05  max_mem: 17458M
[01/27 05:39:13] d2.utils.events INFO:  eta: 1 day, 2:56:54  iter: 4299  total_loss: 52.79  loss_mask: 5.27  loss_mask_0: 5.481  loss_mask_1: 5.25  loss_mask_2: 5.227  loss_mask_3: 5.249  loss_mask_4: 5.26  loss_mask_5: 5.254  loss_mask_6: 5.238  loss_mask_7: 5.262  loss_mask_8: 5.25  time: 1.9946  data_time: 0.4045  lr: 9.3528e-05  max_mem: 17458M
[01/27 05:39:48] d2.utils.events INFO:  eta: 1 day, 2:56:19  iter: 4319  total_loss: 52.3  loss_mask: 5.178  loss_mask_0: 5.254  loss_mask_1: 5.222  loss_mask_2: 5.237  loss_mask_3: 5.23  loss_mask_4: 5.234  loss_mask_5: 5.222  loss_mask_6: 5.251  loss_mask_7: 5.194  loss_mask_8: 5.21  time: 1.9935  data_time: 0.4094  lr: 9.3498e-05  max_mem: 17458M
[01/27 05:40:23] d2.utils.events INFO:  eta: 1 day, 2:55:38  iter: 4339  total_loss: 49.63  loss_mask: 4.947  loss_mask_0: 4.984  loss_mask_1: 4.942  loss_mask_2: 4.971  loss_mask_3: 4.96  loss_mask_4: 4.954  loss_mask_5: 4.947  loss_mask_6: 4.936  loss_mask_7: 4.976  loss_mask_8: 4.963  time: 1.9923  data_time: 0.3999  lr: 9.3467e-05  max_mem: 17458M
[01/27 05:40:58] d2.utils.events INFO:  eta: 1 day, 2:54:23  iter: 4359  total_loss: 48.76  loss_mask: 4.866  loss_mask_0: 4.937  loss_mask_1: 4.869  loss_mask_2: 4.866  loss_mask_3: 4.896  loss_mask_4: 4.853  loss_mask_5: 4.851  loss_mask_6: 4.905  loss_mask_7: 4.844  loss_mask_8: 4.866  time: 1.9911  data_time: 0.3916  lr: 9.3437e-05  max_mem: 17458M
[01/27 05:41:32] d2.utils.events INFO:  eta: 1 day, 2:53:29  iter: 4379  total_loss: 47.46  loss_mask: 4.731  loss_mask_0: 4.871  loss_mask_1: 4.734  loss_mask_2: 4.725  loss_mask_3: 4.742  loss_mask_4: 4.752  loss_mask_5: 4.732  loss_mask_6: 4.746  loss_mask_7: 4.742  loss_mask_8: 4.744  time: 1.9899  data_time: 0.4007  lr: 9.3407e-05  max_mem: 17458M
[01/27 05:42:07] d2.utils.events INFO:  eta: 1 day, 2:52:32  iter: 4399  total_loss: 46.48  loss_mask: 4.671  loss_mask_0: 4.658  loss_mask_1: 4.632  loss_mask_2: 4.624  loss_mask_3: 4.641  loss_mask_4: 4.65  loss_mask_5: 4.644  loss_mask_6: 4.653  loss_mask_7: 4.654  loss_mask_8: 4.663  time: 1.9887  data_time: 0.4046  lr: 9.3377e-05  max_mem: 17458M
[01/27 05:42:42] d2.utils.events INFO:  eta: 1 day, 2:52:35  iter: 4419  total_loss: 46.21  loss_mask: 4.606  loss_mask_0: 4.676  loss_mask_1: 4.61  loss_mask_2: 4.618  loss_mask_3: 4.6  loss_mask_4: 4.613  loss_mask_5: 4.63  loss_mask_6: 4.605  loss_mask_7: 4.606  loss_mask_8: 4.611  time: 1.9877  data_time: 0.4172  lr: 9.3346e-05  max_mem: 17458M
[01/27 05:43:18] d2.utils.events INFO:  eta: 1 day, 2:52:36  iter: 4439  total_loss: 50.77  loss_mask: 5.059  loss_mask_0: 5.156  loss_mask_1: 5.047  loss_mask_2: 5.043  loss_mask_3: 5.06  loss_mask_4: 5.068  loss_mask_5: 5.075  loss_mask_6: 5.062  loss_mask_7: 5.059  loss_mask_8: 5.064  time: 1.9867  data_time: 0.4096  lr: 9.3316e-05  max_mem: 17458M
[01/27 05:43:53] d2.utils.events INFO:  eta: 1 day, 2:51:18  iter: 4459  total_loss: 54.3  loss_mask: 5.397  loss_mask_0: 5.722  loss_mask_1: 5.368  loss_mask_2: 5.36  loss_mask_3: 5.384  loss_mask_4: 5.414  loss_mask_5: 5.419  loss_mask_6: 5.336  loss_mask_7: 5.383  loss_mask_8: 5.445  time: 1.9856  data_time: 0.4096  lr: 9.3286e-05  max_mem: 17458M
[01/27 05:44:27] d2.utils.events INFO:  eta: 1 day, 2:50:12  iter: 4479  total_loss: 48.4  loss_mask: 4.815  loss_mask_0: 4.95  loss_mask_1: 4.829  loss_mask_2: 4.753  loss_mask_3: 4.804  loss_mask_4: 4.847  loss_mask_5: 4.828  loss_mask_6: 4.843  loss_mask_7: 4.812  loss_mask_8: 4.803  time: 1.9845  data_time: 0.3954  lr: 9.3256e-05  max_mem: 17458M
[01/27 05:45:02] d2.utils.events INFO:  eta: 1 day, 2:49:14  iter: 4499  total_loss: 54.72  loss_mask: 5.458  loss_mask_0: 5.658  loss_mask_1: 5.46  loss_mask_2: 5.44  loss_mask_3: 5.473  loss_mask_4: 5.465  loss_mask_5: 5.475  loss_mask_6: 5.471  loss_mask_7: 5.461  loss_mask_8: 5.478  time: 1.9834  data_time: 0.4182  lr: 9.3225e-05  max_mem: 17458M
[01/27 05:45:37] d2.utils.events INFO:  eta: 1 day, 2:48:17  iter: 4519  total_loss: 50.53  loss_mask: 5.034  loss_mask_0: 5.218  loss_mask_1: 5.039  loss_mask_2: 5.039  loss_mask_3: 5.04  loss_mask_4: 5.053  loss_mask_5: 5.054  loss_mask_6: 5.027  loss_mask_7: 5.037  loss_mask_8: 5.048  time: 1.9823  data_time: 0.4033  lr: 9.3195e-05  max_mem: 17458M
[01/27 05:46:12] d2.utils.events INFO:  eta: 1 day, 2:48:04  iter: 4539  total_loss: 44.5  loss_mask: 4.431  loss_mask_0: 4.524  loss_mask_1: 4.442  loss_mask_2: 4.448  loss_mask_3: 4.437  loss_mask_4: 4.441  loss_mask_5: 4.446  loss_mask_6: 4.433  loss_mask_7: 4.444  loss_mask_8: 4.453  time: 1.9813  data_time: 0.3991  lr: 9.3165e-05  max_mem: 17478M
[01/27 05:46:47] d2.utils.events INFO:  eta: 1 day, 2:46:32  iter: 4559  total_loss: 45.71  loss_mask: 4.568  loss_mask_0: 4.658  loss_mask_1: 4.563  loss_mask_2: 4.554  loss_mask_3: 4.581  loss_mask_4: 4.567  loss_mask_5: 4.568  loss_mask_6: 4.566  loss_mask_7: 4.577  loss_mask_8: 4.565  time: 1.9802  data_time: 0.4037  lr: 9.3135e-05  max_mem: 17478M
[01/27 05:47:21] d2.utils.events INFO:  eta: 1 day, 2:45:57  iter: 4579  total_loss: 46.2  loss_mask: 4.614  loss_mask_0: 4.723  loss_mask_1: 4.607  loss_mask_2: 4.603  loss_mask_3: 4.61  loss_mask_4: 4.607  loss_mask_5: 4.599  loss_mask_6: 4.613  loss_mask_7: 4.605  loss_mask_8: 4.607  time: 1.9791  data_time: 0.4028  lr: 9.3105e-05  max_mem: 17478M
[01/27 05:47:56] d2.utils.events INFO:  eta: 1 day, 2:44:58  iter: 4599  total_loss: 44.67  loss_mask: 4.452  loss_mask_0: 4.586  loss_mask_1: 4.452  loss_mask_2: 4.456  loss_mask_3: 4.456  loss_mask_4: 4.457  loss_mask_5: 4.454  loss_mask_6: 4.463  loss_mask_7: 4.446  loss_mask_8: 4.455  time: 1.9781  data_time: 0.4143  lr: 9.3074e-05  max_mem: 17478M
[01/27 05:48:32] d2.utils.events INFO:  eta: 1 day, 2:45:45  iter: 4619  total_loss: 46.2  loss_mask: 4.623  loss_mask_0: 4.681  loss_mask_1: 4.605  loss_mask_2: 4.601  loss_mask_3: 4.608  loss_mask_4: 4.609  loss_mask_5: 4.604  loss_mask_6: 4.591  loss_mask_7: 4.616  loss_mask_8: 4.616  time: 1.9772  data_time: 0.4208  lr: 9.3044e-05  max_mem: 17478M
[01/27 05:49:06] d2.utils.events INFO:  eta: 1 day, 2:43:39  iter: 4639  total_loss: 43.16  loss_mask: 4.312  loss_mask_0: 4.384  loss_mask_1: 4.309  loss_mask_2: 4.308  loss_mask_3: 4.321  loss_mask_4: 4.313  loss_mask_5: 4.321  loss_mask_6: 4.297  loss_mask_7: 4.309  loss_mask_8: 4.318  time: 1.9761  data_time: 0.3962  lr: 9.3014e-05  max_mem: 17478M
[01/27 05:49:41] d2.utils.events INFO:  eta: 1 day, 2:43:08  iter: 4659  total_loss: 45.01  loss_mask: 4.484  loss_mask_0: 4.596  loss_mask_1: 4.491  loss_mask_2: 4.483  loss_mask_3: 4.487  loss_mask_4: 4.48  loss_mask_5: 4.485  loss_mask_6: 4.494  loss_mask_7: 4.486  loss_mask_8: 4.486  time: 1.9751  data_time: 0.4056  lr: 9.2984e-05  max_mem: 17478M
[01/27 05:50:16] d2.utils.events INFO:  eta: 1 day, 2:42:08  iter: 4679  total_loss: 42.89  loss_mask: 4.28  loss_mask_0: 4.387  loss_mask_1: 4.292  loss_mask_2: 4.277  loss_mask_3: 4.282  loss_mask_4: 4.276  loss_mask_5: 4.284  loss_mask_6: 4.284  loss_mask_7: 4.276  loss_mask_8: 4.288  time: 1.9741  data_time: 0.4056  lr: 9.2953e-05  max_mem: 17478M
[01/27 05:50:51] d2.utils.events INFO:  eta: 1 day, 2:41:32  iter: 4699  total_loss: 43.46  loss_mask: 4.339  loss_mask_0: 4.446  loss_mask_1: 4.335  loss_mask_2: 4.321  loss_mask_3: 4.333  loss_mask_4: 4.345  loss_mask_5: 4.327  loss_mask_6: 4.342  loss_mask_7: 4.332  loss_mask_8: 4.326  time: 1.9731  data_time: 0.3903  lr: 9.2923e-05  max_mem: 17478M
[01/27 05:51:25] d2.utils.events INFO:  eta: 1 day, 2:40:43  iter: 4719  total_loss: 44.13  loss_mask: 4.391  loss_mask_0: 4.562  loss_mask_1: 4.392  loss_mask_2: 4.378  loss_mask_3: 4.394  loss_mask_4: 4.409  loss_mask_5: 4.404  loss_mask_6: 4.411  loss_mask_7: 4.401  loss_mask_8: 4.391  time: 1.9720  data_time: 0.3852  lr: 9.2893e-05  max_mem: 17478M
[01/27 05:52:00] d2.utils.events INFO:  eta: 1 day, 2:39:47  iter: 4739  total_loss: 47.96  loss_mask: 4.779  loss_mask_0: 4.983  loss_mask_1: 4.771  loss_mask_2: 4.772  loss_mask_3: 4.772  loss_mask_4: 4.798  loss_mask_5: 4.777  loss_mask_6: 4.79  loss_mask_7: 4.78  loss_mask_8: 4.77  time: 1.9710  data_time: 0.4099  lr: 9.2863e-05  max_mem: 17478M
[01/27 05:52:35] d2.utils.events INFO:  eta: 1 day, 2:39:33  iter: 4759  total_loss: 45.69  loss_mask: 4.602  loss_mask_0: 4.678  loss_mask_1: 4.545  loss_mask_2: 4.575  loss_mask_3: 4.602  loss_mask_4: 4.584  loss_mask_5: 4.57  loss_mask_6: 4.56  loss_mask_7: 4.613  loss_mask_8: 4.584  time: 1.9701  data_time: 0.3981  lr: 9.2832e-05  max_mem: 17478M
[01/27 05:53:10] d2.utils.events INFO:  eta: 1 day, 2:38:15  iter: 4779  total_loss: 49.05  loss_mask: 4.843  loss_mask_0: 5.387  loss_mask_1: 4.856  loss_mask_2: 4.848  loss_mask_3: 4.859  loss_mask_4: 4.901  loss_mask_5: 4.888  loss_mask_6: 4.852  loss_mask_7: 4.88  loss_mask_8: 4.884  time: 1.9691  data_time: 0.3930  lr: 9.2802e-05  max_mem: 17478M
[01/27 05:53:44] d2.utils.events INFO:  eta: 1 day, 2:37:32  iter: 4799  total_loss: 49.16  loss_mask: 4.813  loss_mask_0: 5.168  loss_mask_1: 4.776  loss_mask_2: 4.842  loss_mask_3: 4.839  loss_mask_4: 4.809  loss_mask_5: 4.801  loss_mask_6: 4.815  loss_mask_7: 4.773  loss_mask_8: 4.803  time: 1.9681  data_time: 0.3907  lr: 9.2772e-05  max_mem: 17478M
[01/27 05:54:19] d2.utils.events INFO:  eta: 1 day, 2:36:36  iter: 4819  total_loss: 53.05  loss_mask: 5.279  loss_mask_0: 5.577  loss_mask_1: 5.281  loss_mask_2: 5.27  loss_mask_3: 5.255  loss_mask_4: 5.285  loss_mask_5: 5.306  loss_mask_6: 5.299  loss_mask_7: 5.267  loss_mask_8: 5.286  time: 1.9671  data_time: 0.4041  lr: 9.2742e-05  max_mem: 17478M
[01/27 05:54:54] d2.utils.events INFO:  eta: 1 day, 2:36:11  iter: 4839  total_loss: 50.77  loss_mask: 4.941  loss_mask_0: 5.257  loss_mask_1: 5.064  loss_mask_2: 5.063  loss_mask_3: 5.026  loss_mask_4: 5.102  loss_mask_5: 5.03  loss_mask_6: 5.015  loss_mask_7: 5.022  loss_mask_8: 4.984  time: 1.9663  data_time: 0.4190  lr: 9.2711e-05  max_mem: 17478M
[01/27 05:55:29] d2.utils.events INFO:  eta: 1 day, 2:36:25  iter: 4859  total_loss: 51.52  loss_mask: 5.131  loss_mask_0: 5.129  loss_mask_1: 5.122  loss_mask_2: 5.126  loss_mask_3: 5.151  loss_mask_4: 5.152  loss_mask_5: 5.157  loss_mask_6: 5.145  loss_mask_7: 5.142  loss_mask_8: 5.134  time: 1.9654  data_time: 0.4153  lr: 9.2681e-05  max_mem: 17478M
[01/27 05:56:04] d2.utils.events INFO:  eta: 1 day, 2:35:42  iter: 4879  total_loss: 46.5  loss_mask: 4.649  loss_mask_0: 4.761  loss_mask_1: 4.623  loss_mask_2: 4.652  loss_mask_3: 4.625  loss_mask_4: 4.6  loss_mask_5: 4.648  loss_mask_6: 4.608  loss_mask_7: 4.637  loss_mask_8: 4.624  time: 1.9645  data_time: 0.3995  lr: 9.2651e-05  max_mem: 17478M
[01/27 05:56:39] d2.utils.events INFO:  eta: 1 day, 2:35:24  iter: 4899  total_loss: 44.79  loss_mask: 4.473  loss_mask_0: 4.554  loss_mask_1: 4.453  loss_mask_2: 4.458  loss_mask_3: 4.479  loss_mask_4: 4.498  loss_mask_5: 4.463  loss_mask_6: 4.478  loss_mask_7: 4.464  loss_mask_8: 4.483  time: 1.9636  data_time: 0.3883  lr: 9.2621e-05  max_mem: 17478M
[01/27 05:57:14] d2.utils.events INFO:  eta: 1 day, 2:34:41  iter: 4919  total_loss: 43.38  loss_mask: 4.339  loss_mask_0: 4.323  loss_mask_1: 4.33  loss_mask_2: 4.348  loss_mask_3: 4.341  loss_mask_4: 4.347  loss_mask_5: 4.331  loss_mask_6: 4.335  loss_mask_7: 4.334  loss_mask_8: 4.331  time: 1.9626  data_time: 0.4039  lr: 9.259e-05  max_mem: 17478M
[01/27 05:57:49] d2.utils.events INFO:  eta: 1 day, 2:34:33  iter: 4939  total_loss: 50.72  loss_mask: 5.079  loss_mask_0: 5.225  loss_mask_1: 5.02  loss_mask_2: 5.034  loss_mask_3: 5.094  loss_mask_4: 5.084  loss_mask_5: 5.037  loss_mask_6: 5.076  loss_mask_7: 5.052  loss_mask_8: 5.081  time: 1.9618  data_time: 0.4097  lr: 9.256e-05  max_mem: 17478M
[01/27 05:58:24] d2.utils.events INFO:  eta: 1 day, 2:33:55  iter: 4959  total_loss: 50.16  loss_mask: 5.015  loss_mask_0: 5.145  loss_mask_1: 4.989  loss_mask_2: 4.987  loss_mask_3: 5.05  loss_mask_4: 5.03  loss_mask_5: 5.029  loss_mask_6: 5.036  loss_mask_7: 4.984  loss_mask_8: 5.011  time: 1.9610  data_time: 0.4136  lr: 9.253e-05  max_mem: 17478M
[01/27 05:58:59] d2.utils.events INFO:  eta: 1 day, 2:33:21  iter: 4979  total_loss: 46.15  loss_mask: 4.61  loss_mask_0: 4.663  loss_mask_1: 4.6  loss_mask_2: 4.6  loss_mask_3: 4.618  loss_mask_4: 4.618  loss_mask_5: 4.606  loss_mask_6: 4.619  loss_mask_7: 4.617  loss_mask_8: 4.616  time: 1.9601  data_time: 0.4071  lr: 9.25e-05  max_mem: 17478M
[01/27 05:59:34] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE/model_0004999.pth
[01/27 05:59:34] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 05:59:35] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 05:59:35] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 06:06:31] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.569251114509122, 'error_1pix': 0.6818620052749897, 'error_3pix': 0.40593101895132927, 'mIoU': 2.958320373891312, 'fwIoU': 8.044847588277284, 'IoU-0': nan, 'IoU-1': 40.99474869732609, 'IoU-2': 2.5209847735312483, 'IoU-3': 1.9968286977795517, 'IoU-4': 1.6642352696421585, 'IoU-5': 1.3804136903646729, 'IoU-6': 1.2721671305602165, 'IoU-7': 1.0268139627001234, 'IoU-8': 3.0811069059783858, 'IoU-9': 7.20603770408241, 'IoU-10': 11.10083772761366, 'IoU-11': 14.422783065830275, 'IoU-12': 13.092839103342996, 'IoU-13': 11.188603530820458, 'IoU-14': 9.54222718277256, 'IoU-15': 8.019793250870373, 'IoU-16': 6.977912741560919, 'IoU-17': 6.0288962905842745, 'IoU-18': 5.501294375812627, 'IoU-19': 4.6065174179170505, 'IoU-20': 5.193807396223904, 'IoU-21': 5.374295491033743, 'IoU-22': 6.261638216812216, 'IoU-23': 5.399065718911226, 'IoU-24': 4.783528489148836, 'IoU-25': 4.24122364500783, 'IoU-26': 4.456141558845863, 'IoU-27': 4.3936624176408, 'IoU-28': 4.121482797273453, 'IoU-29': 4.176740027782429, 'IoU-30': 3.8029438867450747, 'IoU-31': 3.4586242322592136, 'IoU-32': 3.254385827455507, 'IoU-33': 2.9271603825518255, 'IoU-34': 2.777702429640757, 'IoU-35': 2.449920366259784, 'IoU-36': 2.608464651449011, 'IoU-37': 2.4874312490165993, 'IoU-38': 2.4168000755665853, 'IoU-39': 2.3694768940867137, 'IoU-40': 2.3434523483129888, 'IoU-41': 2.2909142837397103, 'IoU-42': 2.3099193308191013, 'IoU-43': 2.2530063965273124, 'IoU-44': 2.203756682638654, 'IoU-45': 2.2565099547954754, 'IoU-46': 2.16888895813384, 'IoU-47': 2.102745002653848, 'IoU-48': 2.051246282665904, 'IoU-49': 2.076176100059323, 'IoU-50': 2.307593261990739, 'IoU-51': 2.1439172711739096, 'IoU-52': 2.0643621803122634, 'IoU-53': 2.056837704469574, 'IoU-54': 2.090995135680055, 'IoU-55': 2.0901681374335532, 'IoU-56': 2.1560772236635097, 'IoU-57': 2.373402923196805, 'IoU-58': 2.3457995341654683, 'IoU-59': 2.3221577159865694, 'IoU-60': 2.252850972917128, 'IoU-61': 2.261829191281488, 'IoU-62': 2.382104393458183, 'IoU-63': 2.4263417044205213, 'IoU-64': 2.4731868886782413, 'IoU-65': 2.622184545465249, 'IoU-66': 2.623576541449374, 'IoU-67': 2.499349506146883, 'IoU-68': 2.588582169594746, 'IoU-69': 2.6759125591896074, 'IoU-70': 2.7608888846637267, 'IoU-71': 2.9261020404644884, 'IoU-72': 2.9972226004984828, 'IoU-73': 2.9229135974430474, 'IoU-74': 3.077474819884047, 'IoU-75': 3.0974737691037455, 'IoU-76': 3.22791337729347, 'IoU-77': 3.318916448317937, 'IoU-78': 3.4288601618225423, 'IoU-79': 3.448016071578821, 'IoU-80': 3.5827885723007795, 'IoU-81': 3.5988038549713197, 'IoU-82': 3.6590997769622877, 'IoU-83': 3.645640428146615, 'IoU-84': 3.649194880305572, 'IoU-85': 3.7792932552050296, 'IoU-86': 3.7173355885758563, 'IoU-87': 3.5955276213211986, 'IoU-88': 3.7600248180050553, 'IoU-89': 3.515913475863745, 'IoU-90': 3.529788947087506, 'IoU-91': 3.480957440310792, 'IoU-92': 3.428489659003521, 'IoU-93': 3.4447940815350226, 'IoU-94': 3.521120837425215, 'IoU-95': 3.592501669256504, 'IoU-96': 3.581775766954578, 'IoU-97': 3.549431167408015, 'IoU-98': 3.476966689577879, 'IoU-99': 3.2515778472971677, 'IoU-100': 3.110445546749469, 'IoU-101': 3.0625027765265163, 'IoU-102': 3.1096564449190334, 'IoU-103': 3.1046628536598178, 'IoU-104': 3.081238157801871, 'IoU-105': 3.105812082198564, 'IoU-106': 3.0242517587772317, 'IoU-107': 3.1815557216501604, 'IoU-108': 3.2350673377863264, 'IoU-109': 3.1345097517576317, 'IoU-110': 3.051930050488691, 'IoU-111': 3.0397711801682172, 'IoU-112': 3.0693172061101213, 'IoU-113': 2.897899917042681, 'IoU-114': 3.0035476034698116, 'IoU-115': 2.831611901747677, 'IoU-116': 2.8485776712094046, 'IoU-117': 2.988587992707847, 'IoU-118': 2.88823106742521, 'IoU-119': 2.7283243776388133, 'IoU-120': 2.768760848891513, 'IoU-121': 2.7034591672487625, 'IoU-122': 2.608761437871412, 'IoU-123': 2.753596230323258, 'IoU-124': 2.473999794458119, 'IoU-125': 2.3295136277529944, 'IoU-126': 2.1948773025692514, 'IoU-127': 2.2632271103049177, 'IoU-128': 2.2578870698329614, 'IoU-129': 2.2112617981654683, 'IoU-130': 2.268214619234808, 'IoU-131': 2.196705973003839, 'IoU-132': 2.1948690497014707, 'IoU-133': 2.140951619970616, 'IoU-134': 2.078901443256946, 'IoU-135': 2.1602439228434163, 'IoU-136': 2.054119112323153, 'IoU-137': 2.0933663142628323, 'IoU-138': 2.114641572413771, 'IoU-139': 2.081338927982118, 'IoU-140': 2.0828316425568913, 'IoU-141': 2.029698289710842, 'IoU-142': 2.0889888777262398, 'IoU-143': 1.9658706602301428, 'IoU-144': 1.9123914473173182, 'IoU-145': 1.8955081990186553, 'IoU-146': 1.796193349287652, 'IoU-147': 1.97857494954751, 'IoU-148': 1.9328924855586567, 'IoU-149': 1.7616445640938363, 'IoU-150': 1.7091164676911252, 'IoU-151': 1.826148664112126, 'IoU-152': 1.872445094092848, 'IoU-153': 1.4299332134084106, 'IoU-154': 1.557801904334947, 'IoU-155': 1.5501939634780963, 'IoU-156': 1.4584514113069842, 'IoU-157': 1.378355166866253, 'IoU-158': 1.4288130970506088, 'IoU-159': 1.2404338828829207, 'IoU-160': 1.2847654776226713, 'IoU-161': 1.3603820003838616, 'IoU-162': 1.3255824633377216, 'IoU-163': 1.5299824553236776, 'IoU-164': 1.4316057703343075, 'IoU-165': 1.451704083190327, 'IoU-166': 1.3399545123247012, 'IoU-167': 1.2081647631175938, 'IoU-168': 1.235116169459253, 'IoU-169': 1.175616034606846, 'IoU-170': 1.2585683122475178, 'IoU-171': 1.1256564314515283, 'IoU-172': 1.117500695505082, 'IoU-173': 0.9883106986203473, 'IoU-174': 0.9037141890020617, 'IoU-175': 0.9016665677443308, 'IoU-176': 1.0069452943730361, 'IoU-177': 0.9212647784228867, 'IoU-178': 0.9519591342604895, 'IoU-179': 1.050869583860727, 'IoU-180': 0.8856458435976284, 'IoU-181': 0.9053605158600925, 'IoU-182': 0.9934031665596033, 'IoU-183': 0.7722221879834092, 'IoU-184': 0.5239564037576498, 'IoU-185': 0.42080183747278926, 'IoU-186': 0.3871371287515777, 'IoU-187': 0.35316101047010373, 'IoU-188': 0.2872056324350571, 'IoU-189': 0.2581193311256139, 'IoU-190': 0.08769978548069966, 'IoU-191': 0.08390592304189669, 'IoU-192': 0.12520798437404354, 'mACC': 5.672766119372736, 'pACC': 11.661246200292496, 'ACC-0': nan, 'ACC-1': 41.56001156889902, 'ACC-2': 7.790904155868744, 'ACC-3': 15.46963496329298, 'ACC-4': 11.392085949872408, 'ACC-5': 9.593256770768397, 'ACC-6': 8.852142929823382, 'ACC-7': 7.831147379590229, 'ACC-8': 11.049594311139538, 'ACC-9': 17.027181295739986, 'ACC-10': 25.544779441193672, 'ACC-11': 27.108008694076158, 'ACC-12': 23.99043190663936, 'ACC-13': 20.472467895807473, 'ACC-14': 17.77598293392527, 'ACC-15': 15.534907276115398, 'ACC-16': 13.538273384347088, 'ACC-17': 12.316601152149165, 'ACC-18': 10.721932511743832, 'ACC-19': 8.948054482343538, 'ACC-20': 10.094869832414345, 'ACC-21': 10.490082129419415, 'ACC-22': 11.943029659129675, 'ACC-23': 10.906080873573975, 'ACC-24': 9.846270999034429, 'ACC-25': 8.89547171447096, 'ACC-26': 9.403416369349227, 'ACC-27': 8.968654939300718, 'ACC-28': 8.62830344123523, 'ACC-29': 8.491076966949983, 'ACC-30': 7.817047518076853, 'ACC-31': 6.927520235274518, 'ACC-32': 6.63349939077144, 'ACC-33': 6.166289459854947, 'ACC-34': 5.821076229258184, 'ACC-35': 4.939062709102727, 'ACC-36': 5.0800535469658366, 'ACC-37': 4.792853063411698, 'ACC-38': 4.551121553148306, 'ACC-39': 4.415956096541748, 'ACC-40': 4.334565076592256, 'ACC-41': 4.384251530394275, 'ACC-42': 4.415167519284701, 'ACC-43': 4.288485860560415, 'ACC-44': 4.0806160189918925, 'ACC-45': 4.1909250571589025, 'ACC-46': 4.101781683576783, 'ACC-47': 3.964890408089515, 'ACC-48': 3.8654428454912937, 'ACC-49': 3.8634936445134542, 'ACC-50': 4.2386103623410705, 'ACC-51': 3.9598006766119207, 'ACC-52': 3.766820244707515, 'ACC-53': 3.7126462770552524, 'ACC-54': 3.714910122591065, 'ACC-55': 3.702559011762528, 'ACC-56': 3.8533602158569846, 'ACC-57': 4.177871570774543, 'ACC-58': 4.148383868525105, 'ACC-59': 4.143164763905366, 'ACC-60': 4.053703316033415, 'ACC-61': 4.117388496837472, 'ACC-62': 4.370136338495769, 'ACC-63': 4.494002954253343, 'ACC-64': 4.558653775840474, 'ACC-65': 4.846581436054538, 'ACC-66': 4.866097363443064, 'ACC-67': 4.658738319032584, 'ACC-68': 4.840791773194362, 'ACC-69': 4.920803737808942, 'ACC-70': 5.04398348088394, 'ACC-71': 5.4083368110934025, 'ACC-72': 5.551620700131053, 'ACC-73': 5.410840509173422, 'ACC-74': 5.671031853361447, 'ACC-75': 5.717404194863383, 'ACC-76': 5.875197357913952, 'ACC-77': 6.13212253503507, 'ACC-78': 6.400222460181558, 'ACC-79': 6.4586033644188605, 'ACC-80': 6.644760042069035, 'ACC-81': 6.637681063071388, 'ACC-82': 6.747451445086836, 'ACC-83': 6.614543956708673, 'ACC-84': 6.615766586711396, 'ACC-85': 6.863681118080909, 'ACC-86': 6.77180602008672, 'ACC-87': 6.604235731225451, 'ACC-88': 6.914406256260647, 'ACC-89': 6.424009757288849, 'ACC-90': 6.353588929115575, 'ACC-91': 6.281717754812282, 'ACC-92': 6.210924607662335, 'ACC-93': 6.240859669491837, 'ACC-94': 6.365390182726717, 'ACC-95': 6.482675363349902, 'ACC-96': 6.501690544789569, 'ACC-97': 6.379556737579546, 'ACC-98': 6.241985528954638, 'ACC-99': 5.875161118383347, 'ACC-100': 5.6034479263218415, 'ACC-101': 5.511945231106778, 'ACC-102': 5.613819664703217, 'ACC-103': 5.624185321620856, 'ACC-104': 5.5831632276628715, 'ACC-105': 5.638567854179399, 'ACC-106': 5.452156357732991, 'ACC-107': 5.740881558163519, 'ACC-108': 5.846324936222286, 'ACC-109': 5.6716604085428, 'ACC-110': 5.588724933901286, 'ACC-111': 5.562821051615526, 'ACC-112': 5.703621994489299, 'ACC-113': 5.395454805536628, 'ACC-114': 5.5945032009874645, 'ACC-115': 5.263632673311984, 'ACC-116': 5.312093709862268, 'ACC-117': 5.548461136019712, 'ACC-118': 5.425963084305015, 'ACC-119': 5.106331145506162, 'ACC-120': 5.16015876195195, 'ACC-121': 5.054035038632794, 'ACC-122': 4.880268334795777, 'ACC-123': 5.120305367014757, 'ACC-124': 4.693780462532383, 'ACC-125': 4.383252317093466, 'ACC-126': 4.173876811264219, 'ACC-127': 4.335207786260969, 'ACC-128': 4.383021645560203, 'ACC-129': 4.310979386392345, 'ACC-130': 4.406373905887634, 'ACC-131': 4.243998689451079, 'ACC-132': 4.187962698600996, 'ACC-133': 4.0693390054359915, 'ACC-134': 3.937613097802671, 'ACC-135': 4.12192024673657, 'ACC-136': 3.9259778000372716, 'ACC-137': 4.051847900004351, 'ACC-138': 4.152765681342617, 'ACC-139': 4.108536728337622, 'ACC-140': 4.119104767868117, 'ACC-141': 3.992634627182703, 'ACC-142': 4.096750022269692, 'ACC-143': 3.825143977563852, 'ACC-144': 3.666348975989083, 'ACC-145': 3.581283973984548, 'ACC-146': 3.3879344932309854, 'ACC-147': 3.6864446522547047, 'ACC-148': 3.5683901845506, 'ACC-149': 3.2856979141629417, 'ACC-150': 3.170933319712844, 'ACC-151': 3.376767905035198, 'ACC-152': 3.4385074472715473, 'ACC-153': 2.769347409312777, 'ACC-154': 3.036018145883414, 'ACC-155': 3.029809897181744, 'ACC-156': 2.8984888750945665, 'ACC-157': 2.792378851926729, 'ACC-158': 2.9216465588445, 'ACC-159': 2.517786163307964, 'ACC-160': 2.552653427228586, 'ACC-161': 2.629072097159894, 'ACC-162': 2.5776464074583414, 'ACC-163': 2.9147560384516, 'ACC-164': 2.7300365876287187, 'ACC-165': 2.7496628056791628, 'ACC-166': 2.5623974596009718, 'ACC-167': 2.3112196935865867, 'ACC-168': 2.3140126615455245, 'ACC-169': 2.1683933274802456, 'ACC-170': 2.2757181547751184, 'ACC-171': 1.9688701931915957, 'ACC-172': 1.8543444163876437, 'ACC-173': 1.5707999608194758, 'ACC-174': 1.370292535619767, 'ACC-175': 1.3221365281879878, 'ACC-176': 1.4201123225995178, 'ACC-177': 1.2438233848405444, 'ACC-178': 1.2472363694744315, 'ACC-179': 1.345298773433958, 'ACC-180': 1.1060379103882272, 'ACC-181': 1.1219257430443452, 'ACC-182': 1.1854246169618954, 'ACC-183': 0.8867322771492466, 'ACC-184': 0.5816154617903724, 'ACC-185': 0.4547275223601377, 'ACC-186': 0.41036011290230917, 'ACC-187': 0.37026991684062166, 'ACC-188': 0.2988958791278203, 'ACC-189': 0.2672428205820698, 'ACC-190': 0.09012488734389082, 'ACC-191': 0.08593293563151538, 'ACC-192': 0.12788595982675716})])
[01/27 06:06:31] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 06:06:31] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 06:06:31] d2.evaluation.testing INFO: copypaste: 4.5693,0.6819,0.4059,2.9583,8.0448,5.6728,11.6612
[01/27 06:06:32] d2.utils.events INFO:  eta: 1 day, 2:33:00  iter: 4999  total_loss: 41.63  loss_mask: 4.159  loss_mask_0: 4.223  loss_mask_1: 4.152  loss_mask_2: 4.16  loss_mask_3: 4.163  loss_mask_4: 4.177  loss_mask_5: 4.15  loss_mask_6: 4.17  loss_mask_7: 4.15  loss_mask_8: 4.149  time: 1.9592  data_time: 0.3977  lr: 9.2469e-05  max_mem: 17478M
[01/27 06:07:07] d2.utils.events INFO:  eta: 1 day, 2:32:30  iter: 5019  total_loss: 47.88  loss_mask: 4.764  loss_mask_0: 4.842  loss_mask_1: 4.77  loss_mask_2: 4.777  loss_mask_3: 4.792  loss_mask_4: 4.789  loss_mask_5: 4.774  loss_mask_6: 4.789  loss_mask_7: 4.776  loss_mask_8: 4.787  time: 1.9583  data_time: 0.4128  lr: 9.2439e-05  max_mem: 17478M
[01/27 06:07:42] d2.utils.events INFO:  eta: 1 day, 2:32:28  iter: 5039  total_loss: 44.69  loss_mask: 4.467  loss_mask_0: 4.51  loss_mask_1: 4.449  loss_mask_2: 4.451  loss_mask_3: 4.473  loss_mask_4: 4.462  loss_mask_5: 4.454  loss_mask_6: 4.465  loss_mask_7: 4.464  loss_mask_8: 4.465  time: 1.9575  data_time: 0.4006  lr: 9.2409e-05  max_mem: 17478M
[01/27 06:08:16] d2.utils.events INFO:  eta: 1 day, 2:31:07  iter: 5059  total_loss: 45.13  loss_mask: 4.512  loss_mask_0: 4.484  loss_mask_1: 4.509  loss_mask_2: 4.499  loss_mask_3: 4.509  loss_mask_4: 4.511  loss_mask_5: 4.508  loss_mask_6: 4.514  loss_mask_7: 4.52  loss_mask_8: 4.519  time: 1.9566  data_time: 0.3960  lr: 9.2378e-05  max_mem: 17478M
[01/27 06:08:51] d2.utils.events INFO:  eta: 1 day, 2:29:08  iter: 5079  total_loss: 42.78  loss_mask: 4.24  loss_mask_0: 4.498  loss_mask_1: 4.248  loss_mask_2: 4.241  loss_mask_3: 4.266  loss_mask_4: 4.255  loss_mask_5: 4.24  loss_mask_6: 4.253  loss_mask_7: 4.274  loss_mask_8: 4.242  time: 1.9557  data_time: 0.4009  lr: 9.2348e-05  max_mem: 17478M
[01/27 06:09:26] d2.utils.events INFO:  eta: 1 day, 2:28:45  iter: 5099  total_loss: 46.52  loss_mask: 4.674  loss_mask_0: 4.64  loss_mask_1: 4.635  loss_mask_2: 4.63  loss_mask_3: 4.648  loss_mask_4: 4.666  loss_mask_5: 4.646  loss_mask_6: 4.661  loss_mask_7: 4.673  loss_mask_8: 4.656  time: 1.9549  data_time: 0.4109  lr: 9.2318e-05  max_mem: 17478M
[01/27 06:10:01] d2.utils.events INFO:  eta: 1 day, 2:27:56  iter: 5119  total_loss: 44.89  loss_mask: 4.459  loss_mask_0: 4.717  loss_mask_1: 4.478  loss_mask_2: 4.459  loss_mask_3: 4.463  loss_mask_4: 4.483  loss_mask_5: 4.454  loss_mask_6: 4.453  loss_mask_7: 4.47  loss_mask_8: 4.462  time: 1.9541  data_time: 0.4113  lr: 9.2288e-05  max_mem: 17478M
[01/27 06:10:36] d2.utils.events INFO:  eta: 1 day, 2:27:13  iter: 5139  total_loss: 48.2  loss_mask: 4.832  loss_mask_0: 5.052  loss_mask_1: 4.782  loss_mask_2: 4.783  loss_mask_3: 4.817  loss_mask_4: 4.819  loss_mask_5: 4.82  loss_mask_6: 4.843  loss_mask_7: 4.815  loss_mask_8: 4.835  time: 1.9533  data_time: 0.4108  lr: 9.2257e-05  max_mem: 17478M
[01/27 06:11:11] d2.utils.events INFO:  eta: 1 day, 2:27:17  iter: 5159  total_loss: 46.1  loss_mask: 4.624  loss_mask_0: 4.562  loss_mask_1: 4.569  loss_mask_2: 4.591  loss_mask_3: 4.602  loss_mask_4: 4.607  loss_mask_5: 4.6  loss_mask_6: 4.612  loss_mask_7: 4.618  loss_mask_8: 4.621  time: 1.9524  data_time: 0.3921  lr: 9.2227e-05  max_mem: 17478M
[01/27 06:11:46] d2.utils.events INFO:  eta: 1 day, 2:26:26  iter: 5179  total_loss: 46.94  loss_mask: 4.687  loss_mask_0: 4.721  loss_mask_1: 4.697  loss_mask_2: 4.686  loss_mask_3: 4.691  loss_mask_4: 4.702  loss_mask_5: 4.679  loss_mask_6: 4.704  loss_mask_7: 4.684  loss_mask_8: 4.687  time: 1.9516  data_time: 0.3835  lr: 9.2197e-05  max_mem: 17478M
[01/27 06:12:21] d2.utils.events INFO:  eta: 1 day, 2:26:16  iter: 5199  total_loss: 43.14  loss_mask: 4.315  loss_mask_0: 4.379  loss_mask_1: 4.306  loss_mask_2: 4.311  loss_mask_3: 4.309  loss_mask_4: 4.318  loss_mask_5: 4.34  loss_mask_6: 4.31  loss_mask_7: 4.316  loss_mask_8: 4.312  time: 1.9508  data_time: 0.3976  lr: 9.2167e-05  max_mem: 17478M
[01/27 06:12:56] d2.utils.events INFO:  eta: 1 day, 2:25:05  iter: 5219  total_loss: 44.28  loss_mask: 4.42  loss_mask_0: 4.509  loss_mask_1: 4.415  loss_mask_2: 4.414  loss_mask_3: 4.418  loss_mask_4: 4.431  loss_mask_5: 4.429  loss_mask_6: 4.417  loss_mask_7: 4.426  loss_mask_8: 4.412  time: 1.9501  data_time: 0.4046  lr: 9.2136e-05  max_mem: 17478M
[01/27 06:13:30] d2.utils.events INFO:  eta: 1 day, 2:24:19  iter: 5239  total_loss: 42.41  loss_mask: 4.231  loss_mask_0: 4.21  loss_mask_1: 4.234  loss_mask_2: 4.234  loss_mask_3: 4.237  loss_mask_4: 4.241  loss_mask_5: 4.221  loss_mask_6: 4.243  loss_mask_7: 4.235  loss_mask_8: 4.236  time: 1.9492  data_time: 0.4100  lr: 9.2106e-05  max_mem: 17478M
[01/27 06:14:05] d2.utils.events INFO:  eta: 1 day, 2:23:49  iter: 5259  total_loss: 45.15  loss_mask: 4.505  loss_mask_0: 4.559  loss_mask_1: 4.51  loss_mask_2: 4.488  loss_mask_3: 4.507  loss_mask_4: 4.51  loss_mask_5: 4.512  loss_mask_6: 4.52  loss_mask_7: 4.538  loss_mask_8: 4.518  time: 1.9484  data_time: 0.3879  lr: 9.2076e-05  max_mem: 17478M
[01/27 06:14:40] d2.utils.events INFO:  eta: 1 day, 2:23:14  iter: 5279  total_loss: 45.49  loss_mask: 4.557  loss_mask_0: 4.553  loss_mask_1: 4.546  loss_mask_2: 4.562  loss_mask_3: 4.54  loss_mask_4: 4.541  loss_mask_5: 4.588  loss_mask_6: 4.551  loss_mask_7: 4.565  loss_mask_8: 4.572  time: 1.9477  data_time: 0.3994  lr: 9.2045e-05  max_mem: 17478M
[01/27 06:15:15] d2.utils.events INFO:  eta: 1 day, 2:22:31  iter: 5299  total_loss: 40.54  loss_mask: 4.044  loss_mask_0: 4.173  loss_mask_1: 4.042  loss_mask_2: 4.04  loss_mask_3: 4.033  loss_mask_4: 4.044  loss_mask_5: 4.053  loss_mask_6: 4.033  loss_mask_7: 4.05  loss_mask_8: 4.035  time: 1.9469  data_time: 0.3982  lr: 9.2015e-05  max_mem: 17478M
[01/27 06:15:50] d2.utils.events INFO:  eta: 1 day, 2:21:53  iter: 5319  total_loss: 41.57  loss_mask: 4.155  loss_mask_0: 4.253  loss_mask_1: 4.133  loss_mask_2: 4.122  loss_mask_3: 4.133  loss_mask_4: 4.14  loss_mask_5: 4.115  loss_mask_6: 4.132  loss_mask_7: 4.13  loss_mask_8: 4.134  time: 1.9461  data_time: 0.4069  lr: 9.1985e-05  max_mem: 17478M
[01/27 06:16:25] d2.utils.events INFO:  eta: 1 day, 2:21:22  iter: 5339  total_loss: 40.99  loss_mask: 4.089  loss_mask_0: 4.218  loss_mask_1: 4.084  loss_mask_2: 4.08  loss_mask_3: 4.093  loss_mask_4: 4.095  loss_mask_5: 4.09  loss_mask_6: 4.093  loss_mask_7: 4.089  loss_mask_8: 4.086  time: 1.9454  data_time: 0.4066  lr: 9.1955e-05  max_mem: 17478M
[01/27 06:17:00] d2.utils.events INFO:  eta: 1 day, 2:21:14  iter: 5359  total_loss: 41.25  loss_mask: 4.113  loss_mask_0: 4.221  loss_mask_1: 4.107  loss_mask_2: 4.116  loss_mask_3: 4.109  loss_mask_4: 4.112  loss_mask_5: 4.104  loss_mask_6: 4.101  loss_mask_7: 4.117  loss_mask_8: 4.106  time: 1.9447  data_time: 0.4234  lr: 9.1924e-05  max_mem: 17478M
[01/27 06:17:35] d2.utils.events INFO:  eta: 1 day, 2:21:27  iter: 5379  total_loss: 42.4  loss_mask: 4.237  loss_mask_0: 4.377  loss_mask_1: 4.222  loss_mask_2: 4.219  loss_mask_3: 4.221  loss_mask_4: 4.224  loss_mask_5: 4.225  loss_mask_6: 4.213  loss_mask_7: 4.233  loss_mask_8: 4.224  time: 1.9440  data_time: 0.3974  lr: 9.1894e-05  max_mem: 17478M
[01/27 06:18:10] d2.utils.events INFO:  eta: 1 day, 2:21:03  iter: 5399  total_loss: 39.87  loss_mask: 3.976  loss_mask_0: 4.078  loss_mask_1: 3.97  loss_mask_2: 3.962  loss_mask_3: 3.973  loss_mask_4: 3.978  loss_mask_5: 3.982  loss_mask_6: 3.973  loss_mask_7: 3.977  loss_mask_8: 3.982  time: 1.9433  data_time: 0.4136  lr: 9.1864e-05  max_mem: 17478M
[01/27 06:18:45] d2.utils.events INFO:  eta: 1 day, 2:19:52  iter: 5419  total_loss: 41.42  loss_mask: 4.143  loss_mask_0: 4.19  loss_mask_1: 4.138  loss_mask_2: 4.131  loss_mask_3: 4.137  loss_mask_4: 4.135  loss_mask_5: 4.141  loss_mask_6: 4.139  loss_mask_7: 4.133  loss_mask_8: 4.135  time: 1.9424  data_time: 0.3895  lr: 9.1834e-05  max_mem: 17478M
[01/27 06:19:19] d2.utils.events INFO:  eta: 1 day, 2:18:40  iter: 5439  total_loss: 39.04  loss_mask: 3.897  loss_mask_0: 3.979  loss_mask_1: 3.906  loss_mask_2: 3.89  loss_mask_3: 3.894  loss_mask_4: 3.895  loss_mask_5: 3.899  loss_mask_6: 3.896  loss_mask_7: 3.893  loss_mask_8: 3.897  time: 1.9417  data_time: 0.3946  lr: 9.1803e-05  max_mem: 17478M
[01/27 06:19:54] d2.utils.events INFO:  eta: 1 day, 2:18:06  iter: 5459  total_loss: 42.15  loss_mask: 4.216  loss_mask_0: 4.383  loss_mask_1: 4.179  loss_mask_2: 4.202  loss_mask_3: 4.206  loss_mask_4: 4.193  loss_mask_5: 4.18  loss_mask_6: 4.218  loss_mask_7: 4.194  loss_mask_8: 4.178  time: 1.9410  data_time: 0.4117  lr: 9.1773e-05  max_mem: 17478M
[01/27 06:20:29] d2.utils.events INFO:  eta: 1 day, 2:18:08  iter: 5479  total_loss: 42.31  loss_mask: 4.225  loss_mask_0: 4.318  loss_mask_1: 4.223  loss_mask_2: 4.228  loss_mask_3: 4.228  loss_mask_4: 4.215  loss_mask_5: 4.216  loss_mask_6: 4.218  loss_mask_7: 4.214  loss_mask_8: 4.236  time: 1.9403  data_time: 0.4081  lr: 9.1743e-05  max_mem: 17478M
[01/27 06:21:04] d2.utils.events INFO:  eta: 1 day, 2:17:30  iter: 5499  total_loss: 42.18  loss_mask: 4.219  loss_mask_0: 4.291  loss_mask_1: 4.212  loss_mask_2: 4.203  loss_mask_3: 4.217  loss_mask_4: 4.207  loss_mask_5: 4.216  loss_mask_6: 4.221  loss_mask_7: 4.214  loss_mask_8: 4.211  time: 1.9396  data_time: 0.4123  lr: 9.1712e-05  max_mem: 17478M
[01/27 06:21:40] d2.utils.events INFO:  eta: 1 day, 2:16:58  iter: 5519  total_loss: 40.79  loss_mask: 4.071  loss_mask_0: 4.186  loss_mask_1: 4.074  loss_mask_2: 4.083  loss_mask_3: 4.068  loss_mask_4: 4.084  loss_mask_5: 4.083  loss_mask_6: 4.075  loss_mask_7: 4.083  loss_mask_8: 4.083  time: 1.9389  data_time: 0.4033  lr: 9.1682e-05  max_mem: 17478M
[01/27 06:22:15] d2.utils.events INFO:  eta: 1 day, 2:16:33  iter: 5539  total_loss: 40.13  loss_mask: 4.017  loss_mask_0: 4.041  loss_mask_1: 4.004  loss_mask_2: 4.002  loss_mask_3: 4.008  loss_mask_4: 4.005  loss_mask_5: 4.009  loss_mask_6: 4.012  loss_mask_7: 4.012  loss_mask_8: 4.017  time: 1.9382  data_time: 0.4153  lr: 9.1652e-05  max_mem: 17478M
[01/27 06:22:50] d2.utils.events INFO:  eta: 1 day, 2:16:34  iter: 5559  total_loss: 40.62  loss_mask: 4.045  loss_mask_0: 4.184  loss_mask_1: 4.042  loss_mask_2: 4.039  loss_mask_3: 4.051  loss_mask_4: 4.052  loss_mask_5: 4.041  loss_mask_6: 4.047  loss_mask_7: 4.05  loss_mask_8: 4.05  time: 1.9376  data_time: 0.4110  lr: 9.1621e-05  max_mem: 17478M
[01/27 06:23:25] d2.utils.events INFO:  eta: 1 day, 2:16:08  iter: 5579  total_loss: 38.6  loss_mask: 3.854  loss_mask_0: 3.895  loss_mask_1: 3.858  loss_mask_2: 3.857  loss_mask_3: 3.855  loss_mask_4: 3.86  loss_mask_5: 3.852  loss_mask_6: 3.855  loss_mask_7: 3.855  loss_mask_8: 3.855  time: 1.9369  data_time: 0.4098  lr: 9.1591e-05  max_mem: 17478M
[01/27 06:24:00] d2.utils.events INFO:  eta: 1 day, 2:15:56  iter: 5599  total_loss: 40.29  loss_mask: 4.035  loss_mask_0: 4.038  loss_mask_1: 4.021  loss_mask_2: 4.025  loss_mask_3: 4.029  loss_mask_4: 4.033  loss_mask_5: 4.024  loss_mask_6: 4.028  loss_mask_7: 4.03  loss_mask_8: 4.028  time: 1.9362  data_time: 0.4105  lr: 9.1561e-05  max_mem: 17478M
[01/27 06:24:35] d2.utils.events INFO:  eta: 1 day, 2:15:10  iter: 5619  total_loss: 42.42  loss_mask: 4.227  loss_mask_0: 4.356  loss_mask_1: 4.237  loss_mask_2: 4.228  loss_mask_3: 4.226  loss_mask_4: 4.229  loss_mask_5: 4.228  loss_mask_6: 4.233  loss_mask_7: 4.227  loss_mask_8: 4.228  time: 1.9356  data_time: 0.4135  lr: 9.1531e-05  max_mem: 17478M
[01/27 06:25:10] d2.utils.events INFO:  eta: 1 day, 2:15:02  iter: 5639  total_loss: 39.97  loss_mask: 3.992  loss_mask_0: 4.082  loss_mask_1: 3.994  loss_mask_2: 3.989  loss_mask_3: 3.978  loss_mask_4: 3.981  loss_mask_5: 3.994  loss_mask_6: 3.982  loss_mask_7: 3.986  loss_mask_8: 3.994  time: 1.9349  data_time: 0.4044  lr: 9.15e-05  max_mem: 17478M
[01/27 06:25:45] d2.utils.events INFO:  eta: 1 day, 2:13:49  iter: 5659  total_loss: 39.51  loss_mask: 3.94  loss_mask_0: 4.058  loss_mask_1: 3.945  loss_mask_2: 3.932  loss_mask_3: 3.935  loss_mask_4: 3.94  loss_mask_5: 3.937  loss_mask_6: 3.94  loss_mask_7: 3.943  loss_mask_8: 3.939  time: 1.9342  data_time: 0.4039  lr: 9.147e-05  max_mem: 17478M
[01/27 06:26:20] d2.utils.events INFO:  eta: 1 day, 2:13:26  iter: 5679  total_loss: 40.24  loss_mask: 4.014  loss_mask_0: 4.178  loss_mask_1: 4.001  loss_mask_2: 3.993  loss_mask_3: 3.992  loss_mask_4: 4.012  loss_mask_5: 4.007  loss_mask_6: 4.004  loss_mask_7: 4  loss_mask_8: 4.01  time: 1.9335  data_time: 0.4113  lr: 9.144e-05  max_mem: 17478M
[01/27 06:26:54] d2.utils.events INFO:  eta: 1 day, 2:12:22  iter: 5699  total_loss: 38.79  loss_mask: 3.882  loss_mask_0: 3.901  loss_mask_1: 3.87  loss_mask_2: 3.877  loss_mask_3: 3.877  loss_mask_4: 3.878  loss_mask_5: 3.879  loss_mask_6: 3.882  loss_mask_7: 3.88  loss_mask_8: 3.879  time: 1.9328  data_time: 0.4047  lr: 9.1409e-05  max_mem: 17478M
[01/27 06:27:29] d2.utils.events INFO:  eta: 1 day, 2:12:26  iter: 5719  total_loss: 40.62  loss_mask: 4.062  loss_mask_0: 4.166  loss_mask_1: 4.063  loss_mask_2: 4.06  loss_mask_3: 4.058  loss_mask_4: 4.063  loss_mask_5: 4.054  loss_mask_6: 4.055  loss_mask_7: 4.046  loss_mask_8: 4.055  time: 1.9322  data_time: 0.4100  lr: 9.1379e-05  max_mem: 17478M
[01/27 06:28:04] d2.utils.events INFO:  eta: 1 day, 2:12:28  iter: 5739  total_loss: 44.91  loss_mask: 4.484  loss_mask_0: 4.534  loss_mask_1: 4.472  loss_mask_2: 4.483  loss_mask_3: 4.478  loss_mask_4: 4.469  loss_mask_5: 4.489  loss_mask_6: 4.508  loss_mask_7: 4.481  loss_mask_8: 4.473  time: 1.9316  data_time: 0.4146  lr: 9.1349e-05  max_mem: 17478M
[01/27 06:28:39] d2.utils.events INFO:  eta: 1 day, 2:11:51  iter: 5759  total_loss: 49.87  loss_mask: 4.964  loss_mask_0: 5.032  loss_mask_1: 4.992  loss_mask_2: 5.022  loss_mask_3: 5.009  loss_mask_4: 4.977  loss_mask_5: 4.968  loss_mask_6: 4.972  loss_mask_7: 4.976  loss_mask_8: 4.982  time: 1.9309  data_time: 0.3993  lr: 9.1319e-05  max_mem: 17478M
[01/27 06:29:14] d2.utils.events INFO:  eta: 1 day, 2:11:19  iter: 5779  total_loss: 44.62  loss_mask: 4.445  loss_mask_0: 4.628  loss_mask_1: 4.443  loss_mask_2: 4.458  loss_mask_3: 4.481  loss_mask_4: 4.453  loss_mask_5: 4.474  loss_mask_6: 4.469  loss_mask_7: 4.474  loss_mask_8: 4.459  time: 1.9302  data_time: 0.4051  lr: 9.1288e-05  max_mem: 17478M
[01/27 06:29:49] d2.utils.events INFO:  eta: 1 day, 2:11:09  iter: 5799  total_loss: 43.15  loss_mask: 4.323  loss_mask_0: 4.328  loss_mask_1: 4.309  loss_mask_2: 4.301  loss_mask_3: 4.314  loss_mask_4: 4.316  loss_mask_5: 4.312  loss_mask_6: 4.318  loss_mask_7: 4.316  loss_mask_8: 4.31  time: 1.9296  data_time: 0.4077  lr: 9.1258e-05  max_mem: 17478M
[01/27 06:30:24] d2.utils.events INFO:  eta: 1 day, 2:10:42  iter: 5819  total_loss: 41.34  loss_mask: 4.131  loss_mask_0: 4.316  loss_mask_1: 4.12  loss_mask_2: 4.117  loss_mask_3: 4.115  loss_mask_4: 4.122  loss_mask_5: 4.125  loss_mask_6: 4.121  loss_mask_7: 4.119  loss_mask_8: 4.129  time: 1.9289  data_time: 0.4131  lr: 9.1228e-05  max_mem: 17478M
[01/27 06:30:59] d2.utils.events INFO:  eta: 1 day, 2:09:35  iter: 5839  total_loss: 48.47  loss_mask: 4.832  loss_mask_0: 4.959  loss_mask_1: 4.823  loss_mask_2: 4.802  loss_mask_3: 4.831  loss_mask_4: 4.838  loss_mask_5: 4.835  loss_mask_6: 4.825  loss_mask_7: 4.832  loss_mask_8: 4.847  time: 1.9283  data_time: 0.3919  lr: 9.1197e-05  max_mem: 17478M
[01/27 06:31:34] d2.utils.events INFO:  eta: 1 day, 2:08:56  iter: 5859  total_loss: 41.88  loss_mask: 4.176  loss_mask_0: 4.345  loss_mask_1: 4.163  loss_mask_2: 4.131  loss_mask_3: 4.17  loss_mask_4: 4.148  loss_mask_5: 4.208  loss_mask_6: 4.198  loss_mask_7: 4.151  loss_mask_8: 4.188  time: 1.9277  data_time: 0.4158  lr: 9.1167e-05  max_mem: 17478M
[01/27 06:32:08] d2.utils.events INFO:  eta: 1 day, 2:08:16  iter: 5879  total_loss: 42.02  loss_mask: 4.186  loss_mask_0: 4.322  loss_mask_1: 4.183  loss_mask_2: 4.183  loss_mask_3: 4.191  loss_mask_4: 4.171  loss_mask_5: 4.202  loss_mask_6: 4.201  loss_mask_7: 4.171  loss_mask_8: 4.206  time: 1.9270  data_time: 0.4158  lr: 9.1137e-05  max_mem: 17478M
[01/27 06:32:44] d2.utils.events INFO:  eta: 1 day, 2:07:46  iter: 5899  total_loss: 41.92  loss_mask: 4.205  loss_mask_0: 4.3  loss_mask_1: 4.183  loss_mask_2: 4.181  loss_mask_3: 4.184  loss_mask_4: 4.188  loss_mask_5: 4.175  loss_mask_6: 4.17  loss_mask_7: 4.2  loss_mask_8: 4.175  time: 1.9265  data_time: 0.4114  lr: 9.1106e-05  max_mem: 17478M
[01/27 06:33:18] d2.utils.events INFO:  eta: 1 day, 2:07:13  iter: 5919  total_loss: 41.8  loss_mask: 4.168  loss_mask_0: 4.303  loss_mask_1: 4.17  loss_mask_2: 4.16  loss_mask_3: 4.165  loss_mask_4: 4.171  loss_mask_5: 4.169  loss_mask_6: 4.171  loss_mask_7: 4.16  loss_mask_8: 4.163  time: 1.9258  data_time: 0.4009  lr: 9.1076e-05  max_mem: 17478M
[01/27 06:33:53] d2.utils.events INFO:  eta: 1 day, 2:06:03  iter: 5939  total_loss: 42.68  loss_mask: 4.259  loss_mask_0: 4.385  loss_mask_1: 4.258  loss_mask_2: 4.247  loss_mask_3: 4.257  loss_mask_4: 4.265  loss_mask_5: 4.26  loss_mask_6: 4.259  loss_mask_7: 4.256  loss_mask_8: 4.264  time: 1.9252  data_time: 0.3767  lr: 9.1046e-05  max_mem: 17478M
[01/27 06:34:28] d2.utils.events INFO:  eta: 1 day, 2:05:45  iter: 5959  total_loss: 43.23  loss_mask: 4.328  loss_mask_0: 4.388  loss_mask_1: 4.323  loss_mask_2: 4.326  loss_mask_3: 4.322  loss_mask_4: 4.309  loss_mask_5: 4.34  loss_mask_6: 4.317  loss_mask_7: 4.317  loss_mask_8: 4.309  time: 1.9245  data_time: 0.4009  lr: 9.1015e-05  max_mem: 17478M
[01/27 06:35:03] d2.utils.events INFO:  eta: 1 day, 2:05:10  iter: 5979  total_loss: 43.64  loss_mask: 4.344  loss_mask_0: 4.427  loss_mask_1: 4.351  loss_mask_2: 4.329  loss_mask_3: 4.36  loss_mask_4: 4.381  loss_mask_5: 4.351  loss_mask_6: 4.36  loss_mask_7: 4.354  loss_mask_8: 4.369  time: 1.9239  data_time: 0.3878  lr: 9.0985e-05  max_mem: 17478M
[01/27 06:35:37] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 06:35:37] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 06:35:37] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 06:42:18] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.736757816239972, 'error_1pix': 0.6763631099087645, 'error_3pix': 0.40812979047993647, 'mIoU': 2.2226924047930314, 'fwIoU': 6.6358052571088315, 'IoU-0': nan, 'IoU-1': 24.72425575277244, 'IoU-2': 2.3830903612571954, 'IoU-3': 1.402680874813265, 'IoU-4': 1.1540968332845736, 'IoU-5': 1.0231441746714514, 'IoU-6': 1.079546857183391, 'IoU-7': 0.9776598024829769, 'IoU-8': 2.1221330536683234, 'IoU-9': 5.537097899862079, 'IoU-10': 12.061103513739594, 'IoU-11': 18.52712226200281, 'IoU-12': 17.62525483944816, 'IoU-13': 14.83045689928059, 'IoU-14': 13.092852265757712, 'IoU-15': 11.224819289285294, 'IoU-16': 9.569070189778015, 'IoU-17': 8.20108333189852, 'IoU-18': 7.490678502973309, 'IoU-19': 6.927718022328768, 'IoU-20': 7.199377748192603, 'IoU-21': 7.4382109362644915, 'IoU-22': 7.075305661181458, 'IoU-23': 5.997021770550577, 'IoU-24': 5.812293433363808, 'IoU-25': 5.101115700209051, 'IoU-26': 5.0025690247999615, 'IoU-27': 4.451610031040536, 'IoU-28': 4.219678248721237, 'IoU-29': 4.314957159195198, 'IoU-30': 3.7816709234282464, 'IoU-31': 3.377267183088961, 'IoU-32': 2.9923913425447988, 'IoU-33': 2.704978818659942, 'IoU-34': 2.6749544773355822, 'IoU-35': 2.3195931057380106, 'IoU-36': 2.3609546637135446, 'IoU-37': 2.1820867960243224, 'IoU-38': 2.0534528158100573, 'IoU-39': 2.0269767022192506, 'IoU-40': 2.093564404840909, 'IoU-41': 2.0093322096415376, 'IoU-42': 2.089694702759224, 'IoU-43': 2.0995970241131396, 'IoU-44': 2.0505434981595436, 'IoU-45': 2.0716368896183246, 'IoU-46': 2.1510393231910294, 'IoU-47': 2.074030532152208, 'IoU-48': 2.0645969822264116, 'IoU-49': 2.049912715706596, 'IoU-50': 1.97706314123345, 'IoU-51': 2.030156272982693, 'IoU-52': 2.1102652706535077, 'IoU-53': 1.9551019849520113, 'IoU-54': 1.9392943860136644, 'IoU-55': 1.88968106545317, 'IoU-56': 1.975780776673579, 'IoU-57': 2.1245018549613914, 'IoU-58': 2.207581837996644, 'IoU-59': 2.275842410103896, 'IoU-60': 2.134154324903514, 'IoU-61': 2.0204468332425365, 'IoU-62': 2.132515952192834, 'IoU-63': 2.1040834275186344, 'IoU-64': 2.1211830419009643, 'IoU-65': 1.9851220097957971, 'IoU-66': 1.983679646371933, 'IoU-67': 1.8430458407291017, 'IoU-68': 1.8588018453474016, 'IoU-69': 1.789579690245716, 'IoU-70': 1.7899225134055265, 'IoU-71': 1.8289844764327101, 'IoU-72': 1.9156988895203744, 'IoU-73': 1.8996866632211211, 'IoU-74': 1.8066967269090306, 'IoU-75': 1.774857587148853, 'IoU-76': 1.7947404163260992, 'IoU-77': 1.7202889206754663, 'IoU-78': 1.7061232449189878, 'IoU-79': 1.6943723002404056, 'IoU-80': 1.6530443982219118, 'IoU-81': 1.7500243094681087, 'IoU-82': 1.5430141913725084, 'IoU-83': 1.5755336695576205, 'IoU-84': 1.565946589298877, 'IoU-85': 1.4447876113505296, 'IoU-86': 1.3422910147800604, 'IoU-87': 1.2939119804320802, 'IoU-88': 1.2442337208857452, 'IoU-89': 1.2709755293268543, 'IoU-90': 1.176048080502781, 'IoU-91': 1.2007476194536304, 'IoU-92': 1.1609485649750961, 'IoU-93': 1.1393669458601177, 'IoU-94': 1.1250766778314185, 'IoU-95': 1.1183449927730595, 'IoU-96': 1.1093804622331729, 'IoU-97': 1.1158494674366217, 'IoU-98': 1.0238903544526947, 'IoU-99': 1.0498734743867661, 'IoU-100': 1.0700564496729095, 'IoU-101': 1.0705978459910082, 'IoU-102': 1.0771289591912443, 'IoU-103': 1.0263581049862303, 'IoU-104': 1.0594174861144483, 'IoU-105': 1.1165997232054048, 'IoU-106': 1.10366110839286, 'IoU-107': 1.1644387906661846, 'IoU-108': 1.2617715396536122, 'IoU-109': 1.3498394241501301, 'IoU-110': 1.3401809776607079, 'IoU-111': 1.231912193877076, 'IoU-112': 1.140592474317464, 'IoU-113': 1.0899285057214132, 'IoU-114': 1.1094312088367126, 'IoU-115': 1.1410659200278328, 'IoU-116': 1.2648232847301977, 'IoU-117': 1.5133320953776108, 'IoU-118': 1.3732686975678037, 'IoU-119': 1.4224146488707967, 'IoU-120': 1.3694098049065193, 'IoU-121': 1.3659881614534175, 'IoU-122': 1.3873915568132544, 'IoU-123': 1.370398837115346, 'IoU-124': 1.3637311955397529, 'IoU-125': 1.3650013484194339, 'IoU-126': 1.398232360600461, 'IoU-127': 1.4347160028281876, 'IoU-128': 1.3694742759962235, 'IoU-129': 1.4176895951893436, 'IoU-130': 1.326424124402108, 'IoU-131': 1.3438600944119627, 'IoU-132': 1.4254875865311516, 'IoU-133': 1.433436032907693, 'IoU-134': 1.4374287572997095, 'IoU-135': 1.3567737079876705, 'IoU-136': 1.3147481193720805, 'IoU-137': 1.3195935065711162, 'IoU-138': 1.3643745587214005, 'IoU-139': 1.3358392012735865, 'IoU-140': 1.3877253734723631, 'IoU-141': 1.3121701692351777, 'IoU-142': 1.3558207392367563, 'IoU-143': 1.281627391412971, 'IoU-144': 1.2227316546900826, 'IoU-145': 1.2117962820454786, 'IoU-146': 1.2347107325529054, 'IoU-147': 1.3883915002211917, 'IoU-148': 1.4768201427635814, 'IoU-149': 1.3299329489420542, 'IoU-150': 1.263688557140261, 'IoU-151': 1.1415007210331027, 'IoU-152': 1.0102866501532792, 'IoU-153': 0.9667625142998485, 'IoU-154': 0.9535675539385104, 'IoU-155': 0.9749169643835324, 'IoU-156': 0.9293479253318949, 'IoU-157': 0.9235195432069696, 'IoU-158': 0.9167727548465923, 'IoU-159': 0.7316463770770619, 'IoU-160': 0.7470225838173123, 'IoU-161': 0.7521581761436842, 'IoU-162': 0.6740112838703732, 'IoU-163': 0.6664221646238419, 'IoU-164': 0.47981169654173456, 'IoU-165': 0.4407494755804169, 'IoU-166': 0.42658693047032914, 'IoU-167': 0.43934609851008566, 'IoU-168': 0.3261683242433964, 'IoU-169': 0.2942976632133936, 'IoU-170': 0.29004209780855333, 'IoU-171': 0.26119084979771495, 'IoU-172': 0.19028707101230302, 'IoU-173': 0.11209801793568289, 'IoU-174': 0.08466882982643789, 'IoU-175': 0.09003623057918507, 'IoU-176': 0.07112160011122777, 'IoU-177': 0.0457075843632715, 'IoU-178': 0.02353648058814412, 'IoU-179': 0.010682274881134497, 'IoU-180': 0.006533165297511918, 'IoU-181': 0.008500008263896923, 'IoU-182': 0.002364150028960838, 'IoU-183': 0.0009402052938259069, 'IoU-184': 0.0009422251117125649, 'IoU-185': 0.005076762963629609, 'IoU-186': 0.0014152779252025616, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0002566274026740575, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.00028294786402657444, 'mACC': 4.192080446287902, 'pACC': 10.312936531696709, 'ACC-0': nan, 'ACC-1': 25.03786050884186, 'ACC-2': 6.136677287088643, 'ACC-3': 9.19639700428191, 'ACC-4': 6.617614520937005, 'ACC-5': 5.762550836985495, 'ACC-6': 5.958053728892775, 'ACC-7': 5.405449752234267, 'ACC-8': 5.167910882810496, 'ACC-9': 8.745892783344669, 'ACC-10': 20.029830517773004, 'ACC-11': 29.96405010275631, 'ACC-12': 30.556016879388633, 'ACC-13': 26.263679196838076, 'ACC-14': 23.749278226560104, 'ACC-15': 21.46554102626874, 'ACC-16': 18.34289434053573, 'ACC-17': 16.404782051913124, 'ACC-18': 14.333811239963998, 'ACC-19': 13.4550218793749, 'ACC-20': 14.48509139960823, 'ACC-21': 15.087142859024233, 'ACC-22': 13.798667173797902, 'ACC-23': 12.122212307609404, 'ACC-24': 12.016886689253719, 'ACC-25': 10.8134376441536, 'ACC-26': 10.627120976331428, 'ACC-27': 9.238877202123524, 'ACC-28': 9.001215334780769, 'ACC-29': 8.888703455912118, 'ACC-30': 7.939117760493045, 'ACC-31': 6.907351752483998, 'ACC-32': 6.2372342024871426, 'ACC-33': 5.801133308632146, 'ACC-34': 5.6822205527710885, 'ACC-35': 4.714952411182553, 'ACC-36': 4.600170159481218, 'ACC-37': 4.208876396434266, 'ACC-38': 3.8724338359936676, 'ACC-39': 3.7905965371572856, 'ACC-40': 3.8958075968015615, 'ACC-41': 3.845209262436084, 'ACC-42': 3.9913631350353453, 'ACC-43': 3.9848135444333472, 'ACC-44': 3.7928104831978926, 'ACC-45': 3.8773339167821774, 'ACC-46': 4.11095450420884, 'ACC-47': 3.943816064732953, 'ACC-48': 3.910280129725965, 'ACC-49': 3.827280485761205, 'ACC-50': 3.674267623154135, 'ACC-51': 3.802085784352173, 'ACC-52': 3.940797546653511, 'ACC-53': 3.6301333522705472, 'ACC-54': 3.519877355159168, 'ACC-55': 3.4142149909777104, 'ACC-56': 3.5794384549864158, 'ACC-57': 3.8077712070560024, 'ACC-58': 4.00890263867982, 'ACC-59': 4.201439605240998, 'ACC-60': 3.9887457385650507, 'ACC-61': 3.8250416016710114, 'ACC-62': 4.082338665412335, 'ACC-63': 4.094110750560379, 'ACC-64': 4.138764632432014, 'ACC-65': 3.8943521571680315, 'ACC-66': 3.908167966800094, 'ACC-67': 3.662418798483117, 'ACC-68': 3.715324271184444, 'ACC-69': 3.536369249189628, 'ACC-70': 3.531810397012021, 'ACC-71': 3.6943680133545986, 'ACC-72': 3.8881345845282675, 'ACC-73': 3.850976478507396, 'ACC-74': 3.633143495404882, 'ACC-75': 3.582636537266623, 'ACC-76': 3.552400088284173, 'ACC-77': 3.441917727050334, 'ACC-78': 3.4140361548818006, 'ACC-79': 3.3692082752616828, 'ACC-80': 3.233578795012535, 'ACC-81': 3.390019246174864, 'ACC-82': 2.9892850769882644, 'ACC-83': 3.0019435555324554, 'ACC-84': 2.960276910105497, 'ACC-85': 2.722236958014103, 'ACC-86': 2.5141068916100977, 'ACC-87': 2.4137482149656107, 'ACC-88': 2.2971185878720224, 'ACC-89': 2.303274711270635, 'ACC-90': 2.0958260122847716, 'ACC-91': 2.138661512447879, 'ACC-92': 2.065767314966059, 'ACC-93': 2.0064199427482183, 'ACC-94': 1.9596412610600629, 'ACC-95': 1.9301379738029207, 'ACC-96': 1.9141466699773135, 'ACC-97': 1.9039249394221265, 'ACC-98': 1.7583950314837937, 'ACC-99': 1.817195525787812, 'ACC-100': 1.8577063399578475, 'ACC-101': 1.8748785616889425, 'ACC-102': 1.8951517897598549, 'ACC-103': 1.789246245395296, 'ACC-104': 1.8315093086741594, 'ACC-105': 1.9220538820717699, 'ACC-106': 1.886254151985414, 'ACC-107': 1.9861058531215052, 'ACC-108': 2.135181945082767, 'ACC-109': 2.275519041564432, 'ACC-110': 2.2856710995435643, 'ACC-111': 2.1149331485567777, 'ACC-112': 1.9815967418932707, 'ACC-113': 1.899050006848828, 'ACC-114': 1.9371741295635527, 'ACC-115': 1.9872055086975478, 'ACC-116': 2.220476315495739, 'ACC-117': 2.6525181885469014, 'ACC-118': 2.4291503075328222, 'ACC-119': 2.489001890169446, 'ACC-120': 2.3817367531458973, 'ACC-121': 2.3658412619394658, 'ACC-122': 2.4211459896024983, 'ACC-123': 2.4184428098028494, 'ACC-124': 2.455009080491673, 'ACC-125': 2.4444098794491405, 'ACC-126': 2.517156349329229, 'ACC-127': 2.5883920978609276, 'ACC-128': 2.492709396736883, 'ACC-129': 2.5990879534425773, 'ACC-130': 2.4476773732532253, 'ACC-131': 2.4982837258666604, 'ACC-132': 2.615167569777456, 'ACC-133': 2.6110623473296726, 'ACC-134': 2.6122533390779834, 'ACC-135': 2.488384356650134, 'ACC-136': 2.4331438688035782, 'ACC-137': 2.4943196432346704, 'ACC-138': 2.6195681143234255, 'ACC-139': 2.5948696170454184, 'ACC-140': 2.6795342619602542, 'ACC-141': 2.5086722130679857, 'ACC-142': 2.596280896825584, 'ACC-143': 2.4800220694017985, 'ACC-144': 2.354693140794224, 'ACC-145': 2.2987097207003737, 'ACC-146': 2.3211715519407825, 'ACC-147': 2.5702451022721893, 'ACC-148': 2.7199251747301223, 'ACC-149': 2.4813679367265373, 'ACC-150': 2.3483402664787714, 'ACC-151': 2.1023687085342786, 'ACC-152': 1.8303643869738664, 'ACC-153': 1.790300952407127, 'ACC-154': 1.74516565746941, 'ACC-155': 1.7988058906763824, 'ACC-156': 1.7105906139872327, 'ACC-157': 1.7082395917972923, 'ACC-158': 1.6657939936574784, 'ACC-159': 1.2910881319697067, 'ACC-160': 1.2566167488576212, 'ACC-161': 1.2033914012980338, 'ACC-162': 1.055486297273736, 'ACC-163': 0.9916428068062131, 'ACC-164': 0.6806550016172096, 'ACC-165': 0.5906474728737326, 'ACC-166': 0.5551908751936957, 'ACC-167': 0.553275093240316, 'ACC-168': 0.39683167620504434, 'ACC-169': 0.34340201373608054, 'ACC-170': 0.32707518825013887, 'ACC-171': 0.28710296030154075, 'ACC-172': 0.20409750749160088, 'ACC-173': 0.11815549488902227, 'ACC-174': 0.08779500332726287, 'ACC-175': 0.09244211736820988, 'ACC-176': 0.07237504421407777, 'ACC-177': 0.04632124428827685, 'ACC-178': 0.023758428930426435, 'ACC-179': 0.010753102675899457, 'ACC-180': 0.006561929800051648, 'ACC-181': 0.008527410888556214, 'ACC-182': 0.0023691685876675297, 'ACC-183': 0.000941728212529223, 'ACC-184': 0.0009433584030828952, 'ACC-185': 0.005081136511661208, 'ACC-186': 0.0014163904705249144, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0002567268862366149, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.00028299030192235317})])
[01/27 06:42:18] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 06:42:18] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 06:42:18] d2.evaluation.testing INFO: copypaste: 4.7368,0.6764,0.4081,2.2227,6.6358,4.1921,10.3129
[01/27 06:42:18] d2.utils.events INFO:  eta: 1 day, 2:03:50  iter: 5999  total_loss: 44.11  loss_mask: 4.398  loss_mask_0: 4.504  loss_mask_1: 4.391  loss_mask_2: 4.375  loss_mask_3: 4.392  loss_mask_4: 4.404  loss_mask_5: 4.43  loss_mask_6: 4.373  loss_mask_7: 4.403  loss_mask_8: 4.455  time: 1.9232  data_time: 0.3973  lr: 9.0955e-05  max_mem: 17478M
[01/27 06:42:53] d2.utils.events INFO:  eta: 1 day, 2:03:06  iter: 6019  total_loss: 45.21  loss_mask: 4.517  loss_mask_0: 4.752  loss_mask_1: 4.489  loss_mask_2: 4.477  loss_mask_3: 4.476  loss_mask_4: 4.508  loss_mask_5: 4.491  loss_mask_6: 4.473  loss_mask_7: 4.498  loss_mask_8: 4.505  time: 1.9226  data_time: 0.4089  lr: 9.0924e-05  max_mem: 17478M
[01/27 06:43:28] d2.utils.events INFO:  eta: 1 day, 2:02:31  iter: 6039  total_loss: 42.52  loss_mask: 4.241  loss_mask_0: 4.244  loss_mask_1: 4.24  loss_mask_2: 4.243  loss_mask_3: 4.243  loss_mask_4: 4.244  loss_mask_5: 4.232  loss_mask_6: 4.241  loss_mask_7: 4.269  loss_mask_8: 4.234  time: 1.9220  data_time: 0.4069  lr: 9.0894e-05  max_mem: 17478M
[01/27 06:44:03] d2.utils.events INFO:  eta: 1 day, 2:03:08  iter: 6059  total_loss: 41.67  loss_mask: 4.161  loss_mask_0: 4.24  loss_mask_1: 4.16  loss_mask_2: 4.147  loss_mask_3: 4.167  loss_mask_4: 4.167  loss_mask_5: 4.145  loss_mask_6: 4.168  loss_mask_7: 4.177  loss_mask_8: 4.165  time: 1.9215  data_time: 0.4326  lr: 9.0864e-05  max_mem: 17478M
[01/27 06:44:38] d2.utils.events INFO:  eta: 1 day, 2:02:33  iter: 6079  total_loss: 42.74  loss_mask: 4.272  loss_mask_0: 4.288  loss_mask_1: 4.272  loss_mask_2: 4.275  loss_mask_3: 4.279  loss_mask_4: 4.272  loss_mask_5: 4.281  loss_mask_6: 4.271  loss_mask_7: 4.269  loss_mask_8: 4.271  time: 1.9210  data_time: 0.4055  lr: 9.0833e-05  max_mem: 17478M
[01/27 06:45:14] d2.utils.events INFO:  eta: 1 day, 2:02:06  iter: 6099  total_loss: 43.53  loss_mask: 4.345  loss_mask_0: 4.44  loss_mask_1: 4.349  loss_mask_2: 4.335  loss_mask_3: 4.336  loss_mask_4: 4.308  loss_mask_5: 4.336  loss_mask_6: 4.34  loss_mask_7: 4.317  loss_mask_8: 4.347  time: 1.9204  data_time: 0.4301  lr: 9.0803e-05  max_mem: 17478M
[01/27 06:45:49] d2.utils.events INFO:  eta: 1 day, 2:01:52  iter: 6119  total_loss: 46.65  loss_mask: 4.64  loss_mask_0: 4.707  loss_mask_1: 4.64  loss_mask_2: 4.625  loss_mask_3: 4.666  loss_mask_4: 4.635  loss_mask_5: 4.626  loss_mask_6: 4.645  loss_mask_7: 4.646  loss_mask_8: 4.64  time: 1.9199  data_time: 0.3974  lr: 9.0773e-05  max_mem: 17478M
[01/27 06:46:24] d2.utils.events INFO:  eta: 1 day, 2:01:29  iter: 6139  total_loss: 40.32  loss_mask: 4.019  loss_mask_0: 4.104  loss_mask_1: 4.034  loss_mask_2: 4.023  loss_mask_3: 4.018  loss_mask_4: 4.048  loss_mask_5: 4.027  loss_mask_6: 4.029  loss_mask_7: 4.022  loss_mask_8: 4.024  time: 1.9193  data_time: 0.3999  lr: 9.0743e-05  max_mem: 17478M
[01/27 06:46:58] d2.utils.events INFO:  eta: 1 day, 2:00:43  iter: 6159  total_loss: 39.73  loss_mask: 3.969  loss_mask_0: 4.05  loss_mask_1: 3.956  loss_mask_2: 3.96  loss_mask_3: 3.968  loss_mask_4: 3.967  loss_mask_5: 3.972  loss_mask_6: 3.969  loss_mask_7: 3.956  loss_mask_8: 3.965  time: 1.9186  data_time: 0.3935  lr: 9.0712e-05  max_mem: 17478M
[01/27 06:47:32] d2.utils.events INFO:  eta: 1 day, 2:00:00  iter: 6179  total_loss: 40.85  loss_mask: 4.075  loss_mask_0: 4.092  loss_mask_1: 4.071  loss_mask_2: 4.07  loss_mask_3: 4.071  loss_mask_4: 4.072  loss_mask_5: 4.075  loss_mask_6: 4.053  loss_mask_7: 4.075  loss_mask_8: 4.082  time: 1.9180  data_time: 0.3901  lr: 9.0682e-05  max_mem: 17478M
[01/27 06:48:07] d2.utils.events INFO:  eta: 1 day, 1:59:12  iter: 6199  total_loss: 39.67  loss_mask: 3.958  loss_mask_0: 4.061  loss_mask_1: 3.962  loss_mask_2: 3.957  loss_mask_3: 3.964  loss_mask_4: 3.955  loss_mask_5: 3.958  loss_mask_6: 3.951  loss_mask_7: 3.95  loss_mask_8: 3.955  time: 1.9175  data_time: 0.4081  lr: 9.0652e-05  max_mem: 17478M
[01/27 06:48:42] d2.utils.events INFO:  eta: 1 day, 1:58:34  iter: 6219  total_loss: 44.77  loss_mask: 4.468  loss_mask_0: 4.638  loss_mask_1: 4.467  loss_mask_2: 4.466  loss_mask_3: 4.464  loss_mask_4: 4.439  loss_mask_5: 4.46  loss_mask_6: 4.462  loss_mask_7: 4.408  loss_mask_8: 4.457  time: 1.9169  data_time: 0.4083  lr: 9.0621e-05  max_mem: 17478M
[01/27 06:49:17] d2.utils.events INFO:  eta: 1 day, 1:58:07  iter: 6239  total_loss: 44  loss_mask: 4.392  loss_mask_0: 4.455  loss_mask_1: 4.393  loss_mask_2: 4.388  loss_mask_3: 4.393  loss_mask_4: 4.393  loss_mask_5: 4.4  loss_mask_6: 4.412  loss_mask_7: 4.394  loss_mask_8: 4.407  time: 1.9164  data_time: 0.4104  lr: 9.0591e-05  max_mem: 17478M
[01/27 06:49:52] d2.utils.events INFO:  eta: 1 day, 1:57:30  iter: 6259  total_loss: 39.53  loss_mask: 3.942  loss_mask_0: 4.013  loss_mask_1: 3.941  loss_mask_2: 3.943  loss_mask_3: 3.947  loss_mask_4: 3.955  loss_mask_5: 3.936  loss_mask_6: 3.948  loss_mask_7: 3.934  loss_mask_8: 3.944  time: 1.9158  data_time: 0.3959  lr: 9.0561e-05  max_mem: 17478M
[01/27 06:50:27] d2.utils.events INFO:  eta: 1 day, 1:56:57  iter: 6279  total_loss: 41.97  loss_mask: 4.198  loss_mask_0: 4.429  loss_mask_1: 4.189  loss_mask_2: 4.196  loss_mask_3: 4.179  loss_mask_4: 4.193  loss_mask_5: 4.184  loss_mask_6: 4.175  loss_mask_7: 4.191  loss_mask_8: 4.2  time: 1.9152  data_time: 0.4177  lr: 9.053e-05  max_mem: 17478M
[01/27 06:51:02] d2.utils.events INFO:  eta: 1 day, 1:57:16  iter: 6299  total_loss: 41.67  loss_mask: 4.164  loss_mask_0: 4.193  loss_mask_1: 4.164  loss_mask_2: 4.171  loss_mask_3: 4.154  loss_mask_4: 4.163  loss_mask_5: 4.177  loss_mask_6: 4.164  loss_mask_7: 4.161  loss_mask_8: 4.163  time: 1.9148  data_time: 0.4214  lr: 9.05e-05  max_mem: 17478M
[01/27 06:51:37] d2.utils.events INFO:  eta: 1 day, 1:57:13  iter: 6319  total_loss: 44.86  loss_mask: 4.478  loss_mask_0: 4.505  loss_mask_1: 4.455  loss_mask_2: 4.461  loss_mask_3: 4.455  loss_mask_4: 4.448  loss_mask_5: 4.455  loss_mask_6: 4.466  loss_mask_7: 4.487  loss_mask_8: 4.482  time: 1.9142  data_time: 0.4160  lr: 9.047e-05  max_mem: 17478M
[01/27 06:52:12] d2.utils.events INFO:  eta: 1 day, 1:56:07  iter: 6339  total_loss: 48.52  loss_mask: 4.822  loss_mask_0: 5.144  loss_mask_1: 4.822  loss_mask_2: 4.834  loss_mask_3: 4.825  loss_mask_4: 4.824  loss_mask_5: 4.811  loss_mask_6: 4.834  loss_mask_7: 4.829  loss_mask_8: 4.837  time: 1.9137  data_time: 0.4112  lr: 9.0439e-05  max_mem: 17478M
[01/27 06:52:47] d2.utils.events INFO:  eta: 1 day, 1:55:30  iter: 6359  total_loss: 49.08  loss_mask: 4.842  loss_mask_0: 5.204  loss_mask_1: 4.872  loss_mask_2: 4.865  loss_mask_3: 4.87  loss_mask_4: 4.872  loss_mask_5: 4.88  loss_mask_6: 4.877  loss_mask_7: 4.859  loss_mask_8: 4.853  time: 1.9132  data_time: 0.4017  lr: 9.0409e-05  max_mem: 17478M
[01/27 06:53:22] d2.utils.events INFO:  eta: 1 day, 1:54:47  iter: 6379  total_loss: 44.77  loss_mask: 4.473  loss_mask_0: 4.682  loss_mask_1: 4.475  loss_mask_2: 4.479  loss_mask_3: 4.474  loss_mask_4: 4.484  loss_mask_5: 4.481  loss_mask_6: 4.487  loss_mask_7: 4.476  loss_mask_8: 4.485  time: 1.9127  data_time: 0.4203  lr: 9.0379e-05  max_mem: 17478M
[01/27 06:53:57] d2.utils.events INFO:  eta: 1 day, 1:54:04  iter: 6399  total_loss: 42.46  loss_mask: 4.192  loss_mask_0: 4.43  loss_mask_1: 4.206  loss_mask_2: 4.2  loss_mask_3: 4.188  loss_mask_4: 4.204  loss_mask_5: 4.19  loss_mask_6: 4.179  loss_mask_7: 4.192  loss_mask_8: 4.192  time: 1.9121  data_time: 0.3790  lr: 9.0348e-05  max_mem: 17478M
[01/27 06:54:31] d2.utils.events INFO:  eta: 1 day, 1:53:46  iter: 6419  total_loss: 38.82  loss_mask: 3.9  loss_mask_0: 3.988  loss_mask_1: 3.875  loss_mask_2: 3.876  loss_mask_3: 3.882  loss_mask_4: 3.878  loss_mask_5: 3.896  loss_mask_6: 3.898  loss_mask_7: 3.883  loss_mask_8: 3.892  time: 1.9115  data_time: 0.4036  lr: 9.0318e-05  max_mem: 17478M
[01/27 06:55:06] d2.utils.events INFO:  eta: 1 day, 1:53:11  iter: 6439  total_loss: 37.89  loss_mask: 3.785  loss_mask_0: 3.835  loss_mask_1: 3.783  loss_mask_2: 3.783  loss_mask_3: 3.789  loss_mask_4: 3.787  loss_mask_5: 3.781  loss_mask_6: 3.781  loss_mask_7: 3.782  loss_mask_8: 3.789  time: 1.9110  data_time: 0.3935  lr: 9.0288e-05  max_mem: 17478M
[01/27 06:55:41] d2.utils.events INFO:  eta: 1 day, 1:52:28  iter: 6459  total_loss: 42.61  loss_mask: 4.257  loss_mask_0: 4.282  loss_mask_1: 4.25  loss_mask_2: 4.242  loss_mask_3: 4.265  loss_mask_4: 4.252  loss_mask_5: 4.243  loss_mask_6: 4.26  loss_mask_7: 4.253  loss_mask_8: 4.256  time: 1.9105  data_time: 0.4018  lr: 9.0257e-05  max_mem: 17478M
[01/27 06:56:16] d2.utils.events INFO:  eta: 1 day, 1:51:58  iter: 6479  total_loss: 43.07  loss_mask: 4.288  loss_mask_0: 4.414  loss_mask_1: 4.288  loss_mask_2: 4.296  loss_mask_3: 4.282  loss_mask_4: 4.288  loss_mask_5: 4.308  loss_mask_6: 4.309  loss_mask_7: 4.29  loss_mask_8: 4.302  time: 1.9099  data_time: 0.3945  lr: 9.0227e-05  max_mem: 17478M
[01/27 06:56:51] d2.utils.events INFO:  eta: 1 day, 1:51:17  iter: 6499  total_loss: 38.85  loss_mask: 3.89  loss_mask_0: 3.96  loss_mask_1: 3.884  loss_mask_2: 3.892  loss_mask_3: 3.883  loss_mask_4: 3.873  loss_mask_5: 3.902  loss_mask_6: 3.878  loss_mask_7: 3.875  loss_mask_8: 3.889  time: 1.9094  data_time: 0.4049  lr: 9.0196e-05  max_mem: 17478M
[01/27 06:57:26] d2.utils.events INFO:  eta: 1 day, 1:50:42  iter: 6519  total_loss: 39.25  loss_mask: 3.904  loss_mask_0: 4.016  loss_mask_1: 3.921  loss_mask_2: 3.91  loss_mask_3: 3.91  loss_mask_4: 3.912  loss_mask_5: 3.9  loss_mask_6: 3.907  loss_mask_7: 3.909  loss_mask_8: 3.912  time: 1.9090  data_time: 0.4077  lr: 9.0166e-05  max_mem: 17478M
[01/27 06:58:01] d2.utils.events INFO:  eta: 1 day, 1:50:00  iter: 6539  total_loss: 38.51  loss_mask: 3.849  loss_mask_0: 3.901  loss_mask_1: 3.842  loss_mask_2: 3.848  loss_mask_3: 3.854  loss_mask_4: 3.843  loss_mask_5: 3.844  loss_mask_6: 3.852  loss_mask_7: 3.844  loss_mask_8: 3.853  time: 1.9084  data_time: 0.3981  lr: 9.0136e-05  max_mem: 17478M
[01/27 06:58:36] d2.utils.events INFO:  eta: 1 day, 1:49:25  iter: 6559  total_loss: 38.06  loss_mask: 3.805  loss_mask_0: 3.854  loss_mask_1: 3.802  loss_mask_2: 3.799  loss_mask_3: 3.8  loss_mask_4: 3.803  loss_mask_5: 3.799  loss_mask_6: 3.807  loss_mask_7: 3.796  loss_mask_8: 3.794  time: 1.9079  data_time: 0.4219  lr: 9.0105e-05  max_mem: 17478M
[01/27 06:59:11] d2.utils.events INFO:  eta: 1 day, 1:48:16  iter: 6579  total_loss: 36.79  loss_mask: 3.677  loss_mask_0: 3.754  loss_mask_1: 3.673  loss_mask_2: 3.674  loss_mask_3: 3.671  loss_mask_4: 3.665  loss_mask_5: 3.671  loss_mask_6: 3.674  loss_mask_7: 3.671  loss_mask_8: 3.664  time: 1.9074  data_time: 0.3884  lr: 9.0075e-05  max_mem: 17478M
[01/27 06:59:45] d2.utils.events INFO:  eta: 1 day, 1:47:38  iter: 6599  total_loss: 36.51  loss_mask: 3.648  loss_mask_0: 3.723  loss_mask_1: 3.641  loss_mask_2: 3.639  loss_mask_3: 3.643  loss_mask_4: 3.639  loss_mask_5: 3.648  loss_mask_6: 3.64  loss_mask_7: 3.646  loss_mask_8: 3.639  time: 1.9069  data_time: 0.3957  lr: 9.0045e-05  max_mem: 17478M
[01/27 07:00:20] d2.utils.events INFO:  eta: 1 day, 1:46:55  iter: 6619  total_loss: 36.39  loss_mask: 3.629  loss_mask_0: 3.68  loss_mask_1: 3.628  loss_mask_2: 3.635  loss_mask_3: 3.63  loss_mask_4: 3.642  loss_mask_5: 3.634  loss_mask_6: 3.631  loss_mask_7: 3.634  loss_mask_8: 3.637  time: 1.9065  data_time: 0.4157  lr: 9.0014e-05  max_mem: 17478M
[01/27 07:00:56] d2.utils.events INFO:  eta: 1 day, 1:47:08  iter: 6639  total_loss: 42.04  loss_mask: 4.196  loss_mask_0: 4.247  loss_mask_1: 4.201  loss_mask_2: 4.198  loss_mask_3: 4.201  loss_mask_4: 4.194  loss_mask_5: 4.196  loss_mask_6: 4.202  loss_mask_7: 4.197  loss_mask_8: 4.198  time: 1.9061  data_time: 0.4256  lr: 8.9984e-05  max_mem: 17478M
[01/27 07:01:31] d2.utils.events INFO:  eta: 1 day, 1:46:51  iter: 6659  total_loss: 39.62  loss_mask: 3.954  loss_mask_0: 4.021  loss_mask_1: 3.954  loss_mask_2: 3.959  loss_mask_3: 3.958  loss_mask_4: 3.955  loss_mask_5: 3.957  loss_mask_6: 3.956  loss_mask_7: 3.948  loss_mask_8: 3.954  time: 1.9056  data_time: 0.4012  lr: 8.9954e-05  max_mem: 17478M
[01/27 07:02:06] d2.utils.events INFO:  eta: 1 day, 1:45:58  iter: 6679  total_loss: 37.64  loss_mask: 3.747  loss_mask_0: 3.87  loss_mask_1: 3.739  loss_mask_2: 3.726  loss_mask_3: 3.74  loss_mask_4: 3.741  loss_mask_5: 3.75  loss_mask_6: 3.737  loss_mask_7: 3.739  loss_mask_8: 3.738  time: 1.9051  data_time: 0.3822  lr: 8.9923e-05  max_mem: 17478M
[01/27 07:02:40] d2.utils.events INFO:  eta: 1 day, 1:45:52  iter: 6699  total_loss: 36.2  loss_mask: 3.611  loss_mask_0: 3.671  loss_mask_1: 3.617  loss_mask_2: 3.618  loss_mask_3: 3.617  loss_mask_4: 3.618  loss_mask_5: 3.62  loss_mask_6: 3.62  loss_mask_7: 3.612  loss_mask_8: 3.622  time: 1.9046  data_time: 0.3948  lr: 8.9893e-05  max_mem: 17478M
[01/27 07:03:15] d2.utils.events INFO:  eta: 1 day, 1:44:47  iter: 6719  total_loss: 41.42  loss_mask: 4.12  loss_mask_0: 4.199  loss_mask_1: 4.141  loss_mask_2: 4.124  loss_mask_3: 4.129  loss_mask_4: 4.138  loss_mask_5: 4.138  loss_mask_6: 4.131  loss_mask_7: 4.127  loss_mask_8: 4.136  time: 1.9041  data_time: 0.3854  lr: 8.9863e-05  max_mem: 17478M
[01/27 07:03:50] d2.utils.events INFO:  eta: 1 day, 1:43:54  iter: 6739  total_loss: 47.7  loss_mask: 4.739  loss_mask_0: 4.921  loss_mask_1: 4.754  loss_mask_2: 4.754  loss_mask_3: 4.742  loss_mask_4: 4.768  loss_mask_5: 4.762  loss_mask_6: 4.741  loss_mask_7: 4.747  loss_mask_8: 4.769  time: 1.9036  data_time: 0.4128  lr: 8.9832e-05  max_mem: 17478M
[01/27 07:04:25] d2.utils.events INFO:  eta: 1 day, 1:43:37  iter: 6759  total_loss: 38.55  loss_mask: 3.853  loss_mask_0: 3.848  loss_mask_1: 3.849  loss_mask_2: 3.861  loss_mask_3: 3.873  loss_mask_4: 3.856  loss_mask_5: 3.849  loss_mask_6: 3.854  loss_mask_7: 3.861  loss_mask_8: 3.872  time: 1.9032  data_time: 0.4005  lr: 8.9802e-05  max_mem: 17478M
[01/27 07:05:01] d2.utils.events INFO:  eta: 1 day, 1:42:28  iter: 6779  total_loss: 49.28  loss_mask: 4.903  loss_mask_0: 4.976  loss_mask_1: 4.915  loss_mask_2: 4.931  loss_mask_3: 4.929  loss_mask_4: 4.943  loss_mask_5: 4.967  loss_mask_6: 4.926  loss_mask_7: 4.893  loss_mask_8: 4.924  time: 1.9027  data_time: 0.3964  lr: 8.9772e-05  max_mem: 17478M
[01/27 07:05:35] d2.utils.events INFO:  eta: 1 day, 1:41:27  iter: 6799  total_loss: 38.51  loss_mask: 3.847  loss_mask_0: 4.013  loss_mask_1: 3.83  loss_mask_2: 3.845  loss_mask_3: 3.84  loss_mask_4: 3.847  loss_mask_5: 3.85  loss_mask_6: 3.842  loss_mask_7: 3.85  loss_mask_8: 3.849  time: 1.9023  data_time: 0.3908  lr: 8.9741e-05  max_mem: 17478M
[01/27 07:06:11] d2.utils.events INFO:  eta: 1 day, 1:41:06  iter: 6819  total_loss: 40.77  loss_mask: 4.032  loss_mask_0: 4.179  loss_mask_1: 4.051  loss_mask_2: 4.048  loss_mask_3: 4.042  loss_mask_4: 4.041  loss_mask_5: 4.05  loss_mask_6: 4.058  loss_mask_7: 4.045  loss_mask_8: 4.042  time: 1.9018  data_time: 0.4224  lr: 8.9711e-05  max_mem: 17478M
[01/27 07:06:46] d2.utils.events INFO:  eta: 1 day, 1:40:43  iter: 6839  total_loss: 41.57  loss_mask: 4.16  loss_mask_0: 4.105  loss_mask_1: 4.16  loss_mask_2: 4.151  loss_mask_3: 4.163  loss_mask_4: 4.171  loss_mask_5: 4.164  loss_mask_6: 4.166  loss_mask_7: 4.16  loss_mask_8: 4.164  time: 1.9014  data_time: 0.4009  lr: 8.968e-05  max_mem: 17478M
[01/27 07:07:21] d2.utils.events INFO:  eta: 1 day, 1:40:09  iter: 6859  total_loss: 43.45  loss_mask: 4.382  loss_mask_0: 4.156  loss_mask_1: 4.343  loss_mask_2: 4.359  loss_mask_3: 4.376  loss_mask_4: 4.364  loss_mask_5: 4.385  loss_mask_6: 4.375  loss_mask_7: 4.358  loss_mask_8: 4.377  time: 1.9010  data_time: 0.4151  lr: 8.965e-05  max_mem: 17478M
[01/27 07:07:56] d2.utils.events INFO:  eta: 1 day, 1:40:10  iter: 6879  total_loss: 43.28  loss_mask: 4.158  loss_mask_0: 4.439  loss_mask_1: 4.161  loss_mask_2: 4.116  loss_mask_3: 4.117  loss_mask_4: 4.118  loss_mask_5: 4.088  loss_mask_6: 4.077  loss_mask_7: 4.102  loss_mask_8: 4.169  time: 1.9005  data_time: 0.4049  lr: 8.962e-05  max_mem: 17478M
[01/27 07:08:31] d2.utils.events INFO:  eta: 1 day, 1:39:34  iter: 6899  total_loss: 41.05  loss_mask: 4.063  loss_mask_0: 4.214  loss_mask_1: 4.04  loss_mask_2: 4.048  loss_mask_3: 4.043  loss_mask_4: 4.048  loss_mask_5: 4.059  loss_mask_6: 4.056  loss_mask_7: 4.195  loss_mask_8: 4.109  time: 1.9001  data_time: 0.4209  lr: 8.9589e-05  max_mem: 17478M
[01/27 07:09:06] d2.utils.events INFO:  eta: 1 day, 1:39:19  iter: 6919  total_loss: 43.61  loss_mask: 4.385  loss_mask_0: 4.379  loss_mask_1: 4.372  loss_mask_2: 4.39  loss_mask_3: 4.382  loss_mask_4: 4.357  loss_mask_5: 4.377  loss_mask_6: 4.371  loss_mask_7: 4.399  loss_mask_8: 4.342  time: 1.8996  data_time: 0.3968  lr: 8.9559e-05  max_mem: 17478M
[01/27 07:09:41] d2.utils.events INFO:  eta: 1 day, 1:39:28  iter: 6939  total_loss: 39.24  loss_mask: 3.889  loss_mask_0: 4.007  loss_mask_1: 3.881  loss_mask_2: 3.89  loss_mask_3: 3.883  loss_mask_4: 3.885  loss_mask_5: 3.884  loss_mask_6: 3.89  loss_mask_7: 3.899  loss_mask_8: 3.887  time: 1.8993  data_time: 0.4096  lr: 8.9529e-05  max_mem: 17478M
[01/27 07:10:16] d2.utils.events INFO:  eta: 1 day, 1:38:28  iter: 6959  total_loss: 41.58  loss_mask: 4.137  loss_mask_0: 4.115  loss_mask_1: 4.145  loss_mask_2: 4.143  loss_mask_3: 4.135  loss_mask_4: 4.15  loss_mask_5: 4.155  loss_mask_6: 4.149  loss_mask_7: 4.153  loss_mask_8: 4.143  time: 1.8988  data_time: 0.4098  lr: 8.9498e-05  max_mem: 17478M
[01/27 07:10:51] d2.utils.events INFO:  eta: 1 day, 1:37:50  iter: 6979  total_loss: 40.27  loss_mask: 4.026  loss_mask_0: 4.108  loss_mask_1: 4.011  loss_mask_2: 3.997  loss_mask_3: 3.996  loss_mask_4: 3.999  loss_mask_5: 4.024  loss_mask_6: 4.022  loss_mask_7: 4.015  loss_mask_8: 4.026  time: 1.8984  data_time: 0.4111  lr: 8.9468e-05  max_mem: 17478M
[01/27 07:11:26] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 07:11:27] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 07:11:27] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 07:18:10] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.8123451023472006, 'error_1pix': 0.5135769933153334, 'error_3pix': 0.2634841671995183, 'mIoU': 3.7991840909283967, 'fwIoU': 8.77162649173652, 'IoU-0': nan, 'IoU-1': 6.998471364665669, 'IoU-2': 1.2410318397951132, 'IoU-3': 1.047107888380496, 'IoU-4': 0.9683379556688144, 'IoU-5': 0.8555085176452903, 'IoU-6': 0.791121908304529, 'IoU-7': 0.8513507543016885, 'IoU-8': 3.3412572075084412, 'IoU-9': 9.050643060614632, 'IoU-10': 11.809275085283083, 'IoU-11': 16.548015183748017, 'IoU-12': 15.832258872024923, 'IoU-13': 14.670563180236448, 'IoU-14': 14.380293184774452, 'IoU-15': 13.560453004554185, 'IoU-16': 12.741909420445726, 'IoU-17': 10.915228071260234, 'IoU-18': 11.231453717825081, 'IoU-19': 10.733549161463824, 'IoU-20': 10.318267250989505, 'IoU-21': 10.23300157196262, 'IoU-22': 10.68743336904821, 'IoU-23': 9.58529678921963, 'IoU-24': 9.838982848314405, 'IoU-25': 10.059594321975032, 'IoU-26': 9.96577622346289, 'IoU-27': 10.789488463045629, 'IoU-28': 10.810467616207294, 'IoU-29': 10.86011741605303, 'IoU-30': 11.324726222566952, 'IoU-31': 11.613648977781384, 'IoU-32': 11.768029638876083, 'IoU-33': 11.458874646358131, 'IoU-34': 11.345384283029105, 'IoU-35': 12.25965739007696, 'IoU-36': 12.248075007702951, 'IoU-37': 11.597911061800882, 'IoU-38': 11.758660789513263, 'IoU-39': 11.47029379538074, 'IoU-40': 11.224584429169468, 'IoU-41': 10.578388461186483, 'IoU-42': 10.157720590208262, 'IoU-43': 10.216349430601218, 'IoU-44': 10.693620189203648, 'IoU-45': 10.361532449559183, 'IoU-46': 9.638992339377822, 'IoU-47': 9.377252912598733, 'IoU-48': 9.006985438948783, 'IoU-49': 8.573031275999154, 'IoU-50': 8.231415329811723, 'IoU-51': 7.765311596356493, 'IoU-52': 7.314367422663577, 'IoU-53': 7.088533520888841, 'IoU-54': 7.187539588777557, 'IoU-55': 6.695433330721369, 'IoU-56': 6.259817163855491, 'IoU-57': 6.129920326880382, 'IoU-58': 6.046168148446735, 'IoU-59': 6.022914781099264, 'IoU-60': 6.002912132398516, 'IoU-61': 5.602781027414134, 'IoU-62': 5.556089055617427, 'IoU-63': 5.525262290078887, 'IoU-64': 5.224086276151055, 'IoU-65': 5.1038441511982695, 'IoU-66': 5.042140939002549, 'IoU-67': 4.621448984499985, 'IoU-68': 4.4803436048719725, 'IoU-69': 4.33334333417938, 'IoU-70': 4.447953063045087, 'IoU-71': 4.210737704057646, 'IoU-72': 4.051429999984997, 'IoU-73': 4.081422056614549, 'IoU-74': 3.8578358047226335, 'IoU-75': 3.72305798448152, 'IoU-76': 3.7146531718735902, 'IoU-77': 3.5912867078249895, 'IoU-78': 3.480059139279021, 'IoU-79': 3.454714067017603, 'IoU-80': 3.262318585822673, 'IoU-81': 3.100822689576777, 'IoU-82': 2.945609461392696, 'IoU-83': 2.9472946503674637, 'IoU-84': 3.0562839256963414, 'IoU-85': 2.8894550635624507, 'IoU-86': 2.620624922323835, 'IoU-87': 2.41588156336111, 'IoU-88': 2.2318728553745553, 'IoU-89': 2.183872921927186, 'IoU-90': 2.0163395361853573, 'IoU-91': 1.937340597388269, 'IoU-92': 1.8385947717706126, 'IoU-93': 1.779167137163951, 'IoU-94': 1.662876223678312, 'IoU-95': 1.5705139888510418, 'IoU-96': 1.5381708249072694, 'IoU-97': 1.433912637755123, 'IoU-98': 1.329316100568208, 'IoU-99': 1.2259441658545864, 'IoU-100': 1.132017809932061, 'IoU-101': 1.0664747663832868, 'IoU-102': 1.033077650274535, 'IoU-103': 0.9666706165393313, 'IoU-104': 0.9771404675756397, 'IoU-105': 0.9189247252816198, 'IoU-106': 0.9235140119170818, 'IoU-107': 0.8775747499441158, 'IoU-108': 0.9618261730583422, 'IoU-109': 0.8924487475566293, 'IoU-110': 0.8420227842226168, 'IoU-111': 0.8148165963318071, 'IoU-112': 0.8330537396268024, 'IoU-113': 0.8749823925475871, 'IoU-114': 0.7857136002541294, 'IoU-115': 0.7402540766099058, 'IoU-116': 0.7663136304680525, 'IoU-117': 0.7890695627639073, 'IoU-118': 0.7008708230869376, 'IoU-119': 0.6742321462914023, 'IoU-120': 0.7720124241346926, 'IoU-121': 0.7078588298778001, 'IoU-122': 0.5666699635327511, 'IoU-123': 0.5605024058024017, 'IoU-124': 0.6537602169600195, 'IoU-125': 0.5484035326604195, 'IoU-126': 0.5172734872444631, 'IoU-127': 0.6244371686182502, 'IoU-128': 0.6827780955765946, 'IoU-129': 0.7400962382884599, 'IoU-130': 0.6482829468954373, 'IoU-131': 0.613210890088289, 'IoU-132': 0.6825770577930135, 'IoU-133': 0.6603627763909391, 'IoU-134': 0.700597003538152, 'IoU-135': 0.708793247744194, 'IoU-136': 0.631774756664589, 'IoU-137': 0.6393392969453061, 'IoU-138': 0.6011878531643938, 'IoU-139': 0.6223289698500689, 'IoU-140': 0.7106062879316076, 'IoU-141': 0.6419366275070678, 'IoU-142': 0.6699259361994311, 'IoU-143': 0.7259387815236226, 'IoU-144': 0.7305144962498354, 'IoU-145': 0.7222936145699472, 'IoU-146': 0.7419513160002348, 'IoU-147': 0.7123609013737593, 'IoU-148': 0.6976360250648836, 'IoU-149': 0.6806449964223653, 'IoU-150': 0.7882579307649764, 'IoU-151': 0.8193261342845198, 'IoU-152': 0.7182859862301815, 'IoU-153': 0.6809702303818825, 'IoU-154': 0.6932320548253271, 'IoU-155': 0.6631207116058019, 'IoU-156': 0.7308631354227655, 'IoU-157': 0.7013146227624082, 'IoU-158': 0.5994887853139458, 'IoU-159': 0.538354457428931, 'IoU-160': 0.6230699572035423, 'IoU-161': 0.6121146516129714, 'IoU-162': 0.5003825354336305, 'IoU-163': 0.5177687025843428, 'IoU-164': 0.44976865524709586, 'IoU-165': 0.4690875253976945, 'IoU-166': 0.5622319212210996, 'IoU-167': 0.4565738687397588, 'IoU-168': 0.39074962130822616, 'IoU-169': 0.38232706792356586, 'IoU-170': 0.3714415295854524, 'IoU-171': 0.3707798087827396, 'IoU-172': 0.3087275236337259, 'IoU-173': 0.2558730647770161, 'IoU-174': 0.2599552290569726, 'IoU-175': 0.22673702190936607, 'IoU-176': 0.3069408072511157, 'IoU-177': 0.2770009144367537, 'IoU-178': 0.1752303230209281, 'IoU-179': 0.2039513925316295, 'IoU-180': 0.17611006180805, 'IoU-181': 0.2270494585657218, 'IoU-182': 0.19915207088632889, 'IoU-183': 0.10586472229987673, 'IoU-184': 0.054690523476370684, 'IoU-185': 0.02716411232702852, 'IoU-186': 0.031869149023421486, 'IoU-187': 0.015150385613386207, 'IoU-188': 0.00879792670572946, 'IoU-189': 0.007937076902594145, 'IoU-190': 0.008891306394418352, 'IoU-191': 0.006254609516909597, 'IoU-192': 0.009606853642410302, 'mACC': 7.121799680271799, 'pACC': 15.30190827951288, 'ACC-0': nan, 'ACC-1': 7.070735103590693, 'ACC-2': 2.643604967635817, 'ACC-3': 5.9143710817537105, 'ACC-4': 5.105687393813101, 'ACC-5': 4.742102414135404, 'ACC-6': 4.758061317232257, 'ACC-7': 6.183022122070658, 'ACC-8': 11.792293077583345, 'ACC-9': 19.210948006451705, 'ACC-10': 22.715481072427373, 'ACC-11': 25.996796848111963, 'ACC-12': 24.45105972390323, 'ACC-13': 22.78696356549007, 'ACC-14': 22.724898395067044, 'ACC-15': 22.46224987364757, 'ACC-16': 21.781692308470475, 'ACC-17': 20.081945886649336, 'ACC-18': 19.455783389055945, 'ACC-19': 18.30833183213664, 'ACC-20': 17.868011886087473, 'ACC-21': 17.748710603194308, 'ACC-22': 18.24199944926194, 'ACC-23': 17.725744822249577, 'ACC-24': 18.626223166053432, 'ACC-25': 18.86558331780935, 'ACC-26': 18.45122866289638, 'ACC-27': 19.419408827300057, 'ACC-28': 20.175050169196123, 'ACC-29': 19.890042605795234, 'ACC-30': 20.993068898112522, 'ACC-31': 21.28726782016419, 'ACC-32': 22.148133896132364, 'ACC-33': 22.19760514260794, 'ACC-34': 21.7617649077993, 'ACC-35': 22.91909630721068, 'ACC-36': 22.965487680536864, 'ACC-37': 21.973286758726918, 'ACC-38': 21.985921640850687, 'ACC-39': 21.40092998746737, 'ACC-40': 20.78883030161234, 'ACC-41': 20.03994277674591, 'ACC-42': 19.137169709716055, 'ACC-43': 19.332381819461364, 'ACC-44': 19.74661322084318, 'ACC-45': 19.274707345018783, 'ACC-46': 18.46421303659869, 'ACC-47': 17.980764368606156, 'ACC-48': 17.284443484140564, 'ACC-49': 16.37801852183207, 'ACC-50': 15.775322898348044, 'ACC-51': 15.091498670064606, 'ACC-52': 14.091069200007524, 'ACC-53': 13.607988239337002, 'ACC-54': 13.666045779400616, 'ACC-55': 12.731464304527455, 'ACC-56': 11.893673066587395, 'ACC-57': 11.394903171876027, 'ACC-58': 11.400472727564905, 'ACC-59': 11.527883398497615, 'ACC-60': 11.582214711592776, 'ACC-61': 10.890656384888244, 'ACC-62': 10.798739312299906, 'ACC-63': 10.858329017054098, 'ACC-64': 10.317152475311923, 'ACC-65': 10.121653682920954, 'ACC-66': 10.002050260197029, 'ACC-67': 9.289354076173842, 'ACC-68': 9.019780522294846, 'ACC-69': 8.551791810202246, 'ACC-70': 8.727774744255736, 'ACC-71': 8.403749475579508, 'ACC-72': 8.11957045633335, 'ACC-73': 8.176667761292583, 'ACC-74': 7.698136234738631, 'ACC-75': 7.493128500588049, 'ACC-76': 7.388821884985718, 'ACC-77': 7.239060252963809, 'ACC-78': 7.080048174564248, 'ACC-79': 7.01478804112169, 'ACC-80': 6.538426365532407, 'ACC-81': 6.185179891348307, 'ACC-82': 5.873799417595317, 'ACC-83': 5.785124426841434, 'ACC-84': 5.973133985398457, 'ACC-85': 5.640537098783349, 'ACC-86': 5.1059210108935975, 'ACC-87': 4.68480379058598, 'ACC-88': 4.2966922668739285, 'ACC-89': 4.175574309957414, 'ACC-90': 3.8087690008566404, 'ACC-91': 3.6716324647201004, 'ACC-92': 3.506257253036979, 'ACC-93': 3.393591931302576, 'ACC-94': 3.149335483918054, 'ACC-95': 2.9295272752456176, 'ACC-96': 2.841277636531288, 'ACC-97': 2.616084120935573, 'ACC-98': 2.4174975479306666, 'ACC-99': 2.2421006674601416, 'ACC-100': 2.0591219051743224, 'ACC-101': 1.9484508340340216, 'ACC-102': 1.902605346624377, 'ACC-103': 1.7857513932180977, 'ACC-104': 1.8188436093554021, 'ACC-105': 1.7019571447288007, 'ACC-106': 1.6998130606835595, 'ACC-107': 1.6100870723078733, 'ACC-108': 1.752722937342663, 'ACC-109': 1.6262050254931728, 'ACC-110': 1.5557172790664975, 'ACC-111': 1.497078706476362, 'ACC-112': 1.538431765873294, 'ACC-113': 1.6155605375723243, 'ACC-114': 1.4620642806825226, 'ACC-115': 1.3691684332386151, 'ACC-116': 1.414380961214669, 'ACC-117': 1.4316574340989145, 'ACC-118': 1.2714463678629144, 'ACC-119': 1.2164507790354602, 'ACC-120': 1.3840278729482707, 'ACC-121': 1.2583875470277208, 'ACC-122': 1.0027644899846206, 'ACC-123': 0.9906368852248706, 'ACC-124': 1.1681310701981407, 'ACC-125': 0.9793193765683413, 'ACC-126': 0.9344347398428037, 'ACC-127': 1.1185975011447635, 'ACC-128': 1.214856608988268, 'ACC-129': 1.315232131348761, 'ACC-130': 1.1493178001408513, 'ACC-131': 1.0925671540021253, 'ACC-132': 1.2082583533559195, 'ACC-133': 1.1627780386073063, 'ACC-134': 1.2154071520896166, 'ACC-135': 1.2209252608175132, 'ACC-136': 1.0942741334327246, 'ACC-137': 1.1164562816693722, 'ACC-138': 1.0507621138665382, 'ACC-139': 1.0752996713268999, 'ACC-140': 1.2003737035914306, 'ACC-141': 1.069699178138449, 'ACC-142': 1.1136524604366056, 'ACC-143': 1.2065385095785337, 'ACC-144': 1.2025270758122744, 'ACC-145': 1.1663945973747176, 'ACC-146': 1.18947095227129, 'ACC-147': 1.127874003465239, 'ACC-148': 1.0925325863480002, 'ACC-149': 1.0804517736588413, 'ACC-150': 1.240453738611455, 'ACC-151': 1.2867120048002576, 'ACC-152': 1.110050407984355, 'ACC-153': 1.0759743717470842, 'ACC-154': 1.1003152648048236, 'ACC-155': 1.065062355635426, 'ACC-156': 1.1861192376259, 'ACC-157': 1.1507675640067672, 'ACC-158': 0.9824399964998546, 'ACC-159': 0.8679194459606019, 'ACC-160': 1.001001001001001, 'ACC-161': 0.9750905371002009, 'ACC-162': 0.7958928951310694, 'ACC-163': 0.8089677406533805, 'ACC-164': 0.6953990458478208, 'ACC-165': 0.7197649487810688, 'ACC-166': 0.852514060270293, 'ACC-167': 0.6684547715997055, 'ACC-168': 0.5469822788994245, 'ACC-169': 0.5155426094738412, 'ACC-170': 0.4898898102919459, 'ACC-171': 0.4769209571487622, 'ACC-172': 0.38786037767302295, 'ACC-173': 0.31254527766853646, 'ACC-174': 0.3074290060851927, 'ACC-175': 0.2616537627290395, 'ACC-176': 0.3472392304133671, 'ACC-177': 0.3063985617725341, 'ACC-178': 0.19047692640558833, 'ACC-179': 0.21856082667537935, 'ACC-180': 0.18694556771748563, 'ACC-181': 0.23929339739762506, 'ACC-182': 0.20780660952972202, 'ACC-183': 0.108789073997763, 'ACC-184': 0.05566799231970411, 'ACC-185': 0.027494171928681508, 'ACC-186': 0.03212904536573957, 'ACC-187': 0.015224120807023395, 'ACC-188': 0.008828529772324829, 'ACC-189': 0.0079603114279258, 'ACC-190': 0.00891144124215007, 'ACC-191': 0.006266678503726062, 'ACC-192': 0.009624066960861185})])
[01/27 07:18:10] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 07:18:10] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 07:18:10] d2.evaluation.testing INFO: copypaste: 3.8123,0.5136,0.2635,3.7992,8.7716,7.1218,15.3019
[01/27 07:18:11] d2.utils.events INFO:  eta: 1 day, 1:39:15  iter: 6999  total_loss: 38.12  loss_mask: 3.807  loss_mask_0: 3.808  loss_mask_1: 3.813  loss_mask_2: 3.816  loss_mask_3: 3.804  loss_mask_4: 3.812  loss_mask_5: 3.816  loss_mask_6: 3.814  loss_mask_7: 3.802  loss_mask_8: 3.806  time: 1.8980  data_time: 0.4183  lr: 8.9437e-05  max_mem: 17478M
[01/27 07:18:46] d2.utils.events INFO:  eta: 1 day, 1:38:20  iter: 7019  total_loss: 35.9  loss_mask: 3.591  loss_mask_0: 3.599  loss_mask_1: 3.587  loss_mask_2: 3.591  loss_mask_3: 3.586  loss_mask_4: 3.592  loss_mask_5: 3.59  loss_mask_6: 3.59  loss_mask_7: 3.589  loss_mask_8: 3.59  time: 1.8976  data_time: 0.4133  lr: 8.9407e-05  max_mem: 17478M
[01/27 07:19:21] d2.utils.events INFO:  eta: 1 day, 1:38:25  iter: 7039  total_loss: 39.12  loss_mask: 3.895  loss_mask_0: 4.019  loss_mask_1: 3.896  loss_mask_2: 3.904  loss_mask_3: 3.899  loss_mask_4: 3.901  loss_mask_5: 3.891  loss_mask_6: 3.893  loss_mask_7: 3.899  loss_mask_8: 3.895  time: 1.8972  data_time: 0.4127  lr: 8.9377e-05  max_mem: 17478M
[01/27 07:19:56] d2.utils.events INFO:  eta: 1 day, 1:36:32  iter: 7059  total_loss: 42.59  loss_mask: 4.259  loss_mask_0: 4.29  loss_mask_1: 4.253  loss_mask_2: 4.247  loss_mask_3: 4.245  loss_mask_4: 4.25  loss_mask_5: 4.258  loss_mask_6: 4.237  loss_mask_7: 4.25  loss_mask_8: 4.248  time: 1.8967  data_time: 0.4011  lr: 8.9346e-05  max_mem: 17478M
[01/27 07:20:31] d2.utils.events INFO:  eta: 1 day, 1:36:35  iter: 7079  total_loss: 44.48  loss_mask: 4.456  loss_mask_0: 4.483  loss_mask_1: 4.418  loss_mask_2: 4.424  loss_mask_3: 4.433  loss_mask_4: 4.443  loss_mask_5: 4.415  loss_mask_6: 4.426  loss_mask_7: 4.432  loss_mask_8: 4.426  time: 1.8963  data_time: 0.4005  lr: 8.9316e-05  max_mem: 17478M
[01/27 07:21:05] d2.utils.events INFO:  eta: 1 day, 1:35:05  iter: 7099  total_loss: 37.61  loss_mask: 3.764  loss_mask_0: 3.771  loss_mask_1: 3.763  loss_mask_2: 3.755  loss_mask_3: 3.77  loss_mask_4: 3.753  loss_mask_5: 3.767  loss_mask_6: 3.759  loss_mask_7: 3.75  loss_mask_8: 3.762  time: 1.8959  data_time: 0.3807  lr: 8.9286e-05  max_mem: 17478M
[01/27 07:21:41] d2.utils.events INFO:  eta: 1 day, 1:34:30  iter: 7119  total_loss: 35.19  loss_mask: 3.523  loss_mask_0: 3.565  loss_mask_1: 3.512  loss_mask_2: 3.508  loss_mask_3: 3.518  loss_mask_4: 3.51  loss_mask_5: 3.506  loss_mask_6: 3.519  loss_mask_7: 3.509  loss_mask_8: 3.52  time: 1.8955  data_time: 0.4190  lr: 8.9255e-05  max_mem: 17478M
[01/27 07:22:16] d2.utils.events INFO:  eta: 1 day, 1:34:06  iter: 7139  total_loss: 35.11  loss_mask: 3.5  loss_mask_0: 3.58  loss_mask_1: 3.506  loss_mask_2: 3.501  loss_mask_3: 3.507  loss_mask_4: 3.507  loss_mask_5: 3.499  loss_mask_6: 3.5  loss_mask_7: 3.51  loss_mask_8: 3.502  time: 1.8951  data_time: 0.3936  lr: 8.9225e-05  max_mem: 17478M
[01/27 07:22:51] d2.utils.events INFO:  eta: 1 day, 1:34:16  iter: 7159  total_loss: 34.5  loss_mask: 3.447  loss_mask_0: 3.475  loss_mask_1: 3.447  loss_mask_2: 3.447  loss_mask_3: 3.448  loss_mask_4: 3.449  loss_mask_5: 3.446  loss_mask_6: 3.452  loss_mask_7: 3.444  loss_mask_8: 3.451  time: 1.8947  data_time: 0.4015  lr: 8.9194e-05  max_mem: 17478M
[01/27 07:23:26] d2.utils.events INFO:  eta: 1 day, 1:34:30  iter: 7179  total_loss: 34.51  loss_mask: 3.452  loss_mask_0: 3.501  loss_mask_1: 3.445  loss_mask_2: 3.444  loss_mask_3: 3.446  loss_mask_4: 3.437  loss_mask_5: 3.443  loss_mask_6: 3.45  loss_mask_7: 3.442  loss_mask_8: 3.445  time: 1.8942  data_time: 0.4039  lr: 8.9164e-05  max_mem: 17478M
[01/27 07:24:01] d2.utils.events INFO:  eta: 1 day, 1:34:00  iter: 7199  total_loss: 36.95  loss_mask: 3.692  loss_mask_0: 3.762  loss_mask_1: 3.685  loss_mask_2: 3.686  loss_mask_3: 3.681  loss_mask_4: 3.685  loss_mask_5: 3.686  loss_mask_6: 3.684  loss_mask_7: 3.683  loss_mask_8: 3.686  time: 1.8938  data_time: 0.4055  lr: 8.9134e-05  max_mem: 17478M
[01/27 07:24:36] d2.utils.events INFO:  eta: 1 day, 1:33:31  iter: 7219  total_loss: 36.62  loss_mask: 3.649  loss_mask_0: 3.714  loss_mask_1: 3.658  loss_mask_2: 3.651  loss_mask_3: 3.655  loss_mask_4: 3.664  loss_mask_5: 3.661  loss_mask_6: 3.652  loss_mask_7: 3.657  loss_mask_8: 3.655  time: 1.8935  data_time: 0.4168  lr: 8.9103e-05  max_mem: 17478M
[01/27 07:25:11] d2.utils.events INFO:  eta: 1 day, 1:32:57  iter: 7239  total_loss: 37.83  loss_mask: 3.767  loss_mask_0: 4.051  loss_mask_1: 3.772  loss_mask_2: 3.76  loss_mask_3: 3.772  loss_mask_4: 3.767  loss_mask_5: 3.771  loss_mask_6: 3.767  loss_mask_7: 3.771  loss_mask_8: 3.772  time: 1.8931  data_time: 0.4070  lr: 8.9073e-05  max_mem: 17478M
[01/27 07:25:46] d2.utils.events INFO:  eta: 1 day, 1:32:27  iter: 7259  total_loss: 38.31  loss_mask: 3.808  loss_mask_0: 4.058  loss_mask_1: 3.808  loss_mask_2: 3.805  loss_mask_3: 3.799  loss_mask_4: 3.815  loss_mask_5: 3.817  loss_mask_6: 3.794  loss_mask_7: 3.799  loss_mask_8: 3.794  time: 1.8927  data_time: 0.4024  lr: 8.9043e-05  max_mem: 17478M
[01/27 07:26:21] d2.utils.events INFO:  eta: 1 day, 1:32:00  iter: 7279  total_loss: 37.8  loss_mask: 3.787  loss_mask_0: 3.858  loss_mask_1: 3.779  loss_mask_2: 3.781  loss_mask_3: 3.761  loss_mask_4: 3.761  loss_mask_5: 3.755  loss_mask_6: 3.775  loss_mask_7: 3.768  loss_mask_8: 3.771  time: 1.8923  data_time: 0.4212  lr: 8.9012e-05  max_mem: 17478M
[01/27 07:26:56] d2.utils.events INFO:  eta: 1 day, 1:31:17  iter: 7299  total_loss: 37.77  loss_mask: 3.772  loss_mask_0: 3.852  loss_mask_1: 3.774  loss_mask_2: 3.762  loss_mask_3: 3.764  loss_mask_4: 3.767  loss_mask_5: 3.768  loss_mask_6: 3.767  loss_mask_7: 3.776  loss_mask_8: 3.767  time: 1.8919  data_time: 0.4032  lr: 8.8982e-05  max_mem: 17478M
[01/27 07:27:32] d2.utils.events INFO:  eta: 1 day, 1:30:42  iter: 7319  total_loss: 39.43  loss_mask: 3.933  loss_mask_0: 4.073  loss_mask_1: 3.935  loss_mask_2: 3.931  loss_mask_3: 3.926  loss_mask_4: 3.927  loss_mask_5: 3.93  loss_mask_6: 3.93  loss_mask_7: 3.928  loss_mask_8: 3.932  time: 1.8916  data_time: 0.4140  lr: 8.8951e-05  max_mem: 17478M
[01/27 07:28:07] d2.utils.events INFO:  eta: 1 day, 1:30:22  iter: 7339  total_loss: 40.93  loss_mask: 4.085  loss_mask_0: 4.176  loss_mask_1: 4.076  loss_mask_2: 4.081  loss_mask_3: 4.07  loss_mask_4: 4.077  loss_mask_5: 4.08  loss_mask_6: 4.078  loss_mask_7: 4.071  loss_mask_8: 4.072  time: 1.8912  data_time: 0.3950  lr: 8.8921e-05  max_mem: 17478M
[01/27 07:28:42] d2.utils.events INFO:  eta: 1 day, 1:29:43  iter: 7359  total_loss: 36.49  loss_mask: 3.641  loss_mask_0: 3.737  loss_mask_1: 3.644  loss_mask_2: 3.638  loss_mask_3: 3.64  loss_mask_4: 3.64  loss_mask_5: 3.641  loss_mask_6: 3.636  loss_mask_7: 3.638  loss_mask_8: 3.64  time: 1.8908  data_time: 0.4083  lr: 8.8891e-05  max_mem: 17478M
[01/27 07:29:17] d2.utils.events INFO:  eta: 1 day, 1:28:53  iter: 7379  total_loss: 35.46  loss_mask: 3.545  loss_mask_0: 3.69  loss_mask_1: 3.542  loss_mask_2: 3.535  loss_mask_3: 3.538  loss_mask_4: 3.534  loss_mask_5: 3.546  loss_mask_6: 3.541  loss_mask_7: 3.536  loss_mask_8: 3.536  time: 1.8904  data_time: 0.3970  lr: 8.886e-05  max_mem: 17478M
[01/27 07:29:52] d2.utils.events INFO:  eta: 1 day, 1:28:33  iter: 7399  total_loss: 37.49  loss_mask: 3.737  loss_mask_0: 3.855  loss_mask_1: 3.738  loss_mask_2: 3.734  loss_mask_3: 3.735  loss_mask_4: 3.734  loss_mask_5: 3.735  loss_mask_6: 3.733  loss_mask_7: 3.735  loss_mask_8: 3.726  time: 1.8900  data_time: 0.4052  lr: 8.883e-05  max_mem: 17478M
[01/27 07:30:27] d2.utils.events INFO:  eta: 1 day, 1:28:32  iter: 7419  total_loss: 38.77  loss_mask: 3.855  loss_mask_0: 4.056  loss_mask_1: 3.866  loss_mask_2: 3.849  loss_mask_3: 3.85  loss_mask_4: 3.847  loss_mask_5: 3.858  loss_mask_6: 3.851  loss_mask_7: 3.851  loss_mask_8: 3.846  time: 1.8897  data_time: 0.4060  lr: 8.8799e-05  max_mem: 17478M
[01/27 07:31:02] d2.utils.events INFO:  eta: 1 day, 1:28:31  iter: 7439  total_loss: 35.83  loss_mask: 3.579  loss_mask_0: 3.731  loss_mask_1: 3.58  loss_mask_2: 3.57  loss_mask_3: 3.563  loss_mask_4: 3.56  loss_mask_5: 3.577  loss_mask_6: 3.57  loss_mask_7: 3.572  loss_mask_8: 3.569  time: 1.8894  data_time: 0.4159  lr: 8.8769e-05  max_mem: 17484M
[01/27 07:31:37] d2.utils.events INFO:  eta: 1 day, 1:28:15  iter: 7459  total_loss: 39.2  loss_mask: 3.904  loss_mask_0: 4.131  loss_mask_1: 3.903  loss_mask_2: 3.881  loss_mask_3: 3.897  loss_mask_4: 3.895  loss_mask_5: 3.896  loss_mask_6: 3.885  loss_mask_7: 3.904  loss_mask_8: 3.898  time: 1.8890  data_time: 0.4159  lr: 8.8739e-05  max_mem: 17484M
[01/27 07:32:12] d2.utils.events INFO:  eta: 1 day, 1:27:29  iter: 7479  total_loss: 34.36  loss_mask: 3.426  loss_mask_0: 3.506  loss_mask_1: 3.435  loss_mask_2: 3.432  loss_mask_3: 3.429  loss_mask_4: 3.429  loss_mask_5: 3.429  loss_mask_6: 3.429  loss_mask_7: 3.432  loss_mask_8: 3.429  time: 1.8886  data_time: 0.4037  lr: 8.8708e-05  max_mem: 17484M
[01/27 07:32:47] d2.utils.events INFO:  eta: 1 day, 1:26:34  iter: 7499  total_loss: 36.61  loss_mask: 3.658  loss_mask_0: 3.682  loss_mask_1: 3.662  loss_mask_2: 3.657  loss_mask_3: 3.654  loss_mask_4: 3.661  loss_mask_5: 3.673  loss_mask_6: 3.659  loss_mask_7: 3.656  loss_mask_8: 3.654  time: 1.8881  data_time: 0.3930  lr: 8.8678e-05  max_mem: 17484M
[01/27 07:33:22] d2.utils.events INFO:  eta: 1 day, 1:26:17  iter: 7519  total_loss: 37.21  loss_mask: 3.71  loss_mask_0: 3.749  loss_mask_1: 3.713  loss_mask_2: 3.717  loss_mask_3: 3.72  loss_mask_4: 3.705  loss_mask_5: 3.72  loss_mask_6: 3.708  loss_mask_7: 3.712  loss_mask_8: 3.727  time: 1.8878  data_time: 0.4031  lr: 8.8647e-05  max_mem: 17484M
[01/27 07:33:57] d2.utils.events INFO:  eta: 1 day, 1:25:52  iter: 7539  total_loss: 38  loss_mask: 3.801  loss_mask_0: 3.81  loss_mask_1: 3.798  loss_mask_2: 3.8  loss_mask_3: 3.795  loss_mask_4: 3.795  loss_mask_5: 3.803  loss_mask_6: 3.797  loss_mask_7: 3.796  loss_mask_8: 3.807  time: 1.8874  data_time: 0.4049  lr: 8.8617e-05  max_mem: 17484M
[01/27 07:34:32] d2.utils.events INFO:  eta: 1 day, 1:25:17  iter: 7559  total_loss: 38.53  loss_mask: 3.841  loss_mask_0: 3.868  loss_mask_1: 3.844  loss_mask_2: 3.846  loss_mask_3: 3.845  loss_mask_4: 3.844  loss_mask_5: 3.849  loss_mask_6: 3.848  loss_mask_7: 3.845  loss_mask_8: 3.857  time: 1.8871  data_time: 0.4201  lr: 8.8587e-05  max_mem: 17484M
[01/27 07:35:07] d2.utils.events INFO:  eta: 1 day, 1:24:47  iter: 7579  total_loss: 35.5  loss_mask: 3.547  loss_mask_0: 3.561  loss_mask_1: 3.544  loss_mask_2: 3.542  loss_mask_3: 3.547  loss_mask_4: 3.548  loss_mask_5: 3.543  loss_mask_6: 3.55  loss_mask_7: 3.546  loss_mask_8: 3.546  time: 1.8867  data_time: 0.4156  lr: 8.8556e-05  max_mem: 17484M
[01/27 07:35:42] d2.utils.events INFO:  eta: 1 day, 1:24:10  iter: 7599  total_loss: 38.13  loss_mask: 3.807  loss_mask_0: 3.847  loss_mask_1: 3.804  loss_mask_2: 3.806  loss_mask_3: 3.811  loss_mask_4: 3.804  loss_mask_5: 3.812  loss_mask_6: 3.806  loss_mask_7: 3.805  loss_mask_8: 3.807  time: 1.8863  data_time: 0.3814  lr: 8.8526e-05  max_mem: 17484M
[01/27 07:36:17] d2.utils.events INFO:  eta: 1 day, 1:23:39  iter: 7619  total_loss: 41.46  loss_mask: 4.14  loss_mask_0: 4.163  loss_mask_1: 4.146  loss_mask_2: 4.141  loss_mask_3: 4.145  loss_mask_4: 4.151  loss_mask_5: 4.15  loss_mask_6: 4.15  loss_mask_7: 4.145  loss_mask_8: 4.148  time: 1.8859  data_time: 0.3990  lr: 8.8495e-05  max_mem: 17484M
[01/27 07:36:52] d2.utils.events INFO:  eta: 1 day, 1:23:03  iter: 7639  total_loss: 38.07  loss_mask: 3.805  loss_mask_0: 3.822  loss_mask_1: 3.81  loss_mask_2: 3.803  loss_mask_3: 3.813  loss_mask_4: 3.798  loss_mask_5: 3.801  loss_mask_6: 3.805  loss_mask_7: 3.808  loss_mask_8: 3.803  time: 1.8856  data_time: 0.4033  lr: 8.8465e-05  max_mem: 17484M
[01/27 07:37:27] d2.utils.events INFO:  eta: 1 day, 1:22:46  iter: 7659  total_loss: 39.44  loss_mask: 3.931  loss_mask_0: 3.981  loss_mask_1: 3.931  loss_mask_2: 3.943  loss_mask_3: 3.947  loss_mask_4: 3.939  loss_mask_5: 3.934  loss_mask_6: 3.929  loss_mask_7: 3.946  loss_mask_8: 3.932  time: 1.8853  data_time: 0.3963  lr: 8.8434e-05  max_mem: 17484M
[01/27 07:38:02] d2.utils.events INFO:  eta: 1 day, 1:22:11  iter: 7679  total_loss: 35.67  loss_mask: 3.566  loss_mask_0: 3.572  loss_mask_1: 3.561  loss_mask_2: 3.566  loss_mask_3: 3.567  loss_mask_4: 3.566  loss_mask_5: 3.57  loss_mask_6: 3.575  loss_mask_7: 3.559  loss_mask_8: 3.566  time: 1.8849  data_time: 0.4026  lr: 8.8404e-05  max_mem: 17484M
[01/27 07:38:37] d2.utils.events INFO:  eta: 1 day, 1:21:55  iter: 7699  total_loss: 43.27  loss_mask: 4.312  loss_mask_0: 4.455  loss_mask_1: 4.309  loss_mask_2: 4.315  loss_mask_3: 4.302  loss_mask_4: 4.312  loss_mask_5: 4.306  loss_mask_6: 4.323  loss_mask_7: 4.313  loss_mask_8: 4.32  time: 1.8846  data_time: 0.4097  lr: 8.8374e-05  max_mem: 17484M
[01/27 07:39:12] d2.utils.events INFO:  eta: 1 day, 1:21:36  iter: 7719  total_loss: 35.14  loss_mask: 3.51  loss_mask_0: 3.563  loss_mask_1: 3.511  loss_mask_2: 3.511  loss_mask_3: 3.517  loss_mask_4: 3.513  loss_mask_5: 3.518  loss_mask_6: 3.512  loss_mask_7: 3.515  loss_mask_8: 3.511  time: 1.8842  data_time: 0.3981  lr: 8.8343e-05  max_mem: 17484M
[01/27 07:39:47] d2.utils.events INFO:  eta: 1 day, 1:21:01  iter: 7739  total_loss: 33.69  loss_mask: 3.363  loss_mask_0: 3.384  loss_mask_1: 3.367  loss_mask_2: 3.368  loss_mask_3: 3.358  loss_mask_4: 3.366  loss_mask_5: 3.367  loss_mask_6: 3.362  loss_mask_7: 3.366  loss_mask_8: 3.37  time: 1.8838  data_time: 0.4003  lr: 8.8313e-05  max_mem: 17484M
[01/27 07:40:22] d2.utils.events INFO:  eta: 1 day, 1:20:52  iter: 7759  total_loss: 36.66  loss_mask: 3.665  loss_mask_0: 3.742  loss_mask_1: 3.654  loss_mask_2: 3.66  loss_mask_3: 3.665  loss_mask_4: 3.654  loss_mask_5: 3.66  loss_mask_6: 3.653  loss_mask_7: 3.658  loss_mask_8: 3.655  time: 1.8836  data_time: 0.4236  lr: 8.8282e-05  max_mem: 17484M
[01/27 07:40:58] d2.utils.events INFO:  eta: 1 day, 1:20:46  iter: 7779  total_loss: 38.19  loss_mask: 3.798  loss_mask_0: 3.987  loss_mask_1: 3.797  loss_mask_2: 3.796  loss_mask_3: 3.81  loss_mask_4: 3.805  loss_mask_5: 3.79  loss_mask_6: 3.8  loss_mask_7: 3.795  loss_mask_8: 3.794  time: 1.8833  data_time: 0.4135  lr: 8.8252e-05  max_mem: 17484M
[01/27 07:41:33] d2.utils.events INFO:  eta: 1 day, 1:21:03  iter: 7799  total_loss: 39.21  loss_mask: 3.918  loss_mask_0: 4.067  loss_mask_1: 3.923  loss_mask_2: 3.918  loss_mask_3: 3.921  loss_mask_4: 3.925  loss_mask_5: 3.918  loss_mask_6: 3.915  loss_mask_7: 3.921  loss_mask_8: 3.923  time: 1.8829  data_time: 0.4139  lr: 8.8222e-05  max_mem: 17484M
[01/27 07:42:07] d2.utils.events INFO:  eta: 1 day, 1:19:49  iter: 7819  total_loss: 42.97  loss_mask: 4.299  loss_mask_0: 4.337  loss_mask_1: 4.29  loss_mask_2: 4.293  loss_mask_3: 4.295  loss_mask_4: 4.272  loss_mask_5: 4.305  loss_mask_6: 4.306  loss_mask_7: 4.272  loss_mask_8: 4.296  time: 1.8825  data_time: 0.4005  lr: 8.8191e-05  max_mem: 17484M
[01/27 07:42:43] d2.utils.events INFO:  eta: 1 day, 1:19:33  iter: 7839  total_loss: 37.97  loss_mask: 3.789  loss_mask_0: 3.812  loss_mask_1: 3.791  loss_mask_2: 3.798  loss_mask_3: 3.794  loss_mask_4: 3.789  loss_mask_5: 3.801  loss_mask_6: 3.791  loss_mask_7: 3.792  loss_mask_8: 3.795  time: 1.8822  data_time: 0.4000  lr: 8.8161e-05  max_mem: 17484M
[01/27 07:43:18] d2.utils.events INFO:  eta: 1 day, 1:18:58  iter: 7859  total_loss: 42.69  loss_mask: 4.266  loss_mask_0: 4.505  loss_mask_1: 4.259  loss_mask_2: 4.26  loss_mask_3: 4.26  loss_mask_4: 4.243  loss_mask_5: 4.255  loss_mask_6: 4.258  loss_mask_7: 4.253  loss_mask_8: 4.264  time: 1.8819  data_time: 0.4175  lr: 8.813e-05  max_mem: 17484M
[01/27 07:43:53] d2.utils.events INFO:  eta: 1 day, 1:19:00  iter: 7879  total_loss: 34.46  loss_mask: 3.449  loss_mask_0: 3.448  loss_mask_1: 3.447  loss_mask_2: 3.447  loss_mask_3: 3.449  loss_mask_4: 3.449  loss_mask_5: 3.445  loss_mask_6: 3.449  loss_mask_7: 3.45  loss_mask_8: 3.446  time: 1.8816  data_time: 0.4095  lr: 8.81e-05  max_mem: 17484M
[01/27 07:44:28] d2.utils.events INFO:  eta: 1 day, 1:18:41  iter: 7899  total_loss: 34.32  loss_mask: 3.419  loss_mask_0: 3.5  loss_mask_1: 3.419  loss_mask_2: 3.414  loss_mask_3: 3.414  loss_mask_4: 3.418  loss_mask_5: 3.416  loss_mask_6: 3.416  loss_mask_7: 3.412  loss_mask_8: 3.415  time: 1.8813  data_time: 0.4179  lr: 8.8069e-05  max_mem: 17484M
[01/27 07:45:03] d2.utils.events INFO:  eta: 1 day, 1:18:02  iter: 7919  total_loss: 33.64  loss_mask: 3.367  loss_mask_0: 3.398  loss_mask_1: 3.362  loss_mask_2: 3.362  loss_mask_3: 3.36  loss_mask_4: 3.359  loss_mask_5: 3.356  loss_mask_6: 3.362  loss_mask_7: 3.363  loss_mask_8: 3.364  time: 1.8809  data_time: 0.3797  lr: 8.8039e-05  max_mem: 17484M
[01/27 07:45:38] d2.utils.events INFO:  eta: 1 day, 1:16:20  iter: 7939  total_loss: 35.76  loss_mask: 3.576  loss_mask_0: 3.63  loss_mask_1: 3.566  loss_mask_2: 3.57  loss_mask_3: 3.579  loss_mask_4: 3.577  loss_mask_5: 3.573  loss_mask_6: 3.573  loss_mask_7: 3.569  loss_mask_8: 3.571  time: 1.8806  data_time: 0.3861  lr: 8.8009e-05  max_mem: 17484M
[01/27 07:46:14] d2.utils.events INFO:  eta: 1 day, 1:16:40  iter: 7959  total_loss: 36.24  loss_mask: 3.624  loss_mask_0: 3.634  loss_mask_1: 3.624  loss_mask_2: 3.618  loss_mask_3: 3.619  loss_mask_4: 3.621  loss_mask_5: 3.628  loss_mask_6: 3.62  loss_mask_7: 3.628  loss_mask_8: 3.625  time: 1.8803  data_time: 0.4311  lr: 8.7978e-05  max_mem: 17484M
[01/27 07:46:49] d2.utils.events INFO:  eta: 1 day, 1:16:06  iter: 7979  total_loss: 36.34  loss_mask: 3.629  loss_mask_0: 3.639  loss_mask_1: 3.631  loss_mask_2: 3.631  loss_mask_3: 3.632  loss_mask_4: 3.635  loss_mask_5: 3.639  loss_mask_6: 3.633  loss_mask_7: 3.637  loss_mask_8: 3.635  time: 1.8800  data_time: 0.4072  lr: 8.7948e-05  max_mem: 17484M
[01/27 07:47:24] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 07:47:24] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 07:47:24] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 07:54:16] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.447059995419115, 'error_1pix': 0.5272355325338686, 'error_3pix': 0.23820681245382344, 'mIoU': 4.845652800003783, 'fwIoU': 11.912988180249402, 'IoU-0': nan, 'IoU-1': 43.24305851990247, 'IoU-2': 2.0319731488153847, 'IoU-3': 1.475178720794212, 'IoU-4': 1.4095966540839298, 'IoU-5': 1.1220508947849936, 'IoU-6': 0.8717940048557261, 'IoU-7': 0.6631635311303391, 'IoU-8': 0.8347798914822904, 'IoU-9': 2.8237236280154097, 'IoU-10': 9.274875822366063, 'IoU-11': 18.592079196340304, 'IoU-12': 19.351327494914877, 'IoU-13': 18.83504260631181, 'IoU-14': 17.6462599759421, 'IoU-15': 15.773142013803385, 'IoU-16': 13.728943348123273, 'IoU-17': 10.59292033488318, 'IoU-18': 9.288727210304796, 'IoU-19': 7.889189491836407, 'IoU-20': 8.20590564673722, 'IoU-21': 8.537685915125154, 'IoU-22': 8.222973320930386, 'IoU-23': 7.660010331037396, 'IoU-24': 7.963132478630784, 'IoU-25': 8.181145572581386, 'IoU-26': 7.915688704422806, 'IoU-27': 8.445097510433468, 'IoU-28': 7.912906167797133, 'IoU-29': 8.395573310036342, 'IoU-30': 8.098472272311765, 'IoU-31': 8.483660739109954, 'IoU-32': 8.444804654415442, 'IoU-33': 7.411867803257093, 'IoU-34': 7.542552429670585, 'IoU-35': 7.393447259162414, 'IoU-36': 7.2578410503303745, 'IoU-37': 7.058051598539307, 'IoU-38': 6.727439448961042, 'IoU-39': 6.603088052186333, 'IoU-40': 7.04195376686407, 'IoU-41': 6.677323166456508, 'IoU-42': 6.794704637335442, 'IoU-43': 7.364277053706673, 'IoU-44': 7.69428818142255, 'IoU-45': 7.724505935775185, 'IoU-46': 7.736176507860043, 'IoU-47': 7.641943298699555, 'IoU-48': 7.600587475901524, 'IoU-49': 7.620411286814702, 'IoU-50': 7.628902451419105, 'IoU-51': 7.516679165985758, 'IoU-52': 7.360680189215494, 'IoU-53': 7.077639996418962, 'IoU-54': 7.470679192791134, 'IoU-55': 7.087966743013905, 'IoU-56': 6.84790885963345, 'IoU-57': 6.986074698408114, 'IoU-58': 6.709779765365694, 'IoU-59': 6.728718820838249, 'IoU-60': 6.517158954681718, 'IoU-61': 6.6523181358546095, 'IoU-62': 6.619900217192262, 'IoU-63': 6.711011989295203, 'IoU-64': 6.483609798009068, 'IoU-65': 6.514268458306072, 'IoU-66': 6.569105822757322, 'IoU-67': 6.48407377663799, 'IoU-68': 6.203842883195758, 'IoU-69': 6.306174910835968, 'IoU-70': 6.371936958850161, 'IoU-71': 6.076515136291027, 'IoU-72': 5.7771366737881555, 'IoU-73': 5.903557993952433, 'IoU-74': 5.943522532616076, 'IoU-75': 5.935882400589679, 'IoU-76': 5.935391807150476, 'IoU-77': 5.747073687240272, 'IoU-78': 5.644942798858285, 'IoU-79': 5.729143570644743, 'IoU-80': 5.725842819626332, 'IoU-81': 5.794947168670469, 'IoU-82': 5.732131126166561, 'IoU-83': 5.632911686461606, 'IoU-84': 5.801109132789821, 'IoU-85': 5.607963628123718, 'IoU-86': 5.574144836583231, 'IoU-87': 5.372060279046841, 'IoU-88': 5.198764468162461, 'IoU-89': 5.219270368864119, 'IoU-90': 5.357877628169511, 'IoU-91': 5.359214569415547, 'IoU-92': 5.126027054581579, 'IoU-93': 5.050906482387742, 'IoU-94': 4.9404501576230535, 'IoU-95': 5.018886204648738, 'IoU-96': 5.142446928769502, 'IoU-97': 5.0481799296007335, 'IoU-98': 4.8558442895119835, 'IoU-99': 4.800230399610753, 'IoU-100': 4.890048333422331, 'IoU-101': 4.923025078595146, 'IoU-102': 4.7582107592716785, 'IoU-103': 4.664458807227142, 'IoU-104': 4.269211737708139, 'IoU-105': 4.210829223120151, 'IoU-106': 4.131900365630589, 'IoU-107': 4.407327213925683, 'IoU-108': 4.339583735208232, 'IoU-109': 4.091535951843205, 'IoU-110': 3.9559856233405744, 'IoU-111': 3.944879757795256, 'IoU-112': 3.9680531864197315, 'IoU-113': 3.7408963842428484, 'IoU-114': 3.58115684603551, 'IoU-115': 3.5944456917156247, 'IoU-116': 3.385422270482862, 'IoU-117': 3.3403781527568883, 'IoU-118': 3.410736139190472, 'IoU-119': 3.38251428751316, 'IoU-120': 3.341491335412308, 'IoU-121': 3.366271102722419, 'IoU-122': 3.208172122214507, 'IoU-123': 3.1588317090297227, 'IoU-124': 3.1843804663764415, 'IoU-125': 3.0527374760176773, 'IoU-126': 2.733062767847356, 'IoU-127': 2.796256326255168, 'IoU-128': 2.6729757635371674, 'IoU-129': 2.5441443615899595, 'IoU-130': 2.629000204232322, 'IoU-131': 2.268580307265621, 'IoU-132': 2.196716922062943, 'IoU-133': 2.248226661879995, 'IoU-134': 2.153036427888269, 'IoU-135': 2.177249641202585, 'IoU-136': 2.1342009916634304, 'IoU-137': 2.0753707786204947, 'IoU-138': 2.0014700039080195, 'IoU-139': 2.2158161620554595, 'IoU-140': 2.1132654089180343, 'IoU-141': 2.113110173881006, 'IoU-142': 2.1489177505142263, 'IoU-143': 1.9448872952563585, 'IoU-144': 1.86743777329984, 'IoU-145': 1.8653797563813264, 'IoU-146': 1.8077427397524461, 'IoU-147': 1.8926551374174507, 'IoU-148': 1.9367246981435646, 'IoU-149': 1.7337149731717536, 'IoU-150': 1.6671334154811246, 'IoU-151': 1.8704737026164309, 'IoU-152': 1.8915094853637429, 'IoU-153': 1.650363618511685, 'IoU-154': 1.7897717406942535, 'IoU-155': 1.7138974815207046, 'IoU-156': 1.8264907793781129, 'IoU-157': 1.7575814688801465, 'IoU-158': 1.5736795972032531, 'IoU-159': 1.5793706980588678, 'IoU-160': 1.7895139593582372, 'IoU-161': 1.6704617879204102, 'IoU-162': 1.6707181133241114, 'IoU-163': 1.888896802683208, 'IoU-164': 1.6883397336958161, 'IoU-165': 1.5492138931913177, 'IoU-166': 1.3866333652334102, 'IoU-167': 1.423373385758934, 'IoU-168': 1.3766520335616446, 'IoU-169': 1.545256949415414, 'IoU-170': 1.591643540019751, 'IoU-171': 1.494306795140804, 'IoU-172': 1.60374892837639, 'IoU-173': 1.6429007774123632, 'IoU-174': 1.5197418761069523, 'IoU-175': 1.7808286707253949, 'IoU-176': 1.4337658532897348, 'IoU-177': 1.140746850723873, 'IoU-178': 1.4791329351434188, 'IoU-179': 1.5407716724931755, 'IoU-180': 1.8958904799449818, 'IoU-181': 1.0869911984374834, 'IoU-182': 0.7367305842750661, 'IoU-183': 0.6409242906946411, 'IoU-184': 0.6295352475669062, 'IoU-185': 0.3375837657290507, 'IoU-186': 0.25854830899632614, 'IoU-187': 0.15520554278956405, 'IoU-188': 0.1340304229349706, 'IoU-189': 0.13569482840680094, 'IoU-190': 0.17753137944996417, 'IoU-191': 0.14224714142947995, 'IoU-192': 0.06458090097407176, 'mACC': 9.00161555890077, 'pACC': 18.202377335850237, 'ACC-0': nan, 'ACC-1': 43.711885423436605, 'ACC-2': 7.504001147833907, 'ACC-3': 13.079923558813267, 'ACC-4': 9.9246785394851, 'ACC-5': 7.428630948341574, 'ACC-6': 5.780934986901491, 'ACC-7': 4.152400538193115, 'ACC-8': 2.0171736250606562, 'ACC-9': 3.95023279632962, 'ACC-10': 13.111637829460458, 'ACC-11': 26.491611496748842, 'ACC-12': 31.1798729693383, 'ACC-13': 33.0748954805271, 'ACC-14': 32.13155513192959, 'ACC-15': 29.861048262888158, 'ACC-16': 26.73119217723785, 'ACC-17': 22.089245071175252, 'ACC-18': 18.049926045602948, 'ACC-19': 15.175263277850433, 'ACC-20': 16.15666790490342, 'ACC-21': 16.604161795399225, 'ACC-22': 15.01977524997418, 'ACC-23': 14.443564097511555, 'ACC-24': 15.03144178534151, 'ACC-25': 15.607712346749524, 'ACC-26': 15.299903525463879, 'ACC-27': 15.876006943827681, 'ACC-28': 15.295142831016188, 'ACC-29': 15.758418156822854, 'ACC-30': 15.449300100081196, 'ACC-31': 15.846335019977275, 'ACC-32': 15.822846176596105, 'ACC-33': 14.390173973698348, 'ACC-34': 14.859072100015942, 'ACC-35': 14.236458696320994, 'ACC-36': 13.639215753760245, 'ACC-37': 13.262668491687934, 'ACC-38': 12.283922963283104, 'ACC-39': 11.98012122294187, 'ACC-40': 12.68665267168414, 'ACC-41': 12.309253703405666, 'ACC-42': 12.574257415242215, 'ACC-43': 13.532102234137728, 'ACC-44': 13.72473359784733, 'ACC-45': 13.854422676826115, 'ACC-46': 14.16899142182835, 'ACC-47': 14.046477979654206, 'ACC-48': 13.962945247283262, 'ACC-49': 13.848164345629902, 'ACC-50': 13.821492259472295, 'ACC-51': 13.882455069179567, 'ACC-52': 13.581580669235127, 'ACC-53': 12.983615228458714, 'ACC-54': 13.478317568039925, 'ACC-55': 12.77346023121252, 'ACC-56': 12.387459523954533, 'ACC-57': 12.378539660144941, 'ACC-58': 11.990772641647181, 'ACC-59': 12.122075331865803, 'ACC-60': 11.859577015579399, 'ACC-61': 12.197110787319971, 'ACC-62': 12.189445946542747, 'ACC-63': 12.4189037536135, 'ACC-64': 11.993751681349062, 'ACC-65': 12.103119511624536, 'ACC-66': 12.268282781371127, 'ACC-67': 12.215073904780688, 'ACC-68': 11.728274471938876, 'ACC-69': 11.696710499765969, 'ACC-70': 11.676908863160667, 'ACC-71': 11.302200167924816, 'ACC-72': 10.766265578686566, 'ACC-73': 10.913766607780802, 'ACC-74': 10.929592941920008, 'ACC-75': 10.915151587952462, 'ACC-76': 10.790685596081268, 'ACC-77': 10.66291163164997, 'ACC-78': 10.580035862497956, 'ACC-79': 10.778220817178806, 'ACC-80': 10.735167552393609, 'ACC-81': 10.865501702461005, 'ACC-82': 10.802929530203608, 'ACC-83': 10.524893548515266, 'ACC-84': 10.877867595295596, 'ACC-85': 10.496752030877579, 'ACC-86': 10.40109997290386, 'ACC-87': 10.06977172114019, 'ACC-88': 9.803701251463593, 'ACC-89': 9.851348437279578, 'ACC-90': 10.080810307202661, 'ACC-91': 10.116519672186024, 'ACC-92': 9.720608856238105, 'ACC-93': 9.563943899676941, 'ACC-94': 9.328237250365525, 'ACC-95': 9.529888028104725, 'ACC-96': 9.8620136425957, 'ACC-97': 9.639162522991171, 'ACC-98': 9.292336310719293, 'ACC-99': 9.314667384548217, 'ACC-100': 9.561289124492053, 'ACC-101': 9.64594176807303, 'ACC-102': 9.321545083824196, 'ACC-103': 9.082294323226598, 'ACC-104': 8.292344015149652, 'ACC-105': 8.191848350334347, 'ACC-106': 8.006609087574082, 'ACC-107': 8.500319830816025, 'ACC-108': 8.2937696407859, 'ACC-109': 7.781647467054487, 'ACC-110': 7.580011736831219, 'ACC-111': 7.538513658140181, 'ACC-112': 7.604139765464896, 'ACC-113': 7.140432187064905, 'ACC-114': 6.84712847718128, 'ACC-115': 6.800024055447808, 'ACC-116': 6.430605054937108, 'ACC-117': 6.369386825167339, 'ACC-118': 6.597480703884667, 'ACC-119': 6.544052271098422, 'ACC-120': 6.469734026291654, 'ACC-121': 6.528444645709741, 'ACC-122': 6.229820638380178, 'ACC-123': 6.195119496160215, 'ACC-124': 6.449253396594003, 'ACC-125': 6.182052138274, 'ACC-126': 5.549401633894662, 'ACC-127': 5.6243516900447625, 'ACC-128': 5.33619712864271, 'ACC-129': 5.027049516208688, 'ACC-130': 5.180346349605178, 'ACC-131': 4.485772369880502, 'ACC-132': 4.2888882186768, 'ACC-133': 4.325052562820225, 'ACC-134': 4.109263248599741, 'ACC-135': 4.172937688843281, 'ACC-136': 4.116922521431234, 'ACC-137': 4.066044021715487, 'ACC-138': 3.883623753077645, 'ACC-139': 4.293987630272383, 'ACC-140': 4.013503686513044, 'ACC-141': 3.972349578881461, 'ACC-142': 4.071081488002291, 'ACC-143': 3.6964915859347127, 'ACC-144': 3.5070523720302242, 'ACC-145': 3.44055858985758, 'ACC-146': 3.32364937048149, 'ACC-147': 3.4563093453969422, 'ACC-148': 3.5195730924278847, 'ACC-149': 3.2181644303231347, 'ACC-150': 3.1024663382662876, 'ACC-151': 3.4830653533051814, 'ACC-152': 3.475075971187848, 'ACC-153': 3.137489321451229, 'ACC-154': 3.388801608157265, 'ACC-155': 3.2555920821515603, 'ACC-156': 3.5085360414229108, 'ACC-157': 3.401725362944169, 'ACC-158': 3.050944104603798, 'ACC-159': 3.0205333889094463, 'ACC-160': 3.3461811456704385, 'ACC-161': 3.0842423357336237, 'ACC-162': 3.146274696500833, 'ACC-163': 3.5677050688989924, 'ACC-164': 3.198197555410743, 'ACC-165': 2.899305748579651, 'ACC-166': 2.6248807940793273, 'ACC-167': 2.6979323380111393, 'ACC-168': 2.60436998195879, 'ACC-169': 2.9094386971667237, 'ACC-170': 2.9836652757094857, 'ACC-171': 2.7974263530570327, 'ACC-172': 2.92147403834041, 'ACC-173': 2.955605695929785, 'ACC-174': 2.648145868996871, 'ACC-175': 2.940300522946183, 'ACC-176': 2.2020868751122635, 'ACC-177': 1.679977255692538, 'ACC-178': 2.1110391931448222, 'ACC-179': 2.1387183520219186, 'ACC-180': 2.5505904869982765, 'ACC-181': 1.453248661200891, 'ACC-182': 0.9296724812678817, 'ACC-183': 0.7640385906633211, 'ACC-184': 0.7186029942577817, 'ACC-185': 0.3714808145300548, 'ACC-186': 0.27508235928024843, 'ACC-187': 0.16153057473932642, 'ACC-188': 0.1372503506948299, 'ACC-189': 0.13768372814656124, 'ACC-190': 0.17934303813399338, 'ACC-191': 0.14321106383868373, 'ACC-192': 0.0648760131565155})])
[01/27 07:54:16] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 07:54:16] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 07:54:16] d2.evaluation.testing INFO: copypaste: 3.4471,0.5272,0.2382,4.8457,11.9130,9.0016,18.2024
[01/27 07:54:16] d2.utils.events INFO:  eta: 1 day, 1:15:22  iter: 7999  total_loss: 37.48  loss_mask: 3.739  loss_mask_0: 3.809  loss_mask_1: 3.738  loss_mask_2: 3.745  loss_mask_3: 3.741  loss_mask_4: 3.737  loss_mask_5: 3.735  loss_mask_6: 3.742  loss_mask_7: 3.736  loss_mask_8: 3.739  time: 1.8797  data_time: 0.4005  lr: 8.7917e-05  max_mem: 17484M
[01/27 07:54:51] d2.utils.events INFO:  eta: 1 day, 1:15:11  iter: 8019  total_loss: 37.36  loss_mask: 3.72  loss_mask_0: 3.829  loss_mask_1: 3.729  loss_mask_2: 3.72  loss_mask_3: 3.727  loss_mask_4: 3.73  loss_mask_5: 3.719  loss_mask_6: 3.727  loss_mask_7: 3.715  loss_mask_8: 3.721  time: 1.8794  data_time: 0.4304  lr: 8.7887e-05  max_mem: 17484M
[01/27 07:55:26] d2.utils.events INFO:  eta: 1 day, 1:14:27  iter: 8039  total_loss: 39.73  loss_mask: 3.958  loss_mask_0: 4.119  loss_mask_1: 3.949  loss_mask_2: 3.94  loss_mask_3: 3.953  loss_mask_4: 3.998  loss_mask_5: 3.953  loss_mask_6: 3.937  loss_mask_7: 3.955  loss_mask_8: 3.961  time: 1.8791  data_time: 0.3973  lr: 8.7856e-05  max_mem: 17484M
[01/27 07:56:01] d2.utils.events INFO:  eta: 1 day, 1:13:52  iter: 8059  total_loss: 35.2  loss_mask: 3.51  loss_mask_0: 3.6  loss_mask_1: 3.51  loss_mask_2: 3.511  loss_mask_3: 3.502  loss_mask_4: 3.51  loss_mask_5: 3.509  loss_mask_6: 3.514  loss_mask_7: 3.5  loss_mask_8: 3.516  time: 1.8787  data_time: 0.4161  lr: 8.7826e-05  max_mem: 17484M
[01/27 07:56:36] d2.utils.events INFO:  eta: 1 day, 1:13:33  iter: 8079  total_loss: 36.06  loss_mask: 3.606  loss_mask_0: 3.642  loss_mask_1: 3.593  loss_mask_2: 3.589  loss_mask_3: 3.595  loss_mask_4: 3.61  loss_mask_5: 3.599  loss_mask_6: 3.589  loss_mask_7: 3.597  loss_mask_8: 3.6  time: 1.8784  data_time: 0.3929  lr: 8.7796e-05  max_mem: 17484M
[01/27 07:57:11] d2.utils.events INFO:  eta: 1 day, 1:13:20  iter: 8099  total_loss: 33.34  loss_mask: 3.325  loss_mask_0: 3.392  loss_mask_1: 3.326  loss_mask_2: 3.331  loss_mask_3: 3.327  loss_mask_4: 3.334  loss_mask_5: 3.326  loss_mask_6: 3.324  loss_mask_7: 3.326  loss_mask_8: 3.33  time: 1.8781  data_time: 0.4055  lr: 8.7765e-05  max_mem: 17484M
[01/27 07:57:46] d2.utils.events INFO:  eta: 1 day, 1:12:13  iter: 8119  total_loss: 33.23  loss_mask: 3.32  loss_mask_0: 3.357  loss_mask_1: 3.322  loss_mask_2: 3.316  loss_mask_3: 3.318  loss_mask_4: 3.318  loss_mask_5: 3.324  loss_mask_6: 3.322  loss_mask_7: 3.318  loss_mask_8: 3.316  time: 1.8778  data_time: 0.3847  lr: 8.7735e-05  max_mem: 17484M
[01/27 07:58:21] d2.utils.events INFO:  eta: 1 day, 1:11:41  iter: 8139  total_loss: 33.69  loss_mask: 3.367  loss_mask_0: 3.378  loss_mask_1: 3.367  loss_mask_2: 3.367  loss_mask_3: 3.368  loss_mask_4: 3.368  loss_mask_5: 3.367  loss_mask_6: 3.367  loss_mask_7: 3.367  loss_mask_8: 3.371  time: 1.8775  data_time: 0.4165  lr: 8.7704e-05  max_mem: 17484M
[01/27 07:58:56] d2.utils.events INFO:  eta: 1 day, 1:11:30  iter: 8159  total_loss: 36.27  loss_mask: 3.631  loss_mask_0: 3.695  loss_mask_1: 3.629  loss_mask_2: 3.63  loss_mask_3: 3.627  loss_mask_4: 3.623  loss_mask_5: 3.623  loss_mask_6: 3.624  loss_mask_7: 3.62  loss_mask_8: 3.627  time: 1.8772  data_time: 0.3845  lr: 8.7674e-05  max_mem: 17484M
[01/27 07:59:32] d2.utils.events INFO:  eta: 1 day, 1:10:55  iter: 8179  total_loss: 39.1  loss_mask: 3.918  loss_mask_0: 3.921  loss_mask_1: 3.904  loss_mask_2: 3.909  loss_mask_3: 3.903  loss_mask_4: 3.91  loss_mask_5: 3.91  loss_mask_6: 3.898  loss_mask_7: 3.899  loss_mask_8: 3.891  time: 1.8769  data_time: 0.4076  lr: 8.7643e-05  max_mem: 17484M
[01/27 08:00:07] d2.utils.events INFO:  eta: 1 day, 1:10:20  iter: 8199  total_loss: 36.1  loss_mask: 3.613  loss_mask_0: 3.667  loss_mask_1: 3.599  loss_mask_2: 3.594  loss_mask_3: 3.596  loss_mask_4: 3.608  loss_mask_5: 3.609  loss_mask_6: 3.608  loss_mask_7: 3.603  loss_mask_8: 3.603  time: 1.8766  data_time: 0.4046  lr: 8.7613e-05  max_mem: 17484M
[01/27 08:00:42] d2.utils.events INFO:  eta: 1 day, 1:09:45  iter: 8219  total_loss: 35.36  loss_mask: 3.532  loss_mask_0: 3.574  loss_mask_1: 3.533  loss_mask_2: 3.528  loss_mask_3: 3.537  loss_mask_4: 3.528  loss_mask_5: 3.532  loss_mask_6: 3.534  loss_mask_7: 3.529  loss_mask_8: 3.538  time: 1.8763  data_time: 0.4059  lr: 8.7582e-05  max_mem: 17484M
[01/27 08:01:17] d2.utils.events INFO:  eta: 1 day, 1:08:53  iter: 8239  total_loss: 35.28  loss_mask: 3.526  loss_mask_0: 3.561  loss_mask_1: 3.525  loss_mask_2: 3.525  loss_mask_3: 3.526  loss_mask_4: 3.523  loss_mask_5: 3.526  loss_mask_6: 3.525  loss_mask_7: 3.523  loss_mask_8: 3.522  time: 1.8760  data_time: 0.4104  lr: 8.7552e-05  max_mem: 17484M
[01/27 08:01:52] d2.utils.events INFO:  eta: 1 day, 1:08:44  iter: 8259  total_loss: 41.2  loss_mask: 4.119  loss_mask_0: 4.207  loss_mask_1: 4.115  loss_mask_2: 4.118  loss_mask_3: 4.125  loss_mask_4: 4.123  loss_mask_5: 4.127  loss_mask_6: 4.109  loss_mask_7: 4.118  loss_mask_8: 4.111  time: 1.8757  data_time: 0.4095  lr: 8.7522e-05  max_mem: 17484M
[01/27 08:02:27] d2.utils.events INFO:  eta: 1 day, 1:08:01  iter: 8279  total_loss: 38.19  loss_mask: 3.819  loss_mask_0: 3.829  loss_mask_1: 3.812  loss_mask_2: 3.813  loss_mask_3: 3.821  loss_mask_4: 3.824  loss_mask_5: 3.813  loss_mask_6: 3.822  loss_mask_7: 3.82  loss_mask_8: 3.821  time: 1.8754  data_time: 0.3945  lr: 8.7491e-05  max_mem: 17484M
[01/27 08:03:02] d2.utils.events INFO:  eta: 1 day, 1:07:25  iter: 8299  total_loss: 33.9  loss_mask: 3.391  loss_mask_0: 3.435  loss_mask_1: 3.384  loss_mask_2: 3.392  loss_mask_3: 3.389  loss_mask_4: 3.387  loss_mask_5: 3.392  loss_mask_6: 3.394  loss_mask_7: 3.385  loss_mask_8: 3.389  time: 1.8751  data_time: 0.3985  lr: 8.7461e-05  max_mem: 17484M
[01/27 08:03:38] d2.utils.events INFO:  eta: 1 day, 1:06:55  iter: 8319  total_loss: 34.72  loss_mask: 3.463  loss_mask_0: 3.484  loss_mask_1: 3.469  loss_mask_2: 3.464  loss_mask_3: 3.465  loss_mask_4: 3.467  loss_mask_5: 3.461  loss_mask_6: 3.46  loss_mask_7: 3.46  loss_mask_8: 3.459  time: 1.8749  data_time: 0.4327  lr: 8.743e-05  max_mem: 17484M
[01/27 08:04:13] d2.utils.events INFO:  eta: 1 day, 1:06:16  iter: 8339  total_loss: 36.15  loss_mask: 3.634  loss_mask_0: 3.577  loss_mask_1: 3.603  loss_mask_2: 3.614  loss_mask_3: 3.615  loss_mask_4: 3.63  loss_mask_5: 3.634  loss_mask_6: 3.621  loss_mask_7: 3.62  loss_mask_8: 3.622  time: 1.8746  data_time: 0.3957  lr: 8.74e-05  max_mem: 17484M
[01/27 08:04:48] d2.utils.events INFO:  eta: 1 day, 1:05:52  iter: 8359  total_loss: 35.29  loss_mask: 3.519  loss_mask_0: 3.626  loss_mask_1: 3.521  loss_mask_2: 3.53  loss_mask_3: 3.529  loss_mask_4: 3.517  loss_mask_5: 3.523  loss_mask_6: 3.519  loss_mask_7: 3.513  loss_mask_8: 3.523  time: 1.8743  data_time: 0.4137  lr: 8.7369e-05  max_mem: 17484M
[01/27 08:05:23] d2.utils.events INFO:  eta: 1 day, 1:05:11  iter: 8379  total_loss: 34.68  loss_mask: 3.456  loss_mask_0: 3.578  loss_mask_1: 3.46  loss_mask_2: 3.465  loss_mask_3: 3.46  loss_mask_4: 3.459  loss_mask_5: 3.461  loss_mask_6: 3.47  loss_mask_7: 3.46  loss_mask_8: 3.462  time: 1.8740  data_time: 0.3943  lr: 8.7339e-05  max_mem: 17484M
[01/27 08:05:58] d2.utils.events INFO:  eta: 1 day, 1:04:50  iter: 8399  total_loss: 33.1  loss_mask: 3.307  loss_mask_0: 3.428  loss_mask_1: 3.302  loss_mask_2: 3.293  loss_mask_3: 3.299  loss_mask_4: 3.299  loss_mask_5: 3.3  loss_mask_6: 3.296  loss_mask_7: 3.296  loss_mask_8: 3.303  time: 1.8737  data_time: 0.4139  lr: 8.7308e-05  max_mem: 17484M
[01/27 08:06:33] d2.utils.events INFO:  eta: 1 day, 1:04:07  iter: 8419  total_loss: 35.64  loss_mask: 3.561  loss_mask_0: 3.604  loss_mask_1: 3.559  loss_mask_2: 3.562  loss_mask_3: 3.559  loss_mask_4: 3.557  loss_mask_5: 3.559  loss_mask_6: 3.558  loss_mask_7: 3.553  loss_mask_8: 3.565  time: 1.8734  data_time: 0.3959  lr: 8.7278e-05  max_mem: 17484M
[01/27 08:07:08] d2.utils.events INFO:  eta: 1 day, 1:03:28  iter: 8439  total_loss: 36.27  loss_mask: 3.633  loss_mask_0: 3.614  loss_mask_1: 3.623  loss_mask_2: 3.623  loss_mask_3: 3.615  loss_mask_4: 3.643  loss_mask_5: 3.627  loss_mask_6: 3.622  loss_mask_7: 3.629  loss_mask_8: 3.626  time: 1.8731  data_time: 0.3919  lr: 8.7248e-05  max_mem: 17484M
[01/27 08:07:43] d2.utils.events INFO:  eta: 1 day, 1:02:51  iter: 8459  total_loss: 36.62  loss_mask: 3.656  loss_mask_0: 3.697  loss_mask_1: 3.653  loss_mask_2: 3.66  loss_mask_3: 3.67  loss_mask_4: 3.661  loss_mask_5: 3.657  loss_mask_6: 3.659  loss_mask_7: 3.655  loss_mask_8: 3.654  time: 1.8729  data_time: 0.3939  lr: 8.7217e-05  max_mem: 17484M
[01/27 08:08:18] d2.utils.events INFO:  eta: 1 day, 1:02:13  iter: 8479  total_loss: 32.63  loss_mask: 3.265  loss_mask_0: 3.255  loss_mask_1: 3.262  loss_mask_2: 3.263  loss_mask_3: 3.266  loss_mask_4: 3.262  loss_mask_5: 3.264  loss_mask_6: 3.263  loss_mask_7: 3.264  loss_mask_8: 3.263  time: 1.8725  data_time: 0.3960  lr: 8.7187e-05  max_mem: 17484M
[01/27 08:08:53] d2.utils.events INFO:  eta: 1 day, 1:01:41  iter: 8499  total_loss: 37.4  loss_mask: 3.734  loss_mask_0: 3.745  loss_mask_1: 3.728  loss_mask_2: 3.731  loss_mask_3: 3.734  loss_mask_4: 3.734  loss_mask_5: 3.736  loss_mask_6: 3.739  loss_mask_7: 3.731  loss_mask_8: 3.732  time: 1.8722  data_time: 0.3801  lr: 8.7156e-05  max_mem: 17484M
[01/27 08:09:28] d2.utils.events INFO:  eta: 1 day, 1:00:47  iter: 8519  total_loss: 33.21  loss_mask: 3.307  loss_mask_0: 3.396  loss_mask_1: 3.315  loss_mask_2: 3.313  loss_mask_3: 3.314  loss_mask_4: 3.314  loss_mask_5: 3.319  loss_mask_6: 3.304  loss_mask_7: 3.305  loss_mask_8: 3.317  time: 1.8719  data_time: 0.3879  lr: 8.7126e-05  max_mem: 17484M
[01/27 08:10:03] d2.utils.events INFO:  eta: 1 day, 1:00:18  iter: 8539  total_loss: 32.01  loss_mask: 3.198  loss_mask_0: 3.219  loss_mask_1: 3.201  loss_mask_2: 3.194  loss_mask_3: 3.207  loss_mask_4: 3.195  loss_mask_5: 3.199  loss_mask_6: 3.198  loss_mask_7: 3.199  loss_mask_8: 3.193  time: 1.8717  data_time: 0.4084  lr: 8.7095e-05  max_mem: 17484M
[01/27 08:10:38] d2.utils.events INFO:  eta: 1 day, 0:59:53  iter: 8559  total_loss: 33.58  loss_mask: 3.358  loss_mask_0: 3.405  loss_mask_1: 3.352  loss_mask_2: 3.352  loss_mask_3: 3.349  loss_mask_4: 3.355  loss_mask_5: 3.353  loss_mask_6: 3.35  loss_mask_7: 3.35  loss_mask_8: 3.348  time: 1.8714  data_time: 0.3980  lr: 8.7065e-05  max_mem: 17484M
[01/27 08:11:14] d2.utils.events INFO:  eta: 1 day, 0:59:23  iter: 8579  total_loss: 33.55  loss_mask: 3.352  loss_mask_0: 3.406  loss_mask_1: 3.352  loss_mask_2: 3.349  loss_mask_3: 3.349  loss_mask_4: 3.349  loss_mask_5: 3.348  loss_mask_6: 3.35  loss_mask_7: 3.351  loss_mask_8: 3.348  time: 1.8711  data_time: 0.4034  lr: 8.7034e-05  max_mem: 17484M
[01/27 08:11:49] d2.utils.events INFO:  eta: 1 day, 0:59:32  iter: 8599  total_loss: 30.21  loss_mask: 3.015  loss_mask_0: 3.042  loss_mask_1: 3.019  loss_mask_2: 3.017  loss_mask_3: 3.02  loss_mask_4: 3.015  loss_mask_5: 3.015  loss_mask_6: 3.016  loss_mask_7: 3.016  loss_mask_8: 3.015  time: 1.8709  data_time: 0.4162  lr: 8.7004e-05  max_mem: 17484M
[01/27 08:12:24] d2.utils.events INFO:  eta: 1 day, 0:58:26  iter: 8619  total_loss: 31.36  loss_mask: 3.134  loss_mask_0: 3.156  loss_mask_1: 3.132  loss_mask_2: 3.131  loss_mask_3: 3.127  loss_mask_4: 3.133  loss_mask_5: 3.129  loss_mask_6: 3.131  loss_mask_7: 3.132  loss_mask_8: 3.128  time: 1.8706  data_time: 0.3991  lr: 8.6973e-05  max_mem: 17484M
[01/27 08:12:59] d2.utils.events INFO:  eta: 1 day, 0:57:37  iter: 8639  total_loss: 37.78  loss_mask: 3.777  loss_mask_0: 3.799  loss_mask_1: 3.777  loss_mask_2: 3.777  loss_mask_3: 3.768  loss_mask_4: 3.778  loss_mask_5: 3.77  loss_mask_6: 3.775  loss_mask_7: 3.768  loss_mask_8: 3.768  time: 1.8703  data_time: 0.4142  lr: 8.6943e-05  max_mem: 17484M
[01/27 08:13:35] d2.utils.events INFO:  eta: 1 day, 0:57:09  iter: 8659  total_loss: 35.71  loss_mask: 3.566  loss_mask_0: 3.629  loss_mask_1: 3.567  loss_mask_2: 3.568  loss_mask_3: 3.565  loss_mask_4: 3.564  loss_mask_5: 3.57  loss_mask_6: 3.562  loss_mask_7: 3.569  loss_mask_8: 3.573  time: 1.8701  data_time: 0.4159  lr: 8.6912e-05  max_mem: 17484M
[01/27 08:14:09] d2.utils.events INFO:  eta: 1 day, 0:56:27  iter: 8679  total_loss: 34.91  loss_mask: 3.477  loss_mask_0: 3.517  loss_mask_1: 3.489  loss_mask_2: 3.488  loss_mask_3: 3.492  loss_mask_4: 3.49  loss_mask_5: 3.485  loss_mask_6: 3.487  loss_mask_7: 3.483  loss_mask_8: 3.49  time: 1.8698  data_time: 0.3929  lr: 8.6882e-05  max_mem: 17484M
[01/27 08:14:45] d2.utils.events INFO:  eta: 1 day, 0:55:52  iter: 8699  total_loss: 33.55  loss_mask: 3.352  loss_mask_0: 3.381  loss_mask_1: 3.352  loss_mask_2: 3.354  loss_mask_3: 3.353  loss_mask_4: 3.352  loss_mask_5: 3.351  loss_mask_6: 3.349  loss_mask_7: 3.351  loss_mask_8: 3.356  time: 1.8696  data_time: 0.3995  lr: 8.6851e-05  max_mem: 17484M
[01/27 08:15:20] d2.utils.events INFO:  eta: 1 day, 0:55:31  iter: 8719  total_loss: 40.15  loss_mask: 3.983  loss_mask_0: 4.094  loss_mask_1: 3.987  loss_mask_2: 3.982  loss_mask_3: 3.981  loss_mask_4: 3.986  loss_mask_5: 3.987  loss_mask_6: 3.982  loss_mask_7: 3.983  loss_mask_8: 3.976  time: 1.8693  data_time: 0.4059  lr: 8.6821e-05  max_mem: 17484M
[01/27 08:15:55] d2.utils.events INFO:  eta: 1 day, 0:55:12  iter: 8739  total_loss: 36.91  loss_mask: 3.7  loss_mask_0: 3.742  loss_mask_1: 3.692  loss_mask_2: 3.712  loss_mask_3: 3.701  loss_mask_4: 3.702  loss_mask_5: 3.696  loss_mask_6: 3.694  loss_mask_7: 3.69  loss_mask_8: 3.699  time: 1.8690  data_time: 0.4049  lr: 8.6791e-05  max_mem: 17484M
[01/27 08:16:31] d2.utils.events INFO:  eta: 1 day, 0:54:21  iter: 8759  total_loss: 33.82  loss_mask: 3.375  loss_mask_0: 3.44  loss_mask_1: 3.376  loss_mask_2: 3.378  loss_mask_3: 3.378  loss_mask_4: 3.372  loss_mask_5: 3.375  loss_mask_6: 3.375  loss_mask_7: 3.375  loss_mask_8: 3.375  time: 1.8688  data_time: 0.4300  lr: 8.676e-05  max_mem: 17484M
[01/27 08:17:06] d2.utils.events INFO:  eta: 1 day, 0:53:39  iter: 8779  total_loss: 36.81  loss_mask: 3.673  loss_mask_0: 3.806  loss_mask_1: 3.678  loss_mask_2: 3.674  loss_mask_3: 3.675  loss_mask_4: 3.676  loss_mask_5: 3.675  loss_mask_6: 3.67  loss_mask_7: 3.674  loss_mask_8: 3.675  time: 1.8686  data_time: 0.3948  lr: 8.673e-05  max_mem: 17484M
[01/27 08:17:41] d2.utils.events INFO:  eta: 1 day, 0:53:04  iter: 8799  total_loss: 34.8  loss_mask: 3.479  loss_mask_0: 3.498  loss_mask_1: 3.476  loss_mask_2: 3.481  loss_mask_3: 3.483  loss_mask_4: 3.474  loss_mask_5: 3.471  loss_mask_6: 3.473  loss_mask_7: 3.481  loss_mask_8: 3.481  time: 1.8683  data_time: 0.3837  lr: 8.6699e-05  max_mem: 17484M
[01/27 08:18:16] d2.utils.events INFO:  eta: 1 day, 0:53:01  iter: 8819  total_loss: 35.49  loss_mask: 3.525  loss_mask_0: 3.713  loss_mask_1: 3.526  loss_mask_2: 3.521  loss_mask_3: 3.527  loss_mask_4: 3.534  loss_mask_5: 3.533  loss_mask_6: 3.522  loss_mask_7: 3.531  loss_mask_8: 3.526  time: 1.8681  data_time: 0.4113  lr: 8.6669e-05  max_mem: 17484M
[01/27 08:18:51] d2.utils.events INFO:  eta: 1 day, 0:52:26  iter: 8839  total_loss: 35.86  loss_mask: 3.584  loss_mask_0: 3.581  loss_mask_1: 3.584  loss_mask_2: 3.585  loss_mask_3: 3.589  loss_mask_4: 3.59  loss_mask_5: 3.592  loss_mask_6: 3.581  loss_mask_7: 3.584  loss_mask_8: 3.585  time: 1.8678  data_time: 0.4049  lr: 8.6638e-05  max_mem: 17484M
[01/27 08:19:26] d2.utils.events INFO:  eta: 1 day, 0:51:42  iter: 8859  total_loss: 35.13  loss_mask: 3.503  loss_mask_0: 3.661  loss_mask_1: 3.497  loss_mask_2: 3.499  loss_mask_3: 3.495  loss_mask_4: 3.496  loss_mask_5: 3.498  loss_mask_6: 3.499  loss_mask_7: 3.499  loss_mask_8: 3.505  time: 1.8675  data_time: 0.3878  lr: 8.6608e-05  max_mem: 17484M
[01/27 08:20:01] d2.utils.events INFO:  eta: 1 day, 0:51:00  iter: 8879  total_loss: 37.33  loss_mask: 3.753  loss_mask_0: 3.784  loss_mask_1: 3.738  loss_mask_2: 3.742  loss_mask_3: 3.743  loss_mask_4: 3.743  loss_mask_5: 3.743  loss_mask_6: 3.741  loss_mask_7: 3.743  loss_mask_8: 3.749  time: 1.8673  data_time: 0.3927  lr: 8.6577e-05  max_mem: 17484M
[01/27 08:20:36] d2.utils.events INFO:  eta: 1 day, 0:50:06  iter: 8899  total_loss: 34.83  loss_mask: 3.468  loss_mask_0: 3.588  loss_mask_1: 3.463  loss_mask_2: 3.467  loss_mask_3: 3.462  loss_mask_4: 3.462  loss_mask_5: 3.465  loss_mask_6: 3.461  loss_mask_7: 3.464  loss_mask_8: 3.466  time: 1.8670  data_time: 0.3990  lr: 8.6547e-05  max_mem: 17484M
[01/27 08:21:11] d2.utils.events INFO:  eta: 1 day, 0:49:27  iter: 8919  total_loss: 36.28  loss_mask: 3.632  loss_mask_0: 3.579  loss_mask_1: 3.632  loss_mask_2: 3.628  loss_mask_3: 3.631  loss_mask_4: 3.615  loss_mask_5: 3.631  loss_mask_6: 3.633  loss_mask_7: 3.631  loss_mask_8: 3.631  time: 1.8668  data_time: 0.3937  lr: 8.6516e-05  max_mem: 17484M
[01/27 08:21:47] d2.utils.events INFO:  eta: 1 day, 0:48:59  iter: 8939  total_loss: 34.9  loss_mask: 3.487  loss_mask_0: 3.547  loss_mask_1: 3.482  loss_mask_2: 3.484  loss_mask_3: 3.48  loss_mask_4: 3.472  loss_mask_5: 3.479  loss_mask_6: 3.485  loss_mask_7: 3.48  loss_mask_8: 3.485  time: 1.8665  data_time: 0.4123  lr: 8.6486e-05  max_mem: 17484M
[01/27 08:22:22] d2.utils.events INFO:  eta: 1 day, 0:48:40  iter: 8959  total_loss: 33.14  loss_mask: 3.308  loss_mask_0: 3.425  loss_mask_1: 3.307  loss_mask_2: 3.305  loss_mask_3: 3.31  loss_mask_4: 3.309  loss_mask_5: 3.3  loss_mask_6: 3.298  loss_mask_7: 3.309  loss_mask_8: 3.315  time: 1.8663  data_time: 0.4127  lr: 8.6455e-05  max_mem: 17484M
[01/27 08:22:57] d2.utils.events INFO:  eta: 1 day, 0:48:13  iter: 8979  total_loss: 33.13  loss_mask: 3.307  loss_mask_0: 3.328  loss_mask_1: 3.304  loss_mask_2: 3.308  loss_mask_3: 3.31  loss_mask_4: 3.311  loss_mask_5: 3.314  loss_mask_6: 3.31  loss_mask_7: 3.308  loss_mask_8: 3.307  time: 1.8661  data_time: 0.4151  lr: 8.6425e-05  max_mem: 17484M
[01/27 08:23:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 08:23:33] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 08:23:33] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 08:30:24] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.030800443099343, 'error_1pix': 0.441643883790688, 'error_3pix': 0.18885199714157558, 'mIoU': 6.175570303914435, 'fwIoU': 15.958761601421866, 'IoU-0': nan, 'IoU-1': 58.59090898395283, 'IoU-2': 2.694502896631518, 'IoU-3': 2.679885674282972, 'IoU-4': 2.12916989528936, 'IoU-5': 1.7926232316365536, 'IoU-6': 1.7798703708563095, 'IoU-7': 1.7362545636917768, 'IoU-8': 2.7363427289762687, 'IoU-9': 4.9443800638289765, 'IoU-10': 11.510604348290999, 'IoU-11': 19.814934018089918, 'IoU-12': 18.23455674535074, 'IoU-13': 17.23044387283871, 'IoU-14': 16.684256926907207, 'IoU-15': 15.413440823843432, 'IoU-16': 14.573073467005063, 'IoU-17': 12.842324743556704, 'IoU-18': 13.871023419406598, 'IoU-19': 13.468109724186675, 'IoU-20': 13.65942046619656, 'IoU-21': 14.235552168859634, 'IoU-22': 15.159900921434671, 'IoU-23': 13.95101988271808, 'IoU-24': 14.339310694684787, 'IoU-25': 14.580070055804088, 'IoU-26': 14.13384449981625, 'IoU-27': 15.361838373364211, 'IoU-28': 14.424026174765196, 'IoU-29': 13.854668106350514, 'IoU-30': 13.574036240934891, 'IoU-31': 13.321926735329933, 'IoU-32': 13.057431422734892, 'IoU-33': 12.49669462027026, 'IoU-34': 12.191663369847017, 'IoU-35': 13.236377511198128, 'IoU-36': 13.276365877119245, 'IoU-37': 12.811764948193577, 'IoU-38': 12.975448871770284, 'IoU-39': 12.478503915182038, 'IoU-40': 12.091628952958771, 'IoU-41': 11.27530289807835, 'IoU-42': 10.790414935199458, 'IoU-43': 9.942328078994393, 'IoU-44': 9.906420390119985, 'IoU-45': 9.207772136637915, 'IoU-46': 8.53640246351117, 'IoU-47': 8.52735108632169, 'IoU-48': 8.393139256550082, 'IoU-49': 8.457639037559108, 'IoU-50': 8.222340610476035, 'IoU-51': 8.32255847504859, 'IoU-52': 8.150344336856122, 'IoU-53': 7.885839575274847, 'IoU-54': 7.962785422357029, 'IoU-55': 7.976536883522931, 'IoU-56': 7.714269719900901, 'IoU-57': 7.8340398470977695, 'IoU-58': 7.6629710282507295, 'IoU-59': 7.23715986836986, 'IoU-60': 7.187756976842046, 'IoU-61': 7.061831046519145, 'IoU-62': 6.828217338727836, 'IoU-63': 6.56911248146965, 'IoU-64': 6.792525723360317, 'IoU-65': 6.606422538905641, 'IoU-66': 6.666944252697046, 'IoU-67': 6.860952795231364, 'IoU-68': 6.712468558303936, 'IoU-69': 6.737357362296419, 'IoU-70': 6.94076472263946, 'IoU-71': 6.837311501367588, 'IoU-72': 6.541439014545477, 'IoU-73': 6.4118316895868155, 'IoU-74': 6.651606885139981, 'IoU-75': 6.4868792778949445, 'IoU-76': 6.6360992661463225, 'IoU-77': 6.587817866813397, 'IoU-78': 6.567378694840971, 'IoU-79': 6.446703097033583, 'IoU-80': 6.562750043460371, 'IoU-81': 6.656849059473938, 'IoU-82': 6.700036030621355, 'IoU-83': 6.868307129289096, 'IoU-84': 6.661709353965427, 'IoU-85': 6.624566435064944, 'IoU-86': 6.626814872476193, 'IoU-87': 6.389396387985041, 'IoU-88': 6.448627173116707, 'IoU-89': 6.314864716807003, 'IoU-90': 6.579173635595563, 'IoU-91': 6.326693362266905, 'IoU-92': 6.332106870076719, 'IoU-93': 6.248054010990456, 'IoU-94': 6.064896045124843, 'IoU-95': 6.002012026602406, 'IoU-96': 6.12627553950444, 'IoU-97': 6.019672585075169, 'IoU-98': 5.892359556772969, 'IoU-99': 5.77314517492651, 'IoU-100': 5.761878858857116, 'IoU-101': 5.530906924371806, 'IoU-102': 5.515458118836627, 'IoU-103': 5.385722777827401, 'IoU-104': 5.044397498174528, 'IoU-105': 4.888545940605175, 'IoU-106': 4.641810021583069, 'IoU-107': 4.67896763642886, 'IoU-108': 4.787557186327482, 'IoU-109': 4.821147188432107, 'IoU-110': 4.556675635529383, 'IoU-111': 4.458279292681522, 'IoU-112': 4.25613858326325, 'IoU-113': 4.345254940369776, 'IoU-114': 4.160140746154097, 'IoU-115': 4.023614846021295, 'IoU-116': 3.746402776644265, 'IoU-117': 3.6948198659245515, 'IoU-118': 3.6100855319041574, 'IoU-119': 3.610285454385466, 'IoU-120': 3.580756091352766, 'IoU-121': 3.507624818427864, 'IoU-122': 3.6539367807786225, 'IoU-123': 3.62726616171844, 'IoU-124': 3.516489364912413, 'IoU-125': 3.5170154284193886, 'IoU-126': 3.3575354744179005, 'IoU-127': 3.195597022484051, 'IoU-128': 3.1100205059376913, 'IoU-129': 3.022497938415194, 'IoU-130': 2.904902707934114, 'IoU-131': 2.869594969217166, 'IoU-132': 2.7294239524358153, 'IoU-133': 2.701802812968224, 'IoU-134': 2.6767697987472165, 'IoU-135': 2.6583568685651313, 'IoU-136': 2.815418376868766, 'IoU-137': 2.7229239578021716, 'IoU-138': 2.553828655225198, 'IoU-139': 2.5992854126516023, 'IoU-140': 2.674347061861793, 'IoU-141': 2.5780575875657465, 'IoU-142': 2.535499892083174, 'IoU-143': 2.5886773384558968, 'IoU-144': 2.424596662395372, 'IoU-145': 2.5044290910444107, 'IoU-146': 2.378056502490172, 'IoU-147': 2.4950127811549585, 'IoU-148': 2.183220177801095, 'IoU-149': 2.2496295963211783, 'IoU-150': 2.024355905298907, 'IoU-151': 2.092766414159563, 'IoU-152': 2.122148160190755, 'IoU-153': 1.9436359601349922, 'IoU-154': 1.90686204083139, 'IoU-155': 1.8139031082128738, 'IoU-156': 1.9378944639197593, 'IoU-157': 2.0970442244078695, 'IoU-158': 2.006560712880289, 'IoU-159': 1.7709650248485531, 'IoU-160': 1.8710358983422573, 'IoU-161': 1.7719471216724685, 'IoU-162': 1.9047619047619049, 'IoU-163': 1.872184768507688, 'IoU-164': 1.887807430301938, 'IoU-165': 1.74857672482311, 'IoU-166': 2.0254713930922748, 'IoU-167': 2.081676343937161, 'IoU-168': 1.9678958976459073, 'IoU-169': 1.9391464078290215, 'IoU-170': 1.9128491409388377, 'IoU-171': 1.8036893112973456, 'IoU-172': 1.6920856682884802, 'IoU-173': 1.6301683364695112, 'IoU-174': 1.789570771814594, 'IoU-175': 1.9011625992161514, 'IoU-176': 2.197985753912037, 'IoU-177': 2.269467020615845, 'IoU-178': 2.093358532625815, 'IoU-179': 2.3582072250558532, 'IoU-180': 2.483139355356303, 'IoU-181': 1.4426962288749787, 'IoU-182': 1.4245841848392033, 'IoU-183': 1.3093595571704202, 'IoU-184': 1.03838375034418, 'IoU-185': 0.688231523180944, 'IoU-186': 0.7311857042628549, 'IoU-187': 0.8073802496260903, 'IoU-188': 0.6702462506943159, 'IoU-189': 0.698620273610057, 'IoU-190': 0.7914244627630487, 'IoU-191': 0.5877837821130337, 'IoU-192': 0.03263799400136179, 'mACC': 11.240645018328808, 'pACC': 23.76839147287166, 'ACC-0': nan, 'ACC-1': 59.61166755221994, 'ACC-2': 6.7293426875880105, 'ACC-3': 16.02907907780687, 'ACC-4': 11.197647427980643, 'ACC-5': 9.463372908719894, 'ACC-6': 9.007358964674555, 'ACC-7': 9.025673561810168, 'ACC-8': 6.541823095894031, 'ACC-9': 7.456324048043084, 'ACC-10': 17.092606146146473, 'ACC-11': 28.21725364017837, 'ACC-12': 28.281198714468275, 'ACC-13': 28.26701289141853, 'ACC-14': 28.033057384119637, 'ACC-15': 27.22540036620081, 'ACC-16': 26.422430713185435, 'ACC-17': 24.57464318613858, 'ACC-18': 24.788045399687288, 'ACC-19': 23.86626088095483, 'ACC-20': 24.542604745961114, 'ACC-21': 25.587748721976965, 'ACC-22': 26.07385498179721, 'ACC-23': 25.27516200110238, 'ACC-24': 26.15178731981056, 'ACC-25': 26.374716315037404, 'ACC-26': 25.121804993716612, 'ACC-27': 26.212794428246504, 'ACC-28': 25.133218946057966, 'ACC-29': 23.550883851289036, 'ACC-30': 23.767401536816507, 'ACC-31': 22.984023942346425, 'ACC-32': 23.02519619043618, 'ACC-33': 22.665752736043146, 'ACC-34': 21.909651285907405, 'ACC-35': 23.30367551146622, 'ACC-36': 23.57457455197219, 'ACC-37': 22.974165406327813, 'ACC-38': 23.063241407709477, 'ACC-39': 22.23981347591798, 'ACC-40': 21.26507947740847, 'ACC-41': 20.408459097390494, 'ACC-42': 19.55095202738983, 'ACC-43': 17.978628036800526, 'ACC-44': 17.45353170313421, 'ACC-45': 16.622998189676398, 'ACC-46': 16.025724226904885, 'ACC-47': 16.011163139742322, 'ACC-48': 15.899473525784602, 'ACC-49': 15.936809127641077, 'ACC-50': 15.551541149742192, 'ACC-51': 15.985559954484957, 'ACC-52': 15.684782813195728, 'ACC-53': 15.187754587853028, 'ACC-54': 15.188205472232827, 'ACC-55': 15.213123558442627, 'ACC-56': 14.884453422238758, 'ACC-57': 14.942134037454627, 'ACC-58': 14.643672801153254, 'ACC-59': 14.043119957722261, 'ACC-60': 13.989205154169456, 'ACC-61': 13.825160129706399, 'ACC-62': 13.366197039935562, 'ACC-63': 12.937982445655463, 'ACC-64': 13.244889340724786, 'ACC-65': 12.915321182637804, 'ACC-66': 13.042905016330536, 'ACC-67': 13.550588764560409, 'ACC-68': 13.187809517316682, 'ACC-69': 12.895254431212496, 'ACC-70': 13.092318712698445, 'ACC-71': 13.051010884240483, 'ACC-72': 12.422412817709878, 'ACC-73': 12.076128948995589, 'ACC-74': 12.429524262149974, 'ACC-75': 12.162996224906879, 'ACC-76': 12.266003518658081, 'ACC-77': 12.378166768878897, 'ACC-78': 12.469139417623735, 'ACC-79': 12.27437820312976, 'ACC-80': 12.398389469427466, 'ACC-81': 12.519498247678436, 'ACC-82': 12.582468138422485, 'ACC-83': 12.80669875022802, 'ACC-84': 12.4977472529529, 'ACC-85': 12.460820924022102, 'ACC-86': 12.461296096791925, 'ACC-87': 12.096782876198137, 'ACC-88': 12.253121557036899, 'ACC-89': 12.03750031872119, 'ACC-90': 12.395069312874, 'ACC-91': 11.976537128092444, 'ACC-92': 12.005703885686806, 'ACC-93': 11.857712925228395, 'ACC-94': 11.478061724700828, 'ACC-95': 11.32211515760115, 'ACC-96': 11.68045464438941, 'ACC-97': 11.434130326362919, 'ACC-98': 11.199579578202552, 'ACC-99': 11.087625259659967, 'ACC-100': 11.033498033892148, 'ACC-101': 10.602940139724987, 'ACC-102': 10.61880380607159, 'ACC-103': 10.322730707471427, 'ACC-104': 9.545043161752046, 'ACC-105': 9.230629354591475, 'ACC-106': 8.728930648896286, 'ACC-107': 8.761732569220527, 'ACC-108': 8.866283608872031, 'ACC-109': 8.86893093100755, 'ACC-110': 8.565066776266763, 'ACC-111': 8.441524863602986, 'ACC-112': 8.211564730714382, 'ACC-113': 8.37547530000468, 'ACC-114': 8.086597762315337, 'ACC-115': 7.765474418534722, 'ACC-116': 7.180576364073694, 'ACC-117': 7.03512822594061, 'ACC-118': 6.848688141270699, 'ACC-119': 6.774972904140059, 'ACC-120': 6.685932102734935, 'ACC-121': 6.576454594715635, 'ACC-122': 6.858341117306839, 'ACC-123': 6.867007849305957, 'ACC-124': 6.828774796880935, 'ACC-125': 6.807865881050248, 'ACC-126': 6.537457080665581, 'ACC-127': 6.209991682942556, 'ACC-128': 6.09050471343142, 'ACC-129': 5.832918643112681, 'ACC-130': 5.609800770296381, 'ACC-131': 5.551557007881238, 'ACC-132': 5.212641540415464, 'ACC-133': 5.1348261854702075, 'ACC-134': 5.050650581645842, 'ACC-135': 5.012613305968873, 'ACC-136': 5.251525810659709, 'ACC-137': 5.131211089460754, 'ACC-138': 4.8514163514988455, 'ACC-139': 4.905009456832654, 'ACC-140': 4.978904631042245, 'ACC-141': 4.737030790826373, 'ACC-142': 4.6679609208592385, 'ACC-143': 4.7323411088436655, 'ACC-144': 4.3803249097472925, 'ACC-145': 4.454665314220187, 'ACC-146': 4.20425250371708, 'ACC-147': 4.374644259544523, 'ACC-148': 3.8210124794330316, 'ACC-149': 4.00813736158423, 'ACC-150': 3.6208749344648634, 'ACC-151': 3.724036351505889, 'ACC-152': 3.7135848674893785, 'ACC-153': 3.490124406823137, 'ACC-154': 3.3973372221772125, 'ACC-155': 3.2529664584054894, 'ACC-156': 3.5268459672873758, 'ACC-157': 3.878521272932424, 'ACC-158': 3.663004696956011, 'ACC-159': 3.165572678168904, 'ACC-160': 3.2928687970637056, 'ACC-161': 3.0915269469486337, 'ACC-162': 3.403219639772861, 'ACC-163': 3.364350541845715, 'ACC-164': 3.455334181060589, 'ACC-165': 3.2180140174670404, 'ACC-166': 3.828376964932987, 'ACC-167': 3.9965950941560697, 'ACC-168': 3.7684956436879635, 'ACC-169': 3.664323343499823, 'ACC-170': 3.600199488500127, 'ACC-171': 3.396991718776407, 'ACC-172': 3.157820644382124, 'ACC-173': 3.0160068348017868, 'ACC-174': 3.252197745853881, 'ACC-175': 3.4159647159989275, 'ACC-176': 3.8193127994325637, 'ACC-177': 3.790164951079463, 'ACC-178': 3.338195376872772, 'ACC-179': 3.633241869753698, 'ACC-180': 3.64347354781887, 'ACC-181': 2.110805437669868, 'ACC-182': 1.9873309429750246, 'ACC-183': 1.6830274710781172, 'ACC-184': 1.236959656048761, 'ACC-185': 0.7890248355620473, 'ACC-186': 0.8172559097522722, 'ACC-187': 0.8847739112566931, 'ACC-188': 0.7306083525488039, 'ACC-189': 0.7375146373030385, 'ACC-190': 0.8194100038270589, 'ACC-191': 0.5962272038459528, 'ACC-192': 0.032850487801424466})])
[01/27 08:30:24] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 08:30:24] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 08:30:24] d2.evaluation.testing INFO: copypaste: 3.0308,0.4416,0.1889,6.1756,15.9588,11.2406,23.7684
[01/27 08:30:24] d2.utils.events INFO:  eta: 1 day, 0:47:33  iter: 8999  total_loss: 31.63  loss_mask: 3.153  loss_mask_0: 3.231  loss_mask_1: 3.157  loss_mask_2: 3.152  loss_mask_3: 3.153  loss_mask_4: 3.158  loss_mask_5: 3.16  loss_mask_6: 3.153  loss_mask_7: 3.158  loss_mask_8: 3.154  time: 1.8659  data_time: 0.4209  lr: 8.6394e-05  max_mem: 17484M
[01/27 08:30:59] d2.utils.events INFO:  eta: 1 day, 0:46:36  iter: 9019  total_loss: 33.03  loss_mask: 3.294  loss_mask_0: 3.352  loss_mask_1: 3.299  loss_mask_2: 3.297  loss_mask_3: 3.303  loss_mask_4: 3.295  loss_mask_5: 3.298  loss_mask_6: 3.296  loss_mask_7: 3.295  loss_mask_8: 3.298  time: 1.8656  data_time: 0.3972  lr: 8.6364e-05  max_mem: 17484M
[01/27 08:31:35] d2.utils.events INFO:  eta: 1 day, 0:46:13  iter: 9039  total_loss: 34.32  loss_mask: 3.401  loss_mask_0: 3.74  loss_mask_1: 3.392  loss_mask_2: 3.39  loss_mask_3: 3.392  loss_mask_4: 3.394  loss_mask_5: 3.391  loss_mask_6: 3.392  loss_mask_7: 3.392  loss_mask_8: 3.397  time: 1.8654  data_time: 0.4109  lr: 8.6333e-05  max_mem: 17484M
[01/27 08:32:10] d2.utils.events INFO:  eta: 1 day, 0:45:31  iter: 9059  total_loss: 36.64  loss_mask: 3.672  loss_mask_0: 3.565  loss_mask_1: 3.671  loss_mask_2: 3.669  loss_mask_3: 3.671  loss_mask_4: 3.671  loss_mask_5: 3.691  loss_mask_6: 3.682  loss_mask_7: 3.678  loss_mask_8: 3.665  time: 1.8651  data_time: 0.3924  lr: 8.6303e-05  max_mem: 17484M
[01/27 08:32:45] d2.utils.events INFO:  eta: 1 day, 0:44:47  iter: 9079  total_loss: 35.1  loss_mask: 3.451  loss_mask_0: 4.164  loss_mask_1: 3.459  loss_mask_2: 3.461  loss_mask_3: 3.46  loss_mask_4: 3.453  loss_mask_5: 3.462  loss_mask_6: 3.459  loss_mask_7: 3.451  loss_mask_8: 3.449  time: 1.8649  data_time: 0.4112  lr: 8.6272e-05  max_mem: 17484M
[01/27 08:33:21] d2.utils.events INFO:  eta: 1 day, 0:44:33  iter: 9099  total_loss: 33.17  loss_mask: 3.264  loss_mask_0: 3.582  loss_mask_1: 3.274  loss_mask_2: 3.272  loss_mask_3: 3.347  loss_mask_4: 3.276  loss_mask_5: 3.284  loss_mask_6: 3.282  loss_mask_7: 3.27  loss_mask_8: 3.323  time: 1.8647  data_time: 0.4163  lr: 8.6242e-05  max_mem: 17484M
[01/27 08:33:56] d2.utils.events INFO:  eta: 1 day, 0:44:39  iter: 9119  total_loss: 33.09  loss_mask: 3.298  loss_mask_0: 3.322  loss_mask_1: 3.3  loss_mask_2: 3.297  loss_mask_3: 3.305  loss_mask_4: 3.3  loss_mask_5: 3.292  loss_mask_6: 3.295  loss_mask_7: 3.305  loss_mask_8: 3.316  time: 1.8645  data_time: 0.4260  lr: 8.6211e-05  max_mem: 17484M
[01/27 08:34:31] d2.utils.events INFO:  eta: 1 day, 0:44:15  iter: 9139  total_loss: 32.17  loss_mask: 3.201  loss_mask_0: 3.294  loss_mask_1: 3.212  loss_mask_2: 3.216  loss_mask_3: 3.212  loss_mask_4: 3.21  loss_mask_5: 3.21  loss_mask_6: 3.21  loss_mask_7: 3.212  loss_mask_8: 3.212  time: 1.8643  data_time: 0.4001  lr: 8.6181e-05  max_mem: 17484M
[01/27 08:35:07] d2.utils.events INFO:  eta: 1 day, 0:43:47  iter: 9159  total_loss: 33  loss_mask: 3.303  loss_mask_0: 3.352  loss_mask_1: 3.3  loss_mask_2: 3.296  loss_mask_3: 3.294  loss_mask_4: 3.293  loss_mask_5: 3.295  loss_mask_6: 3.295  loss_mask_7: 3.3  loss_mask_8: 3.3  time: 1.8641  data_time: 0.4260  lr: 8.615e-05  max_mem: 17484M
[01/27 08:35:42] d2.utils.events INFO:  eta: 1 day, 0:42:39  iter: 9179  total_loss: 30.97  loss_mask: 3.095  loss_mask_0: 3.132  loss_mask_1: 3.096  loss_mask_2: 3.093  loss_mask_3: 3.095  loss_mask_4: 3.096  loss_mask_5: 3.096  loss_mask_6: 3.092  loss_mask_7: 3.098  loss_mask_8: 3.097  time: 1.8639  data_time: 0.3964  lr: 8.612e-05  max_mem: 17484M
[01/27 08:36:18] d2.utils.events INFO:  eta: 1 day, 0:43:02  iter: 9199  total_loss: 35.87  loss_mask: 3.587  loss_mask_0: 3.6  loss_mask_1: 3.576  loss_mask_2: 3.576  loss_mask_3: 3.586  loss_mask_4: 3.574  loss_mask_5: 3.579  loss_mask_6: 3.582  loss_mask_7: 3.579  loss_mask_8: 3.592  time: 1.8637  data_time: 0.4125  lr: 8.6089e-05  max_mem: 17484M
[01/27 08:36:53] d2.utils.events INFO:  eta: 1 day, 0:42:37  iter: 9219  total_loss: 35.3  loss_mask: 3.513  loss_mask_0: 3.635  loss_mask_1: 3.522  loss_mask_2: 3.523  loss_mask_3: 3.52  loss_mask_4: 3.517  loss_mask_5: 3.513  loss_mask_6: 3.514  loss_mask_7: 3.507  loss_mask_8: 3.505  time: 1.8635  data_time: 0.4148  lr: 8.6059e-05  max_mem: 17484M
[01/27 08:37:28] d2.utils.events INFO:  eta: 1 day, 0:42:02  iter: 9239  total_loss: 34.11  loss_mask: 3.409  loss_mask_0: 3.469  loss_mask_1: 3.402  loss_mask_2: 3.402  loss_mask_3: 3.408  loss_mask_4: 3.402  loss_mask_5: 3.401  loss_mask_6: 3.404  loss_mask_7: 3.403  loss_mask_8: 3.409  time: 1.8633  data_time: 0.4001  lr: 8.6028e-05  max_mem: 17484M
[01/27 08:38:03] d2.utils.events INFO:  eta: 1 day, 0:41:19  iter: 9259  total_loss: 34.19  loss_mask: 3.413  loss_mask_0: 3.482  loss_mask_1: 3.413  loss_mask_2: 3.412  loss_mask_3: 3.412  loss_mask_4: 3.411  loss_mask_5: 3.411  loss_mask_6: 3.409  loss_mask_7: 3.415  loss_mask_8: 3.415  time: 1.8630  data_time: 0.3974  lr: 8.5998e-05  max_mem: 17484M
[01/27 08:38:38] d2.utils.events INFO:  eta: 1 day, 0:40:51  iter: 9279  total_loss: 34.66  loss_mask: 3.458  loss_mask_0: 3.561  loss_mask_1: 3.454  loss_mask_2: 3.45  loss_mask_3: 3.457  loss_mask_4: 3.451  loss_mask_5: 3.456  loss_mask_6: 3.453  loss_mask_7: 3.456  loss_mask_8: 3.456  time: 1.8628  data_time: 0.3993  lr: 8.5967e-05  max_mem: 17484M
[01/27 08:39:14] d2.utils.events INFO:  eta: 1 day, 0:40:12  iter: 9299  total_loss: 35.01  loss_mask: 3.493  loss_mask_0: 3.589  loss_mask_1: 3.496  loss_mask_2: 3.494  loss_mask_3: 3.492  loss_mask_4: 3.491  loss_mask_5: 3.493  loss_mask_6: 3.493  loss_mask_7: 3.493  loss_mask_8: 3.492  time: 1.8626  data_time: 0.4159  lr: 8.5937e-05  max_mem: 17484M
[01/27 08:39:49] d2.utils.events INFO:  eta: 1 day, 0:39:24  iter: 9319  total_loss: 34.87  loss_mask: 3.482  loss_mask_0: 3.541  loss_mask_1: 3.477  loss_mask_2: 3.479  loss_mask_3: 3.487  loss_mask_4: 3.476  loss_mask_5: 3.477  loss_mask_6: 3.477  loss_mask_7: 3.476  loss_mask_8: 3.478  time: 1.8624  data_time: 0.4242  lr: 8.5906e-05  max_mem: 17484M
[01/27 08:40:24] d2.utils.events INFO:  eta: 1 day, 0:38:57  iter: 9339  total_loss: 32.35  loss_mask: 3.233  loss_mask_0: 3.277  loss_mask_1: 3.228  loss_mask_2: 3.229  loss_mask_3: 3.232  loss_mask_4: 3.232  loss_mask_5: 3.228  loss_mask_6: 3.232  loss_mask_7: 3.231  loss_mask_8: 3.237  time: 1.8622  data_time: 0.4017  lr: 8.5876e-05  max_mem: 17484M
[01/27 08:41:00] d2.utils.events INFO:  eta: 1 day, 0:38:27  iter: 9359  total_loss: 33.47  loss_mask: 3.342  loss_mask_0: 3.427  loss_mask_1: 3.342  loss_mask_2: 3.339  loss_mask_3: 3.339  loss_mask_4: 3.341  loss_mask_5: 3.343  loss_mask_6: 3.341  loss_mask_7: 3.338  loss_mask_8: 3.34  time: 1.8619  data_time: 0.4197  lr: 8.5845e-05  max_mem: 17484M
[01/27 08:41:34] d2.utils.events INFO:  eta: 1 day, 0:37:56  iter: 9379  total_loss: 34.01  loss_mask: 3.394  loss_mask_0: 3.494  loss_mask_1: 3.394  loss_mask_2: 3.393  loss_mask_3: 3.39  loss_mask_4: 3.392  loss_mask_5: 3.392  loss_mask_6: 3.393  loss_mask_7: 3.394  loss_mask_8: 3.395  time: 1.8617  data_time: 0.3850  lr: 8.5815e-05  max_mem: 17484M
[01/27 08:42:10] d2.utils.events INFO:  eta: 1 day, 0:37:24  iter: 9399  total_loss: 37.12  loss_mask: 3.704  loss_mask_0: 3.772  loss_mask_1: 3.702  loss_mask_2: 3.702  loss_mask_3: 3.699  loss_mask_4: 3.696  loss_mask_5: 3.702  loss_mask_6: 3.703  loss_mask_7: 3.697  loss_mask_8: 3.703  time: 1.8615  data_time: 0.3998  lr: 8.5784e-05  max_mem: 17484M
[01/27 08:42:45] d2.utils.events INFO:  eta: 1 day, 0:37:09  iter: 9419  total_loss: 32.49  loss_mask: 3.243  loss_mask_0: 3.321  loss_mask_1: 3.244  loss_mask_2: 3.243  loss_mask_3: 3.245  loss_mask_4: 3.24  loss_mask_5: 3.244  loss_mask_6: 3.242  loss_mask_7: 3.242  loss_mask_8: 3.244  time: 1.8612  data_time: 0.4155  lr: 8.5754e-05  max_mem: 17484M
[01/27 08:43:20] d2.utils.events INFO:  eta: 1 day, 0:36:38  iter: 9439  total_loss: 34.79  loss_mask: 3.477  loss_mask_0: 3.513  loss_mask_1: 3.475  loss_mask_2: 3.474  loss_mask_3: 3.476  loss_mask_4: 3.473  loss_mask_5: 3.479  loss_mask_6: 3.476  loss_mask_7: 3.473  loss_mask_8: 3.473  time: 1.8610  data_time: 0.3978  lr: 8.5723e-05  max_mem: 17484M
[01/27 08:43:55] d2.utils.events INFO:  eta: 1 day, 0:36:03  iter: 9459  total_loss: 33.85  loss_mask: 3.373  loss_mask_0: 3.466  loss_mask_1: 3.376  loss_mask_2: 3.371  loss_mask_3: 3.373  loss_mask_4: 3.372  loss_mask_5: 3.372  loss_mask_6: 3.371  loss_mask_7: 3.372  loss_mask_8: 3.371  time: 1.8608  data_time: 0.4107  lr: 8.5693e-05  max_mem: 17484M
[01/27 08:44:31] d2.utils.events INFO:  eta: 1 day, 0:36:35  iter: 9479  total_loss: 35.17  loss_mask: 3.506  loss_mask_0: 3.612  loss_mask_1: 3.507  loss_mask_2: 3.5  loss_mask_3: 3.501  loss_mask_4: 3.5  loss_mask_5: 3.505  loss_mask_6: 3.495  loss_mask_7: 3.504  loss_mask_8: 3.506  time: 1.8606  data_time: 0.3997  lr: 8.5662e-05  max_mem: 17484M
[01/27 08:45:06] d2.utils.events INFO:  eta: 1 day, 0:36:45  iter: 9499  total_loss: 33.19  loss_mask: 3.312  loss_mask_0: 3.397  loss_mask_1: 3.313  loss_mask_2: 3.308  loss_mask_3: 3.311  loss_mask_4: 3.307  loss_mask_5: 3.31  loss_mask_6: 3.311  loss_mask_7: 3.309  loss_mask_8: 3.314  time: 1.8604  data_time: 0.4155  lr: 8.5632e-05  max_mem: 17484M
[01/27 08:45:42] d2.utils.events INFO:  eta: 1 day, 0:36:32  iter: 9519  total_loss: 34.47  loss_mask: 3.44  loss_mask_0: 3.531  loss_mask_1: 3.438  loss_mask_2: 3.436  loss_mask_3: 3.437  loss_mask_4: 3.433  loss_mask_5: 3.437  loss_mask_6: 3.435  loss_mask_7: 3.433  loss_mask_8: 3.432  time: 1.8602  data_time: 0.4251  lr: 8.5601e-05  max_mem: 17484M
[01/27 08:46:17] d2.utils.events INFO:  eta: 1 day, 0:36:12  iter: 9539  total_loss: 32.98  loss_mask: 3.291  loss_mask_0: 3.371  loss_mask_1: 3.287  loss_mask_2: 3.285  loss_mask_3: 3.287  loss_mask_4: 3.286  loss_mask_5: 3.29  loss_mask_6: 3.285  loss_mask_7: 3.285  loss_mask_8: 3.284  time: 1.8601  data_time: 0.4224  lr: 8.5571e-05  max_mem: 17484M
[01/27 08:46:53] d2.utils.events INFO:  eta: 1 day, 0:35:22  iter: 9559  total_loss: 32.54  loss_mask: 3.249  loss_mask_0: 3.327  loss_mask_1: 3.244  loss_mask_2: 3.245  loss_mask_3: 3.244  loss_mask_4: 3.245  loss_mask_5: 3.247  loss_mask_6: 3.245  loss_mask_7: 3.245  loss_mask_8: 3.247  time: 1.8599  data_time: 0.4222  lr: 8.554e-05  max_mem: 17484M
[01/27 08:47:28] d2.utils.events INFO:  eta: 1 day, 0:34:25  iter: 9579  total_loss: 31.87  loss_mask: 3.18  loss_mask_0: 3.239  loss_mask_1: 3.184  loss_mask_2: 3.181  loss_mask_3: 3.179  loss_mask_4: 3.184  loss_mask_5: 3.184  loss_mask_6: 3.182  loss_mask_7: 3.183  loss_mask_8: 3.186  time: 1.8596  data_time: 0.4058  lr: 8.5509e-05  max_mem: 17484M
[01/27 08:48:03] d2.utils.events INFO:  eta: 1 day, 0:33:47  iter: 9599  total_loss: 32.04  loss_mask: 3.199  loss_mask_0: 3.263  loss_mask_1: 3.195  loss_mask_2: 3.192  loss_mask_3: 3.192  loss_mask_4: 3.191  loss_mask_5: 3.195  loss_mask_6: 3.194  loss_mask_7: 3.194  loss_mask_8: 3.192  time: 1.8594  data_time: 0.4032  lr: 8.5479e-05  max_mem: 17484M
[01/27 08:48:39] d2.utils.events INFO:  eta: 1 day, 0:34:02  iter: 9619  total_loss: 34.11  loss_mask: 3.401  loss_mask_0: 3.505  loss_mask_1: 3.403  loss_mask_2: 3.401  loss_mask_3: 3.395  loss_mask_4: 3.403  loss_mask_5: 3.401  loss_mask_6: 3.401  loss_mask_7: 3.398  loss_mask_8: 3.402  time: 1.8593  data_time: 0.4300  lr: 8.5448e-05  max_mem: 17484M
[01/27 08:49:14] d2.utils.events INFO:  eta: 1 day, 0:33:32  iter: 9639  total_loss: 33.64  loss_mask: 3.363  loss_mask_0: 3.403  loss_mask_1: 3.356  loss_mask_2: 3.358  loss_mask_3: 3.358  loss_mask_4: 3.359  loss_mask_5: 3.363  loss_mask_6: 3.359  loss_mask_7: 3.359  loss_mask_8: 3.361  time: 1.8591  data_time: 0.3812  lr: 8.5418e-05  max_mem: 17484M
[01/27 08:49:49] d2.utils.events INFO:  eta: 1 day, 0:32:57  iter: 9659  total_loss: 31.65  loss_mask: 3.157  loss_mask_0: 3.254  loss_mask_1: 3.155  loss_mask_2: 3.156  loss_mask_3: 3.154  loss_mask_4: 3.154  loss_mask_5: 3.155  loss_mask_6: 3.156  loss_mask_7: 3.156  loss_mask_8: 3.154  time: 1.8589  data_time: 0.4111  lr: 8.5387e-05  max_mem: 17484M
[01/27 08:50:24] d2.utils.events INFO:  eta: 1 day, 0:32:44  iter: 9679  total_loss: 31.51  loss_mask: 3.146  loss_mask_0: 3.254  loss_mask_1: 3.141  loss_mask_2: 3.139  loss_mask_3: 3.137  loss_mask_4: 3.141  loss_mask_5: 3.143  loss_mask_6: 3.139  loss_mask_7: 3.141  loss_mask_8: 3.138  time: 1.8587  data_time: 0.3945  lr: 8.5357e-05  max_mem: 17484M
[01/27 08:51:00] d2.utils.events INFO:  eta: 1 day, 0:33:01  iter: 9699  total_loss: 33  loss_mask: 3.287  loss_mask_0: 3.413  loss_mask_1: 3.287  loss_mask_2: 3.285  loss_mask_3: 3.286  loss_mask_4: 3.286  loss_mask_5: 3.288  loss_mask_6: 3.286  loss_mask_7: 3.285  loss_mask_8: 3.287  time: 1.8585  data_time: 0.4250  lr: 8.5326e-05  max_mem: 17484M
[01/27 08:51:35] d2.utils.events INFO:  eta: 1 day, 0:31:34  iter: 9719  total_loss: 32.98  loss_mask: 3.284  loss_mask_0: 3.315  loss_mask_1: 3.285  loss_mask_2: 3.284  loss_mask_3: 3.28  loss_mask_4: 3.285  loss_mask_5: 3.284  loss_mask_6: 3.286  loss_mask_7: 3.283  loss_mask_8: 3.283  time: 1.8583  data_time: 0.3813  lr: 8.5296e-05  max_mem: 17484M
[01/27 08:52:11] d2.utils.events INFO:  eta: 1 day, 0:32:01  iter: 9739  total_loss: 34.8  loss_mask: 3.479  loss_mask_0: 3.488  loss_mask_1: 3.48  loss_mask_2: 3.49  loss_mask_3: 3.485  loss_mask_4: 3.475  loss_mask_5: 3.483  loss_mask_6: 3.474  loss_mask_7: 3.472  loss_mask_8: 3.48  time: 1.8581  data_time: 0.4209  lr: 8.5265e-05  max_mem: 17484M
[01/27 08:52:46] d2.utils.events INFO:  eta: 1 day, 0:31:41  iter: 9759  total_loss: 36.1  loss_mask: 3.605  loss_mask_0: 3.642  loss_mask_1: 3.596  loss_mask_2: 3.602  loss_mask_3: 3.616  loss_mask_4: 3.606  loss_mask_5: 3.597  loss_mask_6: 3.609  loss_mask_7: 3.627  loss_mask_8: 3.597  time: 1.8580  data_time: 0.4141  lr: 8.5235e-05  max_mem: 17484M
[01/27 08:53:22] d2.utils.events INFO:  eta: 1 day, 0:31:40  iter: 9779  total_loss: 35.72  loss_mask: 3.584  loss_mask_0: 3.634  loss_mask_1: 3.562  loss_mask_2: 3.561  loss_mask_3: 3.569  loss_mask_4: 3.557  loss_mask_5: 3.565  loss_mask_6: 3.565  loss_mask_7: 3.566  loss_mask_8: 3.562  time: 1.8578  data_time: 0.4092  lr: 8.5204e-05  max_mem: 17484M
[01/27 08:53:57] d2.utils.events INFO:  eta: 1 day, 0:30:58  iter: 9799  total_loss: 35.74  loss_mask: 3.566  loss_mask_0: 3.615  loss_mask_1: 3.572  loss_mask_2: 3.569  loss_mask_3: 3.566  loss_mask_4: 3.57  loss_mask_5: 3.569  loss_mask_6: 3.564  loss_mask_7: 3.567  loss_mask_8: 3.573  time: 1.8576  data_time: 0.3812  lr: 8.5174e-05  max_mem: 17484M
[01/27 08:54:33] d2.utils.events INFO:  eta: 1 day, 0:30:44  iter: 9819  total_loss: 34.22  loss_mask: 3.422  loss_mask_0: 3.51  loss_mask_1: 3.417  loss_mask_2: 3.42  loss_mask_3: 3.426  loss_mask_4: 3.42  loss_mask_5: 3.419  loss_mask_6: 3.42  loss_mask_7: 3.414  loss_mask_8: 3.413  time: 1.8574  data_time: 0.4167  lr: 8.5143e-05  max_mem: 17484M
[01/27 08:55:08] d2.utils.events INFO:  eta: 1 day, 0:30:04  iter: 9839  total_loss: 34.81  loss_mask: 3.48  loss_mask_0: 3.491  loss_mask_1: 3.482  loss_mask_2: 3.482  loss_mask_3: 3.482  loss_mask_4: 3.48  loss_mask_5: 3.485  loss_mask_6: 3.479  loss_mask_7: 3.473  loss_mask_8: 3.48  time: 1.8572  data_time: 0.3897  lr: 8.5113e-05  max_mem: 17484M
[01/27 08:55:43] d2.utils.events INFO:  eta: 1 day, 0:29:22  iter: 9859  total_loss: 33.77  loss_mask: 3.383  loss_mask_0: 3.406  loss_mask_1: 3.363  loss_mask_2: 3.359  loss_mask_3: 3.368  loss_mask_4: 3.375  loss_mask_5: 3.374  loss_mask_6: 3.367  loss_mask_7: 3.37  loss_mask_8: 3.372  time: 1.8570  data_time: 0.3792  lr: 8.5082e-05  max_mem: 17484M
[01/27 08:56:18] d2.utils.events INFO:  eta: 1 day, 0:29:06  iter: 9879  total_loss: 36.89  loss_mask: 3.685  loss_mask_0: 3.768  loss_mask_1: 3.677  loss_mask_2: 3.673  loss_mask_3: 3.68  loss_mask_4: 3.711  loss_mask_5: 3.689  loss_mask_6: 3.683  loss_mask_7: 3.682  loss_mask_8: 3.678  time: 1.8568  data_time: 0.4184  lr: 8.5051e-05  max_mem: 17484M
[01/27 08:56:53] d2.utils.events INFO:  eta: 1 day, 0:28:12  iter: 9899  total_loss: 31.81  loss_mask: 3.174  loss_mask_0: 3.232  loss_mask_1: 3.174  loss_mask_2: 3.179  loss_mask_3: 3.168  loss_mask_4: 3.176  loss_mask_5: 3.177  loss_mask_6: 3.173  loss_mask_7: 3.176  loss_mask_8: 3.187  time: 1.8566  data_time: 0.3779  lr: 8.5021e-05  max_mem: 17484M
[01/27 08:57:29] d2.utils.events INFO:  eta: 1 day, 0:28:54  iter: 9919  total_loss: 31.48  loss_mask: 3.151  loss_mask_0: 3.163  loss_mask_1: 3.146  loss_mask_2: 3.144  loss_mask_3: 3.146  loss_mask_4: 3.145  loss_mask_5: 3.147  loss_mask_6: 3.143  loss_mask_7: 3.144  loss_mask_8: 3.146  time: 1.8564  data_time: 0.4001  lr: 8.499e-05  max_mem: 17484M
[01/27 08:58:04] d2.utils.events INFO:  eta: 1 day, 0:28:33  iter: 9939  total_loss: 31.16  loss_mask: 3.116  loss_mask_0: 3.108  loss_mask_1: 3.113  loss_mask_2: 3.114  loss_mask_3: 3.113  loss_mask_4: 3.12  loss_mask_5: 3.121  loss_mask_6: 3.116  loss_mask_7: 3.117  loss_mask_8: 3.118  time: 1.8563  data_time: 0.4018  lr: 8.496e-05  max_mem: 17484M
[01/27 08:58:40] d2.utils.events INFO:  eta: 1 day, 0:27:58  iter: 9959  total_loss: 33.64  loss_mask: 3.36  loss_mask_0: 3.376  loss_mask_1: 3.356  loss_mask_2: 3.357  loss_mask_3: 3.36  loss_mask_4: 3.358  loss_mask_5: 3.358  loss_mask_6: 3.358  loss_mask_7: 3.356  loss_mask_8: 3.358  time: 1.8561  data_time: 0.4175  lr: 8.4929e-05  max_mem: 17484M
[01/27 08:59:15] d2.utils.events INFO:  eta: 1 day, 0:26:38  iter: 9979  total_loss: 36.61  loss_mask: 3.651  loss_mask_0: 3.669  loss_mask_1: 3.654  loss_mask_2: 3.654  loss_mask_3: 3.656  loss_mask_4: 3.659  loss_mask_5: 3.659  loss_mask_6: 3.652  loss_mask_7: 3.658  loss_mask_8: 3.652  time: 1.8559  data_time: 0.4116  lr: 8.4899e-05  max_mem: 17484M
[01/27 08:59:50] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE/model_0009999.pth
[01/27 08:59:50] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 08:59:51] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 08:59:51] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 09:06:36] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.4572580925886216, 'error_1pix': 0.48928299656790025, 'error_3pix': 0.22627516093680505, 'mIoU': 4.615003732922451, 'fwIoU': 12.154870285204618, 'IoU-0': nan, 'IoU-1': 36.872364833327566, 'IoU-2': 2.6200473271902003, 'IoU-3': 2.399202188536401, 'IoU-4': 2.2363367410771935, 'IoU-5': 2.4592081219702506, 'IoU-6': 2.526182550923045, 'IoU-7': 1.8220391067810884, 'IoU-8': 4.473638451566885, 'IoU-9': 10.565708859192151, 'IoU-10': 11.834117375013648, 'IoU-11': 13.493465321873435, 'IoU-12': 11.158700359717605, 'IoU-13': 9.679232992107197, 'IoU-14': 8.587278579112596, 'IoU-15': 8.603228083852517, 'IoU-16': 8.389698892217492, 'IoU-17': 8.138453089287326, 'IoU-18': 8.980942582591918, 'IoU-19': 8.904378667250024, 'IoU-20': 11.129022188783935, 'IoU-21': 12.556919669000102, 'IoU-22': 13.856715971676062, 'IoU-23': 13.575786356916788, 'IoU-24': 14.22387931719619, 'IoU-25': 13.648858861798724, 'IoU-26': 13.219567843949312, 'IoU-27': 14.11540564910389, 'IoU-28': 13.856604691304844, 'IoU-29': 14.628653897792738, 'IoU-30': 14.749626094968345, 'IoU-31': 15.361162764248155, 'IoU-32': 15.74422781127088, 'IoU-33': 15.000821196242223, 'IoU-34': 14.659787683547654, 'IoU-35': 14.868548781939541, 'IoU-36': 14.31242209969665, 'IoU-37': 12.884990500384738, 'IoU-38': 12.611812653798749, 'IoU-39': 11.787807912904547, 'IoU-40': 11.582508642329097, 'IoU-41': 10.93649160277262, 'IoU-42': 10.517049355700841, 'IoU-43': 10.515877746479957, 'IoU-44': 10.653596233232076, 'IoU-45': 10.397561197188754, 'IoU-46': 9.829940706620278, 'IoU-47': 9.385495632851875, 'IoU-48': 9.154672413412184, 'IoU-49': 8.403779656556642, 'IoU-50': 8.352557823558568, 'IoU-51': 7.521395918272391, 'IoU-52': 6.8680419580761685, 'IoU-53': 6.511251794591373, 'IoU-54': 6.648923849036446, 'IoU-55': 6.088735704124145, 'IoU-56': 5.603389789580318, 'IoU-57': 5.651445427893898, 'IoU-58': 5.273473595375591, 'IoU-59': 5.114236684930294, 'IoU-60': 4.87433373346934, 'IoU-61': 4.639921174826024, 'IoU-62': 4.773903982810619, 'IoU-63': 4.513477640549322, 'IoU-64': 4.286201321537977, 'IoU-65': 4.24429945586089, 'IoU-66': 4.067509767007426, 'IoU-67': 3.903265359974608, 'IoU-68': 3.950823234665135, 'IoU-69': 3.9319313191270173, 'IoU-70': 3.9624990910257987, 'IoU-71': 3.851825751833344, 'IoU-72': 3.9211931095472856, 'IoU-73': 3.9893945268057673, 'IoU-74': 3.945949745476338, 'IoU-75': 3.8087836372628447, 'IoU-76': 3.7358937966742602, 'IoU-77': 3.6080673258971387, 'IoU-78': 3.504992792324013, 'IoU-79': 3.498376446613003, 'IoU-80': 3.471463541856317, 'IoU-81': 3.445201520713862, 'IoU-82': 3.36220438347285, 'IoU-83': 3.3965095736845092, 'IoU-84': 3.380960634259035, 'IoU-85': 3.3346710089201514, 'IoU-86': 3.2571676034749633, 'IoU-87': 3.0657481536486295, 'IoU-88': 3.068234178255492, 'IoU-89': 3.031229768551186, 'IoU-90': 2.906727689726357, 'IoU-91': 2.712456762021537, 'IoU-92': 2.637333570777595, 'IoU-93': 2.732614391203115, 'IoU-94': 2.6193343333472776, 'IoU-95': 2.6366028432748116, 'IoU-96': 2.6585895445363725, 'IoU-97': 2.441947110589718, 'IoU-98': 2.3415572531499564, 'IoU-99': 2.306181546617085, 'IoU-100': 2.124312315542022, 'IoU-101': 2.0766632698457363, 'IoU-102': 2.1418514035333427, 'IoU-103': 1.892471177668515, 'IoU-104': 1.969105675311009, 'IoU-105': 1.9764627115243498, 'IoU-106': 2.082833438077911, 'IoU-107': 2.0935637389372217, 'IoU-108': 2.118739067568519, 'IoU-109': 2.116354970729938, 'IoU-110': 2.0316489231574377, 'IoU-111': 1.9762731746578048, 'IoU-112': 1.9046740050927717, 'IoU-113': 1.891542160275418, 'IoU-114': 1.871646784605523, 'IoU-115': 1.7697464576370128, 'IoU-116': 1.843114036152307, 'IoU-117': 2.002146549134402, 'IoU-118': 1.8428435059874535, 'IoU-119': 1.8701949236667723, 'IoU-120': 1.901220316417114, 'IoU-121': 1.894684951562969, 'IoU-122': 1.7241256966818144, 'IoU-123': 1.7065078828951525, 'IoU-124': 1.8980732211555849, 'IoU-125': 1.7334348391985714, 'IoU-126': 1.8504643922855335, 'IoU-127': 1.767172648711721, 'IoU-128': 1.7941403074890814, 'IoU-129': 1.726418984208853, 'IoU-130': 1.9009764698957592, 'IoU-131': 1.7612692445730396, 'IoU-132': 1.789958679196987, 'IoU-133': 1.8920879996215594, 'IoU-134': 1.8171643816412273, 'IoU-135': 1.8277485573394217, 'IoU-136': 1.9268314432394473, 'IoU-137': 1.8114210188796713, 'IoU-138': 1.6351621033246388, 'IoU-139': 1.7761954743686328, 'IoU-140': 1.856605178811294, 'IoU-141': 1.8685508553732237, 'IoU-142': 1.9010411154717213, 'IoU-143': 1.8401238673903444, 'IoU-144': 1.9042418245539796, 'IoU-145': 1.997480208987606, 'IoU-146': 2.012221233893108, 'IoU-147': 2.018918333453679, 'IoU-148': 2.230218172397998, 'IoU-149': 2.0176004732493737, 'IoU-150': 1.8999232158621409, 'IoU-151': 2.0608146873207116, 'IoU-152': 1.9314987991210588, 'IoU-153': 1.55749658797598, 'IoU-154': 1.6103404255615832, 'IoU-155': 1.6401387613508827, 'IoU-156': 1.6571353417898331, 'IoU-157': 1.6603242270762855, 'IoU-158': 1.5960021041557075, 'IoU-159': 1.4741433590959065, 'IoU-160': 1.6096007885496564, 'IoU-161': 1.543470833522, 'IoU-162': 1.8098309056852298, 'IoU-163': 2.0482289312336537, 'IoU-164': 1.781138903653021, 'IoU-165': 1.3960569964359082, 'IoU-166': 1.3383753633806812, 'IoU-167': 1.4547521121149272, 'IoU-168': 1.434121928844528, 'IoU-169': 1.283170888601184, 'IoU-170': 1.5403559507786162, 'IoU-171': 1.6807484538042938, 'IoU-172': 1.5550632208432953, 'IoU-173': 1.6518948205294308, 'IoU-174': 1.4746229429260733, 'IoU-175': 1.2224213004437592, 'IoU-176': 1.139882360895139, 'IoU-177': 1.1185630577815817, 'IoU-178': 1.2392085716327172, 'IoU-179': 0.7464643141629497, 'IoU-180': 0.7500344634940904, 'IoU-181': 0.44074446993367034, 'IoU-182': 0.4114262848823721, 'IoU-183': 0.3291459733177524, 'IoU-184': 0.3617287473386159, 'IoU-185': 0.2989412133418954, 'IoU-186': 0.21028627608949457, 'IoU-187': 0.18777904743953727, 'IoU-188': 0.18051835970632385, 'IoU-189': 0.1602418286777269, 'IoU-190': 0.20991337849651476, 'IoU-191': 0.16670376947250162, 'IoU-192': 0.08756789327416635, 'mACC': 8.66547231713201, 'pACC': 19.040752860262142, 'ACC-0': nan, 'ACC-1': 37.35148300974414, 'ACC-2': 5.863733921450294, 'ACC-3': 13.745317746232821, 'ACC-4': 11.634530672341588, 'ACC-5': 13.240578685474313, 'ACC-6': 15.309819828675991, 'ACC-7': 14.593201118683249, 'ACC-8': 20.154969036173878, 'ACC-9': 30.70514709379867, 'ACC-10': 33.98170394909922, 'ACC-11': 27.976658769577252, 'ACC-12': 20.842085921843644, 'ACC-13': 17.03167714658006, 'ACC-14': 14.786666572464128, 'ACC-15': 14.982589351349135, 'ACC-16': 14.57622269256405, 'ACC-17': 15.019043355218386, 'ACC-18': 15.498104615437883, 'ACC-19': 15.18453653114534, 'ACC-20': 19.233777579506622, 'ACC-21': 21.50037970444711, 'ACC-22': 22.580001469711537, 'ACC-23': 23.104007079025422, 'ACC-24': 24.749238233445563, 'ACC-25': 24.031339856876887, 'ACC-26': 23.434715476142507, 'ACC-27': 24.071316617734503, 'ACC-28': 23.888347359977633, 'ACC-29': 24.674606794420786, 'ACC-30': 25.686457838975052, 'ACC-31': 26.323984935976853, 'ACC-32': 27.460613983937932, 'ACC-33': 26.85441511929797, 'ACC-34': 26.784775918804776, 'ACC-35': 27.214273370980685, 'ACC-36': 26.01575860503424, 'ACC-37': 23.8552809427582, 'ACC-38': 23.022605778069863, 'ACC-39': 21.410068022342926, 'ACC-40': 20.79469851386454, 'ACC-41': 20.270151620494254, 'ACC-42': 19.535956046291556, 'ACC-43': 19.49413165354473, 'ACC-44': 19.294828755199124, 'ACC-45': 19.03416713818985, 'ACC-46': 18.573998818932473, 'ACC-47': 17.901493824603953, 'ACC-48': 17.57990061562675, 'ACC-49': 16.131627386028775, 'ACC-50': 15.993669987711264, 'ACC-51': 14.56424052503991, 'ACC-52': 13.206894497321095, 'ACC-53': 12.457247742567075, 'ACC-54': 12.565696191413428, 'ACC-55': 11.517866642428915, 'ACC-56': 10.651091688232064, 'ACC-57': 10.4557709883247, 'ACC-58': 9.789591626222165, 'ACC-59': 9.557126096571396, 'ACC-60': 9.216208561422919, 'ACC-61': 8.800806791956921, 'ACC-62': 9.049004117003372, 'ACC-63': 8.65721106384109, 'ACC-64': 8.182170801006341, 'ACC-65': 8.164946903560882, 'ACC-66': 7.855767159124312, 'ACC-67': 7.615543206644966, 'ACC-68': 7.697425784612139, 'ACC-69': 7.480543190214552, 'ACC-70': 7.478928553425124, 'ACC-71': 7.434493609650329, 'ACC-72': 7.622509125152457, 'ACC-73': 7.7895524954156095, 'ACC-74': 7.649815305338493, 'ACC-75': 7.380541835610364, 'ACC-76': 7.090799255600051, 'ACC-77': 6.937401358283743, 'ACC-78': 6.83186575721537, 'ACC-79': 6.799242114145558, 'ACC-80': 6.683805821171658, 'ACC-81': 6.603986406904247, 'ACC-82': 6.447630720958131, 'ACC-83': 6.433187732684376, 'ACC-84': 6.382887265789446, 'ACC-85': 6.280467792728049, 'ACC-86': 6.134435994111184, 'ACC-87': 5.778556390447583, 'ACC-88': 5.724565968272769, 'ACC-89': 5.6044062067283935, 'ACC-90': 5.314195435000553, 'ACC-91': 4.971776352118345, 'ACC-92': 4.8688505871182794, 'ACC-93': 5.030840858107892, 'ACC-94': 4.798264084018771, 'ACC-95': 4.791229235462069, 'ACC-96': 4.850230704450006, 'ACC-97': 4.4330179842621655, 'ACC-98': 4.2208990866730005, 'ACC-99': 4.163777270563951, 'ACC-100': 3.8410059790114235, 'ACC-101': 3.7563341363307314, 'ACC-102': 3.8804485727231537, 'ACC-103': 3.4368801360158683, 'ACC-104': 3.6006492708000297, 'ACC-105': 3.627918522833696, 'ACC-106': 3.753418414453564, 'ACC-107': 3.7576585338259165, 'ACC-108': 3.784351598083919, 'ACC-109': 3.763917769811604, 'ACC-110': 3.6632583286186278, 'ACC-111': 3.582897638614539, 'ACC-112': 3.491033600059792, 'ACC-113': 3.434297197528873, 'ACC-114': 3.4083127641903395, 'ACC-115': 3.2099739900470583, 'ACC-116': 3.342524890306576, 'ACC-117': 3.5912585678844873, 'ACC-118': 3.3111684651742017, 'ACC-119': 3.3154095345688273, 'ACC-120': 3.34948889052875, 'ACC-121': 3.376275817838353, 'ACC-122': 3.094860690462038, 'ACC-123': 3.0912686586311775, 'ACC-124': 3.522559521304394, 'ACC-125': 3.2246240059693503, 'ACC-126': 3.4247238135137845, 'ACC-127': 3.221574820809465, 'ACC-128': 3.2534812554351733, 'ACC-129': 3.0977830127406643, 'ACC-130': 3.3950696904110225, 'ACC-131': 3.1635268652560318, 'ACC-132': 3.2150744102971385, 'ACC-133': 3.3747031646560113, 'ACC-134': 3.2078586816027572, 'ACC-135': 3.2118322786614217, 'ACC-136': 3.41334618430861, 'ACC-137': 3.251064518320248, 'ACC-138': 2.9467662512374035, 'ACC-139': 3.214503264185454, 'ACC-140': 3.353062100061787, 'ACC-141': 3.3451796172104658, 'ACC-142': 3.3728363579201086, 'ACC-143': 3.253981661532711, 'ACC-144': 3.3139891696750903, 'ACC-145': 3.38791117869362, 'ACC-146': 3.3965867812021653, 'ACC-147': 3.3749836348391757, 'ACC-148': 3.7069495680342492, 'ACC-149': 3.382731599374079, 'ACC-150': 3.1696695663775296, 'ACC-151': 3.4454423665354694, 'ACC-152': 3.1861402163009664, 'ACC-153': 2.630611606892358, 'ACC-154': 2.7119818238391855, 'ACC-155': 2.7738780923409907, 'ACC-156': 2.8342938698893123, 'ACC-157': 2.8889917247386756, 'ACC-158': 2.7833369558160608, 'ACC-159': 2.5623431674156825, 'ACC-160': 2.7797885997703893, 'ACC-161': 2.6326247189812126, 'ACC-162': 3.147947585780084, 'ACC-163': 3.578356811459058, 'ACC-164': 3.1401069586545973, 'ACC-165': 2.443610813764012, 'ACC-166': 2.37676322354703, 'ACC-167': 2.5880534009676106, 'ACC-168': 2.5233370433473823, 'ACC-169': 2.212313286163522, 'ACC-170': 2.6242135434691938, 'ACC-171': 2.7926115749543046, 'ACC-172': 2.4636636925875233, 'ACC-173': 2.533446232006774, 'ACC-174': 2.192217998929989, 'ACC-175': 1.7359178563966207, 'ACC-176': 1.5292849912379045, 'ACC-177': 1.4279939978848635, 'ACC-178': 1.5412047205914456, 'ACC-179': 0.9070340797256576, 'ACC-180': 0.8752749125254274, 'ACC-181': 0.5028970470491811, 'ACC-182': 0.4579874142310171, 'ACC-183': 0.35813852732307344, 'ACC-184': 0.3887003304424532, 'ACC-185': 0.31514546597168314, 'ACC-186': 0.2182890297950351, 'ACC-187': 0.19274439481403915, 'ACC-188': 0.184301082327041, 'ACC-189': 0.16295687040559298, 'ACC-190': 0.21348075919422815, 'ACC-191': 0.16821868428957645, 'ACC-192': 0.08808052429153237})])
[01/27 09:06:36] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 09:06:36] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 09:06:36] d2.evaluation.testing INFO: copypaste: 3.4573,0.4893,0.2263,4.6150,12.1549,8.6655,19.0408
[01/27 09:06:36] d2.utils.events INFO:  eta: 1 day, 0:25:14  iter: 9999  total_loss: 35  loss_mask: 3.505  loss_mask_0: 3.494  loss_mask_1: 3.497  loss_mask_2: 3.5  loss_mask_3: 3.504  loss_mask_4: 3.507  loss_mask_5: 3.501  loss_mask_6: 3.502  loss_mask_7: 3.493  loss_mask_8: 3.497  time: 1.8557  data_time: 0.3975  lr: 8.4868e-05  max_mem: 17484M
[01/27 09:07:12] d2.utils.events INFO:  eta: 1 day, 0:24:41  iter: 10019  total_loss: 34.19  loss_mask: 3.415  loss_mask_0: 3.477  loss_mask_1: 3.41  loss_mask_2: 3.411  loss_mask_3: 3.41  loss_mask_4: 3.411  loss_mask_5: 3.416  loss_mask_6: 3.407  loss_mask_7: 3.417  loss_mask_8: 3.413  time: 1.8555  data_time: 0.3928  lr: 8.4838e-05  max_mem: 17484M
[01/27 09:07:47] d2.utils.events INFO:  eta: 1 day, 0:24:17  iter: 10039  total_loss: 36.86  loss_mask: 3.676  loss_mask_0: 3.741  loss_mask_1: 3.669  loss_mask_2: 3.673  loss_mask_3: 3.674  loss_mask_4: 3.669  loss_mask_5: 3.667  loss_mask_6: 3.671  loss_mask_7: 3.666  loss_mask_8: 3.681  time: 1.8553  data_time: 0.4224  lr: 8.4807e-05  max_mem: 17484M
[01/27 09:08:23] d2.utils.events INFO:  eta: 1 day, 0:23:50  iter: 10059  total_loss: 33.28  loss_mask: 3.319  loss_mask_0: 3.333  loss_mask_1: 3.322  loss_mask_2: 3.322  loss_mask_3: 3.325  loss_mask_4: 3.321  loss_mask_5: 3.323  loss_mask_6: 3.322  loss_mask_7: 3.327  loss_mask_8: 3.326  time: 1.8552  data_time: 0.3955  lr: 8.4776e-05  max_mem: 17484M
[01/27 09:08:57] d2.utils.events INFO:  eta: 1 day, 0:23:14  iter: 10079  total_loss: 36.21  loss_mask: 3.613  loss_mask_0: 3.756  loss_mask_1: 3.622  loss_mask_2: 3.622  loss_mask_3: 3.613  loss_mask_4: 3.626  loss_mask_5: 3.627  loss_mask_6: 3.622  loss_mask_7: 3.61  loss_mask_8: 3.617  time: 1.8549  data_time: 0.3760  lr: 8.4746e-05  max_mem: 17484M
[01/27 09:09:33] d2.utils.events INFO:  eta: 1 day, 0:22:11  iter: 10099  total_loss: 31.72  loss_mask: 3.171  loss_mask_0: 3.161  loss_mask_1: 3.176  loss_mask_2: 3.169  loss_mask_3: 3.172  loss_mask_4: 3.177  loss_mask_5: 3.173  loss_mask_6: 3.168  loss_mask_7: 3.18  loss_mask_8: 3.175  time: 1.8547  data_time: 0.3932  lr: 8.4715e-05  max_mem: 17484M
[01/27 09:10:08] d2.utils.events INFO:  eta: 1 day, 0:22:04  iter: 10119  total_loss: 32.52  loss_mask: 3.248  loss_mask_0: 3.299  loss_mask_1: 3.242  loss_mask_2: 3.242  loss_mask_3: 3.244  loss_mask_4: 3.245  loss_mask_5: 3.25  loss_mask_6: 3.244  loss_mask_7: 3.243  loss_mask_8: 3.246  time: 1.8546  data_time: 0.4256  lr: 8.4685e-05  max_mem: 17484M
[01/27 09:10:44] d2.utils.events INFO:  eta: 1 day, 0:21:00  iter: 10139  total_loss: 31.02  loss_mask: 3.098  loss_mask_0: 3.157  loss_mask_1: 3.094  loss_mask_2: 3.094  loss_mask_3: 3.096  loss_mask_4: 3.095  loss_mask_5: 3.097  loss_mask_6: 3.096  loss_mask_7: 3.092  loss_mask_8: 3.097  time: 1.8544  data_time: 0.4027  lr: 8.4654e-05  max_mem: 17484M
[01/27 09:11:19] d2.utils.events INFO:  eta: 1 day, 0:20:05  iter: 10159  total_loss: 29.3  loss_mask: 2.926  loss_mask_0: 2.968  loss_mask_1: 2.925  loss_mask_2: 2.928  loss_mask_3: 2.928  loss_mask_4: 2.923  loss_mask_5: 2.927  loss_mask_6: 2.923  loss_mask_7: 2.927  loss_mask_8: 2.928  time: 1.8542  data_time: 0.4033  lr: 8.4624e-05  max_mem: 17484M
[01/27 09:11:54] d2.utils.events INFO:  eta: 1 day, 0:19:23  iter: 10179  total_loss: 32.83  loss_mask: 3.278  loss_mask_0: 3.305  loss_mask_1: 3.281  loss_mask_2: 3.28  loss_mask_3: 3.282  loss_mask_4: 3.278  loss_mask_5: 3.283  loss_mask_6: 3.28  loss_mask_7: 3.283  loss_mask_8: 3.281  time: 1.8540  data_time: 0.3876  lr: 8.4593e-05  max_mem: 17484M
[01/27 09:12:30] d2.utils.events INFO:  eta: 1 day, 0:19:04  iter: 10199  total_loss: 34.36  loss_mask: 3.433  loss_mask_0: 3.454  loss_mask_1: 3.437  loss_mask_2: 3.434  loss_mask_3: 3.432  loss_mask_4: 3.432  loss_mask_5: 3.434  loss_mask_6: 3.434  loss_mask_7: 3.433  loss_mask_8: 3.436  time: 1.8539  data_time: 0.4258  lr: 8.4563e-05  max_mem: 17484M
[01/27 09:13:05] d2.utils.events INFO:  eta: 1 day, 0:18:29  iter: 10219  total_loss: 33.69  loss_mask: 3.366  loss_mask_0: 3.439  loss_mask_1: 3.359  loss_mask_2: 3.359  loss_mask_3: 3.369  loss_mask_4: 3.362  loss_mask_5: 3.369  loss_mask_6: 3.365  loss_mask_7: 3.359  loss_mask_8: 3.365  time: 1.8538  data_time: 0.4188  lr: 8.4532e-05  max_mem: 17484M
[01/27 09:13:41] d2.utils.events INFO:  eta: 1 day, 0:18:15  iter: 10239  total_loss: 35.65  loss_mask: 3.562  loss_mask_0: 3.59  loss_mask_1: 3.561  loss_mask_2: 3.561  loss_mask_3: 3.561  loss_mask_4: 3.565  loss_mask_5: 3.564  loss_mask_6: 3.561  loss_mask_7: 3.56  loss_mask_8: 3.562  time: 1.8536  data_time: 0.3971  lr: 8.4501e-05  max_mem: 17484M
[01/27 09:14:17] d2.utils.events INFO:  eta: 1 day, 0:19:08  iter: 10259  total_loss: 29.92  loss_mask: 2.99  loss_mask_0: 3.003  loss_mask_1: 2.99  loss_mask_2: 2.989  loss_mask_3: 2.988  loss_mask_4: 2.989  loss_mask_5: 2.988  loss_mask_6: 2.989  loss_mask_7: 2.99  loss_mask_8: 2.99  time: 1.8535  data_time: 0.4105  lr: 8.4471e-05  max_mem: 17484M
[01/27 09:14:51] d2.utils.events INFO:  eta: 1 day, 0:18:09  iter: 10279  total_loss: 31.73  loss_mask: 3.171  loss_mask_0: 3.196  loss_mask_1: 3.168  loss_mask_2: 3.167  loss_mask_3: 3.174  loss_mask_4: 3.173  loss_mask_5: 3.17  loss_mask_6: 3.169  loss_mask_7: 3.171  loss_mask_8: 3.167  time: 1.8532  data_time: 0.3945  lr: 8.444e-05  max_mem: 17484M
[01/27 09:15:26] d2.utils.events INFO:  eta: 1 day, 0:17:34  iter: 10299  total_loss: 32.35  loss_mask: 3.232  loss_mask_0: 3.241  loss_mask_1: 3.228  loss_mask_2: 3.227  loss_mask_3: 3.227  loss_mask_4: 3.23  loss_mask_5: 3.231  loss_mask_6: 3.229  loss_mask_7: 3.227  loss_mask_8: 3.225  time: 1.8531  data_time: 0.3977  lr: 8.441e-05  max_mem: 17484M
[01/27 09:16:02] d2.utils.events INFO:  eta: 1 day, 0:17:09  iter: 10319  total_loss: 30.43  loss_mask: 3.043  loss_mask_0: 3.057  loss_mask_1: 3.042  loss_mask_2: 3.042  loss_mask_3: 3.044  loss_mask_4: 3.042  loss_mask_5: 3.044  loss_mask_6: 3.043  loss_mask_7: 3.045  loss_mask_8: 3.044  time: 1.8529  data_time: 0.3981  lr: 8.4379e-05  max_mem: 17484M
[01/27 09:16:37] d2.utils.events INFO:  eta: 1 day, 0:17:31  iter: 10339  total_loss: 32.38  loss_mask: 3.233  loss_mask_0: 3.279  loss_mask_1: 3.229  loss_mask_2: 3.231  loss_mask_3: 3.231  loss_mask_4: 3.229  loss_mask_5: 3.23  loss_mask_6: 3.231  loss_mask_7: 3.229  loss_mask_8: 3.232  time: 1.8527  data_time: 0.4268  lr: 8.4349e-05  max_mem: 17484M
[01/27 09:17:13] d2.utils.events INFO:  eta: 1 day, 0:17:12  iter: 10359  total_loss: 30.92  loss_mask: 3.088  loss_mask_0: 3.124  loss_mask_1: 3.088  loss_mask_2: 3.087  loss_mask_3: 3.087  loss_mask_4: 3.088  loss_mask_5: 3.088  loss_mask_6: 3.088  loss_mask_7: 3.088  loss_mask_8: 3.088  time: 1.8526  data_time: 0.4089  lr: 8.4318e-05  max_mem: 17484M
[01/27 09:17:48] d2.utils.events INFO:  eta: 1 day, 0:17:13  iter: 10379  total_loss: 32.21  loss_mask: 3.218  loss_mask_0: 3.288  loss_mask_1: 3.212  loss_mask_2: 3.213  loss_mask_3: 3.216  loss_mask_4: 3.213  loss_mask_5: 3.212  loss_mask_6: 3.212  loss_mask_7: 3.213  loss_mask_8: 3.212  time: 1.8524  data_time: 0.3948  lr: 8.4287e-05  max_mem: 17484M
[01/27 09:18:23] d2.utils.events INFO:  eta: 1 day, 0:16:24  iter: 10399  total_loss: 30.97  loss_mask: 3.095  loss_mask_0: 3.126  loss_mask_1: 3.091  loss_mask_2: 3.095  loss_mask_3: 3.094  loss_mask_4: 3.093  loss_mask_5: 3.097  loss_mask_6: 3.094  loss_mask_7: 3.089  loss_mask_8: 3.094  time: 1.8522  data_time: 0.3988  lr: 8.4257e-05  max_mem: 17484M
[01/27 09:18:58] d2.utils.events INFO:  eta: 1 day, 0:14:33  iter: 10419  total_loss: 29.7  loss_mask: 2.969  loss_mask_0: 2.975  loss_mask_1: 2.968  loss_mask_2: 2.969  loss_mask_3: 2.969  loss_mask_4: 2.969  loss_mask_5: 2.97  loss_mask_6: 2.969  loss_mask_7: 2.971  loss_mask_8: 2.97  time: 1.8520  data_time: 0.3924  lr: 8.4226e-05  max_mem: 17484M
[01/27 09:19:33] d2.utils.events INFO:  eta: 1 day, 0:14:33  iter: 10439  total_loss: 31.41  loss_mask: 3.135  loss_mask_0: 3.197  loss_mask_1: 3.132  loss_mask_2: 3.134  loss_mask_3: 3.131  loss_mask_4: 3.133  loss_mask_5: 3.132  loss_mask_6: 3.129  loss_mask_7: 3.132  loss_mask_8: 3.135  time: 1.8518  data_time: 0.4097  lr: 8.4196e-05  max_mem: 17484M
[01/27 09:20:09] d2.utils.events INFO:  eta: 1 day, 0:14:21  iter: 10459  total_loss: 30.85  loss_mask: 3.079  loss_mask_0: 3.143  loss_mask_1: 3.076  loss_mask_2: 3.079  loss_mask_3: 3.076  loss_mask_4: 3.077  loss_mask_5: 3.079  loss_mask_6: 3.079  loss_mask_7: 3.075  loss_mask_8: 3.076  time: 1.8517  data_time: 0.3985  lr: 8.4165e-05  max_mem: 17484M
[01/27 09:20:44] d2.utils.events INFO:  eta: 1 day, 0:13:46  iter: 10479  total_loss: 29.09  loss_mask: 2.904  loss_mask_0: 2.967  loss_mask_1: 2.9  loss_mask_2: 2.899  loss_mask_3: 2.899  loss_mask_4: 2.901  loss_mask_5: 2.904  loss_mask_6: 2.901  loss_mask_7: 2.902  loss_mask_8: 2.903  time: 1.8515  data_time: 0.4151  lr: 8.4135e-05  max_mem: 17484M
[01/27 09:21:20] d2.utils.events INFO:  eta: 1 day, 0:12:59  iter: 10499  total_loss: 29.39  loss_mask: 2.936  loss_mask_0: 2.973  loss_mask_1: 2.935  loss_mask_2: 2.935  loss_mask_3: 2.935  loss_mask_4: 2.935  loss_mask_5: 2.937  loss_mask_6: 2.936  loss_mask_7: 2.935  loss_mask_8: 2.934  time: 1.8514  data_time: 0.4140  lr: 8.4104e-05  max_mem: 17484M
[01/27 09:21:55] d2.utils.events INFO:  eta: 1 day, 0:11:37  iter: 10519  total_loss: 28.49  loss_mask: 2.848  loss_mask_0: 2.861  loss_mask_1: 2.848  loss_mask_2: 2.847  loss_mask_3: 2.848  loss_mask_4: 2.848  loss_mask_5: 2.848  loss_mask_6: 2.848  loss_mask_7: 2.85  loss_mask_8: 2.847  time: 1.8512  data_time: 0.3897  lr: 8.4073e-05  max_mem: 17484M
[01/27 09:22:30] d2.utils.events INFO:  eta: 1 day, 0:11:17  iter: 10539  total_loss: 30.4  loss_mask: 3.039  loss_mask_0: 3.062  loss_mask_1: 3.039  loss_mask_2: 3.037  loss_mask_3: 3.036  loss_mask_4: 3.036  loss_mask_5: 3.039  loss_mask_6: 3.036  loss_mask_7: 3.037  loss_mask_8: 3.036  time: 1.8511  data_time: 0.3841  lr: 8.4043e-05  max_mem: 17484M
[01/27 09:23:06] d2.utils.events INFO:  eta: 1 day, 0:09:57  iter: 10559  total_loss: 29.94  loss_mask: 2.985  loss_mask_0: 3.037  loss_mask_1: 2.986  loss_mask_2: 2.985  loss_mask_3: 2.989  loss_mask_4: 2.993  loss_mask_5: 2.987  loss_mask_6: 2.988  loss_mask_7: 2.99  loss_mask_8: 2.984  time: 1.8509  data_time: 0.3933  lr: 8.4012e-05  max_mem: 17484M
[01/27 09:23:41] d2.utils.events INFO:  eta: 1 day, 0:09:51  iter: 10579  total_loss: 30.54  loss_mask: 3.049  loss_mask_0: 3.088  loss_mask_1: 3.052  loss_mask_2: 3.051  loss_mask_3: 3.05  loss_mask_4: 3.052  loss_mask_5: 3.05  loss_mask_6: 3.051  loss_mask_7: 3.051  loss_mask_8: 3.05  time: 1.8507  data_time: 0.4045  lr: 8.3982e-05  max_mem: 17484M
[01/27 09:24:16] d2.utils.events INFO:  eta: 1 day, 0:09:09  iter: 10599  total_loss: 29.16  loss_mask: 2.912  loss_mask_0: 2.957  loss_mask_1: 2.913  loss_mask_2: 2.911  loss_mask_3: 2.91  loss_mask_4: 2.908  loss_mask_5: 2.912  loss_mask_6: 2.911  loss_mask_7: 2.909  loss_mask_8: 2.911  time: 1.8506  data_time: 0.4003  lr: 8.3951e-05  max_mem: 17484M
[01/27 09:24:52] d2.utils.events INFO:  eta: 1 day, 0:07:46  iter: 10619  total_loss: 33.41  loss_mask: 3.33  loss_mask_0: 3.418  loss_mask_1: 3.33  loss_mask_2: 3.329  loss_mask_3: 3.33  loss_mask_4: 3.331  loss_mask_5: 3.334  loss_mask_6: 3.328  loss_mask_7: 3.331  loss_mask_8: 3.328  time: 1.8504  data_time: 0.3953  lr: 8.392e-05  max_mem: 17484M
[01/27 09:25:27] d2.utils.events INFO:  eta: 1 day, 0:07:25  iter: 10639  total_loss: 34.6  loss_mask: 3.446  loss_mask_0: 3.59  loss_mask_1: 3.446  loss_mask_2: 3.447  loss_mask_3: 3.452  loss_mask_4: 3.448  loss_mask_5: 3.44  loss_mask_6: 3.446  loss_mask_7: 3.437  loss_mask_8: 3.45  time: 1.8502  data_time: 0.4018  lr: 8.389e-05  max_mem: 17484M
[01/27 09:26:02] d2.utils.events INFO:  eta: 1 day, 0:06:22  iter: 10659  total_loss: 32.28  loss_mask: 3.226  loss_mask_0: 3.276  loss_mask_1: 3.22  loss_mask_2: 3.223  loss_mask_3: 3.223  loss_mask_4: 3.224  loss_mask_5: 3.223  loss_mask_6: 3.22  loss_mask_7: 3.224  loss_mask_8: 3.224  time: 1.8501  data_time: 0.4026  lr: 8.3859e-05  max_mem: 17484M
[01/27 09:26:38] d2.utils.events INFO:  eta: 1 day, 0:06:14  iter: 10679  total_loss: 30.7  loss_mask: 3.067  loss_mask_0: 3.119  loss_mask_1: 3.063  loss_mask_2: 3.065  loss_mask_3: 3.066  loss_mask_4: 3.066  loss_mask_5: 3.065  loss_mask_6: 3.064  loss_mask_7: 3.067  loss_mask_8: 3.065  time: 1.8499  data_time: 0.4184  lr: 8.3829e-05  max_mem: 17484M
[01/27 09:27:13] d2.utils.events INFO:  eta: 1 day, 0:04:51  iter: 10699  total_loss: 32.72  loss_mask: 3.265  loss_mask_0: 3.293  loss_mask_1: 3.264  loss_mask_2: 3.264  loss_mask_3: 3.267  loss_mask_4: 3.264  loss_mask_5: 3.265  loss_mask_6: 3.266  loss_mask_7: 3.269  loss_mask_8: 3.264  time: 1.8498  data_time: 0.3908  lr: 8.3798e-05  max_mem: 17484M
[01/27 09:27:48] d2.utils.events INFO:  eta: 1 day, 0:04:20  iter: 10719  total_loss: 32.7  loss_mask: 3.266  loss_mask_0: 3.338  loss_mask_1: 3.26  loss_mask_2: 3.259  loss_mask_3: 3.266  loss_mask_4: 3.262  loss_mask_5: 3.264  loss_mask_6: 3.262  loss_mask_7: 3.261  loss_mask_8: 3.256  time: 1.8496  data_time: 0.3995  lr: 8.3767e-05  max_mem: 17484M
[01/27 09:28:23] d2.utils.events INFO:  eta: 1 day, 0:03:14  iter: 10739  total_loss: 32.93  loss_mask: 3.282  loss_mask_0: 3.392  loss_mask_1: 3.282  loss_mask_2: 3.299  loss_mask_3: 3.287  loss_mask_4: 3.285  loss_mask_5: 3.288  loss_mask_6: 3.291  loss_mask_7: 3.276  loss_mask_8: 3.278  time: 1.8494  data_time: 0.4019  lr: 8.3737e-05  max_mem: 17484M
[01/27 09:28:58] d2.utils.events INFO:  eta: 1 day, 0:01:53  iter: 10759  total_loss: 33.25  loss_mask: 3.312  loss_mask_0: 3.443  loss_mask_1: 3.311  loss_mask_2: 3.314  loss_mask_3: 3.309  loss_mask_4: 3.31  loss_mask_5: 3.31  loss_mask_6: 3.313  loss_mask_7: 3.314  loss_mask_8: 3.313  time: 1.8492  data_time: 0.3963  lr: 8.3706e-05  max_mem: 17484M
[01/27 09:29:34] d2.utils.events INFO:  eta: 1 day, 0:01:34  iter: 10779  total_loss: 29.49  loss_mask: 2.948  loss_mask_0: 2.995  loss_mask_1: 2.944  loss_mask_2: 2.944  loss_mask_3: 2.944  loss_mask_4: 2.946  loss_mask_5: 2.943  loss_mask_6: 2.941  loss_mask_7: 2.943  loss_mask_8: 2.944  time: 1.8491  data_time: 0.4056  lr: 8.3676e-05  max_mem: 17484M
[01/27 09:30:09] d2.utils.events INFO:  eta: 1 day, 0:00:50  iter: 10799  total_loss: 32.69  loss_mask: 3.26  loss_mask_0: 3.353  loss_mask_1: 3.266  loss_mask_2: 3.264  loss_mask_3: 3.261  loss_mask_4: 3.263  loss_mask_5: 3.265  loss_mask_6: 3.269  loss_mask_7: 3.264  loss_mask_8: 3.267  time: 1.8489  data_time: 0.3965  lr: 8.3645e-05  max_mem: 17484M
[01/27 09:30:45] d2.utils.events INFO:  eta: 1 day, 0:00:07  iter: 10819  total_loss: 30.24  loss_mask: 3.011  loss_mask_0: 3.116  loss_mask_1: 3.011  loss_mask_2: 3.012  loss_mask_3: 3.013  loss_mask_4: 3.012  loss_mask_5: 3.014  loss_mask_6: 3.012  loss_mask_7: 3.012  loss_mask_8: 3.012  time: 1.8488  data_time: 0.4241  lr: 8.3614e-05  max_mem: 17484M
[01/27 09:31:20] d2.utils.events INFO:  eta: 1 day, 0:00:10  iter: 10839  total_loss: 31.2  loss_mask: 3.109  loss_mask_0: 3.24  loss_mask_1: 3.109  loss_mask_2: 3.107  loss_mask_3: 3.104  loss_mask_4: 3.107  loss_mask_5: 3.106  loss_mask_6: 3.107  loss_mask_7: 3.105  loss_mask_8: 3.106  time: 1.8487  data_time: 0.4072  lr: 8.3584e-05  max_mem: 17484M
[01/27 09:31:56] d2.utils.events INFO:  eta: 1 day, 0:00:03  iter: 10859  total_loss: 29.12  loss_mask: 2.904  loss_mask_0: 3.034  loss_mask_1: 2.903  loss_mask_2: 2.902  loss_mask_3: 2.902  loss_mask_4: 2.907  loss_mask_5: 2.898  loss_mask_6: 2.9  loss_mask_7: 2.902  loss_mask_8: 2.902  time: 1.8485  data_time: 0.4206  lr: 8.3553e-05  max_mem: 17484M
[01/27 09:32:32] d2.utils.events INFO:  eta: 23:59:36  iter: 10879  total_loss: 32.29  loss_mask: 3.22  loss_mask_0: 3.348  loss_mask_1: 3.217  loss_mask_2: 3.213  loss_mask_3: 3.211  loss_mask_4: 3.214  loss_mask_5: 3.219  loss_mask_6: 3.217  loss_mask_7: 3.217  loss_mask_8: 3.217  time: 1.8484  data_time: 0.3922  lr: 8.3523e-05  max_mem: 17484M
[01/27 09:33:07] d2.utils.events INFO:  eta: 23:59:34  iter: 10899  total_loss: 31.02  loss_mask: 3.095  loss_mask_0: 3.23  loss_mask_1: 3.092  loss_mask_2: 3.095  loss_mask_3: 3.095  loss_mask_4: 3.094  loss_mask_5: 3.093  loss_mask_6: 3.093  loss_mask_7: 3.092  loss_mask_8: 3.093  time: 1.8483  data_time: 0.4198  lr: 8.3492e-05  max_mem: 17484M
[01/27 09:33:43] d2.utils.events INFO:  eta: 23:58:53  iter: 10919  total_loss: 32.13  loss_mask: 3.21  loss_mask_0: 3.262  loss_mask_1: 3.207  loss_mask_2: 3.208  loss_mask_3: 3.208  loss_mask_4: 3.206  loss_mask_5: 3.211  loss_mask_6: 3.207  loss_mask_7: 3.206  loss_mask_8: 3.207  time: 1.8482  data_time: 0.4139  lr: 8.3461e-05  max_mem: 17484M
[01/27 09:34:18] d2.utils.events INFO:  eta: 23:58:09  iter: 10939  total_loss: 32.37  loss_mask: 3.224  loss_mask_0: 3.351  loss_mask_1: 3.224  loss_mask_2: 3.223  loss_mask_3: 3.222  loss_mask_4: 3.223  loss_mask_5: 3.223  loss_mask_6: 3.225  loss_mask_7: 3.226  loss_mask_8: 3.224  time: 1.8480  data_time: 0.4092  lr: 8.3431e-05  max_mem: 17484M
[01/27 09:34:54] d2.utils.events INFO:  eta: 23:58:02  iter: 10959  total_loss: 31.35  loss_mask: 3.123  loss_mask_0: 3.263  loss_mask_1: 3.122  loss_mask_2: 3.121  loss_mask_3: 3.121  loss_mask_4: 3.12  loss_mask_5: 3.12  loss_mask_6: 3.118  loss_mask_7: 3.122  loss_mask_8: 3.121  time: 1.8479  data_time: 0.4133  lr: 8.34e-05  max_mem: 17484M
[01/27 09:35:29] d2.utils.events INFO:  eta: 23:57:58  iter: 10979  total_loss: 30.44  loss_mask: 3.034  loss_mask_0: 3.187  loss_mask_1: 3.023  loss_mask_2: 3.026  loss_mask_3: 3.033  loss_mask_4: 3.027  loss_mask_5: 3.028  loss_mask_6: 3.027  loss_mask_7: 3.032  loss_mask_8: 3.026  time: 1.8478  data_time: 0.4032  lr: 8.337e-05  max_mem: 17484M
[01/27 09:36:05] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 09:36:05] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 09:36:06] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 09:42:52] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.8048084914701885, 'error_1pix': 0.4001619255121034, 'error_3pix': 0.17101958572263304, 'mIoU': 7.037147219005248, 'fwIoU': 17.265457436851513, 'IoU-0': nan, 'IoU-1': 55.32196285079068, 'IoU-2': 2.566877597493003, 'IoU-3': 2.4715608644599287, 'IoU-4': 2.1636819972958112, 'IoU-5': 2.061327948369101, 'IoU-6': 2.185925055777224, 'IoU-7': 2.1992750054756782, 'IoU-8': 3.5031957817278023, 'IoU-9': 8.290587244179502, 'IoU-10': 14.847700283679602, 'IoU-11': 23.18925108209701, 'IoU-12': 21.506778576081405, 'IoU-13': 19.719866323015626, 'IoU-14': 19.274617812433455, 'IoU-15': 18.063637440188334, 'IoU-16': 17.87596814483573, 'IoU-17': 15.702000246549636, 'IoU-18': 16.7441846115376, 'IoU-19': 15.85214904658673, 'IoU-20': 15.1654333571427, 'IoU-21': 15.207194628579302, 'IoU-22': 17.129618310685093, 'IoU-23': 15.557477516116109, 'IoU-24': 14.618918977744583, 'IoU-25': 14.493401012915106, 'IoU-26': 15.32482997951601, 'IoU-27': 17.271881512030614, 'IoU-28': 16.12063221268753, 'IoU-29': 15.765887194800069, 'IoU-30': 15.253416852700544, 'IoU-31': 15.264499854567049, 'IoU-32': 15.200430016502015, 'IoU-33': 14.118114275339726, 'IoU-34': 13.882735512416042, 'IoU-35': 14.886736168485731, 'IoU-36': 14.820424771547028, 'IoU-37': 14.743603656299218, 'IoU-38': 15.246367061581484, 'IoU-39': 14.648612599272292, 'IoU-40': 14.71490312565502, 'IoU-41': 13.604074910689718, 'IoU-42': 13.289367427751511, 'IoU-43': 12.61416739689755, 'IoU-44': 12.616653188487389, 'IoU-45': 12.070445520121313, 'IoU-46': 11.075177600709452, 'IoU-47': 11.114643560343513, 'IoU-48': 11.024812261317383, 'IoU-49': 11.147650218071936, 'IoU-50': 10.845984768119303, 'IoU-51': 10.779739586108212, 'IoU-52': 10.741687718244416, 'IoU-53': 10.521618916462353, 'IoU-54': 10.533216978796611, 'IoU-55': 10.427223854398042, 'IoU-56': 9.940351195496735, 'IoU-57': 10.011877780930044, 'IoU-58': 9.7037267846035, 'IoU-59': 9.284495754667859, 'IoU-60': 9.063510190310765, 'IoU-61': 8.91450370458928, 'IoU-62': 8.813993451585652, 'IoU-63': 8.699954302076833, 'IoU-64': 8.696952946289908, 'IoU-65': 8.293162241768579, 'IoU-66': 8.357116062071578, 'IoU-67': 8.304316555841524, 'IoU-68': 7.970136456134393, 'IoU-69': 8.077323573345568, 'IoU-70': 8.133486148925586, 'IoU-71': 7.904524633894229, 'IoU-72': 7.679895133895832, 'IoU-73': 7.377672014634265, 'IoU-74': 7.621655318739, 'IoU-75': 7.436914575851408, 'IoU-76': 7.679905718334436, 'IoU-77': 7.718840664179878, 'IoU-78': 7.581316481992599, 'IoU-79': 7.416617850032944, 'IoU-80': 7.358823930333392, 'IoU-81': 7.470174448174835, 'IoU-82': 7.423752410758917, 'IoU-83': 7.361281199061074, 'IoU-84': 7.165132751639303, 'IoU-85': 7.168474850094181, 'IoU-86': 7.15000939188332, 'IoU-87': 7.047710833479405, 'IoU-88': 7.0679814054704595, 'IoU-89': 6.817872799290099, 'IoU-90': 6.835989683659327, 'IoU-91': 6.58683239523673, 'IoU-92': 6.5786610458881105, 'IoU-93': 6.3538617500745, 'IoU-94': 6.249736534703056, 'IoU-95': 6.255346943261511, 'IoU-96': 6.067253239243207, 'IoU-97': 5.941557602495708, 'IoU-98': 6.023741682467685, 'IoU-99': 5.798796578013345, 'IoU-100': 5.579360616223094, 'IoU-101': 5.490148452473616, 'IoU-102': 5.4658612563684645, 'IoU-103': 5.361227662611608, 'IoU-104': 5.153651771284089, 'IoU-105': 4.935960241243234, 'IoU-106': 4.91482041920251, 'IoU-107': 5.061348413583291, 'IoU-108': 4.95704345626192, 'IoU-109': 5.010693009478912, 'IoU-110': 4.759747775812396, 'IoU-111': 4.628434896022749, 'IoU-112': 4.5144572433858805, 'IoU-113': 4.215955584708325, 'IoU-114': 4.327115168017053, 'IoU-115': 4.14400718503403, 'IoU-116': 3.9792992516959225, 'IoU-117': 3.853163255415352, 'IoU-118': 3.8661807432232296, 'IoU-119': 3.7235321236490564, 'IoU-120': 3.625605887278431, 'IoU-121': 3.7823084282092023, 'IoU-122': 3.6409526561048065, 'IoU-123': 3.409182912651363, 'IoU-124': 3.3718258070327147, 'IoU-125': 3.328927691062339, 'IoU-126': 3.251161265450237, 'IoU-127': 3.414807013300579, 'IoU-128': 3.2855910514407767, 'IoU-129': 3.1250778664479983, 'IoU-130': 3.133946590322429, 'IoU-131': 2.9408833274385775, 'IoU-132': 2.7412559640910836, 'IoU-133': 2.8587278968656387, 'IoU-134': 2.675190638846653, 'IoU-135': 2.77873919366412, 'IoU-136': 2.924155226815088, 'IoU-137': 2.7949515766220823, 'IoU-138': 2.5148576790741317, 'IoU-139': 2.71875733867549, 'IoU-140': 2.818654123957236, 'IoU-141': 3.102912394392512, 'IoU-142': 2.9950637201376793, 'IoU-143': 2.7809355858110716, 'IoU-144': 2.7664130796159037, 'IoU-145': 2.9213578311259583, 'IoU-146': 2.897133783303658, 'IoU-147': 3.026479743473088, 'IoU-148': 2.9147072675068086, 'IoU-149': 2.6150743021706475, 'IoU-150': 2.5123967903582782, 'IoU-151': 2.4443048408509074, 'IoU-152': 2.412642406482672, 'IoU-153': 2.3235135489701615, 'IoU-154': 2.218990844746001, 'IoU-155': 2.037725119001725, 'IoU-156': 2.124620260018581, 'IoU-157': 2.236437802829046, 'IoU-158': 1.9600644643423828, 'IoU-159': 1.9289271127239012, 'IoU-160': 2.0432312713896734, 'IoU-161': 2.267799111468873, 'IoU-162': 2.3092924006860986, 'IoU-163': 2.158903725510812, 'IoU-164': 2.0752889782689756, 'IoU-165': 1.8910002710275173, 'IoU-166': 1.770027081209111, 'IoU-167': 1.9389541202536713, 'IoU-168': 2.02992048229343, 'IoU-169': 1.9198456359619493, 'IoU-170': 2.096404022149538, 'IoU-171': 2.1610627835331577, 'IoU-172': 2.1758539438519087, 'IoU-173': 2.282250976063449, 'IoU-174': 2.132995765603817, 'IoU-175': 2.2830501398044003, 'IoU-176': 2.2129800014073004, 'IoU-177': 2.202621944742257, 'IoU-178': 1.86051555871423, 'IoU-179': 2.081748417546218, 'IoU-180': 2.3442356773941393, 'IoU-181': 1.659875157446197, 'IoU-182': 1.479020026482346, 'IoU-183': 1.4707586186052057, 'IoU-184': 1.6049725823864547, 'IoU-185': 1.4732186767989917, 'IoU-186': 1.3635987299777996, 'IoU-187': 1.2232440512716305, 'IoU-188': 1.1894570068077341, 'IoU-189': 1.1772407773234712, 'IoU-190': 0.8814375392642537, 'IoU-191': 1.9130379110975406, 'IoU-192': 0.4109288916676018, 'mACC': 12.643143510880234, 'pACC': 25.981282376162934, 'ACC-0': nan, 'ACC-1': 56.25436436464061, 'ACC-2': 5.764481788490895, 'ACC-3': 13.611638101356208, 'ACC-4': 10.525426524364487, 'ACC-5': 9.805994858303492, 'ACC-6': 10.292030346459436, 'ACC-7': 10.91062566772774, 'ACC-8': 8.28261528570334, 'ACC-9': 12.710194669251301, 'ACC-10': 22.904251830664897, 'ACC-11': 33.42239304400317, 'ACC-12': 32.93542232523256, 'ACC-13': 31.014196101998, 'ACC-14': 31.091434912360594, 'ACC-15': 30.69742630231989, 'ACC-16': 31.093088726628814, 'ACC-17': 28.650129036643595, 'ACC-18': 28.996197590389492, 'ACC-19': 26.88264729702657, 'ACC-20': 25.58953473993087, 'ACC-21': 26.237556343578472, 'ACC-22': 29.30357810713462, 'ACC-23': 27.63134521843312, 'ACC-24': 25.424388892031207, 'ACC-25': 25.298995055682035, 'ACC-26': 27.155755819832095, 'ACC-27': 29.62110632644505, 'ACC-28': 27.852047126557487, 'ACC-29': 26.350853398223883, 'ACC-30': 26.30699296265736, 'ACC-31': 25.961827086429544, 'ACC-32': 26.475784254212154, 'ACC-33': 25.116089251404038, 'ACC-34': 24.344110738517877, 'ACC-35': 25.780311247021114, 'ACC-36': 26.01358009454133, 'ACC-37': 26.34485355972832, 'ACC-38': 26.963810697334534, 'ACC-39': 25.914753694596655, 'ACC-40': 25.8174656944969, 'ACC-41': 24.547342341886292, 'ACC-42': 23.875196247794836, 'ACC-43': 22.667330782233456, 'ACC-44': 22.20910749575989, 'ACC-45': 21.762662076674, 'ACC-46': 20.539040043127482, 'ACC-47': 20.53033391225652, 'ACC-48': 20.635361350022094, 'ACC-49': 20.735097457295833, 'ACC-50': 20.19341358858838, 'ACC-51': 20.386046276844564, 'ACC-52': 20.33034782917718, 'ACC-53': 19.81997130576717, 'ACC-54': 19.646423595959416, 'ACC-55': 19.628512683811326, 'ACC-56': 19.003769563183575, 'ACC-57': 18.67787811457244, 'ACC-58': 18.203883226150904, 'ACC-59': 17.629848214401385, 'ACC-60': 17.286854051398347, 'ACC-61': 17.140948531454335, 'ACC-62': 17.001548520423434, 'ACC-63': 16.922756678427607, 'ACC-64': 16.74604171561934, 'ACC-65': 16.0612141034588, 'ACC-66': 16.198149164912465, 'ACC-67': 16.22221098354269, 'ACC-68': 15.44754684350992, 'ACC-69': 15.338989702298655, 'ACC-70': 15.243571816175058, 'ACC-71': 14.98216832505746, 'ACC-72': 14.528993351133728, 'ACC-73': 13.88545498501924, 'ACC-74': 14.176670075783035, 'ACC-75': 13.94909923540416, 'ACC-76': 14.266790196728826, 'ACC-77': 14.572523998769524, 'ACC-78': 14.400791699138354, 'ACC-79': 14.017071036276926, 'ACC-80': 13.813691146449758, 'ACC-81': 13.984201959630676, 'ACC-82': 13.960610613572626, 'ACC-83': 13.660959464018068, 'ACC-84': 13.363970315116921, 'ACC-85': 13.378607735185138, 'ACC-86': 13.37449501501496, 'ACC-87': 13.271888487551674, 'ACC-88': 13.297980843444954, 'ACC-89': 12.804609368263211, 'ACC-90': 12.658692194980626, 'ACC-91': 12.246608358750175, 'ACC-92': 12.252077847118743, 'ACC-93': 11.817096600117473, 'ACC-94': 11.609401874706544, 'ACC-95': 11.609836024289432, 'ACC-96': 11.386913072672142, 'ACC-97': 11.021449181272041, 'ACC-98': 11.184930635102457, 'ACC-99': 10.85709293856221, 'ACC-100': 10.421162322049087, 'ACC-101': 10.280119522477525, 'ACC-102': 10.238505463933057, 'ACC-103': 9.951000649388984, 'ACC-104': 9.521462579287112, 'ACC-105': 9.051523016811682, 'ACC-106': 9.060407700253071, 'ACC-107': 9.403923475581896, 'ACC-108': 9.194773969337488, 'ACC-109': 9.177513845124546, 'ACC-110': 8.893812197715077, 'ACC-111': 8.734735015188596, 'ACC-112': 8.590333651643366, 'ACC-113': 8.068474410523962, 'ACC-114': 8.371146178366812, 'ACC-115': 7.86662005923654, 'ACC-116': 7.581108677846409, 'ACC-117': 7.251912077773769, 'ACC-118': 7.26162899814712, 'ACC-119': 6.949021182164383, 'ACC-120': 6.751819366990305, 'ACC-121': 7.037613546708865, 'ACC-122': 6.759744119561834, 'ACC-123': 6.357700984271783, 'ACC-124': 6.441635266296272, 'ACC-125': 6.333950789840356, 'ACC-126': 6.298042331897376, 'ACC-127': 6.629874589987758, 'ACC-128': 6.440917146303595, 'ACC-129': 6.060145874736988, 'ACC-130': 6.029065402960971, 'ACC-131': 5.647522152064878, 'ACC-132': 5.199840489522909, 'ACC-133': 5.340042322426123, 'ACC-134': 4.944903059026282, 'ACC-135': 5.160552420044468, 'ACC-136': 5.422087565225494, 'ACC-137': 5.226241494716516, 'ACC-138': 4.751154910272356, 'ACC-139': 5.1158760141405795, 'ACC-140': 5.202120637118769, 'ACC-141': 5.674378992670864, 'ACC-142': 5.538375280665335, 'ACC-143': 5.231777605644687, 'ACC-144': 5.106747835033868, 'ACC-145': 5.306710628359407, 'ACC-146': 5.223770114270257, 'ACC-147': 5.392450903013139, 'ACC-148': 5.17116330974984, 'ACC-149': 4.687431861352621, 'ACC-150': 4.5022301116671475, 'ACC-151': 4.358554034004673, 'ACC-152': 4.2510078796908815, 'ACC-153': 4.19865206113252, 'ACC-154': 3.9761585484708073, 'ACC-155': 3.674985885352077, 'ACC-156': 3.855756611909518, 'ACC-157': 4.053158226443808, 'ACC-158': 3.55694069224841, 'ACC-159': 3.421839197803943, 'ACC-160': 3.5772973982006038, 'ACC-161': 3.9411939036500288, 'ACC-162': 4.125971547897944, 'ACC-163': 3.8621162121411383, 'ACC-164': 3.724991078862852, 'ACC-165': 3.3475841185563655, 'ACC-166': 3.186791961638912, 'ACC-167': 3.5347136409218964, 'ACC-168': 3.717523128968076, 'ACC-169': 3.5431204323807988, 'ACC-170': 3.922414788215885, 'ACC-171': 4.110594028275504, 'ACC-172': 4.10834929778068, 'ACC-173': 4.206857573474002, 'ACC-174': 3.8563276217072904, 'ACC-175': 4.0094951006169595, 'ACC-176': 3.7710037660985725, 'ACC-177': 3.7198626944730084, 'ACC-178': 3.1210626244718718, 'ACC-179': 3.4385299984343516, 'ACC-180': 3.7936238085232374, 'ACC-181': 2.6886828304324695, 'ACC-182': 2.2194176464856055, 'ACC-183': 2.0684704087584693, 'ACC-184': 2.1329639889196677, 'ACC-185': 1.8795795579455692, 'ACC-186': 1.6859536398458312, 'ACC-187': 1.4828327959690362, 'ACC-188': 1.3970668723572703, 'ACC-189': 1.3299321669720106, 'ACC-190': 0.9731097686878902, 'ACC-191': 2.0500465739760982, 'ACC-192': 0.4385739787043532})])
[01/27 09:42:52] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 09:42:52] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 09:42:52] d2.evaluation.testing INFO: copypaste: 2.8048,0.4002,0.1710,7.0371,17.2655,12.6431,25.9813
[01/27 09:42:52] d2.utils.events INFO:  eta: 23:58:02  iter: 10999  total_loss: 32.21  loss_mask: 3.212  loss_mask_0: 3.309  loss_mask_1: 3.211  loss_mask_2: 3.21  loss_mask_3: 3.212  loss_mask_4: 3.214  loss_mask_5: 3.21  loss_mask_6: 3.21  loss_mask_7: 3.212  loss_mask_8: 3.211  time: 1.8476  data_time: 0.4174  lr: 8.3339e-05  max_mem: 17484M
[01/27 09:43:28] d2.utils.events INFO:  eta: 23:58:10  iter: 11019  total_loss: 31.67  loss_mask: 3.153  loss_mask_0: 3.288  loss_mask_1: 3.153  loss_mask_2: 3.152  loss_mask_3: 3.151  loss_mask_4: 3.148  loss_mask_5: 3.152  loss_mask_6: 3.151  loss_mask_7: 3.151  loss_mask_8: 3.153  time: 1.8475  data_time: 0.4267  lr: 8.3308e-05  max_mem: 17484M
[01/27 09:44:04] d2.utils.events INFO:  eta: 23:57:29  iter: 11039  total_loss: 32.46  loss_mask: 3.238  loss_mask_0: 3.358  loss_mask_1: 3.238  loss_mask_2: 3.237  loss_mask_3: 3.233  loss_mask_4: 3.235  loss_mask_5: 3.24  loss_mask_6: 3.237  loss_mask_7: 3.237  loss_mask_8: 3.236  time: 1.8474  data_time: 0.4047  lr: 8.3278e-05  max_mem: 17484M
[01/27 09:44:39] d2.utils.events INFO:  eta: 23:56:54  iter: 11059  total_loss: 32.23  loss_mask: 3.212  loss_mask_0: 3.359  loss_mask_1: 3.209  loss_mask_2: 3.205  loss_mask_3: 3.208  loss_mask_4: 3.207  loss_mask_5: 3.207  loss_mask_6: 3.208  loss_mask_7: 3.208  loss_mask_8: 3.207  time: 1.8472  data_time: 0.4207  lr: 8.3247e-05  max_mem: 17484M
[01/27 09:45:14] d2.utils.events INFO:  eta: 23:56:22  iter: 11079  total_loss: 30.94  loss_mask: 3.078  loss_mask_0: 3.226  loss_mask_1: 3.074  loss_mask_2: 3.074  loss_mask_3: 3.076  loss_mask_4: 3.072  loss_mask_5: 3.071  loss_mask_6: 3.076  loss_mask_7: 3.073  loss_mask_8: 3.079  time: 1.8471  data_time: 0.3885  lr: 8.3217e-05  max_mem: 17484M
[01/27 09:45:50] d2.utils.events INFO:  eta: 23:56:03  iter: 11099  total_loss: 31.62  loss_mask: 3.151  loss_mask_0: 3.198  loss_mask_1: 3.156  loss_mask_2: 3.154  loss_mask_3: 3.153  loss_mask_4: 3.156  loss_mask_5: 3.153  loss_mask_6: 3.154  loss_mask_7: 3.155  loss_mask_8: 3.151  time: 1.8469  data_time: 0.4100  lr: 8.3186e-05  max_mem: 17484M
[01/27 09:46:25] d2.utils.events INFO:  eta: 23:55:04  iter: 11119  total_loss: 29.93  loss_mask: 2.986  loss_mask_0: 3.06  loss_mask_1: 2.984  loss_mask_2: 2.986  loss_mask_3: 2.985  loss_mask_4: 2.982  loss_mask_5: 2.983  loss_mask_6: 2.983  loss_mask_7: 2.986  loss_mask_8: 2.983  time: 1.8468  data_time: 0.4286  lr: 8.3155e-05  max_mem: 17484M
[01/27 09:47:01] d2.utils.events INFO:  eta: 23:54:36  iter: 11139  total_loss: 30.39  loss_mask: 3.032  loss_mask_0: 3.128  loss_mask_1: 3.03  loss_mask_2: 3.031  loss_mask_3: 3.033  loss_mask_4: 3.03  loss_mask_5: 3.031  loss_mask_6: 3.029  loss_mask_7: 3.032  loss_mask_8: 3.031  time: 1.8467  data_time: 0.3976  lr: 8.3125e-05  max_mem: 17484M
[01/27 09:47:37] d2.utils.events INFO:  eta: 23:54:50  iter: 11159  total_loss: 31.45  loss_mask: 3.139  loss_mask_0: 3.238  loss_mask_1: 3.136  loss_mask_2: 3.137  loss_mask_3: 3.138  loss_mask_4: 3.142  loss_mask_5: 3.14  loss_mask_6: 3.141  loss_mask_7: 3.138  loss_mask_8: 3.139  time: 1.8466  data_time: 0.4205  lr: 8.3094e-05  max_mem: 17484M
[01/27 09:48:12] d2.utils.events INFO:  eta: 23:54:21  iter: 11179  total_loss: 29.45  loss_mask: 2.943  loss_mask_0: 2.983  loss_mask_1: 2.94  loss_mask_2: 2.941  loss_mask_3: 2.941  loss_mask_4: 2.943  loss_mask_5: 2.943  loss_mask_6: 2.94  loss_mask_7: 2.942  loss_mask_8: 2.941  time: 1.8464  data_time: 0.3944  lr: 8.3063e-05  max_mem: 17484M
[01/27 09:48:47] d2.utils.events INFO:  eta: 23:52:52  iter: 11199  total_loss: 29.13  loss_mask: 2.912  loss_mask_0: 2.952  loss_mask_1: 2.912  loss_mask_2: 2.913  loss_mask_3: 2.912  loss_mask_4: 2.909  loss_mask_5: 2.911  loss_mask_6: 2.912  loss_mask_7: 2.914  loss_mask_8: 2.914  time: 1.8463  data_time: 0.4110  lr: 8.3033e-05  max_mem: 17484M
[01/27 09:49:23] d2.utils.events INFO:  eta: 23:52:12  iter: 11219  total_loss: 28.75  loss_mask: 2.871  loss_mask_0: 2.902  loss_mask_1: 2.871  loss_mask_2: 2.872  loss_mask_3: 2.872  loss_mask_4: 2.875  loss_mask_5: 2.872  loss_mask_6: 2.87  loss_mask_7: 2.869  loss_mask_8: 2.872  time: 1.8462  data_time: 0.4107  lr: 8.3002e-05  max_mem: 17484M
[01/27 09:49:58] d2.utils.events INFO:  eta: 23:51:33  iter: 11239  total_loss: 28.67  loss_mask: 2.858  loss_mask_0: 2.945  loss_mask_1: 2.858  loss_mask_2: 2.861  loss_mask_3: 2.86  loss_mask_4: 2.862  loss_mask_5: 2.857  loss_mask_6: 2.859  loss_mask_7: 2.858  loss_mask_8: 2.857  time: 1.8460  data_time: 0.3969  lr: 8.2972e-05  max_mem: 17484M
[01/27 09:50:33] d2.utils.events INFO:  eta: 23:50:46  iter: 11259  total_loss: 29.73  loss_mask: 2.973  loss_mask_0: 2.988  loss_mask_1: 2.971  loss_mask_2: 2.97  loss_mask_3: 2.97  loss_mask_4: 2.971  loss_mask_5: 2.973  loss_mask_6: 2.971  loss_mask_7: 2.973  loss_mask_8: 2.973  time: 1.8459  data_time: 0.4000  lr: 8.2941e-05  max_mem: 17484M
[01/27 09:51:09] d2.utils.events INFO:  eta: 23:50:31  iter: 11279  total_loss: 28.33  loss_mask: 2.83  loss_mask_0: 2.897  loss_mask_1: 2.828  loss_mask_2: 2.831  loss_mask_3: 2.831  loss_mask_4: 2.831  loss_mask_5: 2.828  loss_mask_6: 2.829  loss_mask_7: 2.83  loss_mask_8: 2.829  time: 1.8457  data_time: 0.4287  lr: 8.291e-05  max_mem: 17484M
[01/27 09:51:44] d2.utils.events INFO:  eta: 23:49:47  iter: 11299  total_loss: 27.48  loss_mask: 2.743  loss_mask_0: 2.787  loss_mask_1: 2.742  loss_mask_2: 2.742  loss_mask_3: 2.743  loss_mask_4: 2.744  loss_mask_5: 2.743  loss_mask_6: 2.744  loss_mask_7: 2.744  loss_mask_8: 2.742  time: 1.8456  data_time: 0.3710  lr: 8.288e-05  max_mem: 17484M
[01/27 09:52:19] d2.utils.events INFO:  eta: 23:49:19  iter: 11319  total_loss: 29.41  loss_mask: 2.935  loss_mask_0: 2.977  loss_mask_1: 2.933  loss_mask_2: 2.933  loss_mask_3: 2.931  loss_mask_4: 2.928  loss_mask_5: 2.932  loss_mask_6: 2.933  loss_mask_7: 2.933  loss_mask_8: 2.931  time: 1.8454  data_time: 0.4011  lr: 8.2849e-05  max_mem: 17484M
[01/27 09:52:54] d2.utils.events INFO:  eta: 23:48:14  iter: 11339  total_loss: 30.32  loss_mask: 3.029  loss_mask_0: 3.057  loss_mask_1: 3.029  loss_mask_2: 3.028  loss_mask_3: 3.029  loss_mask_4: 3.029  loss_mask_5: 3.029  loss_mask_6: 3.029  loss_mask_7: 3.029  loss_mask_8: 3.029  time: 1.8453  data_time: 0.3891  lr: 8.2818e-05  max_mem: 17484M
[01/27 09:53:30] d2.utils.events INFO:  eta: 23:47:54  iter: 11359  total_loss: 31.3  loss_mask: 3.129  loss_mask_0: 3.153  loss_mask_1: 3.13  loss_mask_2: 3.13  loss_mask_3: 3.129  loss_mask_4: 3.13  loss_mask_5: 3.129  loss_mask_6: 3.129  loss_mask_7: 3.126  loss_mask_8: 3.129  time: 1.8451  data_time: 0.4078  lr: 8.2788e-05  max_mem: 17484M
[01/27 09:54:05] d2.utils.events INFO:  eta: 23:47:19  iter: 11379  total_loss: 36.1  loss_mask: 3.594  loss_mask_0: 3.597  loss_mask_1: 3.602  loss_mask_2: 3.608  loss_mask_3: 3.603  loss_mask_4: 3.605  loss_mask_5: 3.606  loss_mask_6: 3.599  loss_mask_7: 3.603  loss_mask_8: 3.601  time: 1.8450  data_time: 0.3933  lr: 8.2757e-05  max_mem: 17484M
[01/27 09:54:40] d2.utils.events INFO:  eta: 23:46:55  iter: 11399  total_loss: 34.46  loss_mask: 3.446  loss_mask_0: 3.462  loss_mask_1: 3.443  loss_mask_2: 3.447  loss_mask_3: 3.446  loss_mask_4: 3.44  loss_mask_5: 3.441  loss_mask_6: 3.444  loss_mask_7: 3.446  loss_mask_8: 3.444  time: 1.8448  data_time: 0.4082  lr: 8.2726e-05  max_mem: 17484M
[01/27 09:55:15] d2.utils.events INFO:  eta: 23:46:23  iter: 11419  total_loss: 30.36  loss_mask: 3.019  loss_mask_0: 3.126  loss_mask_1: 3.019  loss_mask_2: 3.025  loss_mask_3: 3.024  loss_mask_4: 3.032  loss_mask_5: 3.022  loss_mask_6: 3.019  loss_mask_7: 3.022  loss_mask_8: 3.08  time: 1.8446  data_time: 0.3843  lr: 8.2696e-05  max_mem: 17484M
[01/27 09:55:51] d2.utils.events INFO:  eta: 23:46:06  iter: 11439  total_loss: 36.02  loss_mask: 3.59  loss_mask_0: 3.705  loss_mask_1: 3.588  loss_mask_2: 3.585  loss_mask_3: 3.594  loss_mask_4: 3.589  loss_mask_5: 3.587  loss_mask_6: 3.586  loss_mask_7: 3.59  loss_mask_8: 3.592  time: 1.8446  data_time: 0.4318  lr: 8.2665e-05  max_mem: 17484M
[01/27 09:56:27] d2.utils.events INFO:  eta: 23:45:45  iter: 11459  total_loss: 36.82  loss_mask: 3.694  loss_mask_0: 3.716  loss_mask_1: 3.675  loss_mask_2: 3.673  loss_mask_3: 3.685  loss_mask_4: 3.681  loss_mask_5: 3.677  loss_mask_6: 3.67  loss_mask_7: 3.682  loss_mask_8: 3.69  time: 1.8445  data_time: 0.4106  lr: 8.2635e-05  max_mem: 17484M
[01/27 09:57:01] d2.utils.events INFO:  eta: 23:43:55  iter: 11479  total_loss: 31.4  loss_mask: 3.134  loss_mask_0: 3.165  loss_mask_1: 3.137  loss_mask_2: 3.137  loss_mask_3: 3.136  loss_mask_4: 3.137  loss_mask_5: 3.135  loss_mask_6: 3.137  loss_mask_7: 3.136  loss_mask_8: 3.136  time: 1.8443  data_time: 0.3935  lr: 8.2604e-05  max_mem: 17484M
[01/27 09:57:37] d2.utils.events INFO:  eta: 23:43:14  iter: 11499  total_loss: 30.54  loss_mask: 3.052  loss_mask_0: 3.061  loss_mask_1: 3.053  loss_mask_2: 3.054  loss_mask_3: 3.054  loss_mask_4: 3.051  loss_mask_5: 3.054  loss_mask_6: 3.049  loss_mask_7: 3.053  loss_mask_8: 3.055  time: 1.8441  data_time: 0.4048  lr: 8.2573e-05  max_mem: 17484M
[01/27 09:58:12] d2.utils.events INFO:  eta: 23:42:59  iter: 11519  total_loss: 33.16  loss_mask: 3.318  loss_mask_0: 3.318  loss_mask_1: 3.314  loss_mask_2: 3.316  loss_mask_3: 3.316  loss_mask_4: 3.317  loss_mask_5: 3.314  loss_mask_6: 3.314  loss_mask_7: 3.318  loss_mask_8: 3.315  time: 1.8440  data_time: 0.3896  lr: 8.2543e-05  max_mem: 17484M
[01/27 09:58:47] d2.utils.events INFO:  eta: 23:42:09  iter: 11539  total_loss: 31.27  loss_mask: 3.131  loss_mask_0: 3.152  loss_mask_1: 3.126  loss_mask_2: 3.126  loss_mask_3: 3.127  loss_mask_4: 3.124  loss_mask_5: 3.127  loss_mask_6: 3.125  loss_mask_7: 3.123  loss_mask_8: 3.128  time: 1.8439  data_time: 0.4143  lr: 8.2512e-05  max_mem: 17484M
[01/27 09:59:23] d2.utils.events INFO:  eta: 23:42:18  iter: 11559  total_loss: 31.14  loss_mask: 3.108  loss_mask_0: 3.218  loss_mask_1: 3.105  loss_mask_2: 3.104  loss_mask_3: 3.106  loss_mask_4: 3.106  loss_mask_5: 3.103  loss_mask_6: 3.106  loss_mask_7: 3.107  loss_mask_8: 3.105  time: 1.8437  data_time: 0.4065  lr: 8.2481e-05  max_mem: 17484M
[01/27 09:59:58] d2.utils.events INFO:  eta: 23:41:45  iter: 11579  total_loss: 28.15  loss_mask: 2.81  loss_mask_0: 2.86  loss_mask_1: 2.811  loss_mask_2: 2.811  loss_mask_3: 2.809  loss_mask_4: 2.811  loss_mask_5: 2.81  loss_mask_6: 2.812  loss_mask_7: 2.81  loss_mask_8: 2.811  time: 1.8436  data_time: 0.4004  lr: 8.2451e-05  max_mem: 17484M
[01/27 10:00:34] d2.utils.events INFO:  eta: 23:41:35  iter: 11599  total_loss: 28.38  loss_mask: 2.834  loss_mask_0: 2.86  loss_mask_1: 2.835  loss_mask_2: 2.837  loss_mask_3: 2.837  loss_mask_4: 2.835  loss_mask_5: 2.835  loss_mask_6: 2.835  loss_mask_7: 2.836  loss_mask_8: 2.836  time: 1.8435  data_time: 0.3890  lr: 8.242e-05  max_mem: 17484M
[01/27 10:01:09] d2.utils.events INFO:  eta: 23:41:16  iter: 11619  total_loss: 30.77  loss_mask: 3.072  loss_mask_0: 3.121  loss_mask_1: 3.073  loss_mask_2: 3.072  loss_mask_3: 3.073  loss_mask_4: 3.073  loss_mask_5: 3.073  loss_mask_6: 3.072  loss_mask_7: 3.074  loss_mask_8: 3.069  time: 1.8434  data_time: 0.3993  lr: 8.2389e-05  max_mem: 17484M
[01/27 10:01:45] d2.utils.events INFO:  eta: 23:40:41  iter: 11639  total_loss: 28.97  loss_mask: 2.891  loss_mask_0: 2.943  loss_mask_1: 2.89  loss_mask_2: 2.891  loss_mask_3: 2.889  loss_mask_4: 2.888  loss_mask_5: 2.891  loss_mask_6: 2.892  loss_mask_7: 2.892  loss_mask_8: 2.891  time: 1.8432  data_time: 0.4017  lr: 8.2359e-05  max_mem: 17484M
[01/27 10:02:20] d2.utils.events INFO:  eta: 23:40:06  iter: 11659  total_loss: 30.63  loss_mask: 3.06  loss_mask_0: 3.1  loss_mask_1: 3.058  loss_mask_2: 3.058  loss_mask_3: 3.059  loss_mask_4: 3.059  loss_mask_5: 3.058  loss_mask_6: 3.056  loss_mask_7: 3.06  loss_mask_8: 3.06  time: 1.8431  data_time: 0.4077  lr: 8.2328e-05  max_mem: 17484M
[01/27 10:02:55] d2.utils.events INFO:  eta: 23:39:17  iter: 11679  total_loss: 28.9  loss_mask: 2.889  loss_mask_0: 2.903  loss_mask_1: 2.886  loss_mask_2: 2.887  loss_mask_3: 2.886  loss_mask_4: 2.888  loss_mask_5: 2.888  loss_mask_6: 2.889  loss_mask_7: 2.888  loss_mask_8: 2.887  time: 1.8430  data_time: 0.3961  lr: 8.2297e-05  max_mem: 17484M
[01/27 10:03:31] d2.utils.events INFO:  eta: 23:38:54  iter: 11699  total_loss: 30.17  loss_mask: 3.013  loss_mask_0: 3.049  loss_mask_1: 3.014  loss_mask_2: 3.013  loss_mask_3: 3.013  loss_mask_4: 3.014  loss_mask_5: 3.014  loss_mask_6: 3.014  loss_mask_7: 3.011  loss_mask_8: 3.014  time: 1.8428  data_time: 0.4129  lr: 8.2267e-05  max_mem: 17484M
[01/27 10:04:07] d2.utils.events INFO:  eta: 23:38:44  iter: 11719  total_loss: 31.25  loss_mask: 3.123  loss_mask_0: 3.194  loss_mask_1: 3.115  loss_mask_2: 3.114  loss_mask_3: 3.116  loss_mask_4: 3.115  loss_mask_5: 3.118  loss_mask_6: 3.115  loss_mask_7: 3.121  loss_mask_8: 3.118  time: 1.8428  data_time: 0.4147  lr: 8.2236e-05  max_mem: 17484M
[01/27 10:04:42] d2.utils.events INFO:  eta: 23:39:13  iter: 11739  total_loss: 28.94  loss_mask: 2.892  loss_mask_0: 2.928  loss_mask_1: 2.889  loss_mask_2: 2.891  loss_mask_3: 2.89  loss_mask_4: 2.889  loss_mask_5: 2.89  loss_mask_6: 2.891  loss_mask_7: 2.898  loss_mask_8: 2.891  time: 1.8427  data_time: 0.4196  lr: 8.2205e-05  max_mem: 17484M
[01/27 10:05:17] d2.utils.events INFO:  eta: 23:38:45  iter: 11759  total_loss: 31.12  loss_mask: 3.109  loss_mask_0: 3.14  loss_mask_1: 3.107  loss_mask_2: 3.105  loss_mask_3: 3.105  loss_mask_4: 3.106  loss_mask_5: 3.109  loss_mask_6: 3.105  loss_mask_7: 3.112  loss_mask_8: 3.106  time: 1.8425  data_time: 0.3970  lr: 8.2175e-05  max_mem: 17484M
[01/27 10:05:53] d2.utils.events INFO:  eta: 23:38:15  iter: 11779  total_loss: 30.09  loss_mask: 3.01  loss_mask_0: 3.022  loss_mask_1: 3.004  loss_mask_2: 3.004  loss_mask_3: 3.005  loss_mask_4: 3.007  loss_mask_5: 3.008  loss_mask_6: 3.011  loss_mask_7: 3.01  loss_mask_8: 3.009  time: 1.8424  data_time: 0.4084  lr: 8.2144e-05  max_mem: 17484M
[01/27 10:06:28] d2.utils.events INFO:  eta: 23:37:34  iter: 11799  total_loss: 30.25  loss_mask: 3.027  loss_mask_0: 3.017  loss_mask_1: 3.025  loss_mask_2: 3.026  loss_mask_3: 3.027  loss_mask_4: 3.019  loss_mask_5: 3.027  loss_mask_6: 3.024  loss_mask_7: 3.026  loss_mask_8: 3.029  time: 1.8423  data_time: 0.3883  lr: 8.2113e-05  max_mem: 17484M
[01/27 10:07:04] d2.utils.events INFO:  eta: 23:37:04  iter: 11819  total_loss: 31.32  loss_mask: 3.129  loss_mask_0: 3.149  loss_mask_1: 3.129  loss_mask_2: 3.129  loss_mask_3: 3.129  loss_mask_4: 3.133  loss_mask_5: 3.128  loss_mask_6: 3.13  loss_mask_7: 3.129  loss_mask_8: 3.132  time: 1.8422  data_time: 0.4112  lr: 8.2083e-05  max_mem: 17484M
[01/27 10:07:40] d2.utils.events INFO:  eta: 23:36:20  iter: 11839  total_loss: 32.08  loss_mask: 3.208  loss_mask_0: 3.229  loss_mask_1: 3.206  loss_mask_2: 3.205  loss_mask_3: 3.203  loss_mask_4: 3.204  loss_mask_5: 3.206  loss_mask_6: 3.203  loss_mask_7: 3.206  loss_mask_8: 3.212  time: 1.8421  data_time: 0.4108  lr: 8.2052e-05  max_mem: 17484M
[01/27 10:08:15] d2.utils.events INFO:  eta: 23:35:41  iter: 11859  total_loss: 29  loss_mask: 2.899  loss_mask_0: 2.93  loss_mask_1: 2.895  loss_mask_2: 2.895  loss_mask_3: 2.895  loss_mask_4: 2.896  loss_mask_5: 2.895  loss_mask_6: 2.895  loss_mask_7: 2.899  loss_mask_8: 2.897  time: 1.8419  data_time: 0.3995  lr: 8.2021e-05  max_mem: 17484M
[01/27 10:08:50] d2.utils.events INFO:  eta: 23:34:50  iter: 11879  total_loss: 28.65  loss_mask: 2.861  loss_mask_0: 2.899  loss_mask_1: 2.86  loss_mask_2: 2.862  loss_mask_3: 2.863  loss_mask_4: 2.862  loss_mask_5: 2.863  loss_mask_6: 2.861  loss_mask_7: 2.86  loss_mask_8: 2.862  time: 1.8418  data_time: 0.3795  lr: 8.1991e-05  max_mem: 17484M
[01/27 10:09:25] d2.utils.events INFO:  eta: 23:34:14  iter: 11899  total_loss: 29.27  loss_mask: 2.926  loss_mask_0: 2.959  loss_mask_1: 2.923  loss_mask_2: 2.923  loss_mask_3: 2.924  loss_mask_4: 2.924  loss_mask_5: 2.923  loss_mask_6: 2.924  loss_mask_7: 2.924  loss_mask_8: 2.924  time: 1.8416  data_time: 0.4065  lr: 8.196e-05  max_mem: 17484M
[01/27 10:10:00] d2.utils.events INFO:  eta: 23:32:50  iter: 11919  total_loss: 28.81  loss_mask: 2.88  loss_mask_0: 2.899  loss_mask_1: 2.878  loss_mask_2: 2.88  loss_mask_3: 2.88  loss_mask_4: 2.879  loss_mask_5: 2.88  loss_mask_6: 2.879  loss_mask_7: 2.878  loss_mask_8: 2.879  time: 1.8414  data_time: 0.3803  lr: 8.1929e-05  max_mem: 17484M
[01/27 10:10:35] d2.utils.events INFO:  eta: 23:32:31  iter: 11939  total_loss: 28.75  loss_mask: 2.867  loss_mask_0: 2.924  loss_mask_1: 2.868  loss_mask_2: 2.868  loss_mask_3: 2.869  loss_mask_4: 2.87  loss_mask_5: 2.868  loss_mask_6: 2.868  loss_mask_7: 2.866  loss_mask_8: 2.869  time: 1.8413  data_time: 0.4057  lr: 8.1899e-05  max_mem: 17484M
[01/27 10:11:11] d2.utils.events INFO:  eta: 23:31:45  iter: 11959  total_loss: 29.97  loss_mask: 2.994  loss_mask_0: 3.058  loss_mask_1: 2.993  loss_mask_2: 2.994  loss_mask_3: 2.995  loss_mask_4: 2.994  loss_mask_5: 2.994  loss_mask_6: 2.993  loss_mask_7: 2.993  loss_mask_8: 2.994  time: 1.8412  data_time: 0.4263  lr: 8.1868e-05  max_mem: 17484M
[01/27 10:11:46] d2.utils.events INFO:  eta: 23:31:02  iter: 11979  total_loss: 29.01  loss_mask: 2.898  loss_mask_0: 2.927  loss_mask_1: 2.897  loss_mask_2: 2.897  loss_mask_3: 2.898  loss_mask_4: 2.897  loss_mask_5: 2.897  loss_mask_6: 2.898  loss_mask_7: 2.896  loss_mask_8: 2.896  time: 1.8411  data_time: 0.4087  lr: 8.1837e-05  max_mem: 17484M
[01/27 10:12:22] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 10:12:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 10:12:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 10:18:53] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.998629035195922, 'error_1pix': 0.44558425672460145, 'error_3pix': 0.20276734970688504, 'mIoU': 5.3866722221275625, 'fwIoU': 17.075550047100247, 'IoU-0': nan, 'IoU-1': 68.59007641790832, 'IoU-2': 3.0320467100092197, 'IoU-3': 2.9324799852735004, 'IoU-4': 2.505941020158981, 'IoU-5': 2.399205563608378, 'IoU-6': 2.5178078020218377, 'IoU-7': 2.5273165574735983, 'IoU-8': 4.180938116641281, 'IoU-9': 12.239404235830314, 'IoU-10': 18.25431267633588, 'IoU-11': 24.0406263855388, 'IoU-12': 22.168134018893674, 'IoU-13': 20.719052103535013, 'IoU-14': 19.275314957634517, 'IoU-15': 19.923749973502513, 'IoU-16': 19.540764535275063, 'IoU-17': 16.635082609879678, 'IoU-18': 16.32674001873444, 'IoU-19': 15.760884289139055, 'IoU-20': 16.742025166859488, 'IoU-21': 17.54322428036371, 'IoU-22': 17.42432809747173, 'IoU-23': 15.628319989408428, 'IoU-24': 16.13308613806119, 'IoU-25': 15.931454717849888, 'IoU-26': 14.539657736597583, 'IoU-27': 14.495044140535013, 'IoU-28': 13.24739789235369, 'IoU-29': 14.158893076142299, 'IoU-30': 13.88934840674649, 'IoU-31': 14.745776870647747, 'IoU-32': 14.814103050425894, 'IoU-33': 13.975242045238891, 'IoU-34': 13.737568582892933, 'IoU-35': 13.6836632058694, 'IoU-36': 13.0536626317225, 'IoU-37': 11.57352586121854, 'IoU-38': 10.790984500408697, 'IoU-39': 10.22754716434109, 'IoU-40': 9.786893073266247, 'IoU-41': 9.490177165277192, 'IoU-42': 9.101627803330732, 'IoU-43': 9.44287787295028, 'IoU-44': 9.40490519181994, 'IoU-45': 9.188917612272402, 'IoU-46': 9.052710670966482, 'IoU-47': 8.446631523480743, 'IoU-48': 8.096645486405144, 'IoU-49': 7.574168049856636, 'IoU-50': 7.69463709085273, 'IoU-51': 6.9562118119001, 'IoU-52': 6.39101454579518, 'IoU-53': 6.377354573873631, 'IoU-54': 6.508613056009013, 'IoU-55': 5.822439495405009, 'IoU-56': 5.661715263106277, 'IoU-57': 5.804323522208194, 'IoU-58': 5.723019246184689, 'IoU-59': 5.45020969793244, 'IoU-60': 5.275102514890807, 'IoU-61': 4.934073121134828, 'IoU-62': 4.90575696847404, 'IoU-63': 4.815927077546355, 'IoU-64': 4.593570888837478, 'IoU-65': 4.545438725613133, 'IoU-66': 4.398525680273149, 'IoU-67': 4.067989080982712, 'IoU-68': 3.9722716220843384, 'IoU-69': 4.1767929456370245, 'IoU-70': 4.230888091350091, 'IoU-71': 3.9326974970827475, 'IoU-72': 3.7619515839005366, 'IoU-73': 3.968908253819618, 'IoU-74': 3.8902372111534715, 'IoU-75': 3.8228163710726117, 'IoU-76': 3.7532683501587414, 'IoU-77': 3.643578316183649, 'IoU-78': 3.5703242163404125, 'IoU-79': 3.5023062740901425, 'IoU-80': 3.4654569160643427, 'IoU-81': 3.534356178694767, 'IoU-82': 3.38377644579827, 'IoU-83': 3.499675129815293, 'IoU-84': 3.405898037344289, 'IoU-85': 3.3047864193915832, 'IoU-86': 3.2419099178035147, 'IoU-87': 3.05545538324612, 'IoU-88': 2.9708313562411286, 'IoU-89': 3.0728880683281163, 'IoU-90': 2.990864443427782, 'IoU-91': 2.9056984178950347, 'IoU-92': 2.857302695067202, 'IoU-93': 2.9085451107159477, 'IoU-94': 2.90543900806477, 'IoU-95': 2.8335955143626763, 'IoU-96': 2.81119553513313, 'IoU-97': 2.8210459359261, 'IoU-98': 2.5550157813103733, 'IoU-99': 2.5444344346601993, 'IoU-100': 2.4122086583627693, 'IoU-101': 2.546972152995503, 'IoU-102': 2.454063950989008, 'IoU-103': 2.436690610269715, 'IoU-104': 2.4091323926603803, 'IoU-105': 2.336859279717703, 'IoU-106': 2.3920342482003054, 'IoU-107': 2.2863417234916175, 'IoU-108': 2.4479521631591, 'IoU-109': 2.5488582609066226, 'IoU-110': 2.4450224469023016, 'IoU-111': 2.205306164336546, 'IoU-112': 2.2185450130063034, 'IoU-113': 2.1895718456201885, 'IoU-114': 2.2172583789944813, 'IoU-115': 2.1383693744856354, 'IoU-116': 2.111729450513087, 'IoU-117': 1.988147967928262, 'IoU-118': 1.8888356473288004, 'IoU-119': 1.9657333062738191, 'IoU-120': 2.045572806080521, 'IoU-121': 2.1174184602247794, 'IoU-122': 2.0022638789484635, 'IoU-123': 1.9387771685423418, 'IoU-124': 1.8986141009053843, 'IoU-125': 1.9439980906627599, 'IoU-126': 1.9146516764605956, 'IoU-127': 2.1171625586673968, 'IoU-128': 1.906158876027216, 'IoU-129': 1.815450806656187, 'IoU-130': 1.7465888954317788, 'IoU-131': 1.8047557758307056, 'IoU-132': 1.7818942668219004, 'IoU-133': 1.8829382086755597, 'IoU-134': 1.8144587585833638, 'IoU-135': 1.7473016510727726, 'IoU-136': 1.720626351427123, 'IoU-137': 1.656351318713757, 'IoU-138': 1.55165347716802, 'IoU-139': 1.6472970753237943, 'IoU-140': 1.6022697082982356, 'IoU-141': 1.6338707146524694, 'IoU-142': 1.5406932062711343, 'IoU-143': 1.7588388963737926, 'IoU-144': 1.5993807859726568, 'IoU-145': 1.7500659158537046, 'IoU-146': 2.057338381052846, 'IoU-147': 2.0089140254891404, 'IoU-148': 1.9802765156264672, 'IoU-149': 1.893452821654907, 'IoU-150': 1.928093213270756, 'IoU-151': 2.0170130887798696, 'IoU-152': 2.0535888542412533, 'IoU-153': 1.8657874525234885, 'IoU-154': 1.6261652538791078, 'IoU-155': 1.6376426193808424, 'IoU-156': 1.7711413102871811, 'IoU-157': 1.7290024607467178, 'IoU-158': 1.6771167244703222, 'IoU-159': 1.7426213202632646, 'IoU-160': 1.9450913990361016, 'IoU-161': 1.9209444429732807, 'IoU-162': 1.7573966898965236, 'IoU-163': 2.0055612571598993, 'IoU-164': 1.872490425517817, 'IoU-165': 1.8065295292162713, 'IoU-166': 1.6487041547017558, 'IoU-167': 1.6174448056963238, 'IoU-168': 1.5287985048076518, 'IoU-169': 1.4012923218375148, 'IoU-170': 1.4729797531172701, 'IoU-171': 1.4762518031678011, 'IoU-172': 1.5715029053039415, 'IoU-173': 1.5365785113385193, 'IoU-174': 1.5962911139056661, 'IoU-175': 1.8107894054083578, 'IoU-176': 1.7699615471612757, 'IoU-177': 1.6043365437882071, 'IoU-178': 1.6712867268770433, 'IoU-179': 1.938182577956473, 'IoU-180': 1.9920973893977116, 'IoU-181': 1.2443357425365584, 'IoU-182': 1.1803476112833107, 'IoU-183': 1.157222665602554, 'IoU-184': 0.74275055780075, 'IoU-185': 0.5726493489234635, 'IoU-186': 0.8518603407441363, 'IoU-187': 0.7905625337428397, 'IoU-188': 0.564556594777257, 'IoU-189': 0.5232384468852989, 'IoU-190': 0.45202968446904307, 'IoU-191': 0.2972852417086295, 'IoU-192': 0.029127981066812303, 'mACC': 9.64749162142632, 'pACC': 24.852680341570057, 'ACC-0': nan, 'ACC-1': 69.79872050877411, 'ACC-2': 7.0898157844912255, 'ACC-3': 16.49170077018886, 'ACC-4': 12.657143201959938, 'ACC-5': 11.861884373377437, 'ACC-6': 12.034761493316225, 'ACC-7': 12.595943132386026, 'ACC-8': 9.870947969445917, 'ACC-9': 20.082891801751547, 'ACC-10': 33.84078670275837, 'ACC-11': 38.37186252078806, 'ACC-12': 35.29606948111566, 'ACC-13': 33.32113221342944, 'ACC-14': 30.81393777965041, 'ACC-15': 32.76536711779997, 'ACC-16': 32.60455331531006, 'ACC-17': 29.889012078579917, 'ACC-18': 27.863512612243014, 'ACC-19': 26.56039645380151, 'ACC-20': 28.751361608814406, 'ACC-21': 31.127303174156772, 'ACC-22': 29.75834494998567, 'ACC-23': 27.05616525886344, 'ACC-24': 28.380249343514897, 'ACC-25': 29.16718469388437, 'ACC-26': 27.15019998129808, 'ACC-27': 25.8695587816103, 'ACC-28': 23.953692030056935, 'ACC-29': 24.93658971801505, 'ACC-30': 24.74939854091476, 'ACC-31': 25.785339765595083, 'ACC-32': 25.87794066400202, 'ACC-33': 24.929387804642072, 'ACC-34': 25.360565736596552, 'ACC-35': 25.266170312792102, 'ACC-36': 23.895196491233456, 'ACC-37': 21.732026157728317, 'ACC-38': 20.00162071247555, 'ACC-39': 18.74412138329581, 'ACC-40': 17.653044918350005, 'ACC-41': 17.548867530076524, 'ACC-42': 16.99451197290514, 'ACC-43': 17.70179873694015, 'ACC-44': 17.095361417856, 'ACC-45': 16.72893623347873, 'ACC-46': 17.048919652428697, 'ACC-47': 16.077576928488792, 'ACC-48': 15.421402342138697, 'ACC-49': 14.368315338520162, 'ACC-50': 14.46751029783157, 'ACC-51': 13.223555844616566, 'ACC-52': 12.115755267399297, 'ACC-53': 12.103769403502241, 'ACC-54': 12.164624088982045, 'ACC-55': 10.861595225068461, 'ACC-56': 10.621160997996526, 'ACC-57': 10.665179000084358, 'ACC-58': 10.564492734951445, 'ACC-59': 10.162791331395852, 'ACC-60': 9.9493632436573, 'ACC-61': 9.390333521197487, 'ACC-62': 9.345862281926054, 'ACC-63': 9.279041180993024, 'ACC-64': 8.851553364462085, 'ACC-65': 8.784823286365658, 'ACC-66': 8.526200199425109, 'ACC-67': 7.9821733852221755, 'ACC-68': 7.815048972086175, 'ACC-69': 8.030969896427713, 'ACC-70': 8.085888304918246, 'ACC-71': 7.665663123853649, 'ACC-72': 7.403088965447811, 'ACC-73': 7.822866396560723, 'ACC-74': 7.649041909038355, 'ACC-75': 7.474433217325024, 'ACC-76': 7.187153551341018, 'ACC-77': 7.099867498890367, 'ACC-78': 6.997768077496361, 'ACC-79': 6.830128268315919, 'ACC-80': 6.719954405676466, 'ACC-81': 6.789257155266881, 'ACC-82': 6.490655129884434, 'ACC-83': 6.600142302588546, 'ACC-84': 6.417524846566519, 'ACC-85': 6.236642313263185, 'ACC-86': 6.089943774024109, 'ACC-87': 5.723145693063153, 'ACC-88': 5.500449258657231, 'ACC-89': 5.6546968868595515, 'ACC-90': 5.462270806888976, 'ACC-91': 5.340611980020689, 'ACC-92': 5.287327980110343, 'ACC-93': 5.3775749269547, 'ACC-94': 5.346690556646255, 'ACC-95': 5.180439388168188, 'ACC-96': 5.118146624014612, 'ACC-97': 5.087377151428333, 'ACC-98': 4.6378005195336005, 'ACC-99': 4.612151122294156, 'ACC-100': 4.37502673546356, 'ACC-101': 4.622360430541651, 'ACC-102': 4.492917825204482, 'ACC-103': 4.4608026493018755, 'ACC-104': 4.418509136519023, 'ACC-105': 4.314871648970988, 'ACC-106': 4.4285134771211085, 'ACC-107': 4.217224956376818, 'ACC-108': 4.449060323726305, 'ACC-109': 4.611932534164537, 'ACC-110': 4.495826620084675, 'ACC-111': 4.067654042880321, 'ACC-112': 4.125384791453542, 'ACC-113': 4.0352948723950615, 'ACC-114': 4.106163381373959, 'ACC-115': 3.9387037120562898, 'ACC-116': 3.917717747932293, 'ACC-117': 3.6776104673449987, 'ACC-118': 3.546798774151372, 'ACC-119': 3.6433477144047037, 'ACC-120': 3.755705837084515, 'ACC-121': 3.899298109988658, 'ACC-122': 3.7217771990904542, 'ACC-123': 3.64952266667193, 'ACC-124': 3.662615916778053, 'ACC-125': 3.7121898531918296, 'ACC-126': 3.679450632519422, 'ACC-127': 4.020514629610593, 'ACC-128': 3.617736991868431, 'ACC-129': 3.4221512978182793, 'ACC-130': 3.3130999398931493, 'ACC-131': 3.4088228120578474, 'ACC-132': 3.312188141937516, 'ACC-133': 3.4721400042186343, 'ACC-134': 3.318707453683757, 'ACC-135': 3.2232341371643574, 'ACC-136': 3.1720992126351097, 'ACC-137': 3.1091796244438896, 'ACC-138': 2.910040739142574, 'ACC-139': 3.050289689797853, 'ACC-140': 2.927179150785092, 'ACC-141': 2.961769824518883, 'ACC-142': 2.8012481431120264, 'ACC-143': 3.1732124901266747, 'ACC-144': 2.8253712107263924, 'ACC-145': 2.992295864561782, 'ACC-146': 3.5111399484583186, 'ACC-147': 3.4063000533902827, 'ACC-148': 3.3477182209632805, 'ACC-149': 3.239340205767368, 'ACC-150': 3.289038241649199, 'ACC-151': 3.4209477361720086, 'ACC-152': 3.4480578595994333, 'ACC-153': 3.2492785488525495, 'ACC-154': 2.8235512377033976, 'ACC-155': 2.858625488260185, 'ACC-156': 3.10092552012835, 'ACC-157': 3.014398937263426, 'ACC-158': 2.9197069989979254, 'ACC-159': 3.0228321507304727, 'ACC-160': 3.33928573953345, 'ACC-161': 3.2595569485166087, 'ACC-162': 3.027165342616561, 'ACC-163': 3.4952548674298014, 'ACC-164': 3.3605784095323417, 'ACC-165': 3.2548100288744677, 'ACC-166': 3.046033843328123, 'ACC-167': 3.0196480378020603, 'ACC-168': 2.8637142123642962, 'ACC-169': 2.5996816644701397, 'ACC-170': 2.6781863584652164, 'ACC-171': 2.630437898001404, 'ACC-172': 2.74703187549901, 'ACC-173': 2.6649679323115834, 'ACC-174': 2.688683291008014, 'ACC-175': 2.94279733108458, 'ACC-176': 2.782908799268391, 'ACC-177': 2.4381462998554393, 'ACC-178': 2.4829116235745192, 'ACC-179': 2.7870879204535997, 'ACC-180': 2.7702197669568234, 'ACC-181': 1.719137279805883, 'ACC-182': 1.543064980391599, 'ACC-183': 1.434794593486645, 'ACC-184': 0.8908113108258943, 'ACC-185': 0.6573214842892308, 'ACC-186': 0.9487320694602344, 'ACC-187': 0.8538591821921123, 'ACC-188': 0.5991363754520653, 'ACC-189': 0.5490454009418814, 'ACC-190': 0.4666740158637669, 'ACC-191': 0.30170609168934476, 'ACC-192': 0.029478625162274164})])
[01/27 10:18:53] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 10:18:53] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 10:18:53] d2.evaluation.testing INFO: copypaste: 2.9986,0.4456,0.2028,5.3867,17.0756,9.6475,24.8527
[01/27 10:18:53] d2.utils.events INFO:  eta: 23:30:35  iter: 11999  total_loss: 29.74  loss_mask: 2.968  loss_mask_0: 3.008  loss_mask_1: 2.97  loss_mask_2: 2.969  loss_mask_3: 2.969  loss_mask_4: 2.969  loss_mask_5: 2.97  loss_mask_6: 2.969  loss_mask_7: 2.97  loss_mask_8: 2.97  time: 1.8410  data_time: 0.4037  lr: 8.1807e-05  max_mem: 17484M
[01/27 10:19:28] d2.utils.events INFO:  eta: 23:29:59  iter: 12019  total_loss: 28.18  loss_mask: 2.815  loss_mask_0: 2.848  loss_mask_1: 2.814  loss_mask_2: 2.816  loss_mask_3: 2.814  loss_mask_4: 2.815  loss_mask_5: 2.814  loss_mask_6: 2.813  loss_mask_7: 2.813  loss_mask_8: 2.814  time: 1.8408  data_time: 0.3978  lr: 8.1776e-05  max_mem: 17484M
[01/27 10:20:03] d2.utils.events INFO:  eta: 23:29:06  iter: 12039  total_loss: 26.89  loss_mask: 2.684  loss_mask_0: 2.743  loss_mask_1: 2.682  loss_mask_2: 2.682  loss_mask_3: 2.685  loss_mask_4: 2.684  loss_mask_5: 2.683  loss_mask_6: 2.683  loss_mask_7: 2.683  loss_mask_8: 2.683  time: 1.8407  data_time: 0.3725  lr: 8.1745e-05  max_mem: 17484M
[01/27 10:20:38] d2.utils.events INFO:  eta: 23:28:42  iter: 12059  total_loss: 29.21  loss_mask: 2.918  loss_mask_0: 2.95  loss_mask_1: 2.918  loss_mask_2: 2.917  loss_mask_3: 2.919  loss_mask_4: 2.916  loss_mask_5: 2.917  loss_mask_6: 2.917  loss_mask_7: 2.918  loss_mask_8: 2.918  time: 1.8405  data_time: 0.4181  lr: 8.1715e-05  max_mem: 17484M
[01/27 10:21:14] d2.utils.events INFO:  eta: 23:28:14  iter: 12079  total_loss: 29.98  loss_mask: 2.993  loss_mask_0: 3.026  loss_mask_1: 2.994  loss_mask_2: 2.992  loss_mask_3: 2.994  loss_mask_4: 2.992  loss_mask_5: 2.994  loss_mask_6: 2.992  loss_mask_7: 2.993  loss_mask_8: 2.994  time: 1.8404  data_time: 0.4055  lr: 8.1684e-05  max_mem: 17484M
[01/27 10:21:49] d2.utils.events INFO:  eta: 23:27:49  iter: 12099  total_loss: 29.11  loss_mask: 2.913  loss_mask_0: 2.927  loss_mask_1: 2.909  loss_mask_2: 2.91  loss_mask_3: 2.908  loss_mask_4: 2.908  loss_mask_5: 2.909  loss_mask_6: 2.91  loss_mask_7: 2.911  loss_mask_8: 2.914  time: 1.8403  data_time: 0.4121  lr: 8.1653e-05  max_mem: 17484M
[01/27 10:22:25] d2.utils.events INFO:  eta: 23:27:14  iter: 12119  total_loss: 34.5  loss_mask: 3.452  loss_mask_0: 3.437  loss_mask_1: 3.449  loss_mask_2: 3.452  loss_mask_3: 3.451  loss_mask_4: 3.451  loss_mask_5: 3.453  loss_mask_6: 3.451  loss_mask_7: 3.452  loss_mask_8: 3.451  time: 1.8402  data_time: 0.4150  lr: 8.1623e-05  max_mem: 17484M
[01/27 10:23:00] d2.utils.events INFO:  eta: 23:26:49  iter: 12139  total_loss: 36.66  loss_mask: 3.616  loss_mask_0: 3.803  loss_mask_1: 3.636  loss_mask_2: 3.638  loss_mask_3: 3.653  loss_mask_4: 3.629  loss_mask_5: 3.626  loss_mask_6: 3.639  loss_mask_7: 3.618  loss_mask_8: 3.617  time: 1.8401  data_time: 0.4065  lr: 8.1592e-05  max_mem: 17484M
[01/27 10:23:36] d2.utils.events INFO:  eta: 23:25:48  iter: 12159  total_loss: 29.12  loss_mask: 2.907  loss_mask_0: 2.933  loss_mask_1: 2.91  loss_mask_2: 2.911  loss_mask_3: 2.909  loss_mask_4: 2.908  loss_mask_5: 2.914  loss_mask_6: 2.911  loss_mask_7: 2.909  loss_mask_8: 2.913  time: 1.8400  data_time: 0.4022  lr: 8.1561e-05  max_mem: 17484M
[01/27 10:24:11] d2.utils.events INFO:  eta: 23:25:28  iter: 12179  total_loss: 33.87  loss_mask: 3.388  loss_mask_0: 3.392  loss_mask_1: 3.384  loss_mask_2: 3.387  loss_mask_3: 3.388  loss_mask_4: 3.386  loss_mask_5: 3.386  loss_mask_6: 3.387  loss_mask_7: 3.385  loss_mask_8: 3.387  time: 1.8399  data_time: 0.3940  lr: 8.1531e-05  max_mem: 17484M
[01/27 10:24:46] d2.utils.events INFO:  eta: 23:24:38  iter: 12199  total_loss: 34.45  loss_mask: 3.447  loss_mask_0: 3.462  loss_mask_1: 3.462  loss_mask_2: 3.456  loss_mask_3: 3.457  loss_mask_4: 3.461  loss_mask_5: 3.457  loss_mask_6: 3.463  loss_mask_7: 3.4  loss_mask_8: 3.457  time: 1.8397  data_time: 0.3923  lr: 8.15e-05  max_mem: 17484M
[01/27 10:25:21] d2.utils.events INFO:  eta: 23:24:04  iter: 12219  total_loss: 31.77  loss_mask: 3.169  loss_mask_0: 3.202  loss_mask_1: 3.167  loss_mask_2: 3.169  loss_mask_3: 3.168  loss_mask_4: 3.168  loss_mask_5: 3.167  loss_mask_6: 3.168  loss_mask_7: 3.191  loss_mask_8: 3.167  time: 1.8396  data_time: 0.4046  lr: 8.1469e-05  max_mem: 17484M
[01/27 10:25:57] d2.utils.events INFO:  eta: 23:23:42  iter: 12239  total_loss: 29.3  loss_mask: 2.925  loss_mask_0: 2.967  loss_mask_1: 2.928  loss_mask_2: 2.929  loss_mask_3: 2.928  loss_mask_4: 2.927  loss_mask_5: 2.924  loss_mask_6: 2.926  loss_mask_7: 2.934  loss_mask_8: 2.924  time: 1.8395  data_time: 0.4202  lr: 8.1439e-05  max_mem: 17484M
[01/27 10:26:32] d2.utils.events INFO:  eta: 23:23:27  iter: 12259  total_loss: 30.3  loss_mask: 3.029  loss_mask_0: 3.046  loss_mask_1: 3.028  loss_mask_2: 3.029  loss_mask_3: 3.028  loss_mask_4: 3.025  loss_mask_5: 3.032  loss_mask_6: 3.026  loss_mask_7: 3.024  loss_mask_8: 3.03  time: 1.8394  data_time: 0.4133  lr: 8.1408e-05  max_mem: 17484M
[01/27 10:27:07] d2.utils.events INFO:  eta: 23:22:21  iter: 12279  total_loss: 28.89  loss_mask: 2.879  loss_mask_0: 2.986  loss_mask_1: 2.879  loss_mask_2: 2.881  loss_mask_3: 2.877  loss_mask_4: 2.883  loss_mask_5: 2.882  loss_mask_6: 2.88  loss_mask_7: 2.873  loss_mask_8: 2.874  time: 1.8392  data_time: 0.4068  lr: 8.1377e-05  max_mem: 17484M
[01/27 10:27:43] d2.utils.events INFO:  eta: 23:22:29  iter: 12299  total_loss: 28.72  loss_mask: 2.867  loss_mask_0: 2.891  loss_mask_1: 2.868  loss_mask_2: 2.866  loss_mask_3: 2.868  loss_mask_4: 2.868  loss_mask_5: 2.868  loss_mask_6: 2.868  loss_mask_7: 2.869  loss_mask_8: 2.868  time: 1.8391  data_time: 0.4068  lr: 8.1346e-05  max_mem: 17484M
[01/27 10:28:18] d2.utils.events INFO:  eta: 23:21:48  iter: 12319  total_loss: 29.31  loss_mask: 2.926  loss_mask_0: 2.964  loss_mask_1: 2.926  loss_mask_2: 2.927  loss_mask_3: 2.926  loss_mask_4: 2.929  loss_mask_5: 2.929  loss_mask_6: 2.927  loss_mask_7: 2.925  loss_mask_8: 2.93  time: 1.8390  data_time: 0.4041  lr: 8.1316e-05  max_mem: 17484M
[01/27 10:28:54] d2.utils.events INFO:  eta: 23:21:23  iter: 12339  total_loss: 27.9  loss_mask: 2.787  loss_mask_0: 2.83  loss_mask_1: 2.784  loss_mask_2: 2.785  loss_mask_3: 2.784  loss_mask_4: 2.786  loss_mask_5: 2.787  loss_mask_6: 2.785  loss_mask_7: 2.785  loss_mask_8: 2.786  time: 1.8389  data_time: 0.4027  lr: 8.1285e-05  max_mem: 17484M
[01/27 10:29:29] d2.utils.events INFO:  eta: 23:20:49  iter: 12359  total_loss: 29.47  loss_mask: 2.943  loss_mask_0: 2.997  loss_mask_1: 2.94  loss_mask_2: 2.941  loss_mask_3: 2.94  loss_mask_4: 2.94  loss_mask_5: 2.943  loss_mask_6: 2.938  loss_mask_7: 2.941  loss_mask_8: 2.94  time: 1.8388  data_time: 0.4141  lr: 8.1254e-05  max_mem: 17484M
[01/27 10:30:04] d2.utils.events INFO:  eta: 23:20:13  iter: 12379  total_loss: 26.79  loss_mask: 2.678  loss_mask_0: 2.69  loss_mask_1: 2.68  loss_mask_2: 2.678  loss_mask_3: 2.678  loss_mask_4: 2.678  loss_mask_5: 2.678  loss_mask_6: 2.679  loss_mask_7: 2.677  loss_mask_8: 2.679  time: 1.8387  data_time: 0.3936  lr: 8.1224e-05  max_mem: 17484M
[01/27 10:30:40] d2.utils.events INFO:  eta: 23:19:18  iter: 12399  total_loss: 31.65  loss_mask: 3.164  loss_mask_0: 3.166  loss_mask_1: 3.163  loss_mask_2: 3.164  loss_mask_3: 3.163  loss_mask_4: 3.162  loss_mask_5: 3.163  loss_mask_6: 3.163  loss_mask_7: 3.163  loss_mask_8: 3.166  time: 1.8385  data_time: 0.4127  lr: 8.1193e-05  max_mem: 17484M
[01/27 10:31:15] d2.utils.events INFO:  eta: 23:19:21  iter: 12419  total_loss: 33.19  loss_mask: 3.32  loss_mask_0: 3.333  loss_mask_1: 3.317  loss_mask_2: 3.317  loss_mask_3: 3.318  loss_mask_4: 3.317  loss_mask_5: 3.319  loss_mask_6: 3.317  loss_mask_7: 3.318  loss_mask_8: 3.318  time: 1.8384  data_time: 0.4358  lr: 8.1162e-05  max_mem: 17484M
[01/27 10:31:51] d2.utils.events INFO:  eta: 23:18:18  iter: 12439  total_loss: 30.01  loss_mask: 2.997  loss_mask_0: 3.027  loss_mask_1: 2.997  loss_mask_2: 2.996  loss_mask_3: 2.996  loss_mask_4: 2.999  loss_mask_5: 2.999  loss_mask_6: 3  loss_mask_7: 2.999  loss_mask_8: 2.997  time: 1.8383  data_time: 0.4086  lr: 8.1132e-05  max_mem: 17484M
[01/27 10:32:26] d2.utils.events INFO:  eta: 23:17:49  iter: 12459  total_loss: 28.83  loss_mask: 2.884  loss_mask_0: 2.886  loss_mask_1: 2.883  loss_mask_2: 2.884  loss_mask_3: 2.883  loss_mask_4: 2.881  loss_mask_5: 2.881  loss_mask_6: 2.884  loss_mask_7: 2.885  loss_mask_8: 2.884  time: 1.8382  data_time: 0.4174  lr: 8.1101e-05  max_mem: 17484M
[01/27 10:33:01] d2.utils.events INFO:  eta: 23:17:40  iter: 12479  total_loss: 34.13  loss_mask: 3.398  loss_mask_0: 3.519  loss_mask_1: 3.398  loss_mask_2: 3.398  loss_mask_3: 3.4  loss_mask_4: 3.401  loss_mask_5: 3.403  loss_mask_6: 3.395  loss_mask_7: 3.399  loss_mask_8: 3.398  time: 1.8381  data_time: 0.4089  lr: 8.107e-05  max_mem: 17484M
[01/27 10:33:37] d2.utils.events INFO:  eta: 23:17:08  iter: 12499  total_loss: 33.5  loss_mask: 3.341  loss_mask_0: 3.494  loss_mask_1: 3.34  loss_mask_2: 3.346  loss_mask_3: 3.348  loss_mask_4: 3.344  loss_mask_5: 3.341  loss_mask_6: 3.341  loss_mask_7: 3.344  loss_mask_8: 3.342  time: 1.8380  data_time: 0.4042  lr: 8.1039e-05  max_mem: 17484M
[01/27 10:34:12] d2.utils.events INFO:  eta: 23:16:33  iter: 12519  total_loss: 33.38  loss_mask: 3.314  loss_mask_0: 3.606  loss_mask_1: 3.318  loss_mask_2: 3.316  loss_mask_3: 3.314  loss_mask_4: 3.314  loss_mask_5: 3.317  loss_mask_6: 3.321  loss_mask_7: 3.31  loss_mask_8: 3.313  time: 1.8379  data_time: 0.4123  lr: 8.1009e-05  max_mem: 17484M
[01/27 10:34:48] d2.utils.events INFO:  eta: 23:16:00  iter: 12539  total_loss: 29.95  loss_mask: 2.993  loss_mask_0: 3.03  loss_mask_1: 2.991  loss_mask_2: 2.992  loss_mask_3: 2.992  loss_mask_4: 2.993  loss_mask_5: 2.992  loss_mask_6: 2.993  loss_mask_7: 2.991  loss_mask_8: 2.99  time: 1.8378  data_time: 0.4101  lr: 8.0978e-05  max_mem: 17484M
[01/27 10:35:23] d2.utils.events INFO:  eta: 23:15:27  iter: 12559  total_loss: 31.78  loss_mask: 3.156  loss_mask_0: 3.25  loss_mask_1: 3.149  loss_mask_2: 3.152  loss_mask_3: 3.154  loss_mask_4: 3.153  loss_mask_5: 3.161  loss_mask_6: 3.155  loss_mask_7: 3.157  loss_mask_8: 3.165  time: 1.8377  data_time: 0.4003  lr: 8.0947e-05  max_mem: 17484M
[01/27 10:35:58] d2.utils.events INFO:  eta: 23:14:50  iter: 12579  total_loss: 30.23  loss_mask: 3.018  loss_mask_0: 3.056  loss_mask_1: 3.017  loss_mask_2: 3.017  loss_mask_3: 3.015  loss_mask_4: 3.018  loss_mask_5: 3.016  loss_mask_6: 3.016  loss_mask_7: 3.017  loss_mask_8: 3.016  time: 1.8375  data_time: 0.3898  lr: 8.0917e-05  max_mem: 17484M
[01/27 10:36:35] d2.utils.events INFO:  eta: 23:14:29  iter: 12599  total_loss: 34.33  loss_mask: 3.432  loss_mask_0: 3.44  loss_mask_1: 3.431  loss_mask_2: 3.433  loss_mask_3: 3.432  loss_mask_4: 3.433  loss_mask_5: 3.433  loss_mask_6: 3.433  loss_mask_7: 3.431  loss_mask_8: 3.433  time: 1.8375  data_time: 0.4092  lr: 8.0886e-05  max_mem: 17484M
[01/27 10:37:14] d2.utils.events INFO:  eta: 23:15:18  iter: 12619  total_loss: 31.77  loss_mask: 3.176  loss_mask_0: 3.196  loss_mask_1: 3.176  loss_mask_2: 3.178  loss_mask_3: 3.176  loss_mask_4: 3.174  loss_mask_5: 3.177  loss_mask_6: 3.174  loss_mask_7: 3.175  loss_mask_8: 3.177  time: 1.8377  data_time: 0.4616  lr: 8.0855e-05  max_mem: 17484M
[01/27 10:37:54] d2.utils.events INFO:  eta: 23:16:10  iter: 12639  total_loss: 32.71  loss_mask: 3.266  loss_mask_0: 3.311  loss_mask_1: 3.265  loss_mask_2: 3.268  loss_mask_3: 3.268  loss_mask_4: 3.269  loss_mask_5: 3.267  loss_mask_6: 3.262  loss_mask_7: 3.267  loss_mask_8: 3.267  time: 1.8380  data_time: 0.4685  lr: 8.0824e-05  max_mem: 17484M
[01/27 10:38:34] d2.utils.events INFO:  eta: 23:17:11  iter: 12659  total_loss: 31.22  loss_mask: 3.121  loss_mask_0: 3.147  loss_mask_1: 3.12  loss_mask_2: 3.12  loss_mask_3: 3.117  loss_mask_4: 3.119  loss_mask_5: 3.119  loss_mask_6: 3.122  loss_mask_7: 3.12  loss_mask_8: 3.118  time: 1.8382  data_time: 0.4705  lr: 8.0794e-05  max_mem: 17484M
[01/27 10:39:13] d2.utils.events INFO:  eta: 23:17:37  iter: 12679  total_loss: 30.46  loss_mask: 3.044  loss_mask_0: 3.082  loss_mask_1: 3.043  loss_mask_2: 3.044  loss_mask_3: 3.043  loss_mask_4: 3.041  loss_mask_5: 3.042  loss_mask_6: 3.04  loss_mask_7: 3.042  loss_mask_8: 3.043  time: 1.8384  data_time: 0.4546  lr: 8.0763e-05  max_mem: 17484M
[01/27 10:39:48] d2.utils.events INFO:  eta: 23:16:31  iter: 12699  total_loss: 27.78  loss_mask: 2.772  loss_mask_0: 2.804  loss_mask_1: 2.774  loss_mask_2: 2.774  loss_mask_3: 2.774  loss_mask_4: 2.774  loss_mask_5: 2.773  loss_mask_6: 2.773  loss_mask_7: 2.773  loss_mask_8: 2.773  time: 1.8382  data_time: 0.3854  lr: 8.0732e-05  max_mem: 17484M
[01/27 10:40:23] d2.utils.events INFO:  eta: 23:15:01  iter: 12719  total_loss: 26.96  loss_mask: 2.695  loss_mask_0: 2.714  loss_mask_1: 2.696  loss_mask_2: 2.696  loss_mask_3: 2.695  loss_mask_4: 2.695  loss_mask_5: 2.694  loss_mask_6: 2.694  loss_mask_7: 2.694  loss_mask_8: 2.694  time: 1.8381  data_time: 0.3816  lr: 8.0702e-05  max_mem: 17484M
[01/27 10:40:58] d2.utils.events INFO:  eta: 23:13:34  iter: 12739  total_loss: 27.72  loss_mask: 2.768  loss_mask_0: 2.811  loss_mask_1: 2.767  loss_mask_2: 2.768  loss_mask_3: 2.769  loss_mask_4: 2.766  loss_mask_5: 2.767  loss_mask_6: 2.768  loss_mask_7: 2.768  loss_mask_8: 2.768  time: 1.8380  data_time: 0.4242  lr: 8.0671e-05  max_mem: 17484M
[01/27 10:41:35] d2.utils.events INFO:  eta: 23:14:29  iter: 12759  total_loss: 28.45  loss_mask: 2.842  loss_mask_0: 2.872  loss_mask_1: 2.844  loss_mask_2: 2.844  loss_mask_3: 2.843  loss_mask_4: 2.845  loss_mask_5: 2.842  loss_mask_6: 2.842  loss_mask_7: 2.843  loss_mask_8: 2.843  time: 1.8379  data_time: 0.4338  lr: 8.064e-05  max_mem: 17484M
[01/27 10:42:11] d2.utils.events INFO:  eta: 23:13:59  iter: 12779  total_loss: 29.29  loss_mask: 2.926  loss_mask_0: 2.963  loss_mask_1: 2.925  loss_mask_2: 2.925  loss_mask_3: 2.925  loss_mask_4: 2.925  loss_mask_5: 2.927  loss_mask_6: 2.927  loss_mask_7: 2.925  loss_mask_8: 2.927  time: 1.8379  data_time: 0.4248  lr: 8.0609e-05  max_mem: 17484M
[01/27 10:42:50] d2.utils.events INFO:  eta: 23:14:58  iter: 12799  total_loss: 28.77  loss_mask: 2.87  loss_mask_0: 2.923  loss_mask_1: 2.87  loss_mask_2: 2.871  loss_mask_3: 2.871  loss_mask_4: 2.872  loss_mask_5: 2.87  loss_mask_6: 2.87  loss_mask_7: 2.869  loss_mask_8: 2.87  time: 1.8381  data_time: 0.4346  lr: 8.0579e-05  max_mem: 17484M
[01/27 10:43:30] d2.utils.events INFO:  eta: 23:15:37  iter: 12819  total_loss: 26.7  loss_mask: 2.666  loss_mask_0: 2.725  loss_mask_1: 2.665  loss_mask_2: 2.665  loss_mask_3: 2.667  loss_mask_4: 2.663  loss_mask_5: 2.665  loss_mask_6: 2.664  loss_mask_7: 2.666  loss_mask_8: 2.667  time: 1.8383  data_time: 0.4466  lr: 8.0548e-05  max_mem: 17484M
[01/27 10:44:09] d2.utils.events INFO:  eta: 23:16:45  iter: 12839  total_loss: 27.07  loss_mask: 2.703  loss_mask_0: 2.749  loss_mask_1: 2.701  loss_mask_2: 2.701  loss_mask_3: 2.703  loss_mask_4: 2.701  loss_mask_5: 2.703  loss_mask_6: 2.701  loss_mask_7: 2.702  loss_mask_8: 2.703  time: 1.8385  data_time: 0.4780  lr: 8.0517e-05  max_mem: 17484M
[01/27 10:44:47] d2.utils.events INFO:  eta: 23:17:16  iter: 12859  total_loss: 27.85  loss_mask: 2.782  loss_mask_0: 2.829  loss_mask_1: 2.782  loss_mask_2: 2.781  loss_mask_3: 2.781  loss_mask_4: 2.782  loss_mask_5: 2.782  loss_mask_6: 2.781  loss_mask_7: 2.782  loss_mask_8: 2.781  time: 1.8386  data_time: 0.4273  lr: 8.0486e-05  max_mem: 17484M
[01/27 10:45:23] d2.utils.events INFO:  eta: 23:17:45  iter: 12879  total_loss: 29.59  loss_mask: 2.953  loss_mask_0: 3.001  loss_mask_1: 2.952  loss_mask_2: 2.954  loss_mask_3: 2.957  loss_mask_4: 2.954  loss_mask_5: 2.955  loss_mask_6: 2.952  loss_mask_7: 2.954  loss_mask_8: 2.954  time: 1.8385  data_time: 0.4399  lr: 8.0456e-05  max_mem: 17484M
[01/27 10:45:59] d2.utils.events INFO:  eta: 23:17:29  iter: 12899  total_loss: 28.84  loss_mask: 2.879  loss_mask_0: 2.909  loss_mask_1: 2.877  loss_mask_2: 2.878  loss_mask_3: 2.879  loss_mask_4: 2.878  loss_mask_5: 2.878  loss_mask_6: 2.877  loss_mask_7: 2.878  loss_mask_8: 2.88  time: 1.8384  data_time: 0.4146  lr: 8.0425e-05  max_mem: 17484M
[01/27 10:46:34] d2.utils.events INFO:  eta: 23:16:56  iter: 12919  total_loss: 27.15  loss_mask: 2.711  loss_mask_0: 2.761  loss_mask_1: 2.711  loss_mask_2: 2.71  loss_mask_3: 2.711  loss_mask_4: 2.71  loss_mask_5: 2.711  loss_mask_6: 2.71  loss_mask_7: 2.711  loss_mask_8: 2.71  time: 1.8383  data_time: 0.3843  lr: 8.0394e-05  max_mem: 17484M
[01/27 10:47:09] d2.utils.events INFO:  eta: 23:16:14  iter: 12939  total_loss: 27.6  loss_mask: 2.756  loss_mask_0: 2.826  loss_mask_1: 2.756  loss_mask_2: 2.755  loss_mask_3: 2.756  loss_mask_4: 2.756  loss_mask_5: 2.757  loss_mask_6: 2.755  loss_mask_7: 2.756  loss_mask_8: 2.756  time: 1.8382  data_time: 0.3779  lr: 8.0364e-05  max_mem: 17484M
[01/27 10:47:50] d2.utils.events INFO:  eta: 23:17:06  iter: 12959  total_loss: 28.25  loss_mask: 2.82  loss_mask_0: 2.863  loss_mask_1: 2.822  loss_mask_2: 2.821  loss_mask_3: 2.821  loss_mask_4: 2.821  loss_mask_5: 2.821  loss_mask_6: 2.822  loss_mask_7: 2.821  loss_mask_8: 2.821  time: 1.8385  data_time: 0.4191  lr: 8.0333e-05  max_mem: 17484M
[01/27 10:48:31] d2.utils.events INFO:  eta: 23:17:41  iter: 12979  total_loss: 28.65  loss_mask: 2.86  loss_mask_0: 2.904  loss_mask_1: 2.86  loss_mask_2: 2.86  loss_mask_3: 2.861  loss_mask_4: 2.86  loss_mask_5: 2.861  loss_mask_6: 2.86  loss_mask_7: 2.86  loss_mask_8: 2.862  time: 1.8389  data_time: 0.4192  lr: 8.0302e-05  max_mem: 17484M
[01/27 10:49:14] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 10:49:14] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 10:49:14] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 10:56:42] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.1424389858560398, 'error_1pix': 0.5119489837070309, 'error_3pix': 0.21818606977708888, 'mIoU': 4.8905930513180715, 'fwIoU': 13.922446527524409, 'IoU-0': nan, 'IoU-1': 56.025324540789754, 'IoU-2': 2.749208475946135, 'IoU-3': 2.724388460332589, 'IoU-4': 2.3446611457565636, 'IoU-5': 2.3702427188508954, 'IoU-6': 2.5041273342624235, 'IoU-7': 2.472568392830545, 'IoU-8': 3.54127044966447, 'IoU-9': 9.372032812339043, 'IoU-10': 16.88523085199601, 'IoU-11': 25.279793107833658, 'IoU-12': 23.792706432636997, 'IoU-13': 22.760055951611474, 'IoU-14': 22.30998720362689, 'IoU-15': 21.8159638002993, 'IoU-16': 22.125672121428444, 'IoU-17': 18.91976608823347, 'IoU-18': 19.077745686893866, 'IoU-19': 18.55622322018787, 'IoU-20': 18.57539437147848, 'IoU-21': 18.943065001155507, 'IoU-22': 18.164800329012955, 'IoU-23': 15.332785814382047, 'IoU-24': 14.888012809108215, 'IoU-25': 14.30389267169881, 'IoU-26': 12.560427015262633, 'IoU-27': 11.369801554120379, 'IoU-28': 9.866305357926334, 'IoU-29': 9.2247710671424, 'IoU-30': 8.339578763200867, 'IoU-31': 8.059515097042445, 'IoU-32': 7.012022506280068, 'IoU-33': 6.414931360618096, 'IoU-34': 6.17973437658601, 'IoU-35': 5.736285991083321, 'IoU-36': 5.339258724859875, 'IoU-37': 4.564066933465728, 'IoU-38': 4.173801086668765, 'IoU-39': 4.048780193141022, 'IoU-40': 3.9306481919212306, 'IoU-41': 3.6466280876489163, 'IoU-42': 3.5865250005498823, 'IoU-43': 3.758916435862139, 'IoU-44': 3.5998913042662957, 'IoU-45': 3.7258674938916783, 'IoU-46': 3.7928091367130587, 'IoU-47': 3.75639864163035, 'IoU-48': 3.658435575937395, 'IoU-49': 3.371132015116143, 'IoU-50': 3.6499339697614714, 'IoU-51': 3.407701168485825, 'IoU-52': 3.461115291819608, 'IoU-53': 3.4622446347781852, 'IoU-54': 3.5146104149068753, 'IoU-55': 3.409564915252014, 'IoU-56': 3.4532220158997275, 'IoU-57': 3.5676121326864942, 'IoU-58': 3.6424624202768365, 'IoU-59': 3.6549397354459687, 'IoU-60': 3.501327156121805, 'IoU-61': 3.382415606628252, 'IoU-62': 3.664932638930481, 'IoU-63': 3.6331761146643964, 'IoU-64': 3.396298406823596, 'IoU-65': 3.5661317772915146, 'IoU-66': 3.41311937497336, 'IoU-67': 3.2916478186655835, 'IoU-68': 3.3547095614512705, 'IoU-69': 3.4858987049885366, 'IoU-70': 3.545516634826875, 'IoU-71': 3.2614204764733383, 'IoU-72': 3.2867447997763297, 'IoU-73': 3.4667021015434445, 'IoU-74': 3.407518179292051, 'IoU-75': 3.478427695177028, 'IoU-76': 3.41356480341762, 'IoU-77': 3.151194489733412, 'IoU-78': 3.1963407003588817, 'IoU-79': 3.175938087742992, 'IoU-80': 3.132043270593992, 'IoU-81': 3.208798299394207, 'IoU-82': 3.0856795612579218, 'IoU-83': 3.3004667054387564, 'IoU-84': 3.3086619690646497, 'IoU-85': 3.1096920718298455, 'IoU-86': 3.0620086851047676, 'IoU-87': 2.9349776703131885, 'IoU-88': 2.9432046919461357, 'IoU-89': 3.070597688105992, 'IoU-90': 2.9991992864118817, 'IoU-91': 2.9704986023094406, 'IoU-92': 2.9558885445107483, 'IoU-93': 3.031632467756486, 'IoU-94': 3.0168100370172977, 'IoU-95': 3.072603738794381, 'IoU-96': 3.0349780476857178, 'IoU-97': 3.064955578491884, 'IoU-98': 3.0539472906032232, 'IoU-99': 2.9629672290528157, 'IoU-100': 2.9619202967170994, 'IoU-101': 3.118954420850087, 'IoU-102': 3.046944137467629, 'IoU-103': 2.9815192013177483, 'IoU-104': 3.0439505716458224, 'IoU-105': 3.066349970799995, 'IoU-106': 2.9964259076401785, 'IoU-107': 3.1100761821065177, 'IoU-108': 3.2910642711263054, 'IoU-109': 3.4367526971449007, 'IoU-110': 3.339142849611666, 'IoU-111': 3.048179389962874, 'IoU-112': 3.150195878890171, 'IoU-113': 3.1796430460482736, 'IoU-114': 3.2765087784488243, 'IoU-115': 3.0681688722065994, 'IoU-116': 2.981150370524738, 'IoU-117': 2.9603937782958027, 'IoU-118': 2.9633582223095845, 'IoU-119': 3.102282403919742, 'IoU-120': 3.0926497018392185, 'IoU-121': 3.194838341588163, 'IoU-122': 3.045073876744429, 'IoU-123': 3.0175764552241318, 'IoU-124': 2.9976367132586823, 'IoU-125': 3.0691793653206663, 'IoU-126': 2.9728304187140613, 'IoU-127': 3.1401045093985345, 'IoU-128': 2.910843658399684, 'IoU-129': 2.658657672772666, 'IoU-130': 2.587830830745374, 'IoU-131': 2.6798550061495825, 'IoU-132': 2.6012452409854987, 'IoU-133': 2.609442922984186, 'IoU-134': 2.6265958049843197, 'IoU-135': 2.746016769283227, 'IoU-136': 2.887430825585132, 'IoU-137': 2.8449425414270793, 'IoU-138': 2.7660793632937737, 'IoU-139': 2.8266721133294914, 'IoU-140': 3.0768556136660608, 'IoU-141': 2.900506686160556, 'IoU-142': 2.9002549916510403, 'IoU-143': 2.7868462586210625, 'IoU-144': 2.8114265699602425, 'IoU-145': 2.9331348097238785, 'IoU-146': 2.7953585099903147, 'IoU-147': 2.8425505935876134, 'IoU-148': 2.7308869114871297, 'IoU-149': 2.533091626487268, 'IoU-150': 2.5072247527244147, 'IoU-151': 2.676668990504993, 'IoU-152': 2.70452909372176, 'IoU-153': 2.23153385823509, 'IoU-154': 2.2855279441890124, 'IoU-155': 2.343232843047304, 'IoU-156': 2.4535755997407143, 'IoU-157': 2.3575620828431116, 'IoU-158': 2.12743464092933, 'IoU-159': 1.9475154020944008, 'IoU-160': 2.20099521873413, 'IoU-161': 2.103069648152601, 'IoU-162': 2.118871742852982, 'IoU-163': 2.231677993039761, 'IoU-164': 2.5552063817149624, 'IoU-165': 2.4629868061211972, 'IoU-166': 2.3392680378480493, 'IoU-167': 2.160432427516668, 'IoU-168': 2.2128069756032462, 'IoU-169': 2.050904939065985, 'IoU-170': 2.2583367892079136, 'IoU-171': 2.047188794082995, 'IoU-172': 2.1132977413717517, 'IoU-173': 2.2392601078634984, 'IoU-174': 2.3528754885538805, 'IoU-175': 2.364831059671125, 'IoU-176': 2.5386999990032195, 'IoU-177': 2.3457250776687215, 'IoU-178': 2.5713003738411797, 'IoU-179': 2.615966386554622, 'IoU-180': 2.60044033267077, 'IoU-181': 2.5677225249063085, 'IoU-182': 2.4501918398205116, 'IoU-183': 2.131532327167016, 'IoU-184': 2.123114974885155, 'IoU-185': 2.1782764977233, 'IoU-186': 2.2300905262185027, 'IoU-187': 2.3030081198344607, 'IoU-188': 1.9392538114327198, 'IoU-189': 1.74087369241709, 'IoU-190': 1.3789229079951992, 'IoU-191': 1.63545875508109, 'IoU-192': 1.2101744801707333, 'mACC': 8.754205901716649, 'pACC': 20.25172764364319, 'ACC-0': nan, 'ACC-1': 56.92829977595938, 'ACC-2': 5.800037275018637, 'ACC-3': 14.045721442584766, 'ACC-4': 10.810379530585179, 'ACC-5': 10.77941364459167, 'ACC-6': 11.245746649489426, 'ACC-7': 11.71226358335977, 'ACC-8': 8.07918788940745, 'ACC-9': 14.092671903889123, 'ACC-10': 26.55634881943466, 'ACC-11': 36.48392814197846, 'ACC-12': 36.025364143810364, 'ACC-13': 35.82423960575221, 'ACC-14': 35.400494606155235, 'ACC-15': 36.27371919494786, 'ACC-16': 37.500600484381025, 'ACC-17': 34.17626335195242, 'ACC-18': 32.834313646336064, 'ACC-19': 31.9087082530503, 'ACC-20': 32.52069940998183, 'ACC-21': 34.664112715770955, 'ACC-22': 32.395605579212116, 'ACC-23': 27.94803846111175, 'ACC-24': 27.198900570371993, 'ACC-25': 27.045448789727356, 'ACC-26': 24.782187257910874, 'ACC-27': 21.763356675849728, 'ACC-28': 19.4874728814864, 'ACC-29': 17.743168719927667, 'ACC-30': 16.483594565930385, 'ACC-31': 15.426296244104648, 'ACC-32': 13.309577380472563, 'ACC-33': 12.657049809209461, 'ACC-34': 12.614208426750412, 'ACC-35': 11.494855194417035, 'ACC-36': 10.548986288372749, 'ACC-37': 9.016898164990419, 'ACC-38': 8.049785758477633, 'ACC-39': 7.668525942256951, 'ACC-40': 7.3522223173742045, 'ACC-41': 7.031181590767075, 'ACC-42': 6.980597631935827, 'ACC-43': 7.244501841584622, 'ACC-44': 6.710434631348278, 'ACC-45': 7.001212596396115, 'ACC-46': 7.314170436446445, 'ACC-47': 7.2348173882801, 'ACC-48': 6.987675077760724, 'ACC-49': 6.373833758990805, 'ACC-50': 6.83719220826217, 'ACC-51': 6.48015192596284, 'ACC-52': 6.579529942491852, 'ACC-53': 6.520349478668834, 'ACC-54': 6.506686387479808, 'ACC-55': 6.290356825345128, 'ACC-56': 6.416401255359775, 'ACC-57': 6.481411532193347, 'ACC-58': 6.645934845764367, 'ACC-59': 6.715581696383833, 'ACC-60': 6.495339378674338, 'ACC-61': 6.343311613209966, 'ACC-62': 6.922347203655321, 'ACC-63': 6.925682156575427, 'ACC-64': 6.480286577478419, 'ACC-65': 6.790082729648097, 'ACC-66': 6.5228220738003735, 'ACC-67': 6.384816101933601, 'ACC-68': 6.529284279516447, 'ACC-69': 6.666236629252352, 'ACC-70': 6.7637469028775445, 'ACC-71': 6.3528615303871705, 'ACC-72': 6.441050223306758, 'ACC-73': 6.803063243596107, 'ACC-74': 6.636132399782273, 'ACC-75': 6.725835636573303, 'ACC-76': 6.471793333697653, 'ACC-77': 6.06034837159433, 'ACC-78': 6.161978431478249, 'ACC-79': 6.110802769350822, 'ACC-80': 5.948438119074919, 'ACC-81': 6.067763820515292, 'ACC-82': 5.8342516149342405, 'ACC-83': 6.146111792673164, 'ACC-84': 6.132995380635142, 'ACC-85': 5.746531976868659, 'ACC-86': 5.6470032431183785, 'ACC-87': 5.391562403040456, 'ACC-88': 5.373886483639226, 'ACC-89': 5.5590613106814715, 'ACC-90': 5.4278280090291195, 'ACC-91': 5.386541497880538, 'ACC-92': 5.357048142461768, 'ACC-93': 5.494282408829462, 'ACC-94': 5.429010025519947, 'ACC-95': 5.505778026814074, 'ACC-96': 5.440918028353325, 'ACC-97': 5.391169643898152, 'ACC-98': 5.40691894261246, 'ACC-99': 5.258208991201639, 'ACC-100': 5.23779692938975, 'ACC-101': 5.537787429882176, 'ACC-102': 5.418122469101344, 'ACC-103': 5.293756905672907, 'ACC-104': 5.4435238428543, 'ACC-105': 5.491233670876378, 'ACC-106': 5.386338194699566, 'ACC-107': 5.613112410741094, 'ACC-108': 5.8878623224953825, 'ACC-109': 6.1296728624219154, 'ACC-110': 6.064711047090719, 'ACC-111': 5.571000610803098, 'ACC-112': 5.843858584928387, 'ACC-113': 5.84941941009916, 'ACC-114': 5.989875353362266, 'ACC-115': 5.5775938538330845, 'ACC-116': 5.425520876729902, 'ACC-117': 5.3438123580055725, 'ACC-118': 5.367685310096121, 'ACC-119': 5.554833571159282, 'ACC-120': 5.557737161832725, 'ACC-121': 5.758332360567889, 'ACC-122': 5.539971883344184, 'ACC-123': 5.5295469034024185, 'ACC-124': 5.657234213822272, 'ACC-125': 5.775520659413093, 'ACC-126': 5.624086754027105, 'ACC-127': 5.894656056967171, 'ACC-128': 5.46493375338917, 'ACC-129': 4.9531269316040385, 'ACC-130': 4.770046150710835, 'ACC-131': 4.9392807797899, 'ACC-132': 4.740812230030193, 'ACC-133': 4.7334500036742995, 'ACC-134': 4.7274990883202275, 'ACC-135': 4.92984595255792, 'ACC-136': 5.147821048156496, 'ACC-137': 5.1130010555567855, 'ACC-138': 4.99312283551758, 'ACC-139': 5.083033816932078, 'ACC-140': 5.462805365403171, 'ACC-141': 5.14560835375542, 'ACC-142': 5.180109566980742, 'ACC-143': 4.980653208080903, 'ACC-144': 4.955162293004668, 'ACC-145': 5.092444341082498, 'ACC-146': 4.818873028347925, 'ACC-147': 4.859364960277519, 'ACC-148': 4.659359544805153, 'ACC-149': 4.414252334553007, 'ACC-150': 4.382254594576565, 'ACC-151': 4.648664319028658, 'ACC-152': 4.651442143052077, 'ACC-153': 3.9470293928695352, 'ACC-154': 4.0571926429698655, 'ACC-155': 4.2498379100628885, 'ACC-156': 4.443338353835513, 'ACC-157': 4.279519016908456, 'ACC-158': 3.8630868277038997, 'ACC-159': 3.5024509074100068, 'ACC-160': 3.8974406829746955, 'ACC-161': 3.684844672001079, 'ACC-162': 3.7667436867578505, 'ACC-163': 3.9843628168945178, 'ACC-164': 4.598023777468018, 'ACC-165': 4.433409897416836, 'ACC-166': 4.289681993276487, 'ACC-167': 3.962725429312631, 'ACC-168': 4.054320292710385, 'ACC-169': 3.721024949616241, 'ACC-170': 4.109243667638463, 'ACC-171': 3.772090099297455, 'ACC-172': 3.913203029146079, 'ACC-173': 4.129206449025548, 'ACC-174': 4.324083298818279, 'ACC-175': 4.329394436199858, 'ACC-176': 4.625403853383288, 'ACC-177': 4.347343741910672, 'ACC-178': 4.847038512307758, 'ACC-179': 5.0661030430386855, 'ACC-180': 4.901860885735757, 'ACC-181': 4.879149914934466, 'ACC-182': 4.521052218818547, 'ACC-183': 3.8325665364647947, 'ACC-184': 3.5607149368191515, 'ACC-185': 3.394034165388694, 'ACC-186': 3.319670381281756, 'ACC-187': 3.2381400904028315, 'ACC-188': 2.493892120772371, 'ACC-189': 2.102948215417653, 'ACC-190': 1.5708966275970044, 'ACC-191': 1.7705586222007512, 'ACC-192': 1.2784877300173545})])
[01/27 10:56:42] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 10:56:42] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 10:56:42] d2.evaluation.testing INFO: copypaste: 3.1424,0.5119,0.2182,4.8906,13.9224,8.7542,20.2517
[01/27 10:56:43] d2.utils.events INFO:  eta: 23:18:49  iter: 12999  total_loss: 28.05  loss_mask: 2.801  loss_mask_0: 2.842  loss_mask_1: 2.802  loss_mask_2: 2.801  loss_mask_3: 2.799  loss_mask_4: 2.8  loss_mask_5: 2.801  loss_mask_6: 2.801  loss_mask_7: 2.801  loss_mask_8: 2.802  time: 1.8393  data_time: 0.4255  lr: 8.0271e-05  max_mem: 17484M
[01/27 10:57:24] d2.utils.events INFO:  eta: 23:19:37  iter: 13019  total_loss: 29.41  loss_mask: 2.938  loss_mask_0: 2.966  loss_mask_1: 2.937  loss_mask_2: 2.938  loss_mask_3: 2.938  loss_mask_4: 2.938  loss_mask_5: 2.939  loss_mask_6: 2.938  loss_mask_7: 2.938  loss_mask_8: 2.939  time: 1.8397  data_time: 0.4117  lr: 8.0241e-05  max_mem: 17484M
[01/27 10:58:06] d2.utils.events INFO:  eta: 23:21:47  iter: 13039  total_loss: 28.11  loss_mask: 2.809  loss_mask_0: 2.842  loss_mask_1: 2.808  loss_mask_2: 2.808  loss_mask_3: 2.809  loss_mask_4: 2.806  loss_mask_5: 2.808  loss_mask_6: 2.807  loss_mask_7: 2.808  loss_mask_8: 2.808  time: 1.8400  data_time: 0.4350  lr: 8.021e-05  max_mem: 17484M
[01/27 10:58:48] d2.utils.events INFO:  eta: 23:24:17  iter: 13059  total_loss: 26.82  loss_mask: 2.676  loss_mask_0: 2.747  loss_mask_1: 2.674  loss_mask_2: 2.675  loss_mask_3: 2.673  loss_mask_4: 2.676  loss_mask_5: 2.674  loss_mask_6: 2.675  loss_mask_7: 2.675  loss_mask_8: 2.674  time: 1.8404  data_time: 0.4058  lr: 8.0179e-05  max_mem: 17484M
[01/27 10:59:30] d2.utils.events INFO:  eta: 23:27:35  iter: 13079  total_loss: 26.68  loss_mask: 2.665  loss_mask_0: 2.713  loss_mask_1: 2.661  loss_mask_2: 2.663  loss_mask_3: 2.661  loss_mask_4: 2.661  loss_mask_5: 2.662  loss_mask_6: 2.664  loss_mask_7: 2.664  loss_mask_8: 2.666  time: 1.8408  data_time: 0.4284  lr: 8.0148e-05  max_mem: 17484M
[01/27 11:00:11] d2.utils.events INFO:  eta: 23:30:04  iter: 13099  total_loss: 26.25  loss_mask: 2.623  loss_mask_0: 2.645  loss_mask_1: 2.622  loss_mask_2: 2.622  loss_mask_3: 2.622  loss_mask_4: 2.623  loss_mask_5: 2.622  loss_mask_6: 2.623  loss_mask_7: 2.622  loss_mask_8: 2.623  time: 1.8411  data_time: 0.4129  lr: 8.0118e-05  max_mem: 17484M
[01/27 11:00:53] d2.utils.events INFO:  eta: 23:32:34  iter: 13119  total_loss: 27.45  loss_mask: 2.738  loss_mask_0: 2.781  loss_mask_1: 2.739  loss_mask_2: 2.739  loss_mask_3: 2.738  loss_mask_4: 2.739  loss_mask_5: 2.738  loss_mask_6: 2.739  loss_mask_7: 2.738  loss_mask_8: 2.738  time: 1.8415  data_time: 0.4051  lr: 8.0087e-05  max_mem: 17484M
[01/27 11:01:35] d2.utils.events INFO:  eta: 23:33:59  iter: 13139  total_loss: 27.35  loss_mask: 2.734  loss_mask_0: 2.742  loss_mask_1: 2.733  loss_mask_2: 2.734  loss_mask_3: 2.733  loss_mask_4: 2.734  loss_mask_5: 2.734  loss_mask_6: 2.734  loss_mask_7: 2.734  loss_mask_8: 2.734  time: 1.8419  data_time: 0.4129  lr: 8.0056e-05  max_mem: 17484M
[01/27 11:02:16] d2.utils.events INFO:  eta: 23:38:59  iter: 13159  total_loss: 27.96  loss_mask: 2.792  loss_mask_0: 2.828  loss_mask_1: 2.793  loss_mask_2: 2.792  loss_mask_3: 2.792  loss_mask_4: 2.792  loss_mask_5: 2.793  loss_mask_6: 2.792  loss_mask_7: 2.792  loss_mask_8: 2.792  time: 1.8423  data_time: 0.4091  lr: 8.0025e-05  max_mem: 17484M
[01/27 11:02:58] d2.utils.events INFO:  eta: 23:42:35  iter: 13179  total_loss: 31.71  loss_mask: 3.17  loss_mask_0: 3.193  loss_mask_1: 3.167  loss_mask_2: 3.17  loss_mask_3: 3.168  loss_mask_4: 3.167  loss_mask_5: 3.169  loss_mask_6: 3.166  loss_mask_7: 3.169  loss_mask_8: 3.168  time: 1.8426  data_time: 0.4174  lr: 7.9995e-05  max_mem: 17484M
[01/27 11:03:40] d2.utils.events INFO:  eta: 23:48:18  iter: 13199  total_loss: 32.43  loss_mask: 3.241  loss_mask_0: 3.237  loss_mask_1: 3.243  loss_mask_2: 3.243  loss_mask_3: 3.242  loss_mask_4: 3.243  loss_mask_5: 3.242  loss_mask_6: 3.242  loss_mask_7: 3.244  loss_mask_8: 3.242  time: 1.8430  data_time: 0.4083  lr: 7.9964e-05  max_mem: 17484M
[01/27 11:04:21] d2.utils.events INFO:  eta: 23:53:49  iter: 13219  total_loss: 37.17  loss_mask: 3.713  loss_mask_0: 3.845  loss_mask_1: 3.709  loss_mask_2: 3.702  loss_mask_3: 3.714  loss_mask_4: 3.715  loss_mask_5: 3.715  loss_mask_6: 3.71  loss_mask_7: 3.719  loss_mask_8: 3.714  time: 1.8433  data_time: 0.4020  lr: 7.9933e-05  max_mem: 17484M
[01/27 11:05:03] d2.utils.events INFO:  eta: 1 day, 0:05:08  iter: 13239  total_loss: 32.7  loss_mask: 3.271  loss_mask_0: 3.429  loss_mask_1: 3.271  loss_mask_2: 3.274  loss_mask_3: 3.272  loss_mask_4: 3.275  loss_mask_5: 3.275  loss_mask_6: 3.273  loss_mask_7: 3.272  loss_mask_8: 3.273  time: 1.8437  data_time: 0.4061  lr: 7.9902e-05  max_mem: 17484M
[01/27 11:05:45] d2.utils.events INFO:  eta: 1 day, 0:11:57  iter: 13259  total_loss: 30.17  loss_mask: 2.992  loss_mask_0: 3.163  loss_mask_1: 2.989  loss_mask_2: 2.99  loss_mask_3: 2.997  loss_mask_4: 2.992  loss_mask_5: 2.998  loss_mask_6: 2.992  loss_mask_7: 2.991  loss_mask_8: 2.991  time: 1.8441  data_time: 0.4288  lr: 7.9872e-05  max_mem: 17484M
[01/27 11:06:27] d2.utils.events INFO:  eta: 1 day, 0:26:24  iter: 13279  total_loss: 30.63  loss_mask: 3.027  loss_mask_0: 3.331  loss_mask_1: 3.031  loss_mask_2: 3.029  loss_mask_3: 3.027  loss_mask_4: 3.029  loss_mask_5: 3.03  loss_mask_6: 3.03  loss_mask_7: 3.03  loss_mask_8: 3.03  time: 1.8445  data_time: 0.4165  lr: 7.9841e-05  max_mem: 17484M
[01/27 11:07:08] d2.utils.events INFO:  eta: 1 day, 0:38:16  iter: 13299  total_loss: 30.54  loss_mask: 3.028  loss_mask_0: 3.221  loss_mask_1: 3.031  loss_mask_2: 3.029  loss_mask_3: 3.029  loss_mask_4: 3.03  loss_mask_5: 3.03  loss_mask_6: 3.028  loss_mask_7: 3.027  loss_mask_8: 3.027  time: 1.8448  data_time: 0.4089  lr: 7.981e-05  max_mem: 17484M
[01/27 11:07:50] d2.utils.events INFO:  eta: 1 day, 1:01:04  iter: 13319  total_loss: 29.4  loss_mask: 2.939  loss_mask_0: 3.03  loss_mask_1: 2.937  loss_mask_2: 2.941  loss_mask_3: 2.937  loss_mask_4: 2.939  loss_mask_5: 2.936  loss_mask_6: 2.94  loss_mask_7: 2.943  loss_mask_8: 2.94  time: 1.8451  data_time: 0.4037  lr: 7.9779e-05  max_mem: 17484M
[01/27 11:08:31] d2.utils.events INFO:  eta: 1 day, 1:13:34  iter: 13339  total_loss: 29.35  loss_mask: 2.93  loss_mask_0: 2.97  loss_mask_1: 2.931  loss_mask_2: 2.929  loss_mask_3: 2.931  loss_mask_4: 2.929  loss_mask_5: 2.932  loss_mask_6: 2.931  loss_mask_7: 2.93  loss_mask_8: 2.93  time: 1.8455  data_time: 0.4048  lr: 7.9748e-05  max_mem: 17484M
[01/27 11:09:13] d2.utils.events INFO:  eta: 1 day, 1:24:25  iter: 13359  total_loss: 31.5  loss_mask: 3.146  loss_mask_0: 3.176  loss_mask_1: 3.148  loss_mask_2: 3.148  loss_mask_3: 3.146  loss_mask_4: 3.148  loss_mask_5: 3.15  loss_mask_6: 3.147  loss_mask_7: 3.146  loss_mask_8: 3.146  time: 1.8459  data_time: 0.4284  lr: 7.9718e-05  max_mem: 17484M
[01/27 11:09:55] d2.utils.events INFO:  eta: 1 day, 1:41:00  iter: 13379  total_loss: 29.09  loss_mask: 2.908  loss_mask_0: 2.946  loss_mask_1: 2.908  loss_mask_2: 2.909  loss_mask_3: 2.907  loss_mask_4: 2.908  loss_mask_5: 2.908  loss_mask_6: 2.909  loss_mask_7: 2.908  loss_mask_8: 2.908  time: 1.8463  data_time: 0.4277  lr: 7.9687e-05  max_mem: 17484M
[01/27 11:10:37] d2.utils.events INFO:  eta: 1 day, 1:48:25  iter: 13399  total_loss: 29.68  loss_mask: 2.964  loss_mask_0: 3.016  loss_mask_1: 2.964  loss_mask_2: 2.963  loss_mask_3: 2.963  loss_mask_4: 2.963  loss_mask_5: 2.964  loss_mask_6: 2.962  loss_mask_7: 2.961  loss_mask_8: 2.962  time: 1.8466  data_time: 0.4212  lr: 7.9656e-05  max_mem: 17484M
[01/27 11:11:19] d2.utils.events INFO:  eta: 1 day, 1:54:04  iter: 13419  total_loss: 30.25  loss_mask: 3.02  loss_mask_0: 3.079  loss_mask_1: 3.017  loss_mask_2: 3.018  loss_mask_3: 3.021  loss_mask_4: 3.02  loss_mask_5: 3.019  loss_mask_6: 3.018  loss_mask_7: 3.018  loss_mask_8: 3.016  time: 1.8470  data_time: 0.4101  lr: 7.9625e-05  max_mem: 17484M
[01/27 11:12:01] d2.utils.events INFO:  eta: 1 day, 1:58:57  iter: 13439  total_loss: 28.78  loss_mask: 2.874  loss_mask_0: 2.922  loss_mask_1: 2.874  loss_mask_2: 2.874  loss_mask_3: 2.874  loss_mask_4: 2.873  loss_mask_5: 2.873  loss_mask_6: 2.873  loss_mask_7: 2.873  loss_mask_8: 2.874  time: 1.8473  data_time: 0.4271  lr: 7.9595e-05  max_mem: 17484M
[01/27 11:12:43] d2.utils.events INFO:  eta: 1 day, 2:02:44  iter: 13459  total_loss: 29.34  loss_mask: 2.929  loss_mask_0: 2.981  loss_mask_1: 2.928  loss_mask_2: 2.929  loss_mask_3: 2.931  loss_mask_4: 2.931  loss_mask_5: 2.928  loss_mask_6: 2.929  loss_mask_7: 2.927  loss_mask_8: 2.925  time: 1.8477  data_time: 0.4028  lr: 7.9564e-05  max_mem: 17484M
[01/27 11:13:24] d2.utils.events INFO:  eta: 1 day, 2:07:34  iter: 13479  total_loss: 27.26  loss_mask: 2.72  loss_mask_0: 2.764  loss_mask_1: 2.721  loss_mask_2: 2.721  loss_mask_3: 2.723  loss_mask_4: 2.722  loss_mask_5: 2.722  loss_mask_6: 2.721  loss_mask_7: 2.72  loss_mask_8: 2.721  time: 1.8480  data_time: 0.3962  lr: 7.9533e-05  max_mem: 17484M
[01/27 11:14:06] d2.utils.events INFO:  eta: 1 day, 2:13:04  iter: 13499  total_loss: 30.69  loss_mask: 3.063  loss_mask_0: 3.126  loss_mask_1: 3.062  loss_mask_2: 3.062  loss_mask_3: 3.065  loss_mask_4: 3.064  loss_mask_5: 3.063  loss_mask_6: 3.061  loss_mask_7: 3.061  loss_mask_8: 3.062  time: 1.8484  data_time: 0.4334  lr: 7.9502e-05  max_mem: 17484M
[01/27 11:14:48] d2.utils.events INFO:  eta: 1 day, 2:13:48  iter: 13519  total_loss: 27.81  loss_mask: 2.777  loss_mask_0: 2.819  loss_mask_1: 2.776  loss_mask_2: 2.777  loss_mask_3: 2.777  loss_mask_4: 2.775  loss_mask_5: 2.777  loss_mask_6: 2.776  loss_mask_7: 2.775  loss_mask_8: 2.776  time: 1.8487  data_time: 0.4079  lr: 7.9472e-05  max_mem: 17484M
[01/27 11:15:30] d2.utils.events INFO:  eta: 1 day, 2:17:39  iter: 13539  total_loss: 29.78  loss_mask: 2.969  loss_mask_0: 3.047  loss_mask_1: 2.97  loss_mask_2: 2.97  loss_mask_3: 2.97  loss_mask_4: 2.97  loss_mask_5: 2.971  loss_mask_6: 2.971  loss_mask_7: 2.97  loss_mask_8: 2.971  time: 1.8491  data_time: 0.4197  lr: 7.9441e-05  max_mem: 17484M
[01/27 11:16:12] d2.utils.events INFO:  eta: 1 day, 2:21:26  iter: 13559  total_loss: 29.07  loss_mask: 2.902  loss_mask_0: 2.963  loss_mask_1: 2.902  loss_mask_2: 2.9  loss_mask_3: 2.9  loss_mask_4: 2.901  loss_mask_5: 2.901  loss_mask_6: 2.901  loss_mask_7: 2.902  loss_mask_8: 2.902  time: 1.8495  data_time: 0.4358  lr: 7.941e-05  max_mem: 17484M
[01/27 11:16:53] d2.utils.events INFO:  eta: 1 day, 2:23:53  iter: 13579  total_loss: 28.97  loss_mask: 2.888  loss_mask_0: 2.959  loss_mask_1: 2.887  loss_mask_2: 2.887  loss_mask_3: 2.884  loss_mask_4: 2.884  loss_mask_5: 2.887  loss_mask_6: 2.887  loss_mask_7: 2.887  loss_mask_8: 2.888  time: 1.8498  data_time: 0.4017  lr: 7.9379e-05  max_mem: 17484M
[01/27 11:17:35] d2.utils.events INFO:  eta: 1 day, 2:25:42  iter: 13599  total_loss: 28.44  loss_mask: 2.839  loss_mask_0: 2.915  loss_mask_1: 2.84  loss_mask_2: 2.839  loss_mask_3: 2.84  loss_mask_4: 2.841  loss_mask_5: 2.84  loss_mask_6: 2.839  loss_mask_7: 2.84  loss_mask_8: 2.838  time: 1.8502  data_time: 0.4385  lr: 7.9348e-05  max_mem: 17484M
[01/27 11:18:17] d2.utils.events INFO:  eta: 1 day, 2:26:44  iter: 13619  total_loss: 29.54  loss_mask: 2.947  loss_mask_0: 2.987  loss_mask_1: 2.949  loss_mask_2: 2.949  loss_mask_3: 2.952  loss_mask_4: 2.951  loss_mask_5: 2.948  loss_mask_6: 2.948  loss_mask_7: 2.948  loss_mask_8: 2.947  time: 1.8505  data_time: 0.4093  lr: 7.9318e-05  max_mem: 17484M
[01/27 11:18:59] d2.utils.events INFO:  eta: 1 day, 2:27:17  iter: 13639  total_loss: 29.51  loss_mask: 2.948  loss_mask_0: 2.99  loss_mask_1: 2.948  loss_mask_2: 2.948  loss_mask_3: 2.947  loss_mask_4: 2.948  loss_mask_5: 2.947  loss_mask_6: 2.947  loss_mask_7: 2.948  loss_mask_8: 2.946  time: 1.8509  data_time: 0.4197  lr: 7.9287e-05  max_mem: 17484M
[01/27 11:19:41] d2.utils.events INFO:  eta: 1 day, 2:27:39  iter: 13659  total_loss: 30.58  loss_mask: 3.052  loss_mask_0: 3.116  loss_mask_1: 3.048  loss_mask_2: 3.05  loss_mask_3: 3.052  loss_mask_4: 3.05  loss_mask_5: 3.052  loss_mask_6: 3.051  loss_mask_7: 3.052  loss_mask_8: 3.052  time: 1.8512  data_time: 0.4080  lr: 7.9256e-05  max_mem: 17484M
[01/27 11:20:23] d2.utils.events INFO:  eta: 1 day, 2:29:16  iter: 13679  total_loss: 29.99  loss_mask: 2.996  loss_mask_0: 3.024  loss_mask_1: 2.996  loss_mask_2: 2.997  loss_mask_3: 2.997  loss_mask_4: 2.997  loss_mask_5: 2.995  loss_mask_6: 2.996  loss_mask_7: 2.995  loss_mask_8: 2.997  time: 1.8516  data_time: 0.4218  lr: 7.9225e-05  max_mem: 17484M
[01/27 11:21:04] d2.utils.events INFO:  eta: 1 day, 2:31:12  iter: 13699  total_loss: 28.42  loss_mask: 2.834  loss_mask_0: 2.92  loss_mask_1: 2.831  loss_mask_2: 2.833  loss_mask_3: 2.834  loss_mask_4: 2.832  loss_mask_5: 2.834  loss_mask_6: 2.833  loss_mask_7: 2.833  loss_mask_8: 2.834  time: 1.8519  data_time: 0.3949  lr: 7.9195e-05  max_mem: 17484M
[01/27 11:21:46] d2.utils.events INFO:  eta: 1 day, 2:32:48  iter: 13719  total_loss: 27.89  loss_mask: 2.786  loss_mask_0: 2.823  loss_mask_1: 2.788  loss_mask_2: 2.786  loss_mask_3: 2.786  loss_mask_4: 2.788  loss_mask_5: 2.787  loss_mask_6: 2.786  loss_mask_7: 2.788  loss_mask_8: 2.787  time: 1.8522  data_time: 0.4190  lr: 7.9164e-05  max_mem: 17484M
[01/27 11:22:27] d2.utils.events INFO:  eta: 1 day, 2:33:36  iter: 13739  total_loss: 26.9  loss_mask: 2.686  loss_mask_0: 2.744  loss_mask_1: 2.684  loss_mask_2: 2.685  loss_mask_3: 2.684  loss_mask_4: 2.682  loss_mask_5: 2.686  loss_mask_6: 2.686  loss_mask_7: 2.684  loss_mask_8: 2.687  time: 1.8526  data_time: 0.4121  lr: 7.9133e-05  max_mem: 17484M
[01/27 11:23:09] d2.utils.events INFO:  eta: 1 day, 2:33:57  iter: 13759  total_loss: 27.9  loss_mask: 2.782  loss_mask_0: 2.831  loss_mask_1: 2.779  loss_mask_2: 2.781  loss_mask_3: 2.783  loss_mask_4: 2.782  loss_mask_5: 2.779  loss_mask_6: 2.78  loss_mask_7: 2.781  loss_mask_8: 2.779  time: 1.8529  data_time: 0.4185  lr: 7.9102e-05  max_mem: 17484M
[01/27 11:23:51] d2.utils.events INFO:  eta: 1 day, 2:34:23  iter: 13779  total_loss: 28.95  loss_mask: 2.886  loss_mask_0: 2.968  loss_mask_1: 2.884  loss_mask_2: 2.884  loss_mask_3: 2.883  loss_mask_4: 2.882  loss_mask_5: 2.886  loss_mask_6: 2.886  loss_mask_7: 2.883  loss_mask_8: 2.886  time: 1.8532  data_time: 0.4153  lr: 7.9071e-05  max_mem: 17484M
[01/27 11:24:33] d2.utils.events INFO:  eta: 1 day, 2:35:07  iter: 13799  total_loss: 27.73  loss_mask: 2.772  loss_mask_0: 2.788  loss_mask_1: 2.772  loss_mask_2: 2.773  loss_mask_3: 2.773  loss_mask_4: 2.773  loss_mask_5: 2.772  loss_mask_6: 2.772  loss_mask_7: 2.773  loss_mask_8: 2.772  time: 1.8536  data_time: 0.4166  lr: 7.9041e-05  max_mem: 17484M
[01/27 11:25:14] d2.utils.events INFO:  eta: 1 day, 2:35:20  iter: 13819  total_loss: 31.53  loss_mask: 3.153  loss_mask_0: 3.166  loss_mask_1: 3.153  loss_mask_2: 3.153  loss_mask_3: 3.152  loss_mask_4: 3.154  loss_mask_5: 3.152  loss_mask_6: 3.153  loss_mask_7: 3.154  loss_mask_8: 3.149  time: 1.8539  data_time: 0.4069  lr: 7.901e-05  max_mem: 17484M
[01/27 11:25:55] d2.utils.events INFO:  eta: 1 day, 2:34:39  iter: 13839  total_loss: 28.27  loss_mask: 2.822  loss_mask_0: 2.866  loss_mask_1: 2.822  loss_mask_2: 2.821  loss_mask_3: 2.823  loss_mask_4: 2.822  loss_mask_5: 2.823  loss_mask_6: 2.822  loss_mask_7: 2.825  loss_mask_8: 2.82  time: 1.8542  data_time: 0.3896  lr: 7.8979e-05  max_mem: 17484M
[01/27 11:26:37] d2.utils.events INFO:  eta: 1 day, 2:35:32  iter: 13859  total_loss: 28.14  loss_mask: 2.814  loss_mask_0: 2.825  loss_mask_1: 2.812  loss_mask_2: 2.813  loss_mask_3: 2.812  loss_mask_4: 2.813  loss_mask_5: 2.812  loss_mask_6: 2.813  loss_mask_7: 2.815  loss_mask_8: 2.816  time: 1.8545  data_time: 0.4351  lr: 7.8948e-05  max_mem: 17484M
[01/27 11:27:19] d2.utils.events INFO:  eta: 1 day, 2:36:32  iter: 13879  total_loss: 29.29  loss_mask: 2.923  loss_mask_0: 2.954  loss_mask_1: 2.925  loss_mask_2: 2.923  loss_mask_3: 2.924  loss_mask_4: 2.924  loss_mask_5: 2.923  loss_mask_6: 2.926  loss_mask_7: 2.924  loss_mask_8: 2.924  time: 1.8549  data_time: 0.4264  lr: 7.8917e-05  max_mem: 17484M
[01/27 11:28:01] d2.utils.events INFO:  eta: 1 day, 2:37:33  iter: 13899  total_loss: 30.8  loss_mask: 3.078  loss_mask_0: 3.095  loss_mask_1: 3.077  loss_mask_2: 3.077  loss_mask_3: 3.079  loss_mask_4: 3.079  loss_mask_5: 3.08  loss_mask_6: 3.079  loss_mask_7: 3.079  loss_mask_8: 3.075  time: 1.8553  data_time: 0.4298  lr: 7.8887e-05  max_mem: 17484M
[01/27 11:28:43] d2.utils.events INFO:  eta: 1 day, 2:37:56  iter: 13919  total_loss: 27.89  loss_mask: 2.787  loss_mask_0: 2.816  loss_mask_1: 2.786  loss_mask_2: 2.787  loss_mask_3: 2.786  loss_mask_4: 2.783  loss_mask_5: 2.786  loss_mask_6: 2.789  loss_mask_7: 2.784  loss_mask_8: 2.789  time: 1.8556  data_time: 0.4168  lr: 7.8856e-05  max_mem: 17484M
[01/27 11:29:25] d2.utils.events INFO:  eta: 1 day, 2:38:23  iter: 13939  total_loss: 28.11  loss_mask: 2.805  loss_mask_0: 2.852  loss_mask_1: 2.806  loss_mask_2: 2.806  loss_mask_3: 2.808  loss_mask_4: 2.805  loss_mask_5: 2.806  loss_mask_6: 2.806  loss_mask_7: 2.806  loss_mask_8: 2.807  time: 1.8560  data_time: 0.4327  lr: 7.8825e-05  max_mem: 17484M
[01/27 11:30:07] d2.utils.events INFO:  eta: 1 day, 2:37:43  iter: 13959  total_loss: 27.31  loss_mask: 2.73  loss_mask_0: 2.747  loss_mask_1: 2.729  loss_mask_2: 2.729  loss_mask_3: 2.729  loss_mask_4: 2.729  loss_mask_5: 2.729  loss_mask_6: 2.729  loss_mask_7: 2.73  loss_mask_8: 2.73  time: 1.8563  data_time: 0.4146  lr: 7.8794e-05  max_mem: 17484M
[01/27 11:30:49] d2.utils.events INFO:  eta: 1 day, 2:37:08  iter: 13979  total_loss: 28.94  loss_mask: 2.894  loss_mask_0: 2.911  loss_mask_1: 2.892  loss_mask_2: 2.892  loss_mask_3: 2.891  loss_mask_4: 2.893  loss_mask_5: 2.893  loss_mask_6: 2.893  loss_mask_7: 2.893  loss_mask_8: 2.893  time: 1.8566  data_time: 0.4259  lr: 7.8763e-05  max_mem: 17484M
[01/27 11:31:30] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 11:31:31] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 11:31:31] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 11:38:37] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.785504650266833, 'error_1pix': 0.6053539320290144, 'error_3pix': 0.31493289287017634, 'mIoU': 4.016700289748089, 'fwIoU': 7.247662495019518, 'IoU-0': nan, 'IoU-1': 14.801002522586238, 'IoU-2': 2.2723036484082444, 'IoU-3': 2.6285877353581095, 'IoU-4': 2.8641692904721423, 'IoU-5': 2.930239481026967, 'IoU-6': 2.740816524294102, 'IoU-7': 1.767060930821336, 'IoU-8': 4.732247565399695, 'IoU-9': 9.513762323361618, 'IoU-10': 12.981199079312425, 'IoU-11': 16.999053052556544, 'IoU-12': 15.232861127444439, 'IoU-13': 13.641305862409393, 'IoU-14': 12.400383725166837, 'IoU-15': 11.67449404886292, 'IoU-16': 11.291592905986406, 'IoU-17': 9.742082377070659, 'IoU-18': 10.039392187979185, 'IoU-19': 10.126728822898217, 'IoU-20': 11.794735747701669, 'IoU-21': 13.934837062447587, 'IoU-22': 15.7020868057802, 'IoU-23': 14.79095160923069, 'IoU-24': 13.527135072201732, 'IoU-25': 13.058927666482706, 'IoU-26': 11.793882159940246, 'IoU-27': 11.090840800365882, 'IoU-28': 9.19762643217785, 'IoU-29': 6.930918579759003, 'IoU-30': 5.460871212378363, 'IoU-31': 4.605563721728792, 'IoU-32': 3.482195006745233, 'IoU-33': 2.578996023110216, 'IoU-34': 2.0881356694364945, 'IoU-35': 1.7779579008383575, 'IoU-36': 1.573541288340127, 'IoU-37': 1.2955010190606229, 'IoU-38': 1.1708261544692926, 'IoU-39': 1.1657379954137121, 'IoU-40': 1.0487734194647829, 'IoU-41': 0.92917863549461, 'IoU-42': 0.8944714661816275, 'IoU-43': 0.9347762558613812, 'IoU-44': 1.0303340797768883, 'IoU-45': 1.1022717153379027, 'IoU-46': 1.1415686921137231, 'IoU-47': 1.184361950899879, 'IoU-48': 1.4004097246854612, 'IoU-49': 1.6042295966607327, 'IoU-50': 1.796705248347464, 'IoU-51': 2.0754643042029848, 'IoU-52': 2.3721821252083632, 'IoU-53': 2.6991498394005786, 'IoU-54': 3.08397412318965, 'IoU-55': 3.5994594142973133, 'IoU-56': 3.84130509342901, 'IoU-57': 4.13730692479156, 'IoU-58': 4.323419402889439, 'IoU-59': 4.753544948183634, 'IoU-60': 5.164051854872886, 'IoU-61': 5.521162698749428, 'IoU-62': 5.690226951153457, 'IoU-63': 6.0342219211092365, 'IoU-64': 6.3985371667046484, 'IoU-65': 6.622075928260649, 'IoU-66': 6.71196132732244, 'IoU-67': 6.881879501142945, 'IoU-68': 6.775094206416009, 'IoU-69': 6.817801989275547, 'IoU-70': 6.678318081981646, 'IoU-71': 6.439063553479983, 'IoU-72': 6.35290648603619, 'IoU-73': 6.029860943962679, 'IoU-74': 6.085373596188181, 'IoU-75': 5.842352246218417, 'IoU-76': 5.873984873679129, 'IoU-77': 5.710176972948959, 'IoU-78': 5.213758066535557, 'IoU-79': 5.0679612787289505, 'IoU-80': 4.785085503121862, 'IoU-81': 4.905557808171119, 'IoU-82': 4.644467906288716, 'IoU-83': 4.692716609276193, 'IoU-84': 4.562662747766696, 'IoU-85': 4.486981509458863, 'IoU-86': 4.394679536115715, 'IoU-87': 4.24803228526021, 'IoU-88': 4.134852149501279, 'IoU-89': 4.177701905028605, 'IoU-90': 4.054309612577941, 'IoU-91': 3.9174789556900618, 'IoU-92': 3.7129824227477926, 'IoU-93': 3.7938288716859123, 'IoU-94': 3.668756307077095, 'IoU-95': 3.579089871370733, 'IoU-96': 3.525567354832387, 'IoU-97': 3.282688406582021, 'IoU-98': 3.2394565040179764, 'IoU-99': 3.0860530066025476, 'IoU-100': 2.9131707129943156, 'IoU-101': 2.9586412812964458, 'IoU-102': 2.894889132141255, 'IoU-103': 2.8736924921889146, 'IoU-104': 2.752199003929178, 'IoU-105': 2.7099783385847966, 'IoU-106': 2.7895359767825223, 'IoU-107': 2.9622023749010262, 'IoU-108': 3.0571497615985503, 'IoU-109': 3.001416588237455, 'IoU-110': 3.1092258858822013, 'IoU-111': 3.0941324565207324, 'IoU-112': 2.9260054285156736, 'IoU-113': 2.9101002964538187, 'IoU-114': 2.947976080697414, 'IoU-115': 2.9987682113579406, 'IoU-116': 2.8875308456683935, 'IoU-117': 2.980809893868757, 'IoU-118': 2.880731698408713, 'IoU-119': 2.9252372846620123, 'IoU-120': 2.8935521390990195, 'IoU-121': 3.0486052543856763, 'IoU-122': 3.0474199099635233, 'IoU-123': 2.8031845954452876, 'IoU-124': 2.9211210138656316, 'IoU-125': 2.6784177357853967, 'IoU-126': 2.567240077630656, 'IoU-127': 2.7096090549922796, 'IoU-128': 2.4531335492315134, 'IoU-129': 2.4888193421297644, 'IoU-130': 2.513848858225654, 'IoU-131': 2.473015063740725, 'IoU-132': 2.5305356913818806, 'IoU-133': 2.396402720877934, 'IoU-134': 2.6190646738398238, 'IoU-135': 2.50722579239231, 'IoU-136': 2.369953261337715, 'IoU-137': 2.3128947618443725, 'IoU-138': 2.169893959048919, 'IoU-139': 2.231381288091279, 'IoU-140': 2.3361090042061483, 'IoU-141': 2.450791618606277, 'IoU-142': 2.42517869013987, 'IoU-143': 2.2931244370018504, 'IoU-144': 2.3601965056843994, 'IoU-145': 2.501476795845281, 'IoU-146': 2.586784214078987, 'IoU-147': 2.669257995953953, 'IoU-148': 2.691585337875784, 'IoU-149': 2.573364392403111, 'IoU-150': 2.4302201912510895, 'IoU-151': 2.4632845967310706, 'IoU-152': 2.5222273730320293, 'IoU-153': 2.273978030686596, 'IoU-154': 2.1920073084461786, 'IoU-155': 2.269525596649846, 'IoU-156': 2.156565895507089, 'IoU-157': 1.9507128736935302, 'IoU-158': 2.063940177094149, 'IoU-159': 1.9358264395448914, 'IoU-160': 1.9551898772534044, 'IoU-161': 1.8452021189604293, 'IoU-162': 1.8499913985893686, 'IoU-163': 1.836283127073555, 'IoU-164': 2.109170131695232, 'IoU-165': 2.1034460712230674, 'IoU-166': 2.0409425796927927, 'IoU-167': 1.836005103770793, 'IoU-168': 1.833873464836637, 'IoU-169': 1.7743701633947242, 'IoU-170': 1.6401275348469673, 'IoU-171': 1.6910229645093946, 'IoU-172': 1.5408463642247228, 'IoU-173': 1.6183534938543271, 'IoU-174': 1.8989949408184406, 'IoU-175': 1.9574290394305507, 'IoU-176': 2.019834015358025, 'IoU-177': 1.8097327188114065, 'IoU-178': 1.8799155956263187, 'IoU-179': 1.955033347293941, 'IoU-180': 2.0059297318694815, 'IoU-181': 1.5188530216692095, 'IoU-182': 1.4390196678512763, 'IoU-183': 1.6123524127829345, 'IoU-184': 1.6366631388193882, 'IoU-185': 1.5829471925087528, 'IoU-186': 1.6964765768791068, 'IoU-187': 1.468286004435304, 'IoU-188': 1.0977058652580474, 'IoU-189': 1.2206543032814698, 'IoU-190': 1.2694761459981607, 'IoU-191': 1.0289071564343726, 'IoU-192': 0.8380936725160619, 'mACC': 7.738474378422977, 'pACC': 11.757165358005894, 'ACC-0': nan, 'ACC-1': 14.928435772029125, 'ACC-2': 4.663592956796479, 'ACC-3': 13.877957532160526, 'ACC-4': 13.996355283431022, 'ACC-5': 14.944377196623334, 'ACC-6': 15.658021133525457, 'ACC-7': 13.921006669073222, 'ACC-8': 21.20075463569063, 'ACC-9': 24.265457620689933, 'ACC-10': 30.13476411759645, 'ACC-11': 31.920087374724105, 'ACC-12': 26.812737390938636, 'ACC-13': 23.41615330385473, 'ACC-14': 20.77354844055188, 'ACC-15': 20.178987990492995, 'ACC-16': 19.624609807704942, 'ACC-17': 17.847217176132872, 'ACC-18': 16.890742545126656, 'ACC-19': 16.61985896068086, 'ACC-20': 19.135629047260576, 'ACC-21': 22.090891056131486, 'ACC-22': 23.81615752077541, 'ACC-23': 23.000584351213487, 'ACC-24': 21.043811394885818, 'ACC-25': 20.508582834455385, 'ACC-26': 18.789061353699672, 'ACC-27': 17.4644286722453, 'ACC-28': 15.036732529025768, 'ACC-29': 11.15658311232369, 'ACC-30': 9.01659201153196, 'ACC-31': 7.635777107357619, 'ACC-32': 6.0031331135848145, 'ACC-33': 4.645015449858936, 'ACC-34': 3.8191199995945397, 'ACC-35': 3.2037916573524186, 'ACC-36': 2.8154302336262056, 'ACC-37': 2.390758525388048, 'ACC-38': 2.20497644938104, 'ACC-39': 2.2575552306542526, 'ACC-40': 2.0727333395319767, 'ACC-41': 1.911613443096679, 'ACC-42': 1.8731472212591964, 'ACC-43': 1.9705861268898832, 'ACC-44': 2.1341213112918056, 'ACC-45': 2.3232240250954646, 'ACC-46': 2.496340542509172, 'ACC-47': 2.618309306011692, 'ACC-48': 3.1313633772778537, 'ACC-49': 3.6155315767983893, 'ACC-50': 4.075641226213594, 'ACC-51': 4.785037352018795, 'ACC-52': 5.474452669184957, 'ACC-53': 6.272163138658228, 'ACC-54': 7.082993873135546, 'ACC-55': 8.206241954528418, 'ACC-56': 8.898143725038421, 'ACC-57': 9.386546806749726, 'ACC-58': 9.805218067823745, 'ACC-59': 10.784516210114642, 'ACC-60': 11.661199463099454, 'ACC-61': 12.437004853305696, 'ACC-62': 12.75768950097545, 'ACC-63': 13.566812682335131, 'ACC-64': 14.332297240357628, 'ACC-65': 14.843391346796334, 'ACC-66': 14.818250463710395, 'ACC-67': 15.00884622798997, 'ACC-68': 14.62104546776953, 'ACC-69': 14.254967064536011, 'ACC-70': 13.662964451875514, 'ACC-71': 13.181546793744111, 'ACC-72': 12.898738203229195, 'ACC-73': 12.14639199953681, 'ACC-74': 12.117605909270592, 'ACC-75': 11.644955604162321, 'ACC-76': 11.597750786995793, 'ACC-77': 11.516494739799828, 'ACC-78': 10.577285058497845, 'ACC-79': 10.220220618251034, 'ACC-80': 9.536790556384107, 'ACC-81': 9.698664955895568, 'ACC-82': 9.143643244841515, 'ACC-83': 9.030371352327563, 'ACC-84': 8.722228264833, 'ACC-85': 8.569576622954598, 'ACC-86': 8.41493501372891, 'ACC-87': 8.128256250189638, 'ACC-88': 7.89926809030062, 'ACC-89': 7.91167854658525, 'ACC-90': 7.590689814727971, 'ACC-91': 7.348258940708975, 'ACC-92': 6.979197283885627, 'ACC-93': 7.136849613968127, 'ACC-94': 6.874968069655591, 'ACC-95': 6.642133793350941, 'ACC-96': 6.518626801017641, 'ACC-97': 6.023973651685402, 'ACC-98': 5.940263204120307, 'ACC-99': 5.656383373431337, 'ACC-100': 5.357633761425037, 'ACC-101': 5.460403802803097, 'ACC-102': 5.3287745032961045, 'ACC-103': 5.225110985170492, 'ACC-104': 4.996753645999853, 'ACC-105': 4.962009178274015, 'ACC-106': 5.088294672373705, 'ACC-107': 5.4678287186315595, 'ACC-108': 5.646403810274465, 'ACC-109': 5.512223540468019, 'ACC-110': 5.768390587771957, 'ACC-111': 5.758127614285835, 'ACC-112': 5.503226809579196, 'ACC-113': 5.464914060210735, 'ACC-114': 5.525807790606185, 'ACC-115': 5.54605866522334, 'ACC-116': 5.308163454600049, 'ACC-117': 5.4124840174648625, 'ACC-118': 5.26540529714737, 'ACC-119': 5.344457325789811, 'ACC-120': 5.324920847433208, 'ACC-121': 5.603719431129797, 'ACC-122': 5.621444139375583, 'ACC-123': 5.191900432037484, 'ACC-124': 5.550953305123166, 'ACC-125': 5.085858360625782, 'ACC-126': 4.904814706873468, 'ACC-127': 5.164518872244391, 'ACC-128': 4.713736338122994, 'ACC-129': 4.780808241175884, 'ACC-130': 4.80880604060953, 'ACC-131': 4.783769396556021, 'ACC-132': 4.839601491892109, 'ACC-133': 4.510672463886451, 'ACC-134': 4.864661783713917, 'ACC-135': 4.640556410694943, 'ACC-136': 4.326139116660455, 'ACC-137': 4.217698289672627, 'ACC-138': 3.9631824758230323, 'ACC-139': 4.075005349443699, 'ACC-140': 4.265206969837018, 'ACC-141': 4.472017490856517, 'ACC-142': 4.466661601434334, 'ACC-143': 4.218167179312991, 'ACC-144': 4.243682310469314, 'ACC-145': 4.36353390520318, 'ACC-146': 4.444166226493375, 'ACC-147': 4.550122471870468, 'ACC-148': 4.605687768702349, 'ACC-149': 4.535252948436712, 'ACC-150': 4.3038481343042445, 'ACC-151': 4.350008632872701, 'ACC-152': 4.351307836906036, 'ACC-153': 4.022037494889715, 'ACC-154': 3.9105036663907335, 'ACC-155': 4.066696083675779, 'ACC-156': 3.889297547745216, 'ACC-157': 3.517583151969011, 'ACC-158': 3.7340995919842044, 'ACC-159': 3.468113852465873, 'ACC-160': 3.4665874917820716, 'ACC-161': 3.206663839515153, 'ACC-162': 3.200138075513022, 'ACC-163': 3.1710087933225184, 'ACC-164': 3.6939535754102235, 'ACC-165': 3.658354487083769, 'ACC-166': 3.6007475530734134, 'ACC-167': 3.2552434004653072, 'ACC-168': 3.2162930240083285, 'ACC-169': 3.0512234200306403, 'ACC-170': 2.8512403294766604, 'ACC-171': 3.0060241738577678, 'ACC-172': 2.734571835077215, 'ACC-173': 2.873657325586429, 'ACC-174': 3.2923952067888287, 'ACC-175': 3.3647958145403285, 'ACC-176': 3.383568585923352, 'ACC-177': 2.9867855908026084, 'ACC-178': 3.054413393112954, 'ACC-179': 3.142535791064386, 'ACC-180': 3.1580219225820403, 'ACC-181': 2.4037629065274473, 'ACC-182': 2.1860464013017604, 'ACC-183': 2.350376433005306, 'ACC-184': 2.300005674939467, 'ACC-185': 2.1266725889090163, 'ACC-186': 2.1958003092408873, 'ACC-187': 1.8232730128763321, 'ACC-188': 1.3043301628571864, 'ACC-189': 1.3972360826637598, 'ACC-190': 1.3996436693060552, 'ACC-191': 1.1001773798462708, 'ACC-192': 0.878879034181183})])
[01/27 11:38:37] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 11:38:37] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 11:38:37] d2.evaluation.testing INFO: copypaste: 3.7855,0.6054,0.3149,4.0167,7.2477,7.7385,11.7572
[01/27 11:38:37] d2.utils.events INFO:  eta: 1 day, 2:36:22  iter: 13999  total_loss: 28.56  loss_mask: 2.856  loss_mask_0: 2.878  loss_mask_1: 2.854  loss_mask_2: 2.853  loss_mask_3: 2.853  loss_mask_4: 2.853  loss_mask_5: 2.854  loss_mask_6: 2.853  loss_mask_7: 2.856  loss_mask_8: 2.855  time: 1.8569  data_time: 0.4249  lr: 7.8733e-05  max_mem: 17484M
[01/27 11:39:19] d2.utils.events INFO:  eta: 1 day, 2:35:39  iter: 14019  total_loss: 34.31  loss_mask: 3.429  loss_mask_0: 3.467  loss_mask_1: 3.426  loss_mask_2: 3.425  loss_mask_3: 3.429  loss_mask_4: 3.426  loss_mask_5: 3.428  loss_mask_6: 3.423  loss_mask_7: 3.427  loss_mask_8: 3.428  time: 1.8573  data_time: 0.4177  lr: 7.8702e-05  max_mem: 17484M
[01/27 11:40:01] d2.utils.events INFO:  eta: 1 day, 2:34:37  iter: 14039  total_loss: 32.47  loss_mask: 3.241  loss_mask_0: 3.266  loss_mask_1: 3.243  loss_mask_2: 3.247  loss_mask_3: 3.242  loss_mask_4: 3.242  loss_mask_5: 3.246  loss_mask_6: 3.267  loss_mask_7: 3.243  loss_mask_8: 3.242  time: 1.8576  data_time: 0.4059  lr: 7.8671e-05  max_mem: 17484M
[01/27 11:40:42] d2.utils.events INFO:  eta: 1 day, 2:33:43  iter: 14059  total_loss: 30.48  loss_mask: 3.048  loss_mask_0: 3.069  loss_mask_1: 3.049  loss_mask_2: 3.045  loss_mask_3: 3.046  loss_mask_4: 3.044  loss_mask_5: 3.047  loss_mask_6: 3.04  loss_mask_7: 3.046  loss_mask_8: 3.05  time: 1.8579  data_time: 0.4072  lr: 7.864e-05  max_mem: 17484M
[01/27 11:41:24] d2.utils.events INFO:  eta: 1 day, 2:32:49  iter: 14079  total_loss: 32.29  loss_mask: 3.216  loss_mask_0: 3.295  loss_mask_1: 3.217  loss_mask_2: 3.21  loss_mask_3: 3.214  loss_mask_4: 3.242  loss_mask_5: 3.218  loss_mask_6: 3.231  loss_mask_7: 3.219  loss_mask_8: 3.21  time: 1.8582  data_time: 0.4064  lr: 7.8609e-05  max_mem: 17484M
[01/27 11:42:06] d2.utils.events INFO:  eta: 1 day, 2:32:24  iter: 14099  total_loss: 30.59  loss_mask: 3.058  loss_mask_0: 3.062  loss_mask_1: 3.061  loss_mask_2: 3.06  loss_mask_3: 3.058  loss_mask_4: 3.064  loss_mask_5: 3.057  loss_mask_6: 3.054  loss_mask_7: 3.059  loss_mask_8: 3.054  time: 1.8586  data_time: 0.4117  lr: 7.8579e-05  max_mem: 17484M
[01/27 11:42:48] d2.utils.events INFO:  eta: 1 day, 2:31:46  iter: 14119  total_loss: 32.26  loss_mask: 3.216  loss_mask_0: 3.299  loss_mask_1: 3.22  loss_mask_2: 3.218  loss_mask_3: 3.227  loss_mask_4: 3.217  loss_mask_5: 3.218  loss_mask_6: 3.216  loss_mask_7: 3.216  loss_mask_8: 3.213  time: 1.8589  data_time: 0.4075  lr: 7.8548e-05  max_mem: 17484M
[01/27 11:43:30] d2.utils.events INFO:  eta: 1 day, 2:31:09  iter: 14139  total_loss: 30.41  loss_mask: 3.037  loss_mask_0: 3.037  loss_mask_1: 3.034  loss_mask_2: 3.035  loss_mask_3: 3.036  loss_mask_4: 3.033  loss_mask_5: 3.035  loss_mask_6: 3.035  loss_mask_7: 3.034  loss_mask_8: 3.038  time: 1.8592  data_time: 0.4157  lr: 7.8517e-05  max_mem: 17484M
[01/27 11:44:12] d2.utils.events INFO:  eta: 1 day, 2:30:45  iter: 14159  total_loss: 32.04  loss_mask: 3.204  loss_mask_0: 3.236  loss_mask_1: 3.204  loss_mask_2: 3.206  loss_mask_3: 3.203  loss_mask_4: 3.202  loss_mask_5: 3.202  loss_mask_6: 3.203  loss_mask_7: 3.203  loss_mask_8: 3.203  time: 1.8596  data_time: 0.4078  lr: 7.8486e-05  max_mem: 17484M
[01/27 11:44:54] d2.utils.events INFO:  eta: 1 day, 2:29:57  iter: 14179  total_loss: 28.45  loss_mask: 2.841  loss_mask_0: 2.884  loss_mask_1: 2.841  loss_mask_2: 2.842  loss_mask_3: 2.842  loss_mask_4: 2.838  loss_mask_5: 2.839  loss_mask_6: 2.841  loss_mask_7: 2.842  loss_mask_8: 2.842  time: 1.8599  data_time: 0.4029  lr: 7.8455e-05  max_mem: 17484M
[01/27 11:45:36] d2.utils.events INFO:  eta: 1 day, 2:29:22  iter: 14199  total_loss: 29.8  loss_mask: 2.974  loss_mask_0: 3.014  loss_mask_1: 2.976  loss_mask_2: 2.976  loss_mask_3: 2.975  loss_mask_4: 2.977  loss_mask_5: 2.975  loss_mask_6: 2.979  loss_mask_7: 2.975  loss_mask_8: 2.974  time: 1.8602  data_time: 0.4059  lr: 7.8424e-05  max_mem: 17484M
[01/27 11:46:18] d2.utils.events INFO:  eta: 1 day, 2:28:59  iter: 14219  total_loss: 28.6  loss_mask: 2.851  loss_mask_0: 2.911  loss_mask_1: 2.852  loss_mask_2: 2.852  loss_mask_3: 2.85  loss_mask_4: 2.853  loss_mask_5: 2.852  loss_mask_6: 2.852  loss_mask_7: 2.852  loss_mask_8: 2.852  time: 1.8606  data_time: 0.4223  lr: 7.8394e-05  max_mem: 17484M
[01/27 11:46:59] d2.utils.events INFO:  eta: 1 day, 2:28:27  iter: 14239  total_loss: 27.67  loss_mask: 2.763  loss_mask_0: 2.838  loss_mask_1: 2.763  loss_mask_2: 2.763  loss_mask_3: 2.763  loss_mask_4: 2.764  loss_mask_5: 2.763  loss_mask_6: 2.764  loss_mask_7: 2.763  loss_mask_8: 2.762  time: 1.8609  data_time: 0.4192  lr: 7.8363e-05  max_mem: 17484M
[01/27 11:47:42] d2.utils.events INFO:  eta: 1 day, 2:27:29  iter: 14259  total_loss: 27.87  loss_mask: 2.778  loss_mask_0: 2.839  loss_mask_1: 2.777  loss_mask_2: 2.78  loss_mask_3: 2.779  loss_mask_4: 2.775  loss_mask_5: 2.778  loss_mask_6: 2.779  loss_mask_7: 2.777  loss_mask_8: 2.78  time: 1.8612  data_time: 0.4017  lr: 7.8332e-05  max_mem: 17484M
[01/27 11:48:23] d2.utils.events INFO:  eta: 1 day, 2:26:44  iter: 14279  total_loss: 28.8  loss_mask: 2.873  loss_mask_0: 2.925  loss_mask_1: 2.871  loss_mask_2: 2.871  loss_mask_3: 2.872  loss_mask_4: 2.87  loss_mask_5: 2.872  loss_mask_6: 2.871  loss_mask_7: 2.873  loss_mask_8: 2.873  time: 1.8615  data_time: 0.3982  lr: 7.8301e-05  max_mem: 17484M
[01/27 11:49:05] d2.utils.events INFO:  eta: 1 day, 2:26:06  iter: 14299  total_loss: 29.45  loss_mask: 2.938  loss_mask_0: 2.997  loss_mask_1: 2.937  loss_mask_2: 2.936  loss_mask_3: 2.937  loss_mask_4: 2.935  loss_mask_5: 2.937  loss_mask_6: 2.937  loss_mask_7: 2.938  loss_mask_8: 2.937  time: 1.8618  data_time: 0.4064  lr: 7.827e-05  max_mem: 17484M
[01/27 11:49:47] d2.utils.events INFO:  eta: 1 day, 2:26:24  iter: 14319  total_loss: 27.51  loss_mask: 2.747  loss_mask_0: 2.783  loss_mask_1: 2.747  loss_mask_2: 2.746  loss_mask_3: 2.746  loss_mask_4: 2.75  loss_mask_5: 2.748  loss_mask_6: 2.746  loss_mask_7: 2.748  loss_mask_8: 2.747  time: 1.8622  data_time: 0.3975  lr: 7.8239e-05  max_mem: 17484M
[01/27 11:50:29] d2.utils.events INFO:  eta: 1 day, 2:25:55  iter: 14339  total_loss: 28.24  loss_mask: 2.818  loss_mask_0: 2.883  loss_mask_1: 2.818  loss_mask_2: 2.817  loss_mask_3: 2.817  loss_mask_4: 2.818  loss_mask_5: 2.818  loss_mask_6: 2.819  loss_mask_7: 2.816  loss_mask_8: 2.817  time: 1.8625  data_time: 0.4245  lr: 7.8209e-05  max_mem: 17484M
[01/27 11:51:10] d2.utils.events INFO:  eta: 1 day, 2:24:36  iter: 14359  total_loss: 27.02  loss_mask: 2.7  loss_mask_0: 2.762  loss_mask_1: 2.698  loss_mask_2: 2.699  loss_mask_3: 2.699  loss_mask_4: 2.699  loss_mask_5: 2.7  loss_mask_6: 2.699  loss_mask_7: 2.699  loss_mask_8: 2.7  time: 1.8628  data_time: 0.4170  lr: 7.8178e-05  max_mem: 17484M
[01/27 11:51:52] d2.utils.events INFO:  eta: 1 day, 2:23:26  iter: 14379  total_loss: 29.63  loss_mask: 2.955  loss_mask_0: 3.04  loss_mask_1: 2.954  loss_mask_2: 2.955  loss_mask_3: 2.955  loss_mask_4: 2.954  loss_mask_5: 2.954  loss_mask_6: 2.954  loss_mask_7: 2.954  loss_mask_8: 2.955  time: 1.8631  data_time: 0.4120  lr: 7.8147e-05  max_mem: 17484M
[01/27 11:52:34] d2.utils.events INFO:  eta: 1 day, 2:22:38  iter: 14399  total_loss: 29.09  loss_mask: 2.903  loss_mask_0: 2.986  loss_mask_1: 2.9  loss_mask_2: 2.902  loss_mask_3: 2.899  loss_mask_4: 2.901  loss_mask_5: 2.9  loss_mask_6: 2.898  loss_mask_7: 2.902  loss_mask_8: 2.902  time: 1.8634  data_time: 0.3999  lr: 7.8116e-05  max_mem: 17484M
[01/27 11:53:15] d2.utils.events INFO:  eta: 1 day, 2:21:56  iter: 14419  total_loss: 28.6  loss_mask: 2.855  loss_mask_0: 2.911  loss_mask_1: 2.853  loss_mask_2: 2.855  loss_mask_3: 2.854  loss_mask_4: 2.853  loss_mask_5: 2.854  loss_mask_6: 2.853  loss_mask_7: 2.855  loss_mask_8: 2.854  time: 1.8637  data_time: 0.4048  lr: 7.8085e-05  max_mem: 17484M
[01/27 11:53:57] d2.utils.events INFO:  eta: 1 day, 2:20:44  iter: 14439  total_loss: 28.13  loss_mask: 2.809  loss_mask_0: 2.859  loss_mask_1: 2.807  loss_mask_2: 2.807  loss_mask_3: 2.808  loss_mask_4: 2.805  loss_mask_5: 2.807  loss_mask_6: 2.806  loss_mask_7: 2.808  loss_mask_8: 2.808  time: 1.8640  data_time: 0.4036  lr: 7.8054e-05  max_mem: 17484M
[01/27 11:54:39] d2.utils.events INFO:  eta: 1 day, 2:19:52  iter: 14459  total_loss: 28.96  loss_mask: 2.889  loss_mask_0: 2.971  loss_mask_1: 2.888  loss_mask_2: 2.885  loss_mask_3: 2.886  loss_mask_4: 2.892  loss_mask_5: 2.889  loss_mask_6: 2.887  loss_mask_7: 2.89  loss_mask_8: 2.888  time: 1.8643  data_time: 0.4054  lr: 7.8024e-05  max_mem: 17484M
[01/27 11:55:20] d2.utils.events INFO:  eta: 1 day, 2:19:25  iter: 14479  total_loss: 28.79  loss_mask: 2.877  loss_mask_0: 2.913  loss_mask_1: 2.874  loss_mask_2: 2.876  loss_mask_3: 2.875  loss_mask_4: 2.875  loss_mask_5: 2.875  loss_mask_6: 2.872  loss_mask_7: 2.875  loss_mask_8: 2.877  time: 1.8646  data_time: 0.4003  lr: 7.7993e-05  max_mem: 17484M
[01/27 11:56:02] d2.utils.events INFO:  eta: 1 day, 2:18:29  iter: 14499  total_loss: 28.88  loss_mask: 2.882  loss_mask_0: 2.944  loss_mask_1: 2.881  loss_mask_2: 2.881  loss_mask_3: 2.881  loss_mask_4: 2.882  loss_mask_5: 2.882  loss_mask_6: 2.881  loss_mask_7: 2.881  loss_mask_8: 2.881  time: 1.8649  data_time: 0.3985  lr: 7.7962e-05  max_mem: 17484M
[01/27 11:56:44] d2.utils.events INFO:  eta: 1 day, 2:18:16  iter: 14519  total_loss: 28.13  loss_mask: 2.804  loss_mask_0: 2.907  loss_mask_1: 2.802  loss_mask_2: 2.803  loss_mask_3: 2.804  loss_mask_4: 2.802  loss_mask_5: 2.803  loss_mask_6: 2.801  loss_mask_7: 2.804  loss_mask_8: 2.803  time: 1.8653  data_time: 0.4271  lr: 7.7931e-05  max_mem: 17484M
[01/27 11:57:26] d2.utils.events INFO:  eta: 1 day, 2:17:38  iter: 14539  total_loss: 27.87  loss_mask: 2.78  loss_mask_0: 2.844  loss_mask_1: 2.781  loss_mask_2: 2.778  loss_mask_3: 2.779  loss_mask_4: 2.782  loss_mask_5: 2.78  loss_mask_6: 2.78  loss_mask_7: 2.781  loss_mask_8: 2.779  time: 1.8656  data_time: 0.4021  lr: 7.79e-05  max_mem: 17484M
[01/27 11:58:08] d2.utils.events INFO:  eta: 1 day, 2:16:54  iter: 14559  total_loss: 28.18  loss_mask: 2.811  loss_mask_0: 2.878  loss_mask_1: 2.81  loss_mask_2: 2.81  loss_mask_3: 2.811  loss_mask_4: 2.809  loss_mask_5: 2.811  loss_mask_6: 2.811  loss_mask_7: 2.811  loss_mask_8: 2.811  time: 1.8659  data_time: 0.4031  lr: 7.7869e-05  max_mem: 17484M
[01/27 11:58:50] d2.utils.events INFO:  eta: 1 day, 2:16:04  iter: 14579  total_loss: 26.89  loss_mask: 2.686  loss_mask_0: 2.732  loss_mask_1: 2.684  loss_mask_2: 2.685  loss_mask_3: 2.683  loss_mask_4: 2.681  loss_mask_5: 2.685  loss_mask_6: 2.683  loss_mask_7: 2.684  loss_mask_8: 2.686  time: 1.8662  data_time: 0.3925  lr: 7.7839e-05  max_mem: 17484M
[01/27 11:59:32] d2.utils.events INFO:  eta: 1 day, 2:15:15  iter: 14599  total_loss: 27.56  loss_mask: 2.748  loss_mask_0: 2.833  loss_mask_1: 2.748  loss_mask_2: 2.747  loss_mask_3: 2.747  loss_mask_4: 2.749  loss_mask_5: 2.749  loss_mask_6: 2.748  loss_mask_7: 2.748  loss_mask_8: 2.747  time: 1.8665  data_time: 0.4035  lr: 7.7808e-05  max_mem: 17484M
[01/27 12:00:14] d2.utils.events INFO:  eta: 1 day, 2:14:44  iter: 14619  total_loss: 27.46  loss_mask: 2.738  loss_mask_0: 2.802  loss_mask_1: 2.74  loss_mask_2: 2.738  loss_mask_3: 2.737  loss_mask_4: 2.741  loss_mask_5: 2.74  loss_mask_6: 2.74  loss_mask_7: 2.739  loss_mask_8: 2.739  time: 1.8668  data_time: 0.4158  lr: 7.7777e-05  max_mem: 17484M
[01/27 12:00:55] d2.utils.events INFO:  eta: 1 day, 2:14:06  iter: 14639  total_loss: 27.95  loss_mask: 2.787  loss_mask_0: 2.875  loss_mask_1: 2.786  loss_mask_2: 2.786  loss_mask_3: 2.786  loss_mask_4: 2.786  loss_mask_5: 2.786  loss_mask_6: 2.786  loss_mask_7: 2.786  loss_mask_8: 2.787  time: 1.8671  data_time: 0.3943  lr: 7.7746e-05  max_mem: 17484M
[01/27 12:01:38] d2.utils.events INFO:  eta: 1 day, 2:13:39  iter: 14659  total_loss: 29.4  loss_mask: 2.932  loss_mask_0: 3.004  loss_mask_1: 2.932  loss_mask_2: 2.933  loss_mask_3: 2.933  loss_mask_4: 2.933  loss_mask_5: 2.933  loss_mask_6: 2.933  loss_mask_7: 2.933  loss_mask_8: 2.933  time: 1.8675  data_time: 0.4313  lr: 7.7715e-05  max_mem: 17484M
[01/27 12:02:19] d2.utils.events INFO:  eta: 1 day, 2:12:44  iter: 14679  total_loss: 26.93  loss_mask: 2.691  loss_mask_0: 2.725  loss_mask_1: 2.689  loss_mask_2: 2.689  loss_mask_3: 2.688  loss_mask_4: 2.69  loss_mask_5: 2.689  loss_mask_6: 2.689  loss_mask_7: 2.689  loss_mask_8: 2.69  time: 1.8677  data_time: 0.3867  lr: 7.7684e-05  max_mem: 17484M
[01/27 12:03:01] d2.utils.events INFO:  eta: 1 day, 2:12:05  iter: 14699  total_loss: 27.69  loss_mask: 2.757  loss_mask_0: 2.864  loss_mask_1: 2.758  loss_mask_2: 2.758  loss_mask_3: 2.76  loss_mask_4: 2.759  loss_mask_5: 2.757  loss_mask_6: 2.758  loss_mask_7: 2.759  loss_mask_8: 2.759  time: 1.8680  data_time: 0.4108  lr: 7.7653e-05  max_mem: 17484M
[01/27 12:03:43] d2.utils.events INFO:  eta: 1 day, 2:12:37  iter: 14719  total_loss: 28.35  loss_mask: 2.827  loss_mask_0: 2.915  loss_mask_1: 2.825  loss_mask_2: 2.827  loss_mask_3: 2.828  loss_mask_4: 2.825  loss_mask_5: 2.826  loss_mask_6: 2.827  loss_mask_7: 2.825  loss_mask_8: 2.827  time: 1.8684  data_time: 0.4296  lr: 7.7623e-05  max_mem: 17484M
[01/27 12:04:25] d2.utils.events INFO:  eta: 1 day, 2:12:19  iter: 14739  total_loss: 29.5  loss_mask: 2.941  loss_mask_0: 3.017  loss_mask_1: 2.941  loss_mask_2: 2.941  loss_mask_3: 2.941  loss_mask_4: 2.942  loss_mask_5: 2.942  loss_mask_6: 2.94  loss_mask_7: 2.942  loss_mask_8: 2.941  time: 1.8687  data_time: 0.4026  lr: 7.7592e-05  max_mem: 17484M
[01/27 12:05:07] d2.utils.events INFO:  eta: 1 day, 2:11:37  iter: 14759  total_loss: 27.81  loss_mask: 2.773  loss_mask_0: 2.856  loss_mask_1: 2.773  loss_mask_2: 2.772  loss_mask_3: 2.773  loss_mask_4: 2.772  loss_mask_5: 2.772  loss_mask_6: 2.773  loss_mask_7: 2.773  loss_mask_8: 2.772  time: 1.8690  data_time: 0.4153  lr: 7.7561e-05  max_mem: 17484M
[01/27 12:05:49] d2.utils.events INFO:  eta: 1 day, 2:10:58  iter: 14779  total_loss: 30.22  loss_mask: 3.02  loss_mask_0: 3.095  loss_mask_1: 3.019  loss_mask_2: 3.018  loss_mask_3: 3.021  loss_mask_4: 3.019  loss_mask_5: 3.019  loss_mask_6: 3.018  loss_mask_7: 3.018  loss_mask_8: 3.017  time: 1.8693  data_time: 0.4141  lr: 7.753e-05  max_mem: 17484M
[01/27 12:06:30] d2.utils.events INFO:  eta: 1 day, 2:10:17  iter: 14799  total_loss: 29.9  loss_mask: 2.992  loss_mask_0: 3.023  loss_mask_1: 2.988  loss_mask_2: 2.989  loss_mask_3: 2.988  loss_mask_4: 2.994  loss_mask_5: 2.986  loss_mask_6: 2.989  loss_mask_7: 2.987  loss_mask_8: 2.988  time: 1.8695  data_time: 0.3978  lr: 7.7499e-05  max_mem: 17484M
[01/27 12:07:12] d2.utils.events INFO:  eta: 1 day, 2:09:44  iter: 14819  total_loss: 31.52  loss_mask: 3.144  loss_mask_0: 3.184  loss_mask_1: 3.15  loss_mask_2: 3.145  loss_mask_3: 3.143  loss_mask_4: 3.153  loss_mask_5: 3.151  loss_mask_6: 3.149  loss_mask_7: 3.147  loss_mask_8: 3.149  time: 1.8698  data_time: 0.4200  lr: 7.7468e-05  max_mem: 17484M
[01/27 12:07:54] d2.utils.events INFO:  eta: 1 day, 2:09:58  iter: 14839  total_loss: 28.02  loss_mask: 2.803  loss_mask_0: 2.82  loss_mask_1: 2.799  loss_mask_2: 2.8  loss_mask_3: 2.798  loss_mask_4: 2.799  loss_mask_5: 2.8  loss_mask_6: 2.8  loss_mask_7: 2.797  loss_mask_8: 2.8  time: 1.8701  data_time: 0.4201  lr: 7.7437e-05  max_mem: 17484M
[01/27 12:08:36] d2.utils.events INFO:  eta: 1 day, 2:09:23  iter: 14859  total_loss: 27.14  loss_mask: 2.709  loss_mask_0: 2.735  loss_mask_1: 2.712  loss_mask_2: 2.712  loss_mask_3: 2.711  loss_mask_4: 2.711  loss_mask_5: 2.71  loss_mask_6: 2.711  loss_mask_7: 2.712  loss_mask_8: 2.714  time: 1.8704  data_time: 0.4294  lr: 7.7407e-05  max_mem: 17484M
[01/27 12:09:18] d2.utils.events INFO:  eta: 1 day, 2:09:27  iter: 14879  total_loss: 28.1  loss_mask: 2.809  loss_mask_0: 2.824  loss_mask_1: 2.808  loss_mask_2: 2.81  loss_mask_3: 2.81  loss_mask_4: 2.807  loss_mask_5: 2.809  loss_mask_6: 2.807  loss_mask_7: 2.809  loss_mask_8: 2.809  time: 1.8708  data_time: 0.4277  lr: 7.7376e-05  max_mem: 17484M
[01/27 12:10:01] d2.utils.events INFO:  eta: 1 day, 2:09:07  iter: 14899  total_loss: 27.2  loss_mask: 2.718  loss_mask_0: 2.744  loss_mask_1: 2.718  loss_mask_2: 2.717  loss_mask_3: 2.718  loss_mask_4: 2.718  loss_mask_5: 2.718  loss_mask_6: 2.717  loss_mask_7: 2.718  loss_mask_8: 2.717  time: 1.8711  data_time: 0.4075  lr: 7.7345e-05  max_mem: 17484M
[01/27 12:10:43] d2.utils.events INFO:  eta: 1 day, 2:09:19  iter: 14919  total_loss: 25.73  loss_mask: 2.57  loss_mask_0: 2.596  loss_mask_1: 2.57  loss_mask_2: 2.57  loss_mask_3: 2.571  loss_mask_4: 2.568  loss_mask_5: 2.569  loss_mask_6: 2.57  loss_mask_7: 2.57  loss_mask_8: 2.57  time: 1.8714  data_time: 0.4216  lr: 7.7314e-05  max_mem: 17484M
[01/27 12:11:25] d2.utils.events INFO:  eta: 1 day, 2:08:27  iter: 14939  total_loss: 24.79  loss_mask: 2.476  loss_mask_0: 2.515  loss_mask_1: 2.476  loss_mask_2: 2.477  loss_mask_3: 2.476  loss_mask_4: 2.477  loss_mask_5: 2.476  loss_mask_6: 2.476  loss_mask_7: 2.476  loss_mask_8: 2.477  time: 1.8717  data_time: 0.4074  lr: 7.7283e-05  max_mem: 17484M
[01/27 12:12:07] d2.utils.events INFO:  eta: 1 day, 2:08:16  iter: 14959  total_loss: 27.05  loss_mask: 2.702  loss_mask_0: 2.727  loss_mask_1: 2.701  loss_mask_2: 2.7  loss_mask_3: 2.702  loss_mask_4: 2.701  loss_mask_5: 2.702  loss_mask_6: 2.701  loss_mask_7: 2.702  loss_mask_8: 2.7  time: 1.8720  data_time: 0.4082  lr: 7.7252e-05  max_mem: 17484M
[01/27 12:12:49] d2.utils.events INFO:  eta: 1 day, 2:07:22  iter: 14979  total_loss: 26.48  loss_mask: 2.646  loss_mask_0: 2.674  loss_mask_1: 2.646  loss_mask_2: 2.646  loss_mask_3: 2.646  loss_mask_4: 2.644  loss_mask_5: 2.645  loss_mask_6: 2.645  loss_mask_7: 2.645  loss_mask_8: 2.645  time: 1.8723  data_time: 0.4119  lr: 7.7221e-05  max_mem: 17484M
[01/27 12:13:31] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE/model_0014999.pth
[01/27 12:13:32] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 12:13:32] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 12:13:32] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 12:20:48] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.6051559709475502, 'error_1pix': 0.34468018561297015, 'error_3pix': 0.15064255866818888, 'mIoU': 7.958834266303742, 'fwIoU': 18.148815537613345, 'IoU-0': nan, 'IoU-1': 38.005784661602746, 'IoU-2': 2.2850658218831708, 'IoU-3': 2.5164544180281343, 'IoU-4': 2.6453399143947864, 'IoU-5': 2.8337492688209296, 'IoU-6': 3.160874604640198, 'IoU-7': 3.076830069877023, 'IoU-8': 4.405845854235388, 'IoU-9': 13.944377606049658, 'IoU-10': 20.162292462952262, 'IoU-11': 26.12219649189558, 'IoU-12': 24.98608106534954, 'IoU-13': 23.144667243502226, 'IoU-14': 22.864069089601525, 'IoU-15': 22.925015227432848, 'IoU-16': 23.089891763985655, 'IoU-17': 19.28285984163057, 'IoU-18': 19.248043852929534, 'IoU-19': 19.300642563825836, 'IoU-20': 19.551084350734698, 'IoU-21': 19.342598793768417, 'IoU-22': 20.53303659161079, 'IoU-23': 19.401857827156434, 'IoU-24': 18.768798551598255, 'IoU-25': 18.464142868858865, 'IoU-26': 18.885098857425525, 'IoU-27': 20.514799189579698, 'IoU-28': 19.344746772286197, 'IoU-29': 19.85784097831872, 'IoU-30': 19.164839212593655, 'IoU-31': 19.966519333005238, 'IoU-32': 20.012148036544342, 'IoU-33': 18.559380451618825, 'IoU-34': 18.17579076032775, 'IoU-35': 19.184984741503097, 'IoU-36': 19.6452076309113, 'IoU-37': 18.894570161414627, 'IoU-38': 18.96116651651188, 'IoU-39': 18.23405006997655, 'IoU-40': 17.962806157052448, 'IoU-41': 17.136753824982538, 'IoU-42': 16.86207072656421, 'IoU-43': 16.64943050879176, 'IoU-44': 16.869775193337663, 'IoU-45': 16.306142027263007, 'IoU-46': 15.423666056161265, 'IoU-47': 15.359534680110027, 'IoU-48': 15.110529536097186, 'IoU-49': 15.005476397933116, 'IoU-50': 14.864805399142641, 'IoU-51': 14.122951026943639, 'IoU-52': 13.613219041045719, 'IoU-53': 13.425945511304569, 'IoU-54': 13.697095257999258, 'IoU-55': 13.111841426362403, 'IoU-56': 12.456253773492014, 'IoU-57': 12.337161663618, 'IoU-58': 12.062911688783748, 'IoU-59': 11.47325233263827, 'IoU-60': 11.252905390103402, 'IoU-61': 10.903197959540904, 'IoU-62': 10.672682650057705, 'IoU-63': 10.352748477459974, 'IoU-64': 10.276668969654649, 'IoU-65': 9.655403269004669, 'IoU-66': 9.589911824686531, 'IoU-67': 9.208017866202736, 'IoU-68': 8.80617439122249, 'IoU-69': 8.846341543118582, 'IoU-70': 8.979575947307689, 'IoU-71': 8.407060077489975, 'IoU-72': 8.203354072961083, 'IoU-73': 7.981163032126147, 'IoU-74': 8.078980565002583, 'IoU-75': 7.911475078544612, 'IoU-76': 8.006621600123404, 'IoU-77': 7.948389762372175, 'IoU-78': 7.62587113720745, 'IoU-79': 7.548744877374661, 'IoU-80': 7.510792471633643, 'IoU-81': 7.74881610007569, 'IoU-82': 7.5930935975270675, 'IoU-83': 7.45839393483962, 'IoU-84': 7.389532078031226, 'IoU-85': 7.394540760014682, 'IoU-86': 7.224495526413591, 'IoU-87': 6.953128683971636, 'IoU-88': 7.002936638672273, 'IoU-89': 6.910056540255774, 'IoU-90': 6.7554463674461935, 'IoU-91': 6.411793574334449, 'IoU-92': 6.2133553260525956, 'IoU-93': 6.394681510586168, 'IoU-94': 6.182885627322944, 'IoU-95': 5.768941420141132, 'IoU-96': 5.53073230403039, 'IoU-97': 5.666400230176874, 'IoU-98': 5.478441771677055, 'IoU-99': 5.4767855489598585, 'IoU-100': 5.396011476457177, 'IoU-101': 5.411146482320278, 'IoU-102': 5.275453237259917, 'IoU-103': 5.019628216215686, 'IoU-104': 5.205849006801673, 'IoU-105': 5.0040465791357045, 'IoU-106': 4.711726829482391, 'IoU-107': 4.74741271729293, 'IoU-108': 4.884979730868887, 'IoU-109': 4.962633938909121, 'IoU-110': 4.841148748728184, 'IoU-111': 4.607691539666959, 'IoU-112': 4.67725586688052, 'IoU-113': 4.582834174802539, 'IoU-114': 4.438704031043487, 'IoU-115': 4.271451152090536, 'IoU-116': 4.138691449344711, 'IoU-117': 4.227410866630577, 'IoU-118': 4.0733935370509995, 'IoU-119': 3.978361663588302, 'IoU-120': 3.9253715739319963, 'IoU-121': 3.8322136303396834, 'IoU-122': 3.6653188884535033, 'IoU-123': 3.6855839857704664, 'IoU-124': 3.595844895078806, 'IoU-125': 3.5140043152294744, 'IoU-126': 3.3762360091913126, 'IoU-127': 3.421439091478012, 'IoU-128': 3.2887968595401023, 'IoU-129': 3.094570573659508, 'IoU-130': 3.0340038495920245, 'IoU-131': 3.0563247550525268, 'IoU-132': 2.8794004332225476, 'IoU-133': 2.7993358280730503, 'IoU-134': 2.6027098609983326, 'IoU-135': 2.6436868081201426, 'IoU-136': 2.6377406091419435, 'IoU-137': 2.5020831015440965, 'IoU-138': 2.340003809482617, 'IoU-139': 2.370755767262149, 'IoU-140': 2.3911855262692234, 'IoU-141': 2.569607136017811, 'IoU-142': 2.4416481940279047, 'IoU-143': 2.3496554225607547, 'IoU-144': 2.2855653894046624, 'IoU-145': 2.5079111804404066, 'IoU-146': 2.629852355928624, 'IoU-147': 2.4708354086769218, 'IoU-148': 2.459310515313926, 'IoU-149': 2.1725450309489003, 'IoU-150': 2.3258924021437326, 'IoU-151': 2.5408567057313447, 'IoU-152': 2.4060041270380017, 'IoU-153': 2.226403708834436, 'IoU-154': 2.0671361502347416, 'IoU-155': 2.1038904555367965, 'IoU-156': 2.191007617586613, 'IoU-157': 1.9652378506958679, 'IoU-158': 2.0970111303503063, 'IoU-159': 1.847215068327642, 'IoU-160': 1.9210758992223007, 'IoU-161': 2.174543814572555, 'IoU-162': 2.181969123361523, 'IoU-163': 2.611001651328007, 'IoU-164': 2.319652535399109, 'IoU-165': 2.024588195405871, 'IoU-166': 2.2072765681271553, 'IoU-167': 1.9733104858893913, 'IoU-168': 1.8331499662715245, 'IoU-169': 1.696175092098665, 'IoU-170': 1.602228011358723, 'IoU-171': 1.8079213384197028, 'IoU-172': 1.7832808415158812, 'IoU-173': 1.9208939083471008, 'IoU-174': 1.9704412932690853, 'IoU-175': 2.1582865203243125, 'IoU-176': 1.7998163250231247, 'IoU-177': 1.788492874027494, 'IoU-178': 1.7620154275158488, 'IoU-179': 2.232588098404255, 'IoU-180': 2.0712200129582725, 'IoU-181': 1.039310959771526, 'IoU-182': 0.9157609030253884, 'IoU-183': 0.7633457004220293, 'IoU-184': 0.627912222341889, 'IoU-185': 0.49552221226690896, 'IoU-186': 0.3694901036569534, 'IoU-187': 0.2076291534530236, 'IoU-188': 0.1739224823795556, 'IoU-189': 0.07792768209567083, 'IoU-190': 0.042402091489666116, 'IoU-191': 0.053262386102934114, 'IoU-192': 0.043667999244966206, 'mACC': 14.091804925559773, 'pACC': 28.165105685294566, 'ACC-0': nan, 'ACC-1': 38.48315751055498, 'ACC-2': 4.519817884908942, 'ACC-3': 12.047459162428279, 'ACC-4': 11.49896008914671, 'ACC-5': 12.339755982469624, 'ACC-6': 13.874416430824525, 'ACC-7': 14.567859369701477, 'ACC-8': 10.22689039238613, 'ACC-9': 22.71842917919912, 'ACC-10': 36.290816689130466, 'ACC-11': 40.31493502777834, 'ACC-12': 39.345493990775836, 'ACC-13': 36.51011056167028, 'ACC-14': 35.63175756034261, 'ACC-15': 36.70798099010141, 'ACC-16': 37.56355235530322, 'ACC-17': 33.33760252025793, 'ACC-18': 31.905340162617595, 'ACC-19': 31.71669113632396, 'ACC-20': 32.45824769136177, 'ACC-21': 32.350172384502024, 'ACC-22': 33.81102299803388, 'ACC-23': 33.122009436668606, 'ACC-24': 31.61947745470605, 'ACC-25': 31.236918485640068, 'ACC-26': 32.32439467740329, 'ACC-27': 34.40035897683145, 'ACC-28': 33.03676255863952, 'ACC-29': 32.89407403460584, 'ACC-30': 32.511556825912336, 'ACC-31': 33.177311347417046, 'ACC-32': 33.65841493599866, 'ACC-33': 31.290859687321355, 'ACC-34': 30.474428024847334, 'ACC-35': 32.214210575183714, 'ACC-36': 33.50331013023273, 'ACC-37': 32.81479676337648, 'ACC-38': 32.55863660149238, 'ACC-39': 31.37944416439298, 'ACC-40': 30.58952725142837, 'ACC-41': 29.87638570320697, 'ACC-42': 29.26176538472946, 'ACC-43': 28.918535177366877, 'ACC-44': 28.784247236500214, 'ACC-45': 28.039687942153503, 'ACC-46': 27.08277143462668, 'ACC-47': 27.18390187628546, 'ACC-48': 26.857268271452007, 'ACC-49': 26.58711030155133, 'ACC-50': 26.328451590231218, 'ACC-51': 25.41245493644747, 'ACC-52': 24.388199854923105, 'ACC-53': 24.14366380132468, 'ACC-54': 24.582741004831878, 'ACC-55': 23.63899129482026, 'ACC-56': 22.5990188989295, 'ACC-57': 21.962229716850512, 'ACC-58': 21.686086122196002, 'ACC-59': 20.868222915898244, 'ACC-60': 20.517390380437167, 'ACC-61': 19.85594169355528, 'ACC-62': 19.522161577485956, 'ACC-63': 19.143620686856526, 'ACC-64': 19.077959347891888, 'ACC-65': 18.120824754301303, 'ACC-66': 18.01991675493892, 'ACC-67': 17.347452030294498, 'ACC-68': 16.659721533791693, 'ACC-69': 16.429897175512146, 'ACC-70': 16.56219725085241, 'ACC-71': 15.76196574576315, 'ACC-72': 15.467757052226075, 'ACC-73': 14.951499821662898, 'ACC-74': 15.035956936858291, 'ACC-75': 14.851677170023336, 'ACC-76': 14.743223956698392, 'ACC-77': 14.76740040420589, 'ACC-78': 14.305467466973159, 'ACC-79': 14.160175894089303, 'ACC-80': 14.04096611045322, 'ACC-81': 14.439151838691128, 'ACC-82': 14.156583195862996, 'ACC-83': 13.763663068516147, 'ACC-84': 13.648806007204481, 'ACC-85': 13.698534861103203, 'ACC-86': 13.418246434960071, 'ACC-87': 12.934941552664265, 'ACC-88': 13.031371041794287, 'ACC-89': 12.790809861893464, 'ACC-90': 12.396801874188432, 'ACC-91': 11.81191487045504, 'ACC-92': 11.576511273897442, 'ACC-93': 11.875568197638419, 'ACC-94': 11.43185395486205, 'ACC-95': 10.609250509177793, 'ACC-96': 10.227916712254673, 'ACC-97': 10.240138857001293, 'ACC-98': 9.931796998085824, 'ACC-99': 10.027310096289206, 'ACC-100': 9.84060281588717, 'ACC-101': 9.863610747273654, 'ACC-102': 9.620229362162947, 'ACC-103': 9.185846203980622, 'ACC-104': 9.54105908911263, 'ACC-105': 9.171429512730137, 'ACC-106': 8.557750980257959, 'ACC-107': 8.697956781501158, 'ACC-108': 8.952398376421577, 'ACC-109': 9.022159286616404, 'ACC-110': 8.826628961033563, 'ACC-111': 8.489692971940977, 'ACC-112': 8.788193033347815, 'ACC-113': 8.673182589758662, 'ACC-114': 8.435614178878476, 'ACC-115': 8.05771052275495, 'ACC-116': 7.832094778891699, 'ACC-117': 7.932561135457158, 'ACC-118': 7.6623096892677784, 'ACC-119': 7.462673764130701, 'ACC-120': 7.355566331783665, 'ACC-121': 7.123958781392126, 'ACC-122': 6.81333559776199, 'ACC-123': 6.905297146657877, 'ACC-124': 6.911242389194827, 'ACC-125': 6.723731540207731, 'ACC-126': 6.481844096940774, 'ACC-127': 6.568372753693614, 'ACC-128': 6.423719738355464, 'ACC-129': 6.0337270223443245, 'ACC-130': 5.929682723536862, 'ACC-131': 6.017692410446378, 'ACC-132': 5.602034763901036, 'ACC-133': 5.349091973027958, 'ACC-134': 4.929599310641965, 'ACC-135': 5.05850578644319, 'ACC-136': 4.985309704621692, 'ACC-137': 4.7716523293469715, 'ACC-138': 4.463061908267127, 'ACC-139': 4.511241210310612, 'ACC-140': 4.532895358024937, 'ACC-141': 4.8330481865760255, 'ACC-142': 4.578807361723162, 'ACC-143': 4.365872419655727, 'ACC-144': 4.187831003000011, 'ACC-145': 4.521372467814057, 'ACC-146': 4.688635181852992, 'ACC-147': 4.371265547162628, 'ACC-148': 4.29328479156666, 'ACC-149': 3.8688628997253693, 'ACC-150': 4.115179153094463, 'ACC-151': 4.451691979749533, 'ACC-152': 4.123283326361089, 'ACC-153': 3.9295108982573552, 'ACC-154': 3.619021674676712, 'ACC-155': 3.6849721670274187, 'ACC-156': 3.8704205539810923, 'ACC-157': 3.510918790010495, 'ACC-158': 3.7658882231302884, 'ACC-159': 3.2950454506140194, 'ACC-160': 3.3701764482143792, 'ACC-161': 3.778043954778618, 'ACC-162': 3.89451572207279, 'ACC-163': 4.6554183272413745, 'ACC-164': 4.147929444447969, 'ACC-165': 3.6420874736333833, 'ACC-166': 4.077297898133876, 'ACC-167': 3.657290779895412, 'ACC-168': 3.3021489114761016, 'ACC-169': 3.015788882492523, 'ACC-170': 2.8614741207002448, 'ACC-171': 3.263420398307094, 'ACC-172': 3.2102187454837194, 'ACC-173': 3.497556604697041, 'ACC-174': 3.5211792966593563, 'ACC-175': 3.716124354210097, 'ACC-176': 2.963246665553369, 'ACC-177': 2.8793219387114175, 'ACC-178': 2.8012033052227, 'ACC-179': 3.491917121808842, 'ACC-180': 3.1284355280466185, 'ACC-181': 1.5258594520755862, 'ACC-182': 1.235411653591142, 'ACC-183': 0.9456565828074446, 'ACC-184': 0.7294789773129677, 'ACC-185': 0.5448482241555547, 'ACC-186': 0.3934663320430474, 'ACC-187': 0.21651200371578141, 'ACC-188': 0.1780235597136472, 'ACC-189': 0.07892091712789559, 'ACC-190': 0.04278675658010442, 'ACC-191': 0.05361972368840925, 'ACC-192': 0.04394545093703042})])
[01/27 12:20:48] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 12:20:48] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 12:20:48] d2.evaluation.testing INFO: copypaste: 2.6052,0.3447,0.1506,7.9588,18.1488,14.0918,28.1651
[01/27 12:20:48] d2.utils.events INFO:  eta: 1 day, 2:07:09  iter: 14999  total_loss: 26.98  loss_mask: 2.697  loss_mask_0: 2.715  loss_mask_1: 2.695  loss_mask_2: 2.698  loss_mask_3: 2.696  loss_mask_4: 2.697  loss_mask_5: 2.695  loss_mask_6: 2.696  loss_mask_7: 2.695  loss_mask_8: 2.695  time: 1.8726  data_time: 0.4031  lr: 7.719e-05  max_mem: 17484M
[01/27 12:21:31] d2.utils.events INFO:  eta: 1 day, 2:07:05  iter: 15019  total_loss: 27.48  loss_mask: 2.745  loss_mask_0: 2.781  loss_mask_1: 2.743  loss_mask_2: 2.745  loss_mask_3: 2.744  loss_mask_4: 2.744  loss_mask_5: 2.744  loss_mask_6: 2.744  loss_mask_7: 2.743  loss_mask_8: 2.744  time: 1.8730  data_time: 0.4224  lr: 7.716e-05  max_mem: 17484M
[01/27 12:22:13] d2.utils.events INFO:  eta: 1 day, 2:06:30  iter: 15039  total_loss: 27.34  loss_mask: 2.732  loss_mask_0: 2.751  loss_mask_1: 2.731  loss_mask_2: 2.732  loss_mask_3: 2.733  loss_mask_4: 2.728  loss_mask_5: 2.731  loss_mask_6: 2.73  loss_mask_7: 2.732  loss_mask_8: 2.732  time: 1.8733  data_time: 0.4088  lr: 7.7129e-05  max_mem: 17484M
[01/27 12:22:55] d2.utils.events INFO:  eta: 1 day, 2:06:15  iter: 15059  total_loss: 29.63  loss_mask: 2.961  loss_mask_0: 2.986  loss_mask_1: 2.961  loss_mask_2: 2.962  loss_mask_3: 2.96  loss_mask_4: 2.962  loss_mask_5: 2.959  loss_mask_6: 2.961  loss_mask_7: 2.96  loss_mask_8: 2.959  time: 1.8736  data_time: 0.4349  lr: 7.7098e-05  max_mem: 17484M
[01/27 12:23:37] d2.utils.events INFO:  eta: 1 day, 2:05:42  iter: 15079  total_loss: 27.35  loss_mask: 2.732  loss_mask_0: 2.766  loss_mask_1: 2.732  loss_mask_2: 2.729  loss_mask_3: 2.731  loss_mask_4: 2.728  loss_mask_5: 2.732  loss_mask_6: 2.733  loss_mask_7: 2.734  loss_mask_8: 2.731  time: 1.8739  data_time: 0.4000  lr: 7.7067e-05  max_mem: 17484M
[01/27 12:24:19] d2.utils.events INFO:  eta: 1 day, 2:05:03  iter: 15099  total_loss: 27.86  loss_mask: 2.783  loss_mask_0: 2.815  loss_mask_1: 2.782  loss_mask_2: 2.783  loss_mask_3: 2.784  loss_mask_4: 2.781  loss_mask_5: 2.784  loss_mask_6: 2.783  loss_mask_7: 2.783  loss_mask_8: 2.782  time: 1.8742  data_time: 0.4164  lr: 7.7036e-05  max_mem: 17484M
[01/27 12:25:02] d2.utils.events INFO:  eta: 1 day, 2:04:21  iter: 15119  total_loss: 26.75  loss_mask: 2.673  loss_mask_0: 2.68  loss_mask_1: 2.674  loss_mask_2: 2.673  loss_mask_3: 2.674  loss_mask_4: 2.675  loss_mask_5: 2.674  loss_mask_6: 2.674  loss_mask_7: 2.675  loss_mask_8: 2.674  time: 1.8745  data_time: 0.4114  lr: 7.7005e-05  max_mem: 17484M
[01/27 12:25:44] d2.utils.events INFO:  eta: 1 day, 2:04:04  iter: 15139  total_loss: 34.23  loss_mask: 3.422  loss_mask_0: 3.441  loss_mask_1: 3.421  loss_mask_2: 3.425  loss_mask_3: 3.424  loss_mask_4: 3.42  loss_mask_5: 3.417  loss_mask_6: 3.422  loss_mask_7: 3.418  loss_mask_8: 3.42  time: 1.8748  data_time: 0.4025  lr: 7.6974e-05  max_mem: 17484M
[01/27 12:26:26] d2.utils.events INFO:  eta: 1 day, 2:03:51  iter: 15159  total_loss: 32.32  loss_mask: 3.227  loss_mask_0: 3.268  loss_mask_1: 3.231  loss_mask_2: 3.228  loss_mask_3: 3.232  loss_mask_4: 3.224  loss_mask_5: 3.23  loss_mask_6: 3.226  loss_mask_7: 3.229  loss_mask_8: 3.229  time: 1.8751  data_time: 0.4201  lr: 7.6943e-05  max_mem: 17484M
[01/27 12:27:08] d2.utils.events INFO:  eta: 1 day, 2:03:19  iter: 15179  total_loss: 32.79  loss_mask: 3.275  loss_mask_0: 3.311  loss_mask_1: 3.274  loss_mask_2: 3.276  loss_mask_3: 3.275  loss_mask_4: 3.274  loss_mask_5: 3.275  loss_mask_6: 3.278  loss_mask_7: 3.273  loss_mask_8: 3.275  time: 1.8754  data_time: 0.4106  lr: 7.6913e-05  max_mem: 17484M
[01/27 12:27:50] d2.utils.events INFO:  eta: 1 day, 2:02:44  iter: 15199  total_loss: 32.08  loss_mask: 3.208  loss_mask_0: 3.218  loss_mask_1: 3.205  loss_mask_2: 3.207  loss_mask_3: 3.207  loss_mask_4: 3.206  loss_mask_5: 3.206  loss_mask_6: 3.205  loss_mask_7: 3.208  loss_mask_8: 3.208  time: 1.8757  data_time: 0.4096  lr: 7.6882e-05  max_mem: 17484M
[01/27 12:28:33] d2.utils.events INFO:  eta: 1 day, 2:01:55  iter: 15219  total_loss: 29.92  loss_mask: 2.988  loss_mask_0: 3.012  loss_mask_1: 2.991  loss_mask_2: 2.989  loss_mask_3: 2.99  loss_mask_4: 2.99  loss_mask_5: 2.992  loss_mask_6: 2.988  loss_mask_7: 2.99  loss_mask_8: 2.989  time: 1.8760  data_time: 0.4092  lr: 7.6851e-05  max_mem: 17484M
[01/27 12:29:14] d2.utils.events INFO:  eta: 1 day, 2:01:10  iter: 15239  total_loss: 32.91  loss_mask: 3.287  loss_mask_0: 3.321  loss_mask_1: 3.287  loss_mask_2: 3.287  loss_mask_3: 3.286  loss_mask_4: 3.288  loss_mask_5: 3.286  loss_mask_6: 3.285  loss_mask_7: 3.286  loss_mask_8: 3.286  time: 1.8763  data_time: 0.4043  lr: 7.682e-05  max_mem: 17484M
[01/27 12:29:56] d2.utils.events INFO:  eta: 1 day, 2:00:38  iter: 15259  total_loss: 28.21  loss_mask: 2.816  loss_mask_0: 2.856  loss_mask_1: 2.817  loss_mask_2: 2.818  loss_mask_3: 2.818  loss_mask_4: 2.817  loss_mask_5: 2.82  loss_mask_6: 2.818  loss_mask_7: 2.815  loss_mask_8: 2.817  time: 1.8766  data_time: 0.4111  lr: 7.6789e-05  max_mem: 17484M
[01/27 12:30:39] d2.utils.events INFO:  eta: 1 day, 2:00:30  iter: 15279  total_loss: 30.8  loss_mask: 3.074  loss_mask_0: 3.143  loss_mask_1: 3.074  loss_mask_2: 3.077  loss_mask_3: 3.073  loss_mask_4: 3.074  loss_mask_5: 3.072  loss_mask_6: 3.077  loss_mask_7: 3.074  loss_mask_8: 3.074  time: 1.8769  data_time: 0.4070  lr: 7.6758e-05  max_mem: 17484M
[01/27 12:31:21] d2.utils.events INFO:  eta: 1 day, 1:59:57  iter: 15299  total_loss: 28.52  loss_mask: 2.852  loss_mask_0: 2.856  loss_mask_1: 2.852  loss_mask_2: 2.851  loss_mask_3: 2.851  loss_mask_4: 2.851  loss_mask_5: 2.851  loss_mask_6: 2.851  loss_mask_7: 2.851  loss_mask_8: 2.851  time: 1.8772  data_time: 0.4226  lr: 7.6727e-05  max_mem: 17484M
[01/27 12:32:03] d2.utils.events INFO:  eta: 1 day, 1:59:53  iter: 15319  total_loss: 29.74  loss_mask: 2.973  loss_mask_0: 2.994  loss_mask_1: 2.972  loss_mask_2: 2.972  loss_mask_3: 2.972  loss_mask_4: 2.971  loss_mask_5: 2.972  loss_mask_6: 2.971  loss_mask_7: 2.971  loss_mask_8: 2.972  time: 1.8775  data_time: 0.4050  lr: 7.6696e-05  max_mem: 17484M
[01/27 12:32:45] d2.utils.events INFO:  eta: 1 day, 2:00:21  iter: 15339  total_loss: 27.61  loss_mask: 2.755  loss_mask_0: 2.784  loss_mask_1: 2.759  loss_mask_2: 2.755  loss_mask_3: 2.761  loss_mask_4: 2.758  loss_mask_5: 2.763  loss_mask_6: 2.757  loss_mask_7: 2.76  loss_mask_8: 2.756  time: 1.8778  data_time: 0.4345  lr: 7.6665e-05  max_mem: 17484M
[01/27 12:33:27] d2.utils.events INFO:  eta: 1 day, 1:59:39  iter: 15359  total_loss: 26.24  loss_mask: 2.623  loss_mask_0: 2.647  loss_mask_1: 2.622  loss_mask_2: 2.621  loss_mask_3: 2.622  loss_mask_4: 2.621  loss_mask_5: 2.621  loss_mask_6: 2.622  loss_mask_7: 2.621  loss_mask_8: 2.623  time: 1.8781  data_time: 0.4108  lr: 7.6635e-05  max_mem: 17484M
[01/27 12:34:10] d2.utils.events INFO:  eta: 1 day, 1:59:10  iter: 15379  total_loss: 26.59  loss_mask: 2.657  loss_mask_0: 2.701  loss_mask_1: 2.656  loss_mask_2: 2.657  loss_mask_3: 2.658  loss_mask_4: 2.657  loss_mask_5: 2.656  loss_mask_6: 2.656  loss_mask_7: 2.656  loss_mask_8: 2.656  time: 1.8784  data_time: 0.4171  lr: 7.6604e-05  max_mem: 17484M
[01/27 12:34:53] d2.utils.events INFO:  eta: 1 day, 1:59:06  iter: 15399  total_loss: 26.22  loss_mask: 2.618  loss_mask_0: 2.661  loss_mask_1: 2.618  loss_mask_2: 2.618  loss_mask_3: 2.615  loss_mask_4: 2.618  loss_mask_5: 2.619  loss_mask_6: 2.618  loss_mask_7: 2.618  loss_mask_8: 2.618  time: 1.8788  data_time: 0.4123  lr: 7.6573e-05  max_mem: 17484M
[01/27 12:35:34] d2.utils.events INFO:  eta: 1 day, 1:58:30  iter: 15419  total_loss: 27.83  loss_mask: 2.782  loss_mask_0: 2.794  loss_mask_1: 2.782  loss_mask_2: 2.782  loss_mask_3: 2.782  loss_mask_4: 2.783  loss_mask_5: 2.782  loss_mask_6: 2.782  loss_mask_7: 2.782  loss_mask_8: 2.782  time: 1.8791  data_time: 0.3933  lr: 7.6542e-05  max_mem: 17484M
[01/27 12:36:16] d2.utils.events INFO:  eta: 1 day, 1:57:48  iter: 15439  total_loss: 25.92  loss_mask: 2.584  loss_mask_0: 2.659  loss_mask_1: 2.584  loss_mask_2: 2.583  loss_mask_3: 2.584  loss_mask_4: 2.587  loss_mask_5: 2.583  loss_mask_6: 2.584  loss_mask_7: 2.585  loss_mask_8: 2.583  time: 1.8793  data_time: 0.3954  lr: 7.6511e-05  max_mem: 17484M
[01/27 12:36:58] d2.utils.events INFO:  eta: 1 day, 1:57:13  iter: 15459  total_loss: 25.87  loss_mask: 2.586  loss_mask_0: 2.604  loss_mask_1: 2.585  loss_mask_2: 2.586  loss_mask_3: 2.586  loss_mask_4: 2.586  loss_mask_5: 2.586  loss_mask_6: 2.585  loss_mask_7: 2.585  loss_mask_8: 2.585  time: 1.8796  data_time: 0.4020  lr: 7.648e-05  max_mem: 17484M
[01/27 12:37:39] d2.utils.events INFO:  eta: 1 day, 1:55:59  iter: 15479  total_loss: 26.22  loss_mask: 2.62  loss_mask_0: 2.636  loss_mask_1: 2.621  loss_mask_2: 2.621  loss_mask_3: 2.621  loss_mask_4: 2.62  loss_mask_5: 2.621  loss_mask_6: 2.621  loss_mask_7: 2.621  loss_mask_8: 2.621  time: 1.8798  data_time: 0.3820  lr: 7.6449e-05  max_mem: 17484M
[01/27 12:38:22] d2.utils.events INFO:  eta: 1 day, 1:55:27  iter: 15499  total_loss: 28.24  loss_mask: 2.82  loss_mask_0: 2.853  loss_mask_1: 2.821  loss_mask_2: 2.819  loss_mask_3: 2.821  loss_mask_4: 2.821  loss_mask_5: 2.822  loss_mask_6: 2.82  loss_mask_7: 2.822  loss_mask_8: 2.821  time: 1.8801  data_time: 0.4225  lr: 7.6418e-05  max_mem: 17484M
[01/27 12:39:03] d2.utils.events INFO:  eta: 1 day, 1:54:24  iter: 15519  total_loss: 27.67  loss_mask: 2.764  loss_mask_0: 2.795  loss_mask_1: 2.763  loss_mask_2: 2.763  loss_mask_3: 2.764  loss_mask_4: 2.764  loss_mask_5: 2.764  loss_mask_6: 2.763  loss_mask_7: 2.763  loss_mask_8: 2.763  time: 1.8804  data_time: 0.4020  lr: 7.6387e-05  max_mem: 17484M
[01/27 12:39:46] d2.utils.events INFO:  eta: 1 day, 1:54:12  iter: 15539  total_loss: 25.32  loss_mask: 2.529  loss_mask_0: 2.563  loss_mask_1: 2.528  loss_mask_2: 2.53  loss_mask_3: 2.531  loss_mask_4: 2.529  loss_mask_5: 2.529  loss_mask_6: 2.528  loss_mask_7: 2.529  loss_mask_8: 2.529  time: 1.8807  data_time: 0.4033  lr: 7.6356e-05  max_mem: 17484M
[01/27 12:40:28] d2.utils.events INFO:  eta: 1 day, 1:53:58  iter: 15559  total_loss: 25.3  loss_mask: 2.529  loss_mask_0: 2.552  loss_mask_1: 2.527  loss_mask_2: 2.529  loss_mask_3: 2.528  loss_mask_4: 2.528  loss_mask_5: 2.528  loss_mask_6: 2.529  loss_mask_7: 2.528  loss_mask_8: 2.528  time: 1.8810  data_time: 0.4290  lr: 7.6325e-05  max_mem: 17484M
[01/27 12:41:10] d2.utils.events INFO:  eta: 1 day, 1:53:24  iter: 15579  total_loss: 26.93  loss_mask: 2.691  loss_mask_0: 2.71  loss_mask_1: 2.691  loss_mask_2: 2.691  loss_mask_3: 2.691  loss_mask_4: 2.691  loss_mask_5: 2.691  loss_mask_6: 2.691  loss_mask_7: 2.691  loss_mask_8: 2.691  time: 1.8813  data_time: 0.3951  lr: 7.6295e-05  max_mem: 17484M
[01/27 12:41:53] d2.utils.events INFO:  eta: 1 day, 1:52:55  iter: 15599  total_loss: 27.92  loss_mask: 2.79  loss_mask_0: 2.802  loss_mask_1: 2.791  loss_mask_2: 2.791  loss_mask_3: 2.791  loss_mask_4: 2.791  loss_mask_5: 2.791  loss_mask_6: 2.791  loss_mask_7: 2.791  loss_mask_8: 2.791  time: 1.8816  data_time: 0.4255  lr: 7.6264e-05  max_mem: 17484M
[01/27 12:42:34] d2.utils.events INFO:  eta: 1 day, 1:51:52  iter: 15619  total_loss: 30.06  loss_mask: 3.005  loss_mask_0: 3.02  loss_mask_1: 3.005  loss_mask_2: 3.005  loss_mask_3: 3.004  loss_mask_4: 3.002  loss_mask_5: 3.003  loss_mask_6: 3.006  loss_mask_7: 3.004  loss_mask_8: 3.005  time: 1.8819  data_time: 0.4017  lr: 7.6233e-05  max_mem: 17484M
[01/27 12:43:10] d2.utils.events INFO:  eta: 1 day, 1:49:52  iter: 15639  total_loss: 31.45  loss_mask: 3.144  loss_mask_0: 3.179  loss_mask_1: 3.142  loss_mask_2: 3.143  loss_mask_3: 3.145  loss_mask_4: 3.143  loss_mask_5: 3.141  loss_mask_6: 3.145  loss_mask_7: 3.144  loss_mask_8: 3.143  time: 1.8817  data_time: 0.4071  lr: 7.6202e-05  max_mem: 17484M
[01/27 12:43:46] d2.utils.events INFO:  eta: 1 day, 1:47:35  iter: 15659  total_loss: 27.69  loss_mask: 2.768  loss_mask_0: 2.794  loss_mask_1: 2.765  loss_mask_2: 2.767  loss_mask_3: 2.767  loss_mask_4: 2.766  loss_mask_5: 2.766  loss_mask_6: 2.765  loss_mask_7: 2.765  loss_mask_8: 2.767  time: 1.8816  data_time: 0.3990  lr: 7.6171e-05  max_mem: 17484M
[01/27 12:44:21] d2.utils.events INFO:  eta: 1 day, 1:46:33  iter: 15679  total_loss: 29.08  loss_mask: 2.907  loss_mask_0: 2.934  loss_mask_1: 2.906  loss_mask_2: 2.905  loss_mask_3: 2.906  loss_mask_4: 2.905  loss_mask_5: 2.908  loss_mask_6: 2.908  loss_mask_7: 2.908  loss_mask_8: 2.907  time: 1.8814  data_time: 0.3996  lr: 7.614e-05  max_mem: 17484M
[01/27 12:44:56] d2.utils.events INFO:  eta: 1 day, 1:44:41  iter: 15699  total_loss: 27.83  loss_mask: 2.78  loss_mask_0: 2.773  loss_mask_1: 2.781  loss_mask_2: 2.781  loss_mask_3: 2.781  loss_mask_4: 2.783  loss_mask_5: 2.781  loss_mask_6: 2.781  loss_mask_7: 2.78  loss_mask_8: 2.781  time: 1.8813  data_time: 0.4058  lr: 7.6109e-05  max_mem: 17484M
[01/27 12:45:32] d2.utils.events INFO:  eta: 1 day, 1:42:55  iter: 15719  total_loss: 29.64  loss_mask: 2.963  loss_mask_0: 2.979  loss_mask_1: 2.961  loss_mask_2: 2.961  loss_mask_3: 2.962  loss_mask_4: 2.964  loss_mask_5: 2.961  loss_mask_6: 2.963  loss_mask_7: 2.962  loss_mask_8: 2.962  time: 1.8812  data_time: 0.4206  lr: 7.6078e-05  max_mem: 17484M
[01/27 12:46:08] d2.utils.events INFO:  eta: 1 day, 1:40:36  iter: 15739  total_loss: 28.74  loss_mask: 2.875  loss_mask_0: 2.879  loss_mask_1: 2.874  loss_mask_2: 2.874  loss_mask_3: 2.873  loss_mask_4: 2.874  loss_mask_5: 2.874  loss_mask_6: 2.874  loss_mask_7: 2.874  loss_mask_8: 2.874  time: 1.8811  data_time: 0.4402  lr: 7.6047e-05  max_mem: 17484M
[01/27 12:46:44] d2.utils.events INFO:  eta: 1 day, 1:38:44  iter: 15759  total_loss: 27.49  loss_mask: 2.748  loss_mask_0: 2.762  loss_mask_1: 2.747  loss_mask_2: 2.748  loss_mask_3: 2.75  loss_mask_4: 2.747  loss_mask_5: 2.748  loss_mask_6: 2.745  loss_mask_7: 2.748  loss_mask_8: 2.749  time: 1.8810  data_time: 0.4230  lr: 7.6016e-05  max_mem: 17484M
[01/27 12:47:19] d2.utils.events INFO:  eta: 1 day, 1:36:47  iter: 15779  total_loss: 26.22  loss_mask: 2.618  loss_mask_0: 2.662  loss_mask_1: 2.617  loss_mask_2: 2.618  loss_mask_3: 2.617  loss_mask_4: 2.617  loss_mask_5: 2.618  loss_mask_6: 2.617  loss_mask_7: 2.618  loss_mask_8: 2.618  time: 1.8808  data_time: 0.4115  lr: 7.5985e-05  max_mem: 17484M
[01/27 12:47:55] d2.utils.events INFO:  eta: 1 day, 1:34:54  iter: 15799  total_loss: 25.63  loss_mask: 2.562  loss_mask_0: 2.578  loss_mask_1: 2.561  loss_mask_2: 2.561  loss_mask_3: 2.562  loss_mask_4: 2.562  loss_mask_5: 2.562  loss_mask_6: 2.561  loss_mask_7: 2.562  loss_mask_8: 2.562  time: 1.8807  data_time: 0.4347  lr: 7.5954e-05  max_mem: 17484M
[01/27 12:48:31] d2.utils.events INFO:  eta: 1 day, 1:32:55  iter: 15819  total_loss: 26.76  loss_mask: 2.675  loss_mask_0: 2.705  loss_mask_1: 2.674  loss_mask_2: 2.675  loss_mask_3: 2.675  loss_mask_4: 2.675  loss_mask_5: 2.675  loss_mask_6: 2.675  loss_mask_7: 2.674  loss_mask_8: 2.674  time: 1.8806  data_time: 0.4182  lr: 7.5923e-05  max_mem: 17484M
[01/27 12:49:06] d2.utils.events INFO:  eta: 1 day, 1:30:25  iter: 15839  total_loss: 25.62  loss_mask: 2.561  loss_mask_0: 2.567  loss_mask_1: 2.561  loss_mask_2: 2.561  loss_mask_3: 2.56  loss_mask_4: 2.562  loss_mask_5: 2.561  loss_mask_6: 2.561  loss_mask_7: 2.561  loss_mask_8: 2.561  time: 1.8805  data_time: 0.3915  lr: 7.5893e-05  max_mem: 17484M
[01/27 12:49:42] d2.utils.events INFO:  eta: 1 day, 1:28:02  iter: 15859  total_loss: 26.2  loss_mask: 2.62  loss_mask_0: 2.631  loss_mask_1: 2.617  loss_mask_2: 2.619  loss_mask_3: 2.618  loss_mask_4: 2.619  loss_mask_5: 2.618  loss_mask_6: 2.618  loss_mask_7: 2.619  loss_mask_8: 2.618  time: 1.8803  data_time: 0.4195  lr: 7.5862e-05  max_mem: 17484M
[01/27 12:50:17] d2.utils.events INFO:  eta: 1 day, 1:25:34  iter: 15879  total_loss: 26.82  loss_mask: 2.681  loss_mask_0: 2.692  loss_mask_1: 2.68  loss_mask_2: 2.68  loss_mask_3: 2.68  loss_mask_4: 2.681  loss_mask_5: 2.68  loss_mask_6: 2.68  loss_mask_7: 2.681  loss_mask_8: 2.68  time: 1.8802  data_time: 0.3949  lr: 7.5831e-05  max_mem: 17484M
[01/27 12:50:52] d2.utils.events INFO:  eta: 1 day, 1:22:07  iter: 15899  total_loss: 25.2  loss_mask: 2.52  loss_mask_0: 2.517  loss_mask_1: 2.521  loss_mask_2: 2.521  loss_mask_3: 2.521  loss_mask_4: 2.521  loss_mask_5: 2.521  loss_mask_6: 2.521  loss_mask_7: 2.521  loss_mask_8: 2.521  time: 1.8800  data_time: 0.3969  lr: 7.58e-05  max_mem: 17484M
[01/27 12:51:28] d2.utils.events INFO:  eta: 1 day, 1:19:02  iter: 15919  total_loss: 30.01  loss_mask: 2.991  loss_mask_0: 3.095  loss_mask_1: 2.99  loss_mask_2: 2.991  loss_mask_3: 2.99  loss_mask_4: 2.991  loss_mask_5: 2.991  loss_mask_6: 2.988  loss_mask_7: 2.989  loss_mask_8: 2.989  time: 1.8799  data_time: 0.4172  lr: 7.5769e-05  max_mem: 17484M
[01/27 12:52:04] d2.utils.events INFO:  eta: 1 day, 1:16:31  iter: 15939  total_loss: 32.85  loss_mask: 3.286  loss_mask_0: 3.283  loss_mask_1: 3.283  loss_mask_2: 3.288  loss_mask_3: 3.287  loss_mask_4: 3.283  loss_mask_5: 3.286  loss_mask_6: 3.286  loss_mask_7: 3.283  loss_mask_8: 3.285  time: 1.8798  data_time: 0.4141  lr: 7.5738e-05  max_mem: 17484M
[01/27 12:52:39] d2.utils.events INFO:  eta: 1 day, 1:12:23  iter: 15959  total_loss: 28.3  loss_mask: 2.829  loss_mask_0: 2.837  loss_mask_1: 2.828  loss_mask_2: 2.828  loss_mask_3: 2.829  loss_mask_4: 2.828  loss_mask_5: 2.829  loss_mask_6: 2.83  loss_mask_7: 2.828  loss_mask_8: 2.83  time: 1.8796  data_time: 0.4093  lr: 7.5707e-05  max_mem: 17484M
[01/27 12:53:15] d2.utils.events INFO:  eta: 1 day, 1:07:39  iter: 15979  total_loss: 29.83  loss_mask: 2.983  loss_mask_0: 2.996  loss_mask_1: 2.983  loss_mask_2: 2.981  loss_mask_3: 2.981  loss_mask_4: 2.983  loss_mask_5: 2.982  loss_mask_6: 2.98  loss_mask_7: 2.983  loss_mask_8: 2.983  time: 1.8795  data_time: 0.4125  lr: 7.5676e-05  max_mem: 17484M
[01/27 12:53:50] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 12:53:51] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 12:53:51] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 13:00:25] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.7357897790994192, 'error_1pix': 0.3535903791323496, 'error_3pix': 0.15494051953457233, 'mIoU': 7.57654566120078, 'fwIoU': 18.353411317161658, 'IoU-0': nan, 'IoU-1': 49.175811416582356, 'IoU-2': 1.8087538479397807, 'IoU-3': 2.114776989377794, 'IoU-4': 2.425243037972382, 'IoU-5': 2.880509948204374, 'IoU-6': 3.265341834514136, 'IoU-7': 3.047725872511314, 'IoU-8': 6.668836495336837, 'IoU-9': 17.02044599458038, 'IoU-10': 17.53916546173905, 'IoU-11': 19.84677611022191, 'IoU-12': 19.623385653613738, 'IoU-13': 17.929852238397824, 'IoU-14': 18.52028001874189, 'IoU-15': 19.467818998373946, 'IoU-16': 20.0138743688693, 'IoU-17': 17.60939686951722, 'IoU-18': 18.19634859446325, 'IoU-19': 18.2284995113175, 'IoU-20': 18.420989331723213, 'IoU-21': 19.12525798792008, 'IoU-22': 20.17768585799093, 'IoU-23': 18.660142895985736, 'IoU-24': 18.561555077830597, 'IoU-25': 18.37469821220664, 'IoU-26': 18.423306958957433, 'IoU-27': 20.02808450768846, 'IoU-28': 18.83595155495835, 'IoU-29': 19.274569480711932, 'IoU-30': 18.511998732270335, 'IoU-31': 19.568248068187895, 'IoU-32': 19.26979522441936, 'IoU-33': 18.233497125393075, 'IoU-34': 17.912493346254617, 'IoU-35': 18.926114725885927, 'IoU-36': 18.895639936356464, 'IoU-37': 18.36352517343258, 'IoU-38': 18.445831935287842, 'IoU-39': 17.817580379964994, 'IoU-40': 17.49578897115501, 'IoU-41': 16.106546372725738, 'IoU-42': 15.847362481024666, 'IoU-43': 15.763151607110235, 'IoU-44': 15.94894841826684, 'IoU-45': 15.775353477444106, 'IoU-46': 14.993539963296701, 'IoU-47': 15.089864967839004, 'IoU-48': 14.772245097473464, 'IoU-49': 14.70365942389322, 'IoU-50': 14.443114367584304, 'IoU-51': 13.758027181092173, 'IoU-52': 13.470879871548721, 'IoU-53': 13.08952260236818, 'IoU-54': 13.315050723203392, 'IoU-55': 12.789955210820716, 'IoU-56': 12.163746983403385, 'IoU-57': 12.339402503129376, 'IoU-58': 12.157910579639283, 'IoU-59': 11.568791696024542, 'IoU-60': 11.107660832247028, 'IoU-61': 10.865291077957826, 'IoU-62': 10.594361220372827, 'IoU-63': 10.096440316658557, 'IoU-64': 10.141785075795719, 'IoU-65': 9.500601475440092, 'IoU-66': 9.37061383459246, 'IoU-67': 8.714918331424498, 'IoU-68': 8.509119047627093, 'IoU-69': 8.425010661028919, 'IoU-70': 8.539816307458743, 'IoU-71': 8.007405595036554, 'IoU-72': 7.822933102989642, 'IoU-73': 7.534122917027, 'IoU-74': 7.68439923745733, 'IoU-75': 7.5271554493901895, 'IoU-76': 7.456824539398406, 'IoU-77': 7.344819170328151, 'IoU-78': 7.156209661583077, 'IoU-79': 6.941561011136719, 'IoU-80': 6.875777846466084, 'IoU-81': 6.824939025184156, 'IoU-82': 6.7089273166137104, 'IoU-83': 6.770675157635594, 'IoU-84': 6.570606148360316, 'IoU-85': 6.547414197714965, 'IoU-86': 6.211769246640518, 'IoU-87': 5.963868672854469, 'IoU-88': 6.045732850793129, 'IoU-89': 6.082413119884363, 'IoU-90': 5.931445483026688, 'IoU-91': 5.621763718296592, 'IoU-92': 5.492655568857287, 'IoU-93': 5.523563145832103, 'IoU-94': 5.4661934692117615, 'IoU-95': 5.3222324751366825, 'IoU-96': 5.129370902190076, 'IoU-97': 5.179124096109805, 'IoU-98': 5.292743050041902, 'IoU-99': 4.9573661322608995, 'IoU-100': 4.894786720605813, 'IoU-101': 4.812522471410254, 'IoU-102': 4.773210075662548, 'IoU-103': 4.3564830563948584, 'IoU-104': 4.376465940594914, 'IoU-105': 4.343985056238362, 'IoU-106': 4.30487255089932, 'IoU-107': 4.218871815731211, 'IoU-108': 4.235859541014386, 'IoU-109': 4.266472202214137, 'IoU-110': 4.161403483085048, 'IoU-111': 3.8267039891258023, 'IoU-112': 4.014519651335913, 'IoU-113': 3.852384417198755, 'IoU-114': 3.8827159927805006, 'IoU-115': 3.647850087326475, 'IoU-116': 3.663636083936516, 'IoU-117': 3.679779404169444, 'IoU-118': 3.5515916276027473, 'IoU-119': 3.611078719499176, 'IoU-120': 3.718147194863661, 'IoU-121': 3.6937227837651, 'IoU-122': 3.5811113432700763, 'IoU-123': 3.3963496841993415, 'IoU-124': 3.423921498499917, 'IoU-125': 3.285726519526582, 'IoU-126': 3.227230779730624, 'IoU-127': 3.059282817822558, 'IoU-128': 3.128245301640722, 'IoU-129': 3.197672782739982, 'IoU-130': 2.9129495972238897, 'IoU-131': 2.9580809892336632, 'IoU-132': 2.857619936374164, 'IoU-133': 2.75983526936048, 'IoU-134': 2.6479304292606343, 'IoU-135': 2.5414788529778463, 'IoU-136': 2.5004589262936796, 'IoU-137': 2.3736624126387937, 'IoU-138': 2.308000665265061, 'IoU-139': 2.300882557243382, 'IoU-140': 2.4122735404123476, 'IoU-141': 2.2310693919893367, 'IoU-142': 2.2565406444979565, 'IoU-143': 2.3105312630858688, 'IoU-144': 2.5257894035170687, 'IoU-145': 2.498204444371586, 'IoU-146': 2.5435566691168527, 'IoU-147': 2.6273593736010614, 'IoU-148': 2.697800291366243, 'IoU-149': 2.376172869858289, 'IoU-150': 2.246885444405613, 'IoU-151': 2.3109588867965067, 'IoU-152': 2.4463594805399325, 'IoU-153': 2.1265766495802967, 'IoU-154': 2.0968589224536345, 'IoU-155': 2.0310370854050657, 'IoU-156': 2.105980264137847, 'IoU-157': 2.0893112990527207, 'IoU-158': 2.0697122962841124, 'IoU-159': 1.8925112737487988, 'IoU-160': 2.0136348752106086, 'IoU-161': 1.8947923572770822, 'IoU-162': 1.9508214538646547, 'IoU-163': 2.0916332863391274, 'IoU-164': 2.102589489365837, 'IoU-165': 1.8649891435240076, 'IoU-166': 1.768783566044899, 'IoU-167': 1.7388913087550757, 'IoU-168': 1.797304295435357, 'IoU-169': 1.8913889599136338, 'IoU-170': 1.8592998491526767, 'IoU-171': 1.6876324641226526, 'IoU-172': 1.635808331204796, 'IoU-173': 1.8898069415476764, 'IoU-174': 1.854260264191763, 'IoU-175': 1.8117119082205195, 'IoU-176': 1.7116860961046347, 'IoU-177': 1.562631279657787, 'IoU-178': 1.5924342618237213, 'IoU-179': 1.946665175826019, 'IoU-180': 1.9696469712060984, 'IoU-181': 1.4199306377473784, 'IoU-182': 1.0761198411989226, 'IoU-183': 1.0007326655372208, 'IoU-184': 0.7317483856701472, 'IoU-185': 0.6478660129489607, 'IoU-186': 0.4539554741495747, 'IoU-187': 0.4322165255752951, 'IoU-188': 0.3201203555161728, 'IoU-189': 0.28966355816383954, 'IoU-190': 0.2239215523846998, 'IoU-191': 0.09444169133653155, 'IoU-192': 0.04088814694918026, 'mACC': 13.508551279030803, 'pACC': 28.02826492573721, 'ACC-0': nan, 'ACC-1': 49.98556142869701, 'ACC-2': 3.5377431751215873, 'ACC-3': 10.087902743147907, 'ACC-4': 10.73139726203742, 'ACC-5': 12.74992385302134, 'ACC-6': 15.061129248392222, 'ACC-7': 16.28799894986709, 'ACC-8': 18.80443098625644, 'ACC-9': 36.09050424481884, 'ACC-10': 38.836958920540475, 'ACC-11': 34.1691873151246, 'ACC-12': 32.7552215552039, 'ACC-13': 28.702004115462792, 'ACC-14': 29.045355739835703, 'ACC-15': 31.179269469043057, 'ACC-16': 32.14672345195486, 'ACC-17': 30.37435237512589, 'ACC-18': 30.283429424552562, 'ACC-19': 30.036288141961144, 'ACC-20': 30.607999288588644, 'ACC-21': 32.04886316739955, 'ACC-22': 33.160106192366975, 'ACC-23': 31.849149728141967, 'ACC-24': 31.297485589630842, 'ACC-25': 31.266901657588697, 'ACC-26': 31.57645169849161, 'ACC-27': 33.79707376928774, 'ACC-28': 32.25157638203392, 'ACC-29': 32.027578411938244, 'ACC-30': 31.164904704149716, 'ACC-31': 32.50485222264538, 'ACC-32': 32.510644243706366, 'ACC-33': 31.050295901511905, 'ACC-34': 30.656804426333895, 'ACC-35': 32.3142263975066, 'ACC-36': 32.22782374967747, 'ACC-37': 31.799519929674076, 'ACC-38': 31.574769299912557, 'ACC-39': 30.72076272368832, 'ACC-40': 29.95218447260636, 'ACC-41': 28.413978664837465, 'ACC-42': 27.813970930492143, 'ACC-43': 27.55010201838876, 'ACC-44': 27.40881207900085, 'ACC-45': 27.205503420074052, 'ACC-46': 26.427464141020284, 'ACC-47': 26.737965568007656, 'ACC-48': 26.375771773330403, 'ACC-49': 26.132066429716254, 'ACC-50': 25.486446741610962, 'ACC-51': 24.66010527666397, 'ACC-52': 24.079143210129462, 'ACC-53': 23.43612485827699, 'ACC-54': 23.815524780818503, 'ACC-55': 23.14414315044402, 'ACC-56': 22.0773551950282, 'ACC-57': 21.936819048179327, 'ACC-58': 21.8580947322545, 'ACC-59': 20.960456049214432, 'ACC-60': 20.284998707005567, 'ACC-61': 19.971715204175393, 'ACC-62': 19.519199830637152, 'ACC-63': 18.9623738502834, 'ACC-64': 19.043488423332242, 'ACC-65': 17.994744513417416, 'ACC-66': 17.735118647310685, 'ACC-67': 16.555015793283722, 'ACC-68': 16.296000088886196, 'ACC-69': 15.820250292367186, 'ACC-70': 15.83636179558335, 'ACC-71': 15.2061930407678, 'ACC-72': 14.910704024332553, 'ACC-73': 14.275641980421373, 'ACC-74': 14.41255594732496, 'ACC-75': 14.265309220203573, 'ACC-76': 13.920971685096623, 'ACC-77': 13.902780995031153, 'ACC-78': 13.64641697796229, 'ACC-79': 13.227482818532538, 'ACC-80': 13.03703289233682, 'ACC-81': 12.893773746090101, 'ACC-82': 12.673332449742789, 'ACC-83': 12.562527274384566, 'ACC-84': 12.15658863154676, 'ACC-85': 12.115902044765186, 'ACC-86': 11.481462025134078, 'ACC-87': 11.032640811597465, 'ACC-88': 11.171093224286322, 'ACC-89': 11.108794821328424, 'ACC-90': 10.698566116624043, 'ACC-91': 10.206126114161194, 'ACC-92': 10.04989904583059, 'ACC-93': 10.170713788085907, 'ACC-94': 10.023269618611803, 'ACC-95': 9.673716982141789, 'ACC-96': 9.36020419429633, 'ACC-97': 9.360640415940956, 'ACC-98': 9.537425898582088, 'ACC-99': 9.025618497894564, 'ACC-100': 8.946500295585198, 'ACC-101': 8.800547139286454, 'ACC-102': 8.72352900396966, 'ACC-103': 7.94431144483544, 'ACC-104': 7.988396701003545, 'ACC-105': 7.934132386476386, 'ACC-106': 7.842325903747624, 'ACC-107': 7.717713405480203, 'ACC-108': 7.691546630621538, 'ACC-109': 7.702524369828898, 'ACC-110': 7.5308724126956506, 'ACC-111': 6.975314967872509, 'ACC-112': 7.516754652364736, 'ACC-113': 7.290863663238785, 'ACC-114': 7.407041625774371, 'ACC-115': 6.88248913746185, 'ACC-116': 6.879636718645603, 'ACC-117': 6.799378298469776, 'ACC-118': 6.565822604638625, 'ACC-119': 6.680786108048038, 'ACC-120': 6.878278989517775, 'ACC-121': 6.822091117160173, 'ACC-122': 6.646286808759565, 'ACC-123': 6.371615393876476, 'ACC-124': 6.589309792067661, 'ACC-125': 6.3017545844242155, 'ACC-126': 6.190743995846957, 'ACC-127': 5.818202207290976, 'ACC-128': 5.922494575498451, 'ACC-129': 6.061902948055265, 'ACC-130': 5.617797819127393, 'ACC-131': 5.705539860425211, 'ACC-132': 5.494063596425089, 'ACC-133': 5.252471643294073, 'ACC-134': 4.967100387763894, 'ACC-135': 4.758850692662904, 'ACC-136': 4.620745783637719, 'ACC-137': 4.4259080747692945, 'ACC-138': 4.292932497818672, 'ACC-139': 4.3151359332586186, 'ACC-140': 4.4663045584880905, 'ACC-141': 4.104854427759207, 'ACC-142': 4.174537426390384, 'ACC-143': 4.2541108304511015, 'ACC-144': 4.531227436823105, 'ACC-145': 4.362005488509551, 'ACC-146': 4.411322565168719, 'ACC-147': 4.495905216438559, 'ACC-148': 4.5747782189266495, 'ACC-149': 4.038265148311423, 'ACC-150': 3.806309522444593, 'ACC-151': 3.8975696942374163, 'ACC-152': 4.0593053714541005, 'ACC-153': 3.6362636972536215, 'ACC-154': 3.566664787991508, 'ACC-155': 3.442818545762912, 'ACC-156': 3.6007560126795015, 'ACC-157': 3.618214656600343, 'ACC-158': 3.622902047567702, 'ACC-159': 3.3027996387562895, 'ACC-160': 3.469103824271284, 'ACC-161': 3.19849693953636, 'ACC-162': 3.3111518738200756, 'ACC-163': 3.542661291678705, 'ACC-164': 3.60289081130448, 'ACC-165': 3.185423542528962, 'ACC-166': 3.0429409947482235, 'ACC-167': 3.009898650878857, 'ACC-168': 3.1368032354492703, 'ACC-169': 3.271200241466205, 'ACC-170': 3.250647343098054, 'ACC-171': 2.940144499697811, 'ACC-172': 2.775951142074387, 'ACC-173': 3.1919097639093272, 'ACC-174': 3.0647819472616633, 'ACC-175': 2.8876293330621077, 'ACC-176': 2.6216752737262703, 'ACC-177': 2.3690584317287313, 'ACC-178': 2.3877851147995908, 'ACC-179': 2.827463423447565, 'ACC-180': 2.7555128256712487, 'ACC-181': 1.9565222544332275, 'ACC-182': 1.3993857974554467, 'ACC-183': 1.226857909390744, 'ACC-184': 0.8513440473183962, 'ACC-185': 0.7165625339500394, 'ACC-186': 0.48840077690457406, 'ACC-187': 0.4558568536929242, 'ACC-188': 0.33194832208327235, 'ACC-189': 0.29630657579589026, 'ACC-190': 0.22685549436139524, 'ACC-191': 0.09511018671906438, 'ACC-192': 0.041078000039661514})])
[01/27 13:00:26] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 13:00:26] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 13:00:26] d2.evaluation.testing INFO: copypaste: 2.7358,0.3536,0.1549,7.5765,18.3534,13.5086,28.0283
[01/27 13:00:26] d2.utils.events INFO:  eta: 1 day, 1:03:40  iter: 15999  total_loss: 26.18  loss_mask: 2.616  loss_mask_0: 2.638  loss_mask_1: 2.614  loss_mask_2: 2.616  loss_mask_3: 2.617  loss_mask_4: 2.612  loss_mask_5: 2.614  loss_mask_6: 2.615  loss_mask_7: 2.614  loss_mask_8: 2.616  time: 1.8794  data_time: 0.4159  lr: 7.5645e-05  max_mem: 17484M
[01/27 13:01:01] d2.utils.events INFO:  eta: 1 day, 0:58:41  iter: 16019  total_loss: 28.6  loss_mask: 2.855  loss_mask_0: 2.898  loss_mask_1: 2.856  loss_mask_2: 2.855  loss_mask_3: 2.855  loss_mask_4: 2.855  loss_mask_5: 2.855  loss_mask_6: 2.854  loss_mask_7: 2.855  loss_mask_8: 2.856  time: 1.8793  data_time: 0.4133  lr: 7.5614e-05  max_mem: 17484M
[01/27 13:01:37] d2.utils.events INFO:  eta: 1 day, 0:53:16  iter: 16039  total_loss: 26.94  loss_mask: 2.692  loss_mask_0: 2.715  loss_mask_1: 2.691  loss_mask_2: 2.692  loss_mask_3: 2.691  loss_mask_4: 2.691  loss_mask_5: 2.692  loss_mask_6: 2.692  loss_mask_7: 2.691  loss_mask_8: 2.691  time: 1.8791  data_time: 0.4085  lr: 7.5583e-05  max_mem: 17484M
[01/27 13:02:12] d2.utils.events INFO:  eta: 1 day, 0:48:26  iter: 16059  total_loss: 25.33  loss_mask: 2.53  loss_mask_0: 2.537  loss_mask_1: 2.53  loss_mask_2: 2.533  loss_mask_3: 2.532  loss_mask_4: 2.53  loss_mask_5: 2.532  loss_mask_6: 2.531  loss_mask_7: 2.531  loss_mask_8: 2.531  time: 1.8790  data_time: 0.4013  lr: 7.5552e-05  max_mem: 17484M
[01/27 13:02:48] d2.utils.events INFO:  eta: 1 day, 0:41:33  iter: 16079  total_loss: 28.76  loss_mask: 2.877  loss_mask_0: 2.899  loss_mask_1: 2.873  loss_mask_2: 2.873  loss_mask_3: 2.873  loss_mask_4: 2.874  loss_mask_5: 2.876  loss_mask_6: 2.873  loss_mask_7: 2.873  loss_mask_8: 2.876  time: 1.8789  data_time: 0.4202  lr: 7.5521e-05  max_mem: 17484M
[01/27 13:03:29] d2.utils.events INFO:  eta: 1 day, 0:39:49  iter: 16099  total_loss: 29.94  loss_mask: 2.991  loss_mask_0: 3.014  loss_mask_1: 2.991  loss_mask_2: 2.993  loss_mask_3: 2.991  loss_mask_4: 2.991  loss_mask_5: 2.992  loss_mask_6: 2.992  loss_mask_7: 2.992  loss_mask_8: 2.992  time: 1.8791  data_time: 0.4249  lr: 7.549e-05  max_mem: 17484M
[01/27 13:04:11] d2.utils.events INFO:  eta: 1 day, 0:38:49  iter: 16119  total_loss: 29.36  loss_mask: 2.932  loss_mask_0: 3.003  loss_mask_1: 2.93  loss_mask_2: 2.931  loss_mask_3: 2.931  loss_mask_4: 2.929  loss_mask_5: 2.93  loss_mask_6: 2.931  loss_mask_7: 2.93  loss_mask_8: 2.932  time: 1.8794  data_time: 0.4285  lr: 7.5459e-05  max_mem: 17484M
[01/27 13:04:54] d2.utils.events INFO:  eta: 1 day, 0:38:09  iter: 16139  total_loss: 26.97  loss_mask: 2.691  loss_mask_0: 2.757  loss_mask_1: 2.688  loss_mask_2: 2.691  loss_mask_3: 2.692  loss_mask_4: 2.69  loss_mask_5: 2.689  loss_mask_6: 2.689  loss_mask_7: 2.689  loss_mask_8: 2.69  time: 1.8797  data_time: 0.4161  lr: 7.5428e-05  max_mem: 17484M
[01/27 13:05:36] d2.utils.events INFO:  eta: 1 day, 0:37:00  iter: 16159  total_loss: 26.56  loss_mask: 2.649  loss_mask_0: 2.726  loss_mask_1: 2.645  loss_mask_2: 2.647  loss_mask_3: 2.648  loss_mask_4: 2.647  loss_mask_5: 2.647  loss_mask_6: 2.645  loss_mask_7: 2.647  loss_mask_8: 2.647  time: 1.8799  data_time: 0.4201  lr: 7.5397e-05  max_mem: 17484M
[01/27 13:06:18] d2.utils.events INFO:  eta: 1 day, 0:36:32  iter: 16179  total_loss: 27.84  loss_mask: 2.775  loss_mask_0: 2.845  loss_mask_1: 2.775  loss_mask_2: 2.776  loss_mask_3: 2.774  loss_mask_4: 2.775  loss_mask_5: 2.775  loss_mask_6: 2.775  loss_mask_7: 2.774  loss_mask_8: 2.775  time: 1.8802  data_time: 0.4190  lr: 7.5366e-05  max_mem: 17484M
[01/27 13:06:59] d2.utils.events INFO:  eta: 1 day, 0:34:48  iter: 16199  total_loss: 27.39  loss_mask: 2.732  loss_mask_0: 2.806  loss_mask_1: 2.731  loss_mask_2: 2.731  loss_mask_3: 2.732  loss_mask_4: 2.732  loss_mask_5: 2.731  loss_mask_6: 2.732  loss_mask_7: 2.731  loss_mask_8: 2.731  time: 1.8805  data_time: 0.4159  lr: 7.5335e-05  max_mem: 17484M
[01/27 13:07:41] d2.utils.events INFO:  eta: 1 day, 0:31:55  iter: 16219  total_loss: 27.22  loss_mask: 2.715  loss_mask_0: 2.767  loss_mask_1: 2.715  loss_mask_2: 2.714  loss_mask_3: 2.716  loss_mask_4: 2.716  loss_mask_5: 2.715  loss_mask_6: 2.716  loss_mask_7: 2.715  loss_mask_8: 2.715  time: 1.8807  data_time: 0.4374  lr: 7.5305e-05  max_mem: 17484M
[01/27 13:08:22] d2.utils.events INFO:  eta: 1 day, 0:29:51  iter: 16239  total_loss: 26.68  loss_mask: 2.66  loss_mask_0: 2.744  loss_mask_1: 2.66  loss_mask_2: 2.66  loss_mask_3: 2.659  loss_mask_4: 2.66  loss_mask_5: 2.659  loss_mask_6: 2.66  loss_mask_7: 2.66  loss_mask_8: 2.661  time: 1.8809  data_time: 0.3989  lr: 7.5274e-05  max_mem: 17484M
[01/27 13:09:04] d2.utils.events INFO:  eta: 1 day, 0:28:54  iter: 16259  total_loss: 25.83  loss_mask: 2.575  loss_mask_0: 2.667  loss_mask_1: 2.573  loss_mask_2: 2.573  loss_mask_3: 2.573  loss_mask_4: 2.574  loss_mask_5: 2.573  loss_mask_6: 2.571  loss_mask_7: 2.573  loss_mask_8: 2.574  time: 1.8812  data_time: 0.4122  lr: 7.5243e-05  max_mem: 17484M
[01/27 13:09:46] d2.utils.events INFO:  eta: 1 day, 0:28:30  iter: 16279  total_loss: 27.55  loss_mask: 2.749  loss_mask_0: 2.831  loss_mask_1: 2.748  loss_mask_2: 2.749  loss_mask_3: 2.749  loss_mask_4: 2.747  loss_mask_5: 2.748  loss_mask_6: 2.747  loss_mask_7: 2.748  loss_mask_8: 2.749  time: 1.8815  data_time: 0.4173  lr: 7.5212e-05  max_mem: 17484M
[01/27 13:10:28] d2.utils.events INFO:  eta: 1 day, 0:26:31  iter: 16299  total_loss: 26.48  loss_mask: 2.641  loss_mask_0: 2.746  loss_mask_1: 2.641  loss_mask_2: 2.642  loss_mask_3: 2.64  loss_mask_4: 2.64  loss_mask_5: 2.641  loss_mask_6: 2.64  loss_mask_7: 2.641  loss_mask_8: 2.641  time: 1.8817  data_time: 0.3926  lr: 7.5181e-05  max_mem: 17484M
[01/27 13:11:09] d2.utils.events INFO:  eta: 1 day, 0:23:14  iter: 16319  total_loss: 28.76  loss_mask: 2.87  loss_mask_0: 2.916  loss_mask_1: 2.87  loss_mask_2: 2.869  loss_mask_3: 2.87  loss_mask_4: 2.87  loss_mask_5: 2.87  loss_mask_6: 2.87  loss_mask_7: 2.87  loss_mask_8: 2.87  time: 1.8819  data_time: 0.4116  lr: 7.515e-05  max_mem: 17484M
[01/27 13:11:51] d2.utils.events INFO:  eta: 1 day, 0:22:05  iter: 16339  total_loss: 26.5  loss_mask: 2.64  loss_mask_0: 2.75  loss_mask_1: 2.64  loss_mask_2: 2.639  loss_mask_3: 2.638  loss_mask_4: 2.64  loss_mask_5: 2.639  loss_mask_6: 2.639  loss_mask_7: 2.639  loss_mask_8: 2.64  time: 1.8822  data_time: 0.4044  lr: 7.5119e-05  max_mem: 17484M
[01/27 13:12:33] d2.utils.events INFO:  eta: 1 day, 0:20:44  iter: 16359  total_loss: 25.7  loss_mask: 2.563  loss_mask_0: 2.638  loss_mask_1: 2.562  loss_mask_2: 2.562  loss_mask_3: 2.562  loss_mask_4: 2.563  loss_mask_5: 2.563  loss_mask_6: 2.562  loss_mask_7: 2.564  loss_mask_8: 2.563  time: 1.8824  data_time: 0.4292  lr: 7.5088e-05  max_mem: 17484M
[01/27 13:13:14] d2.utils.events INFO:  eta: 1 day, 0:19:25  iter: 16379  total_loss: 26.28  loss_mask: 2.622  loss_mask_0: 2.679  loss_mask_1: 2.622  loss_mask_2: 2.622  loss_mask_3: 2.622  loss_mask_4: 2.621  loss_mask_5: 2.622  loss_mask_6: 2.622  loss_mask_7: 2.621  loss_mask_8: 2.622  time: 1.8827  data_time: 0.4207  lr: 7.5057e-05  max_mem: 17484M
[01/27 13:13:57] d2.utils.events INFO:  eta: 1 day, 0:18:59  iter: 16399  total_loss: 27.4  loss_mask: 2.737  loss_mask_0: 2.774  loss_mask_1: 2.736  loss_mask_2: 2.736  loss_mask_3: 2.735  loss_mask_4: 2.736  loss_mask_5: 2.735  loss_mask_6: 2.736  loss_mask_7: 2.736  loss_mask_8: 2.736  time: 1.8830  data_time: 0.4465  lr: 7.5026e-05  max_mem: 17484M
[01/27 13:14:38] d2.utils.events INFO:  eta: 1 day, 0:18:34  iter: 16419  total_loss: 26.31  loss_mask: 2.625  loss_mask_0: 2.68  loss_mask_1: 2.625  loss_mask_2: 2.626  loss_mask_3: 2.626  loss_mask_4: 2.626  loss_mask_5: 2.626  loss_mask_6: 2.625  loss_mask_7: 2.625  loss_mask_8: 2.626  time: 1.8832  data_time: 0.4240  lr: 7.4995e-05  max_mem: 17484M
[01/27 13:15:20] d2.utils.events INFO:  eta: 1 day, 0:18:45  iter: 16439  total_loss: 25.78  loss_mask: 2.569  loss_mask_0: 2.656  loss_mask_1: 2.569  loss_mask_2: 2.568  loss_mask_3: 2.568  loss_mask_4: 2.569  loss_mask_5: 2.569  loss_mask_6: 2.569  loss_mask_7: 2.569  loss_mask_8: 2.568  time: 1.8835  data_time: 0.4402  lr: 7.4964e-05  max_mem: 17484M
[01/27 13:16:02] d2.utils.events INFO:  eta: 1 day, 0:17:38  iter: 16459  total_loss: 28.77  loss_mask: 2.867  loss_mask_0: 2.962  loss_mask_1: 2.867  loss_mask_2: 2.867  loss_mask_3: 2.867  loss_mask_4: 2.867  loss_mask_5: 2.867  loss_mask_6: 2.868  loss_mask_7: 2.867  loss_mask_8: 2.867  time: 1.8837  data_time: 0.4241  lr: 7.4933e-05  max_mem: 17484M
[01/27 13:16:44] d2.utils.events INFO:  eta: 1 day, 0:17:24  iter: 16479  total_loss: 26.34  loss_mask: 2.623  loss_mask_0: 2.688  loss_mask_1: 2.624  loss_mask_2: 2.624  loss_mask_3: 2.622  loss_mask_4: 2.623  loss_mask_5: 2.622  loss_mask_6: 2.625  loss_mask_7: 2.624  loss_mask_8: 2.624  time: 1.8840  data_time: 0.4449  lr: 7.4902e-05  max_mem: 17484M
[01/27 13:17:26] d2.utils.events INFO:  eta: 1 day, 0:16:44  iter: 16499  total_loss: 28.29  loss_mask: 2.821  loss_mask_0: 2.883  loss_mask_1: 2.819  loss_mask_2: 2.821  loss_mask_3: 2.821  loss_mask_4: 2.82  loss_mask_5: 2.822  loss_mask_6: 2.819  loss_mask_7: 2.82  loss_mask_8: 2.82  time: 1.8843  data_time: 0.4243  lr: 7.4871e-05  max_mem: 17484M
[01/27 13:18:09] d2.utils.events INFO:  eta: 1 day, 0:16:25  iter: 16519  total_loss: 26.64  loss_mask: 2.662  loss_mask_0: 2.688  loss_mask_1: 2.661  loss_mask_2: 2.662  loss_mask_3: 2.662  loss_mask_4: 2.661  loss_mask_5: 2.662  loss_mask_6: 2.661  loss_mask_7: 2.661  loss_mask_8: 2.66  time: 1.8845  data_time: 0.4379  lr: 7.484e-05  max_mem: 17484M
[01/27 13:18:50] d2.utils.events INFO:  eta: 1 day, 0:15:24  iter: 16539  total_loss: 28.52  loss_mask: 2.849  loss_mask_0: 2.872  loss_mask_1: 2.849  loss_mask_2: 2.849  loss_mask_3: 2.849  loss_mask_4: 2.851  loss_mask_5: 2.848  loss_mask_6: 2.85  loss_mask_7: 2.849  loss_mask_8: 2.85  time: 1.8848  data_time: 0.4252  lr: 7.4809e-05  max_mem: 17484M
[01/27 13:19:33] d2.utils.events INFO:  eta: 1 day, 0:13:38  iter: 16559  total_loss: 26.37  loss_mask: 2.635  loss_mask_0: 2.665  loss_mask_1: 2.634  loss_mask_2: 2.634  loss_mask_3: 2.634  loss_mask_4: 2.635  loss_mask_5: 2.634  loss_mask_6: 2.634  loss_mask_7: 2.634  loss_mask_8: 2.634  time: 1.8851  data_time: 0.4355  lr: 7.4778e-05  max_mem: 17484M
[01/27 13:20:15] d2.utils.events INFO:  eta: 1 day, 0:12:58  iter: 16579  total_loss: 28.31  loss_mask: 2.823  loss_mask_0: 2.906  loss_mask_1: 2.823  loss_mask_2: 2.823  loss_mask_3: 2.823  loss_mask_4: 2.822  loss_mask_5: 2.822  loss_mask_6: 2.823  loss_mask_7: 2.822  loss_mask_8: 2.822  time: 1.8853  data_time: 0.4271  lr: 7.4747e-05  max_mem: 17484M
[01/27 13:20:56] d2.utils.events INFO:  eta: 1 day, 0:10:54  iter: 16599  total_loss: 27.84  loss_mask: 2.781  loss_mask_0: 2.811  loss_mask_1: 2.781  loss_mask_2: 2.781  loss_mask_3: 2.781  loss_mask_4: 2.781  loss_mask_5: 2.781  loss_mask_6: 2.781  loss_mask_7: 2.781  loss_mask_8: 2.781  time: 1.8855  data_time: 0.4105  lr: 7.4716e-05  max_mem: 17484M
[01/27 13:21:38] d2.utils.events INFO:  eta: 1 day, 0:11:23  iter: 16619  total_loss: 25.94  loss_mask: 2.585  loss_mask_0: 2.674  loss_mask_1: 2.586  loss_mask_2: 2.585  loss_mask_3: 2.586  loss_mask_4: 2.586  loss_mask_5: 2.585  loss_mask_6: 2.586  loss_mask_7: 2.585  loss_mask_8: 2.585  time: 1.8858  data_time: 0.4241  lr: 7.4685e-05  max_mem: 17484M
[01/27 13:22:20] d2.utils.events INFO:  eta: 1 day, 0:19:56  iter: 16639  total_loss: 25.63  loss_mask: 2.557  loss_mask_0: 2.627  loss_mask_1: 2.557  loss_mask_2: 2.557  loss_mask_3: 2.557  loss_mask_4: 2.557  loss_mask_5: 2.557  loss_mask_6: 2.556  loss_mask_7: 2.558  loss_mask_8: 2.557  time: 1.8860  data_time: 0.4176  lr: 7.4654e-05  max_mem: 17484M
[01/27 13:23:02] d2.utils.events INFO:  eta: 1 day, 0:23:55  iter: 16659  total_loss: 25.82  loss_mask: 2.577  loss_mask_0: 2.643  loss_mask_1: 2.578  loss_mask_2: 2.577  loss_mask_3: 2.577  loss_mask_4: 2.579  loss_mask_5: 2.577  loss_mask_6: 2.578  loss_mask_7: 2.578  loss_mask_8: 2.578  time: 1.8863  data_time: 0.4370  lr: 7.4623e-05  max_mem: 17484M
[01/27 13:23:45] d2.utils.events INFO:  eta: 1 day, 0:28:14  iter: 16679  total_loss: 27.27  loss_mask: 2.721  loss_mask_0: 2.786  loss_mask_1: 2.722  loss_mask_2: 2.721  loss_mask_3: 2.721  loss_mask_4: 2.723  loss_mask_5: 2.721  loss_mask_6: 2.723  loss_mask_7: 2.724  loss_mask_8: 2.722  time: 1.8866  data_time: 0.4260  lr: 7.4592e-05  max_mem: 17484M
[01/27 13:24:27] d2.utils.events INFO:  eta: 1 day, 0:30:34  iter: 16699  total_loss: 25.13  loss_mask: 2.51  loss_mask_0: 2.574  loss_mask_1: 2.508  loss_mask_2: 2.509  loss_mask_3: 2.509  loss_mask_4: 2.509  loss_mask_5: 2.51  loss_mask_6: 2.51  loss_mask_7: 2.509  loss_mask_8: 2.509  time: 1.8869  data_time: 0.4222  lr: 7.4561e-05  max_mem: 17484M
[01/27 13:25:08] d2.utils.events INFO:  eta: 1 day, 0:33:42  iter: 16719  total_loss: 25.84  loss_mask: 2.579  loss_mask_0: 2.629  loss_mask_1: 2.579  loss_mask_2: 2.579  loss_mask_3: 2.579  loss_mask_4: 2.579  loss_mask_5: 2.579  loss_mask_6: 2.579  loss_mask_7: 2.579  loss_mask_8: 2.579  time: 1.8871  data_time: 0.4156  lr: 7.453e-05  max_mem: 17484M
[01/27 13:25:50] d2.utils.events INFO:  eta: 1 day, 0:35:52  iter: 16739  total_loss: 26.99  loss_mask: 2.691  loss_mask_0: 2.784  loss_mask_1: 2.692  loss_mask_2: 2.692  loss_mask_3: 2.69  loss_mask_4: 2.693  loss_mask_5: 2.691  loss_mask_6: 2.691  loss_mask_7: 2.691  loss_mask_8: 2.691  time: 1.8873  data_time: 0.4057  lr: 7.4499e-05  max_mem: 17484M
[01/27 13:26:32] d2.utils.events INFO:  eta: 1 day, 0:37:46  iter: 16759  total_loss: 27.62  loss_mask: 2.756  loss_mask_0: 2.802  loss_mask_1: 2.756  loss_mask_2: 2.756  loss_mask_3: 2.757  loss_mask_4: 2.756  loss_mask_5: 2.757  loss_mask_6: 2.755  loss_mask_7: 2.755  loss_mask_8: 2.757  time: 1.8876  data_time: 0.4079  lr: 7.4468e-05  max_mem: 17484M
[01/27 13:27:14] d2.utils.events INFO:  eta: 1 day, 0:39:48  iter: 16779  total_loss: 28.35  loss_mask: 2.828  loss_mask_0: 2.885  loss_mask_1: 2.829  loss_mask_2: 2.83  loss_mask_3: 2.83  loss_mask_4: 2.829  loss_mask_5: 2.829  loss_mask_6: 2.829  loss_mask_7: 2.829  loss_mask_8: 2.829  time: 1.8878  data_time: 0.4026  lr: 7.4437e-05  max_mem: 17484M
[01/27 13:27:56] d2.utils.events INFO:  eta: 1 day, 0:40:05  iter: 16799  total_loss: 25.95  loss_mask: 2.587  loss_mask_0: 2.662  loss_mask_1: 2.587  loss_mask_2: 2.587  loss_mask_3: 2.586  loss_mask_4: 2.587  loss_mask_5: 2.587  loss_mask_6: 2.587  loss_mask_7: 2.588  loss_mask_8: 2.588  time: 1.8881  data_time: 0.4087  lr: 7.4406e-05  max_mem: 17484M
[01/27 13:28:38] d2.utils.events INFO:  eta: 1 day, 0:41:49  iter: 16819  total_loss: 24.84  loss_mask: 2.478  loss_mask_0: 2.545  loss_mask_1: 2.477  loss_mask_2: 2.477  loss_mask_3: 2.477  loss_mask_4: 2.478  loss_mask_5: 2.477  loss_mask_6: 2.476  loss_mask_7: 2.477  loss_mask_8: 2.478  time: 1.8883  data_time: 0.4327  lr: 7.4375e-05  max_mem: 17484M
[01/27 13:29:20] d2.utils.events INFO:  eta: 1 day, 0:42:44  iter: 16839  total_loss: 25.01  loss_mask: 2.494  loss_mask_0: 2.567  loss_mask_1: 2.494  loss_mask_2: 2.494  loss_mask_3: 2.494  loss_mask_4: 2.493  loss_mask_5: 2.494  loss_mask_6: 2.494  loss_mask_7: 2.493  loss_mask_8: 2.494  time: 1.8885  data_time: 0.4063  lr: 7.4344e-05  max_mem: 17484M
[01/27 13:30:01] d2.utils.events INFO:  eta: 1 day, 0:43:55  iter: 16859  total_loss: 26.48  loss_mask: 2.638  loss_mask_0: 2.712  loss_mask_1: 2.638  loss_mask_2: 2.646  loss_mask_3: 2.74  loss_mask_4: 2.638  loss_mask_5: 2.639  loss_mask_6: 2.637  loss_mask_7: 2.638  loss_mask_8: 2.639  time: 1.8888  data_time: 0.3906  lr: 7.4313e-05  max_mem: 17484M
[01/27 13:30:43] d2.utils.events INFO:  eta: 1 day, 0:45:27  iter: 16879  total_loss: 26.91  loss_mask: 2.679  loss_mask_0: 2.758  loss_mask_1: 2.683  loss_mask_2: 2.685  loss_mask_3: 2.695  loss_mask_4: 2.683  loss_mask_5: 2.68  loss_mask_6: 2.682  loss_mask_7: 2.682  loss_mask_8: 2.681  time: 1.8890  data_time: 0.4286  lr: 7.4282e-05  max_mem: 17484M
[01/27 13:31:25] d2.utils.events INFO:  eta: 1 day, 0:46:41  iter: 16899  total_loss: 27.76  loss_mask: 2.767  loss_mask_0: 2.838  loss_mask_1: 2.768  loss_mask_2: 2.769  loss_mask_3: 2.777  loss_mask_4: 2.768  loss_mask_5: 2.768  loss_mask_6: 2.768  loss_mask_7: 2.769  loss_mask_8: 2.769  time: 1.8893  data_time: 0.4168  lr: 7.4251e-05  max_mem: 17484M
[01/27 13:32:07] d2.utils.events INFO:  eta: 1 day, 0:46:49  iter: 16919  total_loss: 25.93  loss_mask: 2.584  loss_mask_0: 2.659  loss_mask_1: 2.586  loss_mask_2: 2.586  loss_mask_3: 2.588  loss_mask_4: 2.585  loss_mask_5: 2.585  loss_mask_6: 2.586  loss_mask_7: 2.585  loss_mask_8: 2.586  time: 1.8895  data_time: 0.4071  lr: 7.422e-05  max_mem: 17484M
[01/27 13:32:49] d2.utils.events INFO:  eta: 1 day, 0:48:28  iter: 16939  total_loss: 26.39  loss_mask: 2.633  loss_mask_0: 2.691  loss_mask_1: 2.631  loss_mask_2: 2.63  loss_mask_3: 2.631  loss_mask_4: 2.631  loss_mask_5: 2.632  loss_mask_6: 2.631  loss_mask_7: 2.632  loss_mask_8: 2.632  time: 1.8897  data_time: 0.4185  lr: 7.4189e-05  max_mem: 17484M
[01/27 13:33:31] d2.utils.events INFO:  eta: 1 day, 0:50:22  iter: 16959  total_loss: 26.96  loss_mask: 2.693  loss_mask_0: 2.737  loss_mask_1: 2.691  loss_mask_2: 2.691  loss_mask_3: 2.692  loss_mask_4: 2.691  loss_mask_5: 2.691  loss_mask_6: 2.691  loss_mask_7: 2.691  loss_mask_8: 2.691  time: 1.8900  data_time: 0.4245  lr: 7.4158e-05  max_mem: 17484M
[01/27 13:34:13] d2.utils.events INFO:  eta: 1 day, 0:50:24  iter: 16979  total_loss: 28.44  loss_mask: 2.838  loss_mask_0: 2.886  loss_mask_1: 2.839  loss_mask_2: 2.839  loss_mask_3: 2.846  loss_mask_4: 2.839  loss_mask_5: 2.838  loss_mask_6: 2.838  loss_mask_7: 2.838  loss_mask_8: 2.839  time: 1.8902  data_time: 0.4248  lr: 7.4127e-05  max_mem: 17484M
[01/27 13:34:55] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 13:34:56] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 13:34:56] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 13:42:09] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.462431788646737, 'error_1pix': 0.3343055023150509, 'error_3pix': 0.1403289606505942, 'mIoU': 8.778626373495252, 'fwIoU': 20.9165438644911, 'IoU-0': nan, 'IoU-1': 61.62687208555252, 'IoU-2': 2.8037845833800636, 'IoU-3': 3.218115008360667, 'IoU-4': 3.0655167053703067, 'IoU-5': 3.3315653212465604, 'IoU-6': 3.630209213778003, 'IoU-7': 3.322837450066982, 'IoU-8': 3.795333361248331, 'IoU-9': 8.013955801688716, 'IoU-10': 16.262071938337716, 'IoU-11': 25.485829679227333, 'IoU-12': 24.52022678367255, 'IoU-13': 24.295946477038218, 'IoU-14': 23.91936384991982, 'IoU-15': 23.033908354548373, 'IoU-16': 23.72511096844398, 'IoU-17': 21.05582501387218, 'IoU-18': 21.88996323619201, 'IoU-19': 21.60715078663667, 'IoU-20': 21.39709369283924, 'IoU-21': 20.32013172266381, 'IoU-22': 21.445445799832488, 'IoU-23': 20.684982620661877, 'IoU-24': 20.67447149389918, 'IoU-25': 19.931966403700596, 'IoU-26': 19.992202717428196, 'IoU-27': 21.614056460030667, 'IoU-28': 21.295180299988996, 'IoU-29': 21.351071538831697, 'IoU-30': 20.574202932061482, 'IoU-31': 20.507422555031162, 'IoU-32': 19.954605289862375, 'IoU-33': 18.545602297923374, 'IoU-34': 17.965710741731822, 'IoU-35': 17.934343294917337, 'IoU-36': 17.73560883522617, 'IoU-37': 17.548316011800157, 'IoU-38': 17.77625315522115, 'IoU-39': 17.382228295158832, 'IoU-40': 17.83122079160385, 'IoU-41': 16.833781797302542, 'IoU-42': 16.839221551188345, 'IoU-43': 16.23810460601314, 'IoU-44': 16.605427022997958, 'IoU-45': 15.650992609507878, 'IoU-46': 14.598843697357506, 'IoU-47': 14.250596569519407, 'IoU-48': 14.177391316167295, 'IoU-49': 14.236089644581812, 'IoU-50': 13.599422781284082, 'IoU-51': 13.058483960971518, 'IoU-52': 12.8685417194235, 'IoU-53': 12.511283990678898, 'IoU-54': 12.82600770208758, 'IoU-55': 12.784240253661514, 'IoU-56': 12.282135646571096, 'IoU-57': 12.375424880702058, 'IoU-58': 11.980167622677444, 'IoU-59': 11.574088932682308, 'IoU-60': 11.325642523203811, 'IoU-61': 11.107211449973914, 'IoU-62': 10.795968668115869, 'IoU-63': 10.435389522753109, 'IoU-64': 10.621033954689944, 'IoU-65': 10.052815656685965, 'IoU-66': 10.035160065808757, 'IoU-67': 9.76678066029968, 'IoU-68': 9.469747841340263, 'IoU-69': 9.384385901007867, 'IoU-70': 9.471451033444856, 'IoU-71': 9.407362649291533, 'IoU-72': 9.059498693371532, 'IoU-73': 8.719868928260476, 'IoU-74': 8.920241907049418, 'IoU-75': 8.69456336077227, 'IoU-76': 8.904718165926386, 'IoU-77': 8.788904697042549, 'IoU-78': 8.710718304328733, 'IoU-79': 8.505666955398176, 'IoU-80': 8.551048203297656, 'IoU-81': 8.81754602122808, 'IoU-82': 8.73668558027859, 'IoU-83': 8.5621313288078, 'IoU-84': 8.21218143995868, 'IoU-85': 8.22333744031976, 'IoU-86': 8.283856750967605, 'IoU-87': 8.16282342679606, 'IoU-88': 8.153258324258914, 'IoU-89': 8.144757846634928, 'IoU-90': 8.057102252444276, 'IoU-91': 7.855410971042685, 'IoU-92': 7.579419062435325, 'IoU-93': 7.837180649689913, 'IoU-94': 7.802480201497512, 'IoU-95': 7.702139125396706, 'IoU-96': 7.387984651784195, 'IoU-97': 7.250573612747474, 'IoU-98': 7.207003335156481, 'IoU-99': 7.032621179443792, 'IoU-100': 6.9765700205734955, 'IoU-101': 6.913928513659691, 'IoU-102': 6.573922738857614, 'IoU-103': 6.591344058853976, 'IoU-104': 6.3407947359046934, 'IoU-105': 6.075904667031122, 'IoU-106': 6.059485397167053, 'IoU-107': 6.186954585423483, 'IoU-108': 6.139974251005433, 'IoU-109': 6.027384827240861, 'IoU-110': 6.047045627194924, 'IoU-111': 6.050619766893646, 'IoU-112': 5.792547939884293, 'IoU-113': 5.664822896730998, 'IoU-114': 5.694558056452334, 'IoU-115': 5.673664650583686, 'IoU-116': 5.634104152538252, 'IoU-117': 5.521004098140287, 'IoU-118': 5.6785948434630695, 'IoU-119': 5.445780604029188, 'IoU-120': 5.20569963158275, 'IoU-121': 5.1410511162846415, 'IoU-122': 5.348588204334295, 'IoU-123': 5.2517833497638495, 'IoU-124': 4.894270127544887, 'IoU-125': 4.868555427489176, 'IoU-126': 4.904432447335053, 'IoU-127': 4.723024384035684, 'IoU-128': 4.8390800528687965, 'IoU-129': 4.496751647508387, 'IoU-130': 4.539285756120908, 'IoU-131': 4.491857887764845, 'IoU-132': 4.515427858115238, 'IoU-133': 4.337527979609312, 'IoU-134': 4.333607454355957, 'IoU-135': 4.366544611148221, 'IoU-136': 4.279211745478612, 'IoU-137': 4.209196235507649, 'IoU-138': 3.8896783499586705, 'IoU-139': 3.9353959990888567, 'IoU-140': 4.088028999693665, 'IoU-141': 3.942343490930732, 'IoU-142': 3.859122413657645, 'IoU-143': 3.42672914410005, 'IoU-144': 3.3509707114616734, 'IoU-145': 3.5405283283075586, 'IoU-146': 3.45059578019503, 'IoU-147': 3.2560710076507684, 'IoU-148': 3.059332558536239, 'IoU-149': 2.972711747556629, 'IoU-150': 2.626888645845992, 'IoU-151': 2.779531744417927, 'IoU-152': 2.8736658234304984, 'IoU-153': 2.4464018676608417, 'IoU-154': 2.646110542976676, 'IoU-155': 2.2574002906244077, 'IoU-156': 2.2380921301491523, 'IoU-157': 2.193554863969481, 'IoU-158': 2.03507731656537, 'IoU-159': 1.9934790793329076, 'IoU-160': 2.4056911927804197, 'IoU-161': 2.349493922164494, 'IoU-162': 2.0965680795747255, 'IoU-163': 1.9290135025947306, 'IoU-164': 2.1188895594447796, 'IoU-165': 2.2878121754803646, 'IoU-166': 2.214867322495044, 'IoU-167': 2.0439001760673237, 'IoU-168': 1.9263652142542929, 'IoU-169': 1.746448762053884, 'IoU-170': 1.8176313680846778, 'IoU-171': 1.6765025368577942, 'IoU-172': 1.7049582891357478, 'IoU-173': 1.9020579193671554, 'IoU-174': 2.178451609094755, 'IoU-175': 2.128618388798705, 'IoU-176': 2.0327917866124303, 'IoU-177': 2.0993037237133794, 'IoU-178': 2.136922166857181, 'IoU-179': 2.224260564513534, 'IoU-180': 2.2462280094923686, 'IoU-181': 2.380932921254777, 'IoU-182': 2.568740826137856, 'IoU-183': 2.523766809594111, 'IoU-184': 2.5325088370753073, 'IoU-185': 2.659567495864497, 'IoU-186': 2.7282497362266898, 'IoU-187': 2.6843612871769866, 'IoU-188': 2.671047360112862, 'IoU-189': 2.541945732112446, 'IoU-190': 2.4281462585034013, 'IoU-191': 2.791726738125585, 'IoU-192': 1.7078844110513853, 'mACC': 15.488745944284824, 'pACC': 31.102944030525965, 'ACC-0': nan, 'ACC-1': 62.61346026654019, 'ACC-2': 5.560634030317015, 'ACC-3': 15.040635376925762, 'ACC-4': 13.09040586694773, 'ACC-5': 14.175332166535416, 'ACC-6': 15.555061163740843, 'ACC-7': 14.968222540665302, 'ACC-8': 8.253133859002162, 'ACC-9': 11.526290819664233, 'ACC-10': 23.824702536435623, 'ACC-11': 35.20759681117645, 'ACC-12': 36.74387577676645, 'ACC-13': 38.38670417182926, 'ACC-14': 38.22723451101495, 'ACC-15': 38.00651532146371, 'ACC-16': 39.782007393887945, 'ACC-17': 37.3404434360079, 'ACC-18': 36.19561747630974, 'ACC-19': 35.20667865326118, 'ACC-20': 35.40018797714813, 'ACC-21': 33.77712600069751, 'ACC-22': 34.8350621936088, 'ACC-23': 35.38833935870594, 'ACC-24': 35.17361635552327, 'ACC-25': 33.638667198444075, 'ACC-26': 33.46167512941196, 'ACC-27': 35.299041628850325, 'ACC-28': 36.06109545443555, 'ACC-29': 34.842810497770564, 'ACC-30': 34.10563015570777, 'ACC-31': 33.09810159571988, 'ACC-32': 32.89474759823408, 'ACC-33': 31.030308906056064, 'ACC-34': 29.853665197795404, 'ACC-35': 29.50206980768933, 'ACC-36': 30.013544580709894, 'ACC-37': 30.301909548058738, 'ACC-38': 30.510800295751288, 'ACC-39': 30.01029908535552, 'ACC-40': 30.81895383952639, 'ACC-41': 29.905895316416363, 'ACC-42': 29.496995836936062, 'ACC-43': 28.314124964088865, 'ACC-44': 28.3884749125664, 'ACC-45': 27.355105526150815, 'ACC-46': 25.997674901903494, 'ACC-47': 25.32516771718886, 'ACC-48': 25.47153918292348, 'ACC-49': 25.457553256980287, 'ACC-50': 24.4154091521357, 'ACC-51': 23.842188977524433, 'ACC-52': 23.41048818166805, 'ACC-53': 22.70139359938487, 'ACC-54': 23.372822762617645, 'ACC-55': 23.680993938188934, 'ACC-56': 23.004844219911995, 'ACC-57': 22.625498705429447, 'ACC-58': 22.209731227975098, 'ACC-59': 21.587221437398433, 'ACC-60': 21.12547666342392, 'ACC-61': 20.71813298645241, 'ACC-62': 20.068928085982492, 'ACC-63': 19.53966697507773, 'ACC-64': 19.9080572481704, 'ACC-65': 18.889304891915323, 'ACC-66': 18.829064308669842, 'ACC-67': 18.511459467855108, 'ACC-68': 17.90491571938326, 'ACC-69': 17.36915820387989, 'ACC-70': 17.342265443674837, 'ACC-71': 17.44785151609206, 'ACC-72': 16.81567147491151, 'ACC-73': 16.071366221317447, 'ACC-74': 16.287007149122896, 'ACC-75': 15.965411541934985, 'ACC-76': 16.22448326858172, 'ACC-77': 16.236254565437186, 'ACC-78': 16.222899866519455, 'ACC-79': 15.802099100814981, 'ACC-80': 15.737107677554626, 'ACC-81': 16.19206064816508, 'ACC-82': 16.140937792600297, 'ACC-83': 15.618593893275728, 'ACC-84': 14.989452777261414, 'ACC-85': 15.019839508691668, 'ACC-86': 15.161886104897048, 'ACC-87': 14.939734596339981, 'ACC-88': 14.887405003018312, 'ACC-89': 14.876969777030984, 'ACC-90': 14.597897269796011, 'ACC-91': 14.306932518651683, 'ACC-92': 13.904377127741792, 'ACC-93': 14.374334018227405, 'ACC-94': 14.390063520098478, 'ACC-95': 14.253405274043107, 'ACC-96': 13.727776575975263, 'ACC-97': 13.273560996221597, 'ACC-98': 13.18351263422744, 'ACC-99': 12.913382911385082, 'ACC-100': 12.785722221276133, 'ACC-101': 12.696622596381182, 'ACC-102': 12.139420027186226, 'ACC-103': 12.172924341173138, 'ACC-104': 11.679865227121812, 'ACC-105': 11.143770059437356, 'ACC-106': 11.08936402085518, 'ACC-107': 11.228835685286477, 'ACC-108': 11.09363267519284, 'ACC-109': 10.91944100708309, 'ACC-110': 11.099645937921256, 'ACC-111': 11.120784510610079, 'ACC-112': 10.747167741380103, 'ACC-113': 10.543588889987014, 'ACC-114': 10.703583130739574, 'ACC-115': 10.643220122382091, 'ACC-116': 10.608662911438772, 'ACC-117': 10.314611834349009, 'ACC-118': 10.669997065117855, 'ACC-119': 10.105608446273854, 'ACC-120': 9.622615320282383, 'ACC-121': 9.53167816346729, 'ACC-122': 9.90465811844849, 'ACC-123': 9.804576557871115, 'ACC-124': 9.337590252202732, 'ACC-125': 9.232588215971276, 'ACC-126': 9.396886583666518, 'ACC-127': 9.103498303880981, 'ACC-128': 9.419910695446102, 'ACC-129': 8.70780435490622, 'ACC-130': 8.74709462056583, 'ACC-131': 8.669294410296184, 'ACC-132': 8.620938095860435, 'ACC-133': 8.25137615927385, 'ACC-134': 8.260784144765188, 'ACC-135': 8.296574164206948, 'ACC-136': 8.072164438128961, 'ACC-137': 8.057074602259934, 'ACC-138': 7.495016621836754, 'ACC-139': 7.549522605526068, 'ACC-140': 7.6928301242948525, 'ACC-141': 7.369670998483499, 'ACC-142': 7.249703067141759, 'ACC-143': 6.3763615074732956, 'ACC-144': 6.150230462160794, 'ACC-145': 6.441164631691936, 'ACC-146': 6.294802294169899, 'ACC-147': 5.902912549237366, 'ACC-148': 5.472537500712941, 'ACC-149': 5.3525429091838435, 'ACC-150': 4.731815163698185, 'ACC-151': 4.982680153054155, 'ACC-152': 5.105252565060384, 'ACC-153': 4.457136182064719, 'ACC-154': 4.773664871111048, 'ACC-155': 4.096201376946925, 'ACC-156': 4.123310129397284, 'ACC-157': 4.104476088190494, 'ACC-158': 3.89482257060548, 'ACC-159': 3.7988180446692907, 'ACC-160': 4.478069914960648, 'ACC-161': 4.308114894298257, 'ACC-162': 3.8934103048608115, 'ACC-163': 3.5406375226851234, 'ACC-164': 3.897405482723569, 'ACC-165': 4.210347385829098, 'ACC-166': 4.178597639724639, 'ACC-167': 3.9284323813231734, 'ACC-168': 3.6819830500722963, 'ACC-169': 3.2580494535394426, 'ACC-170': 3.379177364199043, 'ACC-171': 3.1718458470050828, 'ACC-172': 3.2533887921942393, 'ACC-173': 3.6581990317861113, 'ACC-174': 4.131147418639233, 'ACC-175': 3.9771865088030323, 'ACC-176': 3.75385028913492, 'ACC-177': 3.8534138662259174, 'ACC-178': 3.9275316057765783, 'ACC-179': 4.21434988881255, 'ACC-180': 4.354136121655254, 'ACC-181': 4.848035299935334, 'ACC-182': 5.140114679280912, 'ACC-183': 4.902174015829937, 'ACC-184': 4.702537907658223, 'ACC-185': 4.710935686092408, 'ACC-186': 4.627567669056781, 'ACC-187': 4.289550763417324, 'ACC-188': 3.9676302812513513, 'ACC-189': 3.455256068887124, 'ACC-190': 3.0357717137943956, 'ACC-191': 3.211651149250303, 'ACC-192': 1.8856395090765496})])
[01/27 13:42:09] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 13:42:09] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 13:42:09] d2.evaluation.testing INFO: copypaste: 2.4624,0.3343,0.1403,8.7786,20.9165,15.4887,31.1029
[01/27 13:42:10] d2.utils.events INFO:  eta: 1 day, 0:51:12  iter: 16999  total_loss: 27.01  loss_mask: 2.695  loss_mask_0: 2.743  loss_mask_1: 2.696  loss_mask_2: 2.696  loss_mask_3: 2.699  loss_mask_4: 2.696  loss_mask_5: 2.696  loss_mask_6: 2.696  loss_mask_7: 2.696  loss_mask_8: 2.696  time: 1.8905  data_time: 0.4220  lr: 7.4096e-05  max_mem: 17484M
[01/27 13:42:51] d2.utils.events INFO:  eta: 1 day, 0:51:38  iter: 17019  total_loss: 25.83  loss_mask: 2.581  loss_mask_0: 2.617  loss_mask_1: 2.58  loss_mask_2: 2.578  loss_mask_3: 2.576  loss_mask_4: 2.579  loss_mask_5: 2.581  loss_mask_6: 2.58  loss_mask_7: 2.579  loss_mask_8: 2.579  time: 1.8907  data_time: 0.3983  lr: 7.4065e-05  max_mem: 17484M
[01/27 13:43:33] d2.utils.events INFO:  eta: 1 day, 0:51:57  iter: 17039  total_loss: 26.56  loss_mask: 2.65  loss_mask_0: 2.711  loss_mask_1: 2.652  loss_mask_2: 2.651  loss_mask_3: 2.648  loss_mask_4: 2.651  loss_mask_5: 2.65  loss_mask_6: 2.651  loss_mask_7: 2.651  loss_mask_8: 2.649  time: 1.8909  data_time: 0.4075  lr: 7.4034e-05  max_mem: 17484M
[01/27 13:44:15] d2.utils.events INFO:  eta: 1 day, 0:52:48  iter: 17059  total_loss: 25.67  loss_mask: 2.562  loss_mask_0: 2.629  loss_mask_1: 2.561  loss_mask_2: 2.56  loss_mask_3: 2.569  loss_mask_4: 2.562  loss_mask_5: 2.561  loss_mask_6: 2.559  loss_mask_7: 2.561  loss_mask_8: 2.56  time: 1.8912  data_time: 0.4127  lr: 7.4003e-05  max_mem: 17484M
[01/27 13:44:58] d2.utils.events INFO:  eta: 1 day, 0:54:19  iter: 17079  total_loss: 26.44  loss_mask: 2.639  loss_mask_0: 2.714  loss_mask_1: 2.637  loss_mask_2: 2.637  loss_mask_3: 2.643  loss_mask_4: 2.638  loss_mask_5: 2.638  loss_mask_6: 2.637  loss_mask_7: 2.638  loss_mask_8: 2.639  time: 1.8915  data_time: 0.4310  lr: 7.3972e-05  max_mem: 17484M
[01/27 13:45:40] d2.utils.events INFO:  eta: 1 day, 0:53:47  iter: 17099  total_loss: 27.73  loss_mask: 2.764  loss_mask_0: 2.825  loss_mask_1: 2.764  loss_mask_2: 2.765  loss_mask_3: 2.759  loss_mask_4: 2.765  loss_mask_5: 2.764  loss_mask_6: 2.764  loss_mask_7: 2.764  loss_mask_8: 2.764  time: 1.8917  data_time: 0.4314  lr: 7.3941e-05  max_mem: 17484M
[01/27 13:46:22] d2.utils.events INFO:  eta: 1 day, 0:53:17  iter: 17119  total_loss: 25.69  loss_mask: 2.564  loss_mask_0: 2.616  loss_mask_1: 2.566  loss_mask_2: 2.566  loss_mask_3: 2.568  loss_mask_4: 2.564  loss_mask_5: 2.565  loss_mask_6: 2.565  loss_mask_7: 2.565  loss_mask_8: 2.565  time: 1.8920  data_time: 0.4247  lr: 7.391e-05  max_mem: 17484M
[01/27 13:47:04] d2.utils.events INFO:  eta: 1 day, 0:52:28  iter: 17139  total_loss: 28.24  loss_mask: 2.82  loss_mask_0: 2.847  loss_mask_1: 2.82  loss_mask_2: 2.82  loss_mask_3: 2.817  loss_mask_4: 2.821  loss_mask_5: 2.82  loss_mask_6: 2.82  loss_mask_7: 2.82  loss_mask_8: 2.82  time: 1.8922  data_time: 0.4251  lr: 7.3879e-05  max_mem: 17484M
[01/27 13:47:46] d2.utils.events INFO:  eta: 1 day, 0:51:41  iter: 17159  total_loss: 27.43  loss_mask: 2.742  loss_mask_0: 2.757  loss_mask_1: 2.742  loss_mask_2: 2.74  loss_mask_3: 2.737  loss_mask_4: 2.741  loss_mask_5: 2.742  loss_mask_6: 2.741  loss_mask_7: 2.743  loss_mask_8: 2.741  time: 1.8925  data_time: 0.4242  lr: 7.3848e-05  max_mem: 17484M
[01/27 13:48:28] d2.utils.events INFO:  eta: 1 day, 0:51:55  iter: 17179  total_loss: 27.68  loss_mask: 2.767  loss_mask_0: 2.786  loss_mask_1: 2.765  loss_mask_2: 2.765  loss_mask_3: 2.768  loss_mask_4: 2.766  loss_mask_5: 2.765  loss_mask_6: 2.768  loss_mask_7: 2.765  loss_mask_8: 2.768  time: 1.8927  data_time: 0.4316  lr: 7.3817e-05  max_mem: 17484M
[01/27 13:49:10] d2.utils.events INFO:  eta: 1 day, 0:51:30  iter: 17199  total_loss: 27.82  loss_mask: 2.782  loss_mask_0: 2.79  loss_mask_1: 2.781  loss_mask_2: 2.781  loss_mask_3: 2.778  loss_mask_4: 2.782  loss_mask_5: 2.781  loss_mask_6: 2.781  loss_mask_7: 2.782  loss_mask_8: 2.782  time: 1.8930  data_time: 0.4083  lr: 7.3786e-05  max_mem: 17484M
[01/27 13:49:52] d2.utils.events INFO:  eta: 1 day, 0:50:11  iter: 17219  total_loss: 32.53  loss_mask: 3.246  loss_mask_0: 3.311  loss_mask_1: 3.237  loss_mask_2: 3.236  loss_mask_3: 3.24  loss_mask_4: 3.239  loss_mask_5: 3.246  loss_mask_6: 3.242  loss_mask_7: 3.24  loss_mask_8: 3.241  time: 1.8932  data_time: 0.4114  lr: 7.3755e-05  max_mem: 17484M
[01/27 13:50:34] d2.utils.events INFO:  eta: 1 day, 0:50:20  iter: 17239  total_loss: 29.57  loss_mask: 2.957  loss_mask_0: 2.966  loss_mask_1: 2.956  loss_mask_2: 2.955  loss_mask_3: 2.954  loss_mask_4: 2.956  loss_mask_5: 2.957  loss_mask_6: 2.956  loss_mask_7: 2.956  loss_mask_8: 2.956  time: 1.8934  data_time: 0.4155  lr: 7.3724e-05  max_mem: 17484M
[01/27 13:51:16] d2.utils.events INFO:  eta: 1 day, 0:49:49  iter: 17259  total_loss: 27.76  loss_mask: 2.775  loss_mask_0: 2.792  loss_mask_1: 2.775  loss_mask_2: 2.774  loss_mask_3: 2.774  loss_mask_4: 2.775  loss_mask_5: 2.775  loss_mask_6: 2.773  loss_mask_7: 2.775  loss_mask_8: 2.775  time: 1.8937  data_time: 0.4205  lr: 7.3693e-05  max_mem: 17484M
[01/27 13:51:59] d2.utils.events INFO:  eta: 1 day, 0:49:15  iter: 17279  total_loss: 29.08  loss_mask: 2.907  loss_mask_0: 2.948  loss_mask_1: 2.902  loss_mask_2: 2.904  loss_mask_3: 2.904  loss_mask_4: 2.902  loss_mask_5: 2.902  loss_mask_6: 2.905  loss_mask_7: 2.903  loss_mask_8: 2.905  time: 1.8939  data_time: 0.4311  lr: 7.3662e-05  max_mem: 17484M
[01/27 13:52:41] d2.utils.events INFO:  eta: 1 day, 0:48:51  iter: 17299  total_loss: 26.48  loss_mask: 2.641  loss_mask_0: 2.702  loss_mask_1: 2.642  loss_mask_2: 2.644  loss_mask_3: 2.643  loss_mask_4: 2.642  loss_mask_5: 2.642  loss_mask_6: 2.64  loss_mask_7: 2.641  loss_mask_8: 2.642  time: 1.8942  data_time: 0.4346  lr: 7.3631e-05  max_mem: 17484M
[01/27 13:53:23] d2.utils.events INFO:  eta: 1 day, 0:48:45  iter: 17319  total_loss: 30.48  loss_mask: 3.038  loss_mask_0: 3.132  loss_mask_1: 3.04  loss_mask_2: 3.042  loss_mask_3: 3.035  loss_mask_4: 3.039  loss_mask_5: 3.04  loss_mask_6: 3.038  loss_mask_7: 3.037  loss_mask_8: 3.036  time: 1.8944  data_time: 0.4147  lr: 7.36e-05  max_mem: 17484M
[01/27 13:54:06] d2.utils.events INFO:  eta: 1 day, 0:49:03  iter: 17339  total_loss: 29.55  loss_mask: 2.949  loss_mask_0: 3.005  loss_mask_1: 2.95  loss_mask_2: 2.953  loss_mask_3: 2.948  loss_mask_4: 2.951  loss_mask_5: 2.95  loss_mask_6: 2.951  loss_mask_7: 2.95  loss_mask_8: 2.948  time: 1.8947  data_time: 0.4515  lr: 7.3568e-05  max_mem: 17484M
[01/27 13:54:47] d2.utils.events INFO:  eta: 1 day, 0:48:18  iter: 17359  total_loss: 28.96  loss_mask: 2.891  loss_mask_0: 2.912  loss_mask_1: 2.894  loss_mask_2: 2.893  loss_mask_3: 2.892  loss_mask_4: 2.894  loss_mask_5: 2.894  loss_mask_6: 2.892  loss_mask_7: 2.908  loss_mask_8: 2.892  time: 1.8949  data_time: 0.4060  lr: 7.3537e-05  max_mem: 17484M
[01/27 13:55:29] d2.utils.events INFO:  eta: 1 day, 0:47:37  iter: 17379  total_loss: 27.93  loss_mask: 2.792  loss_mask_0: 2.809  loss_mask_1: 2.788  loss_mask_2: 2.792  loss_mask_3: 2.79  loss_mask_4: 2.787  loss_mask_5: 2.791  loss_mask_6: 2.79  loss_mask_7: 2.834  loss_mask_8: 2.804  time: 1.8951  data_time: 0.4201  lr: 7.3506e-05  max_mem: 17484M
[01/27 13:56:12] d2.utils.events INFO:  eta: 1 day, 0:46:57  iter: 17399  total_loss: 31.5  loss_mask: 3.14  loss_mask_0: 3.161  loss_mask_1: 3.147  loss_mask_2: 3.148  loss_mask_3: 3.139  loss_mask_4: 3.148  loss_mask_5: 3.143  loss_mask_6: 3.143  loss_mask_7: 3.176  loss_mask_8: 3.157  time: 1.8954  data_time: 0.4349  lr: 7.3475e-05  max_mem: 17484M
[01/27 13:56:54] d2.utils.events INFO:  eta: 1 day, 0:46:20  iter: 17419  total_loss: 27.59  loss_mask: 2.752  loss_mask_0: 2.803  loss_mask_1: 2.75  loss_mask_2: 2.753  loss_mask_3: 2.763  loss_mask_4: 2.752  loss_mask_5: 2.756  loss_mask_6: 2.754  loss_mask_7: 2.765  loss_mask_8: 2.748  time: 1.8956  data_time: 0.4305  lr: 7.3444e-05  max_mem: 17484M
[01/27 13:57:36] d2.utils.events INFO:  eta: 1 day, 0:45:38  iter: 17439  total_loss: 25.89  loss_mask: 2.587  loss_mask_0: 2.603  loss_mask_1: 2.588  loss_mask_2: 2.587  loss_mask_3: 2.589  loss_mask_4: 2.587  loss_mask_5: 2.588  loss_mask_6: 2.588  loss_mask_7: 2.587  loss_mask_8: 2.589  time: 1.8959  data_time: 0.4362  lr: 7.3413e-05  max_mem: 17484M
[01/27 13:58:18] d2.utils.events INFO:  eta: 1 day, 0:44:51  iter: 17459  total_loss: 25.78  loss_mask: 2.577  loss_mask_0: 2.589  loss_mask_1: 2.576  loss_mask_2: 2.577  loss_mask_3: 2.577  loss_mask_4: 2.577  loss_mask_5: 2.577  loss_mask_6: 2.577  loss_mask_7: 2.577  loss_mask_8: 2.575  time: 1.8961  data_time: 0.4236  lr: 7.3382e-05  max_mem: 17484M
[01/27 13:59:00] d2.utils.events INFO:  eta: 1 day, 0:44:08  iter: 17479  total_loss: 25.92  loss_mask: 2.592  loss_mask_0: 2.598  loss_mask_1: 2.592  loss_mask_2: 2.591  loss_mask_3: 2.591  loss_mask_4: 2.592  loss_mask_5: 2.592  loss_mask_6: 2.592  loss_mask_7: 2.592  loss_mask_8: 2.592  time: 1.8963  data_time: 0.4145  lr: 7.3351e-05  max_mem: 17484M
[01/27 13:59:42] d2.utils.events INFO:  eta: 1 day, 0:42:59  iter: 17499  total_loss: 28.15  loss_mask: 2.813  loss_mask_0: 2.829  loss_mask_1: 2.812  loss_mask_2: 2.813  loss_mask_3: 2.812  loss_mask_4: 2.814  loss_mask_5: 2.813  loss_mask_6: 2.815  loss_mask_7: 2.815  loss_mask_8: 2.815  time: 1.8966  data_time: 0.4342  lr: 7.332e-05  max_mem: 17484M
[01/27 14:00:24] d2.utils.events INFO:  eta: 1 day, 0:42:17  iter: 17519  total_loss: 29.44  loss_mask: 2.94  loss_mask_0: 2.979  loss_mask_1: 2.938  loss_mask_2: 2.939  loss_mask_3: 2.937  loss_mask_4: 2.94  loss_mask_5: 2.939  loss_mask_6: 2.943  loss_mask_7: 2.94  loss_mask_8: 2.941  time: 1.8968  data_time: 0.4237  lr: 7.3289e-05  max_mem: 17484M
[01/27 14:01:06] d2.utils.events INFO:  eta: 1 day, 0:41:53  iter: 17539  total_loss: 27.14  loss_mask: 2.713  loss_mask_0: 2.72  loss_mask_1: 2.713  loss_mask_2: 2.713  loss_mask_3: 2.713  loss_mask_4: 2.713  loss_mask_5: 2.713  loss_mask_6: 2.714  loss_mask_7: 2.713  loss_mask_8: 2.713  time: 1.8970  data_time: 0.4184  lr: 7.3258e-05  max_mem: 17484M
[01/27 14:01:48] d2.utils.events INFO:  eta: 1 day, 0:40:47  iter: 17559  total_loss: 30.88  loss_mask: 3.082  loss_mask_0: 3.134  loss_mask_1: 3.079  loss_mask_2: 3.083  loss_mask_3: 3.078  loss_mask_4: 3.081  loss_mask_5: 3.082  loss_mask_6: 3.078  loss_mask_7: 3.081  loss_mask_8: 3.083  time: 1.8972  data_time: 0.4249  lr: 7.3227e-05  max_mem: 17484M
[01/27 14:02:30] d2.utils.events INFO:  eta: 1 day, 0:39:55  iter: 17579  total_loss: 27.59  loss_mask: 2.759  loss_mask_0: 2.764  loss_mask_1: 2.758  loss_mask_2: 2.759  loss_mask_3: 2.76  loss_mask_4: 2.757  loss_mask_5: 2.759  loss_mask_6: 2.758  loss_mask_7: 2.758  loss_mask_8: 2.758  time: 1.8975  data_time: 0.4091  lr: 7.3196e-05  max_mem: 17484M
[01/27 14:03:11] d2.utils.events INFO:  eta: 1 day, 0:39:24  iter: 17599  total_loss: 27.72  loss_mask: 2.769  loss_mask_0: 2.789  loss_mask_1: 2.771  loss_mask_2: 2.77  loss_mask_3: 2.769  loss_mask_4: 2.772  loss_mask_5: 2.77  loss_mask_6: 2.77  loss_mask_7: 2.772  loss_mask_8: 2.768  time: 1.8977  data_time: 0.4160  lr: 7.3165e-05  max_mem: 17484M
[01/27 14:03:54] d2.utils.events INFO:  eta: 1 day, 0:39:05  iter: 17619  total_loss: 29.46  loss_mask: 2.94  loss_mask_0: 2.993  loss_mask_1: 2.94  loss_mask_2: 2.941  loss_mask_3: 2.942  loss_mask_4: 2.939  loss_mask_5: 2.94  loss_mask_6: 2.941  loss_mask_7: 2.941  loss_mask_8: 2.942  time: 1.8979  data_time: 0.4390  lr: 7.3134e-05  max_mem: 17484M
[01/27 14:04:35] d2.utils.events INFO:  eta: 1 day, 0:38:24  iter: 17639  total_loss: 26.05  loss_mask: 2.599  loss_mask_0: 2.653  loss_mask_1: 2.6  loss_mask_2: 2.602  loss_mask_3: 2.6  loss_mask_4: 2.6  loss_mask_5: 2.6  loss_mask_6: 2.601  loss_mask_7: 2.604  loss_mask_8: 2.601  time: 1.8981  data_time: 0.4154  lr: 7.3103e-05  max_mem: 17484M
[01/27 14:05:17] d2.utils.events INFO:  eta: 1 day, 0:37:14  iter: 17659  total_loss: 25.24  loss_mask: 2.52  loss_mask_0: 2.56  loss_mask_1: 2.52  loss_mask_2: 2.52  loss_mask_3: 2.521  loss_mask_4: 2.52  loss_mask_5: 2.52  loss_mask_6: 2.518  loss_mask_7: 2.519  loss_mask_8: 2.52  time: 1.8984  data_time: 0.4006  lr: 7.3072e-05  max_mem: 17484M
[01/27 14:05:59] d2.utils.events INFO:  eta: 1 day, 0:35:40  iter: 17679  total_loss: 26.37  loss_mask: 2.633  loss_mask_0: 2.675  loss_mask_1: 2.634  loss_mask_2: 2.633  loss_mask_3: 2.634  loss_mask_4: 2.634  loss_mask_5: 2.633  loss_mask_6: 2.634  loss_mask_7: 2.632  loss_mask_8: 2.633  time: 1.8986  data_time: 0.4116  lr: 7.3041e-05  max_mem: 17484M
[01/27 14:06:40] d2.utils.events INFO:  eta: 1 day, 0:34:46  iter: 17699  total_loss: 26.72  loss_mask: 2.667  loss_mask_0: 2.714  loss_mask_1: 2.666  loss_mask_2: 2.665  loss_mask_3: 2.666  loss_mask_4: 2.665  loss_mask_5: 2.666  loss_mask_6: 2.665  loss_mask_7: 2.665  loss_mask_8: 2.666  time: 1.8988  data_time: 0.4018  lr: 7.301e-05  max_mem: 17484M
[01/27 14:07:22] d2.utils.events INFO:  eta: 1 day, 0:34:04  iter: 17719  total_loss: 26.58  loss_mask: 2.652  loss_mask_0: 2.714  loss_mask_1: 2.652  loss_mask_2: 2.65  loss_mask_3: 2.654  loss_mask_4: 2.651  loss_mask_5: 2.651  loss_mask_6: 2.649  loss_mask_7: 2.649  loss_mask_8: 2.65  time: 1.8990  data_time: 0.4079  lr: 7.2978e-05  max_mem: 17484M
[01/27 14:08:05] d2.utils.events INFO:  eta: 1 day, 0:33:38  iter: 17739  total_loss: 25.72  loss_mask: 2.57  loss_mask_0: 2.596  loss_mask_1: 2.569  loss_mask_2: 2.569  loss_mask_3: 2.569  loss_mask_4: 2.569  loss_mask_5: 2.569  loss_mask_6: 2.571  loss_mask_7: 2.571  loss_mask_8: 2.57  time: 1.8992  data_time: 0.4386  lr: 7.2947e-05  max_mem: 17484M
[01/27 14:08:47] d2.utils.events INFO:  eta: 1 day, 0:32:56  iter: 17759  total_loss: 26.29  loss_mask: 2.622  loss_mask_0: 2.689  loss_mask_1: 2.622  loss_mask_2: 2.623  loss_mask_3: 2.622  loss_mask_4: 2.624  loss_mask_5: 2.623  loss_mask_6: 2.623  loss_mask_7: 2.624  loss_mask_8: 2.623  time: 1.8995  data_time: 0.4411  lr: 7.2916e-05  max_mem: 17484M
[01/27 14:09:29] d2.utils.events INFO:  eta: 1 day, 0:32:03  iter: 17779  total_loss: 25.72  loss_mask: 2.566  loss_mask_0: 2.648  loss_mask_1: 2.566  loss_mask_2: 2.567  loss_mask_3: 2.564  loss_mask_4: 2.567  loss_mask_5: 2.566  loss_mask_6: 2.566  loss_mask_7: 2.567  loss_mask_8: 2.567  time: 1.8997  data_time: 0.3973  lr: 7.2885e-05  max_mem: 17484M
[01/27 14:10:11] d2.utils.events INFO:  eta: 1 day, 0:31:51  iter: 17799  total_loss: 26.38  loss_mask: 2.635  loss_mask_0: 2.652  loss_mask_1: 2.635  loss_mask_2: 2.635  loss_mask_3: 2.633  loss_mask_4: 2.635  loss_mask_5: 2.634  loss_mask_6: 2.634  loss_mask_7: 2.636  loss_mask_8: 2.635  time: 1.8999  data_time: 0.4219  lr: 7.2854e-05  max_mem: 17484M
[01/27 14:10:53] d2.utils.events INFO:  eta: 1 day, 0:30:51  iter: 17819  total_loss: 26.58  loss_mask: 2.657  loss_mask_0: 2.674  loss_mask_1: 2.656  loss_mask_2: 2.657  loss_mask_3: 2.657  loss_mask_4: 2.656  loss_mask_5: 2.657  loss_mask_6: 2.656  loss_mask_7: 2.656  loss_mask_8: 2.657  time: 1.9002  data_time: 0.4139  lr: 7.2823e-05  max_mem: 17484M
[01/27 14:11:35] d2.utils.events INFO:  eta: 1 day, 0:30:09  iter: 17839  total_loss: 28.25  loss_mask: 2.822  loss_mask_0: 2.858  loss_mask_1: 2.822  loss_mask_2: 2.822  loss_mask_3: 2.821  loss_mask_4: 2.821  loss_mask_5: 2.821  loss_mask_6: 2.822  loss_mask_7: 2.822  loss_mask_8: 2.822  time: 1.9004  data_time: 0.4144  lr: 7.2792e-05  max_mem: 17484M
[01/27 14:12:17] d2.utils.events INFO:  eta: 1 day, 0:30:08  iter: 17859  total_loss: 25.32  loss_mask: 2.527  loss_mask_0: 2.573  loss_mask_1: 2.526  loss_mask_2: 2.527  loss_mask_3: 2.526  loss_mask_4: 2.527  loss_mask_5: 2.527  loss_mask_6: 2.527  loss_mask_7: 2.526  loss_mask_8: 2.527  time: 1.9006  data_time: 0.4097  lr: 7.2761e-05  max_mem: 17484M
[01/27 14:12:58] d2.utils.events INFO:  eta: 1 day, 0:28:51  iter: 17879  total_loss: 25.87  loss_mask: 2.58  loss_mask_0: 2.668  loss_mask_1: 2.579  loss_mask_2: 2.578  loss_mask_3: 2.579  loss_mask_4: 2.579  loss_mask_5: 2.58  loss_mask_6: 2.58  loss_mask_7: 2.577  loss_mask_8: 2.58  time: 1.9008  data_time: 0.4038  lr: 7.273e-05  max_mem: 17484M
[01/27 14:13:40] d2.utils.events INFO:  eta: 1 day, 0:28:09  iter: 17899  total_loss: 27.13  loss_mask: 2.704  loss_mask_0: 2.787  loss_mask_1: 2.705  loss_mask_2: 2.705  loss_mask_3: 2.705  loss_mask_4: 2.705  loss_mask_5: 2.704  loss_mask_6: 2.705  loss_mask_7: 2.705  loss_mask_8: 2.705  time: 1.9010  data_time: 0.4242  lr: 7.2699e-05  max_mem: 17484M
[01/27 14:14:22] d2.utils.events INFO:  eta: 1 day, 0:27:48  iter: 17919  total_loss: 24.67  loss_mask: 2.461  loss_mask_0: 2.526  loss_mask_1: 2.46  loss_mask_2: 2.46  loss_mask_3: 2.459  loss_mask_4: 2.461  loss_mask_5: 2.46  loss_mask_6: 2.46  loss_mask_7: 2.461  loss_mask_8: 2.46  time: 1.9012  data_time: 0.4023  lr: 7.2668e-05  max_mem: 17484M
[01/27 14:15:04] d2.utils.events INFO:  eta: 1 day, 0:27:12  iter: 17939  total_loss: 26.86  loss_mask: 2.681  loss_mask_0: 2.737  loss_mask_1: 2.68  loss_mask_2: 2.679  loss_mask_3: 2.68  loss_mask_4: 2.679  loss_mask_5: 2.68  loss_mask_6: 2.68  loss_mask_7: 2.68  loss_mask_8: 2.68  time: 1.9014  data_time: 0.4275  lr: 7.2637e-05  max_mem: 17484M
[01/27 14:15:46] d2.utils.events INFO:  eta: 1 day, 0:26:30  iter: 17959  total_loss: 25.25  loss_mask: 2.519  loss_mask_0: 2.582  loss_mask_1: 2.518  loss_mask_2: 2.518  loss_mask_3: 2.517  loss_mask_4: 2.518  loss_mask_5: 2.518  loss_mask_6: 2.519  loss_mask_7: 2.518  loss_mask_8: 2.518  time: 1.9017  data_time: 0.4434  lr: 7.2606e-05  max_mem: 17484M
[01/27 14:16:28] d2.utils.events INFO:  eta: 1 day, 0:25:42  iter: 17979  total_loss: 25.43  loss_mask: 2.538  loss_mask_0: 2.577  loss_mask_1: 2.538  loss_mask_2: 2.538  loss_mask_3: 2.538  loss_mask_4: 2.538  loss_mask_5: 2.537  loss_mask_6: 2.538  loss_mask_7: 2.538  loss_mask_8: 2.537  time: 1.9019  data_time: 0.4213  lr: 7.2574e-05  max_mem: 17484M
[01/27 14:17:11] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 14:17:11] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 14:17:11] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 14:24:25] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.881464584729625, 'error_1pix': 0.4327889492516853, 'error_3pix': 0.18181216815956305, 'mIoU': 5.024275018526871, 'fwIoU': 12.961679122894632, 'IoU-0': nan, 'IoU-1': 38.389250363241814, 'IoU-2': 2.635949933595803, 'IoU-3': 3.275949322177289, 'IoU-4': 3.763223853680225, 'IoU-5': 3.924946522205569, 'IoU-6': 3.7101127235880966, 'IoU-7': 3.001524958358369, 'IoU-8': 7.057904902806887, 'IoU-9': 17.46414724589693, 'IoU-10': 16.940245782980867, 'IoU-11': 18.525256419007068, 'IoU-12': 18.133196420458532, 'IoU-13': 17.064769651638258, 'IoU-14': 16.80687284228674, 'IoU-15': 16.941116686052275, 'IoU-16': 17.126279225982525, 'IoU-17': 14.348114912083851, 'IoU-18': 13.667791987242845, 'IoU-19': 13.565530474974622, 'IoU-20': 13.64451044975174, 'IoU-21': 14.16544009459168, 'IoU-22': 13.806140098952953, 'IoU-23': 12.877153143195258, 'IoU-24': 13.058612352985016, 'IoU-25': 12.572763531516173, 'IoU-26': 12.21239181679193, 'IoU-27': 12.21215663521181, 'IoU-28': 10.876300759360973, 'IoU-29': 11.01515610619722, 'IoU-30': 10.99083613493451, 'IoU-31': 11.707053487117202, 'IoU-32': 11.331976679008257, 'IoU-33': 11.021970092808422, 'IoU-34': 11.140531692484496, 'IoU-35': 11.819168714853328, 'IoU-36': 12.175226545949721, 'IoU-37': 11.644375249851516, 'IoU-38': 11.324105984768652, 'IoU-39': 11.076610050454008, 'IoU-40': 10.437542827787482, 'IoU-41': 9.92446334990411, 'IoU-42': 9.44597567644896, 'IoU-43': 9.506302813085437, 'IoU-44': 9.472156470323155, 'IoU-45': 9.720558581789684, 'IoU-46': 9.425464923030798, 'IoU-47': 9.398088385794056, 'IoU-48': 9.240353667540255, 'IoU-49': 8.921535263710963, 'IoU-50': 9.455438601069226, 'IoU-51': 8.86037452530574, 'IoU-52': 8.669058547740956, 'IoU-53': 8.470178472855597, 'IoU-54': 8.57018846078083, 'IoU-55': 7.659279688232333, 'IoU-56': 7.396763163380839, 'IoU-57': 7.093677456086546, 'IoU-58': 6.847835264458407, 'IoU-59': 6.307728822775671, 'IoU-60': 6.111798008996287, 'IoU-61': 5.778440865525362, 'IoU-62': 5.685305299327329, 'IoU-63': 5.515918536027685, 'IoU-64': 5.10967473617753, 'IoU-65': 4.8622046706822974, 'IoU-66': 4.6382108286056285, 'IoU-67': 4.370436043642699, 'IoU-68': 4.296951344847577, 'IoU-69': 4.407618603438934, 'IoU-70': 4.322279845853248, 'IoU-71': 3.872772418635078, 'IoU-72': 3.710008151870621, 'IoU-73': 3.893473719561401, 'IoU-74': 3.885442695467035, 'IoU-75': 3.822625329419406, 'IoU-76': 3.639161834050021, 'IoU-77': 3.333458449595032, 'IoU-78': 3.3126771949400524, 'IoU-79': 3.4500739719409834, 'IoU-80': 3.3111123486935816, 'IoU-81': 3.3269026921425553, 'IoU-82': 3.1032002002764894, 'IoU-83': 3.38092559442879, 'IoU-84': 3.269701058775882, 'IoU-85': 3.1047104489284885, 'IoU-86': 2.9934746903546023, 'IoU-87': 2.8821980709059707, 'IoU-88': 2.870723207118382, 'IoU-89': 2.9276449499149435, 'IoU-90': 2.8089135879922082, 'IoU-91': 2.714921590384111, 'IoU-92': 2.6459369630580922, 'IoU-93': 2.574175097063837, 'IoU-94': 2.541323137966443, 'IoU-95': 2.4919903825343814, 'IoU-96': 2.3813717708777045, 'IoU-97': 2.3870511014518976, 'IoU-98': 2.322052123693164, 'IoU-99': 2.322201296187017, 'IoU-100': 2.2224456472114666, 'IoU-101': 2.2193565189766846, 'IoU-102': 2.2265801952348183, 'IoU-103': 2.173419472825478, 'IoU-104': 2.110923755532908, 'IoU-105': 2.1608049972252714, 'IoU-106': 2.1229757809050227, 'IoU-107': 2.134737470768102, 'IoU-108': 2.3650863322946294, 'IoU-109': 2.435987366165799, 'IoU-110': 2.3653566592569195, 'IoU-111': 2.2618726571675443, 'IoU-112': 2.192063078086836, 'IoU-113': 2.1250936891020835, 'IoU-114': 2.133574965247079, 'IoU-115': 2.234843140117264, 'IoU-116': 2.2847166674840236, 'IoU-117': 2.1488955490632646, 'IoU-118': 2.0746680434688507, 'IoU-119': 2.216120034153782, 'IoU-120': 2.2454321376445154, 'IoU-121': 2.213095578487692, 'IoU-122': 2.0166813357994777, 'IoU-123': 2.132340421600318, 'IoU-124': 2.0604477666106296, 'IoU-125': 2.0460189025791045, 'IoU-126': 1.8480672906987503, 'IoU-127': 1.9110548864264447, 'IoU-128': 1.8519407783332407, 'IoU-129': 1.9031691417272223, 'IoU-130': 1.7407801343504712, 'IoU-131': 1.5873993307094696, 'IoU-132': 1.7162642333679776, 'IoU-133': 1.679194063619369, 'IoU-134': 1.737059514140952, 'IoU-135': 1.636435605597913, 'IoU-136': 1.6852512284038674, 'IoU-137': 1.6321156805329882, 'IoU-138': 1.584734313858821, 'IoU-139': 1.6393406065060716, 'IoU-140': 1.6027562977909218, 'IoU-141': 1.6400309709427925, 'IoU-142': 1.6036630650685266, 'IoU-143': 1.5604287011223679, 'IoU-144': 1.5785592172639327, 'IoU-145': 1.842476299779551, 'IoU-146': 1.9342335098861236, 'IoU-147': 2.052994477321623, 'IoU-148': 2.213302100525215, 'IoU-149': 2.0953177677595516, 'IoU-150': 2.140734525706465, 'IoU-151': 2.280251008237181, 'IoU-152': 2.548613865045818, 'IoU-153': 2.2503785760534427, 'IoU-154': 2.0755772715999288, 'IoU-155': 1.948256735559939, 'IoU-156': 1.95379955373344, 'IoU-157': 1.9916591202279101, 'IoU-158': 1.9047545413427451, 'IoU-159': 1.8518143354709014, 'IoU-160': 1.9496503213337082, 'IoU-161': 1.7680983095696812, 'IoU-162': 1.839357590764866, 'IoU-163': 1.9779069637119335, 'IoU-164': 1.946644184155852, 'IoU-165': 2.0646141386766463, 'IoU-166': 2.0526812328384945, 'IoU-167': 1.6330494095353854, 'IoU-168': 1.8447209073157746, 'IoU-169': 1.9489912447658926, 'IoU-170': 1.924762505975069, 'IoU-171': 1.7191860970769388, 'IoU-172': 1.669327274819971, 'IoU-173': 1.5982528213898992, 'IoU-174': 1.6685663364695156, 'IoU-175': 1.5023056447151735, 'IoU-176': 1.3577162824824476, 'IoU-177': 1.5537613634052592, 'IoU-178': 1.7365504019308249, 'IoU-179': 1.695103238063425, 'IoU-180': 1.4125717465775303, 'IoU-181': 1.0190424043316908, 'IoU-182': 1.1432499016902555, 'IoU-183': 0.9594354991134671, 'IoU-184': 0.9669308868971077, 'IoU-185': 0.7223911326039597, 'IoU-186': 0.4766759371427597, 'IoU-187': 0.45584775783316706, 'IoU-188': 0.35198968213450843, 'IoU-189': 0.15040776376155457, 'IoU-190': 0.09904584111180254, 'IoU-191': 0.0651619703318328, 'IoU-192': 0.04844319894100914, 'mACC': 9.396896246167996, 'pACC': 20.23368750019705, 'ACC-0': nan, 'ACC-1': 38.85224542837784, 'ACC-2': 5.1828176955755145, 'ACC-3': 15.788756120725314, 'ACC-4': 16.99057442503188, 'ACC-5': 18.08952359609433, 'ACC-6': 18.129577795138978, 'ACC-7': 17.267576052594155, 'ACC-8': 21.453983990086243, 'ACC-9': 39.91250910398277, 'ACC-10': 40.269758899593654, 'ACC-11': 33.09514906490145, 'ACC-12': 30.786492938843708, 'ACC-13': 28.394888702232162, 'ACC-14': 27.299005499501476, 'ACC-15': 28.14167245196273, 'ACC-16': 28.923784682733373, 'ACC-17': 26.314902540806912, 'ACC-18': 23.88166639828879, 'ACC-19': 23.920294891268913, 'ACC-20': 24.772264613492773, 'ACC-21': 25.54249008296749, 'ACC-22': 23.70577878713935, 'ACC-23': 23.124742220405377, 'ACC-24': 23.563357216356607, 'ACC-25': 22.915147996271756, 'ACC-26': 22.82495383438766, 'ACC-27': 22.370919042153275, 'ACC-28': 20.34389613949718, 'ACC-29': 19.89713971843711, 'ACC-30': 20.15147317731289, 'ACC-31': 20.90271509686896, 'ACC-32': 20.135343642316812, 'ACC-33': 19.911100860686243, 'ACC-34': 20.461058785260054, 'ACC-35': 21.426815879091393, 'ACC-36': 21.588479970747127, 'ACC-37': 21.040085840939224, 'ACC-38': 20.460000729895334, 'ACC-39': 20.07085706535472, 'ACC-40': 18.61772752762932, 'ACC-41': 18.19854629855148, 'ACC-42': 17.454042284778065, 'ACC-43': 17.61249191624003, 'ACC-44': 16.93123149927457, 'ACC-45': 17.276774718602546, 'ACC-46': 17.26336578690568, 'ACC-47': 17.213886866323286, 'ACC-48': 16.969649029576946, 'ACC-49': 16.256727539529827, 'ACC-50': 17.064665192495724, 'ACC-51': 16.169690545170944, 'ACC-52': 15.938270198404153, 'ACC-53': 15.758847637868225, 'ACC-54': 15.814433485177428, 'ACC-55': 14.203474804683664, 'ACC-56': 13.888126352777558, 'ACC-57': 13.045132379735685, 'ACC-58': 12.696102837501355, 'ACC-59': 11.763186590725969, 'ACC-60': 11.362618788929947, 'ACC-61': 10.83597489476046, 'ACC-62': 10.769402245880368, 'ACC-63': 10.537162795296215, 'ACC-64': 9.771722601962379, 'ACC-65': 9.339522930806716, 'ACC-66': 8.919664141623716, 'ACC-67': 8.503996091196665, 'ACC-68': 8.438277113714244, 'ACC-69': 8.508533859461867, 'ACC-70': 8.297651206718124, 'ACC-71': 7.619530659510107, 'ACC-72': 7.311013348514452, 'ACC-73': 7.691168755516406, 'ACC-74': 7.620687675668528, 'ACC-75': 7.442033155735422, 'ACC-76': 6.938398913138795, 'ACC-77': 6.446946394142443, 'ACC-78': 6.454240264538609, 'ACC-79': 6.720094255676543, 'ACC-80': 6.377278209524892, 'ACC-81': 6.336124416492986, 'ACC-82': 5.918916540972536, 'ACC-83': 6.370851052060866, 'ACC-84': 6.1595236391281265, 'ACC-85': 5.828950785386847, 'ACC-86': 5.6316098724821195, 'ACC-87': 5.420534037265743, 'ACC-88': 5.3729153375553205, 'ACC-89': 5.4355704635211906, 'ACC-90': 5.2037283677344455, 'ACC-91': 5.061165760237622, 'ACC-92': 4.938371670890687, 'ACC-93': 4.75131450603875, 'ACC-94': 4.65111081106724, 'ACC-95': 4.501808486191602, 'ACC-96': 4.31146791045733, 'ACC-97': 4.269102896181347, 'ACC-98': 4.154228797340554, 'ACC-99': 4.184391938642726, 'ACC-100': 4.001874877853168, 'ACC-101': 4.000159052049783, 'ACC-102': 4.063367840408666, 'ACC-103': 3.9558983792489073, 'ACC-104': 3.852561463465741, 'ACC-105': 3.9448854069325106, 'ACC-106': 3.8716551065323346, 'ACC-107': 3.8845573933135777, 'ACC-108': 4.2305675919398125, 'ACC-109': 4.3475746403527795, 'ACC-110': 4.288760975427628, 'ACC-111': 4.124127474512525, 'ACC-112': 4.055149715823212, 'ACC-113': 3.9328572097353924, 'ACC-114': 3.958422695068544, 'ACC-115': 4.131523160885841, 'ACC-116': 4.247937795063914, 'ACC-117': 4.00035521209457, 'ACC-118': 3.8838693586967614, 'ACC-119': 4.0709626310884195, 'ACC-120': 4.071481532239077, 'ACC-121': 4.060497077842886, 'ACC-122': 3.738949116401068, 'ACC-123': 3.9856888816959395, 'ACC-124': 3.932020706397791, 'ACC-125': 3.8555499840650533, 'ACC-126': 3.5023087641963957, 'ACC-127': 3.6289587791681073, 'ACC-128': 3.5748654394303636, 'ACC-129': 3.6734127823318743, 'ACC-130': 3.347022905095668, 'ACC-131': 3.032339057348478, 'ACC-132': 3.202876550284337, 'ACC-133': 3.0956609306851197, 'ACC-134': 3.183248599741491, 'ACC-135': 3.016789236645573, 'ACC-136': 3.095954272269847, 'ACC-137': 3.0106463280510023, 'ACC-138': 2.930048163871385, 'ACC-139': 3.013396974633389, 'ACC-140': 2.924363121948957, 'ACC-141': 2.9554556723726875, 'ACC-142': 2.8739155571158843, 'ACC-143': 2.792474803387345, 'ACC-144': 2.7934140734784054, 'ACC-145': 3.173517023250156, 'ACC-146': 3.32625399355183, 'ACC-147': 3.511467960187826, 'ACC-148': 3.7757837303473316, 'ACC-149': 3.6374128093884948, 'ACC-150': 3.691261526723445, 'ACC-151': 3.9018245106199756, 'ACC-152': 4.28651960655185, 'ACC-153': 3.91249926994928, 'ACC-154': 3.6457617784478735, 'ACC-155': 3.472260741266654, 'ACC-156': 3.5149184941752, 'ACC-157': 3.610185940092473, 'ACC-158': 3.4772151791536463, 'ACC-159': 3.3695726146726557, 'ACC-160': 3.5400344713984957, 'ACC-161': 3.1263296098406923, 'ACC-162': 3.275476548587649, 'ACC-163': 3.507248548073704, 'ACC-164': 3.4854128313806076, 'ACC-165': 3.7173994882083, 'ACC-166': 3.7558078420770706, 'ACC-167': 3.00705498019045, 'ACC-168': 3.3877528767672573, 'ACC-169': 3.594148978177128, 'ACC-170': 3.566281397759382, 'ACC-171': 3.196100371699399, 'ACC-172': 3.0898709882992836, 'ACC-173': 2.9530059869420295, 'ACC-174': 3.0032208671909824, 'ACC-175': 2.617175433436733, 'ACC-176': 2.290730347276173, 'ACC-177': 2.5399592926826564, 'ACC-178': 2.759803343470334, 'ACC-179': 2.638339700198825, 'ACC-180': 2.108006186309612, 'ACC-181': 1.50972127675219, 'ACC-182': 1.6149669908628428, 'ACC-183': 1.2577161950427578, 'ACC-184': 1.1895710649470856, 'ACC-185': 0.8372505994399833, 'ACC-186': 0.5286800031224054, 'ACC-187': 0.48216801328382564, 'ACC-188': 0.36391553926928993, 'ACC-189': 0.1535114786472476, 'ACC-190': 0.10029853254319794, 'ACC-191': 0.06569493991922926, 'ACC-192': 0.04878200964862772})])
[01/27 14:24:25] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 14:24:25] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 14:24:25] d2.evaluation.testing INFO: copypaste: 2.8815,0.4328,0.1818,5.0243,12.9617,9.3969,20.2337
[01/27 14:24:25] d2.utils.events INFO:  eta: 1 day, 0:25:59  iter: 17999  total_loss: 26.79  loss_mask: 2.674  loss_mask_0: 2.723  loss_mask_1: 2.674  loss_mask_2: 2.674  loss_mask_3: 2.674  loss_mask_4: 2.674  loss_mask_5: 2.673  loss_mask_6: 2.674  loss_mask_7: 2.674  loss_mask_8: 2.673  time: 1.9021  data_time: 0.4433  lr: 7.2543e-05  max_mem: 17484M
[01/27 14:25:07] d2.utils.events INFO:  eta: 1 day, 0:25:33  iter: 18019  total_loss: 25.33  loss_mask: 2.526  loss_mask_0: 2.602  loss_mask_1: 2.525  loss_mask_2: 2.525  loss_mask_3: 2.525  loss_mask_4: 2.527  loss_mask_5: 2.523  loss_mask_6: 2.524  loss_mask_7: 2.528  loss_mask_8: 2.524  time: 1.9023  data_time: 0.4164  lr: 7.2512e-05  max_mem: 17484M
[01/27 14:25:49] d2.utils.events INFO:  eta: 1 day, 0:24:58  iter: 18039  total_loss: 26.06  loss_mask: 2.599  loss_mask_0: 2.668  loss_mask_1: 2.599  loss_mask_2: 2.599  loss_mask_3: 2.6  loss_mask_4: 2.6  loss_mask_5: 2.599  loss_mask_6: 2.6  loss_mask_7: 2.598  loss_mask_8: 2.599  time: 1.9026  data_time: 0.4095  lr: 7.2481e-05  max_mem: 17484M
[01/27 14:26:32] d2.utils.events INFO:  eta: 1 day, 0:24:09  iter: 18059  total_loss: 26.12  loss_mask: 2.607  loss_mask_0: 2.635  loss_mask_1: 2.607  loss_mask_2: 2.608  loss_mask_3: 2.607  loss_mask_4: 2.608  loss_mask_5: 2.607  loss_mask_6: 2.607  loss_mask_7: 2.609  loss_mask_8: 2.608  time: 1.9028  data_time: 0.4211  lr: 7.245e-05  max_mem: 17484M
[01/27 14:27:13] d2.utils.events INFO:  eta: 1 day, 0:23:17  iter: 18079  total_loss: 24.09  loss_mask: 2.408  loss_mask_0: 2.451  loss_mask_1: 2.407  loss_mask_2: 2.406  loss_mask_3: 2.406  loss_mask_4: 2.406  loss_mask_5: 2.406  loss_mask_6: 2.406  loss_mask_7: 2.406  loss_mask_8: 2.407  time: 1.9030  data_time: 0.4259  lr: 7.2419e-05  max_mem: 17484M
[01/27 14:27:55] d2.utils.events INFO:  eta: 1 day, 0:22:07  iter: 18099  total_loss: 26  loss_mask: 2.596  loss_mask_0: 2.666  loss_mask_1: 2.595  loss_mask_2: 2.595  loss_mask_3: 2.596  loss_mask_4: 2.595  loss_mask_5: 2.595  loss_mask_6: 2.595  loss_mask_7: 2.595  loss_mask_8: 2.595  time: 1.9032  data_time: 0.4148  lr: 7.2388e-05  max_mem: 17484M
[01/27 14:28:38] d2.utils.events INFO:  eta: 1 day, 0:21:47  iter: 18119  total_loss: 26.94  loss_mask: 2.685  loss_mask_0: 2.727  loss_mask_1: 2.685  loss_mask_2: 2.686  loss_mask_3: 2.685  loss_mask_4: 2.687  loss_mask_5: 2.685  loss_mask_6: 2.685  loss_mask_7: 2.686  loss_mask_8: 2.685  time: 1.9035  data_time: 0.4457  lr: 7.2357e-05  max_mem: 17484M
[01/27 14:29:21] d2.utils.events INFO:  eta: 1 day, 0:21:08  iter: 18139  total_loss: 27.13  loss_mask: 2.706  loss_mask_0: 2.756  loss_mask_1: 2.706  loss_mask_2: 2.706  loss_mask_3: 2.706  loss_mask_4: 2.706  loss_mask_5: 2.706  loss_mask_6: 2.707  loss_mask_7: 2.705  loss_mask_8: 2.706  time: 1.9037  data_time: 0.4334  lr: 7.2326e-05  max_mem: 17484M
[01/27 14:30:03] d2.utils.events INFO:  eta: 1 day, 0:20:59  iter: 18159  total_loss: 26.64  loss_mask: 2.662  loss_mask_0: 2.707  loss_mask_1: 2.661  loss_mask_2: 2.661  loss_mask_3: 2.661  loss_mask_4: 2.662  loss_mask_5: 2.66  loss_mask_6: 2.661  loss_mask_7: 2.662  loss_mask_8: 2.661  time: 1.9039  data_time: 0.4191  lr: 7.2295e-05  max_mem: 17484M
[01/27 14:30:45] d2.utils.events INFO:  eta: 1 day, 0:20:21  iter: 18179  total_loss: 25.46  loss_mask: 2.541  loss_mask_0: 2.592  loss_mask_1: 2.539  loss_mask_2: 2.54  loss_mask_3: 2.541  loss_mask_4: 2.54  loss_mask_5: 2.54  loss_mask_6: 2.54  loss_mask_7: 2.541  loss_mask_8: 2.541  time: 1.9042  data_time: 0.4123  lr: 7.2263e-05  max_mem: 17484M
[01/27 14:31:27] d2.utils.events INFO:  eta: 1 day, 0:20:01  iter: 18199  total_loss: 25.13  loss_mask: 2.511  loss_mask_0: 2.531  loss_mask_1: 2.511  loss_mask_2: 2.511  loss_mask_3: 2.511  loss_mask_4: 2.511  loss_mask_5: 2.511  loss_mask_6: 2.51  loss_mask_7: 2.51  loss_mask_8: 2.511  time: 1.9044  data_time: 0.4259  lr: 7.2232e-05  max_mem: 17484M
[01/27 14:32:10] d2.utils.events INFO:  eta: 1 day, 0:20:04  iter: 18219  total_loss: 25.92  loss_mask: 2.588  loss_mask_0: 2.654  loss_mask_1: 2.588  loss_mask_2: 2.588  loss_mask_3: 2.588  loss_mask_4: 2.588  loss_mask_5: 2.589  loss_mask_6: 2.588  loss_mask_7: 2.587  loss_mask_8: 2.588  time: 1.9046  data_time: 0.4373  lr: 7.2201e-05  max_mem: 17484M
[01/27 14:32:52] d2.utils.events INFO:  eta: 1 day, 0:19:35  iter: 18239  total_loss: 26.42  loss_mask: 2.637  loss_mask_0: 2.688  loss_mask_1: 2.636  loss_mask_2: 2.637  loss_mask_3: 2.637  loss_mask_4: 2.636  loss_mask_5: 2.636  loss_mask_6: 2.636  loss_mask_7: 2.637  loss_mask_8: 2.637  time: 1.9048  data_time: 0.4067  lr: 7.217e-05  max_mem: 17484M
[01/27 14:33:34] d2.utils.events INFO:  eta: 1 day, 0:19:12  iter: 18259  total_loss: 26.7  loss_mask: 2.668  loss_mask_0: 2.686  loss_mask_1: 2.668  loss_mask_2: 2.668  loss_mask_3: 2.668  loss_mask_4: 2.668  loss_mask_5: 2.668  loss_mask_6: 2.668  loss_mask_7: 2.668  loss_mask_8: 2.668  time: 1.9051  data_time: 0.4220  lr: 7.2139e-05  max_mem: 17484M
[01/27 14:34:16] d2.utils.events INFO:  eta: 1 day, 0:18:12  iter: 18279  total_loss: 25.01  loss_mask: 2.494  loss_mask_0: 2.579  loss_mask_1: 2.493  loss_mask_2: 2.493  loss_mask_3: 2.495  loss_mask_4: 2.493  loss_mask_5: 2.495  loss_mask_6: 2.493  loss_mask_7: 2.493  loss_mask_8: 2.494  time: 1.9053  data_time: 0.3969  lr: 7.2108e-05  max_mem: 17484M
[01/27 14:34:58] d2.utils.events INFO:  eta: 1 day, 0:17:34  iter: 18299  total_loss: 25.09  loss_mask: 2.503  loss_mask_0: 2.581  loss_mask_1: 2.503  loss_mask_2: 2.503  loss_mask_3: 2.503  loss_mask_4: 2.503  loss_mask_5: 2.503  loss_mask_6: 2.504  loss_mask_7: 2.503  loss_mask_8: 2.503  time: 1.9055  data_time: 0.4391  lr: 7.2077e-05  max_mem: 17484M
[01/27 14:35:41] d2.utils.events INFO:  eta: 1 day, 0:17:06  iter: 18319  total_loss: 26.85  loss_mask: 2.677  loss_mask_0: 2.757  loss_mask_1: 2.677  loss_mask_2: 2.678  loss_mask_3: 2.677  loss_mask_4: 2.678  loss_mask_5: 2.678  loss_mask_6: 2.677  loss_mask_7: 2.678  loss_mask_8: 2.677  time: 1.9058  data_time: 0.4234  lr: 7.2046e-05  max_mem: 17484M
[01/27 14:36:23] d2.utils.events INFO:  eta: 1 day, 0:16:06  iter: 18339  total_loss: 24.42  loss_mask: 2.441  loss_mask_0: 2.49  loss_mask_1: 2.441  loss_mask_2: 2.441  loss_mask_3: 2.44  loss_mask_4: 2.441  loss_mask_5: 2.44  loss_mask_6: 2.441  loss_mask_7: 2.441  loss_mask_8: 2.44  time: 1.9060  data_time: 0.4339  lr: 7.2015e-05  max_mem: 17484M
[01/27 14:37:06] d2.utils.events INFO:  eta: 1 day, 0:16:25  iter: 18359  total_loss: 26.49  loss_mask: 2.646  loss_mask_0: 2.669  loss_mask_1: 2.647  loss_mask_2: 2.647  loss_mask_3: 2.647  loss_mask_4: 2.647  loss_mask_5: 2.647  loss_mask_6: 2.648  loss_mask_7: 2.647  loss_mask_8: 2.647  time: 1.9062  data_time: 0.4213  lr: 7.1983e-05  max_mem: 17484M
[01/27 14:37:49] d2.utils.events INFO:  eta: 1 day, 0:15:52  iter: 18379  total_loss: 25.43  loss_mask: 2.538  loss_mask_0: 2.568  loss_mask_1: 2.538  loss_mask_2: 2.538  loss_mask_3: 2.538  loss_mask_4: 2.538  loss_mask_5: 2.537  loss_mask_6: 2.538  loss_mask_7: 2.539  loss_mask_8: 2.538  time: 1.9065  data_time: 0.4421  lr: 7.1952e-05  max_mem: 17484M
[01/27 14:38:31] d2.utils.events INFO:  eta: 1 day, 0:15:13  iter: 18399  total_loss: 26.62  loss_mask: 2.656  loss_mask_0: 2.726  loss_mask_1: 2.654  loss_mask_2: 2.654  loss_mask_3: 2.655  loss_mask_4: 2.654  loss_mask_5: 2.656  loss_mask_6: 2.654  loss_mask_7: 2.654  loss_mask_8: 2.656  time: 1.9067  data_time: 0.4277  lr: 7.1921e-05  max_mem: 17484M
[01/27 14:39:14] d2.utils.events INFO:  eta: 1 day, 0:15:16  iter: 18419  total_loss: 27.07  loss_mask: 2.7  loss_mask_0: 2.778  loss_mask_1: 2.699  loss_mask_2: 2.699  loss_mask_3: 2.699  loss_mask_4: 2.699  loss_mask_5: 2.699  loss_mask_6: 2.699  loss_mask_7: 2.7  loss_mask_8: 2.699  time: 1.9070  data_time: 0.4318  lr: 7.189e-05  max_mem: 17484M
[01/27 14:39:57] d2.utils.events INFO:  eta: 1 day, 0:14:45  iter: 18439  total_loss: 24.55  loss_mask: 2.451  loss_mask_0: 2.493  loss_mask_1: 2.45  loss_mask_2: 2.451  loss_mask_3: 2.451  loss_mask_4: 2.451  loss_mask_5: 2.452  loss_mask_6: 2.451  loss_mask_7: 2.45  loss_mask_8: 2.451  time: 1.9072  data_time: 0.4131  lr: 7.1859e-05  max_mem: 17484M
[01/27 14:40:39] d2.utils.events INFO:  eta: 1 day, 0:14:12  iter: 18459  total_loss: 26.52  loss_mask: 2.647  loss_mask_0: 2.704  loss_mask_1: 2.646  loss_mask_2: 2.645  loss_mask_3: 2.646  loss_mask_4: 2.646  loss_mask_5: 2.645  loss_mask_6: 2.646  loss_mask_7: 2.646  loss_mask_8: 2.646  time: 1.9074  data_time: 0.4132  lr: 7.1828e-05  max_mem: 17484M
[01/27 14:41:22] d2.utils.events INFO:  eta: 1 day, 0:14:31  iter: 18479  total_loss: 26  loss_mask: 2.598  loss_mask_0: 2.624  loss_mask_1: 2.597  loss_mask_2: 2.598  loss_mask_3: 2.599  loss_mask_4: 2.597  loss_mask_5: 2.598  loss_mask_6: 2.598  loss_mask_7: 2.596  loss_mask_8: 2.598  time: 1.9077  data_time: 0.4265  lr: 7.1797e-05  max_mem: 17484M
[01/27 14:42:04] d2.utils.events INFO:  eta: 1 day, 0:14:20  iter: 18499  total_loss: 26.83  loss_mask: 2.678  loss_mask_0: 2.751  loss_mask_1: 2.677  loss_mask_2: 2.678  loss_mask_3: 2.677  loss_mask_4: 2.678  loss_mask_5: 2.678  loss_mask_6: 2.678  loss_mask_7: 2.679  loss_mask_8: 2.678  time: 1.9079  data_time: 0.4346  lr: 7.1766e-05  max_mem: 17484M
[01/27 14:42:47] d2.utils.events INFO:  eta: 1 day, 0:14:06  iter: 18519  total_loss: 26.57  loss_mask: 2.648  loss_mask_0: 2.733  loss_mask_1: 2.648  loss_mask_2: 2.649  loss_mask_3: 2.649  loss_mask_4: 2.648  loss_mask_5: 2.649  loss_mask_6: 2.648  loss_mask_7: 2.648  loss_mask_8: 2.649  time: 1.9082  data_time: 0.4322  lr: 7.1735e-05  max_mem: 17484M
[01/27 14:43:30] d2.utils.events INFO:  eta: 1 day, 0:13:34  iter: 18539  total_loss: 26.79  loss_mask: 2.676  loss_mask_0: 2.719  loss_mask_1: 2.676  loss_mask_2: 2.676  loss_mask_3: 2.676  loss_mask_4: 2.676  loss_mask_5: 2.677  loss_mask_6: 2.677  loss_mask_7: 2.677  loss_mask_8: 2.676  time: 1.9084  data_time: 0.4312  lr: 7.1703e-05  max_mem: 17484M
[01/27 14:44:13] d2.utils.events INFO:  eta: 1 day, 0:13:23  iter: 18559  total_loss: 25.77  loss_mask: 2.571  loss_mask_0: 2.648  loss_mask_1: 2.57  loss_mask_2: 2.571  loss_mask_3: 2.571  loss_mask_4: 2.57  loss_mask_5: 2.571  loss_mask_6: 2.57  loss_mask_7: 2.571  loss_mask_8: 2.571  time: 1.9087  data_time: 0.4164  lr: 7.1672e-05  max_mem: 17484M
[01/27 14:44:55] d2.utils.events INFO:  eta: 1 day, 0:12:45  iter: 18579  total_loss: 24.25  loss_mask: 2.422  loss_mask_0: 2.468  loss_mask_1: 2.421  loss_mask_2: 2.422  loss_mask_3: 2.421  loss_mask_4: 2.422  loss_mask_5: 2.423  loss_mask_6: 2.421  loss_mask_7: 2.421  loss_mask_8: 2.422  time: 1.9089  data_time: 0.3928  lr: 7.1641e-05  max_mem: 17484M
[01/27 14:45:37] d2.utils.events INFO:  eta: 1 day, 0:12:17  iter: 18599  total_loss: 24.73  loss_mask: 2.473  loss_mask_0: 2.514  loss_mask_1: 2.472  loss_mask_2: 2.472  loss_mask_3: 2.472  loss_mask_4: 2.471  loss_mask_5: 2.472  loss_mask_6: 2.471  loss_mask_7: 2.471  loss_mask_8: 2.472  time: 1.9091  data_time: 0.4036  lr: 7.161e-05  max_mem: 17484M
[01/27 14:46:20] d2.utils.events INFO:  eta: 1 day, 0:11:25  iter: 18619  total_loss: 24.63  loss_mask: 2.462  loss_mask_0: 2.489  loss_mask_1: 2.462  loss_mask_2: 2.462  loss_mask_3: 2.462  loss_mask_4: 2.463  loss_mask_5: 2.462  loss_mask_6: 2.462  loss_mask_7: 2.461  loss_mask_8: 2.462  time: 1.9093  data_time: 0.3991  lr: 7.1579e-05  max_mem: 17484M
[01/27 14:47:04] d2.utils.events INFO:  eta: 1 day, 0:12:06  iter: 18639  total_loss: 27.09  loss_mask: 2.7  loss_mask_0: 2.754  loss_mask_1: 2.699  loss_mask_2: 2.7  loss_mask_3: 2.701  loss_mask_4: 2.7  loss_mask_5: 2.701  loss_mask_6: 2.699  loss_mask_7: 2.699  loss_mask_8: 2.7  time: 1.9097  data_time: 0.4370  lr: 7.1548e-05  max_mem: 17484M
[01/27 14:47:47] d2.utils.events INFO:  eta: 1 day, 0:12:01  iter: 18659  total_loss: 23.84  loss_mask: 2.376  loss_mask_0: 2.453  loss_mask_1: 2.376  loss_mask_2: 2.376  loss_mask_3: 2.376  loss_mask_4: 2.376  loss_mask_5: 2.377  loss_mask_6: 2.377  loss_mask_7: 2.376  loss_mask_8: 2.376  time: 1.9099  data_time: 0.4136  lr: 7.1517e-05  max_mem: 17484M
[01/27 14:48:31] d2.utils.events INFO:  eta: 1 day, 0:12:04  iter: 18679  total_loss: 25.39  loss_mask: 2.529  loss_mask_0: 2.612  loss_mask_1: 2.529  loss_mask_2: 2.529  loss_mask_3: 2.53  loss_mask_4: 2.529  loss_mask_5: 2.528  loss_mask_6: 2.528  loss_mask_7: 2.53  loss_mask_8: 2.529  time: 1.9102  data_time: 0.4125  lr: 7.1485e-05  max_mem: 17484M
[01/27 14:49:15] d2.utils.events INFO:  eta: 1 day, 0:12:48  iter: 18699  total_loss: 27.51  loss_mask: 2.747  loss_mask_0: 2.789  loss_mask_1: 2.746  loss_mask_2: 2.746  loss_mask_3: 2.747  loss_mask_4: 2.746  loss_mask_5: 2.746  loss_mask_6: 2.746  loss_mask_7: 2.748  loss_mask_8: 2.747  time: 1.9105  data_time: 0.4427  lr: 7.1454e-05  max_mem: 17484M
[01/27 14:49:59] d2.utils.events INFO:  eta: 1 day, 0:12:59  iter: 18719  total_loss: 24.99  loss_mask: 2.496  loss_mask_0: 2.539  loss_mask_1: 2.494  loss_mask_2: 2.494  loss_mask_3: 2.496  loss_mask_4: 2.494  loss_mask_5: 2.495  loss_mask_6: 2.495  loss_mask_7: 2.496  loss_mask_8: 2.495  time: 1.9109  data_time: 0.4580  lr: 7.1423e-05  max_mem: 17484M
[01/27 14:50:43] d2.utils.events INFO:  eta: 1 day, 0:15:25  iter: 18739  total_loss: 25.19  loss_mask: 2.512  loss_mask_0: 2.562  loss_mask_1: 2.511  loss_mask_2: 2.51  loss_mask_3: 2.51  loss_mask_4: 2.511  loss_mask_5: 2.51  loss_mask_6: 2.511  loss_mask_7: 2.512  loss_mask_8: 2.512  time: 1.9112  data_time: 0.4227  lr: 7.1392e-05  max_mem: 17484M
[01/27 14:51:27] d2.utils.events INFO:  eta: 1 day, 0:15:32  iter: 18759  total_loss: 25.84  loss_mask: 2.576  loss_mask_0: 2.648  loss_mask_1: 2.576  loss_mask_2: 2.575  loss_mask_3: 2.577  loss_mask_4: 2.576  loss_mask_5: 2.575  loss_mask_6: 2.575  loss_mask_7: 2.577  loss_mask_8: 2.576  time: 1.9114  data_time: 0.4369  lr: 7.1361e-05  max_mem: 17484M
[01/27 14:52:11] d2.utils.events INFO:  eta: 1 day, 0:15:46  iter: 18779  total_loss: 25.2  loss_mask: 2.516  loss_mask_0: 2.575  loss_mask_1: 2.516  loss_mask_2: 2.516  loss_mask_3: 2.516  loss_mask_4: 2.516  loss_mask_5: 2.515  loss_mask_6: 2.516  loss_mask_7: 2.516  loss_mask_8: 2.516  time: 1.9118  data_time: 0.4398  lr: 7.133e-05  max_mem: 17484M
[01/27 14:52:54] d2.utils.events INFO:  eta: 1 day, 0:15:20  iter: 18799  total_loss: 25.08  loss_mask: 2.502  loss_mask_0: 2.561  loss_mask_1: 2.502  loss_mask_2: 2.503  loss_mask_3: 2.502  loss_mask_4: 2.502  loss_mask_5: 2.503  loss_mask_6: 2.503  loss_mask_7: 2.502  loss_mask_8: 2.503  time: 1.9120  data_time: 0.4048  lr: 7.1299e-05  max_mem: 17484M
[01/27 14:53:38] d2.utils.events INFO:  eta: 1 day, 0:16:34  iter: 18819  total_loss: 25.26  loss_mask: 2.522  loss_mask_0: 2.569  loss_mask_1: 2.521  loss_mask_2: 2.521  loss_mask_3: 2.522  loss_mask_4: 2.521  loss_mask_5: 2.522  loss_mask_6: 2.52  loss_mask_7: 2.522  loss_mask_8: 2.522  time: 1.9123  data_time: 0.4214  lr: 7.1267e-05  max_mem: 17484M
[01/27 14:54:22] d2.utils.events INFO:  eta: 1 day, 0:16:52  iter: 18839  total_loss: 26.6  loss_mask: 2.655  loss_mask_0: 2.699  loss_mask_1: 2.656  loss_mask_2: 2.657  loss_mask_3: 2.655  loss_mask_4: 2.656  loss_mask_5: 2.657  loss_mask_6: 2.656  loss_mask_7: 2.656  loss_mask_8: 2.657  time: 1.9126  data_time: 0.4289  lr: 7.1236e-05  max_mem: 17484M
[01/27 14:55:06] d2.utils.events INFO:  eta: 1 day, 0:17:08  iter: 18859  total_loss: 25.51  loss_mask: 2.548  loss_mask_0: 2.612  loss_mask_1: 2.547  loss_mask_2: 2.547  loss_mask_3: 2.547  loss_mask_4: 2.547  loss_mask_5: 2.548  loss_mask_6: 2.547  loss_mask_7: 2.547  loss_mask_8: 2.547  time: 1.9129  data_time: 0.4289  lr: 7.1205e-05  max_mem: 17484M
[01/27 14:55:50] d2.utils.events INFO:  eta: 1 day, 0:17:21  iter: 18879  total_loss: 25.21  loss_mask: 2.519  loss_mask_0: 2.54  loss_mask_1: 2.518  loss_mask_2: 2.519  loss_mask_3: 2.518  loss_mask_4: 2.519  loss_mask_5: 2.52  loss_mask_6: 2.518  loss_mask_7: 2.518  loss_mask_8: 2.519  time: 1.9132  data_time: 0.4544  lr: 7.1174e-05  max_mem: 17484M
[01/27 14:56:34] d2.utils.events INFO:  eta: 1 day, 0:17:04  iter: 18899  total_loss: 25.4  loss_mask: 2.534  loss_mask_0: 2.615  loss_mask_1: 2.533  loss_mask_2: 2.533  loss_mask_3: 2.534  loss_mask_4: 2.533  loss_mask_5: 2.533  loss_mask_6: 2.533  loss_mask_7: 2.533  loss_mask_8: 2.534  time: 1.9135  data_time: 0.4302  lr: 7.1143e-05  max_mem: 17484M
[01/27 14:57:17] d2.utils.events INFO:  eta: 1 day, 0:17:28  iter: 18919  total_loss: 26.29  loss_mask: 2.62  loss_mask_0: 2.72  loss_mask_1: 2.618  loss_mask_2: 2.619  loss_mask_3: 2.618  loss_mask_4: 2.618  loss_mask_5: 2.619  loss_mask_6: 2.618  loss_mask_7: 2.619  loss_mask_8: 2.619  time: 1.9138  data_time: 0.4229  lr: 7.1112e-05  max_mem: 17484M
[01/27 14:58:02] d2.utils.events INFO:  eta: 1 day, 0:18:04  iter: 18939  total_loss: 25.02  loss_mask: 2.499  loss_mask_0: 2.537  loss_mask_1: 2.499  loss_mask_2: 2.497  loss_mask_3: 2.498  loss_mask_4: 2.498  loss_mask_5: 2.498  loss_mask_6: 2.498  loss_mask_7: 2.499  loss_mask_8: 2.498  time: 1.9141  data_time: 0.4448  lr: 7.108e-05  max_mem: 17484M
[01/27 14:58:46] d2.utils.events INFO:  eta: 1 day, 0:18:43  iter: 18959  total_loss: 28.33  loss_mask: 2.829  loss_mask_0: 2.857  loss_mask_1: 2.83  loss_mask_2: 2.83  loss_mask_3: 2.831  loss_mask_4: 2.83  loss_mask_5: 2.829  loss_mask_6: 2.829  loss_mask_7: 2.83  loss_mask_8: 2.829  time: 1.9144  data_time: 0.4465  lr: 7.1049e-05  max_mem: 17484M
[01/27 14:59:30] d2.utils.events INFO:  eta: 1 day, 0:19:22  iter: 18979  total_loss: 30.31  loss_mask: 3.028  loss_mask_0: 3.051  loss_mask_1: 3.029  loss_mask_2: 3.03  loss_mask_3: 3.028  loss_mask_4: 3.03  loss_mask_5: 3.029  loss_mask_6: 3.029  loss_mask_7: 3.03  loss_mask_8: 3.029  time: 1.9147  data_time: 0.4252  lr: 7.1018e-05  max_mem: 17484M
[01/27 15:00:13] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 15:00:14] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 15:00:14] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 15:07:58] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.0196459068959913, 'error_1pix': 0.39897045030527856, 'error_3pix': 0.17872240031065234, 'mIoU': 5.8122506584378435, 'fwIoU': 11.7160126772939, 'IoU-0': nan, 'IoU-1': 3.8929523071697316, 'IoU-2': 1.2003653104615688, 'IoU-3': 1.1493696380502354, 'IoU-4': 1.2393234059852634, 'IoU-5': 1.3218138461944746, 'IoU-6': 1.3409977555364263, 'IoU-7': 0.9449420169197842, 'IoU-8': 2.2726762077458242, 'IoU-9': 5.03017526996489, 'IoU-10': 8.278225142311992, 'IoU-11': 16.106597112911167, 'IoU-12': 18.241851221843074, 'IoU-13': 16.35714095500955, 'IoU-14': 13.771351551644795, 'IoU-15': 13.06417057741916, 'IoU-16': 11.396881352167632, 'IoU-17': 10.020349325642565, 'IoU-18': 9.971019191670575, 'IoU-19': 10.933285744531815, 'IoU-20': 12.784487867170501, 'IoU-21': 14.369996619086672, 'IoU-22': 14.62004537151143, 'IoU-23': 15.008191479900615, 'IoU-24': 16.009543018930692, 'IoU-25': 16.569937405868917, 'IoU-26': 16.671436332253545, 'IoU-27': 17.62182296523163, 'IoU-28': 18.35496154959619, 'IoU-29': 19.508458358855115, 'IoU-30': 18.636265791865732, 'IoU-31': 18.834791836626188, 'IoU-32': 17.816079180000905, 'IoU-33': 16.919476956481148, 'IoU-34': 16.574985196570726, 'IoU-35': 16.761547785751873, 'IoU-36': 16.677234823501596, 'IoU-37': 15.857169788587832, 'IoU-38': 16.149624411226277, 'IoU-39': 16.564397305896637, 'IoU-40': 17.568403417258267, 'IoU-41': 16.95633803467502, 'IoU-42': 17.23544624862666, 'IoU-43': 16.66968743057136, 'IoU-44': 16.520960175055, 'IoU-45': 15.171467340921147, 'IoU-46': 14.407635806859542, 'IoU-47': 14.119441764386185, 'IoU-48': 13.94244999218329, 'IoU-49': 13.885326194178713, 'IoU-50': 13.307723805574076, 'IoU-51': 12.507460735712769, 'IoU-52': 12.065527632004114, 'IoU-53': 11.731798075019432, 'IoU-54': 11.48002814568006, 'IoU-55': 11.197958470268393, 'IoU-56': 10.184863416852014, 'IoU-57': 9.736256926291068, 'IoU-58': 9.263312186337739, 'IoU-59': 8.359259330979617, 'IoU-60': 8.16123719991739, 'IoU-61': 7.852613090674707, 'IoU-62': 7.280207254012853, 'IoU-63': 6.911374196029659, 'IoU-64': 6.697157980290541, 'IoU-65': 6.174248088092049, 'IoU-66': 5.966863404381333, 'IoU-67': 5.89799382237329, 'IoU-68': 5.650559491087799, 'IoU-69': 5.617523649787655, 'IoU-70': 5.784487739062836, 'IoU-71': 5.550358548858169, 'IoU-72': 5.5891675357362365, 'IoU-73': 5.66301377809939, 'IoU-74': 5.836761217252353, 'IoU-75': 5.648981558287288, 'IoU-76': 5.9024045574724395, 'IoU-77': 5.885565565034649, 'IoU-78': 5.960117691699243, 'IoU-79': 6.067569444501134, 'IoU-80': 6.183741087340404, 'IoU-81': 6.331298143855636, 'IoU-82': 6.514279045464311, 'IoU-83': 6.526845135348173, 'IoU-84': 6.298397633722328, 'IoU-85': 6.517106111031182, 'IoU-86': 6.727907887495127, 'IoU-87': 6.69518808831991, 'IoU-88': 6.620417247725572, 'IoU-89': 6.603799346385802, 'IoU-90': 6.610781486830063, 'IoU-91': 6.485951821464219, 'IoU-92': 6.3964260881984565, 'IoU-93': 6.451124990065525, 'IoU-94': 6.436414959904231, 'IoU-95': 6.281051681968567, 'IoU-96': 6.092674673282332, 'IoU-97': 6.1912234732666525, 'IoU-98': 6.226274753352294, 'IoU-99': 5.683930480672701, 'IoU-100': 5.723361383734901, 'IoU-101': 5.536673486199488, 'IoU-102': 5.231014183978628, 'IoU-103': 5.141886746679425, 'IoU-104': 4.794540683816401, 'IoU-105': 4.5831943185421595, 'IoU-106': 4.446140979791408, 'IoU-107': 4.4248507024677135, 'IoU-108': 4.405314327367717, 'IoU-109': 4.509081756065473, 'IoU-110': 4.249475613509722, 'IoU-111': 3.8551911680714266, 'IoU-112': 3.6703920742691145, 'IoU-113': 3.4119415864447986, 'IoU-114': 3.262743274080319, 'IoU-115': 3.0618566334242, 'IoU-116': 2.713685919186342, 'IoU-117': 2.6322752733624712, 'IoU-118': 2.5494096819250047, 'IoU-119': 2.5372006115540984, 'IoU-120': 2.4056435576053556, 'IoU-121': 2.291223110203448, 'IoU-122': 2.003948716954274, 'IoU-123': 1.8517798016135485, 'IoU-124': 1.6850567477838334, 'IoU-125': 1.5581321992233812, 'IoU-126': 1.320160223896819, 'IoU-127': 1.4148758684230185, 'IoU-128': 1.3349505753106437, 'IoU-129': 1.233029419550033, 'IoU-130': 1.1763499190846305, 'IoU-131': 1.0237508050978965, 'IoU-132': 0.9755815671127355, 'IoU-133': 1.0649888586380167, 'IoU-134': 1.0652232629214786, 'IoU-135': 0.8968509061236356, 'IoU-136': 0.8732932733520324, 'IoU-137': 0.8450446403234535, 'IoU-138': 0.8609987101283492, 'IoU-139': 0.7802997395880974, 'IoU-140': 0.7601589411359299, 'IoU-141': 0.7058018471569578, 'IoU-142': 0.6794175101443591, 'IoU-143': 0.6695495869709804, 'IoU-144': 0.6385983009863675, 'IoU-145': 0.6084314287222479, 'IoU-146': 0.6310840338213457, 'IoU-147': 0.5885840449191032, 'IoU-148': 0.5626204533384712, 'IoU-149': 0.5121941047115574, 'IoU-150': 0.523367648734999, 'IoU-151': 0.6139878874600394, 'IoU-152': 0.7527917686084747, 'IoU-153': 0.7297403759606842, 'IoU-154': 0.5991486520323847, 'IoU-155': 0.6426600270747391, 'IoU-156': 0.5958681955981129, 'IoU-157': 0.6211414398049522, 'IoU-158': 0.7709599675157751, 'IoU-159': 0.5386490247975475, 'IoU-160': 0.5271887124558787, 'IoU-161': 0.46288957725406843, 'IoU-162': 0.4311325612866912, 'IoU-163': 0.37992055474840325, 'IoU-164': 0.38646109176938687, 'IoU-165': 0.29636949509290555, 'IoU-166': 0.27295022310830086, 'IoU-167': 0.24355679842793437, 'IoU-168': 0.2749726122896126, 'IoU-169': 0.25909458033889365, 'IoU-170': 0.18018645759956797, 'IoU-171': 0.15335446789865717, 'IoU-172': 0.13334457975990532, 'IoU-173': 0.06419631259651595, 'IoU-174': 0.08341983743974833, 'IoU-175': 0.07419425348574454, 'IoU-176': 0.050628638933423335, 'IoU-177': 0.045307253811924936, 'IoU-178': 0.018663921899802458, 'IoU-179': 0.015341495795840094, 'IoU-180': 0.03565446675842855, 'IoU-181': 0.0403590074499912, 'IoU-182': 0.03396923425325479, 'IoU-183': 0.013863563734797075, 'IoU-184': 0.009893340368597596, 'IoU-185': 0.0009234676209165416, 'IoU-186': 0.0004720521523217885, 'IoU-187': 0.00024157623662875532, 'IoU-188': 0.0005043907212282923, 'IoU-189': 0.0, 'IoU-190': 0.0002619906574131566, 'IoU-191': 0.0, 'IoU-192': 0.0005659597828978273, 'mACC': 10.669911189757501, 'pACC': 20.084375962983046, 'ACC-0': nan, 'ACC-1': 3.9319779721133186, 'ACC-2': 2.1844898943282804, 'ACC-3': 5.348687813546358, 'ACC-4': 5.8170641928722855, 'ACC-5': 7.188274785644283, 'ACC-6': 9.771366780664222, 'ACC-7': 10.973524253329979, 'ACC-8': 14.432740706688119, 'ACC-9': 15.478577610410692, 'ACC-10': 17.37113652714172, 'ACC-11': 26.901692532211502, 'ACC-12': 31.450976344243127, 'ACC-13': 28.388650759006808, 'ACC-14': 23.363272613373294, 'ACC-15': 23.246598140794326, 'ACC-16': 20.263236414510146, 'ACC-17': 18.893964929223227, 'ACC-18': 17.57610452917889, 'ACC-19': 18.851798294555895, 'ACC-20': 22.484410779951205, 'ACC-21': 25.344080591445795, 'ACC-22': 24.115488027907478, 'ACC-23': 25.532758719274774, 'ACC-24': 27.24661773404824, 'ACC-25': 28.123388723014877, 'ACC-26': 27.95982584407617, 'ACC-27': 28.20532166517657, 'ACC-28': 30.413704616557425, 'ACC-29': 31.49983281460788, 'ACC-30': 30.391572631343138, 'ACC-31': 30.06381098412243, 'ACC-32': 29.486099319061825, 'ACC-33': 28.83445308973327, 'ACC-34': 28.08451158648233, 'ACC-35': 28.109253486060844, 'ACC-36': 28.423001738643194, 'ACC-37': 27.73975460589131, 'ACC-38': 28.198537852975512, 'ACC-39': 29.071586652002622, 'ACC-40': 30.51041116617379, 'ACC-41': 30.203795115720517, 'ACC-42': 30.494295747260665, 'ACC-43': 29.302467129137412, 'ACC-44': 28.241456832726925, 'ACC-45': 26.167249289328502, 'ACC-46': 25.321902629829978, 'ACC-47': 24.668854416672442, 'ACC-48': 24.58432939791601, 'ACC-49': 24.538020025568052, 'ACC-50': 23.398944206770985, 'ACC-51': 22.323356706248987, 'ACC-52': 21.469619559877668, 'ACC-53': 21.01502923704522, 'ACC-54': 20.522038248985876, 'ACC-55': 20.238959604025215, 'ACC-56': 18.442333897066142, 'ACC-57': 17.204888644644694, 'ACC-58': 16.495115213144388, 'ACC-59': 15.17013171290509, 'ACC-60': 14.966473712112816, 'ACC-61': 14.537889239390573, 'ACC-62': 13.55044748665111, 'ACC-63': 12.917618461574785, 'ACC-64': 12.347361557397322, 'ACC-65': 11.473430513179025, 'ACC-66': 11.188594911511752, 'ACC-67': 11.124293047675254, 'ACC-68': 10.710117632895917, 'ACC-69': 10.500846358117998, 'ACC-70': 10.800638719950657, 'ACC-71': 10.518874451667038, 'ACC-72': 10.60399733795894, 'ACC-73': 10.63507897438708, 'ACC-74': 10.785011405416846, 'ACC-75': 10.422543978142244, 'ACC-76': 10.760650337483622, 'ACC-77': 11.047490153021425, 'ACC-78': 11.328243458576996, 'ACC-79': 11.590171364135506, 'ACC-80': 11.77031748940174, 'ACC-81': 12.027374553609517, 'ACC-82': 12.434875513868283, 'ACC-83': 12.376496634030708, 'ACC-84': 11.989219024628863, 'ACC-85': 12.392403645280018, 'ACC-86': 12.775267448403197, 'ACC-87': 12.80103338687213, 'ACC-88': 12.660162590181596, 'ACC-89': 12.6112881499654, 'ACC-90': 12.557539273126697, 'ACC-91': 12.426855424870611, 'ACC-92': 12.380369771396646, 'ACC-93': 12.591944708762387, 'ACC-94': 12.504637502402376, 'ACC-95': 12.141128029489815, 'ACC-96': 11.924972884504225, 'ACC-97': 12.054881250589599, 'ACC-98': 12.086548975763463, 'ACC-99': 11.085214751231673, 'ACC-100': 11.114469726642485, 'ACC-101': 10.824387735977206, 'ACC-102': 10.161395559583145, 'ACC-103': 9.909818645508643, 'ACC-104': 9.18504217800841, 'ACC-105': 8.777896137733872, 'ACC-106': 8.463429094827191, 'ACC-107': 8.482206963173766, 'ACC-108': 8.47125007634533, 'ACC-109': 8.643581773054771, 'ACC-110': 8.255797883215218, 'ACC-111': 7.549827148050961, 'ACC-112': 7.288732558845649, 'ACC-113': 6.789876218267819, 'ACC-114': 6.544613569183931, 'ACC-115': 6.121134214364109, 'ACC-116': 5.4049263391558755, 'ACC-117': 5.156562543447181, 'ACC-118': 4.985184933263971, 'ACC-119': 4.96955441839439, 'ACC-120': 4.726576638308789, 'ACC-121': 4.494539719943478, 'ACC-122': 3.9488805230830195, 'ACC-123': 3.663535760032684, 'ACC-124': 3.3915063707280533, 'ACC-125': 3.1162881255826043, 'ACC-126': 2.654964981466134, 'ACC-127': 2.8208491809100167, 'ACC-128': 2.6914553275984248, 'ACC-129': 2.4612832031948613, 'ACC-130': 2.329914379983645, 'ACC-131': 2.0387276510537227, 'ACC-132': 1.9121821100287186, 'ACC-133': 2.0465138432437215, 'ACC-134': 2.0254717794054287, 'ACC-135': 1.705860555270509, 'ACC-136': 1.657499184681327, 'ACC-137': 1.613702157734177, 'ACC-138': 1.637656420539635, 'ACC-139': 1.5036650862920606, 'ACC-140': 1.4452025635801333, 'ACC-141': 1.3176209607516085, 'ACC-142': 1.2587102346512544, 'ACC-143': 1.2166925910250501, 'ACC-144': 1.1286101083032491, 'ACC-145': 1.0619199892663074, 'ACC-146': 1.0956112494574033, 'ACC-147': 1.0185861800975502, 'ACC-148': 0.9798004089155373, 'ACC-149': 0.9091655857754377, 'ACC-150': 0.9284882672561963, 'ACC-151': 1.0957248506047748, 'ACC-152': 1.315623103378515, 'ACC-153': 1.2876976492790266, 'ACC-154': 1.053580800946849, 'ACC-155': 1.1392461230134372, 'ACC-156': 1.0689884749882035, 'ACC-157': 1.1206792127208116, 'ACC-158': 1.4094962818484484, 'ACC-159': 0.9772120889060272, 'ACC-160': 0.9536318599285165, 'ACC-161': 0.8324042271755828, 'ACC-162': 0.8033299514134143, 'ACC-163': 0.7215282947626523, 'ACC-164': 0.7293275283090065, 'ACC-165': 0.5496669599494326, 'ACC-166': 0.5143917200392845, 'ACC-167': 0.44782834520651693, 'ACC-168': 0.48544201420634364, 'ACC-169': 0.4413109127502883, 'ACC-170': 0.293702173573548, 'ACC-171': 0.2404442248383109, 'ACC-172': 0.1990961958736156, 'ACC-173': 0.08861612098452322, 'ACC-174': 0.10755273718920147, 'ACC-175': 0.08911420114295435, 'ACC-176': 0.056593916879498496, 'ACC-177': 0.04853571619708823, 'ACC-178': 0.01950895383717943, 'ACC-179': 0.015825320919248254, 'ACC-180': 0.03640489010802939, 'ACC-181': 0.040741398709066144, 'ACC-182': 0.03411756343734451, 'ACC-183': 0.013891079807785126, 'ACC-184': 0.0099052632323704, 'ACC-185': 0.000923834467340142, 'ACC-186': 0.0004721290423098441, 'ACC-187': 0.000241607754642493, 'ACC-188': 0.0005044187078810379, 'ACC-189': 0.0, 'ACC-190': 0.0002620078183132985, 'ACC-191': 0.0, 'ACC-192': 0.0005659774005223972})])
[01/27 15:07:58] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 15:07:58] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 15:07:58] d2.evaluation.testing INFO: copypaste: 3.0196,0.3990,0.1787,5.8123,11.7160,10.6699,20.0844
[01/27 15:07:58] d2.utils.events INFO:  eta: 1 day, 0:20:17  iter: 18999  total_loss: 31.29  loss_mask: 3.126  loss_mask_0: 3.137  loss_mask_1: 3.128  loss_mask_2: 3.131  loss_mask_3: 3.127  loss_mask_4: 3.131  loss_mask_5: 3.13  loss_mask_6: 3.126  loss_mask_7: 3.128  loss_mask_8: 3.128  time: 1.9150  data_time: 0.4027  lr: 7.0987e-05  max_mem: 17484M
[01/27 15:08:44] d2.utils.events INFO:  eta: 1 day, 0:21:15  iter: 19019  total_loss: 28.41  loss_mask: 2.841  loss_mask_0: 2.843  loss_mask_1: 2.84  loss_mask_2: 2.84  loss_mask_3: 2.842  loss_mask_4: 2.839  loss_mask_5: 2.841  loss_mask_6: 2.842  loss_mask_7: 2.841  loss_mask_8: 2.841  time: 1.9154  data_time: 0.4390  lr: 7.0956e-05  max_mem: 17484M
[01/27 15:09:29] d2.utils.events INFO:  eta: 1 day, 0:23:30  iter: 19039  total_loss: 28.05  loss_mask: 2.8  loss_mask_0: 2.82  loss_mask_1: 2.804  loss_mask_2: 2.806  loss_mask_3: 2.799  loss_mask_4: 2.803  loss_mask_5: 2.807  loss_mask_6: 2.805  loss_mask_7: 2.8  loss_mask_8: 2.803  time: 1.9158  data_time: 0.4176  lr: 7.0925e-05  max_mem: 17484M
[01/27 15:10:15] d2.utils.events INFO:  eta: 1 day, 0:24:05  iter: 19059  total_loss: 28.95  loss_mask: 2.895  loss_mask_0: 2.891  loss_mask_1: 2.895  loss_mask_2: 2.895  loss_mask_3: 2.898  loss_mask_4: 2.895  loss_mask_5: 2.896  loss_mask_6: 2.894  loss_mask_7: 2.895  loss_mask_8: 2.895  time: 1.9162  data_time: 0.4610  lr: 7.0894e-05  max_mem: 17484M
[01/27 15:11:01] d2.utils.events INFO:  eta: 1 day, 0:26:08  iter: 19079  total_loss: 27.87  loss_mask: 2.785  loss_mask_0: 2.803  loss_mask_1: 2.785  loss_mask_2: 2.786  loss_mask_3: 2.785  loss_mask_4: 2.786  loss_mask_5: 2.784  loss_mask_6: 2.786  loss_mask_7: 2.785  loss_mask_8: 2.786  time: 1.9165  data_time: 0.4553  lr: 7.0862e-05  max_mem: 17484M
[01/27 15:11:46] d2.utils.events INFO:  eta: 1 day, 0:28:06  iter: 19099  total_loss: 27.6  loss_mask: 2.759  loss_mask_0: 2.768  loss_mask_1: 2.759  loss_mask_2: 2.759  loss_mask_3: 2.758  loss_mask_4: 2.759  loss_mask_5: 2.758  loss_mask_6: 2.759  loss_mask_7: 2.76  loss_mask_8: 2.759  time: 1.9169  data_time: 0.4295  lr: 7.0831e-05  max_mem: 17484M
[01/27 15:12:32] d2.utils.events INFO:  eta: 1 day, 0:29:33  iter: 19119  total_loss: 27.79  loss_mask: 2.776  loss_mask_0: 2.851  loss_mask_1: 2.775  loss_mask_2: 2.775  loss_mask_3: 2.776  loss_mask_4: 2.775  loss_mask_5: 2.775  loss_mask_6: 2.774  loss_mask_7: 2.775  loss_mask_8: 2.775  time: 1.9173  data_time: 0.4460  lr: 7.08e-05  max_mem: 17484M
[01/27 15:13:16] d2.utils.events INFO:  eta: 1 day, 0:30:28  iter: 19139  total_loss: 30.77  loss_mask: 3.076  loss_mask_0: 3.098  loss_mask_1: 3.075  loss_mask_2: 3.075  loss_mask_3: 3.075  loss_mask_4: 3.074  loss_mask_5: 3.075  loss_mask_6: 3.075  loss_mask_7: 3.075  loss_mask_8: 3.074  time: 1.9176  data_time: 0.4377  lr: 7.0769e-05  max_mem: 17484M
[01/27 15:14:01] d2.utils.events INFO:  eta: 1 day, 0:31:24  iter: 19159  total_loss: 26.89  loss_mask: 2.689  loss_mask_0: 2.691  loss_mask_1: 2.688  loss_mask_2: 2.688  loss_mask_3: 2.688  loss_mask_4: 2.688  loss_mask_5: 2.688  loss_mask_6: 2.689  loss_mask_7: 2.689  loss_mask_8: 2.688  time: 1.9179  data_time: 0.4371  lr: 7.0738e-05  max_mem: 17484M
[01/27 15:14:45] d2.utils.events INFO:  eta: 1 day, 0:32:46  iter: 19179  total_loss: 26.16  loss_mask: 2.616  loss_mask_0: 2.621  loss_mask_1: 2.615  loss_mask_2: 2.616  loss_mask_3: 2.615  loss_mask_4: 2.616  loss_mask_5: 2.616  loss_mask_6: 2.615  loss_mask_7: 2.617  loss_mask_8: 2.616  time: 1.9182  data_time: 0.4041  lr: 7.0706e-05  max_mem: 17484M
[01/27 15:15:29] d2.utils.events INFO:  eta: 1 day, 0:33:21  iter: 19199  total_loss: 26.36  loss_mask: 2.635  loss_mask_0: 2.652  loss_mask_1: 2.636  loss_mask_2: 2.635  loss_mask_3: 2.637  loss_mask_4: 2.636  loss_mask_5: 2.636  loss_mask_6: 2.635  loss_mask_7: 2.636  loss_mask_8: 2.635  time: 1.9185  data_time: 0.4061  lr: 7.0675e-05  max_mem: 17484M
[01/27 15:16:14] d2.utils.events INFO:  eta: 1 day, 0:35:09  iter: 19219  total_loss: 27.76  loss_mask: 2.776  loss_mask_0: 2.756  loss_mask_1: 2.781  loss_mask_2: 2.777  loss_mask_3: 2.781  loss_mask_4: 2.78  loss_mask_5: 2.779  loss_mask_6: 2.781  loss_mask_7: 2.779  loss_mask_8: 2.777  time: 1.9189  data_time: 0.4202  lr: 7.0644e-05  max_mem: 17484M
[01/27 15:16:59] d2.utils.events INFO:  eta: 1 day, 0:37:22  iter: 19239  total_loss: 29.28  loss_mask: 2.912  loss_mask_0: 2.98  loss_mask_1: 2.914  loss_mask_2: 2.914  loss_mask_3: 2.913  loss_mask_4: 2.913  loss_mask_5: 2.913  loss_mask_6: 2.912  loss_mask_7: 2.913  loss_mask_8: 2.913  time: 1.9192  data_time: 0.4094  lr: 7.0613e-05  max_mem: 17484M
[01/27 15:17:45] d2.utils.events INFO:  eta: 1 day, 0:39:21  iter: 19259  total_loss: 26.8  loss_mask: 2.678  loss_mask_0: 2.689  loss_mask_1: 2.679  loss_mask_2: 2.678  loss_mask_3: 2.679  loss_mask_4: 2.679  loss_mask_5: 2.679  loss_mask_6: 2.679  loss_mask_7: 2.679  loss_mask_8: 2.678  time: 1.9196  data_time: 0.4433  lr: 7.0582e-05  max_mem: 17484M
[01/27 15:18:31] d2.utils.events INFO:  eta: 1 day, 0:41:17  iter: 19279  total_loss: 25.9  loss_mask: 2.592  loss_mask_0: 2.582  loss_mask_1: 2.591  loss_mask_2: 2.591  loss_mask_3: 2.591  loss_mask_4: 2.591  loss_mask_5: 2.591  loss_mask_6: 2.591  loss_mask_7: 2.591  loss_mask_8: 2.591  time: 1.9200  data_time: 0.4288  lr: 7.0551e-05  max_mem: 17484M
[01/27 15:19:16] d2.utils.events INFO:  eta: 1 day, 0:42:29  iter: 19299  total_loss: 25.6  loss_mask: 2.554  loss_mask_0: 2.603  loss_mask_1: 2.555  loss_mask_2: 2.554  loss_mask_3: 2.555  loss_mask_4: 2.555  loss_mask_5: 2.554  loss_mask_6: 2.554  loss_mask_7: 2.554  loss_mask_8: 2.554  time: 1.9204  data_time: 0.4229  lr: 7.0519e-05  max_mem: 17484M
[01/27 15:20:02] d2.utils.events INFO:  eta: 1 day, 0:44:41  iter: 19319  total_loss: 24.46  loss_mask: 2.446  loss_mask_0: 2.458  loss_mask_1: 2.443  loss_mask_2: 2.444  loss_mask_3: 2.446  loss_mask_4: 2.443  loss_mask_5: 2.442  loss_mask_6: 2.447  loss_mask_7: 2.442  loss_mask_8: 2.445  time: 1.9207  data_time: 0.4309  lr: 7.0488e-05  max_mem: 17484M
[01/27 15:20:47] d2.utils.events INFO:  eta: 1 day, 0:47:47  iter: 19339  total_loss: 26.76  loss_mask: 2.672  loss_mask_0: 2.702  loss_mask_1: 2.674  loss_mask_2: 2.675  loss_mask_3: 2.672  loss_mask_4: 2.674  loss_mask_5: 2.675  loss_mask_6: 2.673  loss_mask_7: 2.673  loss_mask_8: 2.675  time: 1.9211  data_time: 0.4322  lr: 7.0457e-05  max_mem: 17484M
[01/27 15:21:33] d2.utils.events INFO:  eta: 1 day, 0:50:12  iter: 19359  total_loss: 25.03  loss_mask: 2.502  loss_mask_0: 2.512  loss_mask_1: 2.501  loss_mask_2: 2.502  loss_mask_3: 2.501  loss_mask_4: 2.501  loss_mask_5: 2.502  loss_mask_6: 2.502  loss_mask_7: 2.501  loss_mask_8: 2.502  time: 1.9215  data_time: 0.4422  lr: 7.0426e-05  max_mem: 17484M
[01/27 15:22:19] d2.utils.events INFO:  eta: 1 day, 0:51:52  iter: 19379  total_loss: 24.92  loss_mask: 2.491  loss_mask_0: 2.506  loss_mask_1: 2.491  loss_mask_2: 2.491  loss_mask_3: 2.491  loss_mask_4: 2.491  loss_mask_5: 2.491  loss_mask_6: 2.491  loss_mask_7: 2.491  loss_mask_8: 2.491  time: 1.9219  data_time: 0.4400  lr: 7.0395e-05  max_mem: 17484M
[01/27 15:23:04] d2.utils.events INFO:  eta: 1 day, 0:52:49  iter: 19399  total_loss: 28.25  loss_mask: 2.824  loss_mask_0: 2.837  loss_mask_1: 2.823  loss_mask_2: 2.823  loss_mask_3: 2.824  loss_mask_4: 2.823  loss_mask_5: 2.824  loss_mask_6: 2.824  loss_mask_7: 2.824  loss_mask_8: 2.824  time: 1.9222  data_time: 0.4094  lr: 7.0363e-05  max_mem: 17484M
[01/27 15:23:50] d2.utils.events INFO:  eta: 1 day, 0:55:21  iter: 19419  total_loss: 26.68  loss_mask: 2.665  loss_mask_0: 2.705  loss_mask_1: 2.664  loss_mask_2: 2.665  loss_mask_3: 2.664  loss_mask_4: 2.665  loss_mask_5: 2.664  loss_mask_6: 2.664  loss_mask_7: 2.664  loss_mask_8: 2.664  time: 1.9226  data_time: 0.4176  lr: 7.0332e-05  max_mem: 17484M
[01/27 15:24:36] d2.utils.events INFO:  eta: 1 day, 0:57:26  iter: 19439  total_loss: 25.92  loss_mask: 2.59  loss_mask_0: 2.619  loss_mask_1: 2.591  loss_mask_2: 2.59  loss_mask_3: 2.59  loss_mask_4: 2.591  loss_mask_5: 2.591  loss_mask_6: 2.59  loss_mask_7: 2.591  loss_mask_8: 2.59  time: 1.9230  data_time: 0.4481  lr: 7.0301e-05  max_mem: 17484M
[01/27 15:25:22] d2.utils.events INFO:  eta: 1 day, 0:58:01  iter: 19459  total_loss: 26.6  loss_mask: 2.656  loss_mask_0: 2.706  loss_mask_1: 2.655  loss_mask_2: 2.655  loss_mask_3: 2.656  loss_mask_4: 2.655  loss_mask_5: 2.655  loss_mask_6: 2.656  loss_mask_7: 2.656  loss_mask_8: 2.655  time: 1.9233  data_time: 0.4498  lr: 7.027e-05  max_mem: 17484M
[01/27 15:26:07] d2.utils.events INFO:  eta: 1 day, 0:58:56  iter: 19479  total_loss: 25.95  loss_mask: 2.592  loss_mask_0: 2.644  loss_mask_1: 2.591  loss_mask_2: 2.592  loss_mask_3: 2.591  loss_mask_4: 2.592  loss_mask_5: 2.59  loss_mask_6: 2.59  loss_mask_7: 2.591  loss_mask_8: 2.592  time: 1.9237  data_time: 0.4376  lr: 7.0239e-05  max_mem: 17484M
[01/27 15:26:53] d2.utils.events INFO:  eta: 1 day, 1:00:28  iter: 19499  total_loss: 24.98  loss_mask: 2.491  loss_mask_0: 2.559  loss_mask_1: 2.492  loss_mask_2: 2.492  loss_mask_3: 2.492  loss_mask_4: 2.492  loss_mask_5: 2.491  loss_mask_6: 2.492  loss_mask_7: 2.491  loss_mask_8: 2.491  time: 1.9241  data_time: 0.4309  lr: 7.0207e-05  max_mem: 17484M
[01/27 15:27:39] d2.utils.events INFO:  eta: 1 day, 1:01:16  iter: 19519  total_loss: 25.67  loss_mask: 2.56  loss_mask_0: 2.616  loss_mask_1: 2.56  loss_mask_2: 2.561  loss_mask_3: 2.559  loss_mask_4: 2.561  loss_mask_5: 2.56  loss_mask_6: 2.56  loss_mask_7: 2.56  loss_mask_8: 2.561  time: 1.9245  data_time: 0.4441  lr: 7.0176e-05  max_mem: 17484M
[01/27 15:28:25] d2.utils.events INFO:  eta: 1 day, 1:03:37  iter: 19539  total_loss: 26.15  loss_mask: 2.61  loss_mask_0: 2.658  loss_mask_1: 2.61  loss_mask_2: 2.61  loss_mask_3: 2.61  loss_mask_4: 2.61  loss_mask_5: 2.61  loss_mask_6: 2.61  loss_mask_7: 2.611  loss_mask_8: 2.61  time: 1.9249  data_time: 0.4519  lr: 7.0145e-05  max_mem: 17484M
[01/27 15:29:11] d2.utils.events INFO:  eta: 1 day, 1:04:24  iter: 19559  total_loss: 24.32  loss_mask: 2.431  loss_mask_0: 2.445  loss_mask_1: 2.43  loss_mask_2: 2.431  loss_mask_3: 2.431  loss_mask_4: 2.43  loss_mask_5: 2.43  loss_mask_6: 2.431  loss_mask_7: 2.431  loss_mask_8: 2.431  time: 1.9252  data_time: 0.4257  lr: 7.0114e-05  max_mem: 17484M
[01/27 15:29:56] d2.utils.events INFO:  eta: 1 day, 1:06:26  iter: 19579  total_loss: 25.99  loss_mask: 2.594  loss_mask_0: 2.646  loss_mask_1: 2.594  loss_mask_2: 2.595  loss_mask_3: 2.594  loss_mask_4: 2.595  loss_mask_5: 2.594  loss_mask_6: 2.594  loss_mask_7: 2.594  loss_mask_8: 2.594  time: 1.9256  data_time: 0.4221  lr: 7.0083e-05  max_mem: 17484M
[01/27 15:30:42] d2.utils.events INFO:  eta: 1 day, 1:07:38  iter: 19599  total_loss: 26.04  loss_mask: 2.6  loss_mask_0: 2.652  loss_mask_1: 2.6  loss_mask_2: 2.601  loss_mask_3: 2.601  loss_mask_4: 2.601  loss_mask_5: 2.6  loss_mask_6: 2.601  loss_mask_7: 2.6  loss_mask_8: 2.601  time: 1.9259  data_time: 0.4302  lr: 7.0051e-05  max_mem: 17484M
[01/27 15:31:28] d2.utils.events INFO:  eta: 1 day, 1:08:43  iter: 19619  total_loss: 25.95  loss_mask: 2.588  loss_mask_0: 2.627  loss_mask_1: 2.588  loss_mask_2: 2.588  loss_mask_3: 2.587  loss_mask_4: 2.588  loss_mask_5: 2.587  loss_mask_6: 2.587  loss_mask_7: 2.587  loss_mask_8: 2.587  time: 1.9263  data_time: 0.4523  lr: 7.002e-05  max_mem: 17484M
[01/27 15:32:13] d2.utils.events INFO:  eta: 1 day, 1:09:00  iter: 19639  total_loss: 25.79  loss_mask: 2.575  loss_mask_0: 2.609  loss_mask_1: 2.575  loss_mask_2: 2.575  loss_mask_3: 2.575  loss_mask_4: 2.575  loss_mask_5: 2.575  loss_mask_6: 2.575  loss_mask_7: 2.575  loss_mask_8: 2.575  time: 1.9267  data_time: 0.4429  lr: 6.9989e-05  max_mem: 17484M
[01/27 15:32:59] d2.utils.events INFO:  eta: 1 day, 1:11:01  iter: 19659  total_loss: 24.67  loss_mask: 2.465  loss_mask_0: 2.485  loss_mask_1: 2.465  loss_mask_2: 2.465  loss_mask_3: 2.465  loss_mask_4: 2.465  loss_mask_5: 2.465  loss_mask_6: 2.465  loss_mask_7: 2.465  loss_mask_8: 2.465  time: 1.9270  data_time: 0.4256  lr: 6.9958e-05  max_mem: 17484M
[01/27 15:33:45] d2.utils.events INFO:  eta: 1 day, 1:11:54  iter: 19679  total_loss: 25.25  loss_mask: 2.518  loss_mask_0: 2.564  loss_mask_1: 2.519  loss_mask_2: 2.518  loss_mask_3: 2.518  loss_mask_4: 2.519  loss_mask_5: 2.519  loss_mask_6: 2.519  loss_mask_7: 2.519  loss_mask_8: 2.519  time: 1.9274  data_time: 0.4415  lr: 6.9927e-05  max_mem: 17484M
[01/27 15:34:30] d2.utils.events INFO:  eta: 1 day, 1:12:02  iter: 19699  total_loss: 24.98  loss_mask: 2.494  loss_mask_0: 2.522  loss_mask_1: 2.494  loss_mask_2: 2.494  loss_mask_3: 2.495  loss_mask_4: 2.494  loss_mask_5: 2.494  loss_mask_6: 2.494  loss_mask_7: 2.494  loss_mask_8: 2.494  time: 1.9277  data_time: 0.4188  lr: 6.9895e-05  max_mem: 17484M
[01/27 15:35:16] d2.utils.events INFO:  eta: 1 day, 1:12:04  iter: 19719  total_loss: 25.2  loss_mask: 2.515  loss_mask_0: 2.564  loss_mask_1: 2.514  loss_mask_2: 2.515  loss_mask_3: 2.515  loss_mask_4: 2.514  loss_mask_5: 2.515  loss_mask_6: 2.515  loss_mask_7: 2.515  loss_mask_8: 2.515  time: 1.9281  data_time: 0.4427  lr: 6.9864e-05  max_mem: 17484M
[01/27 15:36:01] d2.utils.events INFO:  eta: 1 day, 1:12:28  iter: 19739  total_loss: 25.19  loss_mask: 2.515  loss_mask_0: 2.557  loss_mask_1: 2.514  loss_mask_2: 2.515  loss_mask_3: 2.515  loss_mask_4: 2.515  loss_mask_5: 2.514  loss_mask_6: 2.514  loss_mask_7: 2.514  loss_mask_8: 2.515  time: 1.9284  data_time: 0.4156  lr: 6.9833e-05  max_mem: 17484M
[01/27 15:36:47] d2.utils.events INFO:  eta: 1 day, 1:12:16  iter: 19759  total_loss: 25.33  loss_mask: 2.527  loss_mask_0: 2.592  loss_mask_1: 2.526  loss_mask_2: 2.527  loss_mask_3: 2.527  loss_mask_4: 2.527  loss_mask_5: 2.526  loss_mask_6: 2.526  loss_mask_7: 2.527  loss_mask_8: 2.527  time: 1.9288  data_time: 0.4256  lr: 6.9802e-05  max_mem: 17484M
[01/27 15:37:33] d2.utils.events INFO:  eta: 1 day, 1:13:25  iter: 19779  total_loss: 25.08  loss_mask: 2.5  loss_mask_0: 2.569  loss_mask_1: 2.501  loss_mask_2: 2.5  loss_mask_3: 2.5  loss_mask_4: 2.501  loss_mask_5: 2.5  loss_mask_6: 2.5  loss_mask_7: 2.501  loss_mask_8: 2.5  time: 1.9291  data_time: 0.4461  lr: 6.977e-05  max_mem: 17484M
[01/27 15:38:19] d2.utils.events INFO:  eta: 1 day, 1:14:34  iter: 19799  total_loss: 25.48  loss_mask: 2.544  loss_mask_0: 2.57  loss_mask_1: 2.544  loss_mask_2: 2.543  loss_mask_3: 2.545  loss_mask_4: 2.544  loss_mask_5: 2.544  loss_mask_6: 2.545  loss_mask_7: 2.543  loss_mask_8: 2.544  time: 1.9295  data_time: 0.4302  lr: 6.9739e-05  max_mem: 17484M
[01/27 15:39:04] d2.utils.events INFO:  eta: 1 day, 1:15:41  iter: 19819  total_loss: 25.04  loss_mask: 2.5  loss_mask_0: 2.571  loss_mask_1: 2.5  loss_mask_2: 2.5  loss_mask_3: 2.499  loss_mask_4: 2.501  loss_mask_5: 2.5  loss_mask_6: 2.5  loss_mask_7: 2.5  loss_mask_8: 2.5  time: 1.9299  data_time: 0.4243  lr: 6.9708e-05  max_mem: 17484M
[01/27 15:39:50] d2.utils.events INFO:  eta: 1 day, 1:16:16  iter: 19839  total_loss: 24.39  loss_mask: 2.432  loss_mask_0: 2.492  loss_mask_1: 2.433  loss_mask_2: 2.433  loss_mask_3: 2.433  loss_mask_4: 2.434  loss_mask_5: 2.433  loss_mask_6: 2.433  loss_mask_7: 2.434  loss_mask_8: 2.433  time: 1.9302  data_time: 0.4287  lr: 6.9677e-05  max_mem: 17484M
[01/27 15:40:35] d2.utils.events INFO:  eta: 1 day, 1:15:52  iter: 19859  total_loss: 24.49  loss_mask: 2.444  loss_mask_0: 2.496  loss_mask_1: 2.443  loss_mask_2: 2.443  loss_mask_3: 2.444  loss_mask_4: 2.443  loss_mask_5: 2.444  loss_mask_6: 2.444  loss_mask_7: 2.444  loss_mask_8: 2.443  time: 1.9305  data_time: 0.4122  lr: 6.9646e-05  max_mem: 17484M
[01/27 15:41:20] d2.utils.events INFO:  eta: 1 day, 1:15:54  iter: 19879  total_loss: 25.56  loss_mask: 2.552  loss_mask_0: 2.595  loss_mask_1: 2.551  loss_mask_2: 2.552  loss_mask_3: 2.552  loss_mask_4: 2.552  loss_mask_5: 2.552  loss_mask_6: 2.552  loss_mask_7: 2.552  loss_mask_8: 2.553  time: 1.9309  data_time: 0.4163  lr: 6.9614e-05  max_mem: 17484M
[01/27 15:42:05] d2.utils.events INFO:  eta: 1 day, 1:15:53  iter: 19899  total_loss: 23.8  loss_mask: 2.377  loss_mask_0: 2.414  loss_mask_1: 2.376  loss_mask_2: 2.376  loss_mask_3: 2.377  loss_mask_4: 2.377  loss_mask_5: 2.376  loss_mask_6: 2.376  loss_mask_7: 2.376  loss_mask_8: 2.376  time: 1.9312  data_time: 0.4190  lr: 6.9583e-05  max_mem: 17484M
[01/27 15:42:49] d2.utils.events INFO:  eta: 1 day, 1:14:54  iter: 19919  total_loss: 23.7  loss_mask: 2.366  loss_mask_0: 2.405  loss_mask_1: 2.367  loss_mask_2: 2.366  loss_mask_3: 2.366  loss_mask_4: 2.367  loss_mask_5: 2.367  loss_mask_6: 2.367  loss_mask_7: 2.367  loss_mask_8: 2.367  time: 1.9315  data_time: 0.4084  lr: 6.9552e-05  max_mem: 17484M
[01/27 15:43:33] d2.utils.events INFO:  eta: 1 day, 1:14:08  iter: 19939  total_loss: 24.56  loss_mask: 2.453  loss_mask_0: 2.518  loss_mask_1: 2.452  loss_mask_2: 2.453  loss_mask_3: 2.453  loss_mask_4: 2.452  loss_mask_5: 2.453  loss_mask_6: 2.453  loss_mask_7: 2.453  loss_mask_8: 2.453  time: 1.9317  data_time: 0.4172  lr: 6.9521e-05  max_mem: 17484M
[01/27 15:44:19] d2.utils.events INFO:  eta: 1 day, 1:13:55  iter: 19959  total_loss: 24.99  loss_mask: 2.494  loss_mask_0: 2.55  loss_mask_1: 2.495  loss_mask_2: 2.495  loss_mask_3: 2.495  loss_mask_4: 2.495  loss_mask_5: 2.495  loss_mask_6: 2.494  loss_mask_7: 2.494  loss_mask_8: 2.495  time: 1.9321  data_time: 0.4374  lr: 6.9489e-05  max_mem: 17484M
[01/27 15:45:05] d2.utils.events INFO:  eta: 1 day, 1:13:48  iter: 19979  total_loss: 24.78  loss_mask: 2.474  loss_mask_0: 2.504  loss_mask_1: 2.474  loss_mask_2: 2.474  loss_mask_3: 2.475  loss_mask_4: 2.475  loss_mask_5: 2.474  loss_mask_6: 2.474  loss_mask_7: 2.475  loss_mask_8: 2.475  time: 1.9325  data_time: 0.4542  lr: 6.9458e-05  max_mem: 17484M
[01/27 15:45:51] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE/model_0019999.pth
[01/27 15:45:51] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 15:45:52] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 15:45:52] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 15:53:47] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.3678461024712782, 'error_1pix': 0.30688546870375344, 'error_3pix': 0.13176771279024507, 'mIoU': 9.691397185140733, 'fwIoU': 23.278688714586025, 'IoU-0': nan, 'IoU-1': 67.23561941565364, 'IoU-2': 3.0627809683053213, 'IoU-3': 3.5668151649562914, 'IoU-4': 3.8508609578658524, 'IoU-5': 4.082057335980421, 'IoU-6': 3.8762336137749607, 'IoU-7': 3.1516117750292336, 'IoU-8': 6.793733042743407, 'IoU-9': 18.114527936188008, 'IoU-10': 22.86992784475685, 'IoU-11': 28.70761634139503, 'IoU-12': 28.221177427173792, 'IoU-13': 27.755712216999395, 'IoU-14': 27.359485429696022, 'IoU-15': 26.079298356778775, 'IoU-16': 27.74285627883333, 'IoU-17': 23.704836394054738, 'IoU-18': 23.607166488896215, 'IoU-19': 23.113060787036428, 'IoU-20': 23.04931681577842, 'IoU-21': 22.11401986553245, 'IoU-22': 22.799847113548253, 'IoU-23': 21.501025468988992, 'IoU-24': 21.38059917814122, 'IoU-25': 20.611044089005272, 'IoU-26': 20.648570263674184, 'IoU-27': 21.877402159917192, 'IoU-28': 22.115384927409213, 'IoU-29': 22.537679387080694, 'IoU-30': 22.12325303509125, 'IoU-31': 22.63982348403404, 'IoU-32': 22.586942634313694, 'IoU-33': 21.67665119565468, 'IoU-34': 21.8155302518875, 'IoU-35': 22.443545625277608, 'IoU-36': 22.189775130059154, 'IoU-37': 21.06795686674759, 'IoU-38': 21.433603093051133, 'IoU-39': 21.175979219948513, 'IoU-40': 21.19482316457794, 'IoU-41': 19.847685403691496, 'IoU-42': 19.389402862633645, 'IoU-43': 18.89917413389217, 'IoU-44': 18.94421008112544, 'IoU-45': 18.307296777232366, 'IoU-46': 17.37601172986466, 'IoU-47': 17.190910502460387, 'IoU-48': 16.86096705897557, 'IoU-49': 16.615887732937065, 'IoU-50': 16.521802992727615, 'IoU-51': 15.695559554975237, 'IoU-52': 15.098705358416709, 'IoU-53': 14.87202419356497, 'IoU-54': 14.987482972100516, 'IoU-55': 14.321116129280153, 'IoU-56': 13.720286991103043, 'IoU-57': 13.847382102263648, 'IoU-58': 13.160468109154571, 'IoU-59': 12.695747263732326, 'IoU-60': 12.355660551875, 'IoU-61': 11.897177425641042, 'IoU-62': 11.512528919475464, 'IoU-63': 11.143850379117403, 'IoU-64': 11.30540304669721, 'IoU-65': 10.816887404998578, 'IoU-66': 10.649977821709918, 'IoU-67': 10.228151717179673, 'IoU-68': 9.833977075698048, 'IoU-69': 9.674018456511863, 'IoU-70': 9.896766108484112, 'IoU-71': 9.604670871989441, 'IoU-72': 9.377043572225316, 'IoU-73': 9.020075841893819, 'IoU-74': 9.197812317465285, 'IoU-75': 8.925286093445703, 'IoU-76': 9.136954880762444, 'IoU-77': 8.951468609682545, 'IoU-78': 8.697078156143675, 'IoU-79': 8.506780461170631, 'IoU-80': 8.556607794308455, 'IoU-81': 8.665928857837098, 'IoU-82': 8.669237443719286, 'IoU-83': 8.48880068853534, 'IoU-84': 8.334534723094311, 'IoU-85': 8.516974549788008, 'IoU-86': 8.35464745394804, 'IoU-87': 8.294463642720917, 'IoU-88': 8.278189275252124, 'IoU-89': 8.447835576064671, 'IoU-90': 8.299768761581278, 'IoU-91': 8.212202463018883, 'IoU-92': 7.781505296884007, 'IoU-93': 7.983781454193366, 'IoU-94': 7.820521888235145, 'IoU-95': 7.5544239204899055, 'IoU-96': 7.451894461436148, 'IoU-97': 7.56078360636971, 'IoU-98': 7.533458122347923, 'IoU-99': 7.328993823460288, 'IoU-100': 7.113440683983137, 'IoU-101': 7.300342427924445, 'IoU-102': 6.840217865495202, 'IoU-103': 6.78912979154847, 'IoU-104': 6.648402788188984, 'IoU-105': 6.275562030154832, 'IoU-106': 6.101998152924258, 'IoU-107': 6.316790791284137, 'IoU-108': 6.266170871073987, 'IoU-109': 6.283837683890823, 'IoU-110': 6.271629118022282, 'IoU-111': 6.223694681915889, 'IoU-112': 6.137372635264173, 'IoU-113': 6.286249000586768, 'IoU-114': 6.086238858960103, 'IoU-115': 5.952856620051235, 'IoU-116': 5.7314607886241395, 'IoU-117': 5.751196855897737, 'IoU-118': 5.564362145306189, 'IoU-119': 5.365801780095604, 'IoU-120': 5.248263889302159, 'IoU-121': 5.481712994857799, 'IoU-122': 5.535580650929945, 'IoU-123': 5.282821810203678, 'IoU-124': 5.037393141618364, 'IoU-125': 5.002836185426621, 'IoU-126': 5.110494793479197, 'IoU-127': 4.898535211741372, 'IoU-128': 4.642407942292109, 'IoU-129': 4.362417949023394, 'IoU-130': 4.42019633385749, 'IoU-131': 4.552106568969912, 'IoU-132': 4.19428403911484, 'IoU-133': 4.152612127559176, 'IoU-134': 4.2598069800379275, 'IoU-135': 4.12854941733912, 'IoU-136': 4.211413962152776, 'IoU-137': 4.0994671545411965, 'IoU-138': 4.124083323588861, 'IoU-139': 3.994120231924185, 'IoU-140': 3.9727994762964, 'IoU-141': 3.6978751539743495, 'IoU-142': 3.7866064266889294, 'IoU-143': 4.050987439539641, 'IoU-144': 3.985081412792154, 'IoU-145': 3.8400737036424077, 'IoU-146': 3.9066721557119495, 'IoU-147': 3.6855094470980223, 'IoU-148': 3.3880020629168115, 'IoU-149': 3.1054168443846586, 'IoU-150': 3.0241666904205244, 'IoU-151': 2.8850887529806, 'IoU-152': 2.6177959684523424, 'IoU-153': 2.7352424204629178, 'IoU-154': 2.6894200368544814, 'IoU-155': 2.6900357026939306, 'IoU-156': 2.684264631329916, 'IoU-157': 2.763618322554585, 'IoU-158': 2.6107749475173163, 'IoU-159': 2.3491848784160534, 'IoU-160': 2.3737534112925864, 'IoU-161': 2.272502855401237, 'IoU-162': 2.283729433272395, 'IoU-163': 2.3482895444301817, 'IoU-164': 2.401906139641748, 'IoU-165': 2.4321430274549245, 'IoU-166': 2.4143011776460837, 'IoU-167': 2.3252219352267582, 'IoU-168': 2.4130987044134056, 'IoU-169': 2.411544560857515, 'IoU-170': 2.5776304331040736, 'IoU-171': 2.449867175876007, 'IoU-172': 2.4738193872458525, 'IoU-173': 2.527489849823875, 'IoU-174': 2.531447008369123, 'IoU-175': 2.5583633406120967, 'IoU-176': 2.684612026308246, 'IoU-177': 2.946173012375677, 'IoU-178': 2.6434966540393505, 'IoU-179': 3.3160604928444957, 'IoU-180': 3.120196917768938, 'IoU-181': 2.8048035069305097, 'IoU-182': 2.8159716984659258, 'IoU-183': 2.8657408494840118, 'IoU-184': 2.9854945285612455, 'IoU-185': 2.93142491608712, 'IoU-186': 2.77820946927063, 'IoU-187': 3.10660000659428, 'IoU-188': 2.480653904761538, 'IoU-189': 2.7391454856339625, 'IoU-190': 2.4231787461387344, 'IoU-191': 2.678939718331991, 'IoU-192': 0.7129738485959941, 'mACC': 16.87231711085059, 'pACC': 34.224384452266484, 'ACC-0': nan, 'ACC-1': 68.51712496352626, 'ACC-2': 6.01769675884838, 'ACC-3': 16.59279816799961, 'ACC-4': 16.835157703050807, 'ACC-5': 17.9866265389186, 'ACC-6': 17.488018184420795, 'ACC-7': 15.59100969549792, 'ACC-8': 16.960814686747348, 'ACC-9': 30.415966300901225, 'ACC-10': 40.63796162492472, 'ACC-11': 42.72876756624874, 'ACC-12': 42.1801314718874, 'ACC-13': 41.84417228017456, 'ACC-14': 41.02697468328142, 'ACC-15': 39.39372248561841, 'ACC-16': 43.48753425110634, 'ACC-17': 39.44248044135767, 'ACC-18': 37.418450558750806, 'ACC-19': 36.26351507881782, 'ACC-20': 37.14011589009188, 'ACC-21': 35.973901500009156, 'ACC-22': 36.154658764196476, 'ACC-23': 35.59640703859754, 'ACC-24': 35.693738337074436, 'ACC-25': 34.45795760499431, 'ACC-26': 34.28388753608292, 'ACC-27': 35.42219673407773, 'ACC-28': 37.31710646745947, 'ACC-29': 36.76361878117521, 'ACC-30': 36.81370038757097, 'ACC-31': 37.02733850938672, 'ACC-32': 37.87863892054238, 'ACC-33': 36.721857949049756, 'ACC-34': 36.74386879864945, 'ACC-35': 37.343252056534624, 'ACC-36': 37.03274375257996, 'ACC-37': 35.421920447917785, 'ACC-38': 35.76679096918319, 'ACC-39': 35.88945812820178, 'ACC-40': 35.79028597808868, 'ACC-41': 34.46619664380707, 'ACC-42': 33.60540327611635, 'ACC-43': 32.72874351128424, 'ACC-44': 32.165509268097544, 'ACC-45': 31.14203867616497, 'ACC-46': 30.289176359719423, 'ACC-47': 30.00649952004429, 'ACC-48': 29.43659638324355, 'ACC-49': 28.950681500683107, 'ACC-50': 28.541657699164958, 'ACC-51': 27.410917657431327, 'ACC-52': 26.160306835546766, 'ACC-53': 25.97765680815976, 'ACC-54': 26.20518626987306, 'ACC-55': 25.16473655199593, 'ACC-56': 24.458059334223964, 'ACC-57': 24.421570379323878, 'ACC-58': 23.38407632353051, 'ACC-59': 22.802736199985972, 'ACC-60': 22.302148959905175, 'ACC-61': 21.339361791636392, 'ACC-62': 20.62446772891742, 'ACC-63': 20.226029155912858, 'ACC-64': 20.499083834144358, 'ACC-65': 19.715483605166856, 'ACC-66': 19.376522619705145, 'ACC-67': 18.74435406241939, 'ACC-68': 18.045601853924385, 'ACC-69': 17.442126867604298, 'ACC-70': 17.81245194668099, 'ACC-71': 17.608918208044845, 'ACC-72': 17.228653112351854, 'ACC-73': 16.400637947395193, 'ACC-74': 16.600396044263103, 'ACC-75': 16.287075247423118, 'ACC-76': 16.5280024773793, 'ACC-77': 16.46862819542396, 'ACC-78': 16.06538306165816, 'ACC-79': 15.690962371897044, 'ACC-80': 15.61157732230881, 'ACC-81': 15.767946753357553, 'ACC-82': 15.816510796943916, 'ACC-83': 15.268068316372066, 'ACC-84': 15.054508822885937, 'ACC-85': 15.383738536749753, 'ACC-86': 15.163878293856174, 'ACC-87': 15.067404937731165, 'ACC-88': 15.043960604501358, 'ACC-89': 15.32790740672168, 'ACC-90': 14.940605713856947, 'ACC-91': 14.938026633456719, 'ACC-92': 14.207015273166384, 'ACC-93': 14.606202114317647, 'ACC-94': 14.357707437763198, 'ACC-95': 13.874740689207949, 'ACC-96': 13.719066977148046, 'ACC-97': 13.75022278515601, 'ACC-98': 13.677753769091886, 'ACC-99': 13.38036588818172, 'ACC-100': 12.930250813568861, 'ACC-101': 13.352754865699975, 'ACC-102': 12.525051008225205, 'ACC-103': 12.402241523151394, 'ACC-104': 12.204102210963823, 'ACC-105': 11.499096806554174, 'ACC-106': 11.09534272251718, 'ACC-107': 11.468001688358594, 'ACC-108': 11.298666520009938, 'ACC-109': 11.357778996800773, 'ACC-110': 11.496735035163823, 'ACC-111': 11.411237210036978, 'ACC-112': 11.403607113328382, 'ACC-113': 11.76212546012855, 'ACC-114': 11.505151062482941, 'ACC-115': 11.188489468224256, 'ACC-116': 10.856701321037399, 'ACC-117': 10.804153570564651, 'ACC-118': 10.420007246933594, 'ACC-119': 9.975908595917629, 'ACC-120': 9.684329724468247, 'ACC-121': 10.155585008534601, 'ACC-122': 10.353581099568816, 'ACC-123': 9.913375398929084, 'ACC-124': 9.66058832209881, 'ACC-125': 9.492496435031647, 'ACC-126': 9.863705498228581, 'ACC-127': 9.526243119737591, 'ACC-128': 9.111698994134585, 'ACC-129': 8.479824091859793, 'ACC-130': 8.495123090059668, 'ACC-131': 8.74631906549621, 'ACC-132': 8.035574857663708, 'ACC-133': 7.9160001333633625, 'ACC-134': 8.123464024127532, 'ACC-135': 7.920443532295764, 'ACC-136': 7.998276183376817, 'ACC-137': 7.815581552965313, 'ACC-138': 7.833139657093905, 'ACC-139': 7.578501549084119, 'ACC-140': 7.388845544131313, 'ACC-141': 6.871720038105625, 'ACC-142': 7.070540346758819, 'ACC-143': 7.6162868018388785, 'ACC-144': 7.396480144404332, 'ACC-145': 6.994253002079653, 'ACC-146': 7.102445372307225, 'ACC-147': 6.567077977609259, 'ACC-148': 5.988507768425356, 'ACC-149': 5.567308277386772, 'ACC-150': 5.418572363675782, 'ACC-151': 5.109152201322211, 'ACC-152': 4.5497123963040895, 'ACC-153': 4.871968403489908, 'ACC-154': 4.817146627903427, 'ACC-155': 4.852375282566306, 'ACC-156': 4.928515007388312, 'ACC-157': 5.1404025267146585, 'ACC-158': 4.923488614326725, 'ACC-159': 4.392533699295107, 'ACC-160': 4.375698106805039, 'ACC-161': 4.104324088259538, 'ACC-162': 4.181668323047901, 'ACC-163': 4.360436227091274, 'ACC-164': 4.4758132292264605, 'ACC-165': 4.455821430386825, 'ACC-166': 4.479551843306365, 'ACC-167': 4.339401985504048, 'ACC-168': 4.48069901437285, 'ACC-169': 4.412624350271478, 'ACC-170': 4.682622822748176, 'ACC-171': 4.485406162516474, 'ACC-172': 4.520859015117109, 'ACC-173': 4.710608237773379, 'ACC-174': 4.606624389679639, 'ACC-175': 4.589612446707721, 'ACC-176': 4.81339752891798, 'ACC-177': 5.289934243242693, 'ACC-178': 4.905176901832594, 'ACC-179': 6.2267166631419695, 'ACC-180': 5.776147988975569, 'ACC-181': 5.397646935812344, 'ACC-182': 5.191070465180946, 'ACC-183': 4.89907078036498, 'ACC-184': 4.843343919748197, 'ACC-185': 4.638525752086943, 'ACC-186': 4.190234466560755, 'ACC-187': 4.339195035933732, 'ACC-188': 3.2601320559820146, 'ACC-189': 3.3727283295229977, 'ACC-190': 2.826178724940729, 'ACC-191': 2.922787617731203, 'ACC-192': 0.7586238701346615})])
[01/27 15:53:47] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 15:53:47] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 15:53:47] d2.evaluation.testing INFO: copypaste: 2.3678,0.3069,0.1318,9.6914,23.2787,16.8723,34.2244
[01/27 15:53:47] d2.utils.events INFO:  eta: 1 day, 1:14:26  iter: 19999  total_loss: 25.49  loss_mask: 2.546  loss_mask_0: 2.59  loss_mask_1: 2.545  loss_mask_2: 2.545  loss_mask_3: 2.545  loss_mask_4: 2.545  loss_mask_5: 2.545  loss_mask_6: 2.545  loss_mask_7: 2.545  loss_mask_8: 2.544  time: 1.9328  data_time: 0.4388  lr: 6.9427e-05  max_mem: 17484M
[01/27 15:54:33] d2.utils.events INFO:  eta: 1 day, 1:13:59  iter: 20019  total_loss: 24.19  loss_mask: 2.412  loss_mask_0: 2.482  loss_mask_1: 2.412  loss_mask_2: 2.412  loss_mask_3: 2.412  loss_mask_4: 2.412  loss_mask_5: 2.412  loss_mask_6: 2.412  loss_mask_7: 2.413  loss_mask_8: 2.413  time: 1.9332  data_time: 0.4297  lr: 6.9396e-05  max_mem: 17484M
[01/27 15:55:19] d2.utils.events INFO:  eta: 1 day, 1:13:51  iter: 20039  total_loss: 25.2  loss_mask: 2.513  loss_mask_0: 2.582  loss_mask_1: 2.513  loss_mask_2: 2.513  loss_mask_3: 2.513  loss_mask_4: 2.513  loss_mask_5: 2.513  loss_mask_6: 2.513  loss_mask_7: 2.513  loss_mask_8: 2.513  time: 1.9335  data_time: 0.4442  lr: 6.9364e-05  max_mem: 17484M
[01/27 15:56:06] d2.utils.events INFO:  eta: 1 day, 1:13:33  iter: 20059  total_loss: 24.74  loss_mask: 2.465  loss_mask_0: 2.551  loss_mask_1: 2.465  loss_mask_2: 2.464  loss_mask_3: 2.464  loss_mask_4: 2.465  loss_mask_5: 2.467  loss_mask_6: 2.465  loss_mask_7: 2.466  loss_mask_8: 2.466  time: 1.9339  data_time: 0.4388  lr: 6.9333e-05  max_mem: 17484M
[01/27 15:56:52] d2.utils.events INFO:  eta: 1 day, 1:13:07  iter: 20079  total_loss: 24.64  loss_mask: 2.46  loss_mask_0: 2.508  loss_mask_1: 2.459  loss_mask_2: 2.46  loss_mask_3: 2.46  loss_mask_4: 2.46  loss_mask_5: 2.459  loss_mask_6: 2.459  loss_mask_7: 2.459  loss_mask_8: 2.459  time: 1.9343  data_time: 0.4630  lr: 6.9302e-05  max_mem: 17484M
[01/27 15:57:39] d2.utils.events INFO:  eta: 1 day, 1:12:32  iter: 20099  total_loss: 25.13  loss_mask: 2.509  loss_mask_0: 2.553  loss_mask_1: 2.508  loss_mask_2: 2.509  loss_mask_3: 2.508  loss_mask_4: 2.509  loss_mask_5: 2.509  loss_mask_6: 2.508  loss_mask_7: 2.509  loss_mask_8: 2.509  time: 1.9347  data_time: 0.4218  lr: 6.9271e-05  max_mem: 17484M
[01/27 15:58:25] d2.utils.events INFO:  eta: 1 day, 1:13:05  iter: 20119  total_loss: 24.45  loss_mask: 2.439  loss_mask_0: 2.504  loss_mask_1: 2.439  loss_mask_2: 2.439  loss_mask_3: 2.438  loss_mask_4: 2.439  loss_mask_5: 2.439  loss_mask_6: 2.438  loss_mask_7: 2.439  loss_mask_8: 2.439  time: 1.9351  data_time: 0.4556  lr: 6.9239e-05  max_mem: 17484M
[01/27 15:59:11] d2.utils.events INFO:  eta: 1 day, 1:12:49  iter: 20139  total_loss: 24.63  loss_mask: 2.461  loss_mask_0: 2.486  loss_mask_1: 2.461  loss_mask_2: 2.461  loss_mask_3: 2.461  loss_mask_4: 2.461  loss_mask_5: 2.46  loss_mask_6: 2.462  loss_mask_7: 2.461  loss_mask_8: 2.461  time: 1.9354  data_time: 0.4441  lr: 6.9208e-05  max_mem: 17500M
[01/27 15:59:57] d2.utils.events INFO:  eta: 1 day, 1:12:58  iter: 20159  total_loss: 26.26  loss_mask: 2.623  loss_mask_0: 2.657  loss_mask_1: 2.622  loss_mask_2: 2.623  loss_mask_3: 2.623  loss_mask_4: 2.623  loss_mask_5: 2.623  loss_mask_6: 2.623  loss_mask_7: 2.622  loss_mask_8: 2.623  time: 1.9358  data_time: 0.4444  lr: 6.9177e-05  max_mem: 17500M
[01/27 16:00:44] d2.utils.events INFO:  eta: 1 day, 1:12:58  iter: 20179  total_loss: 26.41  loss_mask: 2.639  loss_mask_0: 2.654  loss_mask_1: 2.638  loss_mask_2: 2.639  loss_mask_3: 2.638  loss_mask_4: 2.638  loss_mask_5: 2.639  loss_mask_6: 2.639  loss_mask_7: 2.639  loss_mask_8: 2.639  time: 1.9362  data_time: 0.4515  lr: 6.9146e-05  max_mem: 17500M
[01/27 16:01:29] d2.utils.events INFO:  eta: 1 day, 1:12:48  iter: 20199  total_loss: 24.05  loss_mask: 2.401  loss_mask_0: 2.436  loss_mask_1: 2.401  loss_mask_2: 2.401  loss_mask_3: 2.401  loss_mask_4: 2.401  loss_mask_5: 2.401  loss_mask_6: 2.401  loss_mask_7: 2.401  loss_mask_8: 2.401  time: 1.9365  data_time: 0.4387  lr: 6.9114e-05  max_mem: 17500M
[01/27 16:02:15] d2.utils.events INFO:  eta: 1 day, 1:12:02  iter: 20219  total_loss: 25.19  loss_mask: 2.516  loss_mask_0: 2.562  loss_mask_1: 2.516  loss_mask_2: 2.516  loss_mask_3: 2.516  loss_mask_4: 2.517  loss_mask_5: 2.516  loss_mask_6: 2.515  loss_mask_7: 2.516  loss_mask_8: 2.516  time: 1.9369  data_time: 0.4396  lr: 6.9083e-05  max_mem: 17500M
[01/27 16:03:01] d2.utils.events INFO:  eta: 1 day, 1:11:25  iter: 20239  total_loss: 24.85  loss_mask: 2.479  loss_mask_0: 2.535  loss_mask_1: 2.479  loss_mask_2: 2.48  loss_mask_3: 2.479  loss_mask_4: 2.48  loss_mask_5: 2.479  loss_mask_6: 2.479  loss_mask_7: 2.479  loss_mask_8: 2.479  time: 1.9372  data_time: 0.4239  lr: 6.9052e-05  max_mem: 17500M
[01/27 16:03:47] d2.utils.events INFO:  eta: 1 day, 1:10:41  iter: 20259  total_loss: 25.78  loss_mask: 2.577  loss_mask_0: 2.615  loss_mask_1: 2.576  loss_mask_2: 2.576  loss_mask_3: 2.576  loss_mask_4: 2.576  loss_mask_5: 2.576  loss_mask_6: 2.576  loss_mask_7: 2.577  loss_mask_8: 2.577  time: 1.9376  data_time: 0.4435  lr: 6.9021e-05  max_mem: 17500M
[01/27 16:04:33] d2.utils.events INFO:  eta: 1 day, 1:10:10  iter: 20279  total_loss: 25.24  loss_mask: 2.519  loss_mask_0: 2.575  loss_mask_1: 2.52  loss_mask_2: 2.52  loss_mask_3: 2.52  loss_mask_4: 2.52  loss_mask_5: 2.52  loss_mask_6: 2.52  loss_mask_7: 2.52  loss_mask_8: 2.52  time: 1.9379  data_time: 0.4186  lr: 6.8989e-05  max_mem: 17500M
[01/27 16:05:19] d2.utils.events INFO:  eta: 1 day, 1:09:29  iter: 20299  total_loss: 25.83  loss_mask: 2.578  loss_mask_0: 2.593  loss_mask_1: 2.578  loss_mask_2: 2.578  loss_mask_3: 2.578  loss_mask_4: 2.577  loss_mask_5: 2.577  loss_mask_6: 2.578  loss_mask_7: 2.578  loss_mask_8: 2.578  time: 1.9383  data_time: 0.4533  lr: 6.8958e-05  max_mem: 17500M
[01/27 16:06:05] d2.utils.events INFO:  eta: 1 day, 1:08:44  iter: 20319  total_loss: 25.1  loss_mask: 2.506  loss_mask_0: 2.544  loss_mask_1: 2.507  loss_mask_2: 2.507  loss_mask_3: 2.507  loss_mask_4: 2.507  loss_mask_5: 2.506  loss_mask_6: 2.506  loss_mask_7: 2.506  loss_mask_8: 2.506  time: 1.9387  data_time: 0.4222  lr: 6.8927e-05  max_mem: 17500M
[01/27 16:06:51] d2.utils.events INFO:  eta: 1 day, 1:08:33  iter: 20339  total_loss: 24.71  loss_mask: 2.465  loss_mask_0: 2.51  loss_mask_1: 2.465  loss_mask_2: 2.465  loss_mask_3: 2.466  loss_mask_4: 2.466  loss_mask_5: 2.466  loss_mask_6: 2.465  loss_mask_7: 2.466  loss_mask_8: 2.466  time: 1.9390  data_time: 0.4356  lr: 6.8896e-05  max_mem: 17500M
[01/27 16:07:37] d2.utils.events INFO:  eta: 1 day, 1:08:08  iter: 20359  total_loss: 24.97  loss_mask: 2.491  loss_mask_0: 2.544  loss_mask_1: 2.49  loss_mask_2: 2.491  loss_mask_3: 2.49  loss_mask_4: 2.49  loss_mask_5: 2.49  loss_mask_6: 2.49  loss_mask_7: 2.49  loss_mask_8: 2.49  time: 1.9394  data_time: 0.4273  lr: 6.8864e-05  max_mem: 17500M
[01/27 16:08:24] d2.utils.events INFO:  eta: 1 day, 1:07:31  iter: 20379  total_loss: 26.39  loss_mask: 2.634  loss_mask_0: 2.686  loss_mask_1: 2.633  loss_mask_2: 2.634  loss_mask_3: 2.633  loss_mask_4: 2.634  loss_mask_5: 2.634  loss_mask_6: 2.633  loss_mask_7: 2.635  loss_mask_8: 2.635  time: 1.9397  data_time: 0.4480  lr: 6.8833e-05  max_mem: 17500M
[01/27 16:09:09] d2.utils.events INFO:  eta: 1 day, 1:07:34  iter: 20399  total_loss: 24.26  loss_mask: 2.42  loss_mask_0: 2.487  loss_mask_1: 2.419  loss_mask_2: 2.42  loss_mask_3: 2.419  loss_mask_4: 2.42  loss_mask_5: 2.42  loss_mask_6: 2.419  loss_mask_7: 2.42  loss_mask_8: 2.42  time: 1.9401  data_time: 0.4272  lr: 6.8802e-05  max_mem: 17500M
[01/27 16:09:55] d2.utils.events INFO:  eta: 1 day, 1:07:05  iter: 20419  total_loss: 24.77  loss_mask: 2.472  loss_mask_0: 2.538  loss_mask_1: 2.471  loss_mask_2: 2.471  loss_mask_3: 2.472  loss_mask_4: 2.471  loss_mask_5: 2.471  loss_mask_6: 2.472  loss_mask_7: 2.472  loss_mask_8: 2.472  time: 1.9404  data_time: 0.4110  lr: 6.877e-05  max_mem: 17500M
[01/27 16:10:41] d2.utils.events INFO:  eta: 1 day, 1:06:17  iter: 20439  total_loss: 24.92  loss_mask: 2.486  loss_mask_0: 2.543  loss_mask_1: 2.487  loss_mask_2: 2.486  loss_mask_3: 2.487  loss_mask_4: 2.486  loss_mask_5: 2.486  loss_mask_6: 2.486  loss_mask_7: 2.486  loss_mask_8: 2.486  time: 1.9407  data_time: 0.4131  lr: 6.8739e-05  max_mem: 17500M
[01/27 16:11:26] d2.utils.events INFO:  eta: 1 day, 1:04:55  iter: 20459  total_loss: 25.54  loss_mask: 2.551  loss_mask_0: 2.587  loss_mask_1: 2.55  loss_mask_2: 2.55  loss_mask_3: 2.55  loss_mask_4: 2.55  loss_mask_5: 2.55  loss_mask_6: 2.55  loss_mask_7: 2.55  loss_mask_8: 2.55  time: 1.9411  data_time: 0.3905  lr: 6.8708e-05  max_mem: 17500M
[01/27 16:12:11] d2.utils.events INFO:  eta: 1 day, 1:03:50  iter: 20479  total_loss: 25.31  loss_mask: 2.528  loss_mask_0: 2.558  loss_mask_1: 2.528  loss_mask_2: 2.528  loss_mask_3: 2.527  loss_mask_4: 2.528  loss_mask_5: 2.528  loss_mask_6: 2.528  loss_mask_7: 2.529  loss_mask_8: 2.528  time: 1.9414  data_time: 0.4139  lr: 6.8677e-05  max_mem: 17500M
[01/27 16:12:55] d2.utils.events INFO:  eta: 1 day, 1:02:07  iter: 20499  total_loss: 24.11  loss_mask: 2.408  loss_mask_0: 2.436  loss_mask_1: 2.408  loss_mask_2: 2.408  loss_mask_3: 2.408  loss_mask_4: 2.408  loss_mask_5: 2.408  loss_mask_6: 2.408  loss_mask_7: 2.409  loss_mask_8: 2.409  time: 1.9416  data_time: 0.3903  lr: 6.8645e-05  max_mem: 17500M
[01/27 16:13:40] d2.utils.events INFO:  eta: 1 day, 1:00:12  iter: 20519  total_loss: 23.28  loss_mask: 2.324  loss_mask_0: 2.365  loss_mask_1: 2.323  loss_mask_2: 2.324  loss_mask_3: 2.324  loss_mask_4: 2.324  loss_mask_5: 2.323  loss_mask_6: 2.324  loss_mask_7: 2.324  loss_mask_8: 2.324  time: 1.9419  data_time: 0.3955  lr: 6.8614e-05  max_mem: 17500M
[01/27 16:14:26] d2.utils.events INFO:  eta: 1 day, 0:59:32  iter: 20539  total_loss: 27.19  loss_mask: 2.716  loss_mask_0: 2.736  loss_mask_1: 2.717  loss_mask_2: 2.718  loss_mask_3: 2.716  loss_mask_4: 2.717  loss_mask_5: 2.718  loss_mask_6: 2.716  loss_mask_7: 2.717  loss_mask_8: 2.717  time: 1.9422  data_time: 0.4362  lr: 6.8583e-05  max_mem: 17500M
[01/27 16:15:12] d2.utils.events INFO:  eta: 1 day, 0:58:56  iter: 20559  total_loss: 26.76  loss_mask: 2.671  loss_mask_0: 2.72  loss_mask_1: 2.67  loss_mask_2: 2.672  loss_mask_3: 2.668  loss_mask_4: 2.67  loss_mask_5: 2.67  loss_mask_6: 2.668  loss_mask_7: 2.671  loss_mask_8: 2.671  time: 1.9426  data_time: 0.4324  lr: 6.8552e-05  max_mem: 17500M
[01/27 16:15:58] d2.utils.events INFO:  eta: 1 day, 0:58:13  iter: 20579  total_loss: 25.04  loss_mask: 2.499  loss_mask_0: 2.542  loss_mask_1: 2.499  loss_mask_2: 2.5  loss_mask_3: 2.497  loss_mask_4: 2.5  loss_mask_5: 2.498  loss_mask_6: 2.498  loss_mask_7: 2.499  loss_mask_8: 2.5  time: 1.9430  data_time: 0.4257  lr: 6.852e-05  max_mem: 17500M
[01/27 16:16:45] d2.utils.events INFO:  eta: 1 day, 0:57:41  iter: 20599  total_loss: 26.2  loss_mask: 2.62  loss_mask_0: 2.626  loss_mask_1: 2.62  loss_mask_2: 2.62  loss_mask_3: 2.62  loss_mask_4: 2.62  loss_mask_5: 2.62  loss_mask_6: 2.619  loss_mask_7: 2.619  loss_mask_8: 2.619  time: 1.9433  data_time: 0.4327  lr: 6.8489e-05  max_mem: 17500M
[01/27 16:17:32] d2.utils.events INFO:  eta: 1 day, 0:57:12  iter: 20619  total_loss: 26.9  loss_mask: 2.689  loss_mask_0: 2.719  loss_mask_1: 2.686  loss_mask_2: 2.687  loss_mask_3: 2.687  loss_mask_4: 2.688  loss_mask_5: 2.686  loss_mask_6: 2.686  loss_mask_7: 2.686  loss_mask_8: 2.687  time: 1.9437  data_time: 0.4225  lr: 6.8458e-05  max_mem: 17500M
[01/27 16:18:19] d2.utils.events INFO:  eta: 1 day, 0:57:49  iter: 20639  total_loss: 27.47  loss_mask: 2.744  loss_mask_0: 2.778  loss_mask_1: 2.743  loss_mask_2: 2.744  loss_mask_3: 2.744  loss_mask_4: 2.745  loss_mask_5: 2.743  loss_mask_6: 2.743  loss_mask_7: 2.743  loss_mask_8: 2.743  time: 1.9441  data_time: 0.4321  lr: 6.8426e-05  max_mem: 17500M
[01/27 16:19:05] d2.utils.events INFO:  eta: 1 day, 0:57:48  iter: 20659  total_loss: 28.15  loss_mask: 2.813  loss_mask_0: 2.841  loss_mask_1: 2.811  loss_mask_2: 2.811  loss_mask_3: 2.812  loss_mask_4: 2.811  loss_mask_5: 2.813  loss_mask_6: 2.812  loss_mask_7: 2.812  loss_mask_8: 2.811  time: 1.9445  data_time: 0.4333  lr: 6.8395e-05  max_mem: 17500M
[01/27 16:19:53] d2.utils.events INFO:  eta: 1 day, 0:57:53  iter: 20679  total_loss: 24.96  loss_mask: 2.493  loss_mask_0: 2.509  loss_mask_1: 2.493  loss_mask_2: 2.493  loss_mask_3: 2.492  loss_mask_4: 2.493  loss_mask_5: 2.494  loss_mask_6: 2.493  loss_mask_7: 2.494  loss_mask_8: 2.494  time: 1.9449  data_time: 0.4345  lr: 6.8364e-05  max_mem: 17500M
[01/27 16:20:39] d2.utils.events INFO:  eta: 1 day, 0:57:43  iter: 20699  total_loss: 26.48  loss_mask: 2.645  loss_mask_0: 2.67  loss_mask_1: 2.644  loss_mask_2: 2.645  loss_mask_3: 2.645  loss_mask_4: 2.645  loss_mask_5: 2.645  loss_mask_6: 2.645  loss_mask_7: 2.645  loss_mask_8: 2.645  time: 1.9453  data_time: 0.4184  lr: 6.8332e-05  max_mem: 17500M
[01/27 16:21:26] d2.utils.events INFO:  eta: 1 day, 0:57:27  iter: 20719  total_loss: 29.26  loss_mask: 2.925  loss_mask_0: 2.928  loss_mask_1: 2.927  loss_mask_2: 2.927  loss_mask_3: 2.927  loss_mask_4: 2.927  loss_mask_5: 2.926  loss_mask_6: 2.926  loss_mask_7: 2.926  loss_mask_8: 2.932  time: 1.9457  data_time: 0.4219  lr: 6.8301e-05  max_mem: 17500M
[01/27 16:22:13] d2.utils.events INFO:  eta: 1 day, 0:57:06  iter: 20739  total_loss: 27.74  loss_mask: 2.773  loss_mask_0: 2.78  loss_mask_1: 2.771  loss_mask_2: 2.771  loss_mask_3: 2.771  loss_mask_4: 2.772  loss_mask_5: 2.771  loss_mask_6: 2.771  loss_mask_7: 2.789  loss_mask_8: 2.771  time: 1.9460  data_time: 0.4287  lr: 6.827e-05  max_mem: 17500M
[01/27 16:22:59] d2.utils.events INFO:  eta: 1 day, 0:56:40  iter: 20759  total_loss: 26.83  loss_mask: 2.683  loss_mask_0: 2.685  loss_mask_1: 2.682  loss_mask_2: 2.682  loss_mask_3: 2.684  loss_mask_4: 2.682  loss_mask_5: 2.682  loss_mask_6: 2.682  loss_mask_7: 2.684  loss_mask_8: 2.682  time: 1.9464  data_time: 0.4226  lr: 6.8239e-05  max_mem: 17500M
[01/27 16:23:46] d2.utils.events INFO:  eta: 1 day, 0:56:30  iter: 20779  total_loss: 28.86  loss_mask: 2.881  loss_mask_0: 2.931  loss_mask_1: 2.881  loss_mask_2: 2.88  loss_mask_3: 2.883  loss_mask_4: 2.879  loss_mask_5: 2.879  loss_mask_6: 2.881  loss_mask_7: 2.882  loss_mask_8: 2.881  time: 1.9468  data_time: 0.4265  lr: 6.8207e-05  max_mem: 17500M
[01/27 16:24:33] d2.utils.events INFO:  eta: 1 day, 0:56:48  iter: 20799  total_loss: 26.29  loss_mask: 2.627  loss_mask_0: 2.64  loss_mask_1: 2.628  loss_mask_2: 2.629  loss_mask_3: 2.622  loss_mask_4: 2.629  loss_mask_5: 2.629  loss_mask_6: 2.626  loss_mask_7: 2.629  loss_mask_8: 2.628  time: 1.9472  data_time: 0.4464  lr: 6.8176e-05  max_mem: 17500M
[01/27 16:25:20] d2.utils.events INFO:  eta: 1 day, 0:56:03  iter: 20819  total_loss: 26.96  loss_mask: 2.692  loss_mask_0: 2.728  loss_mask_1: 2.693  loss_mask_2: 2.693  loss_mask_3: 2.693  loss_mask_4: 2.693  loss_mask_5: 2.693  loss_mask_6: 2.693  loss_mask_7: 2.692  loss_mask_8: 2.692  time: 1.9475  data_time: 0.4230  lr: 6.8145e-05  max_mem: 17500M
[01/27 16:26:07] d2.utils.events INFO:  eta: 1 day, 0:57:11  iter: 20839  total_loss: 28.28  loss_mask: 2.827  loss_mask_0: 2.838  loss_mask_1: 2.827  loss_mask_2: 2.827  loss_mask_3: 2.825  loss_mask_4: 2.827  loss_mask_5: 2.827  loss_mask_6: 2.826  loss_mask_7: 2.828  loss_mask_8: 2.827  time: 1.9479  data_time: 0.4190  lr: 6.8113e-05  max_mem: 17500M
[01/27 16:26:54] d2.utils.events INFO:  eta: 1 day, 0:57:51  iter: 20859  total_loss: 25.98  loss_mask: 2.596  loss_mask_0: 2.606  loss_mask_1: 2.597  loss_mask_2: 2.597  loss_mask_3: 2.597  loss_mask_4: 2.597  loss_mask_5: 2.597  loss_mask_6: 2.596  loss_mask_7: 2.597  loss_mask_8: 2.596  time: 1.9483  data_time: 0.4365  lr: 6.8082e-05  max_mem: 17500M
[01/27 16:27:41] d2.utils.events INFO:  eta: 1 day, 0:58:41  iter: 20879  total_loss: 24.74  loss_mask: 2.472  loss_mask_0: 2.492  loss_mask_1: 2.471  loss_mask_2: 2.473  loss_mask_3: 2.471  loss_mask_4: 2.472  loss_mask_5: 2.472  loss_mask_6: 2.471  loss_mask_7: 2.472  loss_mask_8: 2.472  time: 1.9487  data_time: 0.4272  lr: 6.8051e-05  max_mem: 17500M
[01/27 16:28:28] d2.utils.events INFO:  eta: 1 day, 0:59:43  iter: 20899  total_loss: 26  loss_mask: 2.599  loss_mask_0: 2.61  loss_mask_1: 2.598  loss_mask_2: 2.599  loss_mask_3: 2.599  loss_mask_4: 2.599  loss_mask_5: 2.599  loss_mask_6: 2.599  loss_mask_7: 2.598  loss_mask_8: 2.599  time: 1.9490  data_time: 0.4377  lr: 6.8019e-05  max_mem: 17500M
[01/27 16:29:15] d2.utils.events INFO:  eta: 1 day, 1:01:09  iter: 20919  total_loss: 26.05  loss_mask: 2.601  loss_mask_0: 2.67  loss_mask_1: 2.601  loss_mask_2: 2.601  loss_mask_3: 2.602  loss_mask_4: 2.601  loss_mask_5: 2.601  loss_mask_6: 2.602  loss_mask_7: 2.601  loss_mask_8: 2.601  time: 1.9494  data_time: 0.4425  lr: 6.7988e-05  max_mem: 17500M
[01/27 16:30:01] d2.utils.events INFO:  eta: 1 day, 1:00:58  iter: 20939  total_loss: 24.88  loss_mask: 2.487  loss_mask_0: 2.494  loss_mask_1: 2.486  loss_mask_2: 2.487  loss_mask_3: 2.487  loss_mask_4: 2.487  loss_mask_5: 2.487  loss_mask_6: 2.487  loss_mask_7: 2.487  loss_mask_8: 2.487  time: 1.9498  data_time: 0.3907  lr: 6.7957e-05  max_mem: 17500M
[01/27 16:30:48] d2.utils.events INFO:  eta: 1 day, 1:00:46  iter: 20959  total_loss: 26.52  loss_mask: 2.647  loss_mask_0: 2.701  loss_mask_1: 2.647  loss_mask_2: 2.647  loss_mask_3: 2.647  loss_mask_4: 2.646  loss_mask_5: 2.647  loss_mask_6: 2.647  loss_mask_7: 2.647  loss_mask_8: 2.647  time: 1.9501  data_time: 0.3969  lr: 6.7925e-05  max_mem: 17500M
[01/27 16:31:35] d2.utils.events INFO:  eta: 1 day, 1:00:47  iter: 20979  total_loss: 24.89  loss_mask: 2.488  loss_mask_0: 2.491  loss_mask_1: 2.488  loss_mask_2: 2.488  loss_mask_3: 2.489  loss_mask_4: 2.488  loss_mask_5: 2.489  loss_mask_6: 2.49  loss_mask_7: 2.487  loss_mask_8: 2.488  time: 1.9505  data_time: 0.4353  lr: 6.7894e-05  max_mem: 17500M
[01/27 16:32:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 16:32:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 16:32:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 16:40:26] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.7279024128682927, 'error_1pix': 0.36316226587368095, 'error_3pix': 0.15191961508015556, 'mIoU': 7.054009075731534, 'fwIoU': 19.437815470195787, 'IoU-0': nan, 'IoU-1': 67.53235405196322, 'IoU-2': 2.945900293272074, 'IoU-3': 3.0235705748369077, 'IoU-4': 3.5596488048068378, 'IoU-5': 3.9767970705687543, 'IoU-6': 3.702433796806346, 'IoU-7': 2.5399576099074297, 'IoU-8': 6.305049124281761, 'IoU-9': 14.709193836233675, 'IoU-10': 16.379116745462643, 'IoU-11': 18.65493341114015, 'IoU-12': 19.363253562682967, 'IoU-13': 19.928028378332797, 'IoU-14': 21.104241109495778, 'IoU-15': 22.583664918395698, 'IoU-16': 23.24011508556826, 'IoU-17': 20.247917904044783, 'IoU-18': 20.759297850008355, 'IoU-19': 21.559393685053934, 'IoU-20': 21.460936015825784, 'IoU-21': 21.30637657810977, 'IoU-22': 22.10928726046873, 'IoU-23': 21.06257946003713, 'IoU-24': 21.065954981889277, 'IoU-25': 20.220212710757878, 'IoU-26': 19.93458138435413, 'IoU-27': 19.93673458803946, 'IoU-28': 18.084183691171347, 'IoU-29': 17.916307388458012, 'IoU-30': 17.239928856215954, 'IoU-31': 17.342242457795965, 'IoU-32': 16.134740942092712, 'IoU-33': 15.274370927086894, 'IoU-34': 14.55469824054928, 'IoU-35': 14.50037555301113, 'IoU-36': 14.043145981000313, 'IoU-37': 13.157617565784896, 'IoU-38': 13.187615740432374, 'IoU-39': 12.79485734368773, 'IoU-40': 12.279715240717477, 'IoU-41': 11.490739950500856, 'IoU-42': 10.620283928068439, 'IoU-43': 10.754257261257212, 'IoU-44': 10.865831276335975, 'IoU-45': 11.142629479308196, 'IoU-46': 10.886224913643854, 'IoU-47': 10.853334455967211, 'IoU-48': 11.191371406418039, 'IoU-49': 11.234841888416593, 'IoU-50': 11.785275175412758, 'IoU-51': 11.616887465240811, 'IoU-52': 11.582677701295122, 'IoU-53': 11.592124799524118, 'IoU-54': 11.74453094921577, 'IoU-55': 11.182847251431243, 'IoU-56': 11.055542681965523, 'IoU-57': 11.389068360261323, 'IoU-58': 10.973120246740388, 'IoU-59': 10.647874857306313, 'IoU-60': 10.415373796306266, 'IoU-61': 10.329367741186566, 'IoU-62': 10.364352338139375, 'IoU-63': 10.06621343563881, 'IoU-64': 9.695242458636805, 'IoU-65': 9.407613944030695, 'IoU-66': 9.225427617743449, 'IoU-67': 8.87070451887237, 'IoU-68': 8.475399814457617, 'IoU-69': 8.654089621813323, 'IoU-70': 8.646611235451964, 'IoU-71': 8.321238416757769, 'IoU-72': 8.081604741495912, 'IoU-73': 7.955751760713281, 'IoU-74': 8.187415255211086, 'IoU-75': 7.885736880330713, 'IoU-76': 7.809285542003433, 'IoU-77': 7.597364234723926, 'IoU-78': 7.125563219366404, 'IoU-79': 6.955662686847357, 'IoU-80': 7.061354122379901, 'IoU-81': 6.9524226013032555, 'IoU-82': 6.814384155469357, 'IoU-83': 6.842330394245767, 'IoU-84': 6.8157812803012146, 'IoU-85': 6.7748215760394705, 'IoU-86': 6.612859591447333, 'IoU-87': 6.305613671633509, 'IoU-88': 6.146862669645651, 'IoU-89': 6.309740988874609, 'IoU-90': 5.927057935837329, 'IoU-91': 5.812854442344046, 'IoU-92': 5.39517577333928, 'IoU-93': 5.5513747562242335, 'IoU-94': 5.227120702619902, 'IoU-95': 4.992656234845575, 'IoU-96': 5.109652090658295, 'IoU-97': 4.9178206168785685, 'IoU-98': 4.74980526257207, 'IoU-99': 4.537494427106554, 'IoU-100': 4.296824645635286, 'IoU-101': 4.257425305135749, 'IoU-102': 4.255055953966904, 'IoU-103': 4.067892780998722, 'IoU-104': 3.7999352363078063, 'IoU-105': 3.8282170038523433, 'IoU-106': 3.7578504860084356, 'IoU-107': 3.600585665803057, 'IoU-108': 3.641682377042066, 'IoU-109': 3.495634818279457, 'IoU-110': 3.6313292041750973, 'IoU-111': 3.543379322763189, 'IoU-112': 3.7362280208913337, 'IoU-113': 3.380720462687169, 'IoU-114': 3.343059791655324, 'IoU-115': 3.236256388212256, 'IoU-116': 3.3321853133210206, 'IoU-117': 3.2590474481523475, 'IoU-118': 3.22976150715406, 'IoU-119': 3.2948998066961916, 'IoU-120': 3.0521319705260845, 'IoU-121': 3.0066388352638747, 'IoU-122': 2.8120229397662304, 'IoU-123': 2.6498156433289606, 'IoU-124': 2.5645305113537433, 'IoU-125': 2.2487526130342657, 'IoU-126': 2.5472919774110263, 'IoU-127': 2.700935909215911, 'IoU-128': 2.3312859068382505, 'IoU-129': 2.501511105394105, 'IoU-130': 2.403574886163049, 'IoU-131': 2.1662488491339627, 'IoU-132': 2.0536488272077698, 'IoU-133': 1.9884765185846351, 'IoU-134': 1.9652896931823376, 'IoU-135': 1.9635211575723481, 'IoU-136': 1.9008398539426146, 'IoU-137': 1.792108950506108, 'IoU-138': 1.7239428873759102, 'IoU-139': 1.6918978682393102, 'IoU-140': 1.6423827894922842, 'IoU-141': 1.6349835967084614, 'IoU-142': 1.6617715751956437, 'IoU-143': 1.685699739984231, 'IoU-144': 1.6580088750464266, 'IoU-145': 1.8141750857426635, 'IoU-146': 1.6864756186480634, 'IoU-147': 1.666581150580727, 'IoU-148': 1.8416173057712384, 'IoU-149': 1.7312181704714429, 'IoU-150': 1.9621091736880931, 'IoU-151': 1.7457557879936538, 'IoU-152': 2.257081328635177, 'IoU-153': 1.8386541961195144, 'IoU-154': 1.86224597772771, 'IoU-155': 1.7843532613446476, 'IoU-156': 1.790356387770764, 'IoU-157': 1.9039794836496453, 'IoU-158': 1.673968970687683, 'IoU-159': 1.4999500071301306, 'IoU-160': 1.5870483302560645, 'IoU-161': 1.608333119616932, 'IoU-162': 1.5551859373301562, 'IoU-163': 1.5456698237906656, 'IoU-164': 1.43563256941903, 'IoU-165': 1.4433549964901158, 'IoU-166': 1.2857272205957806, 'IoU-167': 1.2338180394255398, 'IoU-168': 1.40658981244472, 'IoU-169': 1.6629295967954292, 'IoU-170': 1.4443238417918625, 'IoU-171': 1.0778564891705928, 'IoU-172': 0.9286170062808081, 'IoU-173': 0.8606624061033925, 'IoU-174': 0.8820614011779302, 'IoU-175': 0.8960941403204389, 'IoU-176': 0.8574064977126481, 'IoU-177': 0.7697529084232633, 'IoU-178': 0.6468567369116268, 'IoU-179': 0.6123346734700447, 'IoU-180': 1.0100141324401901, 'IoU-181': 0.3871330079789294, 'IoU-182': 0.29260194664759087, 'IoU-183': 0.1239124761221755, 'IoU-184': 0.0865759441904124, 'IoU-185': 0.04853279024989851, 'IoU-186': 0.026189518580528093, 'IoU-187': 0.029368646322058503, 'IoU-188': 0.010580224552670625, 'IoU-189': 0.005129980890821182, 'IoU-190': 0.005237466742086188, 'IoU-191': 0.004435376563470239, 'IoU-192': 0.0019803100599751046, 'mACC': 12.67938739092824, 'pACC': 28.651143943819633, 'ACC-0': nan, 'ACC-1': 68.80105367936966, 'ACC-2': 6.033893641946821, 'ACC-3': 14.967729710618807, 'ACC-4': 15.932158388278978, 'ACC-5': 18.39742567975974, 'ACC-6': 18.697323558172382, 'ACC-7': 16.519356356038813, 'ACC-8': 22.346088630829243, 'ACC-9': 33.78067169632758, 'ACC-10': 38.297833874251744, 'ACC-11': 32.277825065441355, 'ACC-12': 31.316282349302572, 'ACC-13': 31.445042434115116, 'ACC-14': 32.21428637186838, 'ACC-15': 35.436685098940174, 'ACC-16': 36.76198596394833, 'ACC-17': 33.79059888160429, 'ACC-18': 33.380019642574396, 'ACC-19': 34.74273479759424, 'ACC-20': 35.3481438519082, 'ACC-21': 35.1437806590539, 'ACC-22': 35.620377686905165, 'ACC-23': 35.350618043151286, 'ACC-24': 35.41227065037245, 'ACC-25': 34.523486170654245, 'ACC-26': 34.77151804089031, 'ACC-27': 34.21844862348512, 'ACC-28': 31.69464920411005, 'ACC-29': 30.82291612508618, 'ACC-30': 30.42339291245136, 'ACC-31': 30.039239485803222, 'ACC-32': 27.84749726351973, 'ACC-33': 26.86988026055821, 'ACC-34': 26.17385298570661, 'ACC-35': 26.040540911073585, 'ACC-36': 24.737405907528558, 'ACC-37': 23.321729202816734, 'ACC-38': 23.469005741747512, 'ACC-39': 22.923751553503074, 'ACC-40': 21.704531474499085, 'ACC-41': 21.002917811680856, 'ACC-42': 19.461463987427134, 'ACC-43': 19.633855141715507, 'ACC-44': 19.06602720780945, 'ACC-45': 19.45170213216017, 'ACC-46': 19.60505842580571, 'ACC-47': 19.41727033705019, 'ACC-48': 20.005573360698456, 'ACC-49': 19.941945439355376, 'ACC-50': 20.724846970073866, 'ACC-51': 20.567336199542193, 'ACC-52': 20.614873099524004, 'ACC-53': 20.793338671668703, 'ACC-54': 20.857403638117056, 'ACC-55': 19.97747475066657, 'ACC-56': 20.021559251641197, 'ACC-57': 20.260615497968118, 'ACC-58': 19.603343282721948, 'ACC-59': 19.15628125655657, 'ACC-60': 18.85768441273898, 'ACC-61': 18.7766354197829, 'ACC-62': 18.899782898698444, 'ACC-63': 18.54451559541781, 'ACC-64': 17.94555381653043, 'ACC-65': 17.626692292892727, 'ACC-66': 17.353745721129453, 'ACC-67': 16.856143044596372, 'ACC-68': 16.181818005301025, 'ACC-69': 16.200166104599294, 'ACC-70': 16.025397992679164, 'ACC-71': 15.723419116856597, 'ACC-72': 15.277380580107568, 'ACC-73': 15.053076834341846, 'ACC-74': 15.522782675530733, 'ACC-75': 15.05328483334225, 'ACC-76': 14.689846769345735, 'ACC-77': 14.471789096833227, 'ACC-78': 13.59531635687955, 'ACC-79': 13.288520007444754, 'ACC-80': 13.36507936156889, 'ACC-81': 13.091620434850535, 'ACC-82': 12.778496976477665, 'ACC-83': 12.65614915572807, 'ACC-84': 12.640097048739749, 'ACC-85': 12.563238535129587, 'ACC-86': 12.30461280681044, 'ACC-87': 11.822531122484435, 'ACC-88': 11.53604259992464, 'ACC-89': 11.765482194088198, 'ACC-90': 11.01459572179807, 'ACC-91': 10.830785752562118, 'ACC-92': 10.186779788803225, 'ACC-93': 10.465473103580763, 'ACC-94': 9.800061306261266, 'ACC-95': 9.252807167208635, 'ACC-96': 9.443886286278685, 'ACC-97': 9.016699513031455, 'ACC-98': 8.728464169638968, 'ACC-99': 8.341284797135467, 'ACC-100': 7.872662383316831, 'ACC-101': 7.870449179893771, 'ACC-102': 7.9097643860444045, 'ACC-103': 7.560664021913668, 'ACC-104': 7.09667740586803, 'ACC-105': 7.13232952399292, 'ACC-106': 6.956665164124538, 'ACC-107': 6.67328629427046, 'ACC-108': 6.667178859764202, 'ACC-109': 6.304730234463481, 'ACC-110': 6.6133942596718205, 'ACC-111': 6.506196877915535, 'ACC-112': 6.9271804070498, 'ACC-113': 6.3026557848323606, 'ACC-114': 6.310502526059613, 'ACC-115': 6.112263767985206, 'ACC-116': 6.293281936075185, 'ACC-117': 6.101169547876081, 'ACC-118': 5.984766324179776, 'ACC-119': 6.11540799052299, 'ACC-120': 5.633141469619822, 'ACC-121': 5.576466858373376, 'ACC-122': 5.225216300112278, 'ACC-123': 4.931819392937006, 'ACC-124': 4.919713963180458, 'ACC-125': 4.2994986746258, 'ACC-126': 4.8673599030956565, 'ACC-127': 5.11107710566401, 'ACC-128': 4.438516827236792, 'ACC-129': 4.783757614245848, 'ACC-130': 4.62093988541003, 'ACC-131': 4.174948976980993, 'ACC-132': 3.9249630545586154, 'ACC-133': 3.772955833622514, 'ACC-134': 3.617888841016803, 'ACC-135': 3.581822587081694, 'ACC-136': 3.4629204714871418, 'ACC-137': 3.2428216089395874, 'ACC-138': 3.142847171104399, 'ACC-139': 3.0799678295523765, 'ACC-140': 2.956167682921779, 'ACC-141': 2.9085786322729192, 'ACC-142': 2.9484018755332686, 'ACC-143': 2.9932075485261755, 'ACC-144': 2.9250000000000003, 'ACC-145': 3.1369216664057786, 'ACC-146': 2.9190103036256883, 'ACC-147': 2.8349670699242977, 'ACC-148': 3.1068836016504906, 'ACC-149': 2.962368759184195, 'ACC-150': 3.329445523233574, 'ACC-151': 2.9377064275916753, 'ACC-152': 3.749304572122193, 'ACC-153': 3.1192170981513034, 'ACC-154': 3.1512316433535643, 'ACC-155': 3.044275667241035, 'ACC-156': 3.0520920191070866, 'ACC-157': 3.2678582122460975, 'ACC-158': 2.910193297805076, 'ACC-159': 2.5946739857776366, 'ACC-160': 2.7282971224008223, 'ACC-161': 2.729898574880889, 'ACC-162': 2.6817831544684485, 'ACC-163': 2.700992254271463, 'ACC-164': 2.531404734611561, 'ACC-165': 2.5307710632891287, 'ACC-166': 2.288599978510798, 'ACC-167': 2.194860534722572, 'ACC-168': 2.4801540206239947, 'ACC-169': 2.9254717130117864, 'ACC-170': 2.52673946260202, 'ACC-171': 1.8691932124186728, 'ACC-172': 1.59836422331167, 'ACC-173': 1.4331003471274963, 'ACC-174': 1.4232003086862752, 'ACC-175': 1.396107317776656, 'ACC-176': 1.2759512040270282, 'ACC-177': 1.1134139341917553, 'ACC-178': 0.9005250165154202, 'ACC-179': 0.8105519869175489, 'ACC-180': 1.2676393207366659, 'ACC-181': 0.4735250015989464, 'ACC-182': 0.3324227052052704, 'ACC-183': 0.1330247473118406, 'ACC-184': 0.08962116191477972, 'ACC-185': 0.049427198817442716, 'ACC-186': 0.026439413611576687, 'ACC-187': 0.029476787030213707, 'ACC-188': 0.010593113467378254, 'ACC-189': 0.005134695910471442, 'ACC-190': 0.005240774271990944, 'ACC-191': 0.004437564768868134, 'ACC-192': 0.001981122730553158})])
[01/27 16:40:26] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 16:40:26] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 16:40:26] d2.evaluation.testing INFO: copypaste: 2.7279,0.3632,0.1519,7.0540,19.4378,12.6794,28.6511
[01/27 16:40:26] d2.utils.events INFO:  eta: 1 day, 1:01:08  iter: 20999  total_loss: 25.65  loss_mask: 2.565  loss_mask_0: 2.566  loss_mask_1: 2.564  loss_mask_2: 2.564  loss_mask_3: 2.564  loss_mask_4: 2.564  loss_mask_5: 2.564  loss_mask_6: 2.564  loss_mask_7: 2.565  loss_mask_8: 2.565  time: 1.9509  data_time: 0.4197  lr: 6.7863e-05  max_mem: 17500M
[01/27 16:41:14] d2.utils.events INFO:  eta: 1 day, 1:02:52  iter: 21019  total_loss: 26.55  loss_mask: 2.653  loss_mask_0: 2.677  loss_mask_1: 2.652  loss_mask_2: 2.653  loss_mask_3: 2.652  loss_mask_4: 2.653  loss_mask_5: 2.653  loss_mask_6: 2.653  loss_mask_7: 2.653  loss_mask_8: 2.653  time: 1.9513  data_time: 0.4438  lr: 6.7832e-05  max_mem: 17500M
[01/27 16:42:02] d2.utils.events INFO:  eta: 1 day, 1:02:44  iter: 21039  total_loss: 27.28  loss_mask: 2.724  loss_mask_0: 2.76  loss_mask_1: 2.724  loss_mask_2: 2.723  loss_mask_3: 2.721  loss_mask_4: 2.723  loss_mask_5: 2.722  loss_mask_6: 2.723  loss_mask_7: 2.725  loss_mask_8: 2.724  time: 1.9517  data_time: 0.4560  lr: 6.78e-05  max_mem: 17500M
[01/27 16:42:50] d2.utils.events INFO:  eta: 1 day, 1:02:24  iter: 21059  total_loss: 26.34  loss_mask: 2.632  loss_mask_0: 2.637  loss_mask_1: 2.632  loss_mask_2: 2.632  loss_mask_3: 2.632  loss_mask_4: 2.632  loss_mask_5: 2.632  loss_mask_6: 2.632  loss_mask_7: 2.632  loss_mask_8: 2.632  time: 1.9521  data_time: 0.4346  lr: 6.7769e-05  max_mem: 17500M
[01/27 16:43:36] d2.utils.events INFO:  eta: 1 day, 1:01:26  iter: 21079  total_loss: 25.33  loss_mask: 2.53  loss_mask_0: 2.554  loss_mask_1: 2.53  loss_mask_2: 2.53  loss_mask_3: 2.529  loss_mask_4: 2.531  loss_mask_5: 2.53  loss_mask_6: 2.53  loss_mask_7: 2.531  loss_mask_8: 2.53  time: 1.9525  data_time: 0.4321  lr: 6.7738e-05  max_mem: 17500M
[01/27 16:44:22] d2.utils.events INFO:  eta: 1 day, 1:00:12  iter: 21099  total_loss: 25.6  loss_mask: 2.555  loss_mask_0: 2.605  loss_mask_1: 2.555  loss_mask_2: 2.555  loss_mask_3: 2.555  loss_mask_4: 2.555  loss_mask_5: 2.557  loss_mask_6: 2.556  loss_mask_7: 2.554  loss_mask_8: 2.555  time: 1.9528  data_time: 0.4253  lr: 6.7706e-05  max_mem: 17500M
[01/27 16:45:08] d2.utils.events INFO:  eta: 1 day, 0:59:07  iter: 21119  total_loss: 26.65  loss_mask: 2.662  loss_mask_0: 2.667  loss_mask_1: 2.663  loss_mask_2: 2.662  loss_mask_3: 2.663  loss_mask_4: 2.662  loss_mask_5: 2.663  loss_mask_6: 2.662  loss_mask_7: 2.662  loss_mask_8: 2.662  time: 1.9532  data_time: 0.4062  lr: 6.7675e-05  max_mem: 17500M
[01/27 16:45:56] d2.utils.events INFO:  eta: 1 day, 0:58:53  iter: 21139  total_loss: 25.34  loss_mask: 2.532  loss_mask_0: 2.555  loss_mask_1: 2.532  loss_mask_2: 2.532  loss_mask_3: 2.532  loss_mask_4: 2.532  loss_mask_5: 2.532  loss_mask_6: 2.532  loss_mask_7: 2.532  loss_mask_8: 2.532  time: 1.9536  data_time: 0.4412  lr: 6.7644e-05  max_mem: 17500M
[01/27 16:46:43] d2.utils.events INFO:  eta: 1 day, 0:58:44  iter: 21159  total_loss: 23.46  loss_mask: 2.343  loss_mask_0: 2.371  loss_mask_1: 2.343  loss_mask_2: 2.343  loss_mask_3: 2.344  loss_mask_4: 2.343  loss_mask_5: 2.343  loss_mask_6: 2.344  loss_mask_7: 2.343  loss_mask_8: 2.343  time: 1.9539  data_time: 0.4308  lr: 6.7612e-05  max_mem: 17500M
[01/27 16:47:30] d2.utils.events INFO:  eta: 1 day, 0:58:40  iter: 21179  total_loss: 26.84  loss_mask: 2.68  loss_mask_0: 2.713  loss_mask_1: 2.68  loss_mask_2: 2.68  loss_mask_3: 2.679  loss_mask_4: 2.68  loss_mask_5: 2.681  loss_mask_6: 2.68  loss_mask_7: 2.68  loss_mask_8: 2.68  time: 1.9543  data_time: 0.4164  lr: 6.7581e-05  max_mem: 17500M
[01/27 16:48:17] d2.utils.events INFO:  eta: 1 day, 0:59:04  iter: 21199  total_loss: 26.3  loss_mask: 2.627  loss_mask_0: 2.662  loss_mask_1: 2.627  loss_mask_2: 2.627  loss_mask_3: 2.627  loss_mask_4: 2.627  loss_mask_5: 2.626  loss_mask_6: 2.626  loss_mask_7: 2.628  loss_mask_8: 2.627  time: 1.9547  data_time: 0.4231  lr: 6.755e-05  max_mem: 17500M
[01/27 16:49:04] d2.utils.events INFO:  eta: 1 day, 0:59:49  iter: 21219  total_loss: 27.69  loss_mask: 2.767  loss_mask_0: 2.791  loss_mask_1: 2.765  loss_mask_2: 2.767  loss_mask_3: 2.766  loss_mask_4: 2.767  loss_mask_5: 2.765  loss_mask_6: 2.766  loss_mask_7: 2.767  loss_mask_8: 2.767  time: 1.9551  data_time: 0.4205  lr: 6.7518e-05  max_mem: 17500M
[01/27 16:49:52] d2.utils.events INFO:  eta: 1 day, 0:59:54  iter: 21239  total_loss: 27.57  loss_mask: 2.753  loss_mask_0: 2.799  loss_mask_1: 2.752  loss_mask_2: 2.753  loss_mask_3: 2.755  loss_mask_4: 2.755  loss_mask_5: 2.753  loss_mask_6: 2.756  loss_mask_7: 2.753  loss_mask_8: 2.753  time: 1.9555  data_time: 0.4489  lr: 6.7487e-05  max_mem: 17500M
[01/27 16:50:40] d2.utils.events INFO:  eta: 1 day, 0:59:42  iter: 21259  total_loss: 26.46  loss_mask: 2.643  loss_mask_0: 2.673  loss_mask_1: 2.642  loss_mask_2: 2.642  loss_mask_3: 2.644  loss_mask_4: 2.642  loss_mask_5: 2.644  loss_mask_6: 2.644  loss_mask_7: 2.642  loss_mask_8: 2.643  time: 1.9559  data_time: 0.4286  lr: 6.7456e-05  max_mem: 17500M
[01/27 16:51:27] d2.utils.events INFO:  eta: 1 day, 1:00:04  iter: 21279  total_loss: 26.31  loss_mask: 2.629  loss_mask_0: 2.645  loss_mask_1: 2.629  loss_mask_2: 2.629  loss_mask_3: 2.628  loss_mask_4: 2.629  loss_mask_5: 2.631  loss_mask_6: 2.628  loss_mask_7: 2.629  loss_mask_8: 2.629  time: 1.9563  data_time: 0.4319  lr: 6.7424e-05  max_mem: 17500M
[01/27 16:52:15] d2.utils.events INFO:  eta: 1 day, 0:59:50  iter: 21299  total_loss: 26.29  loss_mask: 2.626  loss_mask_0: 2.648  loss_mask_1: 2.626  loss_mask_2: 2.626  loss_mask_3: 2.627  loss_mask_4: 2.627  loss_mask_5: 2.627  loss_mask_6: 2.626  loss_mask_7: 2.626  loss_mask_8: 2.626  time: 1.9567  data_time: 0.4049  lr: 6.7393e-05  max_mem: 17500M
[01/27 16:53:02] d2.utils.events INFO:  eta: 1 day, 1:00:46  iter: 21319  total_loss: 26.09  loss_mask: 2.608  loss_mask_0: 2.617  loss_mask_1: 2.607  loss_mask_2: 2.608  loss_mask_3: 2.608  loss_mask_4: 2.608  loss_mask_5: 2.608  loss_mask_6: 2.609  loss_mask_7: 2.608  loss_mask_8: 2.609  time: 1.9570  data_time: 0.4022  lr: 6.7362e-05  max_mem: 17500M
[01/27 16:53:50] d2.utils.events INFO:  eta: 1 day, 1:00:51  iter: 21339  total_loss: 28.28  loss_mask: 2.826  loss_mask_0: 2.84  loss_mask_1: 2.827  loss_mask_2: 2.827  loss_mask_3: 2.828  loss_mask_4: 2.827  loss_mask_5: 2.827  loss_mask_6: 2.828  loss_mask_7: 2.826  loss_mask_8: 2.826  time: 1.9575  data_time: 0.4319  lr: 6.733e-05  max_mem: 17500M
[01/27 16:54:38] d2.utils.events INFO:  eta: 1 day, 1:01:03  iter: 21359  total_loss: 24.71  loss_mask: 2.469  loss_mask_0: 2.462  loss_mask_1: 2.469  loss_mask_2: 2.469  loss_mask_3: 2.469  loss_mask_4: 2.469  loss_mask_5: 2.469  loss_mask_6: 2.469  loss_mask_7: 2.469  loss_mask_8: 2.469  time: 1.9579  data_time: 0.4236  lr: 6.7299e-05  max_mem: 17500M
[01/27 16:55:25] d2.utils.events INFO:  eta: 1 day, 1:00:45  iter: 21379  total_loss: 23.5  loss_mask: 2.349  loss_mask_0: 2.355  loss_mask_1: 2.349  loss_mask_2: 2.349  loss_mask_3: 2.349  loss_mask_4: 2.349  loss_mask_5: 2.35  loss_mask_6: 2.349  loss_mask_7: 2.35  loss_mask_8: 2.35  time: 1.9582  data_time: 0.4096  lr: 6.7267e-05  max_mem: 17500M
[01/27 16:56:12] d2.utils.events INFO:  eta: 1 day, 1:00:43  iter: 21399  total_loss: 24.17  loss_mask: 2.412  loss_mask_0: 2.439  loss_mask_1: 2.411  loss_mask_2: 2.412  loss_mask_3: 2.411  loss_mask_4: 2.412  loss_mask_5: 2.411  loss_mask_6: 2.412  loss_mask_7: 2.412  loss_mask_8: 2.412  time: 1.9586  data_time: 0.4195  lr: 6.7236e-05  max_mem: 17500M
[01/27 16:56:59] d2.utils.events INFO:  eta: 1 day, 1:01:24  iter: 21419  total_loss: 24.77  loss_mask: 2.472  loss_mask_0: 2.498  loss_mask_1: 2.472  loss_mask_2: 2.472  loss_mask_3: 2.472  loss_mask_4: 2.472  loss_mask_5: 2.472  loss_mask_6: 2.472  loss_mask_7: 2.472  loss_mask_8: 2.472  time: 1.9590  data_time: 0.4006  lr: 6.7205e-05  max_mem: 17500M
[01/27 16:57:47] d2.utils.events INFO:  eta: 1 day, 1:02:11  iter: 21439  total_loss: 24.03  loss_mask: 2.399  loss_mask_0: 2.452  loss_mask_1: 2.398  loss_mask_2: 2.399  loss_mask_3: 2.399  loss_mask_4: 2.399  loss_mask_5: 2.398  loss_mask_6: 2.399  loss_mask_7: 2.398  loss_mask_8: 2.399  time: 1.9594  data_time: 0.4109  lr: 6.7173e-05  max_mem: 17500M
[01/27 16:58:35] d2.utils.events INFO:  eta: 1 day, 1:03:38  iter: 21459  total_loss: 24.88  loss_mask: 2.488  loss_mask_0: 2.488  loss_mask_1: 2.488  loss_mask_2: 2.488  loss_mask_3: 2.487  loss_mask_4: 2.488  loss_mask_5: 2.488  loss_mask_6: 2.488  loss_mask_7: 2.489  loss_mask_8: 2.488  time: 1.9598  data_time: 0.4134  lr: 6.7142e-05  max_mem: 17500M
[01/27 16:59:23] d2.utils.events INFO:  eta: 1 day, 1:04:31  iter: 21479  total_loss: 25.43  loss_mask: 2.543  loss_mask_0: 2.553  loss_mask_1: 2.542  loss_mask_2: 2.543  loss_mask_3: 2.543  loss_mask_4: 2.543  loss_mask_5: 2.541  loss_mask_6: 2.543  loss_mask_7: 2.543  loss_mask_8: 2.543  time: 1.9602  data_time: 0.4321  lr: 6.7111e-05  max_mem: 17500M
[01/27 17:00:11] d2.utils.events INFO:  eta: 1 day, 1:06:26  iter: 21499  total_loss: 26.55  loss_mask: 2.655  loss_mask_0: 2.668  loss_mask_1: 2.655  loss_mask_2: 2.655  loss_mask_3: 2.656  loss_mask_4: 2.655  loss_mask_5: 2.654  loss_mask_6: 2.656  loss_mask_7: 2.655  loss_mask_8: 2.654  time: 1.9606  data_time: 0.4297  lr: 6.7079e-05  max_mem: 17500M
[01/27 17:00:59] d2.utils.events INFO:  eta: 1 day, 1:07:38  iter: 21519  total_loss: 29.9  loss_mask: 2.975  loss_mask_0: 3.126  loss_mask_1: 2.974  loss_mask_2: 2.974  loss_mask_3: 2.976  loss_mask_4: 2.974  loss_mask_5: 2.975  loss_mask_6: 2.975  loss_mask_7: 2.974  loss_mask_8: 2.974  time: 1.9610  data_time: 0.4371  lr: 6.7048e-05  max_mem: 17500M
[01/27 17:01:47] d2.utils.events INFO:  eta: 1 day, 1:08:13  iter: 21539  total_loss: 23.6  loss_mask: 2.357  loss_mask_0: 2.415  loss_mask_1: 2.357  loss_mask_2: 2.358  loss_mask_3: 2.357  loss_mask_4: 2.358  loss_mask_5: 2.358  loss_mask_6: 2.357  loss_mask_7: 2.358  loss_mask_8: 2.358  time: 1.9614  data_time: 0.4058  lr: 6.7017e-05  max_mem: 17500M
[01/27 17:02:35] d2.utils.events INFO:  eta: 1 day, 1:08:21  iter: 21559  total_loss: 24.99  loss_mask: 2.501  loss_mask_0: 2.489  loss_mask_1: 2.501  loss_mask_2: 2.501  loss_mask_3: 2.501  loss_mask_4: 2.501  loss_mask_5: 2.501  loss_mask_6: 2.501  loss_mask_7: 2.501  loss_mask_8: 2.501  time: 1.9618  data_time: 0.4294  lr: 6.6985e-05  max_mem: 17500M
[01/27 17:03:23] d2.utils.events INFO:  eta: 1 day, 1:09:07  iter: 21579  total_loss: 23.48  loss_mask: 2.348  loss_mask_0: 2.347  loss_mask_1: 2.348  loss_mask_2: 2.348  loss_mask_3: 2.348  loss_mask_4: 2.348  loss_mask_5: 2.348  loss_mask_6: 2.348  loss_mask_7: 2.348  loss_mask_8: 2.348  time: 1.9622  data_time: 0.4436  lr: 6.6954e-05  max_mem: 17500M
[01/27 17:04:10] d2.utils.events INFO:  eta: 1 day, 1:08:43  iter: 21599  total_loss: 24.2  loss_mask: 2.419  loss_mask_0: 2.435  loss_mask_1: 2.419  loss_mask_2: 2.419  loss_mask_3: 2.418  loss_mask_4: 2.419  loss_mask_5: 2.418  loss_mask_6: 2.419  loss_mask_7: 2.419  loss_mask_8: 2.419  time: 1.9626  data_time: 0.4539  lr: 6.6922e-05  max_mem: 17500M
[01/27 17:04:58] d2.utils.events INFO:  eta: 1 day, 1:08:22  iter: 21619  total_loss: 22.49  loss_mask: 2.248  loss_mask_0: 2.257  loss_mask_1: 2.248  loss_mask_2: 2.249  loss_mask_3: 2.248  loss_mask_4: 2.248  loss_mask_5: 2.247  loss_mask_6: 2.248  loss_mask_7: 2.249  loss_mask_8: 2.248  time: 1.9630  data_time: 0.4358  lr: 6.6891e-05  max_mem: 17500M
[01/27 17:05:45] d2.utils.events INFO:  eta: 1 day, 1:07:23  iter: 21639  total_loss: 24.19  loss_mask: 2.419  loss_mask_0: 2.412  loss_mask_1: 2.42  loss_mask_2: 2.419  loss_mask_3: 2.419  loss_mask_4: 2.42  loss_mask_5: 2.42  loss_mask_6: 2.419  loss_mask_7: 2.419  loss_mask_8: 2.419  time: 1.9634  data_time: 0.4151  lr: 6.686e-05  max_mem: 17500M
[01/27 17:06:34] d2.utils.events INFO:  eta: 1 day, 1:07:34  iter: 21659  total_loss: 25.14  loss_mask: 2.513  loss_mask_0: 2.52  loss_mask_1: 2.514  loss_mask_2: 2.514  loss_mask_3: 2.513  loss_mask_4: 2.514  loss_mask_5: 2.513  loss_mask_6: 2.514  loss_mask_7: 2.514  loss_mask_8: 2.513  time: 1.9638  data_time: 0.4516  lr: 6.6828e-05  max_mem: 17500M
[01/27 17:07:22] d2.utils.events INFO:  eta: 1 day, 1:06:57  iter: 21679  total_loss: 27.67  loss_mask: 2.765  loss_mask_0: 2.786  loss_mask_1: 2.765  loss_mask_2: 2.765  loss_mask_3: 2.765  loss_mask_4: 2.764  loss_mask_5: 2.764  loss_mask_6: 2.765  loss_mask_7: 2.765  loss_mask_8: 2.765  time: 1.9642  data_time: 0.4253  lr: 6.6797e-05  max_mem: 17500M
[01/27 17:08:10] d2.utils.events INFO:  eta: 1 day, 1:07:47  iter: 21699  total_loss: 25.25  loss_mask: 2.521  loss_mask_0: 2.554  loss_mask_1: 2.522  loss_mask_2: 2.521  loss_mask_3: 2.521  loss_mask_4: 2.521  loss_mask_5: 2.522  loss_mask_6: 2.521  loss_mask_7: 2.521  loss_mask_8: 2.521  time: 1.9646  data_time: 0.4220  lr: 6.6766e-05  max_mem: 17500M
[01/27 17:08:59] d2.utils.events INFO:  eta: 1 day, 1:07:31  iter: 21719  total_loss: 25.3  loss_mask: 2.529  loss_mask_0: 2.537  loss_mask_1: 2.529  loss_mask_2: 2.529  loss_mask_3: 2.53  loss_mask_4: 2.529  loss_mask_5: 2.529  loss_mask_6: 2.529  loss_mask_7: 2.529  loss_mask_8: 2.529  time: 1.9650  data_time: 0.4457  lr: 6.6734e-05  max_mem: 17500M
[01/27 17:09:47] d2.utils.events INFO:  eta: 1 day, 1:07:54  iter: 21739  total_loss: 24.43  loss_mask: 2.439  loss_mask_0: 2.487  loss_mask_1: 2.438  loss_mask_2: 2.439  loss_mask_3: 2.438  loss_mask_4: 2.439  loss_mask_5: 2.438  loss_mask_6: 2.438  loss_mask_7: 2.439  loss_mask_8: 2.439  time: 1.9654  data_time: 0.4483  lr: 6.6703e-05  max_mem: 17500M
[01/27 17:10:36] d2.utils.events INFO:  eta: 1 day, 1:07:57  iter: 21759  total_loss: 24.13  loss_mask: 2.411  loss_mask_0: 2.432  loss_mask_1: 2.411  loss_mask_2: 2.411  loss_mask_3: 2.412  loss_mask_4: 2.411  loss_mask_5: 2.411  loss_mask_6: 2.411  loss_mask_7: 2.411  loss_mask_8: 2.411  time: 1.9659  data_time: 0.4438  lr: 6.6671e-05  max_mem: 17500M
[01/27 17:11:24] d2.utils.events INFO:  eta: 1 day, 1:08:30  iter: 21779  total_loss: 24.4  loss_mask: 2.436  loss_mask_0: 2.47  loss_mask_1: 2.437  loss_mask_2: 2.436  loss_mask_3: 2.436  loss_mask_4: 2.436  loss_mask_5: 2.437  loss_mask_6: 2.436  loss_mask_7: 2.436  loss_mask_8: 2.436  time: 1.9663  data_time: 0.4334  lr: 6.664e-05  max_mem: 17500M
[01/27 17:12:12] d2.utils.events INFO:  eta: 1 day, 1:08:02  iter: 21799  total_loss: 23.95  loss_mask: 2.393  loss_mask_0: 2.415  loss_mask_1: 2.393  loss_mask_2: 2.393  loss_mask_3: 2.393  loss_mask_4: 2.393  loss_mask_5: 2.392  loss_mask_6: 2.393  loss_mask_7: 2.393  loss_mask_8: 2.393  time: 1.9667  data_time: 0.4230  lr: 6.6609e-05  max_mem: 17500M
[01/27 17:13:00] d2.utils.events INFO:  eta: 1 day, 1:07:42  iter: 21819  total_loss: 24.21  loss_mask: 2.418  loss_mask_0: 2.45  loss_mask_1: 2.417  loss_mask_2: 2.418  loss_mask_3: 2.418  loss_mask_4: 2.418  loss_mask_5: 2.418  loss_mask_6: 2.418  loss_mask_7: 2.418  loss_mask_8: 2.418  time: 1.9671  data_time: 0.4201  lr: 6.6577e-05  max_mem: 17500M
[01/27 17:13:48] d2.utils.events INFO:  eta: 1 day, 1:07:12  iter: 21839  total_loss: 24.93  loss_mask: 2.487  loss_mask_0: 2.542  loss_mask_1: 2.487  loss_mask_2: 2.487  loss_mask_3: 2.488  loss_mask_4: 2.487  loss_mask_5: 2.487  loss_mask_6: 2.487  loss_mask_7: 2.487  loss_mask_8: 2.487  time: 1.9675  data_time: 0.4390  lr: 6.6546e-05  max_mem: 17500M
[01/27 17:14:35] d2.utils.events INFO:  eta: 1 day, 1:07:07  iter: 21859  total_loss: 23.67  loss_mask: 2.363  loss_mask_0: 2.401  loss_mask_1: 2.363  loss_mask_2: 2.363  loss_mask_3: 2.364  loss_mask_4: 2.363  loss_mask_5: 2.363  loss_mask_6: 2.364  loss_mask_7: 2.363  loss_mask_8: 2.363  time: 1.9678  data_time: 0.4109  lr: 6.6515e-05  max_mem: 17500M
[01/27 17:15:22] d2.utils.events INFO:  eta: 1 day, 1:05:57  iter: 21879  total_loss: 23.78  loss_mask: 2.378  loss_mask_0: 2.386  loss_mask_1: 2.378  loss_mask_2: 2.378  loss_mask_3: 2.378  loss_mask_4: 2.377  loss_mask_5: 2.378  loss_mask_6: 2.378  loss_mask_7: 2.378  loss_mask_8: 2.378  time: 1.9681  data_time: 0.4186  lr: 6.6483e-05  max_mem: 17500M
[01/27 17:16:08] d2.utils.events INFO:  eta: 1 day, 1:05:27  iter: 21899  total_loss: 25.47  loss_mask: 2.546  loss_mask_0: 2.564  loss_mask_1: 2.545  loss_mask_2: 2.546  loss_mask_3: 2.545  loss_mask_4: 2.546  loss_mask_5: 2.546  loss_mask_6: 2.545  loss_mask_7: 2.546  loss_mask_8: 2.545  time: 1.9685  data_time: 0.4209  lr: 6.6452e-05  max_mem: 17500M
[01/27 17:16:57] d2.utils.events INFO:  eta: 1 day, 1:05:06  iter: 21919  total_loss: 25.19  loss_mask: 2.518  loss_mask_0: 2.528  loss_mask_1: 2.518  loss_mask_2: 2.518  loss_mask_3: 2.518  loss_mask_4: 2.518  loss_mask_5: 2.518  loss_mask_6: 2.518  loss_mask_7: 2.518  loss_mask_8: 2.518  time: 1.9689  data_time: 0.4383  lr: 6.642e-05  max_mem: 17500M
[01/27 17:17:45] d2.utils.events INFO:  eta: 1 day, 1:05:04  iter: 21939  total_loss: 25.83  loss_mask: 2.58  loss_mask_0: 2.611  loss_mask_1: 2.579  loss_mask_2: 2.579  loss_mask_3: 2.579  loss_mask_4: 2.579  loss_mask_5: 2.58  loss_mask_6: 2.58  loss_mask_7: 2.579  loss_mask_8: 2.58  time: 1.9693  data_time: 0.4368  lr: 6.6389e-05  max_mem: 17500M
[01/27 17:18:34] d2.utils.events INFO:  eta: 1 day, 1:05:28  iter: 21959  total_loss: 23.99  loss_mask: 2.399  loss_mask_0: 2.402  loss_mask_1: 2.399  loss_mask_2: 2.399  loss_mask_3: 2.399  loss_mask_4: 2.399  loss_mask_5: 2.398  loss_mask_6: 2.399  loss_mask_7: 2.399  loss_mask_8: 2.399  time: 1.9697  data_time: 0.4289  lr: 6.6358e-05  max_mem: 17500M
[01/27 17:19:22] d2.utils.events INFO:  eta: 1 day, 1:05:12  iter: 21979  total_loss: 23.88  loss_mask: 2.388  loss_mask_0: 2.396  loss_mask_1: 2.387  loss_mask_2: 2.388  loss_mask_3: 2.388  loss_mask_4: 2.388  loss_mask_5: 2.387  loss_mask_6: 2.388  loss_mask_7: 2.388  loss_mask_8: 2.388  time: 1.9701  data_time: 0.4328  lr: 6.6326e-05  max_mem: 17500M
[01/27 17:20:10] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 17:20:11] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 17:20:11] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 17:27:59] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.9996634548434926, 'error_1pix': 0.5027999313581089, 'error_3pix': 0.19046306526376397, 'mIoU': 4.266273067315982, 'fwIoU': 14.242302103986699, 'IoU-0': nan, 'IoU-1': 66.89443384753243, 'IoU-2': 2.6068543955069883, 'IoU-3': 2.58572051700803, 'IoU-4': 3.098062982581798, 'IoU-5': 3.8130264040803308, 'IoU-6': 4.009154557663585, 'IoU-7': 3.265407135344309, 'IoU-8': 6.377457579495073, 'IoU-9': 20.687533186036593, 'IoU-10': 23.349268367800114, 'IoU-11': 28.339420127141267, 'IoU-12': 27.77958117748961, 'IoU-13': 23.65183101653553, 'IoU-14': 22.436831293064092, 'IoU-15': 22.000216633073187, 'IoU-16': 20.081670492844385, 'IoU-17': 15.957525323331634, 'IoU-18': 14.89132555232886, 'IoU-19': 14.65145616213253, 'IoU-20': 13.347064339936296, 'IoU-21': 13.428035022194273, 'IoU-22': 12.253609785141984, 'IoU-23': 10.592259753670357, 'IoU-24': 10.341022446363162, 'IoU-25': 9.931978598738013, 'IoU-26': 8.927860752508705, 'IoU-27': 8.372619901119752, 'IoU-28': 7.610825905226935, 'IoU-29': 6.973160035817232, 'IoU-30': 6.497593143191989, 'IoU-31': 6.1202553551117385, 'IoU-32': 5.432088889887797, 'IoU-33': 5.111288894858808, 'IoU-34': 4.913061617510548, 'IoU-35': 4.698275111470179, 'IoU-36': 4.753681522509945, 'IoU-37': 4.498128471552365, 'IoU-38': 4.703606137272131, 'IoU-39': 4.462052868495638, 'IoU-40': 4.207485340925506, 'IoU-41': 3.735801611216648, 'IoU-42': 3.5414226979581307, 'IoU-43': 3.5324463941753503, 'IoU-44': 3.5363557873800597, 'IoU-45': 3.644530727648117, 'IoU-46': 3.433598591633672, 'IoU-47': 3.3401786528579516, 'IoU-48': 3.113016769456398, 'IoU-49': 3.0861919152767308, 'IoU-50': 3.2003817635757326, 'IoU-51': 3.139315038958643, 'IoU-52': 3.3275939100079874, 'IoU-53': 3.326836480169868, 'IoU-54': 3.4774655422791776, 'IoU-55': 3.2851183770092476, 'IoU-56': 3.1933224323712652, 'IoU-57': 3.2553004110727897, 'IoU-58': 3.311965037807665, 'IoU-59': 3.0885702776233863, 'IoU-60': 3.0949793250567583, 'IoU-61': 3.0363036831918504, 'IoU-62': 3.221718548046864, 'IoU-63': 3.208128904417197, 'IoU-64': 3.0125095118582426, 'IoU-65': 3.261007736451852, 'IoU-66': 3.240734526385347, 'IoU-67': 3.2618751948617444, 'IoU-68': 3.1207734885252965, 'IoU-69': 3.4819968025318753, 'IoU-70': 3.4655230338388394, 'IoU-71': 3.2528712255613974, 'IoU-72': 3.2514544386561455, 'IoU-73': 3.501122316455705, 'IoU-74': 3.485238648148223, 'IoU-75': 3.4508912497911575, 'IoU-76': 3.619989853148992, 'IoU-77': 3.265049358535202, 'IoU-78': 3.1330692625056624, 'IoU-79': 3.2258523621864628, 'IoU-80': 3.252514165148602, 'IoU-81': 3.2993931166578236, 'IoU-82': 3.17728105483371, 'IoU-83': 3.4615724651565474, 'IoU-84': 3.45272317945637, 'IoU-85': 3.3422134394884013, 'IoU-86': 3.2425113310746942, 'IoU-87': 3.184355237951685, 'IoU-88': 3.250533374907753, 'IoU-89': 3.363912095758861, 'IoU-90': 3.3039801689786, 'IoU-91': 3.274163437984311, 'IoU-92': 3.238095793459418, 'IoU-93': 3.2868641301036545, 'IoU-94': 3.2660573580194576, 'IoU-95': 3.257675658849063, 'IoU-96': 3.290634037680528, 'IoU-97': 3.208904305245398, 'IoU-98': 2.9888962480058923, 'IoU-99': 3.064673047866714, 'IoU-100': 3.0950436214201673, 'IoU-101': 3.0292129705929436, 'IoU-102': 3.061329233973445, 'IoU-103': 2.8825748902303676, 'IoU-104': 2.857881923968385, 'IoU-105': 2.9107766304946505, 'IoU-106': 2.937575636555525, 'IoU-107': 2.886108749913292, 'IoU-108': 3.0805004695037166, 'IoU-109': 3.0837004405286343, 'IoU-110': 3.191538096403087, 'IoU-111': 2.8295942411294064, 'IoU-112': 2.8799392628665195, 'IoU-113': 2.578873149252553, 'IoU-114': 2.4339558407960817, 'IoU-115': 2.388194354683568, 'IoU-116': 2.347876056191996, 'IoU-117': 2.4057638905704213, 'IoU-118': 2.438886348707226, 'IoU-119': 2.4383932895797362, 'IoU-120': 2.4843759924010267, 'IoU-121': 2.3473170789073685, 'IoU-122': 2.203827381668323, 'IoU-123': 2.327937739483408, 'IoU-124': 2.301531839494192, 'IoU-125': 2.096144504413348, 'IoU-126': 2.009681502464486, 'IoU-127': 1.9526598880158124, 'IoU-128': 2.041582949966597, 'IoU-129': 1.9631678642695902, 'IoU-130': 2.039259550633131, 'IoU-131': 1.90729452607783, 'IoU-132': 1.7514957956015524, 'IoU-133': 1.6697055888367063, 'IoU-134': 1.6201598964981658, 'IoU-135': 1.62719383048399, 'IoU-136': 1.6453454523199376, 'IoU-137': 1.5321796808706236, 'IoU-138': 1.444703095646492, 'IoU-139': 1.501313256206923, 'IoU-140': 1.3655192813113544, 'IoU-141': 1.380834636181859, 'IoU-142': 1.3818474966326433, 'IoU-143': 1.4409174724265663, 'IoU-144': 1.354046789387556, 'IoU-145': 1.4419876494050243, 'IoU-146': 1.5418986689458403, 'IoU-147': 1.5664205947007421, 'IoU-148': 1.697754088018804, 'IoU-149': 1.6411074481377959, 'IoU-150': 1.5553963885852151, 'IoU-151': 1.5103236707450058, 'IoU-152': 1.6906545471571794, 'IoU-153': 1.7193099676118502, 'IoU-154': 1.653358711905815, 'IoU-155': 1.6542595492445051, 'IoU-156': 1.5301722763535772, 'IoU-157': 1.5834957120996953, 'IoU-158': 1.5688035358318124, 'IoU-159': 1.4563405826765883, 'IoU-160': 1.3912295367522565, 'IoU-161': 1.2430341106733398, 'IoU-162': 1.1690880319234735, 'IoU-163': 1.1174657843105558, 'IoU-164': 1.1895499175353037, 'IoU-165': 1.1692166793817005, 'IoU-166': 1.1724020414377219, 'IoU-167': 1.1627863378932428, 'IoU-168': 0.9114341983317887, 'IoU-169': 0.907512486766875, 'IoU-170': 0.815171620585899, 'IoU-171': 0.7387510490077712, 'IoU-172': 0.6725203389561715, 'IoU-173': 0.7129189421526552, 'IoU-174': 0.7563943924581241, 'IoU-175': 0.6777542558539611, 'IoU-176': 0.5514746083546155, 'IoU-177': 0.5658212425460772, 'IoU-178': 0.6894067124926145, 'IoU-179': 0.7478764100668746, 'IoU-180': 0.5078883128757623, 'IoU-181': 0.375084696544381, 'IoU-182': 0.3229052911072568, 'IoU-183': 0.26804666800948235, 'IoU-184': 0.17647284781081027, 'IoU-185': 0.11292343476197225, 'IoU-186': 0.06927864195263479, 'IoU-187': 0.04739710877636464, 'IoU-188': 0.031058623151197888, 'IoU-189': 0.03907397239283388, 'IoU-190': 0.04489103484275088, 'IoU-191': 0.03149393156186475, 'IoU-192': 0.023146971980872698, 'mACC': 7.754600604668717, 'pACC': 20.137619850998703, 'ACC-0': nan, 'ACC-1': 68.29089113693115, 'ACC-2': 5.097802548901274, 'ACC-3': 11.85589403606231, 'ACC-4': 13.195402668769285, 'ACC-5': 16.41144934923924, 'ACC-6': 17.818628338653795, 'ACC-7': 15.876696894450703, 'ACC-8': 15.689060336432492, 'ACC-9': 36.264537801836795, 'ACC-10': 44.012083074095635, 'ACC-11': 44.41802070948053, 'ACC-12': 45.48757515050583, 'ACC-13': 38.07458064667178, 'ACC-14': 35.3500106084906, 'ACC-15': 36.42592549946797, 'ACC-16': 33.99390840156013, 'ACC-17': 29.11093869763234, 'ACC-18': 26.112380537644214, 'ACC-19': 26.211405261003527, 'ACC-20': 24.834306802550834, 'ACC-21': 24.859560835859806, 'ACC-22': 21.736668848957176, 'ACC-23': 19.73434391671855, 'ACC-24': 19.347135279756024, 'ACC-25': 18.820743731197396, 'ACC-26': 17.634344022570023, 'ACC-27': 15.979978273048514, 'ACC-28': 14.975010433273434, 'ACC-29': 13.47174728171177, 'ACC-30': 12.914173191728937, 'ACC-31': 11.678842842467386, 'ACC-32': 10.297375647889009, 'ACC-33': 10.026153342045877, 'ACC-34': 9.902915926010909, 'ACC-35': 9.185511343402267, 'ACC-36': 8.996571490329167, 'ACC-37': 8.653284257809759, 'ACC-38': 9.026127092019399, 'ACC-39': 8.475222745914994, 'ACC-40': 7.893905047736438, 'ACC-41': 7.268551261516495, 'ACC-42': 6.9590124314995245, 'ACC-43': 6.877662798634017, 'ACC-44': 6.6155542516914005, 'ACC-45': 6.861387925356135, 'ACC-46': 6.627818183733629, 'ACC-47': 6.457703639522483, 'ACC-48': 5.993026176479905, 'ACC-49': 5.845201549883241, 'ACC-50': 5.938062215263179, 'ACC-51': 5.907096179688691, 'ACC-52': 6.290860364531834, 'ACC-53': 6.268321278544925, 'ACC-54': 6.499033798645957, 'ACC-55': 6.158329555060938, 'ACC-56': 6.029749885471244, 'ACC-57': 6.004414018447809, 'ACC-58': 6.110243437240858, 'ACC-59': 5.718171341881898, 'ACC-60': 5.727199645602698, 'ACC-61': 5.6998963630924395, 'ACC-62': 6.059787159038723, 'ACC-63': 6.0620389512843325, 'ACC-64': 5.680770330547164, 'ACC-65': 6.153627774450303, 'ACC-66': 6.1442802646409636, 'ACC-67': 6.251948106361264, 'ACC-68': 6.022805565440788, 'ACC-69': 6.624779327783732, 'ACC-70': 6.531502432159833, 'ACC-71': 6.283442315399852, 'ACC-72': 6.325343201059827, 'ACC-73': 6.802135095106491, 'ACC-74': 6.756422756717736, 'ACC-75': 6.678660622732023, 'ACC-76': 6.887161049564955, 'ACC-77': 6.286783576499469, 'ACC-78': 6.056693626764258, 'ACC-79': 6.235640803191666, 'ACC-80': 6.211894841567134, 'ACC-81': 6.217567092919025, 'ACC-82': 5.998327178577624, 'ACC-83': 6.436259491986659, 'ACC-84': 6.407192549222736, 'ACC-85': 6.170134515406154, 'ACC-86': 5.972167460083589, 'ACC-87': 5.885389291653331, 'ACC-88': 5.983827452608866, 'ACC-89': 6.135142653197905, 'ACC-90': 5.991548748283071, 'ACC-91': 6.008924992127969, 'ACC-92': 6.001124225175506, 'ACC-93': 6.063956937561497, 'ACC-94': 5.950767058102279, 'ACC-95': 5.87869763810759, 'ACC-96': 5.952402958332646, 'ACC-97': 5.712050707887769, 'ACC-98': 5.323225492210244, 'ACC-99': 5.516324255485403, 'ACC-100': 5.6094950657698, 'ACC-101': 5.5150162749390015, 'ACC-102': 5.594419536154527, 'ACC-103': 5.285510462679638, 'ACC-104': 5.2060786607684575, 'ACC-105': 5.290775168041484, 'ACC-106': 5.354373118708432, 'ACC-107': 5.340957055641859, 'ACC-108': 5.633829285487865, 'ACC-109': 5.60727898475229, 'ACC-110': 5.91550746137881, 'ACC-111': 5.252217177638401, 'ACC-112': 5.358852856015092, 'ACC-113': 4.8045136378374345, 'ACC-114': 4.575260104147344, 'ACC-115': 4.465442845759475, 'ACC-116': 4.414384105418879, 'ACC-117': 4.511273965766233, 'ACC-118': 4.595630762435356, 'ACC-119': 4.571319262786737, 'ACC-120': 4.621815888142752, 'ACC-121': 4.35169081774524, 'ACC-122': 4.105833734325908, 'ACC-123': 4.388367948305501, 'ACC-124': 4.468805887376332, 'ACC-125': 4.074016465748567, 'ACC-126': 3.9160192715780653, 'ACC-127': 3.786305357493295, 'ACC-128': 3.9640025320438936, 'ACC-129': 3.8196263834599153, 'ACC-130': 4.018839499229961, 'ACC-131': 3.7679610663295926, 'ACC-132': 3.3682848937546286, 'ACC-133': 3.160301292126804, 'ACC-134': 3.0352434295562256, 'ACC-135': 3.040590616270452, 'ACC-136': 3.0530044493104733, 'ACC-137': 2.8430405039775857, 'ACC-138': 2.6937330253572607, 'ACC-139': 2.7803169986054552, 'ACC-140': 2.5006336064881305, 'ACC-141': 2.5152363335852383, 'ACC-142': 2.5238830071061717, 'ACC-143': 2.6100482273939147, 'ACC-144': 2.4360152274643094, 'ACC-145': 2.536282117220868, 'ACC-146': 2.690555912972277, 'ACC-147': 2.741186225543859, 'ACC-148': 2.995499241952578, 'ACC-149': 2.94625010268065, 'ACC-150': 2.7953754719065755, 'ACC-151': 2.686508625880733, 'ACC-152': 2.9295549664296585, 'ACC-153': 3.0704486636282438, 'ACC-154': 2.9496685864581313, 'ACC-155': 2.9844914420666244, 'ACC-156': 2.791790236297022, 'ACC-157': 2.9366089353159346, 'ACC-158': 2.8945314539837383, 'ACC-159': 2.647864001553814, 'ACC-160': 2.5012724804886326, 'ACC-161': 2.2128796080595494, 'ACC-162': 2.1025180230707208, 'ACC-163': 2.0077687534681936, 'ACC-164': 2.125868271638019, 'ACC-165': 2.07632845791357, 'ACC-166': 2.1139494472100266, 'ACC-167': 2.1549927037731913, 'ACC-168': 1.6600377688923589, 'ACC-169': 1.6215865261443758, 'ACC-170': 1.45158771288415, 'ACC-171': 1.3050738788654823, 'ACC-172': 1.1782815353780836, 'ACC-173': 1.2297357056161382, 'ACC-174': 1.252467928580617, 'ACC-175': 1.0869484818225525, 'ACC-176': 0.8236628408111419, 'ACC-177': 0.7948156969176661, 'ACC-178': 0.9244301537367537, 'ACC-179': 0.9611383450557703, 'ACC-180': 0.6235623541173331, 'ACC-181': 0.44083037273867054, 'ACC-182': 0.3575399920810108, 'ACC-183': 0.28534267039269373, 'ACC-184': 0.18428112663959473, 'ACC-185': 0.11601115740772837, 'ACC-186': 0.07041787574316852, 'ACC-187': 0.04788333877462183, 'ACC-188': 0.031292664646102676, 'ACC-189': 0.039312822146737036, 'ACC-190': 0.04511155931252082, 'ACC-191': 0.03162580142655888, 'ACC-192': 0.023232949989658504})])
[01/27 17:27:59] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 17:27:59] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 17:27:59] d2.evaluation.testing INFO: copypaste: 2.9997,0.5028,0.1905,4.2663,14.2423,7.7546,20.1376
[01/27 17:27:59] d2.utils.events INFO:  eta: 1 day, 1:05:14  iter: 21999  total_loss: 24.23  loss_mask: 2.419  loss_mask_0: 2.453  loss_mask_1: 2.418  loss_mask_2: 2.419  loss_mask_3: 2.419  loss_mask_4: 2.419  loss_mask_5: 2.418  loss_mask_6: 2.419  loss_mask_7: 2.419  loss_mask_8: 2.419  time: 1.9705  data_time: 0.4453  lr: 6.6295e-05  max_mem: 17500M
[01/27 17:28:46] d2.utils.events INFO:  eta: 1 day, 1:04:13  iter: 22019  total_loss: 25.28  loss_mask: 2.526  loss_mask_0: 2.537  loss_mask_1: 2.526  loss_mask_2: 2.527  loss_mask_3: 2.527  loss_mask_4: 2.527  loss_mask_5: 2.527  loss_mask_6: 2.527  loss_mask_7: 2.526  loss_mask_8: 2.527  time: 1.9708  data_time: 0.4238  lr: 6.6263e-05  max_mem: 17500M
[01/27 17:29:33] d2.utils.events INFO:  eta: 1 day, 1:02:14  iter: 22039  total_loss: 23.88  loss_mask: 2.387  loss_mask_0: 2.398  loss_mask_1: 2.386  loss_mask_2: 2.387  loss_mask_3: 2.386  loss_mask_4: 2.387  loss_mask_5: 2.386  loss_mask_6: 2.386  loss_mask_7: 2.387  loss_mask_8: 2.387  time: 1.9712  data_time: 0.4033  lr: 6.6232e-05  max_mem: 17500M
[01/27 17:30:20] d2.utils.events INFO:  eta: 1 day, 1:01:20  iter: 22059  total_loss: 23.84  loss_mask: 2.379  loss_mask_0: 2.417  loss_mask_1: 2.379  loss_mask_2: 2.379  loss_mask_3: 2.379  loss_mask_4: 2.379  loss_mask_5: 2.38  loss_mask_6: 2.379  loss_mask_7: 2.379  loss_mask_8: 2.378  time: 1.9715  data_time: 0.4148  lr: 6.6201e-05  max_mem: 17500M
[01/27 17:31:07] d2.utils.events INFO:  eta: 1 day, 1:00:25  iter: 22079  total_loss: 24.53  loss_mask: 2.451  loss_mask_0: 2.472  loss_mask_1: 2.451  loss_mask_2: 2.451  loss_mask_3: 2.451  loss_mask_4: 2.451  loss_mask_5: 2.451  loss_mask_6: 2.451  loss_mask_7: 2.451  loss_mask_8: 2.451  time: 1.9718  data_time: 0.4238  lr: 6.6169e-05  max_mem: 17500M
[01/27 17:31:54] d2.utils.events INFO:  eta: 1 day, 0:59:57  iter: 22099  total_loss: 24.8  loss_mask: 2.478  loss_mask_0: 2.503  loss_mask_1: 2.478  loss_mask_2: 2.478  loss_mask_3: 2.478  loss_mask_4: 2.478  loss_mask_5: 2.478  loss_mask_6: 2.478  loss_mask_7: 2.478  loss_mask_8: 2.478  time: 1.9722  data_time: 0.4384  lr: 6.6138e-05  max_mem: 17500M
[01/27 17:32:40] d2.utils.events INFO:  eta: 1 day, 0:59:13  iter: 22119  total_loss: 23.44  loss_mask: 2.343  loss_mask_0: 2.353  loss_mask_1: 2.343  loss_mask_2: 2.343  loss_mask_3: 2.343  loss_mask_4: 2.343  loss_mask_5: 2.344  loss_mask_6: 2.343  loss_mask_7: 2.343  loss_mask_8: 2.343  time: 1.9725  data_time: 0.4251  lr: 6.6106e-05  max_mem: 17500M
[01/27 17:33:27] d2.utils.events INFO:  eta: 1 day, 0:58:17  iter: 22139  total_loss: 23.53  loss_mask: 2.349  loss_mask_0: 2.387  loss_mask_1: 2.349  loss_mask_2: 2.349  loss_mask_3: 2.35  loss_mask_4: 2.349  loss_mask_5: 2.349  loss_mask_6: 2.35  loss_mask_7: 2.349  loss_mask_8: 2.349  time: 1.9728  data_time: 0.4507  lr: 6.6075e-05  max_mem: 17500M
[01/27 17:34:14] d2.utils.events INFO:  eta: 1 day, 0:57:12  iter: 22159  total_loss: 24.13  loss_mask: 2.409  loss_mask_0: 2.458  loss_mask_1: 2.408  loss_mask_2: 2.408  loss_mask_3: 2.409  loss_mask_4: 2.408  loss_mask_5: 2.408  loss_mask_6: 2.408  loss_mask_7: 2.408  loss_mask_8: 2.409  time: 1.9732  data_time: 0.4326  lr: 6.6044e-05  max_mem: 17500M
[01/27 17:35:01] d2.utils.events INFO:  eta: 1 day, 0:55:53  iter: 22179  total_loss: 23.67  loss_mask: 2.362  loss_mask_0: 2.405  loss_mask_1: 2.362  loss_mask_2: 2.362  loss_mask_3: 2.362  loss_mask_4: 2.362  loss_mask_5: 2.362  loss_mask_6: 2.362  loss_mask_7: 2.363  loss_mask_8: 2.362  time: 1.9735  data_time: 0.4412  lr: 6.6012e-05  max_mem: 17500M
[01/27 17:35:48] d2.utils.events INFO:  eta: 1 day, 0:54:41  iter: 22199  total_loss: 23.12  loss_mask: 2.31  loss_mask_0: 2.335  loss_mask_1: 2.31  loss_mask_2: 2.31  loss_mask_3: 2.31  loss_mask_4: 2.31  loss_mask_5: 2.31  loss_mask_6: 2.31  loss_mask_7: 2.31  loss_mask_8: 2.31  time: 1.9738  data_time: 0.4016  lr: 6.5981e-05  max_mem: 17500M
[01/27 17:36:35] d2.utils.events INFO:  eta: 1 day, 0:53:47  iter: 22219  total_loss: 24.24  loss_mask: 2.421  loss_mask_0: 2.45  loss_mask_1: 2.421  loss_mask_2: 2.421  loss_mask_3: 2.42  loss_mask_4: 2.421  loss_mask_5: 2.421  loss_mask_6: 2.42  loss_mask_7: 2.421  loss_mask_8: 2.421  time: 1.9742  data_time: 0.4269  lr: 6.5949e-05  max_mem: 17500M
[01/27 17:37:21] d2.utils.events INFO:  eta: 1 day, 0:52:28  iter: 22239  total_loss: 24.53  loss_mask: 2.45  loss_mask_0: 2.481  loss_mask_1: 2.45  loss_mask_2: 2.45  loss_mask_3: 2.45  loss_mask_4: 2.449  loss_mask_5: 2.449  loss_mask_6: 2.45  loss_mask_7: 2.45  loss_mask_8: 2.449  time: 1.9745  data_time: 0.4237  lr: 6.5918e-05  max_mem: 17500M
[01/27 17:38:07] d2.utils.events INFO:  eta: 1 day, 0:50:36  iter: 22259  total_loss: 23.28  loss_mask: 2.325  loss_mask_0: 2.36  loss_mask_1: 2.325  loss_mask_2: 2.326  loss_mask_3: 2.325  loss_mask_4: 2.325  loss_mask_5: 2.325  loss_mask_6: 2.325  loss_mask_7: 2.326  loss_mask_8: 2.326  time: 1.9748  data_time: 0.4042  lr: 6.5886e-05  max_mem: 17500M
[01/27 17:38:52] d2.utils.events INFO:  eta: 1 day, 0:48:41  iter: 22279  total_loss: 24.19  loss_mask: 2.417  loss_mask_0: 2.439  loss_mask_1: 2.416  loss_mask_2: 2.417  loss_mask_3: 2.416  loss_mask_4: 2.416  loss_mask_5: 2.416  loss_mask_6: 2.416  loss_mask_7: 2.416  loss_mask_8: 2.417  time: 1.9750  data_time: 0.4074  lr: 6.5855e-05  max_mem: 17500M
[01/27 17:39:39] d2.utils.events INFO:  eta: 1 day, 0:47:47  iter: 22299  total_loss: 24.01  loss_mask: 2.397  loss_mask_0: 2.439  loss_mask_1: 2.397  loss_mask_2: 2.397  loss_mask_3: 2.397  loss_mask_4: 2.397  loss_mask_5: 2.397  loss_mask_6: 2.397  loss_mask_7: 2.397  loss_mask_8: 2.397  time: 1.9753  data_time: 0.4301  lr: 6.5824e-05  max_mem: 17500M
[01/27 17:40:26] d2.utils.events INFO:  eta: 1 day, 0:46:29  iter: 22319  total_loss: 25.7  loss_mask: 2.565  loss_mask_0: 2.62  loss_mask_1: 2.564  loss_mask_2: 2.565  loss_mask_3: 2.565  loss_mask_4: 2.565  loss_mask_5: 2.565  loss_mask_6: 2.565  loss_mask_7: 2.565  loss_mask_8: 2.565  time: 1.9757  data_time: 0.4160  lr: 6.5792e-05  max_mem: 17500M
[01/27 17:41:12] d2.utils.events INFO:  eta: 1 day, 0:44:33  iter: 22339  total_loss: 24.18  loss_mask: 2.412  loss_mask_0: 2.457  loss_mask_1: 2.412  loss_mask_2: 2.412  loss_mask_3: 2.412  loss_mask_4: 2.412  loss_mask_5: 2.413  loss_mask_6: 2.413  loss_mask_7: 2.412  loss_mask_8: 2.412  time: 1.9760  data_time: 0.4167  lr: 6.5761e-05  max_mem: 17500M
[01/27 17:41:59] d2.utils.events INFO:  eta: 1 day, 0:42:55  iter: 22359  total_loss: 23.44  loss_mask: 2.34  loss_mask_0: 2.373  loss_mask_1: 2.34  loss_mask_2: 2.34  loss_mask_3: 2.34  loss_mask_4: 2.34  loss_mask_5: 2.34  loss_mask_6: 2.34  loss_mask_7: 2.341  loss_mask_8: 2.34  time: 1.9763  data_time: 0.4250  lr: 6.5729e-05  max_mem: 17500M
[01/27 17:42:45] d2.utils.events INFO:  eta: 1 day, 0:42:05  iter: 22379  total_loss: 22.79  loss_mask: 2.276  loss_mask_0: 2.31  loss_mask_1: 2.276  loss_mask_2: 2.276  loss_mask_3: 2.276  loss_mask_4: 2.276  loss_mask_5: 2.276  loss_mask_6: 2.276  loss_mask_7: 2.276  loss_mask_8: 2.276  time: 1.9766  data_time: 0.4221  lr: 6.5698e-05  max_mem: 17500M
[01/27 17:43:33] d2.utils.events INFO:  eta: 1 day, 0:41:47  iter: 22399  total_loss: 24.62  loss_mask: 2.461  loss_mask_0: 2.473  loss_mask_1: 2.461  loss_mask_2: 2.461  loss_mask_3: 2.461  loss_mask_4: 2.461  loss_mask_5: 2.462  loss_mask_6: 2.461  loss_mask_7: 2.461  loss_mask_8: 2.461  time: 1.9770  data_time: 0.4316  lr: 6.5666e-05  max_mem: 17500M
[01/27 17:44:20] d2.utils.events INFO:  eta: 1 day, 0:40:33  iter: 22419  total_loss: 22.44  loss_mask: 2.244  loss_mask_0: 2.245  loss_mask_1: 2.243  loss_mask_2: 2.243  loss_mask_3: 2.245  loss_mask_4: 2.244  loss_mask_5: 2.243  loss_mask_6: 2.245  loss_mask_7: 2.244  loss_mask_8: 2.244  time: 1.9773  data_time: 0.4120  lr: 6.5635e-05  max_mem: 17500M
[01/27 17:45:08] d2.utils.events INFO:  eta: 1 day, 0:39:48  iter: 22439  total_loss: 23.67  loss_mask: 2.364  loss_mask_0: 2.399  loss_mask_1: 2.364  loss_mask_2: 2.364  loss_mask_3: 2.364  loss_mask_4: 2.364  loss_mask_5: 2.364  loss_mask_6: 2.364  loss_mask_7: 2.364  loss_mask_8: 2.364  time: 1.9777  data_time: 0.4439  lr: 6.5604e-05  max_mem: 17500M
[01/27 17:45:56] d2.utils.events INFO:  eta: 1 day, 0:39:06  iter: 22459  total_loss: 28.71  loss_mask: 2.869  loss_mask_0: 2.899  loss_mask_1: 2.868  loss_mask_2: 2.869  loss_mask_3: 2.867  loss_mask_4: 2.869  loss_mask_5: 2.868  loss_mask_6: 2.867  loss_mask_7: 2.869  loss_mask_8: 2.869  time: 1.9780  data_time: 0.4433  lr: 6.5572e-05  max_mem: 17500M
[01/27 17:46:43] d2.utils.events INFO:  eta: 1 day, 0:38:11  iter: 22479  total_loss: 25.23  loss_mask: 2.521  loss_mask_0: 2.542  loss_mask_1: 2.521  loss_mask_2: 2.521  loss_mask_3: 2.521  loss_mask_4: 2.521  loss_mask_5: 2.521  loss_mask_6: 2.521  loss_mask_7: 2.521  loss_mask_8: 2.521  time: 1.9784  data_time: 0.4399  lr: 6.5541e-05  max_mem: 17500M
[01/27 17:47:31] d2.utils.events INFO:  eta: 1 day, 0:37:12  iter: 22499  total_loss: 25.96  loss_mask: 2.592  loss_mask_0: 2.629  loss_mask_1: 2.593  loss_mask_2: 2.592  loss_mask_3: 2.591  loss_mask_4: 2.592  loss_mask_5: 2.592  loss_mask_6: 2.592  loss_mask_7: 2.592  loss_mask_8: 2.592  time: 1.9788  data_time: 0.4540  lr: 6.5509e-05  max_mem: 17500M
[01/27 17:48:20] d2.utils.events INFO:  eta: 1 day, 0:36:34  iter: 22519  total_loss: 25.6  loss_mask: 2.557  loss_mask_0: 2.588  loss_mask_1: 2.556  loss_mask_2: 2.556  loss_mask_3: 2.556  loss_mask_4: 2.556  loss_mask_5: 2.556  loss_mask_6: 2.556  loss_mask_7: 2.557  loss_mask_8: 2.556  time: 1.9792  data_time: 0.4436  lr: 6.5478e-05  max_mem: 17500M
[01/27 17:49:07] d2.utils.events INFO:  eta: 1 day, 0:35:37  iter: 22539  total_loss: 24.61  loss_mask: 2.46  loss_mask_0: 2.473  loss_mask_1: 2.46  loss_mask_2: 2.46  loss_mask_3: 2.46  loss_mask_4: 2.46  loss_mask_5: 2.46  loss_mask_6: 2.46  loss_mask_7: 2.46  loss_mask_8: 2.46  time: 1.9795  data_time: 0.4161  lr: 6.5446e-05  max_mem: 17500M
[01/27 17:49:55] d2.utils.events INFO:  eta: 1 day, 0:35:11  iter: 22559  total_loss: 26.13  loss_mask: 2.609  loss_mask_0: 2.654  loss_mask_1: 2.609  loss_mask_2: 2.609  loss_mask_3: 2.609  loss_mask_4: 2.609  loss_mask_5: 2.609  loss_mask_6: 2.608  loss_mask_7: 2.609  loss_mask_8: 2.609  time: 1.9799  data_time: 0.4459  lr: 6.5415e-05  max_mem: 17500M
[01/27 17:50:44] d2.utils.events INFO:  eta: 1 day, 0:34:57  iter: 22579  total_loss: 26.2  loss_mask: 2.619  loss_mask_0: 2.637  loss_mask_1: 2.619  loss_mask_2: 2.619  loss_mask_3: 2.618  loss_mask_4: 2.618  loss_mask_5: 2.618  loss_mask_6: 2.618  loss_mask_7: 2.619  loss_mask_8: 2.618  time: 1.9803  data_time: 0.4354  lr: 6.5383e-05  max_mem: 17500M
[01/27 17:51:33] d2.utils.events INFO:  eta: 1 day, 0:34:39  iter: 22599  total_loss: 24.16  loss_mask: 2.412  loss_mask_0: 2.447  loss_mask_1: 2.411  loss_mask_2: 2.412  loss_mask_3: 2.412  loss_mask_4: 2.411  loss_mask_5: 2.412  loss_mask_6: 2.412  loss_mask_7: 2.412  loss_mask_8: 2.412  time: 1.9807  data_time: 0.4474  lr: 6.5352e-05  max_mem: 17500M
[01/27 17:52:22] d2.utils.events INFO:  eta: 1 day, 0:35:09  iter: 22619  total_loss: 25.85  loss_mask: 2.582  loss_mask_0: 2.615  loss_mask_1: 2.581  loss_mask_2: 2.581  loss_mask_3: 2.581  loss_mask_4: 2.581  loss_mask_5: 2.581  loss_mask_6: 2.582  loss_mask_7: 2.582  loss_mask_8: 2.582  time: 1.9811  data_time: 0.4428  lr: 6.5321e-05  max_mem: 17500M
[01/27 17:53:10] d2.utils.events INFO:  eta: 1 day, 0:34:54  iter: 22639  total_loss: 22.53  loss_mask: 2.25  loss_mask_0: 2.282  loss_mask_1: 2.25  loss_mask_2: 2.25  loss_mask_3: 2.25  loss_mask_4: 2.25  loss_mask_5: 2.25  loss_mask_6: 2.25  loss_mask_7: 2.25  loss_mask_8: 2.25  time: 1.9815  data_time: 0.4314  lr: 6.5289e-05  max_mem: 17500M
[01/27 17:53:59] d2.utils.events INFO:  eta: 1 day, 0:34:19  iter: 22659  total_loss: 23.11  loss_mask: 2.307  loss_mask_0: 2.353  loss_mask_1: 2.306  loss_mask_2: 2.307  loss_mask_3: 2.307  loss_mask_4: 2.307  loss_mask_5: 2.307  loss_mask_6: 2.307  loss_mask_7: 2.307  loss_mask_8: 2.307  time: 1.9819  data_time: 0.4625  lr: 6.5258e-05  max_mem: 17500M
[01/27 17:54:48] d2.utils.events INFO:  eta: 1 day, 0:33:43  iter: 22679  total_loss: 24.78  loss_mask: 2.474  loss_mask_0: 2.532  loss_mask_1: 2.474  loss_mask_2: 2.474  loss_mask_3: 2.474  loss_mask_4: 2.474  loss_mask_5: 2.475  loss_mask_6: 2.474  loss_mask_7: 2.475  loss_mask_8: 2.474  time: 1.9823  data_time: 0.4469  lr: 6.5226e-05  max_mem: 17500M
[01/27 17:55:36] d2.utils.events INFO:  eta: 1 day, 0:33:09  iter: 22699  total_loss: 24.17  loss_mask: 2.411  loss_mask_0: 2.461  loss_mask_1: 2.412  loss_mask_2: 2.412  loss_mask_3: 2.412  loss_mask_4: 2.411  loss_mask_5: 2.412  loss_mask_6: 2.412  loss_mask_7: 2.411  loss_mask_8: 2.412  time: 1.9827  data_time: 0.4498  lr: 6.5195e-05  max_mem: 17500M
[01/27 17:56:24] d2.utils.events INFO:  eta: 1 day, 0:32:26  iter: 22719  total_loss: 24.52  loss_mask: 2.448  loss_mask_0: 2.491  loss_mask_1: 2.447  loss_mask_2: 2.448  loss_mask_3: 2.448  loss_mask_4: 2.448  loss_mask_5: 2.448  loss_mask_6: 2.448  loss_mask_7: 2.448  loss_mask_8: 2.448  time: 1.9831  data_time: 0.4346  lr: 6.5163e-05  max_mem: 17500M
[01/27 17:57:12] d2.utils.events INFO:  eta: 1 day, 0:30:45  iter: 22739  total_loss: 23.59  loss_mask: 2.354  loss_mask_0: 2.4  loss_mask_1: 2.354  loss_mask_2: 2.354  loss_mask_3: 2.354  loss_mask_4: 2.354  loss_mask_5: 2.354  loss_mask_6: 2.354  loss_mask_7: 2.354  loss_mask_8: 2.354  time: 1.9834  data_time: 0.4118  lr: 6.5132e-05  max_mem: 17500M
[01/27 17:58:00] d2.utils.events INFO:  eta: 1 day, 0:29:31  iter: 22759  total_loss: 24.48  loss_mask: 2.443  loss_mask_0: 2.48  loss_mask_1: 2.443  loss_mask_2: 2.443  loss_mask_3: 2.444  loss_mask_4: 2.443  loss_mask_5: 2.443  loss_mask_6: 2.444  loss_mask_7: 2.442  loss_mask_8: 2.443  time: 1.9838  data_time: 0.4159  lr: 6.51e-05  max_mem: 17500M
[01/27 17:58:48] d2.utils.events INFO:  eta: 1 day, 0:28:29  iter: 22779  total_loss: 23.4  loss_mask: 2.337  loss_mask_0: 2.364  loss_mask_1: 2.337  loss_mask_2: 2.337  loss_mask_3: 2.337  loss_mask_4: 2.337  loss_mask_5: 2.337  loss_mask_6: 2.337  loss_mask_7: 2.337  loss_mask_8: 2.337  time: 1.9841  data_time: 0.4434  lr: 6.5069e-05  max_mem: 17500M
[01/27 17:59:35] d2.utils.events INFO:  eta: 1 day, 0:27:27  iter: 22799  total_loss: 24.01  loss_mask: 2.397  loss_mask_0: 2.424  loss_mask_1: 2.397  loss_mask_2: 2.397  loss_mask_3: 2.397  loss_mask_4: 2.397  loss_mask_5: 2.397  loss_mask_6: 2.397  loss_mask_7: 2.397  loss_mask_8: 2.397  time: 1.9845  data_time: 0.4298  lr: 6.5037e-05  max_mem: 17500M
[01/27 18:00:24] d2.utils.events INFO:  eta: 1 day, 0:27:18  iter: 22819  total_loss: 23.26  loss_mask: 2.322  loss_mask_0: 2.36  loss_mask_1: 2.322  loss_mask_2: 2.322  loss_mask_3: 2.323  loss_mask_4: 2.322  loss_mask_5: 2.322  loss_mask_6: 2.323  loss_mask_7: 2.323  loss_mask_8: 2.322  time: 1.9849  data_time: 0.4328  lr: 6.5006e-05  max_mem: 17500M
[01/27 18:01:11] d2.utils.events INFO:  eta: 1 day, 0:25:56  iter: 22839  total_loss: 24.04  loss_mask: 2.4  loss_mask_0: 2.444  loss_mask_1: 2.399  loss_mask_2: 2.4  loss_mask_3: 2.4  loss_mask_4: 2.4  loss_mask_5: 2.4  loss_mask_6: 2.4  loss_mask_7: 2.399  loss_mask_8: 2.4  time: 1.9852  data_time: 0.4269  lr: 6.4974e-05  max_mem: 17500M
[01/27 18:01:58] d2.utils.events INFO:  eta: 1 day, 0:24:03  iter: 22859  total_loss: 22.74  loss_mask: 2.271  loss_mask_0: 2.298  loss_mask_1: 2.271  loss_mask_2: 2.271  loss_mask_3: 2.271  loss_mask_4: 2.271  loss_mask_5: 2.271  loss_mask_6: 2.271  loss_mask_7: 2.271  loss_mask_8: 2.271  time: 1.9855  data_time: 0.4045  lr: 6.4943e-05  max_mem: 17500M
[01/27 18:02:46] d2.utils.events INFO:  eta: 1 day, 0:24:32  iter: 22879  total_loss: 23.58  loss_mask: 2.357  loss_mask_0: 2.363  loss_mask_1: 2.357  loss_mask_2: 2.357  loss_mask_3: 2.357  loss_mask_4: 2.357  loss_mask_5: 2.357  loss_mask_6: 2.357  loss_mask_7: 2.357  loss_mask_8: 2.357  time: 1.9859  data_time: 0.4318  lr: 6.4911e-05  max_mem: 17500M
[01/27 18:03:35] d2.utils.events INFO:  eta: 1 day, 0:25:17  iter: 22899  total_loss: 24.64  loss_mask: 2.46  loss_mask_0: 2.506  loss_mask_1: 2.461  loss_mask_2: 2.46  loss_mask_3: 2.461  loss_mask_4: 2.46  loss_mask_5: 2.46  loss_mask_6: 2.46  loss_mask_7: 2.46  loss_mask_8: 2.46  time: 1.9863  data_time: 0.4210  lr: 6.488e-05  max_mem: 17500M
[01/27 18:04:23] d2.utils.events INFO:  eta: 1 day, 0:24:36  iter: 22919  total_loss: 24.08  loss_mask: 2.402  loss_mask_0: 2.466  loss_mask_1: 2.402  loss_mask_2: 2.402  loss_mask_3: 2.402  loss_mask_4: 2.402  loss_mask_5: 2.402  loss_mask_6: 2.402  loss_mask_7: 2.401  loss_mask_8: 2.402  time: 1.9866  data_time: 0.4420  lr: 6.4849e-05  max_mem: 17500M
[01/27 18:05:12] d2.utils.events INFO:  eta: 1 day, 0:24:00  iter: 22939  total_loss: 23.61  loss_mask: 2.356  loss_mask_0: 2.402  loss_mask_1: 2.357  loss_mask_2: 2.357  loss_mask_3: 2.357  loss_mask_4: 2.357  loss_mask_5: 2.357  loss_mask_6: 2.357  loss_mask_7: 2.357  loss_mask_8: 2.357  time: 1.9870  data_time: 0.4531  lr: 6.4817e-05  max_mem: 17500M
[01/27 18:06:00] d2.utils.events INFO:  eta: 1 day, 0:23:13  iter: 22959  total_loss: 26.04  loss_mask: 2.602  loss_mask_0: 2.632  loss_mask_1: 2.602  loss_mask_2: 2.602  loss_mask_3: 2.603  loss_mask_4: 2.601  loss_mask_5: 2.601  loss_mask_6: 2.602  loss_mask_7: 2.602  loss_mask_8: 2.602  time: 1.9874  data_time: 0.4054  lr: 6.4786e-05  max_mem: 17500M
[01/27 18:06:48] d2.utils.events INFO:  eta: 1 day, 0:23:00  iter: 22979  total_loss: 25.93  loss_mask: 2.592  loss_mask_0: 2.61  loss_mask_1: 2.592  loss_mask_2: 2.592  loss_mask_3: 2.592  loss_mask_4: 2.592  loss_mask_5: 2.591  loss_mask_6: 2.592  loss_mask_7: 2.592  loss_mask_8: 2.592  time: 1.9878  data_time: 0.4410  lr: 6.4754e-05  max_mem: 17500M
[01/27 18:07:36] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 18:07:37] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 18:07:37] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 18:15:34] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.7665981122696865, 'error_1pix': 0.39102115095590917, 'error_3pix': 0.17965201602868183, 'mIoU': 5.715951611253383, 'fwIoU': 17.352513630311275, 'IoU-0': nan, 'IoU-1': 53.182427735847725, 'IoU-2': 3.1355169602156305, 'IoU-3': 3.7504720082712417, 'IoU-4': 3.4903498392552637, 'IoU-5': 3.372299092834987, 'IoU-6': 3.7591813041549074, 'IoU-7': 3.157241315989597, 'IoU-8': 4.198488962444523, 'IoU-9': 7.547871733992978, 'IoU-10': 14.10357488803166, 'IoU-11': 23.97562115949907, 'IoU-12': 24.3479932279566, 'IoU-13': 26.118421412257792, 'IoU-14': 26.13517574421068, 'IoU-15': 26.017265985151216, 'IoU-16': 28.557468313052496, 'IoU-17': 24.748219669410084, 'IoU-18': 24.634876123058213, 'IoU-19': 24.7705235009288, 'IoU-20': 23.794177489043022, 'IoU-21': 22.382044577907788, 'IoU-22': 21.70466965350954, 'IoU-23': 18.932624023107277, 'IoU-24': 17.634020158975115, 'IoU-25': 16.260681457165692, 'IoU-26': 15.393302578604926, 'IoU-27': 14.935116537594883, 'IoU-28': 13.435766210099892, 'IoU-29': 13.341224428007973, 'IoU-30': 12.834991335785839, 'IoU-31': 13.206296596874974, 'IoU-32': 12.308903870800853, 'IoU-33': 11.360920728158055, 'IoU-34': 11.334887569986227, 'IoU-35': 11.717470381367587, 'IoU-36': 12.304754526535183, 'IoU-37': 12.39646375186479, 'IoU-38': 12.996354799354954, 'IoU-39': 12.985856729008772, 'IoU-40': 12.9342300125759, 'IoU-41': 12.277549526060795, 'IoU-42': 11.746297894849246, 'IoU-43': 12.059485264260598, 'IoU-44': 12.001485333560737, 'IoU-45': 12.405960889410341, 'IoU-46': 11.848551836730275, 'IoU-47': 11.819362647331966, 'IoU-48': 11.69583729065655, 'IoU-49': 11.395892505638034, 'IoU-50': 11.864504684282176, 'IoU-51': 10.996758146029968, 'IoU-52': 10.957881223193484, 'IoU-53': 11.252763430615973, 'IoU-54': 11.529662026431273, 'IoU-55': 10.555479764744442, 'IoU-56': 10.52116747791975, 'IoU-57': 10.525828324895802, 'IoU-58': 10.04307856779509, 'IoU-59': 9.510143504152344, 'IoU-60': 9.206481508882357, 'IoU-61': 8.521228003006042, 'IoU-62': 8.359932666202909, 'IoU-63': 8.091576058368654, 'IoU-64': 7.578527288413815, 'IoU-65': 6.8869804318742265, 'IoU-66': 6.771045502709051, 'IoU-67': 6.449282597751761, 'IoU-68': 5.974721776229896, 'IoU-69': 5.929308364736004, 'IoU-70': 5.777538335511103, 'IoU-71': 5.2569620892233475, 'IoU-72': 5.027408383927264, 'IoU-73': 5.082420485434188, 'IoU-74': 4.951163592215885, 'IoU-75': 4.726999913768375, 'IoU-76': 4.394907853828077, 'IoU-77': 3.800762121688265, 'IoU-78': 3.5538045752603824, 'IoU-79': 3.4595630151026415, 'IoU-80': 3.266881876587624, 'IoU-81': 3.2684005222618975, 'IoU-82': 2.9861500542341033, 'IoU-83': 3.0529688336456777, 'IoU-84': 2.9465825223212967, 'IoU-85': 2.711978646603929, 'IoU-86': 2.456556492915005, 'IoU-87': 2.231250174221018, 'IoU-88': 2.212561783460888, 'IoU-89': 2.191109097201214, 'IoU-90': 2.0547862224374818, 'IoU-91': 1.9375926050556238, 'IoU-92': 1.7856297370725127, 'IoU-93': 1.690221008797296, 'IoU-94': 1.6571804349675188, 'IoU-95': 1.5787094768308654, 'IoU-96': 1.4175934978944575, 'IoU-97': 1.3117314802227358, 'IoU-98': 1.2445068579836325, 'IoU-99': 1.1946139983061144, 'IoU-100': 1.1773337768045966, 'IoU-101': 1.2045875590840793, 'IoU-102': 1.1550697767598437, 'IoU-103': 1.154029563600876, 'IoU-104': 1.102469457972266, 'IoU-105': 1.1013688274728652, 'IoU-106': 1.103767419337278, 'IoU-107': 1.0625162011835196, 'IoU-108': 1.1366241011612344, 'IoU-109': 1.255359193438033, 'IoU-110': 1.1391294631316846, 'IoU-111': 0.8635186423697979, 'IoU-112': 0.8649737030015913, 'IoU-113': 0.8406431919451294, 'IoU-114': 0.8054492207210695, 'IoU-115': 0.7562364464896421, 'IoU-116': 0.7815809667443577, 'IoU-117': 0.8469329677870991, 'IoU-118': 0.8787511315308545, 'IoU-119': 0.9374613126781068, 'IoU-120': 0.968722627090518, 'IoU-121': 0.8163045676249229, 'IoU-122': 0.77769839453832, 'IoU-123': 0.759389037966532, 'IoU-124': 0.781233312685563, 'IoU-125': 0.8094509239996874, 'IoU-126': 0.7774821617162897, 'IoU-127': 0.9883444739689166, 'IoU-128': 0.8851059501825961, 'IoU-129': 0.8640203786774264, 'IoU-130': 0.8717157736417522, 'IoU-131': 0.7992339166762535, 'IoU-132': 0.8083967593091055, 'IoU-133': 0.8125321458412602, 'IoU-134': 0.7992596430668103, 'IoU-135': 0.7657243578020356, 'IoU-136': 0.6983030764253922, 'IoU-137': 0.7032649196121622, 'IoU-138': 0.6716457014983339, 'IoU-139': 0.6987058972190808, 'IoU-140': 0.7047087570839864, 'IoU-141': 0.7431255247942951, 'IoU-142': 0.7400083486085073, 'IoU-143': 0.7354249873632203, 'IoU-144': 0.7769096433844612, 'IoU-145': 0.8497655672677545, 'IoU-146': 0.9324470966802134, 'IoU-147': 0.9633994665886282, 'IoU-148': 1.0053700809774115, 'IoU-149': 0.9877338312279167, 'IoU-150': 1.0622735991376067, 'IoU-151': 1.1136402785638704, 'IoU-152': 1.1768570391913065, 'IoU-153': 1.0372883763532288, 'IoU-154': 1.1321525746374121, 'IoU-155': 1.201039336349324, 'IoU-156': 1.2415735386643498, 'IoU-157': 1.2162179938051652, 'IoU-158': 1.3781432889574892, 'IoU-159': 1.232140176031619, 'IoU-160': 1.291789996427411, 'IoU-161': 1.2825742532254039, 'IoU-162': 1.1713200743088186, 'IoU-163': 1.176327969069978, 'IoU-164': 1.2216822126492806, 'IoU-165': 1.2738572088777667, 'IoU-166': 1.2884659879685332, 'IoU-167': 1.090886244596154, 'IoU-168': 1.1342926412234038, 'IoU-169': 1.1824424208378914, 'IoU-170': 1.1711733421817043, 'IoU-171': 1.1787830605792409, 'IoU-172': 1.1577529686289794, 'IoU-173': 1.0989454686037932, 'IoU-174': 1.0007388481064103, 'IoU-175': 0.9650132911982615, 'IoU-176': 0.7522533715860573, 'IoU-177': 0.7636027323471919, 'IoU-178': 0.8162847432910583, 'IoU-179': 0.7210490031937195, 'IoU-180': 0.827004064779949, 'IoU-181': 0.8427080840048581, 'IoU-182': 0.6687865939834444, 'IoU-183': 0.5281925935846783, 'IoU-184': 0.2574430279908366, 'IoU-185': 0.20045234821943325, 'IoU-186': 0.13344136819746574, 'IoU-187': 0.07410722107391544, 'IoU-188': 0.04114754261887899, 'IoU-189': 0.03953869818198515, 'IoU-190': 0.0480258504360173, 'IoU-191': 0.05856843135519541, 'IoU-192': 0.062396241544038764, 'mACC': 10.1418848745351, 'pACC': 26.043770409356426, 'ACC-0': nan, 'ACC-1': 53.95483656640868, 'ACC-2': 6.175172618836309, 'ACC-3': 17.523356387391363, 'ACC-4': 14.955942912849974, 'ACC-5': 14.754207021935065, 'ACC-6': 16.496015259460847, 'ACC-7': 14.419272855887492, 'ACC-8': 9.135355836933842, 'ACC-9': 10.766143006195342, 'ACC-10': 20.030185865633623, 'ACC-11': 32.244395884293155, 'ACC-12': 36.67479952610995, 'ACC-13': 41.80482816400581, 'ACC-14': 41.413569062344315, 'ACC-15': 42.93417699646986, 'ACC-16': 48.17734155563799, 'ACC-17': 43.48270330791667, 'ACC-18': 40.94904287594032, 'ACC-19': 41.17426054497703, 'ACC-20': 40.923935026071945, 'ACC-21': 38.81731426043201, 'ACC-22': 36.582882806042996, 'ACC-23': 33.64905326691098, 'ACC-24': 31.48856682123017, 'ACC-25': 28.90483426987372, 'ACC-26': 28.305495095307563, 'ACC-27': 26.89197735276861, 'ACC-28': 24.752903398219683, 'ACC-29': 23.971670046845784, 'ACC-30': 23.644087353520153, 'ACC-31': 23.755371495595153, 'ACC-32': 22.001858949688554, 'ACC-33': 20.704385501706735, 'ACC-34': 20.911102187917844, 'ACC-35': 21.278681564398834, 'ACC-36': 21.59812022221136, 'ACC-37': 21.787739518048017, 'ACC-38': 22.829108800669896, 'ACC-39': 22.935680032199166, 'ACC-40': 22.535578025484867, 'ACC-41': 22.07427422350693, 'ACC-42': 21.255393445136946, 'ACC-43': 21.81874123110235, 'ACC-44': 20.994598101412404, 'ACC-45': 21.648096416788327, 'ACC-46': 21.25165586079041, 'ACC-47': 21.31117944285775, 'ACC-48': 21.128832492860987, 'ACC-49': 20.455358678034465, 'ACC-50': 21.02908899004911, 'ACC-51': 19.396784906832124, 'ACC-52': 19.402535082896605, 'ACC-53': 20.118308612922526, 'ACC-54': 20.427045529747673, 'ACC-55': 18.927454725774652, 'ACC-56': 19.112748299805833, 'ACC-57': 18.90876403725637, 'ACC-58': 18.167637512522454, 'ACC-59': 17.465596103157562, 'ACC-60': 16.895720622244543, 'ACC-61': 15.655308119470918, 'ACC-62': 15.537814672458838, 'ACC-63': 15.308007103784012, 'ACC-64': 14.351201570847163, 'ACC-65': 13.043795226934046, 'ACC-66': 12.92979320376561, 'ACC-67': 12.424004013760376, 'ACC-68': 11.618590633876147, 'ACC-69': 11.387676716513935, 'ACC-70': 10.981149755216657, 'ACC-71': 10.20649901014771, 'ACC-72': 9.864307624324356, 'ACC-73': 10.01772763615165, 'ACC-74': 9.845955796371072, 'ACC-75': 9.38627709423755, 'ACC-76': 8.57467447329213, 'ACC-77': 7.521550260799474, 'ACC-78': 7.092881562580902, 'ACC-79': 6.891723901110376, 'ACC-80': 6.424230454800944, 'ACC-81': 6.395757642238318, 'ACC-82': 5.848631246457996, 'ACC-83': 5.891400620962821, 'ACC-84': 5.655645511694266, 'ACC-85': 5.17137185901967, 'ACC-86': 4.688616715295446, 'ACC-87': 4.269780236451601, 'ACC-88': 4.221610614392715, 'ACC-89': 4.164119566508432, 'ACC-90': 3.8885189284277617, 'ACC-91': 3.6865328525656293, 'ACC-92': 3.378576784394628, 'ACC-93': 3.172699229556781, 'ACC-94': 3.0867672138007207, 'ACC-95': 2.895529623601925, 'ACC-96': 2.593678563179313, 'ACC-97': 2.359048689834953, 'ACC-98': 2.2516793493066416, 'ACC-99': 2.1757441914460505, 'ACC-100': 2.1428304979049537, 'ACC-101': 2.213143365126528, 'ACC-102': 2.129136018896252, 'ACC-103': 2.1252730650371197, 'ACC-104': 2.0478837215021763, 'ACC-105': 2.0524569849811685, 'ACC-106': 2.030975443531818, 'ACC-107': 1.9508319952656334, 'ACC-108': 2.0639078804132294, 'ACC-109': 2.2543420606875006, 'ACC-110': 2.056595132617461, 'ACC-111': 1.5732332230503112, 'ACC-112': 1.5924510473200897, 'ACC-113': 1.5421480352532593, 'ACC-114': 1.4979243781972065, 'ACC-115': 1.416001383188249, 'ACC-116': 1.479937618988478, 'ACC-117': 1.5809349150183192, 'ACC-118': 1.6417705526773556, 'ACC-119': 1.7310898347313382, 'ACC-120': 1.7769810780395796, 'ACC-121': 1.5090203744776023, 'ACC-122': 1.4414503665543887, 'ACC-123': 1.4115724467058377, 'ACC-124': 1.480847327874206, 'ACC-125': 1.5214882478411682, 'ACC-126': 1.485100891800524, 'ACC-127': 1.883493036192176, 'ACC-128': 1.6982765980802303, 'ACC-129': 1.6474444937401127, 'ACC-130': 1.6405558722845506, 'ACC-131': 1.4820766485037347, 'ACC-132': 1.4643463924158802, 'ACC-133': 1.445766736750427, 'ACC-134': 1.4068418785006465, 'ACC-135': 1.351619063907417, 'ACC-136': 1.2304032333209094, 'ACC-137': 1.251551273303445, 'ACC-138': 1.2098891562901068, 'ACC-139': 1.2647642596492896, 'ACC-140': 1.2456786381021954, 'ACC-141': 1.3026434935991302, 'ACC-142': 1.3020301155050662, 'ACC-143': 1.2995637268777493, 'ACC-144': 1.3510879100646573, 'ACC-145': 1.4317864279491295, 'ACC-146': 1.561856023394485, 'ACC-147': 1.613953052183739, 'ACC-148': 1.6816707206603494, 'ACC-149': 1.695320906185888, 'ACC-150': 1.8385276769344463, 'ACC-151': 1.9292686748028045, 'ACC-152': 1.9856594191063743, 'ACC-153': 1.7727783872423168, 'ACC-154': 1.951874200809494, 'ACC-155': 2.081854218435688, 'ACC-156': 2.1429171649267964, 'ACC-157': 2.139297997759712, 'ACC-158': 2.4194754862802768, 'ACC-159': 2.1523821945735357, 'ACC-160': 2.259648964056566, 'ACC-161': 2.2075808446970173, 'ACC-162': 2.0411229746838266, 'ACC-163': 2.0767154112614996, 'ACC-164': 2.1956486581618577, 'ACC-165': 2.289613198946676, 'ACC-166': 2.393504496215657, 'ACC-167': 2.0511724708228667, 'ACC-168': 2.1602745795851765, 'ACC-169': 2.2457595889617705, 'ACC-170': 2.242544816289153, 'ACC-171': 2.248545059079419, 'ACC-172': 2.173369463547812, 'ACC-173': 2.0485849766671684, 'ACC-174': 1.840821341148528, 'ACC-175': 1.7030356934831612, 'ACC-176': 1.2689259221623819, 'ACC-177': 1.2482486307476754, 'ACC-178': 1.2632620292957768, 'ACC-179': 1.0402015047910158, 'ACC-180': 1.1467894764702768, 'ACC-181': 1.1265649368810766, 'ACC-182': 0.8169179074570732, 'ACC-183': 0.5948018466193621, 'ACC-184': 0.27420470018005005, 'ACC-185': 0.2088951434189942, 'ACC-186': 0.13769875386170605, 'ACC-187': 0.07566874977335639, 'ACC-188': 0.041636070463371616, 'ACC-189': 0.03982548728410732, 'ACC-190': 0.04826913189015624, 'ACC-191': 0.05880461969092292, 'ACC-192': 0.06261066647779588})])
[01/27 18:15:34] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 18:15:34] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 18:15:34] d2.evaluation.testing INFO: copypaste: 2.7666,0.3910,0.1797,5.7160,17.3525,10.1419,26.0438
[01/27 18:15:35] d2.utils.events INFO:  eta: 1 day, 0:22:33  iter: 22999  total_loss: 22.7  loss_mask: 2.269  loss_mask_0: 2.28  loss_mask_1: 2.27  loss_mask_2: 2.269  loss_mask_3: 2.27  loss_mask_4: 2.269  loss_mask_5: 2.269  loss_mask_6: 2.27  loss_mask_7: 2.269  loss_mask_8: 2.269  time: 1.9881  data_time: 0.4192  lr: 6.4723e-05  max_mem: 17500M
[01/27 18:16:23] d2.utils.events INFO:  eta: 1 day, 0:22:51  iter: 23019  total_loss: 26.49  loss_mask: 2.646  loss_mask_0: 2.671  loss_mask_1: 2.646  loss_mask_2: 2.646  loss_mask_3: 2.646  loss_mask_4: 2.646  loss_mask_5: 2.647  loss_mask_6: 2.647  loss_mask_7: 2.647  loss_mask_8: 2.646  time: 1.9885  data_time: 0.4423  lr: 6.4691e-05  max_mem: 17500M
[01/27 18:17:12] d2.utils.events INFO:  eta: 1 day, 0:23:58  iter: 23039  total_loss: 27.08  loss_mask: 2.705  loss_mask_0: 2.73  loss_mask_1: 2.705  loss_mask_2: 2.705  loss_mask_3: 2.705  loss_mask_4: 2.706  loss_mask_5: 2.706  loss_mask_6: 2.705  loss_mask_7: 2.705  loss_mask_8: 2.706  time: 1.9889  data_time: 0.4291  lr: 6.466e-05  max_mem: 17500M
[01/27 18:18:01] d2.utils.events INFO:  eta: 1 day, 0:24:53  iter: 23059  total_loss: 27.45  loss_mask: 2.731  loss_mask_0: 2.869  loss_mask_1: 2.731  loss_mask_2: 2.731  loss_mask_3: 2.732  loss_mask_4: 2.731  loss_mask_5: 2.73  loss_mask_6: 2.732  loss_mask_7: 2.73  loss_mask_8: 2.732  time: 1.9893  data_time: 0.4526  lr: 6.4628e-05  max_mem: 17500M
[01/27 18:18:50] d2.utils.events INFO:  eta: 1 day, 0:25:17  iter: 23079  total_loss: 26.39  loss_mask: 2.633  loss_mask_0: 2.689  loss_mask_1: 2.634  loss_mask_2: 2.634  loss_mask_3: 2.634  loss_mask_4: 2.634  loss_mask_5: 2.633  loss_mask_6: 2.633  loss_mask_7: 2.633  loss_mask_8: 2.634  time: 1.9897  data_time: 0.4665  lr: 6.4597e-05  max_mem: 17500M
[01/27 18:19:38] d2.utils.events INFO:  eta: 1 day, 0:26:09  iter: 23099  total_loss: 23.29  loss_mask: 2.325  loss_mask_0: 2.342  loss_mask_1: 2.325  loss_mask_2: 2.325  loss_mask_3: 2.325  loss_mask_4: 2.326  loss_mask_5: 2.324  loss_mask_6: 2.325  loss_mask_7: 2.325  loss_mask_8: 2.325  time: 1.9900  data_time: 0.4249  lr: 6.4565e-05  max_mem: 17500M
[01/27 18:20:26] d2.utils.events INFO:  eta: 1 day, 0:26:35  iter: 23119  total_loss: 22.84  loss_mask: 2.281  loss_mask_0: 2.309  loss_mask_1: 2.281  loss_mask_2: 2.281  loss_mask_3: 2.281  loss_mask_4: 2.281  loss_mask_5: 2.281  loss_mask_6: 2.281  loss_mask_7: 2.281  loss_mask_8: 2.281  time: 1.9904  data_time: 0.4407  lr: 6.4534e-05  max_mem: 17500M
[01/27 18:21:15] d2.utils.events INFO:  eta: 1 day, 0:26:39  iter: 23139  total_loss: 23.92  loss_mask: 2.391  loss_mask_0: 2.429  loss_mask_1: 2.392  loss_mask_2: 2.392  loss_mask_3: 2.392  loss_mask_4: 2.392  loss_mask_5: 2.392  loss_mask_6: 2.392  loss_mask_7: 2.392  loss_mask_8: 2.392  time: 1.9908  data_time: 0.4564  lr: 6.4502e-05  max_mem: 17500M
[01/27 18:22:04] d2.utils.events INFO:  eta: 1 day, 0:27:04  iter: 23159  total_loss: 23.52  loss_mask: 2.349  loss_mask_0: 2.38  loss_mask_1: 2.348  loss_mask_2: 2.348  loss_mask_3: 2.348  loss_mask_4: 2.348  loss_mask_5: 2.349  loss_mask_6: 2.349  loss_mask_7: 2.349  loss_mask_8: 2.348  time: 1.9912  data_time: 0.4491  lr: 6.4471e-05  max_mem: 17500M
[01/27 18:22:51] d2.utils.events INFO:  eta: 1 day, 0:26:29  iter: 23179  total_loss: 23.53  loss_mask: 2.351  loss_mask_0: 2.373  loss_mask_1: 2.351  loss_mask_2: 2.351  loss_mask_3: 2.351  loss_mask_4: 2.351  loss_mask_5: 2.351  loss_mask_6: 2.351  loss_mask_7: 2.351  loss_mask_8: 2.351  time: 1.9915  data_time: 0.4128  lr: 6.4439e-05  max_mem: 17500M
[01/27 18:23:40] d2.utils.events INFO:  eta: 1 day, 0:26:23  iter: 23199  total_loss: 23.88  loss_mask: 2.386  loss_mask_0: 2.405  loss_mask_1: 2.386  loss_mask_2: 2.386  loss_mask_3: 2.386  loss_mask_4: 2.386  loss_mask_5: 2.386  loss_mask_6: 2.386  loss_mask_7: 2.386  loss_mask_8: 2.386  time: 1.9919  data_time: 0.4216  lr: 6.4408e-05  max_mem: 17500M
[01/27 18:24:26] d2.utils.events INFO:  eta: 1 day, 0:25:00  iter: 23219  total_loss: 22.96  loss_mask: 2.294  loss_mask_0: 2.315  loss_mask_1: 2.294  loss_mask_2: 2.294  loss_mask_3: 2.295  loss_mask_4: 2.294  loss_mask_5: 2.294  loss_mask_6: 2.294  loss_mask_7: 2.294  loss_mask_8: 2.295  time: 1.9921  data_time: 0.4093  lr: 6.4376e-05  max_mem: 17500M
[01/27 18:25:13] d2.utils.events INFO:  eta: 1 day, 0:24:48  iter: 23239  total_loss: 23.72  loss_mask: 2.368  loss_mask_0: 2.377  loss_mask_1: 2.368  loss_mask_2: 2.369  loss_mask_3: 2.369  loss_mask_4: 2.369  loss_mask_5: 2.368  loss_mask_6: 2.368  loss_mask_7: 2.368  loss_mask_8: 2.368  time: 1.9925  data_time: 0.4309  lr: 6.4345e-05  max_mem: 17500M
[01/27 18:26:02] d2.utils.events INFO:  eta: 1 day, 0:26:01  iter: 23259  total_loss: 24.31  loss_mask: 2.426  loss_mask_0: 2.478  loss_mask_1: 2.425  loss_mask_2: 2.426  loss_mask_3: 2.425  loss_mask_4: 2.425  loss_mask_5: 2.425  loss_mask_6: 2.426  loss_mask_7: 2.426  loss_mask_8: 2.426  time: 1.9928  data_time: 0.4526  lr: 6.4313e-05  max_mem: 17500M
[01/27 18:26:50] d2.utils.events INFO:  eta: 1 day, 0:26:30  iter: 23279  total_loss: 22.99  loss_mask: 2.295  loss_mask_0: 2.336  loss_mask_1: 2.295  loss_mask_2: 2.295  loss_mask_3: 2.295  loss_mask_4: 2.295  loss_mask_5: 2.295  loss_mask_6: 2.295  loss_mask_7: 2.295  loss_mask_8: 2.295  time: 1.9932  data_time: 0.4210  lr: 6.4282e-05  max_mem: 17500M
[01/27 18:27:38] d2.utils.events INFO:  eta: 1 day, 0:26:21  iter: 23299  total_loss: 22.42  loss_mask: 2.239  loss_mask_0: 2.266  loss_mask_1: 2.239  loss_mask_2: 2.239  loss_mask_3: 2.239  loss_mask_4: 2.24  loss_mask_5: 2.239  loss_mask_6: 2.239  loss_mask_7: 2.239  loss_mask_8: 2.239  time: 1.9935  data_time: 0.4250  lr: 6.425e-05  max_mem: 17500M
[01/27 18:28:26] d2.utils.events INFO:  eta: 1 day, 0:26:27  iter: 23319  total_loss: 23.33  loss_mask: 2.329  loss_mask_0: 2.379  loss_mask_1: 2.328  loss_mask_2: 2.329  loss_mask_3: 2.328  loss_mask_4: 2.329  loss_mask_5: 2.328  loss_mask_6: 2.328  loss_mask_7: 2.328  loss_mask_8: 2.329  time: 1.9939  data_time: 0.4362  lr: 6.4219e-05  max_mem: 17500M
[01/27 18:29:15] d2.utils.events INFO:  eta: 1 day, 0:26:51  iter: 23339  total_loss: 22.86  loss_mask: 2.285  loss_mask_0: 2.301  loss_mask_1: 2.284  loss_mask_2: 2.285  loss_mask_3: 2.284  loss_mask_4: 2.284  loss_mask_5: 2.284  loss_mask_6: 2.284  loss_mask_7: 2.284  loss_mask_8: 2.285  time: 1.9943  data_time: 0.4383  lr: 6.4187e-05  max_mem: 17500M
[01/27 18:30:03] d2.utils.events INFO:  eta: 1 day, 0:27:06  iter: 23359  total_loss: 22.91  loss_mask: 2.288  loss_mask_0: 2.321  loss_mask_1: 2.288  loss_mask_2: 2.288  loss_mask_3: 2.288  loss_mask_4: 2.288  loss_mask_5: 2.288  loss_mask_6: 2.288  loss_mask_7: 2.288  loss_mask_8: 2.288  time: 1.9946  data_time: 0.4337  lr: 6.4156e-05  max_mem: 17500M
[01/27 18:30:52] d2.utils.events INFO:  eta: 1 day, 0:27:36  iter: 23379  total_loss: 23.64  loss_mask: 2.362  loss_mask_0: 2.389  loss_mask_1: 2.361  loss_mask_2: 2.362  loss_mask_3: 2.362  loss_mask_4: 2.361  loss_mask_5: 2.361  loss_mask_6: 2.361  loss_mask_7: 2.362  loss_mask_8: 2.362  time: 1.9950  data_time: 0.4374  lr: 6.4124e-05  max_mem: 17500M
[01/27 18:31:40] d2.utils.events INFO:  eta: 1 day, 0:27:17  iter: 23399  total_loss: 22.57  loss_mask: 2.251  loss_mask_0: 2.303  loss_mask_1: 2.251  loss_mask_2: 2.251  loss_mask_3: 2.251  loss_mask_4: 2.251  loss_mask_5: 2.252  loss_mask_6: 2.252  loss_mask_7: 2.251  loss_mask_8: 2.252  time: 1.9954  data_time: 0.4403  lr: 6.4093e-05  max_mem: 17500M
[01/27 18:32:29] d2.utils.events INFO:  eta: 1 day, 0:27:16  iter: 23419  total_loss: 23.87  loss_mask: 2.385  loss_mask_0: 2.402  loss_mask_1: 2.386  loss_mask_2: 2.385  loss_mask_3: 2.385  loss_mask_4: 2.386  loss_mask_5: 2.386  loss_mask_6: 2.386  loss_mask_7: 2.385  loss_mask_8: 2.385  time: 1.9957  data_time: 0.4451  lr: 6.4061e-05  max_mem: 17500M
[01/27 18:33:17] d2.utils.events INFO:  eta: 1 day, 0:26:35  iter: 23439  total_loss: 23.79  loss_mask: 2.378  loss_mask_0: 2.392  loss_mask_1: 2.377  loss_mask_2: 2.378  loss_mask_3: 2.377  loss_mask_4: 2.378  loss_mask_5: 2.378  loss_mask_6: 2.378  loss_mask_7: 2.378  loss_mask_8: 2.378  time: 1.9961  data_time: 0.4134  lr: 6.403e-05  max_mem: 17500M
[01/27 18:34:06] d2.utils.events INFO:  eta: 1 day, 0:26:34  iter: 23459  total_loss: 24.25  loss_mask: 2.421  loss_mask_0: 2.46  loss_mask_1: 2.42  loss_mask_2: 2.42  loss_mask_3: 2.42  loss_mask_4: 2.42  loss_mask_5: 2.42  loss_mask_6: 2.42  loss_mask_7: 2.42  loss_mask_8: 2.42  time: 1.9965  data_time: 0.4446  lr: 6.3998e-05  max_mem: 17500M
[01/27 18:34:55] d2.utils.events INFO:  eta: 1 day, 0:26:28  iter: 23479  total_loss: 23.9  loss_mask: 2.385  loss_mask_0: 2.437  loss_mask_1: 2.384  loss_mask_2: 2.384  loss_mask_3: 2.384  loss_mask_4: 2.384  loss_mask_5: 2.385  loss_mask_6: 2.385  loss_mask_7: 2.385  loss_mask_8: 2.384  time: 1.9969  data_time: 0.4196  lr: 6.3966e-05  max_mem: 17500M
[01/27 18:35:44] d2.utils.events INFO:  eta: 1 day, 0:26:05  iter: 23499  total_loss: 23.86  loss_mask: 2.384  loss_mask_0: 2.408  loss_mask_1: 2.383  loss_mask_2: 2.383  loss_mask_3: 2.383  loss_mask_4: 2.383  loss_mask_5: 2.384  loss_mask_6: 2.383  loss_mask_7: 2.383  loss_mask_8: 2.383  time: 1.9972  data_time: 0.4564  lr: 6.3935e-05  max_mem: 17500M
[01/27 18:36:32] d2.utils.events INFO:  eta: 1 day, 0:25:21  iter: 23519  total_loss: 24.46  loss_mask: 2.443  loss_mask_0: 2.482  loss_mask_1: 2.443  loss_mask_2: 2.443  loss_mask_3: 2.443  loss_mask_4: 2.443  loss_mask_5: 2.443  loss_mask_6: 2.443  loss_mask_7: 2.443  loss_mask_8: 2.443  time: 1.9976  data_time: 0.4439  lr: 6.3903e-05  max_mem: 17500M
[01/27 18:37:21] d2.utils.events INFO:  eta: 1 day, 0:25:01  iter: 23539  total_loss: 24.91  loss_mask: 2.489  loss_mask_0: 2.5  loss_mask_1: 2.489  loss_mask_2: 2.49  loss_mask_3: 2.49  loss_mask_4: 2.49  loss_mask_5: 2.49  loss_mask_6: 2.49  loss_mask_7: 2.489  loss_mask_8: 2.49  time: 1.9980  data_time: 0.4456  lr: 6.3872e-05  max_mem: 17500M
[01/27 18:38:09] d2.utils.events INFO:  eta: 1 day, 0:24:06  iter: 23559  total_loss: 23.78  loss_mask: 2.376  loss_mask_0: 2.391  loss_mask_1: 2.375  loss_mask_2: 2.376  loss_mask_3: 2.376  loss_mask_4: 2.376  loss_mask_5: 2.375  loss_mask_6: 2.376  loss_mask_7: 2.375  loss_mask_8: 2.376  time: 1.9983  data_time: 0.4295  lr: 6.384e-05  max_mem: 17500M
[01/27 18:38:58] d2.utils.events INFO:  eta: 1 day, 0:23:24  iter: 23579  total_loss: 23.83  loss_mask: 2.381  loss_mask_0: 2.402  loss_mask_1: 2.381  loss_mask_2: 2.381  loss_mask_3: 2.381  loss_mask_4: 2.381  loss_mask_5: 2.381  loss_mask_6: 2.381  loss_mask_7: 2.381  loss_mask_8: 2.381  time: 1.9987  data_time: 0.4149  lr: 6.3809e-05  max_mem: 17500M
[01/27 18:39:48] d2.utils.events INFO:  eta: 1 day, 0:22:57  iter: 23599  total_loss: 25.59  loss_mask: 2.558  loss_mask_0: 2.565  loss_mask_1: 2.558  loss_mask_2: 2.558  loss_mask_3: 2.558  loss_mask_4: 2.558  loss_mask_5: 2.558  loss_mask_6: 2.558  loss_mask_7: 2.558  loss_mask_8: 2.558  time: 1.9991  data_time: 0.4283  lr: 6.3777e-05  max_mem: 17500M
[01/27 18:40:35] d2.utils.events INFO:  eta: 1 day, 0:21:49  iter: 23619  total_loss: 26.41  loss_mask: 2.632  loss_mask_0: 2.702  loss_mask_1: 2.632  loss_mask_2: 2.632  loss_mask_3: 2.632  loss_mask_4: 2.631  loss_mask_5: 2.632  loss_mask_6: 2.632  loss_mask_7: 2.632  loss_mask_8: 2.632  time: 1.9994  data_time: 0.4201  lr: 6.3746e-05  max_mem: 17500M
[01/27 18:41:23] d2.utils.events INFO:  eta: 1 day, 0:20:39  iter: 23639  total_loss: 23.5  loss_mask: 2.349  loss_mask_0: 2.353  loss_mask_1: 2.349  loss_mask_2: 2.349  loss_mask_3: 2.349  loss_mask_4: 2.349  loss_mask_5: 2.349  loss_mask_6: 2.349  loss_mask_7: 2.349  loss_mask_8: 2.349  time: 1.9997  data_time: 0.4271  lr: 6.3714e-05  max_mem: 17500M
[01/27 18:42:11] d2.utils.events INFO:  eta: 1 day, 0:19:36  iter: 23659  total_loss: 26.04  loss_mask: 2.601  loss_mask_0: 2.644  loss_mask_1: 2.6  loss_mask_2: 2.6  loss_mask_3: 2.6  loss_mask_4: 2.6  loss_mask_5: 2.601  loss_mask_6: 2.601  loss_mask_7: 2.601  loss_mask_8: 2.6  time: 2.0001  data_time: 0.4322  lr: 6.3683e-05  max_mem: 17500M
[01/27 18:42:58] d2.utils.events INFO:  eta: 1 day, 0:18:14  iter: 23679  total_loss: 24.65  loss_mask: 2.463  loss_mask_0: 2.494  loss_mask_1: 2.463  loss_mask_2: 2.463  loss_mask_3: 2.463  loss_mask_4: 2.463  loss_mask_5: 2.463  loss_mask_6: 2.463  loss_mask_7: 2.462  loss_mask_8: 2.463  time: 2.0004  data_time: 0.4232  lr: 6.3651e-05  max_mem: 17500M
[01/27 18:43:46] d2.utils.events INFO:  eta: 1 day, 0:17:36  iter: 23699  total_loss: 26.2  loss_mask: 2.619  loss_mask_0: 2.637  loss_mask_1: 2.619  loss_mask_2: 2.618  loss_mask_3: 2.619  loss_mask_4: 2.619  loss_mask_5: 2.618  loss_mask_6: 2.618  loss_mask_7: 2.618  loss_mask_8: 2.619  time: 2.0007  data_time: 0.4518  lr: 6.362e-05  max_mem: 17500M
[01/27 18:44:33] d2.utils.events INFO:  eta: 1 day, 0:16:26  iter: 23719  total_loss: 24.53  loss_mask: 2.451  loss_mask_0: 2.476  loss_mask_1: 2.45  loss_mask_2: 2.451  loss_mask_3: 2.451  loss_mask_4: 2.451  loss_mask_5: 2.451  loss_mask_6: 2.451  loss_mask_7: 2.451  loss_mask_8: 2.451  time: 2.0010  data_time: 0.4085  lr: 6.3588e-05  max_mem: 17500M
[01/27 18:45:21] d2.utils.events INFO:  eta: 1 day, 0:16:11  iter: 23739  total_loss: 22.53  loss_mask: 2.25  loss_mask_0: 2.279  loss_mask_1: 2.25  loss_mask_2: 2.25  loss_mask_3: 2.25  loss_mask_4: 2.25  loss_mask_5: 2.25  loss_mask_6: 2.25  loss_mask_7: 2.25  loss_mask_8: 2.25  time: 2.0013  data_time: 0.4314  lr: 6.3556e-05  max_mem: 17500M
[01/27 18:46:09] d2.utils.events INFO:  eta: 1 day, 0:15:28  iter: 23759  total_loss: 23.99  loss_mask: 2.398  loss_mask_0: 2.412  loss_mask_1: 2.397  loss_mask_2: 2.397  loss_mask_3: 2.398  loss_mask_4: 2.397  loss_mask_5: 2.398  loss_mask_6: 2.398  loss_mask_7: 2.398  loss_mask_8: 2.398  time: 2.0017  data_time: 0.4356  lr: 6.3525e-05  max_mem: 17500M
[01/27 18:46:57] d2.utils.events INFO:  eta: 1 day, 0:14:11  iter: 23779  total_loss: 22.92  loss_mask: 2.289  loss_mask_0: 2.329  loss_mask_1: 2.289  loss_mask_2: 2.289  loss_mask_3: 2.289  loss_mask_4: 2.289  loss_mask_5: 2.289  loss_mask_6: 2.289  loss_mask_7: 2.289  loss_mask_8: 2.289  time: 2.0020  data_time: 0.4307  lr: 6.3493e-05  max_mem: 17500M
[01/27 18:47:43] d2.utils.events INFO:  eta: 1 day, 0:13:05  iter: 23799  total_loss: 24.74  loss_mask: 2.47  loss_mask_0: 2.508  loss_mask_1: 2.469  loss_mask_2: 2.47  loss_mask_3: 2.47  loss_mask_4: 2.47  loss_mask_5: 2.47  loss_mask_6: 2.47  loss_mask_7: 2.47  loss_mask_8: 2.47  time: 2.0022  data_time: 0.4294  lr: 6.3462e-05  max_mem: 17500M
[01/27 18:48:31] d2.utils.events INFO:  eta: 1 day, 0:12:32  iter: 23819  total_loss: 24.75  loss_mask: 2.47  loss_mask_0: 2.509  loss_mask_1: 2.47  loss_mask_2: 2.471  loss_mask_3: 2.471  loss_mask_4: 2.471  loss_mask_5: 2.47  loss_mask_6: 2.471  loss_mask_7: 2.47  loss_mask_8: 2.471  time: 2.0026  data_time: 0.4205  lr: 6.343e-05  max_mem: 17500M
[01/27 18:49:18] d2.utils.events INFO:  eta: 1 day, 0:11:58  iter: 23839  total_loss: 23.69  loss_mask: 2.365  loss_mask_0: 2.409  loss_mask_1: 2.365  loss_mask_2: 2.364  loss_mask_3: 2.364  loss_mask_4: 2.364  loss_mask_5: 2.365  loss_mask_6: 2.364  loss_mask_7: 2.365  loss_mask_8: 2.365  time: 2.0029  data_time: 0.4036  lr: 6.3399e-05  max_mem: 17500M
[01/27 18:50:04] d2.utils.events INFO:  eta: 1 day, 0:11:21  iter: 23859  total_loss: 23.5  loss_mask: 2.348  loss_mask_0: 2.368  loss_mask_1: 2.348  loss_mask_2: 2.348  loss_mask_3: 2.348  loss_mask_4: 2.348  loss_mask_5: 2.348  loss_mask_6: 2.348  loss_mask_7: 2.348  loss_mask_8: 2.348  time: 2.0031  data_time: 0.4214  lr: 6.3367e-05  max_mem: 17500M
[01/27 18:50:51] d2.utils.events INFO:  eta: 1 day, 0:09:47  iter: 23879  total_loss: 22.7  loss_mask: 2.268  loss_mask_0: 2.287  loss_mask_1: 2.267  loss_mask_2: 2.267  loss_mask_3: 2.267  loss_mask_4: 2.268  loss_mask_5: 2.268  loss_mask_6: 2.268  loss_mask_7: 2.268  loss_mask_8: 2.268  time: 2.0034  data_time: 0.4137  lr: 6.3336e-05  max_mem: 17500M
[01/27 18:51:38] d2.utils.events INFO:  eta: 1 day, 0:08:17  iter: 23899  total_loss: 23.04  loss_mask: 2.301  loss_mask_0: 2.336  loss_mask_1: 2.301  loss_mask_2: 2.301  loss_mask_3: 2.301  loss_mask_4: 2.301  loss_mask_5: 2.301  loss_mask_6: 2.3  loss_mask_7: 2.301  loss_mask_8: 2.301  time: 2.0037  data_time: 0.4425  lr: 6.3304e-05  max_mem: 17500M
[01/27 18:52:24] d2.utils.events INFO:  eta: 1 day, 0:07:13  iter: 23919  total_loss: 21.59  loss_mask: 2.155  loss_mask_0: 2.185  loss_mask_1: 2.155  loss_mask_2: 2.155  loss_mask_3: 2.155  loss_mask_4: 2.155  loss_mask_5: 2.155  loss_mask_6: 2.155  loss_mask_7: 2.156  loss_mask_8: 2.155  time: 2.0040  data_time: 0.4454  lr: 6.3272e-05  max_mem: 17500M
[01/27 18:53:11] d2.utils.events INFO:  eta: 1 day, 0:05:08  iter: 23939  total_loss: 23.87  loss_mask: 2.384  loss_mask_0: 2.413  loss_mask_1: 2.383  loss_mask_2: 2.384  loss_mask_3: 2.384  loss_mask_4: 2.383  loss_mask_5: 2.384  loss_mask_6: 2.383  loss_mask_7: 2.384  loss_mask_8: 2.384  time: 2.0042  data_time: 0.4386  lr: 6.3241e-05  max_mem: 17500M
[01/27 18:53:57] d2.utils.events INFO:  eta: 1 day, 0:03:59  iter: 23959  total_loss: 24.03  loss_mask: 2.4  loss_mask_0: 2.436  loss_mask_1: 2.399  loss_mask_2: 2.4  loss_mask_3: 2.4  loss_mask_4: 2.4  loss_mask_5: 2.4  loss_mask_6: 2.4  loss_mask_7: 2.4  loss_mask_8: 2.4  time: 2.0045  data_time: 0.4377  lr: 6.3209e-05  max_mem: 17500M
[01/27 18:54:43] d2.utils.events INFO:  eta: 1 day, 0:01:17  iter: 23979  total_loss: 24.17  loss_mask: 2.413  loss_mask_0: 2.452  loss_mask_1: 2.414  loss_mask_2: 2.414  loss_mask_3: 2.413  loss_mask_4: 2.414  loss_mask_5: 2.413  loss_mask_6: 2.413  loss_mask_7: 2.414  loss_mask_8: 2.414  time: 2.0047  data_time: 0.4185  lr: 6.3178e-05  max_mem: 17500M
[01/27 18:55:30] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 18:55:31] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 18:55:31] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 19:03:24] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.720689624989828, 'error_1pix': 0.40022047346514655, 'error_3pix': 0.16580687575989672, 'mIoU': 5.432011641820175, 'fwIoU': 16.301154236669635, 'IoU-0': nan, 'IoU-1': 63.563935027834596, 'IoU-2': 3.121766762975146, 'IoU-3': 4.157859975221164, 'IoU-4': 5.107833840340307, 'IoU-5': 4.910439473810486, 'IoU-6': 4.3499589076545515, 'IoU-7': 2.9945584136094414, 'IoU-8': 7.302321820225201, 'IoU-9': 16.47472158065263, 'IoU-10': 15.079169306225662, 'IoU-11': 15.528992181563483, 'IoU-12': 15.90311872784583, 'IoU-13': 15.157360617920732, 'IoU-14': 14.881590242302739, 'IoU-15': 16.36818243330101, 'IoU-16': 16.24025407035055, 'IoU-17': 14.081671298076737, 'IoU-18': 13.916667504044536, 'IoU-19': 14.524503014711943, 'IoU-20': 14.651227393640273, 'IoU-21': 14.980981175749546, 'IoU-22': 14.685674641885841, 'IoU-23': 14.433004744222014, 'IoU-24': 14.756782471738486, 'IoU-25': 14.630259378623439, 'IoU-26': 14.549269234954274, 'IoU-27': 15.163795663464738, 'IoU-28': 13.991371847740222, 'IoU-29': 14.401777381153291, 'IoU-30': 14.147157515062936, 'IoU-31': 15.137627631854848, 'IoU-32': 14.593904291165632, 'IoU-33': 13.900628595508593, 'IoU-34': 13.526475335412602, 'IoU-35': 13.648441945547024, 'IoU-36': 13.71730671590719, 'IoU-37': 13.424910428741207, 'IoU-38': 13.69705495521187, 'IoU-39': 13.211984810581317, 'IoU-40': 12.691579705620123, 'IoU-41': 12.00446638825568, 'IoU-42': 11.27273250560588, 'IoU-43': 11.527804989824908, 'IoU-44': 11.190387409132338, 'IoU-45': 11.259804728096903, 'IoU-46': 10.404678055066649, 'IoU-47': 9.931629571266182, 'IoU-48': 9.476617441514671, 'IoU-49': 9.063943690249916, 'IoU-50': 9.19195100506312, 'IoU-51': 8.914269263068505, 'IoU-52': 9.047888734273219, 'IoU-53': 9.352266193419712, 'IoU-54': 9.508720321452788, 'IoU-55': 8.742529058881592, 'IoU-56': 8.5047918807601, 'IoU-57': 8.315228502395325, 'IoU-58': 7.939275618874203, 'IoU-59': 7.285493688522253, 'IoU-60': 7.075598877603579, 'IoU-61': 6.569735814409334, 'IoU-62': 6.452092392550438, 'IoU-63': 6.0655729319321345, 'IoU-64': 5.422198219049103, 'IoU-65': 5.208880527936695, 'IoU-66': 5.0236784896821325, 'IoU-67': 4.708425272243042, 'IoU-68': 4.527897454239593, 'IoU-69': 4.593787794146245, 'IoU-70': 4.580679468832273, 'IoU-71': 4.245440284607147, 'IoU-72': 4.101282057608505, 'IoU-73': 4.325168226572142, 'IoU-74': 4.201723946103586, 'IoU-75': 3.9889716849019985, 'IoU-76': 4.011197113740831, 'IoU-77': 3.6994099151396744, 'IoU-78': 3.4926341419849827, 'IoU-79': 3.535435836834001, 'IoU-80': 3.5014467278852033, 'IoU-81': 3.5369473724420044, 'IoU-82': 3.3807307327100586, 'IoU-83': 3.4528314956489496, 'IoU-84': 3.4541229232518713, 'IoU-85': 3.2903791149438124, 'IoU-86': 3.1483253795389277, 'IoU-87': 2.9659664501954635, 'IoU-88': 3.0476499902913687, 'IoU-89': 3.0756650137628894, 'IoU-90': 2.897228854253293, 'IoU-91': 2.8018051422123973, 'IoU-92': 2.59263649356318, 'IoU-93': 2.6030600016465653, 'IoU-94': 2.597659770421454, 'IoU-95': 2.476901711921793, 'IoU-96': 2.431185706393319, 'IoU-97': 2.3312864100342274, 'IoU-98': 2.1678746228108765, 'IoU-99': 2.23589296386137, 'IoU-100': 2.1291572514796226, 'IoU-101': 2.1323261752970555, 'IoU-102': 2.1370014354843305, 'IoU-103': 2.0812054820983064, 'IoU-104': 2.010350944068314, 'IoU-105': 2.0293923545380723, 'IoU-106': 2.1226030662409356, 'IoU-107': 2.092982646768947, 'IoU-108': 2.2280674162596177, 'IoU-109': 2.199572217178245, 'IoU-110': 2.1316673960527, 'IoU-111': 1.9420136516636328, 'IoU-112': 1.910473758626085, 'IoU-113': 1.8958946887353292, 'IoU-114': 1.786108993385198, 'IoU-115': 1.73593328097656, 'IoU-116': 1.8381616459770846, 'IoU-117': 1.7778465941247452, 'IoU-118': 1.676637467393575, 'IoU-119': 1.785600425816217, 'IoU-120': 1.8106573429842572, 'IoU-121': 1.8561882840435275, 'IoU-122': 1.7742819531915262, 'IoU-123': 1.608386861375805, 'IoU-124': 1.5933638461358424, 'IoU-125': 1.6178758961238993, 'IoU-126': 1.41916141849679, 'IoU-127': 1.5438006222475824, 'IoU-128': 1.6249857486804953, 'IoU-129': 1.4709298607603691, 'IoU-130': 1.4217985659719896, 'IoU-131': 1.3109546458569579, 'IoU-132': 1.4131279788386433, 'IoU-133': 1.3976609414638799, 'IoU-134': 1.341039975447866, 'IoU-135': 1.410526677276023, 'IoU-136': 1.3977353078527122, 'IoU-137': 1.2897053306850996, 'IoU-138': 1.2070724980470258, 'IoU-139': 1.1941580023001193, 'IoU-140': 1.238466418427568, 'IoU-141': 1.2429373208570131, 'IoU-142': 1.2040172456435216, 'IoU-143': 1.297547461645014, 'IoU-144': 1.3145659083197128, 'IoU-145': 1.2802560825071303, 'IoU-146': 1.4033857768852644, 'IoU-147': 1.6516509052264352, 'IoU-148': 1.6773671447691214, 'IoU-149': 1.832967025131773, 'IoU-150': 1.8190343508659157, 'IoU-151': 1.6843549074092852, 'IoU-152': 1.8932737167018703, 'IoU-153': 1.9142088302445939, 'IoU-154': 1.97024394220102, 'IoU-155': 2.151686680871462, 'IoU-156': 1.9858279854385048, 'IoU-157': 2.160112206224028, 'IoU-158': 2.0564328412934483, 'IoU-159': 2.100180939434879, 'IoU-160': 2.165914531322075, 'IoU-161': 2.2783999089944893, 'IoU-162': 2.088681094288958, 'IoU-163': 2.0962451468509915, 'IoU-164': 2.213429648852127, 'IoU-165': 2.124890190598705, 'IoU-166': 2.0685768870631587, 'IoU-167': 1.8677017241512555, 'IoU-168': 1.6969356500403963, 'IoU-169': 1.8248879676182612, 'IoU-170': 1.8191492965942766, 'IoU-171': 1.8092605895316134, 'IoU-172': 1.845212743789573, 'IoU-173': 1.5950721550601967, 'IoU-174': 1.4642517316314108, 'IoU-175': 1.6609711599931187, 'IoU-176': 1.4863351495703487, 'IoU-177': 1.495935143973113, 'IoU-178': 1.638500782654067, 'IoU-179': 1.750637853124712, 'IoU-180': 1.9047077013554916, 'IoU-181': 1.2646927310338638, 'IoU-182': 1.243931648145048, 'IoU-183': 1.3365552758183998, 'IoU-184': 1.0514716260083161, 'IoU-185': 0.9467824503900147, 'IoU-186': 0.6004585091126069, 'IoU-187': 0.3709772088100855, 'IoU-188': 0.36100731745290365, 'IoU-189': 0.18653565477795955, 'IoU-190': 0.21312464554755942, 'IoU-191': 0.21864945104480243, 'IoU-192': 0.10342951996866113, 'mACC': 10.055154911330662, 'pACC': 24.09236098408814, 'ACC-0': nan, 'ACC-1': 64.6354562520895, 'ACC-2': 6.066379856106595, 'ACC-3': 19.33317311802861, 'ACC-4': 22.92550859083028, 'ACC-5': 22.609892321070383, 'ACC-6': 21.10455179645314, 'ACC-7': 17.648978490506874, 'ACC-8': 24.566856213918562, 'ACC-9': 41.131114648717535, 'ACC-10': 38.757304892204914, 'ACC-11': 28.547527781378353, 'ACC-12': 27.676909535031662, 'ACC-13': 25.423517357856767, 'ACC-14': 23.923533657175973, 'ACC-15': 27.16214225467301, 'ACC-16': 27.413363493400595, 'ACC-17': 25.33526478100493, 'ACC-18': 23.975464839687373, 'ACC-19': 25.16164698541865, 'ACC-20': 26.34295520473276, 'ACC-21': 26.690729380935093, 'ACC-22': 24.481991425160455, 'ACC-23': 25.24631933714846, 'ACC-24': 25.953029413295308, 'ACC-25': 25.6338967387513, 'ACC-26': 26.01090337113503, 'ACC-27': 26.667867767280836, 'ACC-28': 25.15427425873325, 'ACC-29': 25.223587275371678, 'ACC-30': 24.99978333557197, 'ACC-31': 26.384066060424775, 'ACC-32': 25.39910601724658, 'ACC-33': 24.650712471973716, 'ACC-34': 24.49307124025629, 'ACC-35': 24.513252865810262, 'ACC-36': 23.98325139073244, 'ACC-37': 23.6014759505511, 'ACC-38': 24.187932531233916, 'ACC-39': 23.52850521570799, 'ACC-40': 22.286295267574417, 'ACC-41': 21.701914711698528, 'ACC-42': 20.60312054276543, 'ACC-43': 21.11469183849613, 'ACC-44': 19.95707692904475, 'ACC-45': 20.113625703817647, 'ACC-46': 19.255976839553828, 'ACC-47': 18.42431390487901, 'ACC-48': 17.660399799044026, 'ACC-49': 16.688649876189228, 'ACC-50': 16.56088075764236, 'ACC-51': 16.08444536686548, 'ACC-52': 16.3653586054222, 'ACC-53': 17.066864963242487, 'ACC-54': 17.18595884440975, 'ACC-55': 15.989404975474358, 'ACC-56': 15.885148032947155, 'ACC-57': 15.278699056695336, 'ACC-58': 14.662070904013952, 'ACC-59': 13.639640948949989, 'ACC-60': 13.20191521050865, 'ACC-61': 12.399186463495111, 'ACC-62': 12.304542233108053, 'ACC-63': 11.701875700011954, 'ACC-64': 10.434924172048806, 'ACC-65': 10.023349475020117, 'ACC-66': 9.65462007636044, 'ACC-67': 9.144562029716809, 'ACC-68': 8.846258274155876, 'ACC-69': 8.845106984517276, 'ACC-70': 8.74394607607452, 'ACC-71': 8.245703886693198, 'ACC-72': 8.05245147432351, 'ACC-73': 8.488426209322235, 'ACC-74': 8.247966539608184, 'ACC-75': 7.805368123450022, 'ACC-76': 7.69719163977685, 'ACC-77': 7.190734135617473, 'ACC-78': 6.836402365425233, 'ACC-79': 6.908731895313178, 'ACC-80': 6.76331280269187, 'ACC-81': 6.760925278969815, 'ACC-82': 6.473058326652023, 'ACC-83': 6.512986697167604, 'ACC-84': 6.500444084635013, 'ACC-85': 6.161397193780601, 'ACC-86': 5.871656783788799, 'ACC-87': 5.539014318447199, 'ACC-88': 5.69909335090903, 'ACC-89': 5.730459636315739, 'ACC-90': 5.388395955654768, 'ACC-91': 5.259496717968452, 'ACC-92': 4.876927489466966, 'ACC-93': 4.848973417594897, 'ACC-94': 4.7989483056846955, 'ACC-95': 4.521986722028275, 'ACC-96': 4.443927086502637, 'ACC-97': 4.204574384903239, 'ACC-98': 3.9097891229399773, 'ACC-99': 4.066238457521442, 'ACC-100': 3.8577720255573746, 'ACC-101': 3.8828879019070754, 'ACC-102': 3.908926144086996, 'ACC-103': 3.8262727873807503, 'ACC-104': 3.680996532303682, 'ACC-105': 3.7139345139419717, 'ACC-106': 3.8961992501973888, 'ACC-107': 3.8660909711978206, 'ACC-108': 4.0522304305158015, 'ACC-109': 3.9855531600336223, 'ACC-110': 3.9334945014842666, 'ACC-111': 3.5997895252126293, 'ACC-112': 3.5688760853070893, 'ACC-113': 3.540341331724292, 'ACC-114': 3.3571100843040282, 'ACC-115': 3.2385022476809042, 'ACC-116': 3.4549301908060324, 'ACC-117': 3.3449808611401988, 'ACC-118': 3.157244603322757, 'ACC-119': 3.3150664132715884, 'ACC-120': 3.3345105191213626, 'ACC-121': 3.421469667659417, 'ACC-122': 3.2771943728947894, 'ACC-123': 2.9928809538377124, 'ACC-124': 3.0102269403724145, 'ACC-125': 3.050590463179397, 'ACC-126': 2.6982827712456396, 'ACC-127': 2.929718528348083, 'ACC-128': 3.103034427747103, 'ACC-129': 2.82907630028132, 'ACC-130': 2.736731993096741, 'ACC-131': 2.50619221074052, 'ACC-132': 2.663154755322322, 'ACC-133': 2.5824845033238755, 'ACC-134': 2.4579750107712193, 'ACC-135': 2.575751097428881, 'ACC-136': 2.5427023155050317, 'ACC-137': 2.369456639210634, 'ACC-138': 2.2086142619179823, 'ACC-139': 2.1801135147853703, 'ACC-140': 2.242643100292371, 'ACC-141': 2.220610177593272, 'ACC-142': 2.1639895167157035, 'ACC-143': 2.309776381943415, 'ACC-144': 2.2901707226379875, 'ACC-145': 2.1958471306130556, 'ACC-146': 2.3744553456544626, 'ACC-147': 2.7764675295734365, 'ACC-148': 2.817364623443629, 'ACC-149': 3.1284892405891283, 'ACC-150': 3.085239111242674, 'ACC-151': 2.83220662510831, 'ACC-152': 3.103511496711462, 'ACC-153': 3.257593455268353, 'ACC-154': 3.349040153960502, 'ACC-155': 3.668250160855728, 'ACC-156': 3.4408532643826764, 'ACC-157': 3.7165229155636372, 'ACC-158': 3.5224496535839136, 'ACC-159': 3.57265900026796, 'ACC-160': 3.644780264062054, 'ACC-161': 3.824987748075149, 'ACC-162': 3.598903265062625, 'ACC-163': 3.659778211936931, 'ACC-164': 3.969341223179913, 'ACC-165': 3.7727787493110587, 'ACC-166': 3.679662038615043, 'ACC-167': 3.359169086053732, 'ACC-168': 3.006430670270327, 'ACC-169': 3.2351413389115464, 'ACC-170': 3.240090799214115, 'ACC-171': 3.2762428300035644, 'ACC-172': 3.3628997299009638, 'ACC-173': 2.8919608156812555, 'ACC-174': 2.628399242209526, 'ACC-175': 2.8926995446693766, 'ACC-176': 2.5052362577727116, 'ACC-177': 2.433177646900215, 'ACC-178': 2.6223766085398315, 'ACC-179': 2.7754087575233317, 'ACC-180': 2.977852539521798, 'ACC-181': 1.938422938558111, 'ACC-182': 1.8339784374636612, 'ACC-183': 1.8688151202846373, 'ACC-184': 1.3718680872461833, 'ACC-185': 1.1449781457413104, 'ACC-186': 0.6778779677842515, 'ACC-187': 0.39607841239577846, 'ACC-188': 0.37476545591833954, 'ACC-189': 0.1903013189938718, 'ACC-190': 0.21609444088517327, 'ACC-191': 0.22090828903389265, 'ACC-192': 0.1041314950956052})])
[01/27 19:03:24] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 19:03:24] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 19:03:24] d2.evaluation.testing INFO: copypaste: 2.7207,0.4002,0.1658,5.4320,16.3012,10.0552,24.0924
[01/27 19:03:24] d2.utils.events INFO:  eta: 23:59:38  iter: 23999  total_loss: 23.26  loss_mask: 2.324  loss_mask_0: 2.343  loss_mask_1: 2.324  loss_mask_2: 2.324  loss_mask_3: 2.324  loss_mask_4: 2.324  loss_mask_5: 2.324  loss_mask_6: 2.324  loss_mask_7: 2.324  loss_mask_8: 2.324  time: 2.0050  data_time: 0.4194  lr: 6.3146e-05  max_mem: 17500M
[01/27 19:04:11] d2.utils.events INFO:  eta: 23:57:36  iter: 24019  total_loss: 23.34  loss_mask: 2.332  loss_mask_0: 2.347  loss_mask_1: 2.332  loss_mask_2: 2.333  loss_mask_3: 2.332  loss_mask_4: 2.333  loss_mask_5: 2.332  loss_mask_6: 2.332  loss_mask_7: 2.333  loss_mask_8: 2.333  time: 2.0053  data_time: 0.4443  lr: 6.3115e-05  max_mem: 17500M
[01/27 19:04:58] d2.utils.events INFO:  eta: 23:56:34  iter: 24039  total_loss: 25.9  loss_mask: 2.586  loss_mask_0: 2.619  loss_mask_1: 2.585  loss_mask_2: 2.586  loss_mask_3: 2.585  loss_mask_4: 2.586  loss_mask_5: 2.586  loss_mask_6: 2.585  loss_mask_7: 2.586  loss_mask_8: 2.585  time: 2.0056  data_time: 0.4363  lr: 6.3083e-05  max_mem: 17500M
[01/27 19:05:44] d2.utils.events INFO:  eta: 23:53:23  iter: 24059  total_loss: 23.67  loss_mask: 2.364  loss_mask_0: 2.39  loss_mask_1: 2.364  loss_mask_2: 2.364  loss_mask_3: 2.364  loss_mask_4: 2.364  loss_mask_5: 2.364  loss_mask_6: 2.364  loss_mask_7: 2.364  loss_mask_8: 2.364  time: 2.0058  data_time: 0.4031  lr: 6.3051e-05  max_mem: 17500M
[01/27 19:06:29] d2.utils.events INFO:  eta: 23:50:58  iter: 24079  total_loss: 23.32  loss_mask: 2.33  loss_mask_0: 2.349  loss_mask_1: 2.33  loss_mask_2: 2.33  loss_mask_3: 2.33  loss_mask_4: 2.33  loss_mask_5: 2.329  loss_mask_6: 2.33  loss_mask_7: 2.33  loss_mask_8: 2.33  time: 2.0060  data_time: 0.4131  lr: 6.302e-05  max_mem: 17500M
[01/27 19:07:16] d2.utils.events INFO:  eta: 23:47:45  iter: 24099  total_loss: 23.53  loss_mask: 2.35  loss_mask_0: 2.381  loss_mask_1: 2.349  loss_mask_2: 2.349  loss_mask_3: 2.35  loss_mask_4: 2.349  loss_mask_5: 2.349  loss_mask_6: 2.35  loss_mask_7: 2.35  loss_mask_8: 2.35  time: 2.0063  data_time: 0.4305  lr: 6.2988e-05  max_mem: 17500M
[01/27 19:08:02] d2.utils.events INFO:  eta: 23:45:27  iter: 24119  total_loss: 22.35  loss_mask: 2.231  loss_mask_0: 2.26  loss_mask_1: 2.232  loss_mask_2: 2.232  loss_mask_3: 2.232  loss_mask_4: 2.232  loss_mask_5: 2.232  loss_mask_6: 2.232  loss_mask_7: 2.232  loss_mask_8: 2.232  time: 2.0065  data_time: 0.4215  lr: 6.2957e-05  max_mem: 17500M
[01/27 19:08:48] d2.utils.events INFO:  eta: 23:43:55  iter: 24139  total_loss: 22.92  loss_mask: 2.291  loss_mask_0: 2.3  loss_mask_1: 2.291  loss_mask_2: 2.291  loss_mask_3: 2.291  loss_mask_4: 2.291  loss_mask_5: 2.291  loss_mask_6: 2.291  loss_mask_7: 2.291  loss_mask_8: 2.291  time: 2.0068  data_time: 0.4394  lr: 6.2925e-05  max_mem: 17500M
[01/27 19:09:35] d2.utils.events INFO:  eta: 23:41:49  iter: 24159  total_loss: 20.81  loss_mask: 2.078  loss_mask_0: 2.112  loss_mask_1: 2.078  loss_mask_2: 2.078  loss_mask_3: 2.078  loss_mask_4: 2.078  loss_mask_5: 2.078  loss_mask_6: 2.078  loss_mask_7: 2.078  loss_mask_8: 2.078  time: 2.0070  data_time: 0.4330  lr: 6.2894e-05  max_mem: 17500M
[01/27 19:10:20] d2.utils.events INFO:  eta: 23:39:42  iter: 24179  total_loss: 24.91  loss_mask: 2.491  loss_mask_0: 2.498  loss_mask_1: 2.49  loss_mask_2: 2.49  loss_mask_3: 2.491  loss_mask_4: 2.49  loss_mask_5: 2.491  loss_mask_6: 2.491  loss_mask_7: 2.49  loss_mask_8: 2.491  time: 2.0073  data_time: 0.4291  lr: 6.2862e-05  max_mem: 17500M
[01/27 19:11:05] d2.utils.events INFO:  eta: 23:36:31  iter: 24199  total_loss: 23.07  loss_mask: 2.303  loss_mask_0: 2.339  loss_mask_1: 2.303  loss_mask_2: 2.303  loss_mask_3: 2.303  loss_mask_4: 2.303  loss_mask_5: 2.303  loss_mask_6: 2.303  loss_mask_7: 2.303  loss_mask_8: 2.303  time: 2.0075  data_time: 0.4086  lr: 6.283e-05  max_mem: 17500M
[01/27 19:11:52] d2.utils.events INFO:  eta: 23:37:03  iter: 24219  total_loss: 24.06  loss_mask: 2.402  loss_mask_0: 2.438  loss_mask_1: 2.402  loss_mask_2: 2.402  loss_mask_3: 2.402  loss_mask_4: 2.402  loss_mask_5: 2.402  loss_mask_6: 2.403  loss_mask_7: 2.403  loss_mask_8: 2.402  time: 2.0077  data_time: 0.4291  lr: 6.2799e-05  max_mem: 17500M
[01/27 19:12:38] d2.utils.events INFO:  eta: 23:34:07  iter: 24239  total_loss: 23.5  loss_mask: 2.345  loss_mask_0: 2.378  loss_mask_1: 2.345  loss_mask_2: 2.345  loss_mask_3: 2.346  loss_mask_4: 2.345  loss_mask_5: 2.345  loss_mask_6: 2.346  loss_mask_7: 2.345  loss_mask_8: 2.345  time: 2.0080  data_time: 0.4071  lr: 6.2767e-05  max_mem: 17500M
[01/27 19:13:26] d2.utils.events INFO:  eta: 23:31:43  iter: 24259  total_loss: 23.71  loss_mask: 2.365  loss_mask_0: 2.418  loss_mask_1: 2.366  loss_mask_2: 2.366  loss_mask_3: 2.365  loss_mask_4: 2.366  loss_mask_5: 2.366  loss_mask_6: 2.365  loss_mask_7: 2.366  loss_mask_8: 2.366  time: 2.0083  data_time: 0.4477  lr: 6.2736e-05  max_mem: 17500M
[01/27 19:14:12] d2.utils.events INFO:  eta: 23:29:53  iter: 24279  total_loss: 24.18  loss_mask: 2.413  loss_mask_0: 2.463  loss_mask_1: 2.412  loss_mask_2: 2.413  loss_mask_3: 2.413  loss_mask_4: 2.413  loss_mask_5: 2.413  loss_mask_6: 2.413  loss_mask_7: 2.413  loss_mask_8: 2.413  time: 2.0086  data_time: 0.4417  lr: 6.2704e-05  max_mem: 17500M
[01/27 19:15:00] d2.utils.events INFO:  eta: 23:28:06  iter: 24299  total_loss: 23.43  loss_mask: 2.343  loss_mask_0: 2.364  loss_mask_1: 2.343  loss_mask_2: 2.343  loss_mask_3: 2.343  loss_mask_4: 2.343  loss_mask_5: 2.342  loss_mask_6: 2.343  loss_mask_7: 2.343  loss_mask_8: 2.343  time: 2.0089  data_time: 0.4517  lr: 6.2672e-05  max_mem: 17500M
[01/27 19:15:47] d2.utils.events INFO:  eta: 23:26:58  iter: 24319  total_loss: 26.08  loss_mask: 2.604  loss_mask_0: 2.626  loss_mask_1: 2.604  loss_mask_2: 2.604  loss_mask_3: 2.604  loss_mask_4: 2.604  loss_mask_5: 2.604  loss_mask_6: 2.604  loss_mask_7: 2.603  loss_mask_8: 2.604  time: 2.0091  data_time: 0.4663  lr: 6.2641e-05  max_mem: 17500M
[01/27 19:16:33] d2.utils.events INFO:  eta: 23:24:11  iter: 24339  total_loss: 24.71  loss_mask: 2.471  loss_mask_0: 2.478  loss_mask_1: 2.471  loss_mask_2: 2.471  loss_mask_3: 2.471  loss_mask_4: 2.471  loss_mask_5: 2.471  loss_mask_6: 2.471  loss_mask_7: 2.471  loss_mask_8: 2.471  time: 2.0094  data_time: 0.4326  lr: 6.2609e-05  max_mem: 17500M
[01/27 19:17:20] d2.utils.events INFO:  eta: 23:21:47  iter: 24359  total_loss: 23.36  loss_mask: 2.334  loss_mask_0: 2.351  loss_mask_1: 2.334  loss_mask_2: 2.334  loss_mask_3: 2.334  loss_mask_4: 2.334  loss_mask_5: 2.334  loss_mask_6: 2.334  loss_mask_7: 2.335  loss_mask_8: 2.334  time: 2.0097  data_time: 0.4762  lr: 6.2578e-05  max_mem: 17500M
[01/27 19:18:07] d2.utils.events INFO:  eta: 23:18:19  iter: 24379  total_loss: 24.63  loss_mask: 2.46  loss_mask_0: 2.482  loss_mask_1: 2.461  loss_mask_2: 2.461  loss_mask_3: 2.461  loss_mask_4: 2.461  loss_mask_5: 2.461  loss_mask_6: 2.46  loss_mask_7: 2.46  loss_mask_8: 2.461  time: 2.0099  data_time: 0.4378  lr: 6.2546e-05  max_mem: 17500M
[01/27 19:18:54] d2.utils.events INFO:  eta: 23:16:08  iter: 24399  total_loss: 22.87  loss_mask: 2.283  loss_mask_0: 2.324  loss_mask_1: 2.283  loss_mask_2: 2.283  loss_mask_3: 2.283  loss_mask_4: 2.283  loss_mask_5: 2.283  loss_mask_6: 2.283  loss_mask_7: 2.283  loss_mask_8: 2.283  time: 2.0102  data_time: 0.4282  lr: 6.2514e-05  max_mem: 17500M
[01/27 19:19:40] d2.utils.events INFO:  eta: 23:13:06  iter: 24419  total_loss: 24.67  loss_mask: 2.465  loss_mask_0: 2.491  loss_mask_1: 2.465  loss_mask_2: 2.465  loss_mask_3: 2.465  loss_mask_4: 2.465  loss_mask_5: 2.465  loss_mask_6: 2.465  loss_mask_7: 2.465  loss_mask_8: 2.465  time: 2.0105  data_time: 0.4450  lr: 6.2483e-05  max_mem: 17500M
[01/27 19:20:26] d2.utils.events INFO:  eta: 23:10:34  iter: 24439  total_loss: 24.44  loss_mask: 2.442  loss_mask_0: 2.459  loss_mask_1: 2.442  loss_mask_2: 2.443  loss_mask_3: 2.443  loss_mask_4: 2.442  loss_mask_5: 2.442  loss_mask_6: 2.442  loss_mask_7: 2.442  loss_mask_8: 2.442  time: 2.0107  data_time: 0.4035  lr: 6.2451e-05  max_mem: 17500M
[01/27 19:21:13] d2.utils.events INFO:  eta: 23:07:56  iter: 24459  total_loss: 23.82  loss_mask: 2.379  loss_mask_0: 2.407  loss_mask_1: 2.379  loss_mask_2: 2.379  loss_mask_3: 2.379  loss_mask_4: 2.379  loss_mask_5: 2.379  loss_mask_6: 2.379  loss_mask_7: 2.379  loss_mask_8: 2.379  time: 2.0110  data_time: 0.4199  lr: 6.242e-05  max_mem: 17500M
[01/27 19:22:00] d2.utils.events INFO:  eta: 23:06:17  iter: 24479  total_loss: 23.4  loss_mask: 2.337  loss_mask_0: 2.368  loss_mask_1: 2.337  loss_mask_2: 2.337  loss_mask_3: 2.337  loss_mask_4: 2.337  loss_mask_5: 2.337  loss_mask_6: 2.337  loss_mask_7: 2.337  loss_mask_8: 2.337  time: 2.0112  data_time: 0.4584  lr: 6.2388e-05  max_mem: 17500M
[01/27 19:22:46] d2.utils.events INFO:  eta: 23:04:11  iter: 24499  total_loss: 23.87  loss_mask: 2.385  loss_mask_0: 2.403  loss_mask_1: 2.384  loss_mask_2: 2.385  loss_mask_3: 2.385  loss_mask_4: 2.385  loss_mask_5: 2.385  loss_mask_6: 2.385  loss_mask_7: 2.385  loss_mask_8: 2.385  time: 2.0115  data_time: 0.4163  lr: 6.2356e-05  max_mem: 17500M
[01/27 19:23:33] d2.utils.events INFO:  eta: 23:02:27  iter: 24519  total_loss: 22.61  loss_mask: 2.258  loss_mask_0: 2.297  loss_mask_1: 2.258  loss_mask_2: 2.258  loss_mask_3: 2.258  loss_mask_4: 2.258  loss_mask_5: 2.258  loss_mask_6: 2.258  loss_mask_7: 2.258  loss_mask_8: 2.258  time: 2.0117  data_time: 0.4566  lr: 6.2325e-05  max_mem: 17500M
[01/27 19:24:19] d2.utils.events INFO:  eta: 23:00:21  iter: 24539  total_loss: 23.84  loss_mask: 2.382  loss_mask_0: 2.401  loss_mask_1: 2.382  loss_mask_2: 2.382  loss_mask_3: 2.382  loss_mask_4: 2.382  loss_mask_5: 2.382  loss_mask_6: 2.382  loss_mask_7: 2.382  loss_mask_8: 2.382  time: 2.0120  data_time: 0.4170  lr: 6.2293e-05  max_mem: 17500M
[01/27 19:25:05] d2.utils.events INFO:  eta: 22:58:59  iter: 24559  total_loss: 23.23  loss_mask: 2.319  loss_mask_0: 2.356  loss_mask_1: 2.319  loss_mask_2: 2.318  loss_mask_3: 2.319  loss_mask_4: 2.319  loss_mask_5: 2.319  loss_mask_6: 2.319  loss_mask_7: 2.319  loss_mask_8: 2.319  time: 2.0122  data_time: 0.4421  lr: 6.2261e-05  max_mem: 17500M
[01/27 19:25:51] d2.utils.events INFO:  eta: 22:56:17  iter: 24579  total_loss: 23.14  loss_mask: 2.313  loss_mask_0: 2.331  loss_mask_1: 2.312  loss_mask_2: 2.312  loss_mask_3: 2.312  loss_mask_4: 2.312  loss_mask_5: 2.313  loss_mask_6: 2.313  loss_mask_7: 2.312  loss_mask_8: 2.312  time: 2.0125  data_time: 0.4237  lr: 6.223e-05  max_mem: 17500M
[01/27 19:26:38] d2.utils.events INFO:  eta: 22:53:42  iter: 24599  total_loss: 24.09  loss_mask: 2.407  loss_mask_0: 2.428  loss_mask_1: 2.407  loss_mask_2: 2.407  loss_mask_3: 2.407  loss_mask_4: 2.407  loss_mask_5: 2.407  loss_mask_6: 2.407  loss_mask_7: 2.407  loss_mask_8: 2.407  time: 2.0127  data_time: 0.4398  lr: 6.2198e-05  max_mem: 17500M
[01/27 19:27:25] d2.utils.events INFO:  eta: 22:52:27  iter: 24619  total_loss: 22.76  loss_mask: 2.275  loss_mask_0: 2.296  loss_mask_1: 2.276  loss_mask_2: 2.276  loss_mask_3: 2.276  loss_mask_4: 2.276  loss_mask_5: 2.276  loss_mask_6: 2.276  loss_mask_7: 2.275  loss_mask_8: 2.276  time: 2.0130  data_time: 0.4282  lr: 6.2167e-05  max_mem: 17500M
[01/27 19:28:12] d2.utils.events INFO:  eta: 22:51:04  iter: 24639  total_loss: 22.67  loss_mask: 2.265  loss_mask_0: 2.302  loss_mask_1: 2.264  loss_mask_2: 2.265  loss_mask_3: 2.265  loss_mask_4: 2.265  loss_mask_5: 2.265  loss_mask_6: 2.265  loss_mask_7: 2.265  loss_mask_8: 2.265  time: 2.0133  data_time: 0.4170  lr: 6.2135e-05  max_mem: 17500M
[01/27 19:28:59] d2.utils.events INFO:  eta: 22:49:34  iter: 24659  total_loss: 24.35  loss_mask: 2.427  loss_mask_0: 2.496  loss_mask_1: 2.426  loss_mask_2: 2.427  loss_mask_3: 2.427  loss_mask_4: 2.427  loss_mask_5: 2.427  loss_mask_6: 2.427  loss_mask_7: 2.427  loss_mask_8: 2.427  time: 2.0135  data_time: 0.4183  lr: 6.2103e-05  max_mem: 17500M
[01/27 19:29:45] d2.utils.events INFO:  eta: 22:48:13  iter: 24679  total_loss: 23.84  loss_mask: 2.381  loss_mask_0: 2.404  loss_mask_1: 2.38  loss_mask_2: 2.38  loss_mask_3: 2.38  loss_mask_4: 2.38  loss_mask_5: 2.38  loss_mask_6: 2.38  loss_mask_7: 2.38  loss_mask_8: 2.38  time: 2.0138  data_time: 0.4384  lr: 6.2072e-05  max_mem: 17500M
[01/27 19:30:33] d2.utils.events INFO:  eta: 22:47:07  iter: 24699  total_loss: 23.52  loss_mask: 2.352  loss_mask_0: 2.354  loss_mask_1: 2.352  loss_mask_2: 2.352  loss_mask_3: 2.352  loss_mask_4: 2.352  loss_mask_5: 2.353  loss_mask_6: 2.352  loss_mask_7: 2.352  loss_mask_8: 2.352  time: 2.0141  data_time: 0.4192  lr: 6.204e-05  max_mem: 17500M
[01/27 19:31:19] d2.utils.events INFO:  eta: 22:45:48  iter: 24719  total_loss: 25.85  loss_mask: 2.586  loss_mask_0: 2.582  loss_mask_1: 2.586  loss_mask_2: 2.586  loss_mask_3: 2.586  loss_mask_4: 2.586  loss_mask_5: 2.586  loss_mask_6: 2.586  loss_mask_7: 2.586  loss_mask_8: 2.586  time: 2.0143  data_time: 0.4237  lr: 6.2008e-05  max_mem: 17500M
[01/27 19:32:06] d2.utils.events INFO:  eta: 22:44:19  iter: 24739  total_loss: 26.24  loss_mask: 2.623  loss_mask_0: 2.645  loss_mask_1: 2.623  loss_mask_2: 2.623  loss_mask_3: 2.623  loss_mask_4: 2.623  loss_mask_5: 2.624  loss_mask_6: 2.623  loss_mask_7: 2.623  loss_mask_8: 2.624  time: 2.0146  data_time: 0.4290  lr: 6.1977e-05  max_mem: 17500M
[01/27 19:32:52] d2.utils.events INFO:  eta: 22:43:07  iter: 24759  total_loss: 25.73  loss_mask: 2.568  loss_mask_0: 2.604  loss_mask_1: 2.573  loss_mask_2: 2.569  loss_mask_3: 2.569  loss_mask_4: 2.57  loss_mask_5: 2.569  loss_mask_6: 2.568  loss_mask_7: 2.569  loss_mask_8: 2.569  time: 2.0148  data_time: 0.4187  lr: 6.1945e-05  max_mem: 17500M
[01/27 19:33:39] d2.utils.events INFO:  eta: 22:40:48  iter: 24779  total_loss: 24.4  loss_mask: 2.436  loss_mask_0: 2.511  loss_mask_1: 2.435  loss_mask_2: 2.435  loss_mask_3: 2.435  loss_mask_4: 2.436  loss_mask_5: 2.435  loss_mask_6: 2.435  loss_mask_7: 2.435  loss_mask_8: 2.436  time: 2.0151  data_time: 0.4272  lr: 6.1914e-05  max_mem: 17500M
[01/27 19:34:25] d2.utils.events INFO:  eta: 22:40:47  iter: 24799  total_loss: 25.05  loss_mask: 2.501  loss_mask_0: 2.515  loss_mask_1: 2.502  loss_mask_2: 2.501  loss_mask_3: 2.501  loss_mask_4: 2.501  loss_mask_5: 2.501  loss_mask_6: 2.501  loss_mask_7: 2.501  loss_mask_8: 2.501  time: 2.0153  data_time: 0.4128  lr: 6.1882e-05  max_mem: 17500M
[01/27 19:35:12] d2.utils.events INFO:  eta: 22:38:58  iter: 24819  total_loss: 26.43  loss_mask: 2.645  loss_mask_0: 2.633  loss_mask_1: 2.645  loss_mask_2: 2.645  loss_mask_3: 2.644  loss_mask_4: 2.645  loss_mask_5: 2.645  loss_mask_6: 2.644  loss_mask_7: 2.645  loss_mask_8: 2.645  time: 2.0156  data_time: 0.4325  lr: 6.185e-05  max_mem: 17500M
[01/27 19:35:59] d2.utils.events INFO:  eta: 22:38:19  iter: 24839  total_loss: 25.14  loss_mask: 2.505  loss_mask_0: 2.527  loss_mask_1: 2.504  loss_mask_2: 2.504  loss_mask_3: 2.505  loss_mask_4: 2.505  loss_mask_5: 2.505  loss_mask_6: 2.504  loss_mask_7: 2.504  loss_mask_8: 2.505  time: 2.0158  data_time: 0.4360  lr: 6.1819e-05  max_mem: 17500M
[01/27 19:36:45] d2.utils.events INFO:  eta: 22:37:17  iter: 24859  total_loss: 26.51  loss_mask: 2.652  loss_mask_0: 2.659  loss_mask_1: 2.652  loss_mask_2: 2.652  loss_mask_3: 2.652  loss_mask_4: 2.652  loss_mask_5: 2.652  loss_mask_6: 2.652  loss_mask_7: 2.652  loss_mask_8: 2.652  time: 2.0161  data_time: 0.4165  lr: 6.1787e-05  max_mem: 17500M
[01/27 19:37:31] d2.utils.events INFO:  eta: 22:36:26  iter: 24879  total_loss: 24.4  loss_mask: 2.439  loss_mask_0: 2.477  loss_mask_1: 2.438  loss_mask_2: 2.439  loss_mask_3: 2.439  loss_mask_4: 2.439  loss_mask_5: 2.439  loss_mask_6: 2.439  loss_mask_7: 2.439  loss_mask_8: 2.439  time: 2.0163  data_time: 0.4361  lr: 6.1755e-05  max_mem: 17500M
[01/27 19:38:17] d2.utils.events INFO:  eta: 22:35:30  iter: 24899  total_loss: 26.8  loss_mask: 2.676  loss_mask_0: 2.708  loss_mask_1: 2.675  loss_mask_2: 2.675  loss_mask_3: 2.675  loss_mask_4: 2.675  loss_mask_5: 2.675  loss_mask_6: 2.675  loss_mask_7: 2.675  loss_mask_8: 2.676  time: 2.0165  data_time: 0.4174  lr: 6.1724e-05  max_mem: 17500M
[01/27 19:39:02] d2.utils.events INFO:  eta: 22:34:03  iter: 24919  total_loss: 24.76  loss_mask: 2.475  loss_mask_0: 2.457  loss_mask_1: 2.475  loss_mask_2: 2.474  loss_mask_3: 2.475  loss_mask_4: 2.475  loss_mask_5: 2.475  loss_mask_6: 2.475  loss_mask_7: 2.475  loss_mask_8: 2.475  time: 2.0167  data_time: 0.4091  lr: 6.1692e-05  max_mem: 17500M
[01/27 19:39:48] d2.utils.events INFO:  eta: 22:33:09  iter: 24939  total_loss: 24.16  loss_mask: 2.416  loss_mask_0: 2.418  loss_mask_1: 2.416  loss_mask_2: 2.416  loss_mask_3: 2.416  loss_mask_4: 2.416  loss_mask_5: 2.416  loss_mask_6: 2.416  loss_mask_7: 2.416  loss_mask_8: 2.416  time: 2.0170  data_time: 0.4375  lr: 6.166e-05  max_mem: 17500M
[01/27 19:40:32] d2.utils.events INFO:  eta: 22:31:37  iter: 24959  total_loss: 24.08  loss_mask: 2.407  loss_mask_0: 2.422  loss_mask_1: 2.407  loss_mask_2: 2.407  loss_mask_3: 2.407  loss_mask_4: 2.407  loss_mask_5: 2.407  loss_mask_6: 2.407  loss_mask_7: 2.407  loss_mask_8: 2.406  time: 2.0171  data_time: 0.4563  lr: 6.1629e-05  max_mem: 17500M
[01/27 19:41:16] d2.utils.events INFO:  eta: 22:29:50  iter: 24979  total_loss: 24.89  loss_mask: 2.488  loss_mask_0: 2.502  loss_mask_1: 2.487  loss_mask_2: 2.487  loss_mask_3: 2.487  loss_mask_4: 2.488  loss_mask_5: 2.487  loss_mask_6: 2.488  loss_mask_7: 2.488  loss_mask_8: 2.488  time: 2.0172  data_time: 0.4376  lr: 6.1597e-05  max_mem: 17500M
[01/27 19:42:01] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_inference_argsoftmax_noCE/model_0024999.pth
[01/27 19:42:02] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/27 19:42:02] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/27 19:42:03] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/27 19:50:09] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.6727870805168794, 'error_1pix': 0.405078359798358, 'error_3pix': 0.16495719681966398, 'mIoU': 6.478475296154761, 'fwIoU': 18.686160319050884, 'IoU-0': nan, 'IoU-1': 66.81131268622696, 'IoU-2': 2.749798155060431, 'IoU-3': 3.673136297747231, 'IoU-4': 3.8224041429799382, 'IoU-5': 3.974942424717055, 'IoU-6': 4.157469566017424, 'IoU-7': 4.0852505843938065, 'IoU-8': 4.108215110879912, 'IoU-9': 9.74470267234273, 'IoU-10': 19.301991304894646, 'IoU-11': 28.958291204933555, 'IoU-12': 30.96892292343173, 'IoU-13': 28.690894565554164, 'IoU-14': 27.415156062455853, 'IoU-15': 26.915180561993306, 'IoU-16': 25.01579727424959, 'IoU-17': 21.039048207540482, 'IoU-18': 21.27633447910376, 'IoU-19': 22.733982239667373, 'IoU-20': 22.077685537048197, 'IoU-21': 21.014813576828747, 'IoU-22': 21.764470024005412, 'IoU-23': 21.176556562748893, 'IoU-24': 21.139050909185066, 'IoU-25': 20.16773602066905, 'IoU-26': 19.37553443612988, 'IoU-27': 20.671397420649036, 'IoU-28': 19.2957277145731, 'IoU-29': 18.77132398109277, 'IoU-30': 16.529952345052788, 'IoU-31': 16.231721709761953, 'IoU-32': 14.79097024912837, 'IoU-33': 13.411136874329205, 'IoU-34': 12.416991460671133, 'IoU-35': 12.026185461306628, 'IoU-36': 11.078803716050011, 'IoU-37': 9.84975452018061, 'IoU-38': 9.395349298731038, 'IoU-39': 8.809750692203968, 'IoU-40': 7.952091438516362, 'IoU-41': 7.295869199390009, 'IoU-42': 6.657940674135984, 'IoU-43': 6.5380612382259935, 'IoU-44': 6.21429635721351, 'IoU-45': 6.272001507316623, 'IoU-46': 5.83548021111691, 'IoU-47': 5.883376617380772, 'IoU-48': 5.5094073569956485, 'IoU-49': 5.514086735115358, 'IoU-50': 5.878327527785732, 'IoU-51': 5.900444062684616, 'IoU-52': 6.239428427356294, 'IoU-53': 6.561155950432321, 'IoU-54': 6.921431098388076, 'IoU-55': 6.505624869443268, 'IoU-56': 6.355098812874626, 'IoU-57': 6.546755673070061, 'IoU-58': 6.305795565475446, 'IoU-59': 6.462494549482196, 'IoU-60': 6.274191232858669, 'IoU-61': 6.139983068165444, 'IoU-62': 6.549413184061908, 'IoU-63': 6.54657104103882, 'IoU-64': 6.046468525261988, 'IoU-65': 6.220689647086523, 'IoU-66': 6.168270551232708, 'IoU-67': 5.988828700237999, 'IoU-68': 5.651694540552158, 'IoU-69': 5.98327569616029, 'IoU-70': 6.239290795849243, 'IoU-71': 6.13386257255721, 'IoU-72': 6.033915506254425, 'IoU-73': 6.0351444593113435, 'IoU-74': 6.138509373287375, 'IoU-75': 6.1357226701824885, 'IoU-76': 6.100975112708596, 'IoU-77': 5.885781456459994, 'IoU-78': 5.814452680292989, 'IoU-79': 5.7924269367513155, 'IoU-80': 5.516011832786243, 'IoU-81': 5.445842643397258, 'IoU-82': 5.3222420513514725, 'IoU-83': 5.506122941698356, 'IoU-84': 5.4723743752952965, 'IoU-85': 5.6517686648653065, 'IoU-86': 5.275337860340226, 'IoU-87': 5.072582685797658, 'IoU-88': 5.164060866402784, 'IoU-89': 5.18461689298495, 'IoU-90': 5.10411315212627, 'IoU-91': 5.100217729208937, 'IoU-92': 4.819970151641755, 'IoU-93': 5.053158033742333, 'IoU-94': 4.990289596193154, 'IoU-95': 4.737723039191732, 'IoU-96': 4.477408295090834, 'IoU-97': 4.382887423057014, 'IoU-98': 4.260889151775498, 'IoU-99': 4.346282274148132, 'IoU-100': 4.27101720447264, 'IoU-101': 4.1057720002033085, 'IoU-102': 4.064472875579642, 'IoU-103': 3.7523652482274064, 'IoU-104': 3.7281788505439826, 'IoU-105': 3.6956702376323967, 'IoU-106': 3.5714444409565607, 'IoU-107': 3.6499938880456106, 'IoU-108': 3.741944021262363, 'IoU-109': 3.94623139852308, 'IoU-110': 3.926365218078684, 'IoU-111': 3.7280293603008303, 'IoU-112': 3.8638135295578953, 'IoU-113': 3.4466405217107123, 'IoU-114': 3.3384167074430913, 'IoU-115': 3.2345337969223316, 'IoU-116': 3.351369002365044, 'IoU-117': 3.3386386812260764, 'IoU-118': 3.305842842585982, 'IoU-119': 3.5337900757044904, 'IoU-120': 3.4734373148611226, 'IoU-121': 3.450769226217888, 'IoU-122': 3.2377821788436045, 'IoU-123': 3.3209561432420918, 'IoU-124': 3.257544734860702, 'IoU-125': 3.2153566386239194, 'IoU-126': 3.224317659710748, 'IoU-127': 3.1250886647883718, 'IoU-128': 3.0993299838359754, 'IoU-129': 3.1492761335526485, 'IoU-130': 3.041881831131417, 'IoU-131': 2.7901954410208734, 'IoU-132': 2.7218198813652608, 'IoU-133': 2.799202377817074, 'IoU-134': 2.8114858955919657, 'IoU-135': 2.8079178419327455, 'IoU-136': 2.6452914143908752, 'IoU-137': 2.461885524527252, 'IoU-138': 2.3238351117040414, 'IoU-139': 2.403120380244197, 'IoU-140': 2.5718586791453837, 'IoU-141': 2.487202508303854, 'IoU-142': 2.496981176970947, 'IoU-143': 2.3032890493256164, 'IoU-144': 2.550879535979415, 'IoU-145': 2.8134365031275066, 'IoU-146': 2.565994893639797, 'IoU-147': 2.749137101659907, 'IoU-148': 2.371859808806527, 'IoU-149': 2.269470890462294, 'IoU-150': 2.210747930138744, 'IoU-151': 2.214350868864424, 'IoU-152': 2.455267524657999, 'IoU-153': 2.0120362142346906, 'IoU-154': 2.0466657214547075, 'IoU-155': 2.0946112060493722, 'IoU-156': 2.2216871825261864, 'IoU-157': 2.191141429833206, 'IoU-158': 2.1295473430471343, 'IoU-159': 2.1783559666193266, 'IoU-160': 2.161536819956795, 'IoU-161': 2.3216739215018727, 'IoU-162': 1.9612799502614884, 'IoU-163': 1.9157162188285326, 'IoU-164': 1.7642523319885166, 'IoU-165': 1.7970011360974762, 'IoU-166': 1.9506853550448318, 'IoU-167': 1.854462479490166, 'IoU-168': 1.827190646131388, 'IoU-169': 1.6343352642264966, 'IoU-170': 1.578635088087415, 'IoU-171': 1.54669536109738, 'IoU-172': 1.5294350133624421, 'IoU-173': 1.460668572380918, 'IoU-174': 1.2477782946115994, 'IoU-175': 1.315484644285297, 'IoU-176': 1.1501951393145164, 'IoU-177': 1.1111023233269346, 'IoU-178': 1.0779414715698477, 'IoU-179': 0.6947847858512679, 'IoU-180': 0.7282956455320749, 'IoU-181': 0.6534510976432827, 'IoU-182': 0.39211987030450324, 'IoU-183': 0.311773994026008, 'IoU-184': 0.2534878854364198, 'IoU-185': 0.16508079053888974, 'IoU-186': 0.19255338565431648, 'IoU-187': 0.14933687317032698, 'IoU-188': 0.07220054262829961, 'IoU-189': 0.0440163372265613, 'IoU-190': 0.014912019087384433, 'IoU-191': 0.01538525727279365, 'IoU-192': 0.012439569138559836, 'mACC': 11.490885349254183, 'pACC': 27.181292041380917, 'ACC-0': nan, 'ACC-1': 68.05262021596944, 'ACC-2': 5.724821612410806, 'ACC-3': 17.61913895057435, 'ACC-4': 16.356704843664723, 'ACC-5': 17.30217172761318, 'ACC-6': 18.23615947240345, 'ACC-7': 17.85554109191945, 'ACC-8': 8.471218687782253, 'ACC-9': 13.429324368651535, 'ACC-10': 28.224731961732154, 'ACC-11': 39.07333422452565, 'ACC-12': 47.87542524053367, 'ACC-13': 44.84423359566247, 'ACC-14': 41.63572434367057, 'ACC-15': 43.28905901138886, 'ACC-16': 40.28996809396018, 'ACC-17': 35.52985813391839, 'ACC-18': 34.3186069740541, 'ACC-19': 37.23653846839961, 'ACC-20': 37.19727451610233, 'ACC-21': 35.24182557923336, 'ACC-22': 35.45243571550517, 'ACC-23': 36.044567112547895, 'ACC-24': 36.631900764471524, 'ACC-25': 35.43872334891739, 'ACC-26': 33.78398370652279, 'ACC-27': 35.2996393596724, 'ACC-28': 34.26875484108643, 'ACC-29': 33.29249894874019, 'ACC-30': 30.025124051662534, 'ACC-31': 29.159584560685918, 'ACC-32': 26.658785610718134, 'ACC-33': 24.779632448951393, 'ACC-34': 23.593894416354047, 'ACC-35': 22.83568186379478, 'ACC-36': 20.70465689364024, 'ACC-37': 18.54967162383363, 'ACC-38': 17.68571166662979, 'ACC-39': 16.481606354200157, 'ACC-40': 14.686542141644884, 'ACC-41': 13.974459336650305, 'ACC-42': 12.93031828563342, 'ACC-43': 12.62706698597708, 'ACC-44': 11.499738502161605, 'ACC-45': 11.533295011077216, 'ACC-46': 11.078849631996642, 'ACC-47': 11.204870946591598, 'ACC-48': 10.434098349864069, 'ACC-49': 10.225082307070606, 'ACC-50': 10.66487357447334, 'ACC-51': 10.745135871412362, 'ACC-52': 11.332047361126499, 'ACC-53': 11.887455265593069, 'ACC-54': 12.506839618836613, 'ACC-55': 11.816701277702883, 'ACC-56': 11.694336449693745, 'ACC-57': 11.849962765142056, 'ACC-58': 11.447158107172454, 'ACC-59': 11.767341102220191, 'ACC-60': 11.325818178144004, 'ACC-61': 11.229137396363093, 'ACC-62': 12.014483818347129, 'ACC-63': 12.087906006932608, 'ACC-64': 11.155627998911005, 'ACC-65': 11.546184331765327, 'ACC-66': 11.469938443135023, 'ACC-67': 11.179788149692879, 'ACC-68': 10.614403166419658, 'ACC-69': 11.090834388037164, 'ACC-70': 11.522079216015529, 'ACC-71': 11.568917259815414, 'ACC-72': 11.388377357683703, 'ACC-73': 11.376581222495313, 'ACC-74': 11.551882855078496, 'ACC-75': 11.611387087368781, 'ACC-76': 11.378046471196017, 'ACC-77': 11.15362858513311, 'ACC-78': 11.080815293937826, 'ACC-79': 11.030901413467587, 'ACC-80': 10.437298350556343, 'ACC-81': 10.204417202113644, 'ACC-82': 9.926307198330148, 'ACC-83': 10.137640414736476, 'ACC-84': 10.150489740686556, 'ACC-85': 10.43184125339714, 'ACC-86': 9.720565852813996, 'ACC-87': 9.337185777668155, 'ACC-88': 9.46400413652233, 'ACC-89': 9.48574480241016, 'ACC-90': 9.30945577252955, 'ACC-91': 9.35861382576371, 'ACC-92': 8.95310405453388, 'ACC-93': 9.450934168111514, 'ACC-94': 9.233008799394723, 'ACC-95': 8.69834639199922, 'ACC-96': 8.197197973844226, 'ACC-97': 7.919166953869048, 'ACC-98': 7.67020646848037, 'ACC-99': 7.8768087491042555, 'ACC-100': 7.749501884203587, 'ACC-101': 7.500481454542954, 'ACC-102': 7.449705482555505, 'ACC-103': 6.887933471191181, 'ACC-104': 6.886525171540296, 'ACC-105': 6.7926072218188445, 'ACC-106': 6.533645799162301, 'ACC-107': 6.691480751406603, 'ACC-108': 6.830177864580382, 'ACC-109': 7.163149218336941, 'ACC-110': 7.238535587921, 'ACC-111': 6.880074813194224, 'ACC-112': 7.223836016279857, 'ACC-113': 6.436650073429841, 'ACC-114': 6.2258814422902065, 'ACC-115': 6.039044998722054, 'ACC-116': 6.31674555999063, 'ACC-117': 6.2213549975207485, 'ACC-118': 6.161069187222388, 'ACC-119': 6.523507883426255, 'ACC-120': 6.412417739678311, 'ACC-121': 6.357707277390766, 'ACC-122': 5.993376546180191, 'ACC-123': 6.174691958655454, 'ACC-124': 6.225450841483756, 'ACC-125': 6.149529619965128, 'ACC-126': 6.20366533392836, 'ACC-127': 5.982791167098095, 'ACC-128': 5.938960178853043, 'ACC-129': 6.04219862584316, 'ACC-130': 5.824237765160212, 'ACC-131': 5.373317037867022, 'ACC-132': 5.220348979434542, 'ACC-133': 5.3661025944599805, 'ACC-134': 5.3632055148642825, 'ACC-135': 5.3481842540334075, 'ACC-136': 5.001980059634737, 'ACC-137': 4.646024284526915, 'ACC-138': 4.37438129806838, 'ACC-139': 4.53386874227815, 'ACC-140': 4.823774571922205, 'ACC-141': 4.632333511181727, 'ACC-142': 4.655563900581629, 'ACC-143': 4.293289410191643, 'ACC-144': 4.702711825552189, 'ACC-145': 5.054406404436593, 'ACC-146': 4.556350094811633, 'ACC-147': 4.858126295870208, 'ACC-148': 4.157331673074821, 'ACC-149': 4.068798710024187, 'ACC-150': 3.978503365624147, 'ACC-151': 3.9869676707002797, 'ACC-152': 4.3108098995212085, 'ACC-153': 3.622157789626047, 'ACC-154': 3.695014800489866, 'ACC-155': 3.8539996277638844, 'ACC-156': 4.163256969034128, 'ACC-157': 4.200312767529885, 'ACC-158': 4.163173597762178, 'ACC-159': 4.209835377644704, 'ACC-160': 4.0813181468578925, 'ACC-161': 4.289948929513742, 'ACC-162': 3.7167454377485303, 'ACC-163': 3.6357910795933126, 'ACC-164': 3.3703233335077396, 'ACC-165': 3.4239765710365155, 'ACC-166': 3.813215722946281, 'ACC-167': 3.7087864364381753, 'ACC-168': 3.662104567256973, 'ACC-169': 3.3066262375282074, 'ACC-170': 3.1777468982982566, 'ACC-171': 3.120878474939291, 'ACC-172': 3.0102496286500644, 'ACC-173': 2.819824379523864, 'ACC-174': 2.3752933697960064, 'ACC-175': 2.414730968277535, 'ACC-176': 1.9814841356088413, 'ACC-177': 1.814987209821676, 'ACC-178': 1.691444643629845, 'ACC-179': 1.0586681115041123, 'ACC-180': 1.0374309137901474, 'ACC-181': 0.9015690381526008, 'ACC-182': 0.5025030339805826, 'ACC-183': 0.36505719621942057, 'ACC-184': 0.2771775540437256, 'ACC-185': 0.17325177409816675, 'ACC-186': 0.19926809113445876, 'ACC-187': 0.1522445191973089, 'ACC-188': 0.07290560364073935, 'ACC-189': 0.044172106855408254, 'ACC-190': 0.014943098254803418, 'ACC-191': 0.015411178067020342, 'ACC-192': 0.012457883858546393})])
[01/27 19:50:09] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/27 19:50:09] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/27 19:50:09] d2.evaluation.testing INFO: copypaste: 2.6728,0.4051,0.1650,6.4785,18.6862,11.4909,27.1813
[01/27 19:50:09] d2.utils.events INFO:  eta: 22:27:51  iter: 24999  total_loss: 28.31  loss_mask: 2.83  loss_mask_0: 2.836  loss_mask_1: 2.83  loss_mask_2: 2.83  loss_mask_3: 2.831  loss_mask_4: 2.83  loss_mask_5: 2.83  loss_mask_6: 2.831  loss_mask_7: 2.831  loss_mask_8: 2.831  time: 2.0174  data_time: 0.4550  lr: 6.1565e-05  max_mem: 17500M
[01/27 19:50:54] d2.utils.events INFO:  eta: 22:26:19  iter: 25019  total_loss: 25.93  loss_mask: 2.593  loss_mask_0: 2.597  loss_mask_1: 2.592  loss_mask_2: 2.591  loss_mask_3: 2.592  loss_mask_4: 2.593  loss_mask_5: 2.592  loss_mask_6: 2.593  loss_mask_7: 2.592  loss_mask_8: 2.593  time: 2.0176  data_time: 0.4553  lr: 6.1534e-05  max_mem: 17500M
[01/27 19:51:39] d2.utils.events INFO:  eta: 22:23:46  iter: 25039  total_loss: 23.12  loss_mask: 2.311  loss_mask_0: 2.318  loss_mask_1: 2.311  loss_mask_2: 2.311  loss_mask_3: 2.311  loss_mask_4: 2.311  loss_mask_5: 2.311  loss_mask_6: 2.311  loss_mask_7: 2.312  loss_mask_8: 2.311  time: 2.0178  data_time: 0.4610  lr: 6.1502e-05  max_mem: 17500M
[01/27 19:52:23] d2.utils.events INFO:  eta: 22:22:36  iter: 25059  total_loss: 25.47  loss_mask: 2.544  loss_mask_0: 2.578  loss_mask_1: 2.544  loss_mask_2: 2.543  loss_mask_3: 2.543  loss_mask_4: 2.544  loss_mask_5: 2.542  loss_mask_6: 2.543  loss_mask_7: 2.543  loss_mask_8: 2.544  time: 2.0179  data_time: 0.4337  lr: 6.147e-05  max_mem: 17500M
[01/27 19:53:08] d2.utils.events INFO:  eta: 22:21:14  iter: 25079  total_loss: 21.85  loss_mask: 2.183  loss_mask_0: 2.19  loss_mask_1: 2.183  loss_mask_2: 2.183  loss_mask_3: 2.183  loss_mask_4: 2.183  loss_mask_5: 2.183  loss_mask_6: 2.183  loss_mask_7: 2.183  loss_mask_8: 2.183  time: 2.0181  data_time: 0.4970  lr: 6.1439e-05  max_mem: 17500M
[01/27 19:53:53] d2.utils.events INFO:  eta: 22:19:22  iter: 25099  total_loss: 25.66  loss_mask: 2.565  loss_mask_0: 2.572  loss_mask_1: 2.566  loss_mask_2: 2.566  loss_mask_3: 2.566  loss_mask_4: 2.565  loss_mask_5: 2.566  loss_mask_6: 2.566  loss_mask_7: 2.566  loss_mask_8: 2.565  time: 2.0183  data_time: 0.4559  lr: 6.1407e-05  max_mem: 17500M
[01/27 19:54:38] d2.utils.events INFO:  eta: 22:17:54  iter: 25119  total_loss: 25.02  loss_mask: 2.499  loss_mask_0: 2.522  loss_mask_1: 2.497  loss_mask_2: 2.497  loss_mask_3: 2.497  loss_mask_4: 2.499  loss_mask_5: 2.497  loss_mask_6: 2.497  loss_mask_7: 2.497  loss_mask_8: 2.499  time: 2.0185  data_time: 0.4155  lr: 6.1375e-05  max_mem: 17500M
[01/27 19:55:22] d2.utils.events INFO:  eta: 22:15:44  iter: 25139  total_loss: 24.12  loss_mask: 2.412  loss_mask_0: 2.422  loss_mask_1: 2.411  loss_mask_2: 2.411  loss_mask_3: 2.411  loss_mask_4: 2.411  loss_mask_5: 2.411  loss_mask_6: 2.411  loss_mask_7: 2.411  loss_mask_8: 2.411  time: 2.0187  data_time: 0.4294  lr: 6.1344e-05  max_mem: 17500M
[01/27 19:56:07] d2.utils.events INFO:  eta: 22:13:41  iter: 25159  total_loss: 23.46  loss_mask: 2.345  loss_mask_0: 2.356  loss_mask_1: 2.345  loss_mask_2: 2.345  loss_mask_3: 2.345  loss_mask_4: 2.345  loss_mask_5: 2.345  loss_mask_6: 2.345  loss_mask_7: 2.345  loss_mask_8: 2.345  time: 2.0188  data_time: 0.4844  lr: 6.1312e-05  max_mem: 17500M
[01/27 19:56:51] d2.utils.events INFO:  eta: 22:12:30  iter: 25179  total_loss: 21.59  loss_mask: 2.157  loss_mask_0: 2.173  loss_mask_1: 2.157  loss_mask_2: 2.157  loss_mask_3: 2.157  loss_mask_4: 2.157  loss_mask_5: 2.157  loss_mask_6: 2.157  loss_mask_7: 2.157  loss_mask_8: 2.157  time: 2.0190  data_time: 0.4181  lr: 6.128e-05  max_mem: 17500M
[01/27 19:57:36] d2.utils.events INFO:  eta: 22:11:42  iter: 25199  total_loss: 26.15  loss_mask: 2.614  loss_mask_0: 2.612  loss_mask_1: 2.613  loss_mask_2: 2.613  loss_mask_3: 2.613  loss_mask_4: 2.614  loss_mask_5: 2.613  loss_mask_6: 2.613  loss_mask_7: 2.613  loss_mask_8: 2.614  time: 2.0191  data_time: 0.4455  lr: 6.1249e-05  max_mem: 17500M
[01/27 19:58:22] d2.utils.events INFO:  eta: 22:10:12  iter: 25219  total_loss: 25.57  loss_mask: 2.557  loss_mask_0: 2.564  loss_mask_1: 2.557  loss_mask_2: 2.557  loss_mask_3: 2.557  loss_mask_4: 2.557  loss_mask_5: 2.556  loss_mask_6: 2.557  loss_mask_7: 2.557  loss_mask_8: 2.557  time: 2.0194  data_time: 0.4780  lr: 6.1217e-05  max_mem: 17500M
[01/27 19:59:07] d2.utils.events INFO:  eta: 22:08:34  iter: 25239  total_loss: 22.44  loss_mask: 2.242  loss_mask_0: 2.264  loss_mask_1: 2.241  loss_mask_2: 2.241  loss_mask_3: 2.242  loss_mask_4: 2.241  loss_mask_5: 2.242  loss_mask_6: 2.242  loss_mask_7: 2.241  loss_mask_8: 2.241  time: 2.0195  data_time: 0.4669  lr: 6.1185e-05  max_mem: 17500M
[01/27 19:59:51] d2.utils.events INFO:  eta: 22:06:27  iter: 25259  total_loss: 23.23  loss_mask: 2.322  loss_mask_0: 2.333  loss_mask_1: 2.322  loss_mask_2: 2.322  loss_mask_3: 2.322  loss_mask_4: 2.322  loss_mask_5: 2.322  loss_mask_6: 2.322  loss_mask_7: 2.322  loss_mask_8: 2.322  time: 2.0197  data_time: 0.4573  lr: 6.1154e-05  max_mem: 17500M
[01/27 20:00:36] d2.utils.events INFO:  eta: 22:03:31  iter: 25279  total_loss: 22  loss_mask: 2.199  loss_mask_0: 2.216  loss_mask_1: 2.199  loss_mask_2: 2.199  loss_mask_3: 2.198  loss_mask_4: 2.199  loss_mask_5: 2.198  loss_mask_6: 2.198  loss_mask_7: 2.198  loss_mask_8: 2.199  time: 2.0199  data_time: 0.4615  lr: 6.1122e-05  max_mem: 17500M
[01/27 20:01:21] d2.utils.events INFO:  eta: 22:01:41  iter: 25299  total_loss: 21.67  loss_mask: 2.167  loss_mask_0: 2.177  loss_mask_1: 2.166  loss_mask_2: 2.166  loss_mask_3: 2.166  loss_mask_4: 2.167  loss_mask_5: 2.166  loss_mask_6: 2.166  loss_mask_7: 2.166  loss_mask_8: 2.167  time: 2.0200  data_time: 0.4572  lr: 6.109e-05  max_mem: 17500M
[01/27 20:02:05] d2.utils.events INFO:  eta: 21:59:37  iter: 25319  total_loss: 22.04  loss_mask: 2.203  loss_mask_0: 2.213  loss_mask_1: 2.202  loss_mask_2: 2.203  loss_mask_3: 2.203  loss_mask_4: 2.203  loss_mask_5: 2.203  loss_mask_6: 2.203  loss_mask_7: 2.203  loss_mask_8: 2.203  time: 2.0202  data_time: 0.4469  lr: 6.1059e-05  max_mem: 17500M
[01/27 20:02:49] d2.utils.events INFO:  eta: 21:57:11  iter: 25339  total_loss: 23.03  loss_mask: 2.302  loss_mask_0: 2.314  loss_mask_1: 2.302  loss_mask_2: 2.302  loss_mask_3: 2.302  loss_mask_4: 2.301  loss_mask_5: 2.302  loss_mask_6: 2.302  loss_mask_7: 2.302  loss_mask_8: 2.302  time: 2.0203  data_time: 0.4175  lr: 6.1027e-05  max_mem: 17500M
[01/27 20:03:34] d2.utils.events INFO:  eta: 21:55:15  iter: 25359  total_loss: 21.7  loss_mask: 2.169  loss_mask_0: 2.183  loss_mask_1: 2.168  loss_mask_2: 2.169  loss_mask_3: 2.169  loss_mask_4: 2.169  loss_mask_5: 2.168  loss_mask_6: 2.169  loss_mask_7: 2.169  loss_mask_8: 2.169  time: 2.0205  data_time: 0.4397  lr: 6.0995e-05  max_mem: 17500M
[01/27 20:04:18] d2.utils.events INFO:  eta: 21:53:21  iter: 25379  total_loss: 23.11  loss_mask: 2.311  loss_mask_0: 2.311  loss_mask_1: 2.311  loss_mask_2: 2.311  loss_mask_3: 2.311  loss_mask_4: 2.311  loss_mask_5: 2.311  loss_mask_6: 2.311  loss_mask_7: 2.311  loss_mask_8: 2.311  time: 2.0206  data_time: 0.4161  lr: 6.0963e-05  max_mem: 17500M
[01/27 20:05:01] d2.utils.events INFO:  eta: 21:50:26  iter: 25399  total_loss: 21.94  loss_mask: 2.194  loss_mask_0: 2.204  loss_mask_1: 2.193  loss_mask_2: 2.193  loss_mask_3: 2.193  loss_mask_4: 2.194  loss_mask_5: 2.193  loss_mask_6: 2.193  loss_mask_7: 2.193  loss_mask_8: 2.194  time: 2.0207  data_time: 0.4149  lr: 6.0932e-05  max_mem: 17500M
[01/27 20:05:44] d2.utils.events INFO:  eta: 21:47:41  iter: 25419  total_loss: 24.31  loss_mask: 2.431  loss_mask_0: 2.434  loss_mask_1: 2.432  loss_mask_2: 2.432  loss_mask_3: 2.432  loss_mask_4: 2.431  loss_mask_5: 2.432  loss_mask_6: 2.432  loss_mask_7: 2.432  loss_mask_8: 2.43  time: 2.0209  data_time: 0.4246  lr: 6.09e-05  max_mem: 17500M
[01/27 20:06:28] d2.utils.events INFO:  eta: 21:46:35  iter: 25439  total_loss: 23.64  loss_mask: 2.364  loss_mask_0: 2.376  loss_mask_1: 2.364  loss_mask_2: 2.364  loss_mask_3: 2.364  loss_mask_4: 2.365  loss_mask_5: 2.365  loss_mask_6: 2.364  loss_mask_7: 2.364  loss_mask_8: 2.364  time: 2.0210  data_time: 0.4493  lr: 6.0868e-05  max_mem: 17500M
[01/27 20:07:12] d2.utils.events INFO:  eta: 21:44:11  iter: 25459  total_loss: 24.2  loss_mask: 2.419  loss_mask_0: 2.421  loss_mask_1: 2.419  loss_mask_2: 2.419  loss_mask_3: 2.42  loss_mask_4: 2.419  loss_mask_5: 2.419  loss_mask_6: 2.42  loss_mask_7: 2.42  loss_mask_8: 2.42  time: 2.0211  data_time: 0.4384  lr: 6.0837e-05  max_mem: 17500M
[01/27 20:07:57] d2.utils.events INFO:  eta: 21:41:46  iter: 25479  total_loss: 23.56  loss_mask: 2.353  loss_mask_0: 2.388  loss_mask_1: 2.352  loss_mask_2: 2.353  loss_mask_3: 2.353  loss_mask_4: 2.353  loss_mask_5: 2.353  loss_mask_6: 2.353  loss_mask_7: 2.353  loss_mask_8: 2.352  time: 2.0213  data_time: 0.4610  lr: 6.0805e-05  max_mem: 17500M
[01/27 20:08:42] d2.utils.events INFO:  eta: 21:40:22  iter: 25499  total_loss: 22.16  loss_mask: 2.212  loss_mask_0: 2.253  loss_mask_1: 2.212  loss_mask_2: 2.211  loss_mask_3: 2.212  loss_mask_4: 2.212  loss_mask_5: 2.211  loss_mask_6: 2.212  loss_mask_7: 2.212  loss_mask_8: 2.212  time: 2.0215  data_time: 0.4262  lr: 6.0773e-05  max_mem: 17500M
[01/27 20:09:18] d2.engine.hooks INFO: Overall training speed: 25514 iterations in 14:19:40 (2.0217 s / it)
[01/27 20:09:18] d2.engine.hooks INFO: Total training time: 17:22:50 (3:03:09 on hooks)
[01/27 20:09:18] d2.utils.events INFO:  eta: 21:37:04  iter: 25516  total_loss: 24.27  loss_mask: 2.418  loss_mask_0: 2.496  loss_mask_1: 2.418  loss_mask_2: 2.418  loss_mask_3: 2.418  loss_mask_4: 2.418  loss_mask_5: 2.418  loss_mask_6: 2.418  loss_mask_7: 2.418  loss_mask_8: 2.418  time: 2.0216  data_time: 0.4617  lr: 6.0748e-05  max_mem: 17500M
