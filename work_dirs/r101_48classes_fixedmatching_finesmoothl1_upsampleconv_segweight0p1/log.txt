[02/17 22:40:03] detectron2 INFO: Rank of current process: 0. World size: 4
[02/17 22:40:07] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/17 22:40:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65510', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/17 22:40:07] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/17 22:40:07] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/17 22:40:07] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/config.yaml
[02/17 22:40:07] d2.utils.env INFO: Using a generated random seed 7315069
[02/17 22:40:11] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 5.0, 'loss_ce': 0.0, 'loss_dice': 5.0, 'loss_seg': 0.1, 'loss_mask_0': 5.0, 'loss_ce_0': 0.0, 'loss_dice_0': 5.0, 'loss_mask_1': 5.0, 'loss_ce_1': 0.0, 'loss_dice_1': 5.0, 'loss_mask_2': 5.0, 'loss_ce_2': 0.0, 'loss_dice_2': 5.0, 'loss_mask_3': 5.0, 'loss_ce_3': 0.0, 'loss_dice_3': 5.0, 'loss_mask_4': 5.0, 'loss_ce_4': 0.0, 'loss_dice_4': 5.0, 'loss_mask_5': 5.0, 'loss_ce_5': 0.0, 'loss_dice_5': 5.0, 'loss_mask_6': 5.0, 'loss_ce_6': 0.0, 'loss_dice_6': 5.0, 'loss_mask_7': 5.0, 'loss_ce_7': 0.0, 'loss_dice_7': 5.0, 'loss_mask_8': 5.0, 'loss_ce_8': 0.0, 'loss_dice_8': 5.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[02/17 22:40:11] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/17 22:40:16] d2.data.build INFO: Using training sampler TrainingSampler
[02/17 22:40:19] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/17 22:40:19] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/17 22:40:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/17 22:40:19] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/17 22:40:19] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/17 22:40:20] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[02/17 22:40:20] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/17 22:40:20] d2.engine.train_loop INFO: Starting training from iteration 0
[02/17 22:41:12] d2.utils.events INFO:  eta: 1 day, 10:50:28  iter: 19  total_loss: 64.31  loss_ce: 0  loss_mask: 1.225  loss_dice: 4.776  loss_seg: 5.192  loss_ce_0: 0  loss_mask_0: 1.101  loss_dice_0: 4.77  loss_ce_1: 0  loss_mask_1: 1.147  loss_dice_1: 4.752  loss_ce_2: 0  loss_mask_2: 1.205  loss_dice_2: 4.767  loss_ce_3: 0  loss_mask_3: 1.193  loss_dice_3: 4.75  loss_ce_4: 0  loss_mask_4: 1.229  loss_dice_4: 4.742  loss_ce_5: 0  loss_mask_5: 1.217  loss_dice_5: 4.746  loss_ce_6: 0  loss_mask_6: 1.183  loss_dice_6: 4.743  loss_ce_7: 0  loss_mask_7: 1.216  loss_dice_7: 4.739  loss_ce_8: 0  loss_mask_8: 1.17  loss_dice_8: 4.74  time: 2.0411  data_time: 0.4634  lr: 9.9971e-05  max_mem: 3688M
[02/17 22:41:44] d2.utils.events INFO:  eta: 1 day, 3:58:11  iter: 39  total_loss: 61.66  loss_ce: 0  loss_mask: 1.016  loss_dice: 4.801  loss_seg: 2.964  loss_ce_0: 0  loss_mask_0: 1.047  loss_dice_0: 4.756  loss_ce_1: 0  loss_mask_1: 1.054  loss_dice_1: 4.764  loss_ce_2: 0  loss_mask_2: 1.057  loss_dice_2: 4.785  loss_ce_3: 0  loss_mask_3: 1.013  loss_dice_3: 4.791  loss_ce_4: 0  loss_mask_4: 1.041  loss_dice_4: 4.805  loss_ce_5: 0  loss_mask_5: 1.024  loss_dice_5: 4.809  loss_ce_6: 0  loss_mask_6: 1.042  loss_dice_6: 4.812  loss_ce_7: 0  loss_mask_7: 1.001  loss_dice_7: 4.805  loss_ce_8: 0  loss_mask_8: 1.003  loss_dice_8: 4.811  time: 1.8098  data_time: 0.0148  lr: 9.9941e-05  max_mem: 3688M
[02/17 22:42:13] d2.utils.events INFO:  eta: 1 day, 2:39:03  iter: 59  total_loss: 61.03  loss_ce: 0  loss_mask: 1.021  loss_dice: 4.791  loss_seg: 3.204  loss_ce_0: 0  loss_mask_0: 1.019  loss_dice_0: 4.755  loss_ce_1: 0  loss_mask_1: 1.052  loss_dice_1: 4.759  loss_ce_2: 0  loss_mask_2: 1.046  loss_dice_2: 4.771  loss_ce_3: 0  loss_mask_3: 1.031  loss_dice_3: 4.784  loss_ce_4: 0  loss_mask_4: 1.013  loss_dice_4: 4.789  loss_ce_5: 0  loss_mask_5: 1.008  loss_dice_5: 4.794  loss_ce_6: 0  loss_mask_6: 1  loss_dice_6: 4.795  loss_ce_7: 0  loss_mask_7: 0.9898  loss_dice_7: 4.8  loss_ce_8: 0  loss_mask_8: 0.9904  loss_dice_8: 4.799  time: 1.6828  data_time: 0.0141  lr: 9.9911e-05  max_mem: 3688M
[02/17 22:42:43] d2.utils.events INFO:  eta: 1 day, 1:42:32  iter: 79  total_loss: 60.87  loss_ce: 0  loss_mask: 1.097  loss_dice: 4.78  loss_seg: 2.62  loss_ce_0: 0  loss_mask_0: 1.109  loss_dice_0: 4.697  loss_ce_1: 0  loss_mask_1: 1.143  loss_dice_1: 4.696  loss_ce_2: 0  loss_mask_2: 1.137  loss_dice_2: 4.705  loss_ce_3: 0  loss_mask_3: 1.116  loss_dice_3: 4.721  loss_ce_4: 0  loss_mask_4: 1.119  loss_dice_4: 4.725  loss_ce_5: 0  loss_mask_5: 1.082  loss_dice_5: 4.755  loss_ce_6: 0  loss_mask_6: 1.065  loss_dice_6: 4.762  loss_ce_7: 0  loss_mask_7: 1.07  loss_dice_7: 4.779  loss_ce_8: 0  loss_mask_8: 1.069  loss_dice_8: 4.784  time: 1.6342  data_time: 0.0213  lr: 9.9881e-05  max_mem: 3688M
[02/17 22:43:15] d2.utils.events INFO:  eta: 1 day, 1:10:14  iter: 99  total_loss: 60.83  loss_ce: 0  loss_mask: 1.102  loss_dice: 4.782  loss_seg: 2.021  loss_ce_0: 0  loss_mask_0: 1.176  loss_dice_0: 4.664  loss_ce_1: 0  loss_mask_1: 1.216  loss_dice_1: 4.66  loss_ce_2: 0  loss_mask_2: 1.191  loss_dice_2: 4.669  loss_ce_3: 0  loss_mask_3: 1.196  loss_dice_3: 4.679  loss_ce_4: 0  loss_mask_4: 1.198  loss_dice_4: 4.678  loss_ce_5: 0  loss_mask_5: 1.171  loss_dice_5: 4.715  loss_ce_6: 0  loss_mask_6: 1.135  loss_dice_6: 4.718  loss_ce_7: 0  loss_mask_7: 1.101  loss_dice_7: 4.745  loss_ce_8: 0  loss_mask_8: 1.067  loss_dice_8: 4.752  time: 1.6266  data_time: 0.0166  lr: 9.9851e-05  max_mem: 3688M
[02/17 22:43:46] d2.utils.events INFO:  eta: 1 day, 1:09:43  iter: 119  total_loss: 60.77  loss_ce: 0  loss_mask: 1.075  loss_dice: 4.764  loss_seg: 2.181  loss_ce_0: 0  loss_mask_0: 1.118  loss_dice_0: 4.675  loss_ce_1: 0  loss_mask_1: 1.148  loss_dice_1: 4.672  loss_ce_2: 0  loss_mask_2: 1.142  loss_dice_2: 4.691  loss_ce_3: 0  loss_mask_3: 1.142  loss_dice_3: 4.697  loss_ce_4: 0  loss_mask_4: 1.124  loss_dice_4: 4.699  loss_ce_5: 0  loss_mask_5: 1.116  loss_dice_5: 4.71  loss_ce_6: 0  loss_mask_6: 1.106  loss_dice_6: 4.72  loss_ce_7: 0  loss_mask_7: 1.077  loss_dice_7: 4.731  loss_ce_8: 0  loss_mask_8: 1.068  loss_dice_8: 4.744  time: 1.6092  data_time: 0.0203  lr: 9.9821e-05  max_mem: 3688M
[02/17 22:44:17] d2.utils.events INFO:  eta: 1 day, 0:51:00  iter: 139  total_loss: 61.1  loss_ce: 0  loss_mask: 1.149  loss_dice: 4.693  loss_seg: 2.088  loss_ce_0: 0  loss_mask_0: 1.321  loss_dice_0: 4.604  loss_ce_1: 0  loss_mask_1: 1.38  loss_dice_1: 4.576  loss_ce_2: 0  loss_mask_2: 1.377  loss_dice_2: 4.567  loss_ce_3: 0  loss_mask_3: 1.352  loss_dice_3: 4.578  loss_ce_4: 0  loss_mask_4: 1.321  loss_dice_4: 4.587  loss_ce_5: 0  loss_mask_5: 1.316  loss_dice_5: 4.593  loss_ce_6: 0  loss_mask_6: 1.309  loss_dice_6: 4.636  loss_ce_7: 0  loss_mask_7: 1.259  loss_dice_7: 4.636  loss_ce_8: 0  loss_mask_8: 1.219  loss_dice_8: 4.652  time: 1.6041  data_time: 0.0167  lr: 9.9791e-05  max_mem: 3688M
[02/17 22:44:45] d2.utils.events INFO:  eta: 1 day, 0:26:31  iter: 159  total_loss: 61.19  loss_ce: 0  loss_mask: 1.054  loss_dice: 4.713  loss_seg: 2.64  loss_ce_0: 0  loss_mask_0: 1.138  loss_dice_0: 4.637  loss_ce_1: 0  loss_mask_1: 1.182  loss_dice_1: 4.618  loss_ce_2: 0  loss_mask_2: 1.18  loss_dice_2: 4.625  loss_ce_3: 0  loss_mask_3: 1.177  loss_dice_3: 4.627  loss_ce_4: 0  loss_mask_4: 1.189  loss_dice_4: 4.624  loss_ce_5: 0  loss_mask_5: 1.166  loss_dice_5: 4.62  loss_ce_6: 0  loss_mask_6: 1.175  loss_dice_6: 4.627  loss_ce_7: 0  loss_mask_7: 1.164  loss_dice_7: 4.63  loss_ce_8: 0  loss_mask_8: 1.164  loss_dice_8: 4.644  time: 1.5754  data_time: 0.0154  lr: 9.9761e-05  max_mem: 3690M
[02/17 22:45:19] d2.utils.events INFO:  eta: 1 day, 0:30:13  iter: 179  total_loss: 61.06  loss_ce: 0  loss_mask: 1.158  loss_dice: 4.665  loss_seg: 2.051  loss_ce_0: 0  loss_mask_0: 1.165  loss_dice_0: 4.626  loss_ce_1: 0  loss_mask_1: 1.196  loss_dice_1: 4.587  loss_ce_2: 0  loss_mask_2: 1.197  loss_dice_2: 4.585  loss_ce_3: 0  loss_mask_3: 1.211  loss_dice_3: 4.585  loss_ce_4: 0  loss_mask_4: 1.218  loss_dice_4: 4.59  loss_ce_5: 0  loss_mask_5: 1.215  loss_dice_5: 4.589  loss_ce_6: 0  loss_mask_6: 1.195  loss_dice_6: 4.607  loss_ce_7: 0  loss_mask_7: 1.196  loss_dice_7: 4.616  loss_ce_8: 0  loss_mask_8: 1.169  loss_dice_8: 4.627  time: 1.5874  data_time: 0.0256  lr: 9.9731e-05  max_mem: 3690M
[02/17 22:45:49] d2.utils.events INFO:  eta: 1 day, 0:38:15  iter: 199  total_loss: 60.61  loss_ce: 0  loss_mask: 1.112  loss_dice: 4.652  loss_seg: 2.263  loss_ce_0: 0  loss_mask_0: 1.155  loss_dice_0: 4.608  loss_ce_1: 0  loss_mask_1: 1.172  loss_dice_1: 4.589  loss_ce_2: 0  loss_mask_2: 1.182  loss_dice_2: 4.592  loss_ce_3: 0  loss_mask_3: 1.18  loss_dice_3: 4.59  loss_ce_4: 0  loss_mask_4: 1.168  loss_dice_4: 4.596  loss_ce_5: 0  loss_mask_5: 1.171  loss_dice_5: 4.599  loss_ce_6: 0  loss_mask_6: 1.155  loss_dice_6: 4.602  loss_ce_7: 0  loss_mask_7: 1.177  loss_dice_7: 4.607  loss_ce_8: 0  loss_mask_8: 1.147  loss_dice_8: 4.617  time: 1.5806  data_time: 0.0180  lr: 9.9701e-05  max_mem: 3690M
[02/17 22:46:20] d2.utils.events INFO:  eta: 1 day, 0:41:33  iter: 219  total_loss: 60.41  loss_ce: 0  loss_mask: 1.197  loss_dice: 4.613  loss_seg: 1.813  loss_ce_0: 0  loss_mask_0: 1.256  loss_dice_0: 4.562  loss_ce_1: 0  loss_mask_1: 1.289  loss_dice_1: 4.536  loss_ce_2: 0  loss_mask_2: 1.277  loss_dice_2: 4.527  loss_ce_3: 0  loss_mask_3: 1.267  loss_dice_3: 4.531  loss_ce_4: 0  loss_mask_4: 1.242  loss_dice_4: 4.542  loss_ce_5: 0  loss_mask_5: 1.238  loss_dice_5: 4.553  loss_ce_6: 0  loss_mask_6: 1.241  loss_dice_6: 4.544  loss_ce_7: 0  loss_mask_7: 1.26  loss_dice_7: 4.557  loss_ce_8: 0  loss_mask_8: 1.252  loss_dice_8: 4.562  time: 1.5768  data_time: 0.0178  lr: 9.9671e-05  max_mem: 3693M
[02/17 22:46:49] d2.utils.events INFO:  eta: 1 day, 0:37:16  iter: 239  total_loss: 60.63  loss_ce: 0  loss_mask: 1.192  loss_dice: 4.627  loss_seg: 2.043  loss_ce_0: 0  loss_mask_0: 1.242  loss_dice_0: 4.6  loss_ce_1: 0  loss_mask_1: 1.296  loss_dice_1: 4.582  loss_ce_2: 0  loss_mask_2: 1.29  loss_dice_2: 4.579  loss_ce_3: 0  loss_mask_3: 1.296  loss_dice_3: 4.582  loss_ce_4: 0  loss_mask_4: 1.278  loss_dice_4: 4.591  loss_ce_5: 0  loss_mask_5: 1.277  loss_dice_5: 4.594  loss_ce_6: 0  loss_mask_6: 1.275  loss_dice_6: 4.596  loss_ce_7: 0  loss_mask_7: 1.264  loss_dice_7: 4.596  loss_ce_8: 0  loss_mask_8: 1.238  loss_dice_8: 4.595  time: 1.5641  data_time: 0.0175  lr: 9.9641e-05  max_mem: 3693M
[02/17 22:46:51] d2.engine.hooks INFO: Overall training speed: 240 iterations in 0:06:14 (1.5617 s / it)
[02/17 22:46:51] d2.engine.hooks INFO: Total training time: 0:06:15 (0:00:01 on hooks)
[02/17 22:46:51] d2.utils.events INFO:  eta: 1 day, 0:32:19  iter: 242  total_loss: 60.85  loss_ce: 0  loss_mask: 1.185  loss_dice: 4.641  loss_seg: 2.189  loss_ce_0: 0  loss_mask_0: 1.226  loss_dice_0: 4.62  loss_ce_1: 0  loss_mask_1: 1.277  loss_dice_1: 4.595  loss_ce_2: 0  loss_mask_2: 1.275  loss_dice_2: 4.6  loss_ce_3: 0  loss_mask_3: 1.272  loss_dice_3: 4.599  loss_ce_4: 0  loss_mask_4: 1.262  loss_dice_4: 4.604  loss_ce_5: 0  loss_mask_5: 1.259  loss_dice_5: 4.607  loss_ce_6: 0  loss_mask_6: 1.257  loss_dice_6: 4.608  loss_ce_7: 0  loss_mask_7: 1.246  loss_dice_7: 4.616  loss_ce_8: 0  loss_mask_8: 1.231  loss_dice_8: 4.617  time: 1.5612  data_time: 0.0169  lr: 9.9638e-05  max_mem: 3693M
[02/17 22:47:28] detectron2 INFO: Rank of current process: 0. World size: 4
[02/17 22:47:32] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/17 22:47:32] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65510', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/17 22:47:32] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/17 22:47:32] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/17 22:47:32] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/config.yaml
[02/17 22:47:32] d2.utils.env INFO: Using a generated random seed 32443332
[02/17 22:47:36] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 5.0, 'loss_ce': 0.0, 'loss_dice': 5.0, 'loss_seg': 0.1, 'loss_mask_0': 5.0, 'loss_ce_0': 0.0, 'loss_dice_0': 5.0, 'loss_mask_1': 5.0, 'loss_ce_1': 0.0, 'loss_dice_1': 5.0, 'loss_mask_2': 5.0, 'loss_ce_2': 0.0, 'loss_dice_2': 5.0, 'loss_mask_3': 5.0, 'loss_ce_3': 0.0, 'loss_dice_3': 5.0, 'loss_mask_4': 5.0, 'loss_ce_4': 0.0, 'loss_dice_4': 5.0, 'loss_mask_5': 5.0, 'loss_ce_5': 0.0, 'loss_dice_5': 5.0, 'loss_mask_6': 5.0, 'loss_ce_6': 0.0, 'loss_dice_6': 5.0, 'loss_mask_7': 5.0, 'loss_ce_7': 0.0, 'loss_dice_7': 5.0, 'loss_mask_8': 5.0, 'loss_ce_8': 0.0, 'loss_dice_8': 5.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[02/17 22:47:36] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/17 22:47:41] d2.data.build INFO: Using training sampler TrainingSampler
[02/17 22:47:44] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/17 22:47:44] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/17 22:47:44] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/17 22:47:44] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/17 22:47:44] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/17 22:47:45] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[02/17 22:47:45] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/17 22:47:45] d2.engine.train_loop INFO: Starting training from iteration 0
[02/17 22:48:34] d2.engine.hooks INFO: Overall training speed: 15 iterations in 0:00:31 (2.1030 s / it)
[02/17 22:48:34] d2.engine.hooks INFO: Total training time: 0:00:31 (0:00:00 on hooks)
[02/17 22:48:34] d2.utils.events INFO:  eta: 1 day, 8:36:24  iter: 17  total_loss: 66.42  loss_ce: 0  loss_mask: 1.665  loss_dice: 4.815  loss_seg: 4.35  loss_ce_0: 0  loss_mask_0: 1.278  loss_dice_0: 4.77  loss_ce_1: 0  loss_mask_1: 1.221  loss_dice_1: 4.789  loss_ce_2: 0  loss_mask_2: 1.247  loss_dice_2: 4.777  loss_ce_3: 0  loss_mask_3: 1.363  loss_dice_3: 4.745  loss_ce_4: 0  loss_mask_4: 1.395  loss_dice_4: 4.745  loss_ce_5: 0  loss_mask_5: 1.457  loss_dice_5: 4.777  loss_ce_6: 0  loss_mask_6: 1.357  loss_dice_6: 4.779  loss_ce_7: 0  loss_mask_7: 1.301  loss_dice_7: 4.773  loss_ce_8: 0  loss_mask_8: 1.237  loss_dice_8: 4.786  time: 2.0720  data_time: 0.5872  lr: 9.9976e-05  max_mem: 5988M
[02/17 22:48:54] detectron2 INFO: Rank of current process: 0. World size: 4
[02/17 22:48:59] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/17 22:48:59] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65510', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/17 22:48:59] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/17 22:48:59] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/17 22:48:59] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/config.yaml
[02/17 22:49:00] d2.utils.env INFO: Using a generated random seed 173255
[02/17 22:49:03] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 5.0, 'loss_ce': 0.0, 'loss_dice': 5.0, 'loss_seg': 0.1, 'loss_mask_0': 5.0, 'loss_ce_0': 0.0, 'loss_dice_0': 5.0, 'loss_mask_1': 5.0, 'loss_ce_1': 0.0, 'loss_dice_1': 5.0, 'loss_mask_2': 5.0, 'loss_ce_2': 0.0, 'loss_dice_2': 5.0, 'loss_mask_3': 5.0, 'loss_ce_3': 0.0, 'loss_dice_3': 5.0, 'loss_mask_4': 5.0, 'loss_ce_4': 0.0, 'loss_dice_4': 5.0, 'loss_mask_5': 5.0, 'loss_ce_5': 0.0, 'loss_dice_5': 5.0, 'loss_mask_6': 5.0, 'loss_ce_6': 0.0, 'loss_dice_6': 5.0, 'loss_mask_7': 5.0, 'loss_ce_7': 0.0, 'loss_dice_7': 5.0, 'loss_mask_8': 5.0, 'loss_ce_8': 0.0, 'loss_dice_8': 5.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[02/17 22:49:04] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/17 22:49:09] d2.data.build INFO: Using training sampler TrainingSampler
[02/17 22:49:09] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/17 22:49:09] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/17 22:49:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/17 22:49:10] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/17 22:49:10] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/17 22:49:11] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[02/17 22:49:11] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/17 22:49:11] d2.engine.train_loop INFO: Starting training from iteration 0
[02/17 22:50:08] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0000019.pth
[02/17 22:50:09] d2.utils.events INFO:  eta: 1 day, 12:53:13  iter: 19  total_loss: 62.73  loss_ce: 0  loss_mask: 1.262  loss_dice: 4.787  loss_seg: 4.383  loss_ce_0: 0  loss_mask_0: 1.122  loss_dice_0: 4.768  loss_ce_1: 0  loss_mask_1: 1.131  loss_dice_1: 4.727  loss_ce_2: 0  loss_mask_2: 1.117  loss_dice_2: 4.748  loss_ce_3: 0  loss_mask_3: 1.127  loss_dice_3: 4.766  loss_ce_4: 0  loss_mask_4: 1.148  loss_dice_4: 4.757  loss_ce_5: 0  loss_mask_5: 1.112  loss_dice_5: 4.763  loss_ce_6: 0  loss_mask_6: 1.109  loss_dice_6: 4.756  loss_ce_7: 0  loss_mask_7: 1.111  loss_dice_7: 4.757  loss_ce_8: 0  loss_mask_8: 1.127  loss_dice_8: 4.76  time: 2.2592  data_time: 0.4735  lr: 9.9971e-05  max_mem: 5993M
[02/17 22:50:44] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0000039.pth
[02/17 22:50:45] d2.utils.events INFO:  eta: 1 day, 9:29:31  iter: 39  total_loss: 61.2  loss_ce: 0  loss_mask: 1.099  loss_dice: 4.792  loss_seg: 2.91  loss_ce_0: 0  loss_mask_0: 1.071  loss_dice_0: 4.756  loss_ce_1: 0  loss_mask_1: 1.083  loss_dice_1: 4.762  loss_ce_2: 0  loss_mask_2: 1.072  loss_dice_2: 4.764  loss_ce_3: 0  loss_mask_3: 1.075  loss_dice_3: 4.772  loss_ce_4: 0  loss_mask_4: 1.058  loss_dice_4: 4.78  loss_ce_5: 0  loss_mask_5: 1.061  loss_dice_5: 4.789  loss_ce_6: 0  loss_mask_6: 1.066  loss_dice_6: 4.78  loss_ce_7: 0  loss_mask_7: 1.033  loss_dice_7: 4.788  loss_ce_8: 0  loss_mask_8: 1.032  loss_dice_8: 4.797  time: 1.9708  data_time: 0.0319  lr: 9.9941e-05  max_mem: 5997M
[02/17 22:51:18] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0000059.pth
[02/17 22:51:20] d2.utils.events INFO:  eta: 1 day, 6:41:20  iter: 59  total_loss: 60.61  loss_ce: 0  loss_mask: 1.127  loss_dice: 4.791  loss_seg: 2.519  loss_ce_0: 0  loss_mask_0: 1.044  loss_dice_0: 4.72  loss_ce_1: 0  loss_mask_1: 1.097  loss_dice_1: 4.696  loss_ce_2: 0  loss_mask_2: 1.104  loss_dice_2: 4.711  loss_ce_3: 0  loss_mask_3: 1.076  loss_dice_3: 4.723  loss_ce_4: 0  loss_mask_4: 1.052  loss_dice_4: 4.736  loss_ce_5: 0  loss_mask_5: 1.018  loss_dice_5: 4.765  loss_ce_6: 0  loss_mask_6: 0.9945  loss_dice_6: 4.779  loss_ce_7: 0  loss_mask_7: 0.9821  loss_dice_7: 4.788  loss_ce_8: 0  loss_mask_8: 0.9752  loss_dice_8: 4.785  time: 1.8675  data_time: 0.0317  lr: 9.9911e-05  max_mem: 5997M
[02/17 22:51:53] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0000079.pth
[02/17 22:51:54] d2.utils.events INFO:  eta: 1 day, 5:22:30  iter: 79  total_loss: 60.54  loss_ce: 0  loss_mask: 1.11  loss_dice: 4.826  loss_seg: 2.414  loss_ce_0: 0  loss_mask_0: 1.079  loss_dice_0: 4.675  loss_ce_1: 0  loss_mask_1: 1.137  loss_dice_1: 4.646  loss_ce_2: 0  loss_mask_2: 1.128  loss_dice_2: 4.652  loss_ce_3: 0  loss_mask_3: 1.124  loss_dice_3: 4.658  loss_ce_4: 0  loss_mask_4: 1.123  loss_dice_4: 4.676  loss_ce_5: 0  loss_mask_5: 1.093  loss_dice_5: 4.706  loss_ce_6: 0  loss_mask_6: 1.062  loss_dice_6: 4.731  loss_ce_7: 0  loss_mask_7: 1.022  loss_dice_7: 4.76  loss_ce_8: 0  loss_mask_8: 0.9925  loss_dice_8: 4.776  time: 1.8114  data_time: 0.0231  lr: 9.9881e-05  max_mem: 5998M
[02/17 22:52:26] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0000099.pth
[02/17 22:52:27] d2.utils.events INFO:  eta: 1 day, 4:02:19  iter: 99  total_loss: 61.02  loss_ce: 0  loss_mask: 1.162  loss_dice: 4.787  loss_seg: 2.328  loss_ce_0: 0  loss_mask_0: 1.204  loss_dice_0: 4.609  loss_ce_1: 0  loss_mask_1: 1.275  loss_dice_1: 4.559  loss_ce_2: 0  loss_mask_2: 1.286  loss_dice_2: 4.566  loss_ce_3: 0  loss_mask_3: 1.305  loss_dice_3: 4.569  loss_ce_4: 0  loss_mask_4: 1.272  loss_dice_4: 4.572  loss_ce_5: 0  loss_mask_5: 1.258  loss_dice_5: 4.582  loss_ce_6: 0  loss_mask_6: 1.251  loss_dice_6: 4.6  loss_ce_7: 0  loss_mask_7: 1.213  loss_dice_7: 4.609  loss_ce_8: 0  loss_mask_8: 1.182  loss_dice_8: 4.65  time: 1.7666  data_time: 0.0282  lr: 9.9851e-05  max_mem: 6001M
[02/17 22:53:01] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0000119.pth
[02/17 22:53:02] d2.utils.events INFO:  eta: 1 day, 4:00:23  iter: 119  total_loss: 60.69  loss_ce: 0  loss_mask: 1.302  loss_dice: 4.653  loss_seg: 1.948  loss_ce_0: 0  loss_mask_0: 1.309  loss_dice_0: 4.568  loss_ce_1: 0  loss_mask_1: 1.321  loss_dice_1: 4.54  loss_ce_2: 0  loss_mask_2: 1.324  loss_dice_2: 4.53  loss_ce_3: 0  loss_mask_3: 1.321  loss_dice_3: 4.521  loss_ce_4: 0  loss_mask_4: 1.33  loss_dice_4: 4.52  loss_ce_5: 0  loss_mask_5: 1.337  loss_dice_5: 4.533  loss_ce_6: 0  loss_mask_6: 1.335  loss_dice_6: 4.545  loss_ce_7: 0  loss_mask_7: 1.334  loss_dice_7: 4.532  loss_ce_8: 0  loss_mask_8: 1.31  loss_dice_8: 4.564  time: 1.7508  data_time: 0.0298  lr: 9.9821e-05  max_mem: 6001M
[02/17 22:53:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0000139.pth
[02/17 22:53:39] d2.utils.events INFO:  eta: 1 day, 3:53:15  iter: 139  total_loss: 60.57  loss_ce: 0  loss_mask: 1.249  loss_dice: 4.621  loss_seg: 1.938  loss_ce_0: 0  loss_mask_0: 1.246  loss_dice_0: 4.574  loss_ce_1: 0  loss_mask_1: 1.291  loss_dice_1: 4.541  loss_ce_2: 0  loss_mask_2: 1.304  loss_dice_2: 4.527  loss_ce_3: 0  loss_mask_3: 1.296  loss_dice_3: 4.537  loss_ce_4: 0  loss_mask_4: 1.294  loss_dice_4: 4.538  loss_ce_5: 0  loss_mask_5: 1.287  loss_dice_5: 4.543  loss_ce_6: 0  loss_mask_6: 1.293  loss_dice_6: 4.553  loss_ce_7: 0  loss_mask_7: 1.277  loss_dice_7: 4.565  loss_ce_8: 0  loss_mask_8: 1.274  loss_dice_8: 4.572  time: 1.7538  data_time: 0.0380  lr: 9.9791e-05  max_mem: 6001M
[02/17 22:53:51] d2.engine.hooks INFO: Overall training speed: 146 iterations in 0:04:14 (1.7423 s / it)
[02/17 22:53:51] d2.engine.hooks INFO: Total training time: 0:04:23 (0:00:09 on hooks)
[02/17 22:53:51] d2.utils.events INFO:  eta: 1 day, 3:36:58  iter: 148  total_loss: 60.49  loss_ce: 0  loss_mask: 1.292  loss_dice: 4.621  loss_seg: 2.078  loss_ce_0: 0  loss_mask_0: 1.252  loss_dice_0: 4.574  loss_ce_1: 0  loss_mask_1: 1.295  loss_dice_1: 4.543  loss_ce_2: 0  loss_mask_2: 1.304  loss_dice_2: 4.527  loss_ce_3: 0  loss_mask_3: 1.306  loss_dice_3: 4.525  loss_ce_4: 0  loss_mask_4: 1.3  loss_dice_4: 4.536  loss_ce_5: 0  loss_mask_5: 1.297  loss_dice_5: 4.542  loss_ce_6: 0  loss_mask_6: 1.303  loss_dice_6: 4.552  loss_ce_7: 0  loss_mask_7: 1.29  loss_dice_7: 4.562  loss_ce_8: 0  loss_mask_8: 1.283  loss_dice_8: 4.573  time: 1.7413  data_time: 0.0398  lr: 9.9779e-05  max_mem: 6001M
[02/17 22:54:21] detectron2 INFO: Rank of current process: 0. World size: 4
[02/17 22:54:27] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/17 22:54:27] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65510', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/17 22:54:27] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/17 22:54:27] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/17 22:54:27] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/config.yaml
[02/17 22:54:27] d2.utils.env INFO: Using a generated random seed 27434859
[02/17 22:54:30] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 5.0, 'loss_ce': 0.0, 'loss_dice': 5.0, 'loss_seg': 0.1, 'loss_mask_0': 5.0, 'loss_ce_0': 0.0, 'loss_dice_0': 5.0, 'loss_mask_1': 5.0, 'loss_ce_1': 0.0, 'loss_dice_1': 5.0, 'loss_mask_2': 5.0, 'loss_ce_2': 0.0, 'loss_dice_2': 5.0, 'loss_mask_3': 5.0, 'loss_ce_3': 0.0, 'loss_dice_3': 5.0, 'loss_mask_4': 5.0, 'loss_ce_4': 0.0, 'loss_dice_4': 5.0, 'loss_mask_5': 5.0, 'loss_ce_5': 0.0, 'loss_dice_5': 5.0, 'loss_mask_6': 5.0, 'loss_ce_6': 0.0, 'loss_dice_6': 5.0, 'loss_mask_7': 5.0, 'loss_ce_7': 0.0, 'loss_dice_7': 5.0, 'loss_mask_8': 5.0, 'loss_ce_8': 0.0, 'loss_dice_8': 5.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[02/17 22:54:31] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/17 22:54:36] d2.data.build INFO: Using training sampler TrainingSampler
[02/17 22:54:36] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/17 22:54:36] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/17 22:54:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/17 22:54:36] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/17 22:54:37] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/17 22:54:38] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[02/17 22:54:38] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/17 22:54:38] d2.engine.train_loop INFO: Starting training from iteration 0
[02/17 22:55:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/17 22:55:34] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/17 22:55:34] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/17 22:55:47] mask2former INFO: Inference done 11/1093. Dataloading: 0.0046 s/iter. Inference: 0.2687 s/iter. Eval: 0.0433 s/iter. Total: 0.3166 s/iter. ETA=0:05:42
[02/17 22:55:52] mask2former INFO: Inference done 27/1093. Dataloading: 0.0066 s/iter. Inference: 0.2695 s/iter. Eval: 0.0505 s/iter. Total: 0.3268 s/iter. ETA=0:05:48
[02/17 22:55:57] mask2former INFO: Inference done 43/1093. Dataloading: 0.0068 s/iter. Inference: 0.2692 s/iter. Eval: 0.0507 s/iter. Total: 0.3269 s/iter. ETA=0:05:43
[02/17 22:56:02] mask2former INFO: Inference done 59/1093. Dataloading: 0.0068 s/iter. Inference: 0.2677 s/iter. Eval: 0.0507 s/iter. Total: 0.3253 s/iter. ETA=0:05:36
[02/17 22:56:08] mask2former INFO: Inference done 74/1093. Dataloading: 0.0072 s/iter. Inference: 0.2685 s/iter. Eval: 0.0526 s/iter. Total: 0.3284 s/iter. ETA=0:05:34
[02/17 22:56:13] mask2former INFO: Inference done 89/1093. Dataloading: 0.0073 s/iter. Inference: 0.2698 s/iter. Eval: 0.0523 s/iter. Total: 0.3296 s/iter. ETA=0:05:30
[02/17 22:56:18] mask2former INFO: Inference done 104/1093. Dataloading: 0.0075 s/iter. Inference: 0.2719 s/iter. Eval: 0.0528 s/iter. Total: 0.3324 s/iter. ETA=0:05:28
[02/17 22:56:23] mask2former INFO: Inference done 119/1093. Dataloading: 0.0076 s/iter. Inference: 0.2734 s/iter. Eval: 0.0533 s/iter. Total: 0.3344 s/iter. ETA=0:05:25
[02/17 22:56:28] mask2former INFO: Inference done 136/1093. Dataloading: 0.0075 s/iter. Inference: 0.2709 s/iter. Eval: 0.0524 s/iter. Total: 0.3310 s/iter. ETA=0:05:16
[02/17 22:56:30] d2.engine.hooks INFO: Overall training speed: 17 iterations in 0:00:38 (2.2679 s / it)
[02/17 22:56:30] d2.engine.hooks INFO: Total training time: 0:01:35 (0:00:57 on hooks)
[02/17 22:56:30] d2.utils.events INFO:  eta: 1 day, 11:26:17  iter: 19  total_loss: 65.67  loss_ce: 0  loss_mask: 1.22  loss_dice: 4.75  loss_seg: 5.801  loss_ce_0: 0  loss_mask_0: 1.182  loss_dice_0: 4.789  loss_ce_1: 0  loss_mask_1: 1.102  loss_dice_1: 4.768  loss_ce_2: 0  loss_mask_2: 1.095  loss_dice_2: 4.789  loss_ce_3: 0  loss_mask_3: 1.099  loss_dice_3: 4.774  loss_ce_4: 0  loss_mask_4: 1.092  loss_dice_4: 4.796  loss_ce_5: 0  loss_mask_5: 1.061  loss_dice_5: 4.783  loss_ce_6: 0  loss_mask_6: 1.095  loss_dice_6: 4.769  loss_ce_7: 0  loss_mask_7: 1.09  loss_dice_7: 4.777  loss_ce_8: 0  loss_mask_8: 1.096  loss_dice_8: 4.779  time: 2.1418  data_time: 0.4862  lr: 9.9971e-05  max_mem: 5991M
[02/17 22:56:58] detectron2 INFO: Rank of current process: 0. World size: 4
[02/17 22:57:02] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/17 22:57:02] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65510', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/17 22:57:03] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/17 22:57:03] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/17 22:57:03] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/config.yaml
[02/17 22:57:03] d2.utils.env INFO: Using a generated random seed 3267478
[02/17 22:57:09] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 5.0, 'loss_ce': 0.0, 'loss_dice': 5.0, 'loss_seg': 0.1, 'loss_mask_0': 5.0, 'loss_ce_0': 0.0, 'loss_dice_0': 5.0, 'loss_mask_1': 5.0, 'loss_ce_1': 0.0, 'loss_dice_1': 5.0, 'loss_mask_2': 5.0, 'loss_ce_2': 0.0, 'loss_dice_2': 5.0, 'loss_mask_3': 5.0, 'loss_ce_3': 0.0, 'loss_dice_3': 5.0, 'loss_mask_4': 5.0, 'loss_ce_4': 0.0, 'loss_dice_4': 5.0, 'loss_mask_5': 5.0, 'loss_ce_5': 0.0, 'loss_dice_5': 5.0, 'loss_mask_6': 5.0, 'loss_ce_6': 0.0, 'loss_dice_6': 5.0, 'loss_mask_7': 5.0, 'loss_ce_7': 0.0, 'loss_dice_7': 5.0, 'loss_mask_8': 5.0, 'loss_ce_8': 0.0, 'loss_dice_8': 5.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[02/17 22:57:09] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/17 22:57:14] d2.data.build INFO: Using training sampler TrainingSampler
[02/17 22:57:14] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/17 22:57:15] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/17 22:57:15] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/17 22:57:15] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/17 22:57:15] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/17 22:57:16] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[02/17 22:57:16] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/17 22:57:16] d2.engine.train_loop INFO: Starting training from iteration 0
[02/17 22:58:08] d2.engine.hooks INFO: Overall training speed: 15 iterations in 0:00:33 (2.2650 s / it)
[02/17 22:58:08] d2.engine.hooks INFO: Total training time: 0:00:33 (0:00:00 on hooks)
[02/17 22:58:08] d2.utils.events INFO:  eta: 1 day, 9:54:58  iter: 17  total_loss: 69.16  loss_ce: 0  loss_mask: 2.298  loss_dice: 4.782  loss_seg: 5.76  loss_ce_0: 0  loss_mask_0: 1.317  loss_dice_0: 4.752  loss_ce_1: 0  loss_mask_1: 1.27  loss_dice_1: 4.718  loss_ce_2: 0  loss_mask_2: 1.271  loss_dice_2: 4.721  loss_ce_3: 0  loss_mask_3: 1.373  loss_dice_3: 4.727  loss_ce_4: 0  loss_mask_4: 1.509  loss_dice_4: 4.702  loss_ce_5: 0  loss_mask_5: 1.403  loss_dice_5: 4.718  loss_ce_6: 0  loss_mask_6: 1.461  loss_dice_6: 4.714  loss_ce_7: 0  loss_mask_7: 1.409  loss_dice_7: 4.696  loss_ce_8: 0  loss_mask_8: 1.39  loss_dice_8: 4.716  time: 2.1272  data_time: 0.5833  lr: 9.9976e-05  max_mem: 5989M
[02/17 23:05:11] detectron2 INFO: Rank of current process: 0. World size: 4
[02/17 23:05:17] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/17 23:05:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65510', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/17 23:05:17] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/17 23:05:17] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/17 23:05:17] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/config.yaml
[02/17 23:05:17] d2.utils.env INFO: Using a generated random seed 17504347
[02/17 23:05:21] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 5.0, 'loss_ce': 0.0, 'loss_dice': 5.0, 'loss_seg': 0.1, 'loss_mask_0': 5.0, 'loss_ce_0': 0.0, 'loss_dice_0': 5.0, 'loss_mask_1': 5.0, 'loss_ce_1': 0.0, 'loss_dice_1': 5.0, 'loss_mask_2': 5.0, 'loss_ce_2': 0.0, 'loss_dice_2': 5.0, 'loss_mask_3': 5.0, 'loss_ce_3': 0.0, 'loss_dice_3': 5.0, 'loss_mask_4': 5.0, 'loss_ce_4': 0.0, 'loss_dice_4': 5.0, 'loss_mask_5': 5.0, 'loss_ce_5': 0.0, 'loss_dice_5': 5.0, 'loss_mask_6': 5.0, 'loss_ce_6': 0.0, 'loss_dice_6': 5.0, 'loss_mask_7': 5.0, 'loss_ce_7': 0.0, 'loss_dice_7': 5.0, 'loss_mask_8': 5.0, 'loss_ce_8': 0.0, 'loss_dice_8': 5.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[02/17 23:05:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/17 23:05:27] d2.data.build INFO: Using training sampler TrainingSampler
[02/17 23:05:27] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/17 23:05:27] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/17 23:05:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/17 23:05:27] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/17 23:05:28] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/17 23:05:29] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mupsampler.conv2d.{bias, weight}[0m
[02/17 23:05:29] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/17 23:05:29] d2.engine.train_loop INFO: Starting training from iteration 0
[02/17 23:06:25] d2.utils.events INFO:  eta: 1 day, 12:04:25  iter: 19  total_loss: 63.32  loss_ce: 0  loss_mask: 1.265  loss_dice: 4.832  loss_seg: 4.632  loss_ce_0: 0  loss_mask_0: 1.087  loss_dice_0: 4.768  loss_ce_1: 0  loss_mask_1: 1.089  loss_dice_1: 4.76  loss_ce_2: 0  loss_mask_2: 1.126  loss_dice_2: 4.766  loss_ce_3: 0  loss_mask_3: 1.136  loss_dice_3: 4.765  loss_ce_4: 0  loss_mask_4: 1.154  loss_dice_4: 4.768  loss_ce_5: 0  loss_mask_5: 1.157  loss_dice_5: 4.755  loss_ce_6: 0  loss_mask_6: 1.126  loss_dice_6: 4.778  loss_ce_7: 0  loss_mask_7: 1.15  loss_dice_7: 4.773  loss_ce_8: 0  loss_mask_8: 1.095  loss_dice_8: 4.768  time: 2.1852  data_time: 0.5118  lr: 9.9971e-05  max_mem: 5990M
[02/17 23:07:01] d2.utils.events INFO:  eta: 1 day, 9:37:56  iter: 39  total_loss: 61.21  loss_ce: 0  loss_mask: 1.054  loss_dice: 4.781  loss_seg: 3.032  loss_ce_0: 0  loss_mask_0: 1.076  loss_dice_0: 4.733  loss_ce_1: 0  loss_mask_1: 1.085  loss_dice_1: 4.738  loss_ce_2: 0  loss_mask_2: 1.055  loss_dice_2: 4.753  loss_ce_3: 0  loss_mask_3: 1.04  loss_dice_3: 4.77  loss_ce_4: 0  loss_mask_4: 1.035  loss_dice_4: 4.775  loss_ce_5: 0  loss_mask_5: 1.022  loss_dice_5: 4.776  loss_ce_6: 0  loss_mask_6: 1.03  loss_dice_6: 4.769  loss_ce_7: 0  loss_mask_7: 1.031  loss_dice_7: 4.761  loss_ce_8: 0  loss_mask_8: 1.027  loss_dice_8: 4.769  time: 1.9669  data_time: 0.0320  lr: 9.9941e-05  max_mem: 5990M
[02/17 23:07:33] d2.utils.events INFO:  eta: 1 day, 5:34:52  iter: 59  total_loss: 61.21  loss_ce: 0  loss_mask: 1.049  loss_dice: 4.794  loss_seg: 2.953  loss_ce_0: 0  loss_mask_0: 1.124  loss_dice_0: 4.702  loss_ce_1: 0  loss_mask_1: 1.167  loss_dice_1: 4.695  loss_ce_2: 0  loss_mask_2: 1.134  loss_dice_2: 4.702  loss_ce_3: 0  loss_mask_3: 1.098  loss_dice_3: 4.723  loss_ce_4: 0  loss_mask_4: 1.079  loss_dice_4: 4.744  loss_ce_5: 0  loss_mask_5: 1.082  loss_dice_5: 4.761  loss_ce_6: 0  loss_mask_6: 1.061  loss_dice_6: 4.771  loss_ce_7: 0  loss_mask_7: 1.056  loss_dice_7: 4.775  loss_ce_8: 0  loss_mask_8: 1.043  loss_dice_8: 4.782  time: 1.8399  data_time: 0.0304  lr: 9.9911e-05  max_mem: 5990M
[02/17 23:07:46] d2.utils.events INFO:  eta: 1 day, 2:38:59  iter: 79  total_loss: 61.45  loss_ce: 0  loss_mask: 0.9941  loss_dice: 4.826  loss_seg: 3.521  loss_ce_0: 0  loss_mask_0: 1.075  loss_dice_0: 4.697  loss_ce_1: 0  loss_mask_1: 1.105  loss_dice_1: 4.665  loss_ce_2: 0  loss_mask_2: 1.111  loss_dice_2: 4.683  loss_ce_3: 0  loss_mask_3: 1.1  loss_dice_3: 4.693  loss_ce_4: 0  loss_mask_4: 1.046  loss_dice_4: 4.713  loss_ce_5: 0  loss_mask_5: 1.031  loss_dice_5: 4.721  loss_ce_6: 0  loss_mask_6: 1.025  loss_dice_6: 4.74  loss_ce_7: 0  loss_mask_7: 0.997  loss_dice_7: 4.769  loss_ce_8: 0  loss_mask_8: 0.9901  loss_dice_8: 4.785  time: 1.5407  data_time: 0.0256  lr: 9.9881e-05  max_mem: 5992M
[02/17 23:07:58] d2.utils.events INFO:  eta: 23:38:37  iter: 99  total_loss: 61.08  loss_ce: 0  loss_mask: 1.13  loss_dice: 4.732  loss_seg: 2.573  loss_ce_0: 0  loss_mask_0: 1.254  loss_dice_0: 4.614  loss_ce_1: 0  loss_mask_1: 1.319  loss_dice_1: 4.576  loss_ce_2: 0  loss_mask_2: 1.303  loss_dice_2: 4.585  loss_ce_3: 0  loss_mask_3: 1.291  loss_dice_3: 4.59  loss_ce_4: 0  loss_mask_4: 1.274  loss_dice_4: 4.6  loss_ce_5: 0  loss_mask_5: 1.227  loss_dice_5: 4.634  loss_ce_6: 0  loss_mask_6: 1.2  loss_dice_6: 4.655  loss_ce_7: 0  loss_mask_7: 1.183  loss_dice_7: 4.664  loss_ce_8: 0  loss_mask_8: 1.155  loss_dice_8: 4.698  time: 1.3489  data_time: 0.0223  lr: 9.9851e-05  max_mem: 5993M
[02/17 23:08:11] d2.utils.events INFO:  eta: 16:36:21  iter: 119  total_loss: 60.6  loss_ce: 0  loss_mask: 1.137  loss_dice: 4.695  loss_seg: 2.389  loss_ce_0: 0  loss_mask_0: 1.179  loss_dice_0: 4.61  loss_ce_1: 0  loss_mask_1: 1.221  loss_dice_1: 4.581  loss_ce_2: 0  loss_mask_2: 1.215  loss_dice_2: 4.586  loss_ce_3: 0  loss_mask_3: 1.213  loss_dice_3: 4.59  loss_ce_4: 0  loss_mask_4: 1.204  loss_dice_4: 4.614  loss_ce_5: 0  loss_mask_5: 1.204  loss_dice_5: 4.605  loss_ce_6: 0  loss_mask_6: 1.201  loss_dice_6: 4.613  loss_ce_7: 0  loss_mask_7: 1.2  loss_dice_7: 4.609  loss_ce_8: 0  loss_mask_8: 1.139  loss_dice_8: 4.647  time: 1.2253  data_time: 0.0287  lr: 9.9821e-05  max_mem: 5995M
[02/17 23:08:23] d2.utils.events INFO:  eta: 11:14:41  iter: 139  total_loss: 60.99  loss_ce: 0  loss_mask: 1.189  loss_dice: 4.643  loss_seg: 2.837  loss_ce_0: 0  loss_mask_0: 1.237  loss_dice_0: 4.576  loss_ce_1: 0  loss_mask_1: 1.278  loss_dice_1: 4.554  loss_ce_2: 0  loss_mask_2: 1.28  loss_dice_2: 4.55  loss_ce_3: 0  loss_mask_3: 1.286  loss_dice_3: 4.558  loss_ce_4: 0  loss_mask_4: 1.259  loss_dice_4: 4.572  loss_ce_5: 0  loss_mask_5: 1.261  loss_dice_5: 4.578  loss_ce_6: 0  loss_mask_6: 1.268  loss_dice_6: 4.579  loss_ce_7: 0  loss_mask_7: 1.262  loss_dice_7: 4.586  loss_ce_8: 0  loss_mask_8: 1.24  loss_dice_8: 4.595  time: 1.1386  data_time: 0.0211  lr: 9.9791e-05  max_mem: 5995M
[02/17 23:08:37] d2.utils.events INFO:  eta: 11:15:06  iter: 159  total_loss: 61.07  loss_ce: 0  loss_mask: 1.234  loss_dice: 4.603  loss_seg: 2.493  loss_ce_0: 0  loss_mask_0: 1.284  loss_dice_0: 4.551  loss_ce_1: 0  loss_mask_1: 1.298  loss_dice_1: 4.536  loss_ce_2: 0  loss_mask_2: 1.32  loss_dice_2: 4.548  loss_ce_3: 0  loss_mask_3: 1.311  loss_dice_3: 4.551  loss_ce_4: 0  loss_mask_4: 1.3  loss_dice_4: 4.55  loss_ce_5: 0  loss_mask_5: 1.29  loss_dice_5: 4.545  loss_ce_6: 0  loss_mask_6: 1.301  loss_dice_6: 4.551  loss_ce_7: 0  loss_mask_7: 1.295  loss_dice_7: 4.557  loss_ce_8: 0  loss_mask_8: 1.276  loss_dice_8: 4.569  time: 1.0794  data_time: 0.0367  lr: 9.9761e-05  max_mem: 5995M
[02/17 23:08:50] d2.utils.events INFO:  eta: 11:13:01  iter: 179  total_loss: 60.63  loss_ce: 0  loss_mask: 1.296  loss_dice: 4.548  loss_seg: 2.312  loss_ce_0: 0  loss_mask_0: 1.311  loss_dice_0: 4.524  loss_ce_1: 0  loss_mask_1: 1.339  loss_dice_1: 4.497  loss_ce_2: 0  loss_mask_2: 1.338  loss_dice_2: 4.49  loss_ce_3: 0  loss_mask_3: 1.346  loss_dice_3: 4.489  loss_ce_4: 0  loss_mask_4: 1.347  loss_dice_4: 4.501  loss_ce_5: 0  loss_mask_5: 1.334  loss_dice_5: 4.497  loss_ce_6: 0  loss_mask_6: 1.351  loss_dice_6: 4.502  loss_ce_7: 0  loss_mask_7: 1.36  loss_dice_7: 4.513  loss_ce_8: 0  loss_mask_8: 1.351  loss_dice_8: 4.523  time: 1.0327  data_time: 0.0302  lr: 9.9731e-05  max_mem: 5995M
[02/17 23:09:08] d2.utils.events INFO:  eta: 11:14:39  iter: 199  total_loss: 60.4  loss_ce: 0  loss_mask: 1.37  loss_dice: 4.512  loss_seg: 2.352  loss_ce_0: 0  loss_mask_0: 1.298  loss_dice_0: 4.514  loss_ce_1: 0  loss_mask_1: 1.332  loss_dice_1: 4.49  loss_ce_2: 0  loss_mask_2: 1.353  loss_dice_2: 4.476  loss_ce_3: 0  loss_mask_3: 1.343  loss_dice_3: 4.491  loss_ce_4: 0  loss_mask_4: 1.345  loss_dice_4: 4.495  loss_ce_5: 0  loss_mask_5: 1.345  loss_dice_5: 4.509  loss_ce_6: 0  loss_mask_6: 1.361  loss_dice_6: 4.503  loss_ce_7: 0  loss_mask_7: 1.343  loss_dice_7: 4.51  loss_ce_8: 0  loss_mask_8: 1.341  loss_dice_8: 4.508  time: 1.0159  data_time: 0.0325  lr: 9.9701e-05  max_mem: 5999M
[02/17 23:09:34] d2.utils.events INFO:  eta: 11:34:26  iter: 219  total_loss: 59.75  loss_ce: 0  loss_mask: 1.297  loss_dice: 4.467  loss_seg: 1.916  loss_ce_0: 0  loss_mask_0: 1.288  loss_dice_0: 4.483  loss_ce_1: 0  loss_mask_1: 1.319  loss_dice_1: 4.447  loss_ce_2: 0  loss_mask_2: 1.322  loss_dice_2: 4.458  loss_ce_3: 0  loss_mask_3: 1.328  loss_dice_3: 4.45  loss_ce_4: 0  loss_mask_4: 1.332  loss_dice_4: 4.457  loss_ce_5: 0  loss_mask_5: 1.335  loss_dice_5: 4.468  loss_ce_6: 0  loss_mask_6: 1.339  loss_dice_6: 4.464  loss_ce_7: 0  loss_mask_7: 1.332  loss_dice_7: 4.467  loss_ce_8: 0  loss_mask_8: 1.327  loss_dice_8: 4.464  time: 1.0411  data_time: 0.0254  lr: 9.9671e-05  max_mem: 5999M
[02/17 23:10:05] d2.utils.events INFO:  eta: 12:09:19  iter: 239  total_loss: 59.81  loss_ce: 0  loss_mask: 1.304  loss_dice: 4.502  loss_seg: 1.944  loss_ce_0: 0  loss_mask_0: 1.295  loss_dice_0: 4.505  loss_ce_1: 0  loss_mask_1: 1.326  loss_dice_1: 4.484  loss_ce_2: 0  loss_mask_2: 1.322  loss_dice_2: 4.474  loss_ce_3: 0  loss_mask_3: 1.322  loss_dice_3: 4.482  loss_ce_4: 0  loss_mask_4: 1.32  loss_dice_4: 4.484  loss_ce_5: 0  loss_mask_5: 1.309  loss_dice_5: 4.484  loss_ce_6: 0  loss_mask_6: 1.312  loss_dice_6: 4.491  loss_ce_7: 0  loss_mask_7: 1.317  loss_dice_7: 4.499  loss_ce_8: 0  loss_mask_8: 1.317  loss_dice_8: 4.496  time: 1.0827  data_time: 0.0331  lr: 9.9641e-05  max_mem: 5999M
[02/17 23:10:36] d2.utils.events INFO:  eta: 12:50:01  iter: 259  total_loss: 60.02  loss_ce: 0  loss_mask: 1.313  loss_dice: 4.501  loss_seg: 1.858  loss_ce_0: 0  loss_mask_0: 1.31  loss_dice_0: 4.494  loss_ce_1: 0  loss_mask_1: 1.334  loss_dice_1: 4.463  loss_ce_2: 0  loss_mask_2: 1.329  loss_dice_2: 4.468  loss_ce_3: 0  loss_mask_3: 1.324  loss_dice_3: 4.476  loss_ce_4: 0  loss_mask_4: 1.337  loss_dice_4: 4.481  loss_ce_5: 0  loss_mask_5: 1.328  loss_dice_5: 4.488  loss_ce_6: 0  loss_mask_6: 1.321  loss_dice_6: 4.488  loss_ce_7: 0  loss_mask_7: 1.33  loss_dice_7: 4.487  loss_ce_8: 0  loss_mask_8: 1.329  loss_dice_8: 4.489  time: 1.1214  data_time: 0.0312  lr: 9.9611e-05  max_mem: 5999M
[02/17 23:11:08] d2.utils.events INFO:  eta: 15:12:45  iter: 279  total_loss: 60.08  loss_ce: 0  loss_mask: 1.364  loss_dice: 4.457  loss_seg: 2.084  loss_ce_0: 0  loss_mask_0: 1.378  loss_dice_0: 4.432  loss_ce_1: 0  loss_mask_1: 1.401  loss_dice_1: 4.411  loss_ce_2: 0  loss_mask_2: 1.39  loss_dice_2: 4.402  loss_ce_3: 0  loss_mask_3: 1.391  loss_dice_3: 4.406  loss_ce_4: 0  loss_mask_4: 1.393  loss_dice_4: 4.419  loss_ce_5: 0  loss_mask_5: 1.399  loss_dice_5: 4.409  loss_ce_6: 0  loss_mask_6: 1.392  loss_dice_6: 4.414  loss_ce_7: 0  loss_mask_7: 1.38  loss_dice_7: 4.426  loss_ce_8: 0  loss_mask_8: 1.388  loss_dice_8: 4.428  time: 1.1552  data_time: 0.0334  lr: 9.9581e-05  max_mem: 5999M
[02/17 23:11:43] d2.utils.events INFO:  eta: 20:53:54  iter: 299  total_loss: 59.98  loss_ce: 0  loss_mask: 1.339  loss_dice: 4.476  loss_seg: 1.952  loss_ce_0: 0  loss_mask_0: 1.309  loss_dice_0: 4.474  loss_ce_1: 0  loss_mask_1: 1.342  loss_dice_1: 4.437  loss_ce_2: 0  loss_mask_2: 1.351  loss_dice_2: 4.437  loss_ce_3: 0  loss_mask_3: 1.348  loss_dice_3: 4.429  loss_ce_4: 0  loss_mask_4: 1.351  loss_dice_4: 4.437  loss_ce_5: 0  loss_mask_5: 1.345  loss_dice_5: 4.442  loss_ce_6: 0  loss_mask_6: 1.34  loss_dice_6: 4.456  loss_ce_7: 0  loss_mask_7: 1.346  loss_dice_7: 4.451  loss_ce_8: 0  loss_mask_8: 1.34  loss_dice_8: 4.457  time: 1.1958  data_time: 0.0319  lr: 9.9551e-05  max_mem: 5999M
[02/17 23:12:17] d2.utils.events INFO:  eta: 21:43:37  iter: 319  total_loss: 60.13  loss_ce: 0  loss_mask: 1.383  loss_dice: 4.437  loss_seg: 1.978  loss_ce_0: 0  loss_mask_0: 1.389  loss_dice_0: 4.419  loss_ce_1: 0  loss_mask_1: 1.425  loss_dice_1: 4.386  loss_ce_2: 0  loss_mask_2: 1.418  loss_dice_2: 4.379  loss_ce_3: 0  loss_mask_3: 1.419  loss_dice_3: 4.38  loss_ce_4: 0  loss_mask_4: 1.408  loss_dice_4: 4.4  loss_ce_5: 0  loss_mask_5: 1.41  loss_dice_5: 4.392  loss_ce_6: 0  loss_mask_6: 1.418  loss_dice_6: 4.403  loss_ce_7: 0  loss_mask_7: 1.416  loss_dice_7: 4.402  loss_ce_8: 0  loss_mask_8: 1.401  loss_dice_8: 4.426  time: 1.2273  data_time: 0.0323  lr: 9.9521e-05  max_mem: 5999M
[02/17 23:12:50] d2.utils.events INFO:  eta: 22:35:41  iter: 339  total_loss: 59.28  loss_ce: 0  loss_mask: 1.405  loss_dice: 4.378  loss_seg: 1.549  loss_ce_0: 0  loss_mask_0: 1.394  loss_dice_0: 4.398  loss_ce_1: 0  loss_mask_1: 1.409  loss_dice_1: 4.359  loss_ce_2: 0  loss_mask_2: 1.405  loss_dice_2: 4.353  loss_ce_3: 0  loss_mask_3: 1.396  loss_dice_3: 4.361  loss_ce_4: 0  loss_mask_4: 1.396  loss_dice_4: 4.35  loss_ce_5: 0  loss_mask_5: 1.392  loss_dice_5: 4.364  loss_ce_6: 0  loss_mask_6: 1.403  loss_dice_6: 4.365  loss_ce_7: 0  loss_mask_7: 1.404  loss_dice_7: 4.37  loss_ce_8: 0  loss_mask_8: 1.404  loss_dice_8: 4.377  time: 1.2516  data_time: 0.0335  lr: 9.9491e-05  max_mem: 5999M
[02/17 23:13:25] d2.utils.events INFO:  eta: 23:00:29  iter: 359  total_loss: 59.86  loss_ce: 0  loss_mask: 1.376  loss_dice: 4.423  loss_seg: 1.669  loss_ce_0: 0  loss_mask_0: 1.379  loss_dice_0: 4.411  loss_ce_1: 0  loss_mask_1: 1.406  loss_dice_1: 4.398  loss_ce_2: 0  loss_mask_2: 1.415  loss_dice_2: 4.396  loss_ce_3: 0  loss_mask_3: 1.401  loss_dice_3: 4.4  loss_ce_4: 0  loss_mask_4: 1.4  loss_dice_4: 4.408  loss_ce_5: 0  loss_mask_5: 1.41  loss_dice_5: 4.402  loss_ce_6: 0  loss_mask_6: 1.404  loss_dice_6: 4.409  loss_ce_7: 0  loss_mask_7: 1.392  loss_dice_7: 4.406  loss_ce_8: 0  loss_mask_8: 1.39  loss_dice_8: 4.399  time: 1.2792  data_time: 0.0303  lr: 9.9461e-05  max_mem: 5999M
[02/17 23:13:58] d2.utils.events INFO:  eta: 23:23:47  iter: 379  total_loss: 59.38  loss_ce: 0  loss_mask: 1.373  loss_dice: 4.36  loss_seg: 1.586  loss_ce_0: 0  loss_mask_0: 1.361  loss_dice_0: 4.372  loss_ce_1: 0  loss_mask_1: 1.383  loss_dice_1: 4.327  loss_ce_2: 0  loss_mask_2: 1.38  loss_dice_2: 4.33  loss_ce_3: 0  loss_mask_3: 1.379  loss_dice_3: 4.333  loss_ce_4: 0  loss_mask_4: 1.384  loss_dice_4: 4.334  loss_ce_5: 0  loss_mask_5: 1.387  loss_dice_5: 4.34  loss_ce_6: 0  loss_mask_6: 1.386  loss_dice_6: 4.335  loss_ce_7: 0  loss_mask_7: 1.386  loss_dice_7: 4.343  loss_ce_8: 0  loss_mask_8: 1.381  loss_dice_8: 4.343  time: 1.2986  data_time: 0.0328  lr: 9.9431e-05  max_mem: 5999M
[02/17 23:14:31] d2.utils.events INFO:  eta: 23:34:57  iter: 399  total_loss: 59.42  loss_ce: 0  loss_mask: 1.316  loss_dice: 4.431  loss_seg: 1.884  loss_ce_0: 0  loss_mask_0: 1.326  loss_dice_0: 4.424  loss_ce_1: 0  loss_mask_1: 1.373  loss_dice_1: 4.393  loss_ce_2: 0  loss_mask_2: 1.371  loss_dice_2: 4.396  loss_ce_3: 0  loss_mask_3: 1.375  loss_dice_3: 4.394  loss_ce_4: 0  loss_mask_4: 1.366  loss_dice_4: 4.402  loss_ce_5: 0  loss_mask_5: 1.371  loss_dice_5: 4.404  loss_ce_6: 0  loss_mask_6: 1.357  loss_dice_6: 4.419  loss_ce_7: 0  loss_mask_7: 1.351  loss_dice_7: 4.434  loss_ce_8: 0  loss_mask_8: 1.341  loss_dice_8: 4.419  time: 1.3148  data_time: 0.0301  lr: 9.9401e-05  max_mem: 5999M
[02/17 23:15:04] d2.utils.events INFO:  eta: 23:48:23  iter: 419  total_loss: 59.38  loss_ce: 0  loss_mask: 1.343  loss_dice: 4.395  loss_seg: 1.747  loss_ce_0: 0  loss_mask_0: 1.325  loss_dice_0: 4.385  loss_ce_1: 0  loss_mask_1: 1.349  loss_dice_1: 4.357  loss_ce_2: 0  loss_mask_2: 1.356  loss_dice_2: 4.357  loss_ce_3: 0  loss_mask_3: 1.364  loss_dice_3: 4.355  loss_ce_4: 0  loss_mask_4: 1.374  loss_dice_4: 4.367  loss_ce_5: 0  loss_mask_5: 1.371  loss_dice_5: 4.367  loss_ce_6: 0  loss_mask_6: 1.361  loss_dice_6: 4.367  loss_ce_7: 0  loss_mask_7: 1.364  loss_dice_7: 4.37  loss_ce_8: 0  loss_mask_8: 1.349  loss_dice_8: 4.379  time: 1.3302  data_time: 0.0383  lr: 9.9371e-05  max_mem: 5999M
[02/17 23:15:35] d2.utils.events INFO:  eta: 23:58:45  iter: 439  total_loss: 59.07  loss_ce: 0  loss_mask: 1.389  loss_dice: 4.358  loss_seg: 1.741  loss_ce_0: 0  loss_mask_0: 1.353  loss_dice_0: 4.375  loss_ce_1: 0  loss_mask_1: 1.392  loss_dice_1: 4.332  loss_ce_2: 0  loss_mask_2: 1.387  loss_dice_2: 4.324  loss_ce_3: 0  loss_mask_3: 1.386  loss_dice_3: 4.33  loss_ce_4: 0  loss_mask_4: 1.395  loss_dice_4: 4.332  loss_ce_5: 0  loss_mask_5: 1.398  loss_dice_5: 4.337  loss_ce_6: 0  loss_mask_6: 1.39  loss_dice_6: 4.341  loss_ce_7: 0  loss_mask_7: 1.389  loss_dice_7: 4.34  loss_ce_8: 0  loss_mask_8: 1.388  loss_dice_8: 4.344  time: 1.3402  data_time: 0.0340  lr: 9.9341e-05  max_mem: 5999M
[02/17 23:16:08] d2.utils.events INFO:  eta: 1 day, 0:10:35  iter: 459  total_loss: 59.16  loss_ce: 0  loss_mask: 1.397  loss_dice: 4.345  loss_seg: 1.697  loss_ce_0: 0  loss_mask_0: 1.398  loss_dice_0: 4.354  loss_ce_1: 0  loss_mask_1: 1.418  loss_dice_1: 4.316  loss_ce_2: 0  loss_mask_2: 1.411  loss_dice_2: 4.312  loss_ce_3: 0  loss_mask_3: 1.412  loss_dice_3: 4.321  loss_ce_4: 0  loss_mask_4: 1.403  loss_dice_4: 4.333  loss_ce_5: 0  loss_mask_5: 1.407  loss_dice_5: 4.335  loss_ce_6: 0  loss_mask_6: 1.391  loss_dice_6: 4.332  loss_ce_7: 0  loss_mask_7: 1.4  loss_dice_7: 4.331  loss_ce_8: 0  loss_mask_8: 1.399  loss_dice_8: 4.328  time: 1.3535  data_time: 0.0326  lr: 9.9311e-05  max_mem: 5999M
[02/17 23:16:41] d2.utils.events INFO:  eta: 1 day, 0:30:07  iter: 479  total_loss: 59.01  loss_ce: 0  loss_mask: 1.487  loss_dice: 4.278  loss_seg: 1.508  loss_ce_0: 0  loss_mask_0: 1.487  loss_dice_0: 4.276  loss_ce_1: 0  loss_mask_1: 1.491  loss_dice_1: 4.236  loss_ce_2: 0  loss_mask_2: 1.49  loss_dice_2: 4.243  loss_ce_3: 0  loss_mask_3: 1.494  loss_dice_3: 4.245  loss_ce_4: 0  loss_mask_4: 1.497  loss_dice_4: 4.241  loss_ce_5: 0  loss_mask_5: 1.49  loss_dice_5: 4.252  loss_ce_6: 0  loss_mask_6: 1.489  loss_dice_6: 4.254  loss_ce_7: 0  loss_mask_7: 1.486  loss_dice_7: 4.245  loss_ce_8: 0  loss_mask_8: 1.475  loss_dice_8: 4.253  time: 1.3662  data_time: 0.0305  lr: 9.9281e-05  max_mem: 5999M
[02/17 23:17:15] d2.utils.events INFO:  eta: 1 day, 0:33:27  iter: 499  total_loss: 59.03  loss_ce: 0  loss_mask: 1.381  loss_dice: 4.346  loss_seg: 1.78  loss_ce_0: 0  loss_mask_0: 1.363  loss_dice_0: 4.349  loss_ce_1: 0  loss_mask_1: 1.386  loss_dice_1: 4.321  loss_ce_2: 0  loss_mask_2: 1.394  loss_dice_2: 4.307  loss_ce_3: 0  loss_mask_3: 1.39  loss_dice_3: 4.309  loss_ce_4: 0  loss_mask_4: 1.384  loss_dice_4: 4.308  loss_ce_5: 0  loss_mask_5: 1.383  loss_dice_5: 4.323  loss_ce_6: 0  loss_mask_6: 1.385  loss_dice_6: 4.324  loss_ce_7: 0  loss_mask_7: 1.369  loss_dice_7: 4.329  loss_ce_8: 0  loss_mask_8: 1.384  loss_dice_8: 4.332  time: 1.3801  data_time: 0.0351  lr: 9.9251e-05  max_mem: 5999M
[02/17 23:17:51] d2.utils.events INFO:  eta: 1 day, 0:44:04  iter: 519  total_loss: 59.06  loss_ce: 0  loss_mask: 1.396  loss_dice: 4.321  loss_seg: 1.8  loss_ce_0: 0  loss_mask_0: 1.41  loss_dice_0: 4.311  loss_ce_1: 0  loss_mask_1: 1.416  loss_dice_1: 4.279  loss_ce_2: 0  loss_mask_2: 1.415  loss_dice_2: 4.273  loss_ce_3: 0  loss_mask_3: 1.408  loss_dice_3: 4.278  loss_ce_4: 0  loss_mask_4: 1.402  loss_dice_4: 4.282  loss_ce_5: 0  loss_mask_5: 1.412  loss_dice_5: 4.287  loss_ce_6: 0  loss_mask_6: 1.402  loss_dice_6: 4.304  loss_ce_7: 0  loss_mask_7: 1.406  loss_dice_7: 4.293  loss_ce_8: 0  loss_mask_8: 1.397  loss_dice_8: 4.3  time: 1.3952  data_time: 0.0377  lr: 9.9221e-05  max_mem: 5999M
[02/17 23:18:24] d2.utils.events INFO:  eta: 1 day, 0:52:34  iter: 539  total_loss: 58.62  loss_ce: 0  loss_mask: 1.414  loss_dice: 4.302  loss_seg: 1.634  loss_ce_0: 0  loss_mask_0: 1.386  loss_dice_0: 4.309  loss_ce_1: 0  loss_mask_1: 1.412  loss_dice_1: 4.27  loss_ce_2: 0  loss_mask_2: 1.42  loss_dice_2: 4.272  loss_ce_3: 0  loss_mask_3: 1.428  loss_dice_3: 4.276  loss_ce_4: 0  loss_mask_4: 1.429  loss_dice_4: 4.283  loss_ce_5: 0  loss_mask_5: 1.422  loss_dice_5: 4.287  loss_ce_6: 0  loss_mask_6: 1.428  loss_dice_6: 4.29  loss_ce_7: 0  loss_mask_7: 1.42  loss_dice_7: 4.293  loss_ce_8: 0  loss_mask_8: 1.423  loss_dice_8: 4.295  time: 1.4053  data_time: 0.0307  lr: 9.9191e-05  max_mem: 5999M
[02/17 23:18:59] d2.utils.events INFO:  eta: 1 day, 0:55:38  iter: 559  total_loss: 58.79  loss_ce: 0  loss_mask: 1.434  loss_dice: 4.303  loss_seg: 1.377  loss_ce_0: 0  loss_mask_0: 1.427  loss_dice_0: 4.307  loss_ce_1: 0  loss_mask_1: 1.451  loss_dice_1: 4.274  loss_ce_2: 0  loss_mask_2: 1.438  loss_dice_2: 4.276  loss_ce_3: 0  loss_mask_3: 1.441  loss_dice_3: 4.279  loss_ce_4: 0  loss_mask_4: 1.452  loss_dice_4: 4.278  loss_ce_5: 0  loss_mask_5: 1.442  loss_dice_5: 4.279  loss_ce_6: 0  loss_mask_6: 1.447  loss_dice_6: 4.28  loss_ce_7: 0  loss_mask_7: 1.442  loss_dice_7: 4.28  loss_ce_8: 0  loss_mask_8: 1.443  loss_dice_8: 4.288  time: 1.4164  data_time: 0.0304  lr: 9.9161e-05  max_mem: 5999M
[02/17 23:19:35] d2.utils.events INFO:  eta: 1 day, 1:12:33  iter: 579  total_loss: 58.34  loss_ce: 0  loss_mask: 1.446  loss_dice: 4.264  loss_seg: 1.705  loss_ce_0: 0  loss_mask_0: 1.437  loss_dice_0: 4.297  loss_ce_1: 0  loss_mask_1: 1.441  loss_dice_1: 4.247  loss_ce_2: 0  loss_mask_2: 1.453  loss_dice_2: 4.235  loss_ce_3: 0  loss_mask_3: 1.457  loss_dice_3: 4.24  loss_ce_4: 0  loss_mask_4: 1.451  loss_dice_4: 4.247  loss_ce_5: 0  loss_mask_5: 1.451  loss_dice_5: 4.24  loss_ce_6: 0  loss_mask_6: 1.457  loss_dice_6: 4.243  loss_ce_7: 0  loss_mask_7: 1.454  loss_dice_7: 4.249  loss_ce_8: 0  loss_mask_8: 1.456  loss_dice_8: 4.251  time: 1.4295  data_time: 0.0344  lr: 9.9131e-05  max_mem: 5999M
[02/17 23:20:08] d2.utils.events INFO:  eta: 1 day, 1:15:04  iter: 599  total_loss: 58.34  loss_ce: 0  loss_mask: 1.383  loss_dice: 4.26  loss_seg: 1.835  loss_ce_0: 0  loss_mask_0: 1.358  loss_dice_0: 4.285  loss_ce_1: 0  loss_mask_1: 1.39  loss_dice_1: 4.241  loss_ce_2: 0  loss_mask_2: 1.388  loss_dice_2: 4.24  loss_ce_3: 0  loss_mask_3: 1.387  loss_dice_3: 4.241  loss_ce_4: 0  loss_mask_4: 1.382  loss_dice_4: 4.244  loss_ce_5: 0  loss_mask_5: 1.398  loss_dice_5: 4.242  loss_ce_6: 0  loss_mask_6: 1.392  loss_dice_6: 4.251  loss_ce_7: 0  loss_mask_7: 1.397  loss_dice_7: 4.244  loss_ce_8: 0  loss_mask_8: 1.394  loss_dice_8: 4.246  time: 1.4381  data_time: 0.0414  lr: 9.9101e-05  max_mem: 5999M
[02/17 23:20:42] d2.utils.events INFO:  eta: 1 day, 1:15:02  iter: 619  total_loss: 57.99  loss_ce: 0  loss_mask: 1.447  loss_dice: 4.235  loss_seg: 1.389  loss_ce_0: 0  loss_mask_0: 1.415  loss_dice_0: 4.268  loss_ce_1: 0  loss_mask_1: 1.429  loss_dice_1: 4.213  loss_ce_2: 0  loss_mask_2: 1.446  loss_dice_2: 4.203  loss_ce_3: 0  loss_mask_3: 1.438  loss_dice_3: 4.2  loss_ce_4: 0  loss_mask_4: 1.435  loss_dice_4: 4.202  loss_ce_5: 0  loss_mask_5: 1.43  loss_dice_5: 4.205  loss_ce_6: 0  loss_mask_6: 1.432  loss_dice_6: 4.202  loss_ce_7: 0  loss_mask_7: 1.434  loss_dice_7: 4.198  loss_ce_8: 0  loss_mask_8: 1.438  loss_dice_8: 4.208  time: 1.4453  data_time: 0.0365  lr: 9.9071e-05  max_mem: 5999M
[02/17 23:21:15] d2.utils.events INFO:  eta: 1 day, 1:16:31  iter: 639  total_loss: 57.93  loss_ce: 0  loss_mask: 1.461  loss_dice: 4.221  loss_seg: 1.234  loss_ce_0: 0  loss_mask_0: 1.431  loss_dice_0: 4.255  loss_ce_1: 0  loss_mask_1: 1.484  loss_dice_1: 4.193  loss_ce_2: 0  loss_mask_2: 1.492  loss_dice_2: 4.186  loss_ce_3: 0  loss_mask_3: 1.491  loss_dice_3: 4.178  loss_ce_4: 0  loss_mask_4: 1.473  loss_dice_4: 4.184  loss_ce_5: 0  loss_mask_5: 1.478  loss_dice_5: 4.189  loss_ce_6: 0  loss_mask_6: 1.476  loss_dice_6: 4.196  loss_ce_7: 0  loss_mask_7: 1.475  loss_dice_7: 4.197  loss_ce_8: 0  loss_mask_8: 1.482  loss_dice_8: 4.195  time: 1.4513  data_time: 0.0311  lr: 9.9041e-05  max_mem: 5999M
[02/17 23:21:49] d2.utils.events INFO:  eta: 1 day, 1:17:06  iter: 659  total_loss: 57.33  loss_ce: 0  loss_mask: 1.444  loss_dice: 4.186  loss_seg: 1.376  loss_ce_0: 0  loss_mask_0: 1.433  loss_dice_0: 4.21  loss_ce_1: 0  loss_mask_1: 1.449  loss_dice_1: 4.162  loss_ce_2: 0  loss_mask_2: 1.457  loss_dice_2: 4.157  loss_ce_3: 0  loss_mask_3: 1.458  loss_dice_3: 4.158  loss_ce_4: 0  loss_mask_4: 1.457  loss_dice_4: 4.152  loss_ce_5: 0  loss_mask_5: 1.45  loss_dice_5: 4.163  loss_ce_6: 0  loss_mask_6: 1.454  loss_dice_6: 4.159  loss_ce_7: 0  loss_mask_7: 1.451  loss_dice_7: 4.154  loss_ce_8: 0  loss_mask_8: 1.449  loss_dice_8: 4.161  time: 1.4587  data_time: 0.0363  lr: 9.9011e-05  max_mem: 5999M
[02/17 23:22:22] d2.utils.events INFO:  eta: 1 day, 1:23:40  iter: 679  total_loss: 57.25  loss_ce: 0  loss_mask: 1.438  loss_dice: 4.186  loss_seg: 1.238  loss_ce_0: 0  loss_mask_0: 1.415  loss_dice_0: 4.198  loss_ce_1: 0  loss_mask_1: 1.444  loss_dice_1: 4.152  loss_ce_2: 0  loss_mask_2: 1.442  loss_dice_2: 4.15  loss_ce_3: 0  loss_mask_3: 1.45  loss_dice_3: 4.15  loss_ce_4: 0  loss_mask_4: 1.445  loss_dice_4: 4.164  loss_ce_5: 0  loss_mask_5: 1.448  loss_dice_5: 4.168  loss_ce_6: 0  loss_mask_6: 1.445  loss_dice_6: 4.167  loss_ce_7: 0  loss_mask_7: 1.453  loss_dice_7: 4.168  loss_ce_8: 0  loss_mask_8: 1.447  loss_dice_8: 4.157  time: 1.4650  data_time: 0.0356  lr: 9.8981e-05  max_mem: 5999M
[02/17 23:22:57] d2.utils.events INFO:  eta: 1 day, 1:26:25  iter: 699  total_loss: 57.96  loss_ce: 0  loss_mask: 1.449  loss_dice: 4.209  loss_seg: 1.481  loss_ce_0: 0  loss_mask_0: 1.431  loss_dice_0: 4.241  loss_ce_1: 0  loss_mask_1: 1.46  loss_dice_1: 4.183  loss_ce_2: 0  loss_mask_2: 1.465  loss_dice_2: 4.173  loss_ce_3: 0  loss_mask_3: 1.465  loss_dice_3: 4.172  loss_ce_4: 0  loss_mask_4: 1.465  loss_dice_4: 4.169  loss_ce_5: 0  loss_mask_5: 1.465  loss_dice_5: 4.174  loss_ce_6: 0  loss_mask_6: 1.461  loss_dice_6: 4.173  loss_ce_7: 0  loss_mask_7: 1.463  loss_dice_7: 4.178  loss_ce_8: 0  loss_mask_8: 1.46  loss_dice_8: 4.189  time: 1.4731  data_time: 0.0343  lr: 9.8951e-05  max_mem: 5999M
[02/17 23:23:32] d2.utils.events INFO:  eta: 1 day, 1:29:47  iter: 719  total_loss: 57.58  loss_ce: 0  loss_mask: 1.404  loss_dice: 4.181  loss_seg: 1.606  loss_ce_0: 0  loss_mask_0: 1.393  loss_dice_0: 4.21  loss_ce_1: 0  loss_mask_1: 1.421  loss_dice_1: 4.147  loss_ce_2: 0  loss_mask_2: 1.424  loss_dice_2: 4.143  loss_ce_3: 0  loss_mask_3: 1.414  loss_dice_3: 4.143  loss_ce_4: 0  loss_mask_4: 1.42  loss_dice_4: 4.142  loss_ce_5: 0  loss_mask_5: 1.416  loss_dice_5: 4.144  loss_ce_6: 0  loss_mask_6: 1.413  loss_dice_6: 4.159  loss_ce_7: 0  loss_mask_7: 1.412  loss_dice_7: 4.154  loss_ce_8: 0  loss_mask_8: 1.421  loss_dice_8: 4.151  time: 1.4808  data_time: 0.0387  lr: 9.8921e-05  max_mem: 5999M
[02/17 23:24:05] d2.utils.events INFO:  eta: 1 day, 1:30:44  iter: 739  total_loss: 57.42  loss_ce: 0  loss_mask: 1.483  loss_dice: 4.188  loss_seg: 1.157  loss_ce_0: 0  loss_mask_0: 1.485  loss_dice_0: 4.182  loss_ce_1: 0  loss_mask_1: 1.507  loss_dice_1: 4.15  loss_ce_2: 0  loss_mask_2: 1.505  loss_dice_2: 4.148  loss_ce_3: 0  loss_mask_3: 1.503  loss_dice_3: 4.144  loss_ce_4: 0  loss_mask_4: 1.499  loss_dice_4: 4.162  loss_ce_5: 0  loss_mask_5: 1.496  loss_dice_5: 4.157  loss_ce_6: 0  loss_mask_6: 1.49  loss_dice_6: 4.163  loss_ce_7: 0  loss_mask_7: 1.499  loss_dice_7: 4.155  loss_ce_8: 0  loss_mask_8: 1.497  loss_dice_8: 4.154  time: 1.4842  data_time: 0.0345  lr: 9.8891e-05  max_mem: 5999M
[02/17 23:24:40] d2.utils.events INFO:  eta: 1 day, 1:37:39  iter: 759  total_loss: 57.63  loss_ce: 0  loss_mask: 1.492  loss_dice: 4.17  loss_seg: 1.506  loss_ce_0: 0  loss_mask_0: 1.467  loss_dice_0: 4.202  loss_ce_1: 0  loss_mask_1: 1.49  loss_dice_1: 4.135  loss_ce_2: 0  loss_mask_2: 1.496  loss_dice_2: 4.131  loss_ce_3: 0  loss_mask_3: 1.506  loss_dice_3: 4.139  loss_ce_4: 0  loss_mask_4: 1.502  loss_dice_4: 4.142  loss_ce_5: 0  loss_mask_5: 1.503  loss_dice_5: 4.14  loss_ce_6: 0  loss_mask_6: 1.504  loss_dice_6: 4.145  loss_ce_7: 0  loss_mask_7: 1.506  loss_dice_7: 4.14  loss_ce_8: 0  loss_mask_8: 1.498  loss_dice_8: 4.143  time: 1.4920  data_time: 0.0415  lr: 9.8861e-05  max_mem: 5999M
[02/17 23:25:15] d2.utils.events INFO:  eta: 1 day, 1:39:33  iter: 779  total_loss: 57.01  loss_ce: 0  loss_mask: 1.444  loss_dice: 4.136  loss_seg: 1.284  loss_ce_0: 0  loss_mask_0: 1.427  loss_dice_0: 4.156  loss_ce_1: 0  loss_mask_1: 1.439  loss_dice_1: 4.093  loss_ce_2: 0  loss_mask_2: 1.445  loss_dice_2: 4.088  loss_ce_3: 0  loss_mask_3: 1.44  loss_dice_3: 4.086  loss_ce_4: 0  loss_mask_4: 1.442  loss_dice_4: 4.087  loss_ce_5: 0  loss_mask_5: 1.44  loss_dice_5: 4.094  loss_ce_6: 0  loss_mask_6: 1.439  loss_dice_6: 4.092  loss_ce_7: 0  loss_mask_7: 1.441  loss_dice_7: 4.094  loss_ce_8: 0  loss_mask_8: 1.45  loss_dice_8: 4.098  time: 1.4988  data_time: 0.0363  lr: 9.8831e-05  max_mem: 5999M
[02/17 23:25:48] d2.utils.events INFO:  eta: 1 day, 1:42:40  iter: 799  total_loss: 56.6  loss_ce: 0  loss_mask: 1.409  loss_dice: 4.12  loss_seg: 1.388  loss_ce_0: 0  loss_mask_0: 1.38  loss_dice_0: 4.167  loss_ce_1: 0  loss_mask_1: 1.396  loss_dice_1: 4.105  loss_ce_2: 0  loss_mask_2: 1.403  loss_dice_2: 4.093  loss_ce_3: 0  loss_mask_3: 1.405  loss_dice_3: 4.083  loss_ce_4: 0  loss_mask_4: 1.408  loss_dice_4: 4.089  loss_ce_5: 0  loss_mask_5: 1.402  loss_dice_5: 4.087  loss_ce_6: 0  loss_mask_6: 1.407  loss_dice_6: 4.09  loss_ce_7: 0  loss_mask_7: 1.406  loss_dice_7: 4.101  loss_ce_8: 0  loss_mask_8: 1.405  loss_dice_8: 4.112  time: 1.5024  data_time: 0.0314  lr: 9.8801e-05  max_mem: 5999M
[02/17 23:26:25] d2.utils.events INFO:  eta: 1 day, 1:47:10  iter: 819  total_loss: 55.9  loss_ce: 0  loss_mask: 1.424  loss_dice: 4.049  loss_seg: 1.2  loss_ce_0: 0  loss_mask_0: 1.416  loss_dice_0: 4.078  loss_ce_1: 0  loss_mask_1: 1.427  loss_dice_1: 4.003  loss_ce_2: 0  loss_mask_2: 1.422  loss_dice_2: 4.002  loss_ce_3: 0  loss_mask_3: 1.42  loss_dice_3: 3.999  loss_ce_4: 0  loss_mask_4: 1.424  loss_dice_4: 3.997  loss_ce_5: 0  loss_mask_5: 1.427  loss_dice_5: 4  loss_ce_6: 0  loss_mask_6: 1.421  loss_dice_6: 4.003  loss_ce_7: 0  loss_mask_7: 1.419  loss_dice_7: 4.004  loss_ce_8: 0  loss_mask_8: 1.432  loss_dice_8: 4.005  time: 1.5100  data_time: 0.0440  lr: 9.8771e-05  max_mem: 5999M
[02/17 23:27:00] d2.utils.events INFO:  eta: 1 day, 1:49:38  iter: 839  total_loss: 55.83  loss_ce: 0  loss_mask: 1.48  loss_dice: 4.01  loss_seg: 1.189  loss_ce_0: 0  loss_mask_0: 1.48  loss_dice_0: 4.049  loss_ce_1: 0  loss_mask_1: 1.49  loss_dice_1: 3.976  loss_ce_2: 0  loss_mask_2: 1.485  loss_dice_2: 3.966  loss_ce_3: 0  loss_mask_3: 1.481  loss_dice_3: 3.957  loss_ce_4: 0  loss_mask_4: 1.481  loss_dice_4: 3.972  loss_ce_5: 0  loss_mask_5: 1.485  loss_dice_5: 3.983  loss_ce_6: 0  loss_mask_6: 1.479  loss_dice_6: 3.988  loss_ce_7: 0  loss_mask_7: 1.48  loss_dice_7: 3.998  loss_ce_8: 0  loss_mask_8: 1.497  loss_dice_8: 3.987  time: 1.5158  data_time: 0.0481  lr: 9.8741e-05  max_mem: 5999M
[02/17 23:27:40] d2.utils.events INFO:  eta: 1 day, 1:53:22  iter: 859  total_loss: 56  loss_ce: 0  loss_mask: 1.436  loss_dice: 4.053  loss_seg: 1.237  loss_ce_0: 0  loss_mask_0: 1.424  loss_dice_0: 4.091  loss_ce_1: 0  loss_mask_1: 1.442  loss_dice_1: 4.014  loss_ce_2: 0  loss_mask_2: 1.437  loss_dice_2: 4.005  loss_ce_3: 0  loss_mask_3: 1.438  loss_dice_3: 4.004  loss_ce_4: 0  loss_mask_4: 1.451  loss_dice_4: 3.996  loss_ce_5: 0  loss_mask_5: 1.44  loss_dice_5: 4.01  loss_ce_6: 0  loss_mask_6: 1.446  loss_dice_6: 4.009  loss_ce_7: 0  loss_mask_7: 1.444  loss_dice_7: 4.012  loss_ce_8: 0  loss_mask_8: 1.444  loss_dice_8: 4.013  time: 1.5263  data_time: 0.0574  lr: 9.8711e-05  max_mem: 5999M
[02/17 23:28:14] d2.utils.events INFO:  eta: 1 day, 1:57:02  iter: 879  total_loss: 55.9  loss_ce: 0  loss_mask: 1.387  loss_dice: 4.06  loss_seg: 1.646  loss_ce_0: 0  loss_mask_0: 1.389  loss_dice_0: 4.108  loss_ce_1: 0  loss_mask_1: 1.394  loss_dice_1: 4.04  loss_ce_2: 0  loss_mask_2: 1.396  loss_dice_2: 4.033  loss_ce_3: 0  loss_mask_3: 1.404  loss_dice_3: 4.025  loss_ce_4: 0  loss_mask_4: 1.389  loss_dice_4: 4.028  loss_ce_5: 0  loss_mask_5: 1.396  loss_dice_5: 4.03  loss_ce_6: 0  loss_mask_6: 1.393  loss_dice_6: 4.025  loss_ce_7: 0  loss_mask_7: 1.397  loss_dice_7: 4.027  loss_ce_8: 0  loss_mask_8: 1.397  loss_dice_8: 4.028  time: 1.5301  data_time: 0.0605  lr: 9.8681e-05  max_mem: 5999M
[02/17 23:28:48] d2.utils.events INFO:  eta: 1 day, 1:58:36  iter: 899  total_loss: 56.2  loss_ce: 0  loss_mask: 1.426  loss_dice: 4.033  loss_seg: 1.372  loss_ce_0: 0  loss_mask_0: 1.409  loss_dice_0: 4.074  loss_ce_1: 0  loss_mask_1: 1.438  loss_dice_1: 4.007  loss_ce_2: 0  loss_mask_2: 1.449  loss_dice_2: 3.997  loss_ce_3: 0  loss_mask_3: 1.454  loss_dice_3: 3.989  loss_ce_4: 0  loss_mask_4: 1.445  loss_dice_4: 3.993  loss_ce_5: 0  loss_mask_5: 1.44  loss_dice_5: 3.996  loss_ce_6: 0  loss_mask_6: 1.447  loss_dice_6: 4.005  loss_ce_7: 0  loss_mask_7: 1.451  loss_dice_7: 4.009  loss_ce_8: 0  loss_mask_8: 1.442  loss_dice_8: 4.007  time: 1.5346  data_time: 0.0525  lr: 9.865e-05  max_mem: 5999M
[02/17 23:29:24] d2.utils.events INFO:  eta: 1 day, 2:01:11  iter: 919  total_loss: 55.32  loss_ce: 0  loss_mask: 1.472  loss_dice: 3.94  loss_seg: 1.308  loss_ce_0: 0  loss_mask_0: 1.471  loss_dice_0: 3.973  loss_ce_1: 0  loss_mask_1: 1.478  loss_dice_1: 3.892  loss_ce_2: 0  loss_mask_2: 1.474  loss_dice_2: 3.894  loss_ce_3: 0  loss_mask_3: 1.475  loss_dice_3: 3.899  loss_ce_4: 0  loss_mask_4: 1.481  loss_dice_4: 3.904  loss_ce_5: 0  loss_mask_5: 1.481  loss_dice_5: 3.91  loss_ce_6: 0  loss_mask_6: 1.482  loss_dice_6: 3.907  loss_ce_7: 0  loss_mask_7: 1.489  loss_dice_7: 3.903  loss_ce_8: 0  loss_mask_8: 1.474  loss_dice_8: 3.904  time: 1.5400  data_time: 0.0546  lr: 9.862e-05  max_mem: 5999M
[02/17 23:30:01] d2.utils.events INFO:  eta: 1 day, 2:04:41  iter: 939  total_loss: 55.48  loss_ce: 0  loss_mask: 1.428  loss_dice: 3.993  loss_seg: 1.229  loss_ce_0: 0  loss_mask_0: 1.41  loss_dice_0: 4.025  loss_ce_1: 0  loss_mask_1: 1.443  loss_dice_1: 3.966  loss_ce_2: 0  loss_mask_2: 1.443  loss_dice_2: 3.966  loss_ce_3: 0  loss_mask_3: 1.45  loss_dice_3: 3.97  loss_ce_4: 0  loss_mask_4: 1.446  loss_dice_4: 3.98  loss_ce_5: 0  loss_mask_5: 1.449  loss_dice_5: 3.982  loss_ce_6: 0  loss_mask_6: 1.446  loss_dice_6: 3.971  loss_ce_7: 0  loss_mask_7: 1.44  loss_dice_7: 3.979  loss_ce_8: 0  loss_mask_8: 1.448  loss_dice_8: 3.971  time: 1.5463  data_time: 0.0586  lr: 9.859e-05  max_mem: 5999M
[02/17 23:30:36] d2.utils.events INFO:  eta: 1 day, 2:10:41  iter: 959  total_loss: 53.91  loss_ce: 0  loss_mask: 1.439  loss_dice: 3.856  loss_seg: 1.136  loss_ce_0: 0  loss_mask_0: 1.422  loss_dice_0: 3.947  loss_ce_1: 0  loss_mask_1: 1.443  loss_dice_1: 3.849  loss_ce_2: 0  loss_mask_2: 1.444  loss_dice_2: 3.829  loss_ce_3: 0  loss_mask_3: 1.447  loss_dice_3: 3.82  loss_ce_4: 0  loss_mask_4: 1.448  loss_dice_4: 3.816  loss_ce_5: 0  loss_mask_5: 1.443  loss_dice_5: 3.821  loss_ce_6: 0  loss_mask_6: 1.452  loss_dice_6: 3.822  loss_ce_7: 0  loss_mask_7: 1.45  loss_dice_7: 3.823  loss_ce_8: 0  loss_mask_8: 1.445  loss_dice_8: 3.83  time: 1.5508  data_time: 0.0427  lr: 9.856e-05  max_mem: 5999M
[02/17 23:31:14] d2.utils.events INFO:  eta: 1 day, 2:20:50  iter: 979  total_loss: 54.06  loss_ce: 0  loss_mask: 1.421  loss_dice: 3.814  loss_seg: 1.04  loss_ce_0: 0  loss_mask_0: 1.42  loss_dice_0: 3.867  loss_ce_1: 0  loss_mask_1: 1.442  loss_dice_1: 3.792  loss_ce_2: 0  loss_mask_2: 1.457  loss_dice_2: 3.78  loss_ce_3: 0  loss_mask_3: 1.441  loss_dice_3: 3.779  loss_ce_4: 0  loss_mask_4: 1.438  loss_dice_4: 3.779  loss_ce_5: 0  loss_mask_5: 1.445  loss_dice_5: 3.774  loss_ce_6: 0  loss_mask_6: 1.443  loss_dice_6: 3.785  loss_ce_7: 0  loss_mask_7: 1.446  loss_dice_7: 3.782  loss_ce_8: 0  loss_mask_8: 1.442  loss_dice_8: 3.787  time: 1.5569  data_time: 0.0593  lr: 9.853e-05  max_mem: 5999M
[02/17 23:31:48] d2.utils.events INFO:  eta: 1 day, 2:21:19  iter: 999  total_loss: 54.1  loss_ce: 0  loss_mask: 1.417  loss_dice: 3.844  loss_seg: 1.342  loss_ce_0: 0  loss_mask_0: 1.408  loss_dice_0: 3.905  loss_ce_1: 0  loss_mask_1: 1.423  loss_dice_1: 3.824  loss_ce_2: 0  loss_mask_2: 1.432  loss_dice_2: 3.813  loss_ce_3: 0  loss_mask_3: 1.444  loss_dice_3: 3.802  loss_ce_4: 0  loss_mask_4: 1.438  loss_dice_4: 3.805  loss_ce_5: 0  loss_mask_5: 1.443  loss_dice_5: 3.821  loss_ce_6: 0  loss_mask_6: 1.449  loss_dice_6: 3.814  loss_ce_7: 0  loss_mask_7: 1.438  loss_dice_7: 3.818  loss_ce_8: 0  loss_mask_8: 1.436  loss_dice_8: 3.817  time: 1.5604  data_time: 0.0580  lr: 9.85e-05  max_mem: 5999M
[02/17 23:32:31] d2.utils.events INFO:  eta: 1 day, 2:20:20  iter: 1019  total_loss: 54.15  loss_ce: 0  loss_mask: 1.448  loss_dice: 3.866  loss_seg: 1.274  loss_ce_0: 0  loss_mask_0: 1.422  loss_dice_0: 3.903  loss_ce_1: 0  loss_mask_1: 1.461  loss_dice_1: 3.832  loss_ce_2: 0  loss_mask_2: 1.459  loss_dice_2: 3.835  loss_ce_3: 0  loss_mask_3: 1.466  loss_dice_3: 3.835  loss_ce_4: 0  loss_mask_4: 1.458  loss_dice_4: 3.839  loss_ce_5: 0  loss_mask_5: 1.464  loss_dice_5: 3.847  loss_ce_6: 0  loss_mask_6: 1.47  loss_dice_6: 3.843  loss_ce_7: 0  loss_mask_7: 1.467  loss_dice_7: 3.842  loss_ce_8: 0  loss_mask_8: 1.468  loss_dice_8: 3.843  time: 1.5713  data_time: 0.0569  lr: 9.847e-05  max_mem: 5999M
[02/17 23:33:33] d2.utils.events INFO:  eta: 1 day, 2:31:44  iter: 1039  total_loss: 53.92  loss_ce: 0  loss_mask: 1.44  loss_dice: 3.838  loss_seg: 1.125  loss_ce_0: 0  loss_mask_0: 1.429  loss_dice_0: 3.906  loss_ce_1: 0  loss_mask_1: 1.448  loss_dice_1: 3.826  loss_ce_2: 0  loss_mask_2: 1.45  loss_dice_2: 3.81  loss_ce_3: 0  loss_mask_3: 1.454  loss_dice_3: 3.803  loss_ce_4: 0  loss_mask_4: 1.454  loss_dice_4: 3.809  loss_ce_5: 0  loss_mask_5: 1.452  loss_dice_5: 3.816  loss_ce_6: 0  loss_mask_6: 1.45  loss_dice_6: 3.81  loss_ce_7: 0  loss_mask_7: 1.45  loss_dice_7: 3.81  loss_ce_8: 0  loss_mask_8: 1.457  loss_dice_8: 3.815  time: 1.6013  data_time: 0.0448  lr: 9.844e-05  max_mem: 5999M
[02/17 23:34:41] d2.utils.events INFO:  eta: 1 day, 2:38:39  iter: 1059  total_loss: 54.33  loss_ce: 0  loss_mask: 1.407  loss_dice: 3.882  loss_seg: 1.17  loss_ce_0: 0  loss_mask_0: 1.417  loss_dice_0: 3.909  loss_ce_1: 0  loss_mask_1: 1.421  loss_dice_1: 3.862  loss_ce_2: 0  loss_mask_2: 1.426  loss_dice_2: 3.867  loss_ce_3: 0  loss_mask_3: 1.431  loss_dice_3: 3.86  loss_ce_4: 0  loss_mask_4: 1.435  loss_dice_4: 3.868  loss_ce_5: 0  loss_mask_5: 1.429  loss_dice_5: 3.873  loss_ce_6: 0  loss_mask_6: 1.424  loss_dice_6: 3.87  loss_ce_7: 0  loss_mask_7: 1.428  loss_dice_7: 3.869  loss_ce_8: 0  loss_mask_8: 1.43  loss_dice_8: 3.862  time: 1.6345  data_time: 0.0419  lr: 9.841e-05  max_mem: 5999M
[02/17 23:35:51] d2.utils.events INFO:  eta: 1 day, 2:57:30  iter: 1079  total_loss: 53.98  loss_ce: 0  loss_mask: 1.413  loss_dice: 3.86  loss_seg: 1.14  loss_ce_0: 0  loss_mask_0: 1.407  loss_dice_0: 3.886  loss_ce_1: 0  loss_mask_1: 1.422  loss_dice_1: 3.836  loss_ce_2: 0  loss_mask_2: 1.419  loss_dice_2: 3.83  loss_ce_3: 0  loss_mask_3: 1.423  loss_dice_3: 3.829  loss_ce_4: 0  loss_mask_4: 1.417  loss_dice_4: 3.83  loss_ce_5: 0  loss_mask_5: 1.418  loss_dice_5: 3.831  loss_ce_6: 0  loss_mask_6: 1.419  loss_dice_6: 3.834  loss_ce_7: 0  loss_mask_7: 1.417  loss_dice_7: 3.828  loss_ce_8: 0  loss_mask_8: 1.419  loss_dice_8: 3.828  time: 1.6697  data_time: 0.0320  lr: 9.838e-05  max_mem: 5999M
[02/17 23:36:53] d2.utils.events INFO:  eta: 1 day, 3:14:25  iter: 1099  total_loss: 53.53  loss_ce: 0  loss_mask: 1.418  loss_dice: 3.881  loss_seg: 1.152  loss_ce_0: 0  loss_mask_0: 1.397  loss_dice_0: 3.903  loss_ce_1: 0  loss_mask_1: 1.439  loss_dice_1: 3.853  loss_ce_2: 0  loss_mask_2: 1.436  loss_dice_2: 3.851  loss_ce_3: 0  loss_mask_3: 1.44  loss_dice_3: 3.851  loss_ce_4: 0  loss_mask_4: 1.425  loss_dice_4: 3.852  loss_ce_5: 0  loss_mask_5: 1.426  loss_dice_5: 3.86  loss_ce_6: 0  loss_mask_6: 1.433  loss_dice_6: 3.859  loss_ce_7: 0  loss_mask_7: 1.427  loss_dice_7: 3.855  loss_ce_8: 0  loss_mask_8: 1.423  loss_dice_8: 3.857  time: 1.6953  data_time: 0.0338  lr: 9.835e-05  max_mem: 5999M
[02/17 23:38:02] d2.utils.events INFO:  eta: 1 day, 3:29:38  iter: 1119  total_loss: 53.72  loss_ce: 0  loss_mask: 1.394  loss_dice: 3.819  loss_seg: 1.034  loss_ce_0: 0  loss_mask_0: 1.388  loss_dice_0: 3.843  loss_ce_1: 0  loss_mask_1: 1.404  loss_dice_1: 3.78  loss_ce_2: 0  loss_mask_2: 1.401  loss_dice_2: 3.779  loss_ce_3: 0  loss_mask_3: 1.395  loss_dice_3: 3.784  loss_ce_4: 0  loss_mask_4: 1.399  loss_dice_4: 3.784  loss_ce_5: 0  loss_mask_5: 1.399  loss_dice_5: 3.797  loss_ce_6: 0  loss_mask_6: 1.405  loss_dice_6: 3.789  loss_ce_7: 0  loss_mask_7: 1.406  loss_dice_7: 3.79  loss_ce_8: 0  loss_mask_8: 1.409  loss_dice_8: 3.793  time: 1.7263  data_time: 0.0329  lr: 9.832e-05  max_mem: 5999M
[02/17 23:39:06] d2.utils.events INFO:  eta: 1 day, 3:44:14  iter: 1139  total_loss: 52.55  loss_ce: 0  loss_mask: 1.399  loss_dice: 3.792  loss_seg: 1.31  loss_ce_0: 0  loss_mask_0: 1.37  loss_dice_0: 3.85  loss_ce_1: 0  loss_mask_1: 1.399  loss_dice_1: 3.759  loss_ce_2: 0  loss_mask_2: 1.399  loss_dice_2: 3.745  loss_ce_3: 0  loss_mask_3: 1.399  loss_dice_3: 3.743  loss_ce_4: 0  loss_mask_4: 1.402  loss_dice_4: 3.749  loss_ce_5: 0  loss_mask_5: 1.4  loss_dice_5: 3.758  loss_ce_6: 0  loss_mask_6: 1.405  loss_dice_6: 3.753  loss_ce_7: 0  loss_mask_7: 1.406  loss_dice_7: 3.759  loss_ce_8: 0  loss_mask_8: 1.401  loss_dice_8: 3.761  time: 1.7526  data_time: 0.0324  lr: 9.829e-05  max_mem: 5999M
[02/17 23:40:12] d2.utils.events INFO:  eta: 1 day, 3:59:53  iter: 1159  total_loss: 53.14  loss_ce: 0  loss_mask: 1.433  loss_dice: 3.765  loss_seg: 1.114  loss_ce_0: 0  loss_mask_0: 1.421  loss_dice_0: 3.798  loss_ce_1: 0  loss_mask_1: 1.432  loss_dice_1: 3.732  loss_ce_2: 0  loss_mask_2: 1.431  loss_dice_2: 3.734  loss_ce_3: 0  loss_mask_3: 1.441  loss_dice_3: 3.728  loss_ce_4: 0  loss_mask_4: 1.443  loss_dice_4: 3.728  loss_ce_5: 0  loss_mask_5: 1.447  loss_dice_5: 3.721  loss_ce_6: 0  loss_mask_6: 1.447  loss_dice_6: 3.729  loss_ce_7: 0  loss_mask_7: 1.445  loss_dice_7: 3.724  loss_ce_8: 0  loss_mask_8: 1.45  loss_dice_8: 3.726  time: 1.7791  data_time: 0.0283  lr: 9.826e-05  max_mem: 5999M
[02/17 23:41:21] d2.utils.events INFO:  eta: 1 day, 4:23:17  iter: 1179  total_loss: 52.53  loss_ce: 0  loss_mask: 1.366  loss_dice: 3.775  loss_seg: 1.282  loss_ce_0: 0  loss_mask_0: 1.347  loss_dice_0: 3.837  loss_ce_1: 0  loss_mask_1: 1.367  loss_dice_1: 3.733  loss_ce_2: 0  loss_mask_2: 1.374  loss_dice_2: 3.73  loss_ce_3: 0  loss_mask_3: 1.366  loss_dice_3: 3.732  loss_ce_4: 0  loss_mask_4: 1.37  loss_dice_4: 3.734  loss_ce_5: 0  loss_mask_5: 1.372  loss_dice_5: 3.746  loss_ce_6: 0  loss_mask_6: 1.371  loss_dice_6: 3.739  loss_ce_7: 0  loss_mask_7: 1.371  loss_dice_7: 3.74  loss_ce_8: 0  loss_mask_8: 1.375  loss_dice_8: 3.741  time: 1.8077  data_time: 0.0339  lr: 9.823e-05  max_mem: 5999M
[02/17 23:42:32] d2.utils.events INFO:  eta: 1 day, 4:43:43  iter: 1199  total_loss: 52.8  loss_ce: 0  loss_mask: 1.415  loss_dice: 3.701  loss_seg: 1.207  loss_ce_0: 0  loss_mask_0: 1.395  loss_dice_0: 3.746  loss_ce_1: 0  loss_mask_1: 1.414  loss_dice_1: 3.66  loss_ce_2: 0  loss_mask_2: 1.423  loss_dice_2: 3.656  loss_ce_3: 0  loss_mask_3: 1.439  loss_dice_3: 3.644  loss_ce_4: 0  loss_mask_4: 1.434  loss_dice_4: 3.64  loss_ce_5: 0  loss_mask_5: 1.427  loss_dice_5: 3.651  loss_ce_6: 0  loss_mask_6: 1.434  loss_dice_6: 3.651  loss_ce_7: 0  loss_mask_7: 1.426  loss_dice_7: 3.66  loss_ce_8: 0  loss_mask_8: 1.421  loss_dice_8: 3.66  time: 1.8366  data_time: 0.0366  lr: 9.82e-05  max_mem: 5999M
[02/17 23:43:34] d2.utils.events INFO:  eta: 1 day, 4:59:03  iter: 1219  total_loss: 52.24  loss_ce: 0  loss_mask: 1.393  loss_dice: 3.743  loss_seg: 1.206  loss_ce_0: 0  loss_mask_0: 1.385  loss_dice_0: 3.802  loss_ce_1: 0  loss_mask_1: 1.401  loss_dice_1: 3.712  loss_ce_2: 0  loss_mask_2: 1.402  loss_dice_2: 3.7  loss_ce_3: 0  loss_mask_3: 1.409  loss_dice_3: 3.696  loss_ce_4: 0  loss_mask_4: 1.408  loss_dice_4: 3.706  loss_ce_5: 0  loss_mask_5: 1.4  loss_dice_5: 3.706  loss_ce_6: 0  loss_mask_6: 1.408  loss_dice_6: 3.707  loss_ce_7: 0  loss_mask_7: 1.408  loss_dice_7: 3.703  loss_ce_8: 0  loss_mask_8: 1.411  loss_dice_8: 3.705  time: 1.8575  data_time: 0.0384  lr: 9.817e-05  max_mem: 5999M
[02/17 23:44:42] d2.utils.events INFO:  eta: 1 day, 5:18:18  iter: 1239  total_loss: 52.04  loss_ce: 0  loss_mask: 1.339  loss_dice: 3.677  loss_seg: 1.275  loss_ce_0: 0  loss_mask_0: 1.327  loss_dice_0: 3.745  loss_ce_1: 0  loss_mask_1: 1.344  loss_dice_1: 3.667  loss_ce_2: 0  loss_mask_2: 1.344  loss_dice_2: 3.657  loss_ce_3: 0  loss_mask_3: 1.342  loss_dice_3: 3.637  loss_ce_4: 0  loss_mask_4: 1.353  loss_dice_4: 3.644  loss_ce_5: 0  loss_mask_5: 1.347  loss_dice_5: 3.658  loss_ce_6: 0  loss_mask_6: 1.351  loss_dice_6: 3.662  loss_ce_7: 0  loss_mask_7: 1.348  loss_dice_7: 3.659  loss_ce_8: 0  loss_mask_8: 1.34  loss_dice_8: 3.653  time: 1.8817  data_time: 0.0365  lr: 9.814e-05  max_mem: 5999M
[02/17 23:45:16] d2.utils.events INFO:  eta: 1 day, 5:21:04  iter: 1259  total_loss: 52.96  loss_ce: 0  loss_mask: 1.465  loss_dice: 3.767  loss_seg: 1.246  loss_ce_0: 0  loss_mask_0: 1.449  loss_dice_0: 3.795  loss_ce_1: 0  loss_mask_1: 1.461  loss_dice_1: 3.724  loss_ce_2: 0  loss_mask_2: 1.473  loss_dice_2: 3.72  loss_ce_3: 0  loss_mask_3: 1.482  loss_dice_3: 3.716  loss_ce_4: 0  loss_mask_4: 1.487  loss_dice_4: 3.721  loss_ce_5: 0  loss_mask_5: 1.478  loss_dice_5: 3.73  loss_ce_6: 0  loss_mask_6: 1.477  loss_dice_6: 3.724  loss_ce_7: 0  loss_mask_7: 1.482  loss_dice_7: 3.734  loss_ce_8: 0  loss_mask_8: 1.488  loss_dice_8: 3.741  time: 1.8792  data_time: 0.0301  lr: 9.811e-05  max_mem: 5999M
[02/17 23:45:51] d2.utils.events INFO:  eta: 1 day, 5:24:27  iter: 1279  total_loss: 52.18  loss_ce: 0  loss_mask: 1.379  loss_dice: 3.694  loss_seg: 0.9698  loss_ce_0: 0  loss_mask_0: 1.358  loss_dice_0: 3.748  loss_ce_1: 0  loss_mask_1: 1.381  loss_dice_1: 3.653  loss_ce_2: 0  loss_mask_2: 1.387  loss_dice_2: 3.647  loss_ce_3: 0  loss_mask_3: 1.382  loss_dice_3: 3.643  loss_ce_4: 0  loss_mask_4: 1.392  loss_dice_4: 3.637  loss_ce_5: 0  loss_mask_5: 1.399  loss_dice_5: 3.643  loss_ce_6: 0  loss_mask_6: 1.392  loss_dice_6: 3.65  loss_ce_7: 0  loss_mask_7: 1.388  loss_dice_7: 3.651  loss_ce_8: 0  loss_mask_8: 1.394  loss_dice_8: 3.65  time: 1.8764  data_time: 0.0314  lr: 9.8079e-05  max_mem: 5999M
[02/17 23:46:24] d2.utils.events INFO:  eta: 1 day, 5:21:49  iter: 1299  total_loss: 51.44  loss_ce: 0  loss_mask: 1.385  loss_dice: 3.625  loss_seg: 1.049  loss_ce_0: 0  loss_mask_0: 1.354  loss_dice_0: 3.71  loss_ce_1: 0  loss_mask_1: 1.38  loss_dice_1: 3.617  loss_ce_2: 0  loss_mask_2: 1.39  loss_dice_2: 3.596  loss_ce_3: 0  loss_mask_3: 1.395  loss_dice_3: 3.582  loss_ce_4: 0  loss_mask_4: 1.39  loss_dice_4: 3.59  loss_ce_5: 0  loss_mask_5: 1.388  loss_dice_5: 3.591  loss_ce_6: 0  loss_mask_6: 1.39  loss_dice_6: 3.596  loss_ce_7: 0  loss_mask_7: 1.392  loss_dice_7: 3.595  loss_ce_8: 0  loss_mask_8: 1.395  loss_dice_8: 3.592  time: 1.8730  data_time: 0.0269  lr: 9.8049e-05  max_mem: 5999M
[02/17 23:46:57] d2.utils.events INFO:  eta: 1 day, 5:21:13  iter: 1319  total_loss: 51.23  loss_ce: 0  loss_mask: 1.331  loss_dice: 3.639  loss_seg: 1.107  loss_ce_0: 0  loss_mask_0: 1.323  loss_dice_0: 3.7  loss_ce_1: 0  loss_mask_1: 1.343  loss_dice_1: 3.618  loss_ce_2: 0  loss_mask_2: 1.35  loss_dice_2: 3.616  loss_ce_3: 0  loss_mask_3: 1.361  loss_dice_3: 3.606  loss_ce_4: 0  loss_mask_4: 1.355  loss_dice_4: 3.618  loss_ce_5: 0  loss_mask_5: 1.371  loss_dice_5: 3.622  loss_ce_6: 0  loss_mask_6: 1.362  loss_dice_6: 3.617  loss_ce_7: 0  loss_mask_7: 1.359  loss_dice_7: 3.621  loss_ce_8: 0  loss_mask_8: 1.364  loss_dice_8: 3.624  time: 1.8697  data_time: 0.0436  lr: 9.8019e-05  max_mem: 5999M
[02/17 23:47:32] d2.utils.events INFO:  eta: 1 day, 5:27:25  iter: 1339  total_loss: 51.46  loss_ce: 0  loss_mask: 1.317  loss_dice: 3.684  loss_seg: 1.132  loss_ce_0: 0  loss_mask_0: 1.291  loss_dice_0: 3.737  loss_ce_1: 0  loss_mask_1: 1.316  loss_dice_1: 3.643  loss_ce_2: 0  loss_mask_2: 1.315  loss_dice_2: 3.644  loss_ce_3: 0  loss_mask_3: 1.315  loss_dice_3: 3.644  loss_ce_4: 0  loss_mask_4: 1.323  loss_dice_4: 3.652  loss_ce_5: 0  loss_mask_5: 1.325  loss_dice_5: 3.654  loss_ce_6: 0  loss_mask_6: 1.329  loss_dice_6: 3.658  loss_ce_7: 0  loss_mask_7: 1.331  loss_dice_7: 3.66  loss_ce_8: 0  loss_mask_8: 1.333  loss_dice_8: 3.65  time: 1.8683  data_time: 0.0361  lr: 9.7989e-05  max_mem: 5999M
[02/17 23:48:09] d2.utils.events INFO:  eta: 1 day, 5:26:49  iter: 1359  total_loss: 51.2  loss_ce: 0  loss_mask: 1.393  loss_dice: 3.588  loss_seg: 1.007  loss_ce_0: 0  loss_mask_0: 1.379  loss_dice_0: 3.668  loss_ce_1: 0  loss_mask_1: 1.392  loss_dice_1: 3.558  loss_ce_2: 0  loss_mask_2: 1.399  loss_dice_2: 3.541  loss_ce_3: 0  loss_mask_3: 1.4  loss_dice_3: 3.532  loss_ce_4: 0  loss_mask_4: 1.406  loss_dice_4: 3.535  loss_ce_5: 0  loss_mask_5: 1.412  loss_dice_5: 3.534  loss_ce_6: 0  loss_mask_6: 1.4  loss_dice_6: 3.542  loss_ce_7: 0  loss_mask_7: 1.402  loss_dice_7: 3.544  loss_ce_8: 0  loss_mask_8: 1.403  loss_dice_8: 3.548  time: 1.8679  data_time: 0.0355  lr: 9.7959e-05  max_mem: 5999M
[02/17 23:48:42] d2.utils.events INFO:  eta: 1 day, 5:26:40  iter: 1379  total_loss: 50.72  loss_ce: 0  loss_mask: 1.371  loss_dice: 3.601  loss_seg: 1.078  loss_ce_0: 0  loss_mask_0: 1.378  loss_dice_0: 3.644  loss_ce_1: 0  loss_mask_1: 1.395  loss_dice_1: 3.556  loss_ce_2: 0  loss_mask_2: 1.387  loss_dice_2: 3.539  loss_ce_3: 0  loss_mask_3: 1.389  loss_dice_3: 3.547  loss_ce_4: 0  loss_mask_4: 1.395  loss_dice_4: 3.549  loss_ce_5: 0  loss_mask_5: 1.387  loss_dice_5: 3.553  loss_ce_6: 0  loss_mask_6: 1.386  loss_dice_6: 3.557  loss_ce_7: 0  loss_mask_7: 1.387  loss_dice_7: 3.557  loss_ce_8: 0  loss_mask_8: 1.378  loss_dice_8: 3.572  time: 1.8646  data_time: 0.0330  lr: 9.7929e-05  max_mem: 5999M
[02/17 23:49:16] d2.utils.events INFO:  eta: 1 day, 5:26:27  iter: 1399  total_loss: 51.22  loss_ce: 0  loss_mask: 1.42  loss_dice: 3.673  loss_seg: 0.9852  loss_ce_0: 0  loss_mask_0: 1.417  loss_dice_0: 3.692  loss_ce_1: 0  loss_mask_1: 1.423  loss_dice_1: 3.627  loss_ce_2: 0  loss_mask_2: 1.429  loss_dice_2: 3.63  loss_ce_3: 0  loss_mask_3: 1.432  loss_dice_3: 3.632  loss_ce_4: 0  loss_mask_4: 1.426  loss_dice_4: 3.631  loss_ce_5: 0  loss_mask_5: 1.436  loss_dice_5: 3.637  loss_ce_6: 0  loss_mask_6: 1.426  loss_dice_6: 3.634  loss_ce_7: 0  loss_mask_7: 1.425  loss_dice_7: 3.632  loss_ce_8: 0  loss_mask_8: 1.421  loss_dice_8: 3.633  time: 1.8620  data_time: 0.0302  lr: 9.7899e-05  max_mem: 5999M
[02/17 23:49:51] d2.utils.events INFO:  eta: 1 day, 5:27:24  iter: 1419  total_loss: 50.94  loss_ce: 0  loss_mask: 1.34  loss_dice: 3.648  loss_seg: 1.335  loss_ce_0: 0  loss_mask_0: 1.323  loss_dice_0: 3.715  loss_ce_1: 0  loss_mask_1: 1.342  loss_dice_1: 3.621  loss_ce_2: 0  loss_mask_2: 1.345  loss_dice_2: 3.62  loss_ce_3: 0  loss_mask_3: 1.353  loss_dice_3: 3.617  loss_ce_4: 0  loss_mask_4: 1.353  loss_dice_4: 3.619  loss_ce_5: 0  loss_mask_5: 1.364  loss_dice_5: 3.619  loss_ce_6: 0  loss_mask_6: 1.351  loss_dice_6: 3.625  loss_ce_7: 0  loss_mask_7: 1.35  loss_dice_7: 3.624  loss_ce_8: 0  loss_mask_8: 1.354  loss_dice_8: 3.631  time: 1.8600  data_time: 0.0548  lr: 9.7869e-05  max_mem: 5999M
[02/17 23:50:24] d2.utils.events INFO:  eta: 1 day, 5:28:46  iter: 1439  total_loss: 50.84  loss_ce: 0  loss_mask: 1.341  loss_dice: 3.61  loss_seg: 1.021  loss_ce_0: 0  loss_mask_0: 1.325  loss_dice_0: 3.679  loss_ce_1: 0  loss_mask_1: 1.35  loss_dice_1: 3.588  loss_ce_2: 0  loss_mask_2: 1.345  loss_dice_2: 3.579  loss_ce_3: 0  loss_mask_3: 1.346  loss_dice_3: 3.58  loss_ce_4: 0  loss_mask_4: 1.349  loss_dice_4: 3.585  loss_ce_5: 0  loss_mask_5: 1.342  loss_dice_5: 3.585  loss_ce_6: 0  loss_mask_6: 1.346  loss_dice_6: 3.588  loss_ce_7: 0  loss_mask_7: 1.347  loss_dice_7: 3.585  loss_ce_8: 0  loss_mask_8: 1.354  loss_dice_8: 3.578  time: 1.8574  data_time: 0.0455  lr: 9.7839e-05  max_mem: 5999M
[02/17 23:50:59] d2.utils.events INFO:  eta: 1 day, 5:32:10  iter: 1459  total_loss: 50.07  loss_ce: 0  loss_mask: 1.322  loss_dice: 3.579  loss_seg: 1.106  loss_ce_0: 0  loss_mask_0: 1.294  loss_dice_0: 3.664  loss_ce_1: 0  loss_mask_1: 1.335  loss_dice_1: 3.555  loss_ce_2: 0  loss_mask_2: 1.343  loss_dice_2: 3.536  loss_ce_3: 0  loss_mask_3: 1.334  loss_dice_3: 3.524  loss_ce_4: 0  loss_mask_4: 1.328  loss_dice_4: 3.528  loss_ce_5: 0  loss_mask_5: 1.334  loss_dice_5: 3.535  loss_ce_6: 0  loss_mask_6: 1.333  loss_dice_6: 3.538  loss_ce_7: 0  loss_mask_7: 1.336  loss_dice_7: 3.543  loss_ce_8: 0  loss_mask_8: 1.332  loss_dice_8: 3.542  time: 1.8555  data_time: 0.0335  lr: 9.7809e-05  max_mem: 5999M
[02/17 23:51:30] d2.utils.events INFO:  eta: 1 day, 5:27:10  iter: 1479  total_loss: 50.05  loss_ce: 0  loss_mask: 1.34  loss_dice: 3.555  loss_seg: 1.003  loss_ce_0: 0  loss_mask_0: 1.336  loss_dice_0: 3.597  loss_ce_1: 0  loss_mask_1: 1.347  loss_dice_1: 3.514  loss_ce_2: 0  loss_mask_2: 1.36  loss_dice_2: 3.497  loss_ce_3: 0  loss_mask_3: 1.361  loss_dice_3: 3.498  loss_ce_4: 0  loss_mask_4: 1.358  loss_dice_4: 3.504  loss_ce_5: 0  loss_mask_5: 1.359  loss_dice_5: 3.519  loss_ce_6: 0  loss_mask_6: 1.354  loss_dice_6: 3.518  loss_ce_7: 0  loss_mask_7: 1.357  loss_dice_7: 3.515  loss_ce_8: 0  loss_mask_8: 1.356  loss_dice_8: 3.52  time: 1.8518  data_time: 0.0446  lr: 9.7779e-05  max_mem: 5999M
[02/17 23:52:05] d2.utils.events INFO:  eta: 1 day, 5:25:49  iter: 1499  total_loss: 49.6  loss_ce: 0  loss_mask: 1.308  loss_dice: 3.535  loss_seg: 1.518  loss_ce_0: 0  loss_mask_0: 1.312  loss_dice_0: 3.594  loss_ce_1: 0  loss_mask_1: 1.321  loss_dice_1: 3.52  loss_ce_2: 0  loss_mask_2: 1.321  loss_dice_2: 3.503  loss_ce_3: 0  loss_mask_3: 1.327  loss_dice_3: 3.493  loss_ce_4: 0  loss_mask_4: 1.318  loss_dice_4: 3.506  loss_ce_5: 0  loss_mask_5: 1.324  loss_dice_5: 3.503  loss_ce_6: 0  loss_mask_6: 1.322  loss_dice_6: 3.5  loss_ce_7: 0  loss_mask_7: 1.327  loss_dice_7: 3.504  loss_ce_8: 0  loss_mask_8: 1.323  loss_dice_8: 3.508  time: 1.8504  data_time: 0.0367  lr: 9.7749e-05  max_mem: 5999M
[02/17 23:52:39] d2.utils.events INFO:  eta: 1 day, 5:22:50  iter: 1519  total_loss: 49.98  loss_ce: 0  loss_mask: 1.342  loss_dice: 3.602  loss_seg: 0.9946  loss_ce_0: 0  loss_mask_0: 1.314  loss_dice_0: 3.669  loss_ce_1: 0  loss_mask_1: 1.347  loss_dice_1: 3.571  loss_ce_2: 0  loss_mask_2: 1.361  loss_dice_2: 3.555  loss_ce_3: 0  loss_mask_3: 1.361  loss_dice_3: 3.554  loss_ce_4: 0  loss_mask_4: 1.359  loss_dice_4: 3.56  loss_ce_5: 0  loss_mask_5: 1.359  loss_dice_5: 3.565  loss_ce_6: 0  loss_mask_6: 1.357  loss_dice_6: 3.566  loss_ce_7: 0  loss_mask_7: 1.357  loss_dice_7: 3.558  loss_ce_8: 0  loss_mask_8: 1.362  loss_dice_8: 3.558  time: 1.8479  data_time: 0.0315  lr: 9.7719e-05  max_mem: 5999M
[02/17 23:53:14] d2.utils.events INFO:  eta: 1 day, 5:25:28  iter: 1539  total_loss: 49.9  loss_ce: 0  loss_mask: 1.389  loss_dice: 3.538  loss_seg: 1.201  loss_ce_0: 0  loss_mask_0: 1.38  loss_dice_0: 3.617  loss_ce_1: 0  loss_mask_1: 1.396  loss_dice_1: 3.51  loss_ce_2: 0  loss_mask_2: 1.392  loss_dice_2: 3.508  loss_ce_3: 0  loss_mask_3: 1.391  loss_dice_3: 3.497  loss_ce_4: 0  loss_mask_4: 1.395  loss_dice_4: 3.509  loss_ce_5: 0  loss_mask_5: 1.409  loss_dice_5: 3.512  loss_ce_6: 0  loss_mask_6: 1.393  loss_dice_6: 3.519  loss_ce_7: 0  loss_mask_7: 1.401  loss_dice_7: 3.511  loss_ce_8: 0  loss_mask_8: 1.401  loss_dice_8: 3.513  time: 1.8471  data_time: 0.0379  lr: 9.7689e-05  max_mem: 5999M
[02/17 23:53:48] d2.utils.events INFO:  eta: 1 day, 5:23:10  iter: 1559  total_loss: 49.61  loss_ce: 0  loss_mask: 1.332  loss_dice: 3.552  loss_seg: 0.8584  loss_ce_0: 0  loss_mask_0: 1.335  loss_dice_0: 3.602  loss_ce_1: 0  loss_mask_1: 1.345  loss_dice_1: 3.53  loss_ce_2: 0  loss_mask_2: 1.338  loss_dice_2: 3.525  loss_ce_3: 0  loss_mask_3: 1.345  loss_dice_3: 3.522  loss_ce_4: 0  loss_mask_4: 1.347  loss_dice_4: 3.524  loss_ce_5: 0  loss_mask_5: 1.352  loss_dice_5: 3.523  loss_ce_6: 0  loss_mask_6: 1.344  loss_dice_6: 3.522  loss_ce_7: 0  loss_mask_7: 1.347  loss_dice_7: 3.521  loss_ce_8: 0  loss_mask_8: 1.347  loss_dice_8: 3.525  time: 1.8447  data_time: 0.0426  lr: 9.7658e-05  max_mem: 5999M
[02/17 23:54:25] d2.utils.events INFO:  eta: 1 day, 5:20:50  iter: 1579  total_loss: 48.37  loss_ce: 0  loss_mask: 1.353  loss_dice: 3.4  loss_seg: 0.8933  loss_ce_0: 0  loss_mask_0: 1.334  loss_dice_0: 3.506  loss_ce_1: 0  loss_mask_1: 1.343  loss_dice_1: 3.377  loss_ce_2: 0  loss_mask_2: 1.355  loss_dice_2: 3.366  loss_ce_3: 0  loss_mask_3: 1.359  loss_dice_3: 3.367  loss_ce_4: 0  loss_mask_4: 1.37  loss_dice_4: 3.369  loss_ce_5: 0  loss_mask_5: 1.366  loss_dice_5: 3.382  loss_ce_6: 0  loss_mask_6: 1.366  loss_dice_6: 3.387  loss_ce_7: 0  loss_mask_7: 1.365  loss_dice_7: 3.385  loss_ce_8: 0  loss_mask_8: 1.371  loss_dice_8: 3.377  time: 1.8447  data_time: 0.0416  lr: 9.7628e-05  max_mem: 5999M
[02/17 23:54:57] d2.utils.events INFO:  eta: 1 day, 5:20:02  iter: 1599  total_loss: 49.93  loss_ce: 0  loss_mask: 1.326  loss_dice: 3.546  loss_seg: 1.018  loss_ce_0: 0  loss_mask_0: 1.328  loss_dice_0: 3.588  loss_ce_1: 0  loss_mask_1: 1.329  loss_dice_1: 3.525  loss_ce_2: 0  loss_mask_2: 1.328  loss_dice_2: 3.525  loss_ce_3: 0  loss_mask_3: 1.323  loss_dice_3: 3.527  loss_ce_4: 0  loss_mask_4: 1.324  loss_dice_4: 3.526  loss_ce_5: 0  loss_mask_5: 1.334  loss_dice_5: 3.53  loss_ce_6: 0  loss_mask_6: 1.335  loss_dice_6: 3.529  loss_ce_7: 0  loss_mask_7: 1.329  loss_dice_7: 3.522  loss_ce_8: 0  loss_mask_8: 1.34  loss_dice_8: 3.518  time: 1.8419  data_time: 0.0303  lr: 9.7598e-05  max_mem: 5999M
[02/17 23:55:32] d2.utils.events INFO:  eta: 1 day, 5:19:49  iter: 1619  total_loss: 49.55  loss_ce: 0  loss_mask: 1.275  loss_dice: 3.529  loss_seg: 1.13  loss_ce_0: 0  loss_mask_0: 1.296  loss_dice_0: 3.598  loss_ce_1: 0  loss_mask_1: 1.283  loss_dice_1: 3.519  loss_ce_2: 0  loss_mask_2: 1.288  loss_dice_2: 3.511  loss_ce_3: 0  loss_mask_3: 1.285  loss_dice_3: 3.511  loss_ce_4: 0  loss_mask_4: 1.285  loss_dice_4: 3.51  loss_ce_5: 0  loss_mask_5: 1.276  loss_dice_5: 3.511  loss_ce_6: 0  loss_mask_6: 1.289  loss_dice_6: 3.509  loss_ce_7: 0  loss_mask_7: 1.282  loss_dice_7: 3.508  loss_ce_8: 0  loss_mask_8: 1.287  loss_dice_8: 3.507  time: 1.8407  data_time: 0.0275  lr: 9.7568e-05  max_mem: 5999M
[02/17 23:56:05] d2.utils.events INFO:  eta: 1 day, 5:18:23  iter: 1639  total_loss: 49.73  loss_ce: 0  loss_mask: 1.346  loss_dice: 3.521  loss_seg: 1.046  loss_ce_0: 0  loss_mask_0: 1.321  loss_dice_0: 3.558  loss_ce_1: 0  loss_mask_1: 1.339  loss_dice_1: 3.485  loss_ce_2: 0  loss_mask_2: 1.345  loss_dice_2: 3.486  loss_ce_3: 0  loss_mask_3: 1.352  loss_dice_3: 3.49  loss_ce_4: 0  loss_mask_4: 1.354  loss_dice_4: 3.494  loss_ce_5: 0  loss_mask_5: 1.356  loss_dice_5: 3.498  loss_ce_6: 0  loss_mask_6: 1.348  loss_dice_6: 3.506  loss_ce_7: 0  loss_mask_7: 1.347  loss_dice_7: 3.498  loss_ce_8: 0  loss_mask_8: 1.345  loss_dice_8: 3.498  time: 1.8382  data_time: 0.0375  lr: 9.7538e-05  max_mem: 5999M
[02/17 23:56:41] d2.utils.events INFO:  eta: 1 day, 5:18:37  iter: 1659  total_loss: 48.02  loss_ce: 0  loss_mask: 1.3  loss_dice: 3.444  loss_seg: 1.044  loss_ce_0: 0  loss_mask_0: 1.285  loss_dice_0: 3.517  loss_ce_1: 0  loss_mask_1: 1.295  loss_dice_1: 3.397  loss_ce_2: 0  loss_mask_2: 1.304  loss_dice_2: 3.384  loss_ce_3: 0  loss_mask_3: 1.314  loss_dice_3: 3.38  loss_ce_4: 0  loss_mask_4: 1.315  loss_dice_4: 3.391  loss_ce_5: 0  loss_mask_5: 1.307  loss_dice_5: 3.394  loss_ce_6: 0  loss_mask_6: 1.312  loss_dice_6: 3.393  loss_ce_7: 0  loss_mask_7: 1.316  loss_dice_7: 3.398  loss_ce_8: 0  loss_mask_8: 1.316  loss_dice_8: 3.41  time: 1.8376  data_time: 0.0406  lr: 9.7508e-05  max_mem: 5999M
[02/17 23:57:16] d2.utils.events INFO:  eta: 1 day, 5:20:23  iter: 1679  total_loss: 48.51  loss_ce: 0  loss_mask: 1.331  loss_dice: 3.418  loss_seg: 1.143  loss_ce_0: 0  loss_mask_0: 1.314  loss_dice_0: 3.512  loss_ce_1: 0  loss_mask_1: 1.33  loss_dice_1: 3.389  loss_ce_2: 0  loss_mask_2: 1.332  loss_dice_2: 3.371  loss_ce_3: 0  loss_mask_3: 1.344  loss_dice_3: 3.358  loss_ce_4: 0  loss_mask_4: 1.344  loss_dice_4: 3.362  loss_ce_5: 0  loss_mask_5: 1.34  loss_dice_5: 3.378  loss_ce_6: 0  loss_mask_6: 1.349  loss_dice_6: 3.373  loss_ce_7: 0  loss_mask_7: 1.356  loss_dice_7: 3.377  loss_ce_8: 0  loss_mask_8: 1.344  loss_dice_8: 3.384  time: 1.8367  data_time: 0.0431  lr: 9.7478e-05  max_mem: 5999M
[02/17 23:58:09] d2.utils.events INFO:  eta: 1 day, 5:31:34  iter: 1699  total_loss: 49.41  loss_ce: 0  loss_mask: 1.296  loss_dice: 3.527  loss_seg: 1.118  loss_ce_0: 0  loss_mask_0: 1.285  loss_dice_0: 3.584  loss_ce_1: 0  loss_mask_1: 1.308  loss_dice_1: 3.503  loss_ce_2: 0  loss_mask_2: 1.307  loss_dice_2: 3.485  loss_ce_3: 0  loss_mask_3: 1.318  loss_dice_3: 3.496  loss_ce_4: 0  loss_mask_4: 1.312  loss_dice_4: 3.5  loss_ce_5: 0  loss_mask_5: 1.308  loss_dice_5: 3.502  loss_ce_6: 0  loss_mask_6: 1.312  loss_dice_6: 3.497  loss_ce_7: 0  loss_mask_7: 1.308  loss_dice_7: 3.5  loss_ce_8: 0  loss_mask_8: 1.312  loss_dice_8: 3.501  time: 1.8459  data_time: 0.0328  lr: 9.7448e-05  max_mem: 5999M
[02/17 23:59:14] d2.utils.events INFO:  eta: 1 day, 5:43:37  iter: 1719  total_loss: 48.84  loss_ce: 0  loss_mask: 1.342  loss_dice: 3.52  loss_seg: 1.066  loss_ce_0: 0  loss_mask_0: 1.333  loss_dice_0: 3.571  loss_ce_1: 0  loss_mask_1: 1.343  loss_dice_1: 3.48  loss_ce_2: 0  loss_mask_2: 1.344  loss_dice_2: 3.482  loss_ce_3: 0  loss_mask_3: 1.34  loss_dice_3: 3.475  loss_ce_4: 0  loss_mask_4: 1.346  loss_dice_4: 3.471  loss_ce_5: 0  loss_mask_5: 1.345  loss_dice_5: 3.481  loss_ce_6: 0  loss_mask_6: 1.342  loss_dice_6: 3.482  loss_ce_7: 0  loss_mask_7: 1.344  loss_dice_7: 3.484  loss_ce_8: 0  loss_mask_8: 1.344  loss_dice_8: 3.482  time: 1.8621  data_time: 0.0440  lr: 9.7418e-05  max_mem: 5999M
[02/18 00:00:29] d2.utils.events INFO:  eta: 1 day, 5:59:49  iter: 1739  total_loss: 49.77  loss_ce: 0  loss_mask: 1.391  loss_dice: 3.501  loss_seg: 0.9744  loss_ce_0: 0  loss_mask_0: 1.35  loss_dice_0: 3.519  loss_ce_1: 0  loss_mask_1: 1.394  loss_dice_1: 3.458  loss_ce_2: 0  loss_mask_2: 1.402  loss_dice_2: 3.453  loss_ce_3: 0  loss_mask_3: 1.413  loss_dice_3: 3.454  loss_ce_4: 0  loss_mask_4: 1.416  loss_dice_4: 3.454  loss_ce_5: 0  loss_mask_5: 1.417  loss_dice_5: 3.467  loss_ce_6: 0  loss_mask_6: 1.415  loss_dice_6: 3.48  loss_ce_7: 0  loss_mask_7: 1.41  loss_dice_7: 3.478  loss_ce_8: 0  loss_mask_8: 1.406  loss_dice_8: 3.472  time: 1.8841  data_time: 0.0409  lr: 9.7388e-05  max_mem: 5999M
[02/18 00:01:40] d2.utils.events INFO:  eta: 1 day, 6:21:32  iter: 1759  total_loss: 48.39  loss_ce: 0  loss_mask: 1.275  loss_dice: 3.476  loss_seg: 1.136  loss_ce_0: 0  loss_mask_0: 1.273  loss_dice_0: 3.533  loss_ce_1: 0  loss_mask_1: 1.281  loss_dice_1: 3.436  loss_ce_2: 0  loss_mask_2: 1.286  loss_dice_2: 3.432  loss_ce_3: 0  loss_mask_3: 1.282  loss_dice_3: 3.436  loss_ce_4: 0  loss_mask_4: 1.281  loss_dice_4: 3.442  loss_ce_5: 0  loss_mask_5: 1.28  loss_dice_5: 3.443  loss_ce_6: 0  loss_mask_6: 1.275  loss_dice_6: 3.448  loss_ce_7: 0  loss_mask_7: 1.275  loss_dice_7: 3.443  loss_ce_8: 0  loss_mask_8: 1.276  loss_dice_8: 3.444  time: 1.9026  data_time: 0.0366  lr: 9.7358e-05  max_mem: 5999M
[02/18 00:02:44] d2.utils.events INFO:  eta: 1 day, 6:42:49  iter: 1779  total_loss: 48.04  loss_ce: 0  loss_mask: 1.216  loss_dice: 3.428  loss_seg: 1.273  loss_ce_0: 0  loss_mask_0: 1.22  loss_dice_0: 3.499  loss_ce_1: 0  loss_mask_1: 1.235  loss_dice_1: 3.394  loss_ce_2: 0  loss_mask_2: 1.229  loss_dice_2: 3.382  loss_ce_3: 0  loss_mask_3: 1.23  loss_dice_3: 3.368  loss_ce_4: 0  loss_mask_4: 1.228  loss_dice_4: 3.371  loss_ce_5: 0  loss_mask_5: 1.232  loss_dice_5: 3.374  loss_ce_6: 0  loss_mask_6: 1.235  loss_dice_6: 3.371  loss_ce_7: 0  loss_mask_7: 1.232  loss_dice_7: 3.377  loss_ce_8: 0  loss_mask_8: 1.232  loss_dice_8: 3.379  time: 1.9174  data_time: 0.0364  lr: 9.7328e-05  max_mem: 5999M
[02/18 00:03:51] d2.utils.events INFO:  eta: 1 day, 7:06:09  iter: 1799  total_loss: 49.32  loss_ce: 0  loss_mask: 1.315  loss_dice: 3.485  loss_seg: 1.218  loss_ce_0: 0  loss_mask_0: 1.301  loss_dice_0: 3.53  loss_ce_1: 0  loss_mask_1: 1.333  loss_dice_1: 3.45  loss_ce_2: 0  loss_mask_2: 1.335  loss_dice_2: 3.449  loss_ce_3: 0  loss_mask_3: 1.341  loss_dice_3: 3.445  loss_ce_4: 0  loss_mask_4: 1.338  loss_dice_4: 3.447  loss_ce_5: 0  loss_mask_5: 1.34  loss_dice_5: 3.446  loss_ce_6: 0  loss_mask_6: 1.334  loss_dice_6: 3.456  loss_ce_7: 0  loss_mask_7: 1.331  loss_dice_7: 3.451  loss_ce_8: 0  loss_mask_8: 1.329  loss_dice_8: 3.448  time: 1.9334  data_time: 0.0388  lr: 9.7297e-05  max_mem: 5999M
[02/18 00:04:56] d2.utils.events INFO:  eta: 1 day, 7:26:44  iter: 1819  total_loss: 47.46  loss_ce: 0  loss_mask: 1.252  loss_dice: 3.389  loss_seg: 1.282  loss_ce_0: 0  loss_mask_0: 1.243  loss_dice_0: 3.463  loss_ce_1: 0  loss_mask_1: 1.242  loss_dice_1: 3.36  loss_ce_2: 0  loss_mask_2: 1.254  loss_dice_2: 3.345  loss_ce_3: 0  loss_mask_3: 1.252  loss_dice_3: 3.339  loss_ce_4: 0  loss_mask_4: 1.26  loss_dice_4: 3.344  loss_ce_5: 0  loss_mask_5: 1.254  loss_dice_5: 3.355  loss_ce_6: 0  loss_mask_6: 1.259  loss_dice_6: 3.344  loss_ce_7: 0  loss_mask_7: 1.253  loss_dice_7: 3.343  loss_ce_8: 0  loss_mask_8: 1.25  loss_dice_8: 3.351  time: 1.9480  data_time: 0.0356  lr: 9.7267e-05  max_mem: 5999M
[02/18 00:06:03] d2.utils.events INFO:  eta: 1 day, 7:49:23  iter: 1839  total_loss: 48.98  loss_ce: 0  loss_mask: 1.298  loss_dice: 3.475  loss_seg: 1.217  loss_ce_0: 0  loss_mask_0: 1.289  loss_dice_0: 3.52  loss_ce_1: 0  loss_mask_1: 1.311  loss_dice_1: 3.444  loss_ce_2: 0  loss_mask_2: 1.307  loss_dice_2: 3.439  loss_ce_3: 0  loss_mask_3: 1.308  loss_dice_3: 3.436  loss_ce_4: 0  loss_mask_4: 1.306  loss_dice_4: 3.445  loss_ce_5: 0  loss_mask_5: 1.316  loss_dice_5: 3.449  loss_ce_6: 0  loss_mask_6: 1.312  loss_dice_6: 3.445  loss_ce_7: 0  loss_mask_7: 1.312  loss_dice_7: 3.447  loss_ce_8: 0  loss_mask_8: 1.303  loss_dice_8: 3.44  time: 1.9630  data_time: 0.0320  lr: 9.7237e-05  max_mem: 5999M
[02/18 00:07:12] d2.utils.events INFO:  eta: 1 day, 8:16:58  iter: 1859  total_loss: 47.52  loss_ce: 0  loss_mask: 1.276  loss_dice: 3.39  loss_seg: 0.8389  loss_ce_0: 0  loss_mask_0: 1.25  loss_dice_0: 3.452  loss_ce_1: 0  loss_mask_1: 1.276  loss_dice_1: 3.357  loss_ce_2: 0  loss_mask_2: 1.285  loss_dice_2: 3.357  loss_ce_3: 0  loss_mask_3: 1.29  loss_dice_3: 3.35  loss_ce_4: 0  loss_mask_4: 1.29  loss_dice_4: 3.357  loss_ce_5: 0  loss_mask_5: 1.29  loss_dice_5: 3.361  loss_ce_6: 0  loss_mask_6: 1.283  loss_dice_6: 3.367  loss_ce_7: 0  loss_mask_7: 1.287  loss_dice_7: 3.366  loss_ce_8: 0  loss_mask_8: 1.284  loss_dice_8: 3.369  time: 1.9791  data_time: 0.0374  lr: 9.7207e-05  max_mem: 5999M
[02/18 00:08:23] d2.utils.events INFO:  eta: 1 day, 8:41:19  iter: 1879  total_loss: 48.52  loss_ce: 0  loss_mask: 1.258  loss_dice: 3.457  loss_seg: 1.064  loss_ce_0: 0  loss_mask_0: 1.254  loss_dice_0: 3.519  loss_ce_1: 0  loss_mask_1: 1.268  loss_dice_1: 3.444  loss_ce_2: 0  loss_mask_2: 1.264  loss_dice_2: 3.433  loss_ce_3: 0  loss_mask_3: 1.271  loss_dice_3: 3.427  loss_ce_4: 0  loss_mask_4: 1.268  loss_dice_4: 3.429  loss_ce_5: 0  loss_mask_5: 1.267  loss_dice_5: 3.435  loss_ce_6: 0  loss_mask_6: 1.257  loss_dice_6: 3.436  loss_ce_7: 0  loss_mask_7: 1.267  loss_dice_7: 3.432  loss_ce_8: 0  loss_mask_8: 1.266  loss_dice_8: 3.436  time: 1.9957  data_time: 0.0362  lr: 9.7177e-05  max_mem: 5999M
[02/18 00:09:31] d2.utils.events INFO:  eta: 1 day, 9:04:09  iter: 1899  total_loss: 47.26  loss_ce: 0  loss_mask: 1.266  loss_dice: 3.386  loss_seg: 0.9455  loss_ce_0: 0  loss_mask_0: 1.267  loss_dice_0: 3.447  loss_ce_1: 0  loss_mask_1: 1.274  loss_dice_1: 3.36  loss_ce_2: 0  loss_mask_2: 1.278  loss_dice_2: 3.349  loss_ce_3: 0  loss_mask_3: 1.295  loss_dice_3: 3.342  loss_ce_4: 0  loss_mask_4: 1.288  loss_dice_4: 3.346  loss_ce_5: 0  loss_mask_5: 1.291  loss_dice_5: 3.344  loss_ce_6: 0  loss_mask_6: 1.285  loss_dice_6: 3.34  loss_ce_7: 0  loss_mask_7: 1.29  loss_dice_7: 3.341  loss_ce_8: 0  loss_mask_8: 1.282  loss_dice_8: 3.342  time: 2.0103  data_time: 0.0470  lr: 9.7147e-05  max_mem: 5999M
[02/18 00:10:33] d2.utils.events INFO:  eta: 1 day, 9:43:06  iter: 1919  total_loss: 48.41  loss_ce: 0  loss_mask: 1.27  loss_dice: 3.459  loss_seg: 1.247  loss_ce_0: 0  loss_mask_0: 1.252  loss_dice_0: 3.511  loss_ce_1: 0  loss_mask_1: 1.292  loss_dice_1: 3.434  loss_ce_2: 0  loss_mask_2: 1.291  loss_dice_2: 3.422  loss_ce_3: 0  loss_mask_3: 1.304  loss_dice_3: 3.423  loss_ce_4: 0  loss_mask_4: 1.297  loss_dice_4: 3.42  loss_ce_5: 0  loss_mask_5: 1.298  loss_dice_5: 3.417  loss_ce_6: 0  loss_mask_6: 1.3  loss_dice_6: 3.427  loss_ce_7: 0  loss_mask_7: 1.293  loss_dice_7: 3.431  loss_ce_8: 0  loss_mask_8: 1.295  loss_dice_8: 3.434  time: 2.0217  data_time: 0.0443  lr: 9.7117e-05  max_mem: 5999M
[02/18 00:11:07] d2.utils.events INFO:  eta: 1 day, 9:42:25  iter: 1939  total_loss: 47.56  loss_ce: 0  loss_mask: 1.284  loss_dice: 3.367  loss_seg: 1.088  loss_ce_0: 0  loss_mask_0: 1.267  loss_dice_0: 3.46  loss_ce_1: 0  loss_mask_1: 1.287  loss_dice_1: 3.346  loss_ce_2: 0  loss_mask_2: 1.285  loss_dice_2: 3.336  loss_ce_3: 0  loss_mask_3: 1.285  loss_dice_3: 3.322  loss_ce_4: 0  loss_mask_4: 1.287  loss_dice_4: 3.333  loss_ce_5: 0  loss_mask_5: 1.284  loss_dice_5: 3.327  loss_ce_6: 0  loss_mask_6: 1.289  loss_dice_6: 3.334  loss_ce_7: 0  loss_mask_7: 1.286  loss_dice_7: 3.331  loss_ce_8: 0  loss_mask_8: 1.288  loss_dice_8: 3.336  time: 2.0182  data_time: 0.0302  lr: 9.7087e-05  max_mem: 5999M
[02/18 00:11:40] d2.utils.events INFO:  eta: 1 day, 9:39:48  iter: 1959  total_loss: 48.76  loss_ce: 0  loss_mask: 1.281  loss_dice: 3.453  loss_seg: 0.9393  loss_ce_0: 0  loss_mask_0: 1.274  loss_dice_0: 3.512  loss_ce_1: 0  loss_mask_1: 1.285  loss_dice_1: 3.438  loss_ce_2: 0  loss_mask_2: 1.293  loss_dice_2: 3.432  loss_ce_3: 0  loss_mask_3: 1.298  loss_dice_3: 3.427  loss_ce_4: 0  loss_mask_4: 1.297  loss_dice_4: 3.43  loss_ce_5: 0  loss_mask_5: 1.3  loss_dice_5: 3.435  loss_ce_6: 0  loss_mask_6: 1.299  loss_dice_6: 3.438  loss_ce_7: 0  loss_mask_7: 1.297  loss_dice_7: 3.436  loss_ce_8: 0  loss_mask_8: 1.299  loss_dice_8: 3.439  time: 2.0144  data_time: 0.0416  lr: 9.7057e-05  max_mem: 5999M
[02/18 00:12:15] d2.utils.events INFO:  eta: 1 day, 9:41:01  iter: 1979  total_loss: 47.2  loss_ce: 0  loss_mask: 1.292  loss_dice: 3.384  loss_seg: 0.8732  loss_ce_0: 0  loss_mask_0: 1.285  loss_dice_0: 3.448  loss_ce_1: 0  loss_mask_1: 1.302  loss_dice_1: 3.364  loss_ce_2: 0  loss_mask_2: 1.299  loss_dice_2: 3.357  loss_ce_3: 0  loss_mask_3: 1.309  loss_dice_3: 3.36  loss_ce_4: 0  loss_mask_4: 1.309  loss_dice_4: 3.357  loss_ce_5: 0  loss_mask_5: 1.308  loss_dice_5: 3.345  loss_ce_6: 0  loss_mask_6: 1.312  loss_dice_6: 3.352  loss_ce_7: 0  loss_mask_7: 1.305  loss_dice_7: 3.352  loss_ce_8: 0  loss_mask_8: 1.307  loss_dice_8: 3.349  time: 2.0115  data_time: 0.0358  lr: 9.7027e-05  max_mem: 5999M
[02/18 00:12:47] d2.utils.events INFO:  eta: 1 day, 9:35:54  iter: 1999  total_loss: 47.19  loss_ce: 0  loss_mask: 1.278  loss_dice: 3.274  loss_seg: 1.238  loss_ce_0: 0  loss_mask_0: 1.263  loss_dice_0: 3.37  loss_ce_1: 0  loss_mask_1: 1.285  loss_dice_1: 3.244  loss_ce_2: 0  loss_mask_2: 1.287  loss_dice_2: 3.241  loss_ce_3: 0  loss_mask_3: 1.289  loss_dice_3: 3.247  loss_ce_4: 0  loss_mask_4: 1.293  loss_dice_4: 3.253  loss_ce_5: 0  loss_mask_5: 1.29  loss_dice_5: 3.259  loss_ce_6: 0  loss_mask_6: 1.295  loss_dice_6: 3.264  loss_ce_7: 0  loss_mask_7: 1.292  loss_dice_7: 3.262  loss_ce_8: 0  loss_mask_8: 1.292  loss_dice_8: 3.255  time: 2.0077  data_time: 0.0299  lr: 9.6996e-05  max_mem: 5999M
[02/18 00:13:23] d2.utils.events INFO:  eta: 1 day, 9:28:38  iter: 2019  total_loss: 47.4  loss_ce: 0  loss_mask: 1.259  loss_dice: 3.347  loss_seg: 1.266  loss_ce_0: 0  loss_mask_0: 1.25  loss_dice_0: 3.43  loss_ce_1: 0  loss_mask_1: 1.273  loss_dice_1: 3.335  loss_ce_2: 0  loss_mask_2: 1.268  loss_dice_2: 3.311  loss_ce_3: 0  loss_mask_3: 1.277  loss_dice_3: 3.301  loss_ce_4: 0  loss_mask_4: 1.268  loss_dice_4: 3.312  loss_ce_5: 0  loss_mask_5: 1.275  loss_dice_5: 3.308  loss_ce_6: 0  loss_mask_6: 1.27  loss_dice_6: 3.305  loss_ce_7: 0  loss_mask_7: 1.273  loss_dice_7: 3.306  loss_ce_8: 0  loss_mask_8: 1.27  loss_dice_8: 3.312  time: 2.0054  data_time: 0.0397  lr: 9.6966e-05  max_mem: 5999M
[02/18 00:13:57] d2.utils.events INFO:  eta: 1 day, 8:46:30  iter: 2039  total_loss: 47.17  loss_ce: 0  loss_mask: 1.241  loss_dice: 3.335  loss_seg: 1.254  loss_ce_0: 0  loss_mask_0: 1.239  loss_dice_0: 3.422  loss_ce_1: 0  loss_mask_1: 1.249  loss_dice_1: 3.29  loss_ce_2: 0  loss_mask_2: 1.241  loss_dice_2: 3.286  loss_ce_3: 0  loss_mask_3: 1.247  loss_dice_3: 3.272  loss_ce_4: 0  loss_mask_4: 1.251  loss_dice_4: 3.275  loss_ce_5: 0  loss_mask_5: 1.244  loss_dice_5: 3.295  loss_ce_6: 0  loss_mask_6: 1.247  loss_dice_6: 3.287  loss_ce_7: 0  loss_mask_7: 1.243  loss_dice_7: 3.295  loss_ce_8: 0  loss_mask_8: 1.248  loss_dice_8: 3.295  time: 2.0025  data_time: 0.0448  lr: 9.6936e-05  max_mem: 5999M
[02/18 00:14:35] d2.utils.events INFO:  eta: 1 day, 8:23:21  iter: 2059  total_loss: 47.78  loss_ce: 0  loss_mask: 1.285  loss_dice: 3.392  loss_seg: 1.07  loss_ce_0: 0  loss_mask_0: 1.282  loss_dice_0: 3.442  loss_ce_1: 0  loss_mask_1: 1.296  loss_dice_1: 3.361  loss_ce_2: 0  loss_mask_2: 1.293  loss_dice_2: 3.348  loss_ce_3: 0  loss_mask_3: 1.299  loss_dice_3: 3.346  loss_ce_4: 0  loss_mask_4: 1.294  loss_dice_4: 3.342  loss_ce_5: 0  loss_mask_5: 1.297  loss_dice_5: 3.344  loss_ce_6: 0  loss_mask_6: 1.293  loss_dice_6: 3.346  loss_ce_7: 0  loss_mask_7: 1.297  loss_dice_7: 3.352  loss_ce_8: 0  loss_mask_8: 1.29  loss_dice_8: 3.36  time: 2.0012  data_time: 0.0357  lr: 9.6906e-05  max_mem: 5999M
[02/18 00:15:41] d2.utils.events INFO:  eta: 1 day, 8:27:47  iter: 2079  total_loss: 46.46  loss_ce: 0  loss_mask: 1.251  loss_dice: 3.335  loss_seg: 1.211  loss_ce_0: 0  loss_mask_0: 1.247  loss_dice_0: 3.397  loss_ce_1: 0  loss_mask_1: 1.26  loss_dice_1: 3.295  loss_ce_2: 0  loss_mask_2: 1.256  loss_dice_2: 3.284  loss_ce_3: 0  loss_mask_3: 1.262  loss_dice_3: 3.284  loss_ce_4: 0  loss_mask_4: 1.264  loss_dice_4: 3.287  loss_ce_5: 0  loss_mask_5: 1.264  loss_dice_5: 3.295  loss_ce_6: 0  loss_mask_6: 1.26  loss_dice_6: 3.3  loss_ce_7: 0  loss_mask_7: 1.261  loss_dice_7: 3.301  loss_ce_8: 0  loss_mask_8: 1.263  loss_dice_8: 3.305  time: 2.0138  data_time: 0.0298  lr: 9.6876e-05  max_mem: 5999M
[02/18 00:16:44] d2.utils.events INFO:  eta: 1 day, 8:29:37  iter: 2099  total_loss: 46.89  loss_ce: 0  loss_mask: 1.263  loss_dice: 3.291  loss_seg: 1.143  loss_ce_0: 0  loss_mask_0: 1.25  loss_dice_0: 3.358  loss_ce_1: 0  loss_mask_1: 1.271  loss_dice_1: 3.28  loss_ce_2: 0  loss_mask_2: 1.272  loss_dice_2: 3.264  loss_ce_3: 0  loss_mask_3: 1.276  loss_dice_3: 3.258  loss_ce_4: 0  loss_mask_4: 1.278  loss_dice_4: 3.262  loss_ce_5: 0  loss_mask_5: 1.28  loss_dice_5: 3.261  loss_ce_6: 0  loss_mask_6: 1.28  loss_dice_6: 3.261  loss_ce_7: 0  loss_mask_7: 1.28  loss_dice_7: 3.258  loss_ce_8: 0  loss_mask_8: 1.276  loss_dice_8: 3.26  time: 2.0244  data_time: 0.0299  lr: 9.6846e-05  max_mem: 5999M
[02/18 00:17:47] d2.utils.events INFO:  eta: 1 day, 8:28:56  iter: 2119  total_loss: 46.54  loss_ce: 0  loss_mask: 1.257  loss_dice: 3.33  loss_seg: 1.108  loss_ce_0: 0  loss_mask_0: 1.234  loss_dice_0: 3.422  loss_ce_1: 0  loss_mask_1: 1.257  loss_dice_1: 3.306  loss_ce_2: 0  loss_mask_2: 1.257  loss_dice_2: 3.294  loss_ce_3: 0  loss_mask_3: 1.258  loss_dice_3: 3.287  loss_ce_4: 0  loss_mask_4: 1.263  loss_dice_4: 3.294  loss_ce_5: 0  loss_mask_5: 1.266  loss_dice_5: 3.299  loss_ce_6: 0  loss_mask_6: 1.262  loss_dice_6: 3.295  loss_ce_7: 0  loss_mask_7: 1.263  loss_dice_7: 3.291  loss_ce_8: 0  loss_mask_8: 1.265  loss_dice_8: 3.3  time: 2.0353  data_time: 0.0408  lr: 9.6816e-05  max_mem: 5999M
[02/18 00:18:56] d2.utils.events INFO:  eta: 1 day, 8:26:38  iter: 2139  total_loss: 46.14  loss_ce: 0  loss_mask: 1.216  loss_dice: 3.287  loss_seg: 0.8904  loss_ce_0: 0  loss_mask_0: 1.212  loss_dice_0: 3.358  loss_ce_1: 0  loss_mask_1: 1.229  loss_dice_1: 3.252  loss_ce_2: 0  loss_mask_2: 1.219  loss_dice_2: 3.247  loss_ce_3: 0  loss_mask_3: 1.228  loss_dice_3: 3.242  loss_ce_4: 0  loss_mask_4: 1.233  loss_dice_4: 3.242  loss_ce_5: 0  loss_mask_5: 1.234  loss_dice_5: 3.244  loss_ce_6: 0  loss_mask_6: 1.237  loss_dice_6: 3.248  loss_ce_7: 0  loss_mask_7: 1.228  loss_dice_7: 3.251  loss_ce_8: 0  loss_mask_8: 1.225  loss_dice_8: 3.249  time: 2.0482  data_time: 0.0326  lr: 9.6786e-05  max_mem: 5999M
[02/18 00:19:59] d2.utils.events INFO:  eta: 1 day, 8:25:58  iter: 2159  total_loss: 45.29  loss_ce: 0  loss_mask: 1.167  loss_dice: 3.292  loss_seg: 0.985  loss_ce_0: 0  loss_mask_0: 1.157  loss_dice_0: 3.407  loss_ce_1: 0  loss_mask_1: 1.174  loss_dice_1: 3.274  loss_ce_2: 0  loss_mask_2: 1.176  loss_dice_2: 3.255  loss_ce_3: 0  loss_mask_3: 1.183  loss_dice_3: 3.244  loss_ce_4: 0  loss_mask_4: 1.18  loss_dice_4: 3.251  loss_ce_5: 0  loss_mask_5: 1.176  loss_dice_5: 3.252  loss_ce_6: 0  loss_mask_6: 1.18  loss_dice_6: 3.249  loss_ce_7: 0  loss_mask_7: 1.186  loss_dice_7: 3.25  loss_ce_8: 0  loss_mask_8: 1.18  loss_dice_8: 3.251  time: 2.0583  data_time: 0.0345  lr: 9.6756e-05  max_mem: 5999M
[02/18 00:21:07] d2.utils.events INFO:  eta: 1 day, 8:25:17  iter: 2179  total_loss: 45.85  loss_ce: 0  loss_mask: 1.263  loss_dice: 3.248  loss_seg: 0.9324  loss_ce_0: 0  loss_mask_0: 1.242  loss_dice_0: 3.32  loss_ce_1: 0  loss_mask_1: 1.259  loss_dice_1: 3.219  loss_ce_2: 0  loss_mask_2: 1.258  loss_dice_2: 3.212  loss_ce_3: 0  loss_mask_3: 1.256  loss_dice_3: 3.204  loss_ce_4: 0  loss_mask_4: 1.256  loss_dice_4: 3.203  loss_ce_5: 0  loss_mask_5: 1.26  loss_dice_5: 3.211  loss_ce_6: 0  loss_mask_6: 1.272  loss_dice_6: 3.207  loss_ce_7: 0  loss_mask_7: 1.276  loss_dice_7: 3.209  loss_ce_8: 0  loss_mask_8: 1.279  loss_dice_8: 3.211  time: 2.0707  data_time: 0.0378  lr: 9.6725e-05  max_mem: 5999M
[02/18 00:22:16] d2.utils.events INFO:  eta: 1 day, 8:24:37  iter: 2199  total_loss: 47.06  loss_ce: 0  loss_mask: 1.272  loss_dice: 3.314  loss_seg: 0.8195  loss_ce_0: 0  loss_mask_0: 1.257  loss_dice_0: 3.356  loss_ce_1: 0  loss_mask_1: 1.275  loss_dice_1: 3.299  loss_ce_2: 0  loss_mask_2: 1.278  loss_dice_2: 3.291  loss_ce_3: 0  loss_mask_3: 1.276  loss_dice_3: 3.282  loss_ce_4: 0  loss_mask_4: 1.28  loss_dice_4: 3.288  loss_ce_5: 0  loss_mask_5: 1.282  loss_dice_5: 3.294  loss_ce_6: 0  loss_mask_6: 1.282  loss_dice_6: 3.289  loss_ce_7: 0  loss_mask_7: 1.285  loss_dice_7: 3.285  loss_ce_8: 0  loss_mask_8: 1.285  loss_dice_8: 3.283  time: 2.0835  data_time: 0.0389  lr: 9.6695e-05  max_mem: 5999M
[02/18 00:23:21] d2.utils.events INFO:  eta: 1 day, 8:23:57  iter: 2219  total_loss: 46.61  loss_ce: 0  loss_mask: 1.264  loss_dice: 3.355  loss_seg: 1.217  loss_ce_0: 0  loss_mask_0: 1.24  loss_dice_0: 3.394  loss_ce_1: 0  loss_mask_1: 1.26  loss_dice_1: 3.34  loss_ce_2: 0  loss_mask_2: 1.269  loss_dice_2: 3.339  loss_ce_3: 0  loss_mask_3: 1.266  loss_dice_3: 3.335  loss_ce_4: 0  loss_mask_4: 1.265  loss_dice_4: 3.338  loss_ce_5: 0  loss_mask_5: 1.276  loss_dice_5: 3.341  loss_ce_6: 0  loss_mask_6: 1.268  loss_dice_6: 3.338  loss_ce_7: 0  loss_mask_7: 1.269  loss_dice_7: 3.335  loss_ce_8: 0  loss_mask_8: 1.271  loss_dice_8: 3.337  time: 2.0938  data_time: 0.0411  lr: 9.6665e-05  max_mem: 5999M
[02/18 00:24:32] d2.utils.events INFO:  eta: 1 day, 8:26:58  iter: 2239  total_loss: 45.73  loss_ce: 0  loss_mask: 1.271  loss_dice: 3.237  loss_seg: 0.905  loss_ce_0: 0  loss_mask_0: 1.272  loss_dice_0: 3.298  loss_ce_1: 0  loss_mask_1: 1.277  loss_dice_1: 3.212  loss_ce_2: 0  loss_mask_2: 1.274  loss_dice_2: 3.212  loss_ce_3: 0  loss_mask_3: 1.278  loss_dice_3: 3.209  loss_ce_4: 0  loss_mask_4: 1.279  loss_dice_4: 3.216  loss_ce_5: 0  loss_mask_5: 1.273  loss_dice_5: 3.214  loss_ce_6: 0  loss_mask_6: 1.284  loss_dice_6: 3.206  loss_ce_7: 0  loss_mask_7: 1.284  loss_dice_7: 3.205  loss_ce_8: 0  loss_mask_8: 1.282  loss_dice_8: 3.208  time: 2.1066  data_time: 0.0284  lr: 9.6635e-05  max_mem: 5999M
[02/18 00:25:42] d2.utils.events INFO:  eta: 1 day, 8:44:47  iter: 2259  total_loss: 46.78  loss_ce: 0  loss_mask: 1.274  loss_dice: 3.268  loss_seg: 1.171  loss_ce_0: 0  loss_mask_0: 1.262  loss_dice_0: 3.325  loss_ce_1: 0  loss_mask_1: 1.272  loss_dice_1: 3.213  loss_ce_2: 0  loss_mask_2: 1.264  loss_dice_2: 3.215  loss_ce_3: 0  loss_mask_3: 1.27  loss_dice_3: 3.223  loss_ce_4: 0  loss_mask_4: 1.278  loss_dice_4: 3.221  loss_ce_5: 0  loss_mask_5: 1.273  loss_dice_5: 3.234  loss_ce_6: 0  loss_mask_6: 1.275  loss_dice_6: 3.231  loss_ce_7: 0  loss_mask_7: 1.278  loss_dice_7: 3.232  loss_ce_8: 0  loss_mask_8: 1.279  loss_dice_8: 3.236  time: 2.1189  data_time: 0.0355  lr: 9.6605e-05  max_mem: 5999M
[02/18 00:26:35] d2.utils.events INFO:  eta: 1 day, 9:19:10  iter: 2279  total_loss: 46.44  loss_ce: 0  loss_mask: 1.27  loss_dice: 3.294  loss_seg: 0.8511  loss_ce_0: 0  loss_mask_0: 1.261  loss_dice_0: 3.366  loss_ce_1: 0  loss_mask_1: 1.278  loss_dice_1: 3.262  loss_ce_2: 0  loss_mask_2: 1.29  loss_dice_2: 3.241  loss_ce_3: 0  loss_mask_3: 1.29  loss_dice_3: 3.238  loss_ce_4: 0  loss_mask_4: 1.283  loss_dice_4: 3.243  loss_ce_5: 0  loss_mask_5: 1.278  loss_dice_5: 3.249  loss_ce_6: 0  loss_mask_6: 1.284  loss_dice_6: 3.248  loss_ce_7: 0  loss_mask_7: 1.28  loss_dice_7: 3.238  loss_ce_8: 0  loss_mask_8: 1.275  loss_dice_8: 3.25  time: 2.1235  data_time: 0.0365  lr: 9.6575e-05  max_mem: 5999M
[02/18 00:27:08] d2.utils.events INFO:  eta: 1 day, 9:19:40  iter: 2299  total_loss: 45.26  loss_ce: 0  loss_mask: 1.24  loss_dice: 3.168  loss_seg: 0.9495  loss_ce_0: 0  loss_mask_0: 1.228  loss_dice_0: 3.28  loss_ce_1: 0  loss_mask_1: 1.247  loss_dice_1: 3.167  loss_ce_2: 0  loss_mask_2: 1.249  loss_dice_2: 3.141  loss_ce_3: 0  loss_mask_3: 1.254  loss_dice_3: 3.128  loss_ce_4: 0  loss_mask_4: 1.251  loss_dice_4: 3.135  loss_ce_5: 0  loss_mask_5: 1.254  loss_dice_5: 3.13  loss_ce_6: 0  loss_mask_6: 1.249  loss_dice_6: 3.134  loss_ce_7: 0  loss_mask_7: 1.251  loss_dice_7: 3.131  loss_ce_8: 0  loss_mask_8: 1.249  loss_dice_8: 3.132  time: 2.1194  data_time: 0.0347  lr: 9.6545e-05  max_mem: 5999M
[02/18 00:27:41] d2.utils.events INFO:  eta: 1 day, 9:18:59  iter: 2319  total_loss: 44.79  loss_ce: 0  loss_mask: 1.238  loss_dice: 3.179  loss_seg: 0.9628  loss_ce_0: 0  loss_mask_0: 1.221  loss_dice_0: 3.28  loss_ce_1: 0  loss_mask_1: 1.235  loss_dice_1: 3.161  loss_ce_2: 0  loss_mask_2: 1.24  loss_dice_2: 3.144  loss_ce_3: 0  loss_mask_3: 1.238  loss_dice_3: 3.138  loss_ce_4: 0  loss_mask_4: 1.239  loss_dice_4: 3.138  loss_ce_5: 0  loss_mask_5: 1.244  loss_dice_5: 3.139  loss_ce_6: 0  loss_mask_6: 1.241  loss_dice_6: 3.147  loss_ce_7: 0  loss_mask_7: 1.247  loss_dice_7: 3.146  loss_ce_8: 0  loss_mask_8: 1.247  loss_dice_8: 3.15  time: 2.1154  data_time: 0.0388  lr: 9.6515e-05  max_mem: 5999M
[02/18 00:28:15] d2.utils.events INFO:  eta: 1 day, 9:17:05  iter: 2339  total_loss: 46.93  loss_ce: 0  loss_mask: 1.25  loss_dice: 3.263  loss_seg: 0.9133  loss_ce_0: 0  loss_mask_0: 1.238  loss_dice_0: 3.314  loss_ce_1: 0  loss_mask_1: 1.252  loss_dice_1: 3.247  loss_ce_2: 0  loss_mask_2: 1.258  loss_dice_2: 3.241  loss_ce_3: 0  loss_mask_3: 1.259  loss_dice_3: 3.247  loss_ce_4: 0  loss_mask_4: 1.262  loss_dice_4: 3.244  loss_ce_5: 0  loss_mask_5: 1.258  loss_dice_5: 3.244  loss_ce_6: 0  loss_mask_6: 1.262  loss_dice_6: 3.242  loss_ce_7: 0  loss_mask_7: 1.259  loss_dice_7: 3.243  loss_ce_8: 0  loss_mask_8: 1.262  loss_dice_8: 3.239  time: 2.1118  data_time: 0.0359  lr: 9.6485e-05  max_mem: 5999M
[02/18 00:28:47] d2.utils.events INFO:  eta: 1 day, 9:09:32  iter: 2359  total_loss: 46.49  loss_ce: 0  loss_mask: 1.219  loss_dice: 3.288  loss_seg: 1.155  loss_ce_0: 0  loss_mask_0: 1.204  loss_dice_0: 3.358  loss_ce_1: 0  loss_mask_1: 1.216  loss_dice_1: 3.273  loss_ce_2: 0  loss_mask_2: 1.222  loss_dice_2: 3.26  loss_ce_3: 0  loss_mask_3: 1.235  loss_dice_3: 3.237  loss_ce_4: 0  loss_mask_4: 1.227  loss_dice_4: 3.245  loss_ce_5: 0  loss_mask_5: 1.229  loss_dice_5: 3.24  loss_ce_6: 0  loss_mask_6: 1.23  loss_dice_6: 3.243  loss_ce_7: 0  loss_mask_7: 1.229  loss_dice_7: 3.258  loss_ce_8: 0  loss_mask_8: 1.23  loss_dice_8: 3.252  time: 2.1077  data_time: 0.0353  lr: 9.6454e-05  max_mem: 5999M
[02/18 00:29:20] d2.utils.events INFO:  eta: 1 day, 9:01:17  iter: 2379  total_loss: 46.25  loss_ce: 0  loss_mask: 1.192  loss_dice: 3.292  loss_seg: 1.392  loss_ce_0: 0  loss_mask_0: 1.178  loss_dice_0: 3.352  loss_ce_1: 0  loss_mask_1: 1.199  loss_dice_1: 3.257  loss_ce_2: 0  loss_mask_2: 1.201  loss_dice_2: 3.251  loss_ce_3: 0  loss_mask_3: 1.204  loss_dice_3: 3.247  loss_ce_4: 0  loss_mask_4: 1.201  loss_dice_4: 3.253  loss_ce_5: 0  loss_mask_5: 1.199  loss_dice_5: 3.261  loss_ce_6: 0  loss_mask_6: 1.204  loss_dice_6: 3.257  loss_ce_7: 0  loss_mask_7: 1.202  loss_dice_7: 3.259  loss_ce_8: 0  loss_mask_8: 1.209  loss_dice_8: 3.264  time: 2.1035  data_time: 0.0360  lr: 9.6424e-05  max_mem: 5999M
[02/18 00:29:54] d2.utils.events INFO:  eta: 1 day, 8:54:23  iter: 2399  total_loss: 46.1  loss_ce: 0  loss_mask: 1.232  loss_dice: 3.301  loss_seg: 1.071  loss_ce_0: 0  loss_mask_0: 1.235  loss_dice_0: 3.34  loss_ce_1: 0  loss_mask_1: 1.23  loss_dice_1: 3.272  loss_ce_2: 0  loss_mask_2: 1.222  loss_dice_2: 3.268  loss_ce_3: 0  loss_mask_3: 1.235  loss_dice_3: 3.269  loss_ce_4: 0  loss_mask_4: 1.24  loss_dice_4: 3.266  loss_ce_5: 0  loss_mask_5: 1.24  loss_dice_5: 3.268  loss_ce_6: 0  loss_mask_6: 1.242  loss_dice_6: 3.279  loss_ce_7: 0  loss_mask_7: 1.243  loss_dice_7: 3.27  loss_ce_8: 0  loss_mask_8: 1.239  loss_dice_8: 3.281  time: 2.1000  data_time: 0.0339  lr: 9.6394e-05  max_mem: 5999M
[02/18 00:30:29] d2.utils.events INFO:  eta: 1 day, 8:53:42  iter: 2419  total_loss: 45.99  loss_ce: 0  loss_mask: 1.241  loss_dice: 3.233  loss_seg: 1.019  loss_ce_0: 0  loss_mask_0: 1.237  loss_dice_0: 3.315  loss_ce_1: 0  loss_mask_1: 1.266  loss_dice_1: 3.214  loss_ce_2: 0  loss_mask_2: 1.258  loss_dice_2: 3.21  loss_ce_3: 0  loss_mask_3: 1.256  loss_dice_3: 3.207  loss_ce_4: 0  loss_mask_4: 1.265  loss_dice_4: 3.208  loss_ce_5: 0  loss_mask_5: 1.268  loss_dice_5: 3.213  loss_ce_6: 0  loss_mask_6: 1.267  loss_dice_6: 3.212  loss_ce_7: 0  loss_mask_7: 1.272  loss_dice_7: 3.209  loss_ce_8: 0  loss_mask_8: 1.262  loss_dice_8: 3.215  time: 2.0972  data_time: 0.0346  lr: 9.6364e-05  max_mem: 5999M
[02/18 00:31:01] d2.utils.events INFO:  eta: 1 day, 8:49:31  iter: 2439  total_loss: 46.5  loss_ce: 0  loss_mask: 1.157  loss_dice: 3.291  loss_seg: 1.255  loss_ce_0: 0  loss_mask_0: 1.147  loss_dice_0: 3.337  loss_ce_1: 0  loss_mask_1: 1.167  loss_dice_1: 3.268  loss_ce_2: 0  loss_mask_2: 1.172  loss_dice_2: 3.268  loss_ce_3: 0  loss_mask_3: 1.17  loss_dice_3: 3.264  loss_ce_4: 0  loss_mask_4: 1.174  loss_dice_4: 3.267  loss_ce_5: 0  loss_mask_5: 1.165  loss_dice_5: 3.265  loss_ce_6: 0  loss_mask_6: 1.167  loss_dice_6: 3.273  loss_ce_7: 0  loss_mask_7: 1.169  loss_dice_7: 3.275  loss_ce_8: 0  loss_mask_8: 1.167  loss_dice_8: 3.276  time: 2.0933  data_time: 0.0312  lr: 9.6334e-05  max_mem: 5999M
[02/18 00:31:35] d2.utils.events INFO:  eta: 1 day, 8:48:50  iter: 2459  total_loss: 44.75  loss_ce: 0  loss_mask: 1.21  loss_dice: 3.156  loss_seg: 1.108  loss_ce_0: 0  loss_mask_0: 1.223  loss_dice_0: 3.255  loss_ce_1: 0  loss_mask_1: 1.214  loss_dice_1: 3.133  loss_ce_2: 0  loss_mask_2: 1.216  loss_dice_2: 3.126  loss_ce_3: 0  loss_mask_3: 1.222  loss_dice_3: 3.118  loss_ce_4: 0  loss_mask_4: 1.221  loss_dice_4: 3.122  loss_ce_5: 0  loss_mask_5: 1.222  loss_dice_5: 3.123  loss_ce_6: 0  loss_mask_6: 1.229  loss_dice_6: 3.111  loss_ce_7: 0  loss_mask_7: 1.228  loss_dice_7: 3.113  loss_ce_8: 0  loss_mask_8: 1.227  loss_dice_8: 3.118  time: 2.0899  data_time: 0.0350  lr: 9.6304e-05  max_mem: 5999M
[02/18 00:32:09] d2.utils.events INFO:  eta: 1 day, 8:46:57  iter: 2479  total_loss: 45.45  loss_ce: 0  loss_mask: 1.232  loss_dice: 3.212  loss_seg: 0.8135  loss_ce_0: 0  loss_mask_0: 1.233  loss_dice_0: 3.29  loss_ce_1: 0  loss_mask_1: 1.246  loss_dice_1: 3.172  loss_ce_2: 0  loss_mask_2: 1.245  loss_dice_2: 3.165  loss_ce_3: 0  loss_mask_3: 1.246  loss_dice_3: 3.162  loss_ce_4: 0  loss_mask_4: 1.25  loss_dice_4: 3.167  loss_ce_5: 0  loss_mask_5: 1.247  loss_dice_5: 3.171  loss_ce_6: 0  loss_mask_6: 1.247  loss_dice_6: 3.172  loss_ce_7: 0  loss_mask_7: 1.244  loss_dice_7: 3.177  loss_ce_8: 0  loss_mask_8: 1.245  loss_dice_8: 3.185  time: 2.0865  data_time: 0.0355  lr: 9.6274e-05  max_mem: 5999M
[02/18 00:32:40] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 00:32:40] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 00:32:40] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 00:33:00] mask2former INFO: Inference done 11/1093. Dataloading: 0.0047 s/iter. Inference: 0.3028 s/iter. Eval: 0.1772 s/iter. Total: 0.4847 s/iter. ETA=0:08:44
[02/18 00:33:06] mask2former INFO: Inference done 21/1093. Dataloading: 0.0084 s/iter. Inference: 0.3271 s/iter. Eval: 0.2075 s/iter. Total: 0.5430 s/iter. ETA=0:09:42
[02/18 00:33:11] mask2former INFO: Inference done 31/1093. Dataloading: 0.0083 s/iter. Inference: 0.3273 s/iter. Eval: 0.2022 s/iter. Total: 0.5380 s/iter. ETA=0:09:31
[02/18 00:33:16] mask2former INFO: Inference done 44/1093. Dataloading: 0.0076 s/iter. Inference: 0.3033 s/iter. Eval: 0.1814 s/iter. Total: 0.4925 s/iter. ETA=0:08:36
[02/18 00:33:21] mask2former INFO: Inference done 55/1093. Dataloading: 0.0103 s/iter. Inference: 0.2987 s/iter. Eval: 0.1769 s/iter. Total: 0.4860 s/iter. ETA=0:08:24
[02/18 00:33:26] mask2former INFO: Inference done 68/1093. Dataloading: 0.0099 s/iter. Inference: 0.2876 s/iter. Eval: 0.1688 s/iter. Total: 0.4665 s/iter. ETA=0:07:58
[02/18 00:33:31] mask2former INFO: Inference done 80/1093. Dataloading: 0.0099 s/iter. Inference: 0.2840 s/iter. Eval: 0.1646 s/iter. Total: 0.4586 s/iter. ETA=0:07:44
[02/18 00:33:36] mask2former INFO: Inference done 93/1093. Dataloading: 0.0093 s/iter. Inference: 0.2812 s/iter. Eval: 0.1583 s/iter. Total: 0.4489 s/iter. ETA=0:07:28
[02/18 00:33:42] mask2former INFO: Inference done 106/1093. Dataloading: 0.0089 s/iter. Inference: 0.2786 s/iter. Eval: 0.1564 s/iter. Total: 0.4439 s/iter. ETA=0:07:18
[02/18 00:33:47] mask2former INFO: Inference done 118/1093. Dataloading: 0.0087 s/iter. Inference: 0.2773 s/iter. Eval: 0.1555 s/iter. Total: 0.4417 s/iter. ETA=0:07:10
[02/18 00:33:52] mask2former INFO: Inference done 131/1093. Dataloading: 0.0085 s/iter. Inference: 0.2759 s/iter. Eval: 0.1528 s/iter. Total: 0.4373 s/iter. ETA=0:07:00
[02/18 00:33:57] mask2former INFO: Inference done 144/1093. Dataloading: 0.0083 s/iter. Inference: 0.2760 s/iter. Eval: 0.1506 s/iter. Total: 0.4349 s/iter. ETA=0:06:52
[02/18 00:34:02] mask2former INFO: Inference done 157/1093. Dataloading: 0.0082 s/iter. Inference: 0.2741 s/iter. Eval: 0.1493 s/iter. Total: 0.4316 s/iter. ETA=0:06:44
[02/18 00:34:08] mask2former INFO: Inference done 170/1093. Dataloading: 0.0081 s/iter. Inference: 0.2720 s/iter. Eval: 0.1492 s/iter. Total: 0.4295 s/iter. ETA=0:06:36
[02/18 00:34:13] mask2former INFO: Inference done 182/1093. Dataloading: 0.0081 s/iter. Inference: 0.2710 s/iter. Eval: 0.1501 s/iter. Total: 0.4292 s/iter. ETA=0:06:31
[02/18 00:34:18] mask2former INFO: Inference done 195/1093. Dataloading: 0.0080 s/iter. Inference: 0.2702 s/iter. Eval: 0.1490 s/iter. Total: 0.4274 s/iter. ETA=0:06:23
[02/18 00:34:23] mask2former INFO: Inference done 208/1093. Dataloading: 0.0081 s/iter. Inference: 0.2697 s/iter. Eval: 0.1485 s/iter. Total: 0.4263 s/iter. ETA=0:06:17
[02/18 00:34:29] mask2former INFO: Inference done 221/1093. Dataloading: 0.0080 s/iter. Inference: 0.2692 s/iter. Eval: 0.1478 s/iter. Total: 0.4251 s/iter. ETA=0:06:10
[02/18 00:34:34] mask2former INFO: Inference done 233/1093. Dataloading: 0.0080 s/iter. Inference: 0.2694 s/iter. Eval: 0.1480 s/iter. Total: 0.4256 s/iter. ETA=0:06:05
[02/18 00:34:39] mask2former INFO: Inference done 246/1093. Dataloading: 0.0080 s/iter. Inference: 0.2680 s/iter. Eval: 0.1478 s/iter. Total: 0.4239 s/iter. ETA=0:05:59
[02/18 00:34:44] mask2former INFO: Inference done 259/1093. Dataloading: 0.0079 s/iter. Inference: 0.2672 s/iter. Eval: 0.1468 s/iter. Total: 0.4221 s/iter. ETA=0:05:52
[02/18 00:34:49] mask2former INFO: Inference done 272/1093. Dataloading: 0.0079 s/iter. Inference: 0.2675 s/iter. Eval: 0.1461 s/iter. Total: 0.4216 s/iter. ETA=0:05:46
[02/18 00:34:55] mask2former INFO: Inference done 284/1093. Dataloading: 0.0080 s/iter. Inference: 0.2679 s/iter. Eval: 0.1460 s/iter. Total: 0.4219 s/iter. ETA=0:05:41
[02/18 00:35:00] mask2former INFO: Inference done 296/1093. Dataloading: 0.0079 s/iter. Inference: 0.2672 s/iter. Eval: 0.1466 s/iter. Total: 0.4218 s/iter. ETA=0:05:36
[02/18 00:35:05] mask2former INFO: Inference done 309/1093. Dataloading: 0.0079 s/iter. Inference: 0.2667 s/iter. Eval: 0.1459 s/iter. Total: 0.4206 s/iter. ETA=0:05:29
[02/18 00:35:10] mask2former INFO: Inference done 321/1093. Dataloading: 0.0078 s/iter. Inference: 0.2666 s/iter. Eval: 0.1460 s/iter. Total: 0.4206 s/iter. ETA=0:05:24
[02/18 00:35:15] mask2former INFO: Inference done 334/1093. Dataloading: 0.0078 s/iter. Inference: 0.2659 s/iter. Eval: 0.1457 s/iter. Total: 0.4196 s/iter. ETA=0:05:18
[02/18 00:35:20] mask2former INFO: Inference done 347/1093. Dataloading: 0.0078 s/iter. Inference: 0.2660 s/iter. Eval: 0.1452 s/iter. Total: 0.4191 s/iter. ETA=0:05:12
[02/18 00:35:25] mask2former INFO: Inference done 360/1093. Dataloading: 0.0077 s/iter. Inference: 0.2656 s/iter. Eval: 0.1446 s/iter. Total: 0.4180 s/iter. ETA=0:05:06
[02/18 00:35:30] mask2former INFO: Inference done 372/1093. Dataloading: 0.0077 s/iter. Inference: 0.2662 s/iter. Eval: 0.1444 s/iter. Total: 0.4183 s/iter. ETA=0:05:01
[02/18 00:35:35] mask2former INFO: Inference done 384/1093. Dataloading: 0.0077 s/iter. Inference: 0.2661 s/iter. Eval: 0.1445 s/iter. Total: 0.4184 s/iter. ETA=0:04:56
[02/18 00:35:41] mask2former INFO: Inference done 397/1093. Dataloading: 0.0076 s/iter. Inference: 0.2663 s/iter. Eval: 0.1440 s/iter. Total: 0.4181 s/iter. ETA=0:04:51
[02/18 00:35:46] mask2former INFO: Inference done 411/1093. Dataloading: 0.0076 s/iter. Inference: 0.2659 s/iter. Eval: 0.1435 s/iter. Total: 0.4171 s/iter. ETA=0:04:44
[02/18 00:35:52] mask2former INFO: Inference done 424/1093. Dataloading: 0.0076 s/iter. Inference: 0.2659 s/iter. Eval: 0.1433 s/iter. Total: 0.4169 s/iter. ETA=0:04:38
[02/18 00:35:57] mask2former INFO: Inference done 436/1093. Dataloading: 0.0075 s/iter. Inference: 0.2664 s/iter. Eval: 0.1429 s/iter. Total: 0.4169 s/iter. ETA=0:04:33
[02/18 00:36:02] mask2former INFO: Inference done 449/1093. Dataloading: 0.0075 s/iter. Inference: 0.2665 s/iter. Eval: 0.1427 s/iter. Total: 0.4168 s/iter. ETA=0:04:28
[02/18 00:36:07] mask2former INFO: Inference done 462/1093. Dataloading: 0.0075 s/iter. Inference: 0.2665 s/iter. Eval: 0.1423 s/iter. Total: 0.4164 s/iter. ETA=0:04:22
[02/18 00:36:12] mask2former INFO: Inference done 475/1093. Dataloading: 0.0075 s/iter. Inference: 0.2663 s/iter. Eval: 0.1422 s/iter. Total: 0.4161 s/iter. ETA=0:04:17
[02/18 00:36:18] mask2former INFO: Inference done 488/1093. Dataloading: 0.0075 s/iter. Inference: 0.2665 s/iter. Eval: 0.1419 s/iter. Total: 0.4160 s/iter. ETA=0:04:11
[02/18 00:36:23] mask2former INFO: Inference done 501/1093. Dataloading: 0.0075 s/iter. Inference: 0.2663 s/iter. Eval: 0.1414 s/iter. Total: 0.4153 s/iter. ETA=0:04:05
[02/18 00:36:28] mask2former INFO: Inference done 514/1093. Dataloading: 0.0075 s/iter. Inference: 0.2664 s/iter. Eval: 0.1409 s/iter. Total: 0.4148 s/iter. ETA=0:04:00
[02/18 00:36:33] mask2former INFO: Inference done 527/1093. Dataloading: 0.0074 s/iter. Inference: 0.2663 s/iter. Eval: 0.1407 s/iter. Total: 0.4146 s/iter. ETA=0:03:54
[02/18 00:36:38] mask2former INFO: Inference done 539/1093. Dataloading: 0.0075 s/iter. Inference: 0.2661 s/iter. Eval: 0.1411 s/iter. Total: 0.4148 s/iter. ETA=0:03:49
[02/18 00:36:43] mask2former INFO: Inference done 551/1093. Dataloading: 0.0075 s/iter. Inference: 0.2665 s/iter. Eval: 0.1408 s/iter. Total: 0.4149 s/iter. ETA=0:03:44
[02/18 00:36:49] mask2former INFO: Inference done 563/1093. Dataloading: 0.0076 s/iter. Inference: 0.2666 s/iter. Eval: 0.1408 s/iter. Total: 0.4152 s/iter. ETA=0:03:40
[02/18 00:36:54] mask2former INFO: Inference done 576/1093. Dataloading: 0.0076 s/iter. Inference: 0.2660 s/iter. Eval: 0.1408 s/iter. Total: 0.4146 s/iter. ETA=0:03:34
[02/18 00:36:59] mask2former INFO: Inference done 588/1093. Dataloading: 0.0076 s/iter. Inference: 0.2665 s/iter. Eval: 0.1406 s/iter. Total: 0.4148 s/iter. ETA=0:03:29
[02/18 00:37:04] mask2former INFO: Inference done 600/1093. Dataloading: 0.0076 s/iter. Inference: 0.2671 s/iter. Eval: 0.1408 s/iter. Total: 0.4156 s/iter. ETA=0:03:24
[02/18 00:37:09] mask2former INFO: Inference done 612/1093. Dataloading: 0.0076 s/iter. Inference: 0.2672 s/iter. Eval: 0.1407 s/iter. Total: 0.4157 s/iter. ETA=0:03:19
[02/18 00:37:14] mask2former INFO: Inference done 625/1093. Dataloading: 0.0076 s/iter. Inference: 0.2671 s/iter. Eval: 0.1405 s/iter. Total: 0.4153 s/iter. ETA=0:03:14
[02/18 00:37:20] mask2former INFO: Inference done 637/1093. Dataloading: 0.0076 s/iter. Inference: 0.2673 s/iter. Eval: 0.1406 s/iter. Total: 0.4157 s/iter. ETA=0:03:09
[02/18 00:37:25] mask2former INFO: Inference done 649/1093. Dataloading: 0.0076 s/iter. Inference: 0.2673 s/iter. Eval: 0.1407 s/iter. Total: 0.4157 s/iter. ETA=0:03:04
[02/18 00:37:30] mask2former INFO: Inference done 660/1093. Dataloading: 0.0076 s/iter. Inference: 0.2679 s/iter. Eval: 0.1410 s/iter. Total: 0.4167 s/iter. ETA=0:03:00
[02/18 00:37:35] mask2former INFO: Inference done 673/1093. Dataloading: 0.0075 s/iter. Inference: 0.2680 s/iter. Eval: 0.1408 s/iter. Total: 0.4164 s/iter. ETA=0:02:54
[02/18 00:37:40] mask2former INFO: Inference done 686/1093. Dataloading: 0.0075 s/iter. Inference: 0.2680 s/iter. Eval: 0.1406 s/iter. Total: 0.4162 s/iter. ETA=0:02:49
[02/18 00:37:46] mask2former INFO: Inference done 698/1093. Dataloading: 0.0075 s/iter. Inference: 0.2683 s/iter. Eval: 0.1405 s/iter. Total: 0.4165 s/iter. ETA=0:02:44
[02/18 00:37:51] mask2former INFO: Inference done 710/1093. Dataloading: 0.0075 s/iter. Inference: 0.2685 s/iter. Eval: 0.1406 s/iter. Total: 0.4167 s/iter. ETA=0:02:39
[02/18 00:37:56] mask2former INFO: Inference done 723/1093. Dataloading: 0.0076 s/iter. Inference: 0.2686 s/iter. Eval: 0.1405 s/iter. Total: 0.4169 s/iter. ETA=0:02:34
[02/18 00:38:01] mask2former INFO: Inference done 735/1093. Dataloading: 0.0075 s/iter. Inference: 0.2686 s/iter. Eval: 0.1406 s/iter. Total: 0.4169 s/iter. ETA=0:02:29
[02/18 00:38:06] mask2former INFO: Inference done 747/1093. Dataloading: 0.0075 s/iter. Inference: 0.2690 s/iter. Eval: 0.1404 s/iter. Total: 0.4171 s/iter. ETA=0:02:24
[02/18 00:38:12] mask2former INFO: Inference done 759/1093. Dataloading: 0.0075 s/iter. Inference: 0.2693 s/iter. Eval: 0.1405 s/iter. Total: 0.4174 s/iter. ETA=0:02:19
[02/18 00:38:17] mask2former INFO: Inference done 771/1093. Dataloading: 0.0075 s/iter. Inference: 0.2698 s/iter. Eval: 0.1405 s/iter. Total: 0.4179 s/iter. ETA=0:02:14
[02/18 00:38:22] mask2former INFO: Inference done 784/1093. Dataloading: 0.0075 s/iter. Inference: 0.2695 s/iter. Eval: 0.1406 s/iter. Total: 0.4178 s/iter. ETA=0:02:09
[02/18 00:38:28] mask2former INFO: Inference done 797/1093. Dataloading: 0.0075 s/iter. Inference: 0.2695 s/iter. Eval: 0.1404 s/iter. Total: 0.4176 s/iter. ETA=0:02:03
[02/18 00:38:33] mask2former INFO: Inference done 809/1093. Dataloading: 0.0075 s/iter. Inference: 0.2697 s/iter. Eval: 0.1406 s/iter. Total: 0.4179 s/iter. ETA=0:01:58
[02/18 00:38:38] mask2former INFO: Inference done 822/1093. Dataloading: 0.0075 s/iter. Inference: 0.2696 s/iter. Eval: 0.1407 s/iter. Total: 0.4179 s/iter. ETA=0:01:53
[02/18 00:38:44] mask2former INFO: Inference done 835/1093. Dataloading: 0.0075 s/iter. Inference: 0.2698 s/iter. Eval: 0.1405 s/iter. Total: 0.4179 s/iter. ETA=0:01:47
[02/18 00:38:49] mask2former INFO: Inference done 847/1093. Dataloading: 0.0075 s/iter. Inference: 0.2701 s/iter. Eval: 0.1406 s/iter. Total: 0.4183 s/iter. ETA=0:01:42
[02/18 00:38:54] mask2former INFO: Inference done 859/1093. Dataloading: 0.0075 s/iter. Inference: 0.2704 s/iter. Eval: 0.1406 s/iter. Total: 0.4186 s/iter. ETA=0:01:37
[02/18 00:39:00] mask2former INFO: Inference done 871/1093. Dataloading: 0.0075 s/iter. Inference: 0.2710 s/iter. Eval: 0.1404 s/iter. Total: 0.4190 s/iter. ETA=0:01:33
[02/18 00:39:05] mask2former INFO: Inference done 883/1093. Dataloading: 0.0075 s/iter. Inference: 0.2713 s/iter. Eval: 0.1405 s/iter. Total: 0.4194 s/iter. ETA=0:01:28
[02/18 00:39:10] mask2former INFO: Inference done 894/1093. Dataloading: 0.0075 s/iter. Inference: 0.2716 s/iter. Eval: 0.1407 s/iter. Total: 0.4198 s/iter. ETA=0:01:23
[02/18 00:39:15] mask2former INFO: Inference done 907/1093. Dataloading: 0.0074 s/iter. Inference: 0.2715 s/iter. Eval: 0.1406 s/iter. Total: 0.4197 s/iter. ETA=0:01:18
[02/18 00:39:20] mask2former INFO: Inference done 919/1093. Dataloading: 0.0074 s/iter. Inference: 0.2715 s/iter. Eval: 0.1406 s/iter. Total: 0.4197 s/iter. ETA=0:01:13
[02/18 00:39:26] mask2former INFO: Inference done 930/1093. Dataloading: 0.0075 s/iter. Inference: 0.2719 s/iter. Eval: 0.1407 s/iter. Total: 0.4202 s/iter. ETA=0:01:08
[02/18 00:39:31] mask2former INFO: Inference done 941/1093. Dataloading: 0.0075 s/iter. Inference: 0.2723 s/iter. Eval: 0.1410 s/iter. Total: 0.4209 s/iter. ETA=0:01:03
[02/18 00:39:36] mask2former INFO: Inference done 953/1093. Dataloading: 0.0074 s/iter. Inference: 0.2724 s/iter. Eval: 0.1412 s/iter. Total: 0.4211 s/iter. ETA=0:00:58
[02/18 00:39:41] mask2former INFO: Inference done 964/1093. Dataloading: 0.0075 s/iter. Inference: 0.2726 s/iter. Eval: 0.1413 s/iter. Total: 0.4216 s/iter. ETA=0:00:54
[02/18 00:39:46] mask2former INFO: Inference done 976/1093. Dataloading: 0.0075 s/iter. Inference: 0.2729 s/iter. Eval: 0.1413 s/iter. Total: 0.4217 s/iter. ETA=0:00:49
[02/18 00:39:52] mask2former INFO: Inference done 988/1093. Dataloading: 0.0075 s/iter. Inference: 0.2729 s/iter. Eval: 0.1414 s/iter. Total: 0.4219 s/iter. ETA=0:00:44
[02/18 00:39:57] mask2former INFO: Inference done 999/1093. Dataloading: 0.0075 s/iter. Inference: 0.2732 s/iter. Eval: 0.1416 s/iter. Total: 0.4225 s/iter. ETA=0:00:39
[02/18 00:40:02] mask2former INFO: Inference done 1010/1093. Dataloading: 0.0075 s/iter. Inference: 0.2734 s/iter. Eval: 0.1419 s/iter. Total: 0.4229 s/iter. ETA=0:00:35
[02/18 00:40:07] mask2former INFO: Inference done 1021/1093. Dataloading: 0.0075 s/iter. Inference: 0.2737 s/iter. Eval: 0.1420 s/iter. Total: 0.4233 s/iter. ETA=0:00:30
[02/18 00:40:12] mask2former INFO: Inference done 1032/1093. Dataloading: 0.0075 s/iter. Inference: 0.2739 s/iter. Eval: 0.1423 s/iter. Total: 0.4239 s/iter. ETA=0:00:25
[02/18 00:40:17] mask2former INFO: Inference done 1044/1093. Dataloading: 0.0075 s/iter. Inference: 0.2740 s/iter. Eval: 0.1423 s/iter. Total: 0.4239 s/iter. ETA=0:00:20
[02/18 00:40:22] mask2former INFO: Inference done 1055/1093. Dataloading: 0.0075 s/iter. Inference: 0.2740 s/iter. Eval: 0.1427 s/iter. Total: 0.4243 s/iter. ETA=0:00:16
[02/18 00:40:28] mask2former INFO: Inference done 1067/1093. Dataloading: 0.0075 s/iter. Inference: 0.2742 s/iter. Eval: 0.1427 s/iter. Total: 0.4246 s/iter. ETA=0:00:11
[02/18 00:40:33] mask2former INFO: Inference done 1079/1093. Dataloading: 0.0075 s/iter. Inference: 0.2744 s/iter. Eval: 0.1427 s/iter. Total: 0.4247 s/iter. ETA=0:00:05
[02/18 00:40:38] mask2former INFO: Inference done 1091/1093. Dataloading: 0.0075 s/iter. Inference: 0.2745 s/iter. Eval: 0.1427 s/iter. Total: 0.4249 s/iter. ETA=0:00:00
[02/18 00:42:28] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.321396550546712, 'error_1pix': 0.7238506430352893, 'error_3pix': 0.44146700744449163, 'mIoU': 6.823161221003515, 'fwIoU': 29.4339036102429, 'IoU-1': 83.65015721690204, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.14533914593033206, 'IoU-10': 6.650002722369468, 'IoU-11': 11.178199508422802, 'IoU-12': 19.815697890569027, 'IoU-13': 4.360365513426284, 'IoU-14': 3.132952055612031, 'IoU-15': 3.279285195144679, 'IoU-16': 3.2665313065629795, 'IoU-17': 2.1055747708088797, 'IoU-18': 1.6804815635671524, 'IoU-19': 1.483417295430367, 'IoU-20': 1.8541912484668146, 'IoU-21': 2.4183713120709456, 'IoU-22': 3.6441625922415217, 'IoU-23': 4.782870376765972, 'IoU-24': 5.077248505839938, 'IoU-25': 5.9877133309769714, 'IoU-26': 7.158488408376927, 'IoU-27': 9.191592059328475, 'IoU-28': 11.129989123378731, 'IoU-29': 13.04558583309772, 'IoU-30': 14.780180409133752, 'IoU-31': 15.664580027875926, 'IoU-32': 12.73520149562571, 'IoU-33': 3.7276489910680564, 'IoU-34': 3.1812192942019792, 'IoU-35': 3.965976261812986, 'IoU-36': 5.463452380744855, 'IoU-37': 6.8253406831529775, 'IoU-38': 7.89097778499407, 'IoU-39': 7.9590805148859385, 'IoU-40': 7.43883736992757, 'IoU-41': 7.265662456446297, 'IoU-42': 9.727315751282841, 'IoU-43': 10.853575907752111, 'IoU-44': 1.050879058686365, 'IoU-45': 0.8885141830481045, 'IoU-46': 0.9004795456675143, 'IoU-47': 0.9984217269630311, 'IoU-48': 1.1561777896085628, 'mACC': 12.893781436410215, 'pACC': 34.72015980836706, 'ACC-1': 86.60408881583646, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 9.287410648945107, 'ACC-10': 13.65914016597236, 'ACC-11': 15.949984532289086, 'ACC-12': 75.49151630352941, 'ACC-13': 11.12582800711849, 'ACC-14': 6.792633830381694, 'ACC-15': 6.058802525110298, 'ACC-16': 5.593643934540383, 'ACC-17': 3.6739742540451266, 'ACC-18': 2.82285858281006, 'ACC-19': 2.5298486016832875, 'ACC-20': 3.165403227328725, 'ACC-21': 4.172114973441921, 'ACC-22': 5.920231405451357, 'ACC-23': 7.840269541270191, 'ACC-24': 8.589237129163504, 'ACC-25': 10.170923585474387, 'ACC-26': 12.403023200062943, 'ACC-27': 16.14820553142699, 'ACC-28': 19.985887740897322, 'ACC-29': 23.423018118659986, 'ACC-30': 26.25643757553759, 'ACC-31': 28.96099112569681, 'ACC-32': 33.22603867456764, 'ACC-33': 7.829010015527313, 'ACC-34': 5.752285006972955, 'ACC-35': 6.409135805702841, 'ACC-36': 8.169914267038083, 'ACC-37': 9.880730950529863, 'ACC-38': 11.3400114677359, 'ACC-39': 11.682825935221844, 'ACC-40': 11.72873007794793, 'ACC-41': 13.1917451007462, 'ACC-42': 23.764293681506, 'ACC-43': 61.69885759566728, 'ACC-44': 1.7614969133778686, 'ACC-45': 1.3346504483857835, 'ACC-46': 1.329692130188155, 'ACC-47': 1.478215950270128, 'ACC-48': 1.6984015696311245})])
[02/18 00:42:28] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 00:42:28] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 00:42:28] d2.evaluation.testing INFO: copypaste: 4.3214,0.7239,0.4415,6.8232,29.4339,12.8938,34.7202
[02/18 00:42:29] d2.utils.events INFO:  eta: 1 day, 8:40:26  iter: 2499  total_loss: 45.19  loss_ce: 0  loss_mask: 1.212  loss_dice: 3.178  loss_seg: 0.9872  loss_ce_0: 0  loss_mask_0: 1.204  loss_dice_0: 3.246  loss_ce_1: 0  loss_mask_1: 1.213  loss_dice_1: 3.167  loss_ce_2: 0  loss_mask_2: 1.209  loss_dice_2: 3.154  loss_ce_3: 0  loss_mask_3: 1.209  loss_dice_3: 3.149  loss_ce_4: 0  loss_mask_4: 1.217  loss_dice_4: 3.151  loss_ce_5: 0  loss_mask_5: 1.219  loss_dice_5: 3.153  loss_ce_6: 0  loss_mask_6: 1.22  loss_dice_6: 3.148  loss_ce_7: 0  loss_mask_7: 1.218  loss_dice_7: 3.147  loss_ce_8: 0  loss_mask_8: 1.211  loss_dice_8: 3.151  time: 2.0822  data_time: 0.0298  lr: 9.6244e-05  max_mem: 5999M
[02/18 00:43:50] d2.utils.events INFO:  eta: 1 day, 9:27:03  iter: 2519  total_loss: 45.46  loss_ce: 0  loss_mask: 1.218  loss_dice: 3.204  loss_seg: 1.013  loss_ce_0: 0  loss_mask_0: 1.201  loss_dice_0: 3.277  loss_ce_1: 0  loss_mask_1: 1.215  loss_dice_1: 3.173  loss_ce_2: 0  loss_mask_2: 1.22  loss_dice_2: 3.173  loss_ce_3: 0  loss_mask_3: 1.223  loss_dice_3: 3.168  loss_ce_4: 0  loss_mask_4: 1.225  loss_dice_4: 3.174  loss_ce_5: 0  loss_mask_5: 1.227  loss_dice_5: 3.182  loss_ce_6: 0  loss_mask_6: 1.224  loss_dice_6: 3.179  loss_ce_7: 0  loss_mask_7: 1.221  loss_dice_7: 3.172  loss_ce_8: 0  loss_mask_8: 1.224  loss_dice_8: 3.174  time: 2.0980  data_time: 0.0374  lr: 9.6213e-05  max_mem: 5999M
[02/18 00:45:13] d2.utils.events INFO:  eta: 1 day, 10:30:01  iter: 2539  total_loss: 45.5  loss_ce: 0  loss_mask: 1.179  loss_dice: 3.247  loss_seg: 1.095  loss_ce_0: 0  loss_mask_0: 1.201  loss_dice_0: 3.31  loss_ce_1: 0  loss_mask_1: 1.195  loss_dice_1: 3.221  loss_ce_2: 0  loss_mask_2: 1.193  loss_dice_2: 3.219  loss_ce_3: 0  loss_mask_3: 1.194  loss_dice_3: 3.218  loss_ce_4: 0  loss_mask_4: 1.191  loss_dice_4: 3.223  loss_ce_5: 0  loss_mask_5: 1.198  loss_dice_5: 3.229  loss_ce_6: 0  loss_mask_6: 1.195  loss_dice_6: 3.224  loss_ce_7: 0  loss_mask_7: 1.2  loss_dice_7: 3.223  loss_ce_8: 0  loss_mask_8: 1.197  loss_dice_8: 3.228  time: 2.1142  data_time: 0.0486  lr: 9.6183e-05  max_mem: 5999M
[02/18 00:46:07] d2.utils.events INFO:  eta: 1 day, 11:20:26  iter: 2559  total_loss: 45.86  loss_ce: 0  loss_mask: 1.241  loss_dice: 3.247  loss_seg: 1.009  loss_ce_0: 0  loss_mask_0: 1.228  loss_dice_0: 3.346  loss_ce_1: 0  loss_mask_1: 1.244  loss_dice_1: 3.233  loss_ce_2: 0  loss_mask_2: 1.254  loss_dice_2: 3.225  loss_ce_3: 0  loss_mask_3: 1.259  loss_dice_3: 3.217  loss_ce_4: 0  loss_mask_4: 1.263  loss_dice_4: 3.212  loss_ce_5: 0  loss_mask_5: 1.258  loss_dice_5: 3.219  loss_ce_6: 0  loss_mask_6: 1.255  loss_dice_6: 3.22  loss_ce_7: 0  loss_mask_7: 1.251  loss_dice_7: 3.218  loss_ce_8: 0  loss_mask_8: 1.253  loss_dice_8: 3.218  time: 2.1185  data_time: 0.0431  lr: 9.6153e-05  max_mem: 5999M
[02/18 00:46:41] d2.utils.events INFO:  eta: 1 day, 11:09:28  iter: 2579  total_loss: 45.8  loss_ce: 0  loss_mask: 1.192  loss_dice: 3.24  loss_seg: 1.538  loss_ce_0: 0  loss_mask_0: 1.181  loss_dice_0: 3.31  loss_ce_1: 0  loss_mask_1: 1.191  loss_dice_1: 3.219  loss_ce_2: 0  loss_mask_2: 1.196  loss_dice_2: 3.207  loss_ce_3: 0  loss_mask_3: 1.201  loss_dice_3: 3.196  loss_ce_4: 0  loss_mask_4: 1.211  loss_dice_4: 3.198  loss_ce_5: 0  loss_mask_5: 1.212  loss_dice_5: 3.208  loss_ce_6: 0  loss_mask_6: 1.21  loss_dice_6: 3.207  loss_ce_7: 0  loss_mask_7: 1.211  loss_dice_7: 3.209  loss_ce_8: 0  loss_mask_8: 1.21  loss_dice_8: 3.208  time: 2.1153  data_time: 0.0287  lr: 9.6123e-05  max_mem: 5999M
[02/18 00:47:15] d2.utils.events INFO:  eta: 1 day, 11:13:47  iter: 2599  total_loss: 44.83  loss_ce: 0  loss_mask: 1.188  loss_dice: 3.151  loss_seg: 1.057  loss_ce_0: 0  loss_mask_0: 1.179  loss_dice_0: 3.231  loss_ce_1: 0  loss_mask_1: 1.18  loss_dice_1: 3.119  loss_ce_2: 0  loss_mask_2: 1.182  loss_dice_2: 3.101  loss_ce_3: 0  loss_mask_3: 1.184  loss_dice_3: 3.094  loss_ce_4: 0  loss_mask_4: 1.186  loss_dice_4: 3.092  loss_ce_5: 0  loss_mask_5: 1.199  loss_dice_5: 3.091  loss_ce_6: 0  loss_mask_6: 1.191  loss_dice_6: 3.103  loss_ce_7: 0  loss_mask_7: 1.191  loss_dice_7: 3.104  loss_ce_8: 0  loss_mask_8: 1.185  loss_dice_8: 3.111  time: 2.1120  data_time: 0.0336  lr: 9.6093e-05  max_mem: 5999M
[02/18 00:47:47] d2.utils.events INFO:  eta: 1 day, 11:13:03  iter: 2619  total_loss: 45.57  loss_ce: 0  loss_mask: 1.212  loss_dice: 3.228  loss_seg: 1.284  loss_ce_0: 0  loss_mask_0: 1.189  loss_dice_0: 3.268  loss_ce_1: 0  loss_mask_1: 1.202  loss_dice_1: 3.192  loss_ce_2: 0  loss_mask_2: 1.212  loss_dice_2: 3.191  loss_ce_3: 0  loss_mask_3: 1.221  loss_dice_3: 3.183  loss_ce_4: 0  loss_mask_4: 1.22  loss_dice_4: 3.185  loss_ce_5: 0  loss_mask_5: 1.215  loss_dice_5: 3.188  loss_ce_6: 0  loss_mask_6: 1.214  loss_dice_6: 3.19  loss_ce_7: 0  loss_mask_7: 1.214  loss_dice_7: 3.191  loss_ce_8: 0  loss_mask_8: 1.211  loss_dice_8: 3.195  time: 2.1081  data_time: 0.0322  lr: 9.6063e-05  max_mem: 5999M
[02/18 00:48:19] d2.utils.events INFO:  eta: 1 day, 10:59:46  iter: 2639  total_loss: 45.85  loss_ce: 0  loss_mask: 1.226  loss_dice: 3.174  loss_seg: 1.268  loss_ce_0: 0  loss_mask_0: 1.215  loss_dice_0: 3.195  loss_ce_1: 0  loss_mask_1: 1.242  loss_dice_1: 3.124  loss_ce_2: 0  loss_mask_2: 1.245  loss_dice_2: 3.134  loss_ce_3: 0  loss_mask_3: 1.233  loss_dice_3: 3.128  loss_ce_4: 0  loss_mask_4: 1.23  loss_dice_4: 3.138  loss_ce_5: 0  loss_mask_5: 1.24  loss_dice_5: 3.13  loss_ce_6: 0  loss_mask_6: 1.235  loss_dice_6: 3.142  loss_ce_7: 0  loss_mask_7: 1.242  loss_dice_7: 3.142  loss_ce_8: 0  loss_mask_8: 1.246  loss_dice_8: 3.137  time: 2.1043  data_time: 0.0386  lr: 9.6033e-05  max_mem: 5999M
[02/18 00:48:52] d2.utils.events INFO:  eta: 1 day, 10:58:40  iter: 2659  total_loss: 45.34  loss_ce: 0  loss_mask: 1.194  loss_dice: 3.192  loss_seg: 1.156  loss_ce_0: 0  loss_mask_0: 1.148  loss_dice_0: 3.225  loss_ce_1: 0  loss_mask_1: 1.189  loss_dice_1: 3.175  loss_ce_2: 0  loss_mask_2: 1.186  loss_dice_2: 3.17  loss_ce_3: 0  loss_mask_3: 1.191  loss_dice_3: 3.165  loss_ce_4: 0  loss_mask_4: 1.19  loss_dice_4: 3.166  loss_ce_5: 0  loss_mask_5: 1.196  loss_dice_5: 3.165  loss_ce_6: 0  loss_mask_6: 1.197  loss_dice_6: 3.166  loss_ce_7: 0  loss_mask_7: 1.201  loss_dice_7: 3.167  loss_ce_8: 0  loss_mask_8: 1.196  loss_dice_8: 3.174  time: 2.1010  data_time: 0.0274  lr: 9.6003e-05  max_mem: 5999M
[02/18 00:49:25] d2.utils.events INFO:  eta: 1 day, 10:46:06  iter: 2679  total_loss: 45.45  loss_ce: 0  loss_mask: 1.202  loss_dice: 3.189  loss_seg: 1.194  loss_ce_0: 0  loss_mask_0: 1.204  loss_dice_0: 3.255  loss_ce_1: 0  loss_mask_1: 1.205  loss_dice_1: 3.157  loss_ce_2: 0  loss_mask_2: 1.21  loss_dice_2: 3.147  loss_ce_3: 0  loss_mask_3: 1.208  loss_dice_3: 3.142  loss_ce_4: 0  loss_mask_4: 1.205  loss_dice_4: 3.155  loss_ce_5: 0  loss_mask_5: 1.203  loss_dice_5: 3.157  loss_ce_6: 0  loss_mask_6: 1.212  loss_dice_6: 3.154  loss_ce_7: 0  loss_mask_7: 1.207  loss_dice_7: 3.158  loss_ce_8: 0  loss_mask_8: 1.212  loss_dice_8: 3.155  time: 2.0974  data_time: 0.0363  lr: 9.5972e-05  max_mem: 5999M
[02/18 00:50:00] d2.utils.events INFO:  eta: 1 day, 10:05:04  iter: 2699  total_loss: 44.74  loss_ce: 0  loss_mask: 1.21  loss_dice: 3.112  loss_seg: 0.9354  loss_ce_0: 0  loss_mask_0: 1.199  loss_dice_0: 3.187  loss_ce_1: 0  loss_mask_1: 1.227  loss_dice_1: 3.087  loss_ce_2: 0  loss_mask_2: 1.225  loss_dice_2: 3.073  loss_ce_3: 0  loss_mask_3: 1.227  loss_dice_3: 3.071  loss_ce_4: 0  loss_mask_4: 1.235  loss_dice_4: 3.074  loss_ce_5: 0  loss_mask_5: 1.231  loss_dice_5: 3.082  loss_ce_6: 0  loss_mask_6: 1.232  loss_dice_6: 3.085  loss_ce_7: 0  loss_mask_7: 1.231  loss_dice_7: 3.087  loss_ce_8: 0  loss_mask_8: 1.23  loss_dice_8: 3.088  time: 2.0950  data_time: 0.0306  lr: 9.5942e-05  max_mem: 5999M
[02/18 00:50:51] d2.utils.events INFO:  eta: 1 day, 10:04:22  iter: 2719  total_loss: 44.96  loss_ce: 0  loss_mask: 1.252  loss_dice: 3.179  loss_seg: 0.8259  loss_ce_0: 0  loss_mask_0: 1.232  loss_dice_0: 3.233  loss_ce_1: 0  loss_mask_1: 1.251  loss_dice_1: 3.163  loss_ce_2: 0  loss_mask_2: 1.25  loss_dice_2: 3.149  loss_ce_3: 0  loss_mask_3: 1.254  loss_dice_3: 3.145  loss_ce_4: 0  loss_mask_4: 1.252  loss_dice_4: 3.155  loss_ce_5: 0  loss_mask_5: 1.253  loss_dice_5: 3.149  loss_ce_6: 0  loss_mask_6: 1.253  loss_dice_6: 3.148  loss_ce_7: 0  loss_mask_7: 1.259  loss_dice_7: 3.164  loss_ce_8: 0  loss_mask_8: 1.255  loss_dice_8: 3.156  time: 2.0981  data_time: 0.0322  lr: 9.5912e-05  max_mem: 5999M
[02/18 00:51:51] d2.utils.events INFO:  eta: 1 day, 10:03:39  iter: 2739  total_loss: 45.09  loss_ce: 0  loss_mask: 1.169  loss_dice: 3.216  loss_seg: 1.21  loss_ce_0: 0  loss_mask_0: 1.163  loss_dice_0: 3.285  loss_ce_1: 0  loss_mask_1: 1.173  loss_dice_1: 3.197  loss_ce_2: 0  loss_mask_2: 1.174  loss_dice_2: 3.18  loss_ce_3: 0  loss_mask_3: 1.175  loss_dice_3: 3.165  loss_ce_4: 0  loss_mask_4: 1.179  loss_dice_4: 3.172  loss_ce_5: 0  loss_mask_5: 1.18  loss_dice_5: 3.171  loss_ce_6: 0  loss_mask_6: 1.174  loss_dice_6: 3.172  loss_ce_7: 0  loss_mask_7: 1.176  loss_dice_7: 3.179  loss_ce_8: 0  loss_mask_8: 1.178  loss_dice_8: 3.183  time: 2.1046  data_time: 0.0364  lr: 9.5882e-05  max_mem: 5999M
[02/18 00:53:00] d2.utils.events INFO:  eta: 1 day, 10:07:58  iter: 2759  total_loss: 43.87  loss_ce: 0  loss_mask: 1.211  loss_dice: 3.064  loss_seg: 0.9235  loss_ce_0: 0  loss_mask_0: 1.185  loss_dice_0: 3.134  loss_ce_1: 0  loss_mask_1: 1.223  loss_dice_1: 3.048  loss_ce_2: 0  loss_mask_2: 1.219  loss_dice_2: 3.039  loss_ce_3: 0  loss_mask_3: 1.214  loss_dice_3: 3.033  loss_ce_4: 0  loss_mask_4: 1.221  loss_dice_4: 3.035  loss_ce_5: 0  loss_mask_5: 1.225  loss_dice_5: 3.029  loss_ce_6: 0  loss_mask_6: 1.226  loss_dice_6: 3.024  loss_ce_7: 0  loss_mask_7: 1.226  loss_dice_7: 3.04  loss_ce_8: 0  loss_mask_8: 1.221  loss_dice_8: 3.034  time: 2.1143  data_time: 0.0342  lr: 9.5852e-05  max_mem: 5999M
[02/18 00:54:15] d2.utils.events INFO:  eta: 1 day, 10:07:15  iter: 2779  total_loss: 45.16  loss_ce: 0  loss_mask: 1.236  loss_dice: 3.133  loss_seg: 0.9146  loss_ce_0: 0  loss_mask_0: 1.224  loss_dice_0: 3.206  loss_ce_1: 0  loss_mask_1: 1.246  loss_dice_1: 3.129  loss_ce_2: 0  loss_mask_2: 1.253  loss_dice_2: 3.112  loss_ce_3: 0  loss_mask_3: 1.252  loss_dice_3: 3.11  loss_ce_4: 0  loss_mask_4: 1.255  loss_dice_4: 3.109  loss_ce_5: 0  loss_mask_5: 1.257  loss_dice_5: 3.107  loss_ce_6: 0  loss_mask_6: 1.252  loss_dice_6: 3.108  loss_ce_7: 0  loss_mask_7: 1.25  loss_dice_7: 3.113  loss_ce_8: 0  loss_mask_8: 1.249  loss_dice_8: 3.112  time: 2.1261  data_time: 0.0393  lr: 9.5822e-05  max_mem: 5999M
[02/18 00:55:29] d2.utils.events INFO:  eta: 1 day, 10:07:28  iter: 2799  total_loss: 44.36  loss_ce: 0  loss_mask: 1.224  loss_dice: 3.143  loss_seg: 1.167  loss_ce_0: 0  loss_mask_0: 1.219  loss_dice_0: 3.213  loss_ce_1: 0  loss_mask_1: 1.236  loss_dice_1: 3.126  loss_ce_2: 0  loss_mask_2: 1.24  loss_dice_2: 3.125  loss_ce_3: 0  loss_mask_3: 1.244  loss_dice_3: 3.113  loss_ce_4: 0  loss_mask_4: 1.237  loss_dice_4: 3.113  loss_ce_5: 0  loss_mask_5: 1.246  loss_dice_5: 3.114  loss_ce_6: 0  loss_mask_6: 1.252  loss_dice_6: 3.116  loss_ce_7: 0  loss_mask_7: 1.242  loss_dice_7: 3.112  loss_ce_8: 0  loss_mask_8: 1.242  loss_dice_8: 3.119  time: 2.1376  data_time: 0.0542  lr: 9.5792e-05  max_mem: 5999M
[02/18 00:56:47] d2.utils.events INFO:  eta: 1 day, 10:11:25  iter: 2819  total_loss: 45.35  loss_ce: 0  loss_mask: 1.192  loss_dice: 3.215  loss_seg: 0.801  loss_ce_0: 0  loss_mask_0: 1.209  loss_dice_0: 3.271  loss_ce_1: 0  loss_mask_1: 1.198  loss_dice_1: 3.19  loss_ce_2: 0  loss_mask_2: 1.198  loss_dice_2: 3.18  loss_ce_3: 0  loss_mask_3: 1.211  loss_dice_3: 3.173  loss_ce_4: 0  loss_mask_4: 1.207  loss_dice_4: 3.173  loss_ce_5: 0  loss_mask_5: 1.202  loss_dice_5: 3.181  loss_ce_6: 0  loss_mask_6: 1.198  loss_dice_6: 3.18  loss_ce_7: 0  loss_mask_7: 1.193  loss_dice_7: 3.189  loss_ce_8: 0  loss_mask_8: 1.196  loss_dice_8: 3.19  time: 2.1498  data_time: 0.0386  lr: 9.5761e-05  max_mem: 5999M
[02/18 00:58:05] d2.utils.events INFO:  eta: 1 day, 10:10:42  iter: 2839  total_loss: 44.37  loss_ce: 0  loss_mask: 1.21  loss_dice: 3.167  loss_seg: 1.018  loss_ce_0: 0  loss_mask_0: 1.187  loss_dice_0: 3.231  loss_ce_1: 0  loss_mask_1: 1.214  loss_dice_1: 3.151  loss_ce_2: 0  loss_mask_2: 1.218  loss_dice_2: 3.127  loss_ce_3: 0  loss_mask_3: 1.219  loss_dice_3: 3.13  loss_ce_4: 0  loss_mask_4: 1.218  loss_dice_4: 3.131  loss_ce_5: 0  loss_mask_5: 1.215  loss_dice_5: 3.139  loss_ce_6: 0  loss_mask_6: 1.228  loss_dice_6: 3.137  loss_ce_7: 0  loss_mask_7: 1.226  loss_dice_7: 3.129  loss_ce_8: 0  loss_mask_8: 1.23  loss_dice_8: 3.135  time: 2.1623  data_time: 0.0442  lr: 9.5731e-05  max_mem: 5999M
[02/18 00:59:27] d2.utils.events INFO:  eta: 1 day, 10:13:24  iter: 2859  total_loss: 44.33  loss_ce: 0  loss_mask: 1.165  loss_dice: 3.159  loss_seg: 1.046  loss_ce_0: 0  loss_mask_0: 1.161  loss_dice_0: 3.193  loss_ce_1: 0  loss_mask_1: 1.172  loss_dice_1: 3.132  loss_ce_2: 0  loss_mask_2: 1.166  loss_dice_2: 3.138  loss_ce_3: 0  loss_mask_3: 1.166  loss_dice_3: 3.134  loss_ce_4: 0  loss_mask_4: 1.168  loss_dice_4: 3.135  loss_ce_5: 0  loss_mask_5: 1.178  loss_dice_5: 3.134  loss_ce_6: 0  loss_mask_6: 1.174  loss_dice_6: 3.132  loss_ce_7: 0  loss_mask_7: 1.179  loss_dice_7: 3.13  loss_ce_8: 0  loss_mask_8: 1.173  loss_dice_8: 3.133  time: 2.1756  data_time: 0.0471  lr: 9.5701e-05  max_mem: 5999M
[02/18 01:00:44] d2.utils.events INFO:  eta: 1 day, 10:17:38  iter: 2879  total_loss: 44.23  loss_ce: 0  loss_mask: 1.203  loss_dice: 3.127  loss_seg: 0.9441  loss_ce_0: 0  loss_mask_0: 1.173  loss_dice_0: 3.204  loss_ce_1: 0  loss_mask_1: 1.209  loss_dice_1: 3.107  loss_ce_2: 0  loss_mask_2: 1.215  loss_dice_2: 3.096  loss_ce_3: 0  loss_mask_3: 1.221  loss_dice_3: 3.089  loss_ce_4: 0  loss_mask_4: 1.217  loss_dice_4: 3.086  loss_ce_5: 0  loss_mask_5: 1.211  loss_dice_5: 3.097  loss_ce_6: 0  loss_mask_6: 1.21  loss_dice_6: 3.096  loss_ce_7: 0  loss_mask_7: 1.22  loss_dice_7: 3.092  loss_ce_8: 0  loss_mask_8: 1.215  loss_dice_8: 3.098  time: 2.1874  data_time: 0.0377  lr: 9.5671e-05  max_mem: 5999M
[02/18 01:02:06] d2.utils.events INFO:  eta: 1 day, 10:16:55  iter: 2899  total_loss: 44.9  loss_ce: 0  loss_mask: 1.167  loss_dice: 3.217  loss_seg: 1.059  loss_ce_0: 0  loss_mask_0: 1.161  loss_dice_0: 3.29  loss_ce_1: 0  loss_mask_1: 1.171  loss_dice_1: 3.199  loss_ce_2: 0  loss_mask_2: 1.177  loss_dice_2: 3.185  loss_ce_3: 0  loss_mask_3: 1.174  loss_dice_3: 3.171  loss_ce_4: 0  loss_mask_4: 1.179  loss_dice_4: 3.178  loss_ce_5: 0  loss_mask_5: 1.178  loss_dice_5: 3.181  loss_ce_6: 0  loss_mask_6: 1.179  loss_dice_6: 3.178  loss_ce_7: 0  loss_mask_7: 1.179  loss_dice_7: 3.179  loss_ce_8: 0  loss_mask_8: 1.182  loss_dice_8: 3.181  time: 2.2005  data_time: 0.0350  lr: 9.5641e-05  max_mem: 5999M
[02/18 01:03:20] d2.utils.events INFO:  eta: 1 day, 10:39:14  iter: 2919  total_loss: 45.39  loss_ce: 0  loss_mask: 1.165  loss_dice: 3.274  loss_seg: 1.05  loss_ce_0: 0  loss_mask_0: 1.152  loss_dice_0: 3.303  loss_ce_1: 0  loss_mask_1: 1.171  loss_dice_1: 3.245  loss_ce_2: 0  loss_mask_2: 1.184  loss_dice_2: 3.239  loss_ce_3: 0  loss_mask_3: 1.187  loss_dice_3: 3.237  loss_ce_4: 0  loss_mask_4: 1.184  loss_dice_4: 3.243  loss_ce_5: 0  loss_mask_5: 1.182  loss_dice_5: 3.245  loss_ce_6: 0  loss_mask_6: 1.179  loss_dice_6: 3.248  loss_ce_7: 0  loss_mask_7: 1.181  loss_dice_7: 3.249  loss_ce_8: 0  loss_mask_8: 1.181  loss_dice_8: 3.248  time: 2.2107  data_time: 0.0368  lr: 9.5611e-05  max_mem: 5999M
[02/18 01:04:40] d2.utils.events INFO:  eta: 1 day, 12:36:30  iter: 2939  total_loss: 44.74  loss_ce: 0  loss_mask: 1.169  loss_dice: 3.194  loss_seg: 1.02  loss_ce_0: 0  loss_mask_0: 1.152  loss_dice_0: 3.25  loss_ce_1: 0  loss_mask_1: 1.173  loss_dice_1: 3.16  loss_ce_2: 0  loss_mask_2: 1.183  loss_dice_2: 3.159  loss_ce_3: 0  loss_mask_3: 1.18  loss_dice_3: 3.151  loss_ce_4: 0  loss_mask_4: 1.181  loss_dice_4: 3.156  loss_ce_5: 0  loss_mask_5: 1.176  loss_dice_5: 3.164  loss_ce_6: 0  loss_mask_6: 1.171  loss_dice_6: 3.16  loss_ce_7: 0  loss_mask_7: 1.172  loss_dice_7: 3.168  loss_ce_8: 0  loss_mask_8: 1.173  loss_dice_8: 3.17  time: 2.2229  data_time: 0.0298  lr: 9.5581e-05  max_mem: 5999M
[02/18 01:05:58] d2.utils.events INFO:  eta: 1 day, 14:37:04  iter: 2959  total_loss: 43.96  loss_ce: 0  loss_mask: 1.172  loss_dice: 3.155  loss_seg: 1.192  loss_ce_0: 0  loss_mask_0: 1.163  loss_dice_0: 3.255  loss_ce_1: 0  loss_mask_1: 1.159  loss_dice_1: 3.141  loss_ce_2: 0  loss_mask_2: 1.157  loss_dice_2: 3.121  loss_ce_3: 0  loss_mask_3: 1.16  loss_dice_3: 3.117  loss_ce_4: 0  loss_mask_4: 1.165  loss_dice_4: 3.118  loss_ce_5: 0  loss_mask_5: 1.17  loss_dice_5: 3.123  loss_ce_6: 0  loss_mask_6: 1.17  loss_dice_6: 3.115  loss_ce_7: 0  loss_mask_7: 1.168  loss_dice_7: 3.12  loss_ce_8: 0  loss_mask_8: 1.164  loss_dice_8: 3.122  time: 2.2341  data_time: 0.0372  lr: 9.555e-05  max_mem: 5999M
[02/18 01:07:10] d2.utils.events INFO:  eta: 1 day, 16:16:49  iter: 2979  total_loss: 42.95  loss_ce: 0  loss_mask: 1.098  loss_dice: 2.999  loss_seg: 1.239  loss_ce_0: 0  loss_mask_0: 1.077  loss_dice_0: 3.106  loss_ce_1: 0  loss_mask_1: 1.099  loss_dice_1: 2.983  loss_ce_2: 0  loss_mask_2: 1.11  loss_dice_2: 2.969  loss_ce_3: 0  loss_mask_3: 1.112  loss_dice_3: 2.973  loss_ce_4: 0  loss_mask_4: 1.119  loss_dice_4: 2.973  loss_ce_5: 0  loss_mask_5: 1.118  loss_dice_5: 2.974  loss_ce_6: 0  loss_mask_6: 1.114  loss_dice_6: 2.97  loss_ce_7: 0  loss_mask_7: 1.115  loss_dice_7: 2.967  loss_ce_8: 0  loss_mask_8: 1.119  loss_dice_8: 2.969  time: 2.2434  data_time: 0.0364  lr: 9.552e-05  max_mem: 5999M
[02/18 01:08:31] d2.utils.events INFO:  eta: 1 day, 18:29:56  iter: 2999  total_loss: 42.84  loss_ce: 0  loss_mask: 1.131  loss_dice: 2.997  loss_seg: 1.079  loss_ce_0: 0  loss_mask_0: 1.137  loss_dice_0: 3.069  loss_ce_1: 0  loss_mask_1: 1.137  loss_dice_1: 2.988  loss_ce_2: 0  loss_mask_2: 1.135  loss_dice_2: 2.973  loss_ce_3: 0  loss_mask_3: 1.139  loss_dice_3: 2.959  loss_ce_4: 0  loss_mask_4: 1.138  loss_dice_4: 2.956  loss_ce_5: 0  loss_mask_5: 1.137  loss_dice_5: 2.959  loss_ce_6: 0  loss_mask_6: 1.139  loss_dice_6: 2.958  loss_ce_7: 0  loss_mask_7: 1.137  loss_dice_7: 2.961  loss_ce_8: 0  loss_mask_8: 1.137  loss_dice_8: 2.959  time: 2.2554  data_time: 0.0330  lr: 9.549e-05  max_mem: 5999M
[02/18 01:09:53] d2.utils.events INFO:  eta: 1 day, 20:05:59  iter: 3019  total_loss: 42.8  loss_ce: 0  loss_mask: 1.156  loss_dice: 3.089  loss_seg: 1.088  loss_ce_0: 0  loss_mask_0: 1.14  loss_dice_0: 3.161  loss_ce_1: 0  loss_mask_1: 1.16  loss_dice_1: 3.09  loss_ce_2: 0  loss_mask_2: 1.162  loss_dice_2: 3.07  loss_ce_3: 0  loss_mask_3: 1.157  loss_dice_3: 3.061  loss_ce_4: 0  loss_mask_4: 1.162  loss_dice_4: 3.067  loss_ce_5: 0  loss_mask_5: 1.163  loss_dice_5: 3.06  loss_ce_6: 0  loss_mask_6: 1.165  loss_dice_6: 3.055  loss_ce_7: 0  loss_mask_7: 1.164  loss_dice_7: 3.052  loss_ce_8: 0  loss_mask_8: 1.165  loss_dice_8: 3.05  time: 2.2675  data_time: 0.0390  lr: 9.546e-05  max_mem: 5999M
[02/18 01:11:12] d2.utils.events INFO:  eta: 1 day, 21:57:51  iter: 3039  total_loss: 43.43  loss_ce: 0  loss_mask: 1.191  loss_dice: 3.071  loss_seg: 0.8937  loss_ce_0: 0  loss_mask_0: 1.171  loss_dice_0: 3.125  loss_ce_1: 0  loss_mask_1: 1.181  loss_dice_1: 3.034  loss_ce_2: 0  loss_mask_2: 1.189  loss_dice_2: 3.033  loss_ce_3: 0  loss_mask_3: 1.204  loss_dice_3: 3.033  loss_ce_4: 0  loss_mask_4: 1.213  loss_dice_4: 3.03  loss_ce_5: 0  loss_mask_5: 1.208  loss_dice_5: 3.034  loss_ce_6: 0  loss_mask_6: 1.201  loss_dice_6: 3.042  loss_ce_7: 0  loss_mask_7: 1.202  loss_dice_7: 3.052  loss_ce_8: 0  loss_mask_8: 1.202  loss_dice_8: 3.046  time: 2.2786  data_time: 0.0357  lr: 9.543e-05  max_mem: 5999M
[02/18 01:12:33] d2.utils.events INFO:  eta: 1 day, 23:05:30  iter: 3059  total_loss: 43.21  loss_ce: 0  loss_mask: 1.178  loss_dice: 3.039  loss_seg: 1.073  loss_ce_0: 0  loss_mask_0: 1.168  loss_dice_0: 3.118  loss_ce_1: 0  loss_mask_1: 1.18  loss_dice_1: 3.02  loss_ce_2: 0  loss_mask_2: 1.183  loss_dice_2: 3.012  loss_ce_3: 0  loss_mask_3: 1.184  loss_dice_3: 3.003  loss_ce_4: 0  loss_mask_4: 1.195  loss_dice_4: 3.005  loss_ce_5: 0  loss_mask_5: 1.19  loss_dice_5: 3.011  loss_ce_6: 0  loss_mask_6: 1.189  loss_dice_6: 3.009  loss_ce_7: 0  loss_mask_7: 1.191  loss_dice_7: 3.012  loss_ce_8: 0  loss_mask_8: 1.19  loss_dice_8: 3.01  time: 2.2900  data_time: 0.0371  lr: 9.54e-05  max_mem: 5999M
[02/18 01:13:52] d2.utils.events INFO:  eta: 1 day, 23:14:00  iter: 3079  total_loss: 44.83  loss_ce: 0  loss_mask: 1.181  loss_dice: 3.134  loss_seg: 1.075  loss_ce_0: 0  loss_mask_0: 1.155  loss_dice_0: 3.167  loss_ce_1: 0  loss_mask_1: 1.186  loss_dice_1: 3.108  loss_ce_2: 0  loss_mask_2: 1.191  loss_dice_2: 3.107  loss_ce_3: 0  loss_mask_3: 1.2  loss_dice_3: 3.096  loss_ce_4: 0  loss_mask_4: 1.195  loss_dice_4: 3.104  loss_ce_5: 0  loss_mask_5: 1.199  loss_dice_5: 3.113  loss_ce_6: 0  loss_mask_6: 1.198  loss_dice_6: 3.108  loss_ce_7: 0  loss_mask_7: 1.194  loss_dice_7: 3.105  loss_ce_8: 0  loss_mask_8: 1.194  loss_dice_8: 3.104  time: 2.3010  data_time: 0.0420  lr: 9.5369e-05  max_mem: 5999M
[02/18 01:15:15] d2.utils.events INFO:  eta: 1 day, 23:45:59  iter: 3099  total_loss: 44.24  loss_ce: 0  loss_mask: 1.155  loss_dice: 3.149  loss_seg: 1.161  loss_ce_0: 0  loss_mask_0: 1.15  loss_dice_0: 3.221  loss_ce_1: 0  loss_mask_1: 1.156  loss_dice_1: 3.128  loss_ce_2: 0  loss_mask_2: 1.163  loss_dice_2: 3.123  loss_ce_3: 0  loss_mask_3: 1.165  loss_dice_3: 3.118  loss_ce_4: 0  loss_mask_4: 1.163  loss_dice_4: 3.125  loss_ce_5: 0  loss_mask_5: 1.165  loss_dice_5: 3.122  loss_ce_6: 0  loss_mask_6: 1.167  loss_dice_6: 3.122  loss_ce_7: 0  loss_mask_7: 1.16  loss_dice_7: 3.121  loss_ce_8: 0  loss_mask_8: 1.158  loss_dice_8: 3.127  time: 2.3129  data_time: 0.0351  lr: 9.5339e-05  max_mem: 5999M
[02/18 01:16:29] d2.utils.events INFO:  eta: 2 days, 0:04:26  iter: 3119  total_loss: 42.98  loss_ce: 0  loss_mask: 1.151  loss_dice: 3.086  loss_seg: 1.27  loss_ce_0: 0  loss_mask_0: 1.137  loss_dice_0: 3.176  loss_ce_1: 0  loss_mask_1: 1.14  loss_dice_1: 3.066  loss_ce_2: 0  loss_mask_2: 1.153  loss_dice_2: 3.056  loss_ce_3: 0  loss_mask_3: 1.156  loss_dice_3: 3.05  loss_ce_4: 0  loss_mask_4: 1.164  loss_dice_4: 3.061  loss_ce_5: 0  loss_mask_5: 1.156  loss_dice_5: 3.061  loss_ce_6: 0  loss_mask_6: 1.152  loss_dice_6: 3.056  loss_ce_7: 0  loss_mask_7: 1.162  loss_dice_7: 3.052  loss_ce_8: 0  loss_mask_8: 1.16  loss_dice_8: 3.053  time: 2.3218  data_time: 0.0388  lr: 9.5309e-05  max_mem: 5999M
[02/18 01:17:48] d2.utils.events INFO:  eta: 2 days, 0:23:57  iter: 3139  total_loss: 41.34  loss_ce: 0  loss_mask: 1.118  loss_dice: 2.944  loss_seg: 0.9682  loss_ce_0: 0  loss_mask_0: 1.121  loss_dice_0: 3.041  loss_ce_1: 0  loss_mask_1: 1.122  loss_dice_1: 2.918  loss_ce_2: 0  loss_mask_2: 1.126  loss_dice_2: 2.906  loss_ce_3: 0  loss_mask_3: 1.132  loss_dice_3: 2.9  loss_ce_4: 0  loss_mask_4: 1.131  loss_dice_4: 2.905  loss_ce_5: 0  loss_mask_5: 1.128  loss_dice_5: 2.908  loss_ce_6: 0  loss_mask_6: 1.13  loss_dice_6: 2.908  loss_ce_7: 0  loss_mask_7: 1.126  loss_dice_7: 2.906  loss_ce_8: 0  loss_mask_8: 1.125  loss_dice_8: 2.91  time: 2.3321  data_time: 0.0296  lr: 9.5279e-05  max_mem: 5999M
[02/18 01:19:08] d2.utils.events INFO:  eta: 2 days, 0:47:52  iter: 3159  total_loss: 44.17  loss_ce: 0  loss_mask: 1.202  loss_dice: 3.117  loss_seg: 0.9809  loss_ce_0: 0  loss_mask_0: 1.194  loss_dice_0: 3.174  loss_ce_1: 0  loss_mask_1: 1.207  loss_dice_1: 3.105  loss_ce_2: 0  loss_mask_2: 1.215  loss_dice_2: 3.092  loss_ce_3: 0  loss_mask_3: 1.215  loss_dice_3: 3.081  loss_ce_4: 0  loss_mask_4: 1.219  loss_dice_4: 3.09  loss_ce_5: 0  loss_mask_5: 1.213  loss_dice_5: 3.095  loss_ce_6: 0  loss_mask_6: 1.212  loss_dice_6: 3.087  loss_ce_7: 0  loss_mask_7: 1.217  loss_dice_7: 3.094  loss_ce_8: 0  loss_mask_8: 1.214  loss_dice_8: 3.088  time: 2.3427  data_time: 0.0358  lr: 9.5249e-05  max_mem: 5999M
[02/18 01:20:28] d2.utils.events INFO:  eta: 2 days, 0:55:44  iter: 3179  total_loss: 45.39  loss_ce: 0  loss_mask: 1.157  loss_dice: 3.207  loss_seg: 1.402  loss_ce_0: 0  loss_mask_0: 1.158  loss_dice_0: 3.282  loss_ce_1: 0  loss_mask_1: 1.158  loss_dice_1: 3.198  loss_ce_2: 0  loss_mask_2: 1.157  loss_dice_2: 3.193  loss_ce_3: 0  loss_mask_3: 1.162  loss_dice_3: 3.192  loss_ce_4: 0  loss_mask_4: 1.162  loss_dice_4: 3.189  loss_ce_5: 0  loss_mask_5: 1.159  loss_dice_5: 3.187  loss_ce_6: 0  loss_mask_6: 1.159  loss_dice_6: 3.176  loss_ce_7: 0  loss_mask_7: 1.164  loss_dice_7: 3.187  loss_ce_8: 0  loss_mask_8: 1.162  loss_dice_8: 3.19  time: 2.3529  data_time: 0.0421  lr: 9.5219e-05  max_mem: 5999M
[02/18 01:21:46] d2.utils.events INFO:  eta: 2 days, 1:27:56  iter: 3199  total_loss: 43.59  loss_ce: 0  loss_mask: 1.17  loss_dice: 3.073  loss_seg: 0.9545  loss_ce_0: 0  loss_mask_0: 1.173  loss_dice_0: 3.126  loss_ce_1: 0  loss_mask_1: 1.174  loss_dice_1: 3.042  loss_ce_2: 0  loss_mask_2: 1.171  loss_dice_2: 3.038  loss_ce_3: 0  loss_mask_3: 1.172  loss_dice_3: 3.038  loss_ce_4: 0  loss_mask_4: 1.175  loss_dice_4: 3.035  loss_ce_5: 0  loss_mask_5: 1.175  loss_dice_5: 3.042  loss_ce_6: 0  loss_mask_6: 1.177  loss_dice_6: 3.041  loss_ce_7: 0  loss_mask_7: 1.179  loss_dice_7: 3.043  loss_ce_8: 0  loss_mask_8: 1.177  loss_dice_8: 3.046  time: 2.3625  data_time: 0.0444  lr: 9.5188e-05  max_mem: 5999M
[02/18 01:23:02] d2.utils.events INFO:  eta: 2 days, 1:50:04  iter: 3219  total_loss: 44.59  loss_ce: 0  loss_mask: 1.209  loss_dice: 3.129  loss_seg: 0.9915  loss_ce_0: 0  loss_mask_0: 1.214  loss_dice_0: 3.175  loss_ce_1: 0  loss_mask_1: 1.222  loss_dice_1: 3.129  loss_ce_2: 0  loss_mask_2: 1.226  loss_dice_2: 3.112  loss_ce_3: 0  loss_mask_3: 1.22  loss_dice_3: 3.1  loss_ce_4: 0  loss_mask_4: 1.225  loss_dice_4: 3.11  loss_ce_5: 0  loss_mask_5: 1.217  loss_dice_5: 3.109  loss_ce_6: 0  loss_mask_6: 1.213  loss_dice_6: 3.104  loss_ce_7: 0  loss_mask_7: 1.218  loss_dice_7: 3.108  loss_ce_8: 0  loss_mask_8: 1.217  loss_dice_8: 3.103  time: 2.3715  data_time: 0.0448  lr: 9.5158e-05  max_mem: 5999M
[02/18 01:24:21] d2.utils.events INFO:  eta: 2 days, 1:49:01  iter: 3239  total_loss: 42.73  loss_ce: 0  loss_mask: 1.14  loss_dice: 2.986  loss_seg: 0.9895  loss_ce_0: 0  loss_mask_0: 1.147  loss_dice_0: 3.099  loss_ce_1: 0  loss_mask_1: 1.149  loss_dice_1: 2.972  loss_ce_2: 0  loss_mask_2: 1.148  loss_dice_2: 2.96  loss_ce_3: 0  loss_mask_3: 1.144  loss_dice_3: 2.956  loss_ce_4: 0  loss_mask_4: 1.144  loss_dice_4: 2.954  loss_ce_5: 0  loss_mask_5: 1.142  loss_dice_5: 2.957  loss_ce_6: 0  loss_mask_6: 1.145  loss_dice_6: 2.955  loss_ce_7: 0  loss_mask_7: 1.146  loss_dice_7: 2.951  loss_ce_8: 0  loss_mask_8: 1.144  loss_dice_8: 2.956  time: 2.3812  data_time: 0.0422  lr: 9.5128e-05  max_mem: 5999M
[02/18 01:25:37] d2.utils.events INFO:  eta: 2 days, 1:47:58  iter: 3259  total_loss: 42.11  loss_ce: 0  loss_mask: 1.142  loss_dice: 3.037  loss_seg: 1.005  loss_ce_0: 0  loss_mask_0: 1.12  loss_dice_0: 3.125  loss_ce_1: 0  loss_mask_1: 1.138  loss_dice_1: 3.017  loss_ce_2: 0  loss_mask_2: 1.147  loss_dice_2: 2.996  loss_ce_3: 0  loss_mask_3: 1.142  loss_dice_3: 2.99  loss_ce_4: 0  loss_mask_4: 1.154  loss_dice_4: 2.99  loss_ce_5: 0  loss_mask_5: 1.152  loss_dice_5: 3.002  loss_ce_6: 0  loss_mask_6: 1.152  loss_dice_6: 2.999  loss_ce_7: 0  loss_mask_7: 1.153  loss_dice_7: 3.001  loss_ce_8: 0  loss_mask_8: 1.151  loss_dice_8: 3.004  time: 2.3898  data_time: 0.0365  lr: 9.5098e-05  max_mem: 5999M
[02/18 01:26:56] d2.utils.events INFO:  eta: 2 days, 2:43:53  iter: 3279  total_loss: 42.63  loss_ce: 0  loss_mask: 1.174  loss_dice: 3.107  loss_seg: 1.028  loss_ce_0: 0  loss_mask_0: 1.164  loss_dice_0: 3.144  loss_ce_1: 0  loss_mask_1: 1.17  loss_dice_1: 3.084  loss_ce_2: 0  loss_mask_2: 1.171  loss_dice_2: 3.081  loss_ce_3: 0  loss_mask_3: 1.172  loss_dice_3: 3.075  loss_ce_4: 0  loss_mask_4: 1.173  loss_dice_4: 3.082  loss_ce_5: 0  loss_mask_5: 1.173  loss_dice_5: 3.076  loss_ce_6: 0  loss_mask_6: 1.177  loss_dice_6: 3.07  loss_ce_7: 0  loss_mask_7: 1.175  loss_dice_7: 3.077  loss_ce_8: 0  loss_mask_8: 1.179  loss_dice_8: 3.082  time: 2.3994  data_time: 0.0420  lr: 9.5068e-05  max_mem: 5999M
[02/18 01:28:18] d2.utils.events INFO:  eta: 2 days, 4:52:41  iter: 3299  total_loss: 42.67  loss_ce: 0  loss_mask: 1.183  loss_dice: 3.004  loss_seg: 0.8078  loss_ce_0: 0  loss_mask_0: 1.182  loss_dice_0: 3.071  loss_ce_1: 0  loss_mask_1: 1.198  loss_dice_1: 2.985  loss_ce_2: 0  loss_mask_2: 1.195  loss_dice_2: 2.986  loss_ce_3: 0  loss_mask_3: 1.198  loss_dice_3: 2.974  loss_ce_4: 0  loss_mask_4: 1.198  loss_dice_4: 2.972  loss_ce_5: 0  loss_mask_5: 1.197  loss_dice_5: 2.982  loss_ce_6: 0  loss_mask_6: 1.194  loss_dice_6: 2.982  loss_ce_7: 0  loss_mask_7: 1.196  loss_dice_7: 2.982  loss_ce_8: 0  loss_mask_8: 1.192  loss_dice_8: 2.977  time: 2.4095  data_time: 0.0525  lr: 9.5038e-05  max_mem: 5999M
[02/18 01:29:38] d2.utils.events INFO:  eta: 2 days, 5:59:13  iter: 3319  total_loss: 44.75  loss_ce: 0  loss_mask: 1.175  loss_dice: 3.179  loss_seg: 0.9822  loss_ce_0: 0  loss_mask_0: 1.171  loss_dice_0: 3.239  loss_ce_1: 0  loss_mask_1: 1.178  loss_dice_1: 3.167  loss_ce_2: 0  loss_mask_2: 1.181  loss_dice_2: 3.149  loss_ce_3: 0  loss_mask_3: 1.18  loss_dice_3: 3.142  loss_ce_4: 0  loss_mask_4: 1.183  loss_dice_4: 3.142  loss_ce_5: 0  loss_mask_5: 1.179  loss_dice_5: 3.144  loss_ce_6: 0  loss_mask_6: 1.174  loss_dice_6: 3.146  loss_ce_7: 0  loss_mask_7: 1.184  loss_dice_7: 3.136  loss_ce_8: 0  loss_mask_8: 1.178  loss_dice_8: 3.148  time: 2.4191  data_time: 0.0565  lr: 9.5007e-05  max_mem: 5999M
[02/18 01:30:55] d2.utils.events INFO:  eta: 2 days, 7:12:06  iter: 3339  total_loss: 43.95  loss_ce: 0  loss_mask: 1.191  loss_dice: 3.095  loss_seg: 0.946  loss_ce_0: 0  loss_mask_0: 1.189  loss_dice_0: 3.12  loss_ce_1: 0  loss_mask_1: 1.191  loss_dice_1: 3.067  loss_ce_2: 0  loss_mask_2: 1.201  loss_dice_2: 3.059  loss_ce_3: 0  loss_mask_3: 1.201  loss_dice_3: 3.059  loss_ce_4: 0  loss_mask_4: 1.199  loss_dice_4: 3.063  loss_ce_5: 0  loss_mask_5: 1.203  loss_dice_5: 3.069  loss_ce_6: 0  loss_mask_6: 1.201  loss_dice_6: 3.067  loss_ce_7: 0  loss_mask_7: 1.204  loss_dice_7: 3.063  loss_ce_8: 0  loss_mask_8: 1.203  loss_dice_8: 3.065  time: 2.4278  data_time: 0.0559  lr: 9.4977e-05  max_mem: 5999M
[02/18 01:32:12] d2.utils.events INFO:  eta: 2 days, 7:46:46  iter: 3359  total_loss: 43.64  loss_ce: 0  loss_mask: 1.152  loss_dice: 3.107  loss_seg: 1.067  loss_ce_0: 0  loss_mask_0: 1.155  loss_dice_0: 3.173  loss_ce_1: 0  loss_mask_1: 1.153  loss_dice_1: 3.088  loss_ce_2: 0  loss_mask_2: 1.155  loss_dice_2: 3.076  loss_ce_3: 0  loss_mask_3: 1.157  loss_dice_3: 3.072  loss_ce_4: 0  loss_mask_4: 1.164  loss_dice_4: 3.072  loss_ce_5: 0  loss_mask_5: 1.164  loss_dice_5: 3.072  loss_ce_6: 0  loss_mask_6: 1.169  loss_dice_6: 3.084  loss_ce_7: 0  loss_mask_7: 1.163  loss_dice_7: 3.086  loss_ce_8: 0  loss_mask_8: 1.153  loss_dice_8: 3.088  time: 2.4362  data_time: 0.0576  lr: 9.4947e-05  max_mem: 5999M
[02/18 01:33:29] d2.utils.events INFO:  eta: 2 days, 8:03:45  iter: 3379  total_loss: 42.19  loss_ce: 0  loss_mask: 1.107  loss_dice: 2.983  loss_seg: 0.9939  loss_ce_0: 0  loss_mask_0: 1.091  loss_dice_0: 3.089  loss_ce_1: 0  loss_mask_1: 1.102  loss_dice_1: 2.973  loss_ce_2: 0  loss_mask_2: 1.11  loss_dice_2: 2.967  loss_ce_3: 0  loss_mask_3: 1.11  loss_dice_3: 2.957  loss_ce_4: 0  loss_mask_4: 1.112  loss_dice_4: 2.968  loss_ce_5: 0  loss_mask_5: 1.11  loss_dice_5: 2.969  loss_ce_6: 0  loss_mask_6: 1.112  loss_dice_6: 2.968  loss_ce_7: 0  loss_mask_7: 1.109  loss_dice_7: 2.963  loss_ce_8: 0  loss_mask_8: 1.112  loss_dice_8: 2.963  time: 2.4443  data_time: 0.0600  lr: 9.4917e-05  max_mem: 5999M
[02/18 01:34:50] d2.utils.events INFO:  eta: 2 days, 8:36:10  iter: 3399  total_loss: 40.64  loss_ce: 0  loss_mask: 1.063  loss_dice: 2.92  loss_seg: 0.9369  loss_ce_0: 0  loss_mask_0: 1.056  loss_dice_0: 2.998  loss_ce_1: 0  loss_mask_1: 1.062  loss_dice_1: 2.908  loss_ce_2: 0  loss_mask_2: 1.058  loss_dice_2: 2.89  loss_ce_3: 0  loss_mask_3: 1.062  loss_dice_3: 2.888  loss_ce_4: 0  loss_mask_4: 1.058  loss_dice_4: 2.893  loss_ce_5: 0  loss_mask_5: 1.065  loss_dice_5: 2.891  loss_ce_6: 0  loss_mask_6: 1.076  loss_dice_6: 2.895  loss_ce_7: 0  loss_mask_7: 1.074  loss_dice_7: 2.895  loss_ce_8: 0  loss_mask_8: 1.069  loss_dice_8: 2.9  time: 2.4537  data_time: 0.0491  lr: 9.4887e-05  max_mem: 5999M
[02/18 01:36:10] d2.utils.events INFO:  eta: 2 days, 8:58:50  iter: 3419  total_loss: 42.38  loss_ce: 0  loss_mask: 1.095  loss_dice: 2.966  loss_seg: 1.171  loss_ce_0: 0  loss_mask_0: 1.081  loss_dice_0: 3.074  loss_ce_1: 0  loss_mask_1: 1.097  loss_dice_1: 2.956  loss_ce_2: 0  loss_mask_2: 1.101  loss_dice_2: 2.947  loss_ce_3: 0  loss_mask_3: 1.107  loss_dice_3: 2.935  loss_ce_4: 0  loss_mask_4: 1.105  loss_dice_4: 2.944  loss_ce_5: 0  loss_mask_5: 1.105  loss_dice_5: 2.947  loss_ce_6: 0  loss_mask_6: 1.105  loss_dice_6: 2.951  loss_ce_7: 0  loss_mask_7: 1.105  loss_dice_7: 2.947  loss_ce_8: 0  loss_mask_8: 1.108  loss_dice_8: 2.939  time: 2.4628  data_time: 0.0399  lr: 9.4857e-05  max_mem: 5999M
[02/18 01:37:27] d2.utils.events INFO:  eta: 2 days, 9:14:07  iter: 3439  total_loss: 42.56  loss_ce: 0  loss_mask: 1.168  loss_dice: 3.039  loss_seg: 0.8213  loss_ce_0: 0  loss_mask_0: 1.161  loss_dice_0: 3.08  loss_ce_1: 0  loss_mask_1: 1.162  loss_dice_1: 3.029  loss_ce_2: 0  loss_mask_2: 1.159  loss_dice_2: 3.021  loss_ce_3: 0  loss_mask_3: 1.168  loss_dice_3: 3.011  loss_ce_4: 0  loss_mask_4: 1.171  loss_dice_4: 3.01  loss_ce_5: 0  loss_mask_5: 1.178  loss_dice_5: 3.004  loss_ce_6: 0  loss_mask_6: 1.173  loss_dice_6: 3.014  loss_ce_7: 0  loss_mask_7: 1.174  loss_dice_7: 3.01  loss_ce_8: 0  loss_mask_8: 1.176  loss_dice_8: 3.024  time: 2.4709  data_time: 0.0328  lr: 9.4826e-05  max_mem: 5999M
[02/18 01:38:45] d2.utils.events INFO:  eta: 2 days, 9:44:18  iter: 3459  total_loss: 43.81  loss_ce: 0  loss_mask: 1.191  loss_dice: 3.104  loss_seg: 0.8685  loss_ce_0: 0  loss_mask_0: 1.196  loss_dice_0: 3.124  loss_ce_1: 0  loss_mask_1: 1.191  loss_dice_1: 3.081  loss_ce_2: 0  loss_mask_2: 1.198  loss_dice_2: 3.085  loss_ce_3: 0  loss_mask_3: 1.202  loss_dice_3: 3.078  loss_ce_4: 0  loss_mask_4: 1.204  loss_dice_4: 3.085  loss_ce_5: 0  loss_mask_5: 1.209  loss_dice_5: 3.083  loss_ce_6: 0  loss_mask_6: 1.215  loss_dice_6: 3.083  loss_ce_7: 0  loss_mask_7: 1.211  loss_dice_7: 3.085  loss_ce_8: 0  loss_mask_8: 1.215  loss_dice_8: 3.088  time: 2.4791  data_time: 0.0384  lr: 9.4796e-05  max_mem: 5999M
[02/18 01:40:05] d2.utils.events INFO:  eta: 2 days, 10:01:49  iter: 3479  total_loss: 42.71  loss_ce: 0  loss_mask: 1.14  loss_dice: 2.978  loss_seg: 1.155  loss_ce_0: 0  loss_mask_0: 1.138  loss_dice_0: 3.033  loss_ce_1: 0  loss_mask_1: 1.145  loss_dice_1: 2.957  loss_ce_2: 0  loss_mask_2: 1.152  loss_dice_2: 2.947  loss_ce_3: 0  loss_mask_3: 1.148  loss_dice_3: 2.939  loss_ce_4: 0  loss_mask_4: 1.152  loss_dice_4: 2.941  loss_ce_5: 0  loss_mask_5: 1.15  loss_dice_5: 2.945  loss_ce_6: 0  loss_mask_6: 1.149  loss_dice_6: 2.945  loss_ce_7: 0  loss_mask_7: 1.147  loss_dice_7: 2.949  loss_ce_8: 0  loss_mask_8: 1.147  loss_dice_8: 2.955  time: 2.4879  data_time: 0.0420  lr: 9.4766e-05  max_mem: 5999M
[02/18 01:41:23] d2.utils.events INFO:  eta: 2 days, 10:29:43  iter: 3499  total_loss: 44.71  loss_ce: 0  loss_mask: 1.102  loss_dice: 3.105  loss_seg: 1.358  loss_ce_0: 0  loss_mask_0: 1.089  loss_dice_0: 3.179  loss_ce_1: 0  loss_mask_1: 1.096  loss_dice_1: 3.085  loss_ce_2: 0  loss_mask_2: 1.106  loss_dice_2: 3.079  loss_ce_3: 0  loss_mask_3: 1.106  loss_dice_3: 3.082  loss_ce_4: 0  loss_mask_4: 1.108  loss_dice_4: 3.079  loss_ce_5: 0  loss_mask_5: 1.106  loss_dice_5: 3.084  loss_ce_6: 0  loss_mask_6: 1.109  loss_dice_6: 3.083  loss_ce_7: 0  loss_mask_7: 1.104  loss_dice_7: 3.081  loss_ce_8: 0  loss_mask_8: 1.105  loss_dice_8: 3.083  time: 2.4957  data_time: 0.0450  lr: 9.4736e-05  max_mem: 5999M
[02/18 01:42:41] d2.utils.events INFO:  eta: 2 days, 10:28:29  iter: 3519  total_loss: 42.66  loss_ce: 0  loss_mask: 1.144  loss_dice: 3.004  loss_seg: 1.327  loss_ce_0: 0  loss_mask_0: 1.131  loss_dice_0: 3.071  loss_ce_1: 0  loss_mask_1: 1.147  loss_dice_1: 2.985  loss_ce_2: 0  loss_mask_2: 1.146  loss_dice_2: 2.975  loss_ce_3: 0  loss_mask_3: 1.147  loss_dice_3: 2.964  loss_ce_4: 0  loss_mask_4: 1.141  loss_dice_4: 2.971  loss_ce_5: 0  loss_mask_5: 1.145  loss_dice_5: 2.977  loss_ce_6: 0  loss_mask_6: 1.142  loss_dice_6: 2.97  loss_ce_7: 0  loss_mask_7: 1.146  loss_dice_7: 2.972  loss_ce_8: 0  loss_mask_8: 1.145  loss_dice_8: 2.978  time: 2.5037  data_time: 0.0315  lr: 9.4706e-05  max_mem: 5999M
[02/18 01:44:04] d2.utils.events INFO:  eta: 2 days, 10:37:14  iter: 3539  total_loss: 42.2  loss_ce: 0  loss_mask: 1.121  loss_dice: 2.989  loss_seg: 0.9509  loss_ce_0: 0  loss_mask_0: 1.096  loss_dice_0: 3.05  loss_ce_1: 0  loss_mask_1: 1.119  loss_dice_1: 2.972  loss_ce_2: 0  loss_mask_2: 1.125  loss_dice_2: 2.962  loss_ce_3: 0  loss_mask_3: 1.137  loss_dice_3: 2.955  loss_ce_4: 0  loss_mask_4: 1.132  loss_dice_4: 2.961  loss_ce_5: 0  loss_mask_5: 1.133  loss_dice_5: 2.971  loss_ce_6: 0  loss_mask_6: 1.134  loss_dice_6: 2.97  loss_ce_7: 0  loss_mask_7: 1.128  loss_dice_7: 2.971  loss_ce_8: 0  loss_mask_8: 1.129  loss_dice_8: 2.973  time: 2.5130  data_time: 0.0314  lr: 9.4675e-05  max_mem: 5999M
[02/18 01:45:26] d2.utils.events INFO:  eta: 2 days, 11:13:00  iter: 3559  total_loss: 42.24  loss_ce: 0  loss_mask: 1.103  loss_dice: 3.034  loss_seg: 1.074  loss_ce_0: 0  loss_mask_0: 1.094  loss_dice_0: 3.079  loss_ce_1: 0  loss_mask_1: 1.116  loss_dice_1: 3.02  loss_ce_2: 0  loss_mask_2: 1.117  loss_dice_2: 3.003  loss_ce_3: 0  loss_mask_3: 1.112  loss_dice_3: 2.999  loss_ce_4: 0  loss_mask_4: 1.113  loss_dice_4: 3.001  loss_ce_5: 0  loss_mask_5: 1.114  loss_dice_5: 3.007  loss_ce_6: 0  loss_mask_6: 1.11  loss_dice_6: 3.004  loss_ce_7: 0  loss_mask_7: 1.113  loss_dice_7: 3.007  loss_ce_8: 0  loss_mask_8: 1.113  loss_dice_8: 3.008  time: 2.5218  data_time: 0.0346  lr: 9.4645e-05  max_mem: 5999M
[02/18 01:46:44] d2.utils.events INFO:  eta: 2 days, 11:46:46  iter: 3579  total_loss: 43.04  loss_ce: 0  loss_mask: 1.097  loss_dice: 3.024  loss_seg: 1.041  loss_ce_0: 0  loss_mask_0: 1.073  loss_dice_0: 3.09  loss_ce_1: 0  loss_mask_1: 1.09  loss_dice_1: 2.998  loss_ce_2: 0  loss_mask_2: 1.102  loss_dice_2: 2.991  loss_ce_3: 0  loss_mask_3: 1.108  loss_dice_3: 2.985  loss_ce_4: 0  loss_mask_4: 1.11  loss_dice_4: 2.99  loss_ce_5: 0  loss_mask_5: 1.113  loss_dice_5: 2.99  loss_ce_6: 0  loss_mask_6: 1.115  loss_dice_6: 2.981  loss_ce_7: 0  loss_mask_7: 1.115  loss_dice_7: 2.985  loss_ce_8: 0  loss_mask_8: 1.117  loss_dice_8: 2.988  time: 2.5295  data_time: 0.0436  lr: 9.4615e-05  max_mem: 5999M
[02/18 01:48:04] d2.utils.events INFO:  eta: 2 days, 12:05:06  iter: 3599  total_loss: 43.13  loss_ce: 0  loss_mask: 1.151  loss_dice: 3.033  loss_seg: 1.007  loss_ce_0: 0  loss_mask_0: 1.134  loss_dice_0: 3.069  loss_ce_1: 0  loss_mask_1: 1.16  loss_dice_1: 3.015  loss_ce_2: 0  loss_mask_2: 1.167  loss_dice_2: 3.013  loss_ce_3: 0  loss_mask_3: 1.166  loss_dice_3: 3.008  loss_ce_4: 0  loss_mask_4: 1.164  loss_dice_4: 3.011  loss_ce_5: 0  loss_mask_5: 1.16  loss_dice_5: 3.011  loss_ce_6: 0  loss_mask_6: 1.157  loss_dice_6: 3.01  loss_ce_7: 0  loss_mask_7: 1.161  loss_dice_7: 3.015  loss_ce_8: 0  loss_mask_8: 1.163  loss_dice_8: 3.019  time: 2.5379  data_time: 0.0428  lr: 9.4585e-05  max_mem: 5999M
[02/18 01:49:20] d2.utils.events INFO:  eta: 2 days, 12:18:07  iter: 3619  total_loss: 42.88  loss_ce: 0  loss_mask: 1.154  loss_dice: 3.077  loss_seg: 0.8229  loss_ce_0: 0  loss_mask_0: 1.152  loss_dice_0: 3.111  loss_ce_1: 0  loss_mask_1: 1.159  loss_dice_1: 3.06  loss_ce_2: 0  loss_mask_2: 1.157  loss_dice_2: 3.045  loss_ce_3: 0  loss_mask_3: 1.168  loss_dice_3: 3.043  loss_ce_4: 0  loss_mask_4: 1.168  loss_dice_4: 3.043  loss_ce_5: 0  loss_mask_5: 1.164  loss_dice_5: 3.053  loss_ce_6: 0  loss_mask_6: 1.163  loss_dice_6: 3.048  loss_ce_7: 0  loss_mask_7: 1.161  loss_dice_7: 3.059  loss_ce_8: 0  loss_mask_8: 1.163  loss_dice_8: 3.053  time: 2.5446  data_time: 0.0485  lr: 9.4555e-05  max_mem: 5999M
[02/18 01:50:37] d2.utils.events INFO:  eta: 2 days, 12:31:45  iter: 3639  total_loss: 42.17  loss_ce: 0  loss_mask: 1.143  loss_dice: 3.01  loss_seg: 0.933  loss_ce_0: 0  loss_mask_0: 1.143  loss_dice_0: 3.031  loss_ce_1: 0  loss_mask_1: 1.161  loss_dice_1: 2.98  loss_ce_2: 0  loss_mask_2: 1.155  loss_dice_2: 2.982  loss_ce_3: 0  loss_mask_3: 1.154  loss_dice_3: 2.975  loss_ce_4: 0  loss_mask_4: 1.154  loss_dice_4: 2.979  loss_ce_5: 0  loss_mask_5: 1.155  loss_dice_5: 2.984  loss_ce_6: 0  loss_mask_6: 1.149  loss_dice_6: 2.977  loss_ce_7: 0  loss_mask_7: 1.144  loss_dice_7: 2.976  loss_ce_8: 0  loss_mask_8: 1.15  loss_dice_8: 2.971  time: 2.5519  data_time: 0.0379  lr: 9.4525e-05  max_mem: 5999M
[02/18 01:51:56] d2.utils.events INFO:  eta: 2 days, 12:57:57  iter: 3659  total_loss: 43.05  loss_ce: 0  loss_mask: 1.151  loss_dice: 2.99  loss_seg: 0.8225  loss_ce_0: 0  loss_mask_0: 1.155  loss_dice_0: 3.037  loss_ce_1: 0  loss_mask_1: 1.151  loss_dice_1: 2.971  loss_ce_2: 0  loss_mask_2: 1.16  loss_dice_2: 2.971  loss_ce_3: 0  loss_mask_3: 1.165  loss_dice_3: 2.971  loss_ce_4: 0  loss_mask_4: 1.161  loss_dice_4: 2.969  loss_ce_5: 0  loss_mask_5: 1.166  loss_dice_5: 2.97  loss_ce_6: 0  loss_mask_6: 1.169  loss_dice_6: 2.966  loss_ce_7: 0  loss_mask_7: 1.167  loss_dice_7: 2.971  loss_ce_8: 0  loss_mask_8: 1.155  loss_dice_8: 2.974  time: 2.5593  data_time: 0.0389  lr: 9.4494e-05  max_mem: 5999M
[02/18 01:53:21] d2.utils.events INFO:  eta: 2 days, 13:21:40  iter: 3679  total_loss: 43.36  loss_ce: 0  loss_mask: 1.158  loss_dice: 3.08  loss_seg: 1.046  loss_ce_0: 0  loss_mask_0: 1.155  loss_dice_0: 3.105  loss_ce_1: 0  loss_mask_1: 1.169  loss_dice_1: 3.063  loss_ce_2: 0  loss_mask_2: 1.167  loss_dice_2: 3.055  loss_ce_3: 0  loss_mask_3: 1.163  loss_dice_3: 3.053  loss_ce_4: 0  loss_mask_4: 1.165  loss_dice_4: 3.061  loss_ce_5: 0  loss_mask_5: 1.168  loss_dice_5: 3.054  loss_ce_6: 0  loss_mask_6: 1.167  loss_dice_6: 3.059  loss_ce_7: 0  loss_mask_7: 1.167  loss_dice_7: 3.052  loss_ce_8: 0  loss_mask_8: 1.176  loss_dice_8: 3.055  time: 2.5686  data_time: 0.0375  lr: 9.4464e-05  max_mem: 5999M
[02/18 01:54:43] d2.utils.events INFO:  eta: 2 days, 13:40:17  iter: 3699  total_loss: 42.5  loss_ce: 0  loss_mask: 1.15  loss_dice: 2.996  loss_seg: 0.9745  loss_ce_0: 0  loss_mask_0: 1.161  loss_dice_0: 3.059  loss_ce_1: 0  loss_mask_1: 1.15  loss_dice_1: 2.997  loss_ce_2: 0  loss_mask_2: 1.158  loss_dice_2: 2.982  loss_ce_3: 0  loss_mask_3: 1.159  loss_dice_3: 2.978  loss_ce_4: 0  loss_mask_4: 1.164  loss_dice_4: 2.976  loss_ce_5: 0  loss_mask_5: 1.167  loss_dice_5: 2.983  loss_ce_6: 0  loss_mask_6: 1.174  loss_dice_6: 2.977  loss_ce_7: 0  loss_mask_7: 1.171  loss_dice_7: 2.975  loss_ce_8: 0  loss_mask_8: 1.171  loss_dice_8: 2.978  time: 2.5767  data_time: 0.0408  lr: 9.4434e-05  max_mem: 5999M
[02/18 01:56:05] d2.utils.events INFO:  eta: 2 days, 14:08:05  iter: 3719  total_loss: 41.93  loss_ce: 0  loss_mask: 1.111  loss_dice: 3.013  loss_seg: 1.027  loss_ce_0: 0  loss_mask_0: 1.111  loss_dice_0: 3.087  loss_ce_1: 0  loss_mask_1: 1.116  loss_dice_1: 2.99  loss_ce_2: 0  loss_mask_2: 1.122  loss_dice_2: 2.986  loss_ce_3: 0  loss_mask_3: 1.121  loss_dice_3: 2.983  loss_ce_4: 0  loss_mask_4: 1.12  loss_dice_4: 2.985  loss_ce_5: 0  loss_mask_5: 1.121  loss_dice_5: 2.984  loss_ce_6: 0  loss_mask_6: 1.12  loss_dice_6: 2.992  loss_ce_7: 0  loss_mask_7: 1.117  loss_dice_7: 2.989  loss_ce_8: 0  loss_mask_8: 1.123  loss_dice_8: 2.986  time: 2.5850  data_time: 0.0356  lr: 9.4404e-05  max_mem: 5999M
[02/18 01:57:25] d2.utils.events INFO:  eta: 2 days, 14:29:02  iter: 3739  total_loss: 41.73  loss_ce: 0  loss_mask: 1.12  loss_dice: 3.002  loss_seg: 1.248  loss_ce_0: 0  loss_mask_0: 1.109  loss_dice_0: 3.061  loss_ce_1: 0  loss_mask_1: 1.127  loss_dice_1: 2.967  loss_ce_2: 0  loss_mask_2: 1.13  loss_dice_2: 2.954  loss_ce_3: 0  loss_mask_3: 1.13  loss_dice_3: 2.946  loss_ce_4: 0  loss_mask_4: 1.131  loss_dice_4: 2.948  loss_ce_5: 0  loss_mask_5: 1.133  loss_dice_5: 2.955  loss_ce_6: 0  loss_mask_6: 1.126  loss_dice_6: 2.96  loss_ce_7: 0  loss_mask_7: 1.125  loss_dice_7: 2.953  loss_ce_8: 0  loss_mask_8: 1.123  loss_dice_8: 2.96  time: 2.5925  data_time: 0.0382  lr: 9.4374e-05  max_mem: 5999M
[02/18 01:58:40] d2.utils.events INFO:  eta: 2 days, 14:35:46  iter: 3759  total_loss: 42.31  loss_ce: 0  loss_mask: 1.151  loss_dice: 2.976  loss_seg: 0.9011  loss_ce_0: 0  loss_mask_0: 1.156  loss_dice_0: 3.019  loss_ce_1: 0  loss_mask_1: 1.153  loss_dice_1: 2.956  loss_ce_2: 0  loss_mask_2: 1.136  loss_dice_2: 2.955  loss_ce_3: 0  loss_mask_3: 1.14  loss_dice_3: 2.947  loss_ce_4: 0  loss_mask_4: 1.146  loss_dice_4: 2.942  loss_ce_5: 0  loss_mask_5: 1.146  loss_dice_5: 2.945  loss_ce_6: 0  loss_mask_6: 1.146  loss_dice_6: 2.949  loss_ce_7: 0  loss_mask_7: 1.148  loss_dice_7: 2.946  loss_ce_8: 0  loss_mask_8: 1.148  loss_dice_8: 2.952  time: 2.5987  data_time: 0.0363  lr: 9.4343e-05  max_mem: 5999M
[02/18 01:59:55] d2.utils.events INFO:  eta: 2 days, 14:40:02  iter: 3779  total_loss: 43.61  loss_ce: 0  loss_mask: 1.1  loss_dice: 3.059  loss_seg: 1.046  loss_ce_0: 0  loss_mask_0: 1.112  loss_dice_0: 3.102  loss_ce_1: 0  loss_mask_1: 1.121  loss_dice_1: 3.03  loss_ce_2: 0  loss_mask_2: 1.117  loss_dice_2: 3.018  loss_ce_3: 0  loss_mask_3: 1.116  loss_dice_3: 3.02  loss_ce_4: 0  loss_mask_4: 1.113  loss_dice_4: 3.02  loss_ce_5: 0  loss_mask_5: 1.119  loss_dice_5: 3.021  loss_ce_6: 0  loss_mask_6: 1.114  loss_dice_6: 3.017  loss_ce_7: 0  loss_mask_7: 1.115  loss_dice_7: 3.017  loss_ce_8: 0  loss_mask_8: 1.112  loss_dice_8: 3.023  time: 2.6047  data_time: 0.0366  lr: 9.4313e-05  max_mem: 5999M
[02/18 02:01:11] d2.utils.events INFO:  eta: 2 days, 14:38:42  iter: 3799  total_loss: 42.71  loss_ce: 0  loss_mask: 1.144  loss_dice: 2.925  loss_seg: 1.404  loss_ce_0: 0  loss_mask_0: 1.145  loss_dice_0: 2.977  loss_ce_1: 0  loss_mask_1: 1.158  loss_dice_1: 2.917  loss_ce_2: 0  loss_mask_2: 1.159  loss_dice_2: 2.91  loss_ce_3: 0  loss_mask_3: 1.164  loss_dice_3: 2.913  loss_ce_4: 0  loss_mask_4: 1.153  loss_dice_4: 2.911  loss_ce_5: 0  loss_mask_5: 1.153  loss_dice_5: 2.909  loss_ce_6: 0  loss_mask_6: 1.153  loss_dice_6: 2.913  loss_ce_7: 0  loss_mask_7: 1.155  loss_dice_7: 2.917  loss_ce_8: 0  loss_mask_8: 1.157  loss_dice_8: 2.916  time: 2.6109  data_time: 0.0308  lr: 9.4283e-05  max_mem: 5999M
[02/18 02:02:29] d2.utils.events INFO:  eta: 2 days, 14:39:24  iter: 3819  total_loss: 42.84  loss_ce: 0  loss_mask: 1.125  loss_dice: 3.086  loss_seg: 1.042  loss_ce_0: 0  loss_mask_0: 1.112  loss_dice_0: 3.113  loss_ce_1: 0  loss_mask_1: 1.119  loss_dice_1: 3.061  loss_ce_2: 0  loss_mask_2: 1.12  loss_dice_2: 3.057  loss_ce_3: 0  loss_mask_3: 1.125  loss_dice_3: 3.054  loss_ce_4: 0  loss_mask_4: 1.122  loss_dice_4: 3.061  loss_ce_5: 0  loss_mask_5: 1.121  loss_dice_5: 3.064  loss_ce_6: 0  loss_mask_6: 1.129  loss_dice_6: 3.061  loss_ce_7: 0  loss_mask_7: 1.126  loss_dice_7: 3.056  loss_ce_8: 0  loss_mask_8: 1.133  loss_dice_8: 3.053  time: 2.6177  data_time: 0.0415  lr: 9.4253e-05  max_mem: 5999M
[02/18 02:03:43] d2.utils.events INFO:  eta: 2 days, 14:30:25  iter: 3839  total_loss: 41.87  loss_ce: 0  loss_mask: 1.097  loss_dice: 2.959  loss_seg: 0.9438  loss_ce_0: 0  loss_mask_0: 1.097  loss_dice_0: 3.014  loss_ce_1: 0  loss_mask_1: 1.099  loss_dice_1: 2.938  loss_ce_2: 0  loss_mask_2: 1.102  loss_dice_2: 2.928  loss_ce_3: 0  loss_mask_3: 1.104  loss_dice_3: 2.916  loss_ce_4: 0  loss_mask_4: 1.103  loss_dice_4: 2.915  loss_ce_5: 0  loss_mask_5: 1.108  loss_dice_5: 2.919  loss_ce_6: 0  loss_mask_6: 1.105  loss_dice_6: 2.929  loss_ce_7: 0  loss_mask_7: 1.103  loss_dice_7: 2.93  loss_ce_8: 0  loss_mask_8: 1.104  loss_dice_8: 2.935  time: 2.6234  data_time: 0.0435  lr: 9.4223e-05  max_mem: 5999M
[02/18 02:05:02] d2.utils.events INFO:  eta: 2 days, 14:26:49  iter: 3859  total_loss: 41.83  loss_ce: 0  loss_mask: 1.123  loss_dice: 2.941  loss_seg: 0.8173  loss_ce_0: 0  loss_mask_0: 1.118  loss_dice_0: 2.993  loss_ce_1: 0  loss_mask_1: 1.128  loss_dice_1: 2.927  loss_ce_2: 0  loss_mask_2: 1.125  loss_dice_2: 2.92  loss_ce_3: 0  loss_mask_3: 1.13  loss_dice_3: 2.916  loss_ce_4: 0  loss_mask_4: 1.131  loss_dice_4: 2.919  loss_ce_5: 0  loss_mask_5: 1.132  loss_dice_5: 2.918  loss_ce_6: 0  loss_mask_6: 1.136  loss_dice_6: 2.913  loss_ce_7: 0  loss_mask_7: 1.136  loss_dice_7: 2.917  loss_ce_8: 0  loss_mask_8: 1.137  loss_dice_8: 2.911  time: 2.6302  data_time: 0.0347  lr: 9.4192e-05  max_mem: 5999M
[02/18 02:06:20] d2.utils.events INFO:  eta: 2 days, 14:25:29  iter: 3879  total_loss: 41.32  loss_ce: 0  loss_mask: 1.13  loss_dice: 2.936  loss_seg: 1.009  loss_ce_0: 0  loss_mask_0: 1.133  loss_dice_0: 2.992  loss_ce_1: 0  loss_mask_1: 1.133  loss_dice_1: 2.918  loss_ce_2: 0  loss_mask_2: 1.134  loss_dice_2: 2.916  loss_ce_3: 0  loss_mask_3: 1.143  loss_dice_3: 2.911  loss_ce_4: 0  loss_mask_4: 1.132  loss_dice_4: 2.906  loss_ce_5: 0  loss_mask_5: 1.137  loss_dice_5: 2.922  loss_ce_6: 0  loss_mask_6: 1.144  loss_dice_6: 2.916  loss_ce_7: 0  loss_mask_7: 1.142  loss_dice_7: 2.91  loss_ce_8: 0  loss_mask_8: 1.142  loss_dice_8: 2.911  time: 2.6369  data_time: 0.0355  lr: 9.4162e-05  max_mem: 5999M
[02/18 02:07:37] d2.utils.events INFO:  eta: 2 days, 14:16:03  iter: 3899  total_loss: 43.28  loss_ce: 0  loss_mask: 1.097  loss_dice: 3.104  loss_seg: 1.298  loss_ce_0: 0  loss_mask_0: 1.113  loss_dice_0: 3.149  loss_ce_1: 0  loss_mask_1: 1.101  loss_dice_1: 3.075  loss_ce_2: 0  loss_mask_2: 1.11  loss_dice_2: 3.06  loss_ce_3: 0  loss_mask_3: 1.114  loss_dice_3: 3.057  loss_ce_4: 0  loss_mask_4: 1.114  loss_dice_4: 3.065  loss_ce_5: 0  loss_mask_5: 1.115  loss_dice_5: 3.069  loss_ce_6: 0  loss_mask_6: 1.112  loss_dice_6: 3.073  loss_ce_7: 0  loss_mask_7: 1.111  loss_dice_7: 3.072  loss_ce_8: 0  loss_mask_8: 1.117  loss_dice_8: 3.072  time: 2.6431  data_time: 0.0390  lr: 9.4132e-05  max_mem: 5999M
[02/18 02:08:59] d2.utils.events INFO:  eta: 2 days, 14:19:39  iter: 3919  total_loss: 42.57  loss_ce: 0  loss_mask: 1.15  loss_dice: 2.96  loss_seg: 0.9702  loss_ce_0: 0  loss_mask_0: 1.145  loss_dice_0: 2.99  loss_ce_1: 0  loss_mask_1: 1.143  loss_dice_1: 2.923  loss_ce_2: 0  loss_mask_2: 1.15  loss_dice_2: 2.92  loss_ce_3: 0  loss_mask_3: 1.153  loss_dice_3: 2.927  loss_ce_4: 0  loss_mask_4: 1.16  loss_dice_4: 2.929  loss_ce_5: 0  loss_mask_5: 1.157  loss_dice_5: 2.921  loss_ce_6: 0  loss_mask_6: 1.159  loss_dice_6: 2.925  loss_ce_7: 0  loss_mask_7: 1.162  loss_dice_7: 2.928  loss_ce_8: 0  loss_mask_8: 1.159  loss_dice_8: 2.935  time: 2.6503  data_time: 0.0401  lr: 9.4102e-05  max_mem: 5999M
[02/18 02:10:18] d2.utils.events INFO:  eta: 2 days, 14:19:23  iter: 3939  total_loss: 42.44  loss_ce: 0  loss_mask: 1.088  loss_dice: 3.032  loss_seg: 1.091  loss_ce_0: 0  loss_mask_0: 1.092  loss_dice_0: 3.077  loss_ce_1: 0  loss_mask_1: 1.087  loss_dice_1: 3.025  loss_ce_2: 0  loss_mask_2: 1.09  loss_dice_2: 3.015  loss_ce_3: 0  loss_mask_3: 1.088  loss_dice_3: 3.011  loss_ce_4: 0  loss_mask_4: 1.096  loss_dice_4: 3.014  loss_ce_5: 0  loss_mask_5: 1.096  loss_dice_5: 3.009  loss_ce_6: 0  loss_mask_6: 1.098  loss_dice_6: 3.015  loss_ce_7: 0  loss_mask_7: 1.094  loss_dice_7: 3.01  loss_ce_8: 0  loss_mask_8: 1.097  loss_dice_8: 3.015  time: 2.6570  data_time: 0.0330  lr: 9.4072e-05  max_mem: 5999M
[02/18 02:11:37] d2.utils.events INFO:  eta: 2 days, 14:18:03  iter: 3959  total_loss: 42.29  loss_ce: 0  loss_mask: 1.083  loss_dice: 3.036  loss_seg: 1.09  loss_ce_0: 0  loss_mask_0: 1.091  loss_dice_0: 3.071  loss_ce_1: 0  loss_mask_1: 1.085  loss_dice_1: 3.016  loss_ce_2: 0  loss_mask_2: 1.087  loss_dice_2: 3.009  loss_ce_3: 0  loss_mask_3: 1.088  loss_dice_3: 3.011  loss_ce_4: 0  loss_mask_4: 1.091  loss_dice_4: 3.012  loss_ce_5: 0  loss_mask_5: 1.095  loss_dice_5: 3.008  loss_ce_6: 0  loss_mask_6: 1.093  loss_dice_6: 3.002  loss_ce_7: 0  loss_mask_7: 1.092  loss_dice_7: 3.013  loss_ce_8: 0  loss_mask_8: 1.086  loss_dice_8: 3.013  time: 2.6634  data_time: 0.0455  lr: 9.4041e-05  max_mem: 5999M
[02/18 02:12:57] d2.utils.events INFO:  eta: 2 days, 14:19:59  iter: 3979  total_loss: 41.06  loss_ce: 0  loss_mask: 1.088  loss_dice: 2.912  loss_seg: 1.03  loss_ce_0: 0  loss_mask_0: 1.079  loss_dice_0: 2.986  loss_ce_1: 0  loss_mask_1: 1.087  loss_dice_1: 2.892  loss_ce_2: 0  loss_mask_2: 1.087  loss_dice_2: 2.877  loss_ce_3: 0  loss_mask_3: 1.081  loss_dice_3: 2.875  loss_ce_4: 0  loss_mask_4: 1.083  loss_dice_4: 2.881  loss_ce_5: 0  loss_mask_5: 1.083  loss_dice_5: 2.883  loss_ce_6: 0  loss_mask_6: 1.081  loss_dice_6: 2.884  loss_ce_7: 0  loss_mask_7: 1.082  loss_dice_7: 2.886  loss_ce_8: 0  loss_mask_8: 1.086  loss_dice_8: 2.885  time: 2.6700  data_time: 0.0406  lr: 9.4011e-05  max_mem: 5999M
[02/18 02:14:13] d2.utils.events INFO:  eta: 2 days, 14:15:22  iter: 3999  total_loss: 43.13  loss_ce: 0  loss_mask: 1.135  loss_dice: 3.05  loss_seg: 1.088  loss_ce_0: 0  loss_mask_0: 1.136  loss_dice_0: 3.102  loss_ce_1: 0  loss_mask_1: 1.132  loss_dice_1: 3.019  loss_ce_2: 0  loss_mask_2: 1.135  loss_dice_2: 3.012  loss_ce_3: 0  loss_mask_3: 1.135  loss_dice_3: 3.023  loss_ce_4: 0  loss_mask_4: 1.134  loss_dice_4: 3.022  loss_ce_5: 0  loss_mask_5: 1.139  loss_dice_5: 3.026  loss_ce_6: 0  loss_mask_6: 1.139  loss_dice_6: 3.026  loss_ce_7: 0  loss_mask_7: 1.138  loss_dice_7: 3.032  loss_ce_8: 0  loss_mask_8: 1.14  loss_dice_8: 3.028  time: 2.6758  data_time: 0.0376  lr: 9.3981e-05  max_mem: 5999M
[02/18 02:15:30] d2.utils.events INFO:  eta: 2 days, 14:10:23  iter: 4019  total_loss: 42.21  loss_ce: 0  loss_mask: 1.126  loss_dice: 2.994  loss_seg: 1.108  loss_ce_0: 0  loss_mask_0: 1.111  loss_dice_0: 3.06  loss_ce_1: 0  loss_mask_1: 1.119  loss_dice_1: 2.965  loss_ce_2: 0  loss_mask_2: 1.125  loss_dice_2: 2.96  loss_ce_3: 0  loss_mask_3: 1.136  loss_dice_3: 2.956  loss_ce_4: 0  loss_mask_4: 1.134  loss_dice_4: 2.961  loss_ce_5: 0  loss_mask_5: 1.137  loss_dice_5: 2.962  loss_ce_6: 0  loss_mask_6: 1.136  loss_dice_6: 2.967  loss_ce_7: 0  loss_mask_7: 1.134  loss_dice_7: 2.965  loss_ce_8: 0  loss_mask_8: 1.13  loss_dice_8: 2.97  time: 2.6816  data_time: 0.0399  lr: 9.3951e-05  max_mem: 5999M
[02/18 02:16:40] d2.utils.events INFO:  eta: 2 days, 13:53:53  iter: 4039  total_loss: 42.36  loss_ce: 0  loss_mask: 1.12  loss_dice: 2.961  loss_seg: 0.8206  loss_ce_0: 0  loss_mask_0: 1.113  loss_dice_0: 3.03  loss_ce_1: 0  loss_mask_1: 1.128  loss_dice_1: 2.962  loss_ce_2: 0  loss_mask_2: 1.126  loss_dice_2: 2.94  loss_ce_3: 0  loss_mask_3: 1.134  loss_dice_3: 2.93  loss_ce_4: 0  loss_mask_4: 1.132  loss_dice_4: 2.936  loss_ce_5: 0  loss_mask_5: 1.125  loss_dice_5: 2.932  loss_ce_6: 0  loss_mask_6: 1.126  loss_dice_6: 2.942  loss_ce_7: 0  loss_mask_7: 1.126  loss_dice_7: 2.94  loss_ce_8: 0  loss_mask_8: 1.133  loss_dice_8: 2.95  time: 2.6855  data_time: 0.0544  lr: 9.3921e-05  max_mem: 5999M
[02/18 02:18:00] d2.utils.events INFO:  eta: 2 days, 13:56:24  iter: 4059  total_loss: 42.17  loss_ce: 0  loss_mask: 1.063  loss_dice: 2.956  loss_seg: 0.9987  loss_ce_0: 0  loss_mask_0: 1.056  loss_dice_0: 3.023  loss_ce_1: 0  loss_mask_1: 1.076  loss_dice_1: 2.948  loss_ce_2: 0  loss_mask_2: 1.082  loss_dice_2: 2.934  loss_ce_3: 0  loss_mask_3: 1.075  loss_dice_3: 2.928  loss_ce_4: 0  loss_mask_4: 1.077  loss_dice_4: 2.933  loss_ce_5: 0  loss_mask_5: 1.085  loss_dice_5: 2.932  loss_ce_6: 0  loss_mask_6: 1.081  loss_dice_6: 2.931  loss_ce_7: 0  loss_mask_7: 1.081  loss_dice_7: 2.933  loss_ce_8: 0  loss_mask_8: 1.077  loss_dice_8: 2.932  time: 2.6921  data_time: 0.0376  lr: 9.389e-05  max_mem: 5999M
[02/18 02:19:17] d2.utils.events INFO:  eta: 2 days, 13:51:13  iter: 4079  total_loss: 40.05  loss_ce: 0  loss_mask: 1.087  loss_dice: 2.819  loss_seg: 0.8546  loss_ce_0: 0  loss_mask_0: 1.086  loss_dice_0: 2.877  loss_ce_1: 0  loss_mask_1: 1.09  loss_dice_1: 2.795  loss_ce_2: 0  loss_mask_2: 1.087  loss_dice_2: 2.779  loss_ce_3: 0  loss_mask_3: 1.087  loss_dice_3: 2.781  loss_ce_4: 0  loss_mask_4: 1.088  loss_dice_4: 2.788  loss_ce_5: 0  loss_mask_5: 1.088  loss_dice_5: 2.787  loss_ce_6: 0  loss_mask_6: 1.09  loss_dice_6: 2.785  loss_ce_7: 0  loss_mask_7: 1.09  loss_dice_7: 2.793  loss_ce_8: 0  loss_mask_8: 1.087  loss_dice_8: 2.788  time: 2.6978  data_time: 0.0374  lr: 9.386e-05  max_mem: 5999M
[02/18 02:20:37] d2.utils.events INFO:  eta: 2 days, 13:47:06  iter: 4099  total_loss: 41.94  loss_ce: 0  loss_mask: 1.11  loss_dice: 2.993  loss_seg: 0.9148  loss_ce_0: 0  loss_mask_0: 1.091  loss_dice_0: 3.044  loss_ce_1: 0  loss_mask_1: 1.123  loss_dice_1: 2.979  loss_ce_2: 0  loss_mask_2: 1.121  loss_dice_2: 2.97  loss_ce_3: 0  loss_mask_3: 1.125  loss_dice_3: 2.96  loss_ce_4: 0  loss_mask_4: 1.127  loss_dice_4: 2.965  loss_ce_5: 0  loss_mask_5: 1.127  loss_dice_5: 2.972  loss_ce_6: 0  loss_mask_6: 1.124  loss_dice_6: 2.968  loss_ce_7: 0  loss_mask_7: 1.131  loss_dice_7: 2.971  loss_ce_8: 0  loss_mask_8: 1.133  loss_dice_8: 2.967  time: 2.7039  data_time: 0.0414  lr: 9.383e-05  max_mem: 5999M
[02/18 02:21:56] d2.utils.events INFO:  eta: 2 days, 13:56:22  iter: 4119  total_loss: 41.83  loss_ce: 0  loss_mask: 1.128  loss_dice: 2.991  loss_seg: 1.202  loss_ce_0: 0  loss_mask_0: 1.128  loss_dice_0: 3.076  loss_ce_1: 0  loss_mask_1: 1.135  loss_dice_1: 2.984  loss_ce_2: 0  loss_mask_2: 1.138  loss_dice_2: 2.975  loss_ce_3: 0  loss_mask_3: 1.134  loss_dice_3: 2.962  loss_ce_4: 0  loss_mask_4: 1.138  loss_dice_4: 2.963  loss_ce_5: 0  loss_mask_5: 1.138  loss_dice_5: 2.966  loss_ce_6: 0  loss_mask_6: 1.14  loss_dice_6: 2.965  loss_ce_7: 0  loss_mask_7: 1.138  loss_dice_7: 2.968  loss_ce_8: 0  loss_mask_8: 1.138  loss_dice_8: 2.971  time: 2.7101  data_time: 0.0363  lr: 9.38e-05  max_mem: 5999M
[02/18 02:23:13] d2.utils.events INFO:  eta: 2 days, 13:52:44  iter: 4139  total_loss: 40.83  loss_ce: 0  loss_mask: 1.09  loss_dice: 2.846  loss_seg: 1.077  loss_ce_0: 0  loss_mask_0: 1.079  loss_dice_0: 2.936  loss_ce_1: 0  loss_mask_1: 1.091  loss_dice_1: 2.84  loss_ce_2: 0  loss_mask_2: 1.09  loss_dice_2: 2.823  loss_ce_3: 0  loss_mask_3: 1.09  loss_dice_3: 2.816  loss_ce_4: 0  loss_mask_4: 1.091  loss_dice_4: 2.82  loss_ce_5: 0  loss_mask_5: 1.091  loss_dice_5: 2.82  loss_ce_6: 0  loss_mask_6: 1.092  loss_dice_6: 2.823  loss_ce_7: 0  loss_mask_7: 1.089  loss_dice_7: 2.825  loss_ce_8: 0  loss_mask_8: 1.097  loss_dice_8: 2.825  time: 2.7155  data_time: 0.0398  lr: 9.377e-05  max_mem: 5999M
[02/18 02:24:29] d2.utils.events INFO:  eta: 2 days, 13:49:45  iter: 4159  total_loss: 42.77  loss_ce: 0  loss_mask: 1.138  loss_dice: 2.992  loss_seg: 0.9635  loss_ce_0: 0  loss_mask_0: 1.147  loss_dice_0: 3.021  loss_ce_1: 0  loss_mask_1: 1.148  loss_dice_1: 2.982  loss_ce_2: 0  loss_mask_2: 1.152  loss_dice_2: 2.965  loss_ce_3: 0  loss_mask_3: 1.162  loss_dice_3: 2.96  loss_ce_4: 0  loss_mask_4: 1.156  loss_dice_4: 2.96  loss_ce_5: 0  loss_mask_5: 1.162  loss_dice_5: 2.961  loss_ce_6: 0  loss_mask_6: 1.163  loss_dice_6: 2.957  loss_ce_7: 0  loss_mask_7: 1.155  loss_dice_7: 2.964  loss_ce_8: 0  loss_mask_8: 1.147  loss_dice_8: 2.965  time: 2.7208  data_time: 0.0429  lr: 9.3739e-05  max_mem: 5999M
[02/18 02:25:43] d2.utils.events INFO:  eta: 2 days, 13:34:50  iter: 4179  total_loss: 41.37  loss_ce: 0  loss_mask: 1.152  loss_dice: 2.88  loss_seg: 0.7793  loss_ce_0: 0  loss_mask_0: 1.139  loss_dice_0: 2.958  loss_ce_1: 0  loss_mask_1: 1.161  loss_dice_1: 2.861  loss_ce_2: 0  loss_mask_2: 1.154  loss_dice_2: 2.85  loss_ce_3: 0  loss_mask_3: 1.16  loss_dice_3: 2.847  loss_ce_4: 0  loss_mask_4: 1.156  loss_dice_4: 2.853  loss_ce_5: 0  loss_mask_5: 1.157  loss_dice_5: 2.866  loss_ce_6: 0  loss_mask_6: 1.156  loss_dice_6: 2.863  loss_ce_7: 0  loss_mask_7: 1.157  loss_dice_7: 2.862  loss_ce_8: 0  loss_mask_8: 1.159  loss_dice_8: 2.863  time: 2.7253  data_time: 0.0395  lr: 9.3709e-05  max_mem: 5999M
[02/18 02:26:58] d2.utils.events INFO:  eta: 2 days, 13:32:05  iter: 4199  total_loss: 40.35  loss_ce: 0  loss_mask: 1.078  loss_dice: 2.865  loss_seg: 0.8693  loss_ce_0: 0  loss_mask_0: 1.084  loss_dice_0: 2.965  loss_ce_1: 0  loss_mask_1: 1.087  loss_dice_1: 2.859  loss_ce_2: 0  loss_mask_2: 1.086  loss_dice_2: 2.84  loss_ce_3: 0  loss_mask_3: 1.083  loss_dice_3: 2.842  loss_ce_4: 0  loss_mask_4: 1.082  loss_dice_4: 2.837  loss_ce_5: 0  loss_mask_5: 1.083  loss_dice_5: 2.84  loss_ce_6: 0  loss_mask_6: 1.083  loss_dice_6: 2.838  loss_ce_7: 0  loss_mask_7: 1.088  loss_dice_7: 2.843  loss_ce_8: 0  loss_mask_8: 1.087  loss_dice_8: 2.846  time: 2.7301  data_time: 0.0388  lr: 9.3679e-05  max_mem: 5999M
[02/18 02:28:17] d2.utils.events INFO:  eta: 2 days, 13:30:46  iter: 4219  total_loss: 41.75  loss_ce: 0  loss_mask: 1.092  loss_dice: 2.916  loss_seg: 0.8607  loss_ce_0: 0  loss_mask_0: 1.093  loss_dice_0: 2.977  loss_ce_1: 0  loss_mask_1: 1.092  loss_dice_1: 2.898  loss_ce_2: 0  loss_mask_2: 1.098  loss_dice_2: 2.884  loss_ce_3: 0  loss_mask_3: 1.103  loss_dice_3: 2.882  loss_ce_4: 0  loss_mask_4: 1.107  loss_dice_4: 2.874  loss_ce_5: 0  loss_mask_5: 1.104  loss_dice_5: 2.881  loss_ce_6: 0  loss_mask_6: 1.104  loss_dice_6: 2.878  loss_ce_7: 0  loss_mask_7: 1.102  loss_dice_7: 2.886  loss_ce_8: 0  loss_mask_8: 1.1  loss_dice_8: 2.89  time: 2.7359  data_time: 0.0375  lr: 9.3649e-05  max_mem: 5999M
[02/18 02:29:33] d2.utils.events INFO:  eta: 2 days, 13:21:00  iter: 4239  total_loss: 42.8  loss_ce: 0  loss_mask: 1.141  loss_dice: 3.02  loss_seg: 0.9792  loss_ce_0: 0  loss_mask_0: 1.137  loss_dice_0: 3.04  loss_ce_1: 0  loss_mask_1: 1.145  loss_dice_1: 3.005  loss_ce_2: 0  loss_mask_2: 1.144  loss_dice_2: 2.993  loss_ce_3: 0  loss_mask_3: 1.147  loss_dice_3: 2.991  loss_ce_4: 0  loss_mask_4: 1.139  loss_dice_4: 2.999  loss_ce_5: 0  loss_mask_5: 1.145  loss_dice_5: 2.996  loss_ce_6: 0  loss_mask_6: 1.146  loss_dice_6: 2.997  loss_ce_7: 0  loss_mask_7: 1.143  loss_dice_7: 2.995  loss_ce_8: 0  loss_mask_8: 1.144  loss_dice_8: 2.994  time: 2.7410  data_time: 0.0387  lr: 9.3618e-05  max_mem: 5999M
[02/18 02:30:48] d2.utils.events INFO:  eta: 2 days, 13:18:11  iter: 4259  total_loss: 43.37  loss_ce: 0  loss_mask: 1.141  loss_dice: 3.086  loss_seg: 1.242  loss_ce_0: 0  loss_mask_0: 1.133  loss_dice_0: 3.108  loss_ce_1: 0  loss_mask_1: 1.131  loss_dice_1: 3.065  loss_ce_2: 0  loss_mask_2: 1.139  loss_dice_2: 3.058  loss_ce_3: 0  loss_mask_3: 1.144  loss_dice_3: 3.062  loss_ce_4: 0  loss_mask_4: 1.149  loss_dice_4: 3.056  loss_ce_5: 0  loss_mask_5: 1.152  loss_dice_5: 3.062  loss_ce_6: 0  loss_mask_6: 1.148  loss_dice_6: 3.063  loss_ce_7: 0  loss_mask_7: 1.157  loss_dice_7: 3.065  loss_ce_8: 0  loss_mask_8: 1.149  loss_dice_8: 3.067  time: 2.7456  data_time: 0.0341  lr: 9.3588e-05  max_mem: 5999M
[02/18 02:32:08] d2.utils.events INFO:  eta: 2 days, 13:18:22  iter: 4279  total_loss: 41.98  loss_ce: 0  loss_mask: 1.122  loss_dice: 2.986  loss_seg: 1.026  loss_ce_0: 0  loss_mask_0: 1.1  loss_dice_0: 3.069  loss_ce_1: 0  loss_mask_1: 1.126  loss_dice_1: 2.976  loss_ce_2: 0  loss_mask_2: 1.132  loss_dice_2: 2.964  loss_ce_3: 0  loss_mask_3: 1.136  loss_dice_3: 2.956  loss_ce_4: 0  loss_mask_4: 1.133  loss_dice_4: 2.956  loss_ce_5: 0  loss_mask_5: 1.135  loss_dice_5: 2.965  loss_ce_6: 0  loss_mask_6: 1.138  loss_dice_6: 2.963  loss_ce_7: 0  loss_mask_7: 1.147  loss_dice_7: 2.969  loss_ce_8: 0  loss_mask_8: 1.142  loss_dice_8: 2.969  time: 2.7516  data_time: 0.0443  lr: 9.3558e-05  max_mem: 5999M
[02/18 02:33:24] d2.utils.events INFO:  eta: 2 days, 13:15:03  iter: 4299  total_loss: 41.1  loss_ce: 0  loss_mask: 1.082  loss_dice: 2.887  loss_seg: 0.9673  loss_ce_0: 0  loss_mask_0: 1.101  loss_dice_0: 2.979  loss_ce_1: 0  loss_mask_1: 1.085  loss_dice_1: 2.875  loss_ce_2: 0  loss_mask_2: 1.084  loss_dice_2: 2.864  loss_ce_3: 0  loss_mask_3: 1.089  loss_dice_3: 2.861  loss_ce_4: 0  loss_mask_4: 1.086  loss_dice_4: 2.865  loss_ce_5: 0  loss_mask_5: 1.09  loss_dice_5: 2.865  loss_ce_6: 0  loss_mask_6: 1.099  loss_dice_6: 2.865  loss_ce_7: 0  loss_mask_7: 1.097  loss_dice_7: 2.862  loss_ce_8: 0  loss_mask_8: 1.094  loss_dice_8: 2.86  time: 2.7564  data_time: 0.0318  lr: 9.3528e-05  max_mem: 5999M
[02/18 02:34:41] d2.utils.events INFO:  eta: 2 days, 13:12:27  iter: 4319  total_loss: 40.2  loss_ce: 0  loss_mask: 1.123  loss_dice: 2.834  loss_seg: 0.9228  loss_ce_0: 0  loss_mask_0: 1.114  loss_dice_0: 2.916  loss_ce_1: 0  loss_mask_1: 1.129  loss_dice_1: 2.819  loss_ce_2: 0  loss_mask_2: 1.127  loss_dice_2: 2.811  loss_ce_3: 0  loss_mask_3: 1.127  loss_dice_3: 2.802  loss_ce_4: 0  loss_mask_4: 1.128  loss_dice_4: 2.8  loss_ce_5: 0  loss_mask_5: 1.126  loss_dice_5: 2.802  loss_ce_6: 0  loss_mask_6: 1.126  loss_dice_6: 2.806  loss_ce_7: 0  loss_mask_7: 1.128  loss_dice_7: 2.803  loss_ce_8: 0  loss_mask_8: 1.128  loss_dice_8: 2.81  time: 2.7614  data_time: 0.0344  lr: 9.3498e-05  max_mem: 5999M
[02/18 02:35:56] d2.utils.events INFO:  eta: 2 days, 13:07:43  iter: 4339  total_loss: 40.89  loss_ce: 0  loss_mask: 1.091  loss_dice: 2.882  loss_seg: 1.039  loss_ce_0: 0  loss_mask_0: 1.054  loss_dice_0: 2.95  loss_ce_1: 0  loss_mask_1: 1.077  loss_dice_1: 2.873  loss_ce_2: 0  loss_mask_2: 1.095  loss_dice_2: 2.861  loss_ce_3: 0  loss_mask_3: 1.102  loss_dice_3: 2.859  loss_ce_4: 0  loss_mask_4: 1.098  loss_dice_4: 2.856  loss_ce_5: 0  loss_mask_5: 1.099  loss_dice_5: 2.861  loss_ce_6: 0  loss_mask_6: 1.095  loss_dice_6: 2.856  loss_ce_7: 0  loss_mask_7: 1.089  loss_dice_7: 2.858  loss_ce_8: 0  loss_mask_8: 1.1  loss_dice_8: 2.858  time: 2.7661  data_time: 0.0346  lr: 9.3467e-05  max_mem: 5999M
[02/18 02:37:16] d2.utils.events INFO:  eta: 2 days, 13:09:58  iter: 4359  total_loss: 39.71  loss_ce: 0  loss_mask: 1.072  loss_dice: 2.822  loss_seg: 0.916  loss_ce_0: 0  loss_mask_0: 1.076  loss_dice_0: 2.901  loss_ce_1: 0  loss_mask_1: 1.078  loss_dice_1: 2.806  loss_ce_2: 0  loss_mask_2: 1.082  loss_dice_2: 2.798  loss_ce_3: 0  loss_mask_3: 1.078  loss_dice_3: 2.794  loss_ce_4: 0  loss_mask_4: 1.078  loss_dice_4: 2.793  loss_ce_5: 0  loss_mask_5: 1.08  loss_dice_5: 2.798  loss_ce_6: 0  loss_mask_6: 1.073  loss_dice_6: 2.803  loss_ce_7: 0  loss_mask_7: 1.083  loss_dice_7: 2.803  loss_ce_8: 0  loss_mask_8: 1.083  loss_dice_8: 2.798  time: 2.7717  data_time: 0.0352  lr: 9.3437e-05  max_mem: 5999M
[02/18 02:38:32] d2.utils.events INFO:  eta: 2 days, 13:10:16  iter: 4379  total_loss: 41.27  loss_ce: 0  loss_mask: 1.096  loss_dice: 2.961  loss_seg: 1.014  loss_ce_0: 0  loss_mask_0: 1.095  loss_dice_0: 2.968  loss_ce_1: 0  loss_mask_1: 1.101  loss_dice_1: 2.961  loss_ce_2: 0  loss_mask_2: 1.106  loss_dice_2: 2.952  loss_ce_3: 0  loss_mask_3: 1.109  loss_dice_3: 2.937  loss_ce_4: 0  loss_mask_4: 1.115  loss_dice_4: 2.942  loss_ce_5: 0  loss_mask_5: 1.113  loss_dice_5: 2.937  loss_ce_6: 0  loss_mask_6: 1.113  loss_dice_6: 2.932  loss_ce_7: 0  loss_mask_7: 1.111  loss_dice_7: 2.935  loss_ce_8: 0  loss_mask_8: 1.106  loss_dice_8: 2.939  time: 2.7764  data_time: 0.0421  lr: 9.3407e-05  max_mem: 5999M
[02/18 02:39:55] d2.utils.events INFO:  eta: 2 days, 13:20:17  iter: 4399  total_loss: 41.35  loss_ce: 0  loss_mask: 1.077  loss_dice: 2.92  loss_seg: 1.137  loss_ce_0: 0  loss_mask_0: 1.082  loss_dice_0: 2.98  loss_ce_1: 0  loss_mask_1: 1.081  loss_dice_1: 2.928  loss_ce_2: 0  loss_mask_2: 1.08  loss_dice_2: 2.91  loss_ce_3: 0  loss_mask_3: 1.088  loss_dice_3: 2.904  loss_ce_4: 0  loss_mask_4: 1.087  loss_dice_4: 2.902  loss_ce_5: 0  loss_mask_5: 1.084  loss_dice_5: 2.906  loss_ce_6: 0  loss_mask_6: 1.086  loss_dice_6: 2.906  loss_ce_7: 0  loss_mask_7: 1.082  loss_dice_7: 2.909  loss_ce_8: 0  loss_mask_8: 1.084  loss_dice_8: 2.905  time: 2.7824  data_time: 0.0433  lr: 9.3377e-05  max_mem: 5999M
[02/18 02:41:11] d2.utils.events INFO:  eta: 2 days, 13:14:44  iter: 4419  total_loss: 42.1  loss_ce: 0  loss_mask: 1.102  loss_dice: 2.94  loss_seg: 1.05  loss_ce_0: 0  loss_mask_0: 1.103  loss_dice_0: 2.98  loss_ce_1: 0  loss_mask_1: 1.105  loss_dice_1: 2.934  loss_ce_2: 0  loss_mask_2: 1.109  loss_dice_2: 2.921  loss_ce_3: 0  loss_mask_3: 1.108  loss_dice_3: 2.911  loss_ce_4: 0  loss_mask_4: 1.108  loss_dice_4: 2.916  loss_ce_5: 0  loss_mask_5: 1.107  loss_dice_5: 2.92  loss_ce_6: 0  loss_mask_6: 1.11  loss_dice_6: 2.915  loss_ce_7: 0  loss_mask_7: 1.113  loss_dice_7: 2.912  loss_ce_8: 0  loss_mask_8: 1.108  loss_dice_8: 2.915  time: 2.7872  data_time: 0.0340  lr: 9.3346e-05  max_mem: 5999M
[02/18 02:42:33] d2.utils.events INFO:  eta: 2 days, 13:13:24  iter: 4439  total_loss: 40.91  loss_ce: 0  loss_mask: 1.092  loss_dice: 2.884  loss_seg: 1.064  loss_ce_0: 0  loss_mask_0: 1.102  loss_dice_0: 2.962  loss_ce_1: 0  loss_mask_1: 1.096  loss_dice_1: 2.874  loss_ce_2: 0  loss_mask_2: 1.097  loss_dice_2: 2.859  loss_ce_3: 0  loss_mask_3: 1.094  loss_dice_3: 2.852  loss_ce_4: 0  loss_mask_4: 1.094  loss_dice_4: 2.854  loss_ce_5: 0  loss_mask_5: 1.096  loss_dice_5: 2.861  loss_ce_6: 0  loss_mask_6: 1.093  loss_dice_6: 2.863  loss_ce_7: 0  loss_mask_7: 1.094  loss_dice_7: 2.858  loss_ce_8: 0  loss_mask_8: 1.093  loss_dice_8: 2.86  time: 2.7930  data_time: 0.0348  lr: 9.3316e-05  max_mem: 5999M
[02/18 02:43:42] d2.utils.events INFO:  eta: 2 days, 13:06:29  iter: 4459  total_loss: 42.38  loss_ce: 0  loss_mask: 1.107  loss_dice: 2.916  loss_seg: 1.218  loss_ce_0: 0  loss_mask_0: 1.093  loss_dice_0: 2.961  loss_ce_1: 0  loss_mask_1: 1.109  loss_dice_1: 2.901  loss_ce_2: 0  loss_mask_2: 1.113  loss_dice_2: 2.893  loss_ce_3: 0  loss_mask_3: 1.114  loss_dice_3: 2.887  loss_ce_4: 0  loss_mask_4: 1.114  loss_dice_4: 2.892  loss_ce_5: 0  loss_mask_5: 1.114  loss_dice_5: 2.891  loss_ce_6: 0  loss_mask_6: 1.112  loss_dice_6: 2.887  loss_ce_7: 0  loss_mask_7: 1.109  loss_dice_7: 2.892  loss_ce_8: 0  loss_mask_8: 1.112  loss_dice_8: 2.894  time: 2.7960  data_time: 0.0432  lr: 9.3286e-05  max_mem: 5999M
[02/18 02:45:03] d2.utils.events INFO:  eta: 2 days, 13:06:33  iter: 4479  total_loss: 40.56  loss_ce: 0  loss_mask: 1.109  loss_dice: 2.889  loss_seg: 0.8827  loss_ce_0: 0  loss_mask_0: 1.11  loss_dice_0: 2.947  loss_ce_1: 0  loss_mask_1: 1.118  loss_dice_1: 2.87  loss_ce_2: 0  loss_mask_2: 1.121  loss_dice_2: 2.859  loss_ce_3: 0  loss_mask_3: 1.124  loss_dice_3: 2.856  loss_ce_4: 0  loss_mask_4: 1.121  loss_dice_4: 2.85  loss_ce_5: 0  loss_mask_5: 1.117  loss_dice_5: 2.856  loss_ce_6: 0  loss_mask_6: 1.12  loss_dice_6: 2.858  loss_ce_7: 0  loss_mask_7: 1.117  loss_dice_7: 2.861  loss_ce_8: 0  loss_mask_8: 1.112  loss_dice_8: 2.863  time: 2.8015  data_time: 0.0403  lr: 9.3256e-05  max_mem: 5999M
[02/18 02:46:22] d2.utils.events INFO:  eta: 2 days, 13:06:02  iter: 4499  total_loss: 40.44  loss_ce: 0  loss_mask: 1.075  loss_dice: 2.848  loss_seg: 0.8676  loss_ce_0: 0  loss_mask_0: 1.06  loss_dice_0: 2.893  loss_ce_1: 0  loss_mask_1: 1.075  loss_dice_1: 2.84  loss_ce_2: 0  loss_mask_2: 1.072  loss_dice_2: 2.833  loss_ce_3: 0  loss_mask_3: 1.076  loss_dice_3: 2.823  loss_ce_4: 0  loss_mask_4: 1.069  loss_dice_4: 2.825  loss_ce_5: 0  loss_mask_5: 1.069  loss_dice_5: 2.828  loss_ce_6: 0  loss_mask_6: 1.071  loss_dice_6: 2.823  loss_ce_7: 0  loss_mask_7: 1.071  loss_dice_7: 2.827  loss_ce_8: 0  loss_mask_8: 1.075  loss_dice_8: 2.827  time: 2.8067  data_time: 0.0396  lr: 9.3225e-05  max_mem: 5999M
[02/18 02:47:38] d2.utils.events INFO:  eta: 2 days, 13:08:40  iter: 4519  total_loss: 40.75  loss_ce: 0  loss_mask: 1.054  loss_dice: 2.91  loss_seg: 1.112  loss_ce_0: 0  loss_mask_0: 1.053  loss_dice_0: 2.975  loss_ce_1: 0  loss_mask_1: 1.056  loss_dice_1: 2.897  loss_ce_2: 0  loss_mask_2: 1.059  loss_dice_2: 2.892  loss_ce_3: 0  loss_mask_3: 1.058  loss_dice_3: 2.886  loss_ce_4: 0  loss_mask_4: 1.06  loss_dice_4: 2.887  loss_ce_5: 0  loss_mask_5: 1.057  loss_dice_5: 2.886  loss_ce_6: 0  loss_mask_6: 1.059  loss_dice_6: 2.884  loss_ce_7: 0  loss_mask_7: 1.055  loss_dice_7: 2.891  loss_ce_8: 0  loss_mask_8: 1.052  loss_dice_8: 2.892  time: 2.8110  data_time: 0.0452  lr: 9.3195e-05  max_mem: 5999M
[02/18 02:48:57] d2.utils.events INFO:  eta: 2 days, 13:02:36  iter: 4539  total_loss: 40.59  loss_ce: 0  loss_mask: 1.073  loss_dice: 2.842  loss_seg: 1.297  loss_ce_0: 0  loss_mask_0: 1.056  loss_dice_0: 2.906  loss_ce_1: 0  loss_mask_1: 1.078  loss_dice_1: 2.829  loss_ce_2: 0  loss_mask_2: 1.085  loss_dice_2: 2.811  loss_ce_3: 0  loss_mask_3: 1.082  loss_dice_3: 2.803  loss_ce_4: 0  loss_mask_4: 1.083  loss_dice_4: 2.807  loss_ce_5: 0  loss_mask_5: 1.087  loss_dice_5: 2.816  loss_ce_6: 0  loss_mask_6: 1.082  loss_dice_6: 2.815  loss_ce_7: 0  loss_mask_7: 1.082  loss_dice_7: 2.816  loss_ce_8: 0  loss_mask_8: 1.082  loss_dice_8: 2.809  time: 2.8160  data_time: 0.0356  lr: 9.3165e-05  max_mem: 5999M
[02/18 02:50:16] d2.utils.events INFO:  eta: 2 days, 12:58:19  iter: 4559  total_loss: 40.52  loss_ce: 0  loss_mask: 1.064  loss_dice: 2.829  loss_seg: 0.8553  loss_ce_0: 0  loss_mask_0: 1.059  loss_dice_0: 2.884  loss_ce_1: 0  loss_mask_1: 1.064  loss_dice_1: 2.811  loss_ce_2: 0  loss_mask_2: 1.066  loss_dice_2: 2.803  loss_ce_3: 0  loss_mask_3: 1.071  loss_dice_3: 2.797  loss_ce_4: 0  loss_mask_4: 1.071  loss_dice_4: 2.802  loss_ce_5: 0  loss_mask_5: 1.066  loss_dice_5: 2.807  loss_ce_6: 0  loss_mask_6: 1.067  loss_dice_6: 2.807  loss_ce_7: 0  loss_mask_7: 1.07  loss_dice_7: 2.803  loss_ce_8: 0  loss_mask_8: 1.067  loss_dice_8: 2.801  time: 2.8209  data_time: 0.0377  lr: 9.3135e-05  max_mem: 5999M
[02/18 02:51:35] d2.utils.events INFO:  eta: 2 days, 12:58:48  iter: 4579  total_loss: 41.54  loss_ce: 0  loss_mask: 1.1  loss_dice: 2.884  loss_seg: 1.217  loss_ce_0: 0  loss_mask_0: 1.113  loss_dice_0: 2.931  loss_ce_1: 0  loss_mask_1: 1.11  loss_dice_1: 2.867  loss_ce_2: 0  loss_mask_2: 1.112  loss_dice_2: 2.859  loss_ce_3: 0  loss_mask_3: 1.11  loss_dice_3: 2.862  loss_ce_4: 0  loss_mask_4: 1.107  loss_dice_4: 2.865  loss_ce_5: 0  loss_mask_5: 1.117  loss_dice_5: 2.867  loss_ce_6: 0  loss_mask_6: 1.117  loss_dice_6: 2.861  loss_ce_7: 0  loss_mask_7: 1.111  loss_dice_7: 2.867  loss_ce_8: 0  loss_mask_8: 1.104  loss_dice_8: 2.869  time: 2.8259  data_time: 0.0391  lr: 9.3105e-05  max_mem: 5999M
[02/18 02:52:52] d2.utils.events INFO:  eta: 2 days, 12:56:00  iter: 4599  total_loss: 40.32  loss_ce: 0  loss_mask: 1.132  loss_dice: 2.832  loss_seg: 1.041  loss_ce_0: 0  loss_mask_0: 1.154  loss_dice_0: 2.876  loss_ce_1: 0  loss_mask_1: 1.133  loss_dice_1: 2.812  loss_ce_2: 0  loss_mask_2: 1.13  loss_dice_2: 2.804  loss_ce_3: 0  loss_mask_3: 1.135  loss_dice_3: 2.799  loss_ce_4: 0  loss_mask_4: 1.136  loss_dice_4: 2.8  loss_ce_5: 0  loss_mask_5: 1.138  loss_dice_5: 2.8  loss_ce_6: 0  loss_mask_6: 1.135  loss_dice_6: 2.798  loss_ce_7: 0  loss_mask_7: 1.138  loss_dice_7: 2.799  loss_ce_8: 0  loss_mask_8: 1.138  loss_dice_8: 2.803  time: 2.8303  data_time: 0.0414  lr: 9.3074e-05  max_mem: 5999M
[02/18 02:54:14] d2.utils.events INFO:  eta: 2 days, 13:05:43  iter: 4619  total_loss: 40.43  loss_ce: 0  loss_mask: 1.097  loss_dice: 2.834  loss_seg: 1.095  loss_ce_0: 0  loss_mask_0: 1.09  loss_dice_0: 2.864  loss_ce_1: 0  loss_mask_1: 1.099  loss_dice_1: 2.816  loss_ce_2: 0  loss_mask_2: 1.105  loss_dice_2: 2.81  loss_ce_3: 0  loss_mask_3: 1.115  loss_dice_3: 2.808  loss_ce_4: 0  loss_mask_4: 1.11  loss_dice_4: 2.815  loss_ce_5: 0  loss_mask_5: 1.105  loss_dice_5: 2.813  loss_ce_6: 0  loss_mask_6: 1.104  loss_dice_6: 2.818  loss_ce_7: 0  loss_mask_7: 1.109  loss_dice_7: 2.816  loss_ce_8: 0  loss_mask_8: 1.11  loss_dice_8: 2.819  time: 2.8357  data_time: 0.0324  lr: 9.3044e-05  max_mem: 5999M
[02/18 02:55:29] d2.utils.events INFO:  eta: 2 days, 13:00:44  iter: 4639  total_loss: 39.14  loss_ce: 0  loss_mask: 1.063  loss_dice: 2.739  loss_seg: 0.8301  loss_ce_0: 0  loss_mask_0: 1.073  loss_dice_0: 2.842  loss_ce_1: 0  loss_mask_1: 1.064  loss_dice_1: 2.723  loss_ce_2: 0  loss_mask_2: 1.063  loss_dice_2: 2.714  loss_ce_3: 0  loss_mask_3: 1.069  loss_dice_3: 2.709  loss_ce_4: 0  loss_mask_4: 1.071  loss_dice_4: 2.715  loss_ce_5: 0  loss_mask_5: 1.071  loss_dice_5: 2.715  loss_ce_6: 0  loss_mask_6: 1.071  loss_dice_6: 2.72  loss_ce_7: 0  loss_mask_7: 1.068  loss_dice_7: 2.714  loss_ce_8: 0  loss_mask_8: 1.068  loss_dice_8: 2.717  time: 2.8398  data_time: 0.0294  lr: 9.3014e-05  max_mem: 5999M
[02/18 02:56:46] d2.utils.events INFO:  eta: 2 days, 12:52:02  iter: 4659  total_loss: 40.92  loss_ce: 0  loss_mask: 1.097  loss_dice: 2.911  loss_seg: 0.9543  loss_ce_0: 0  loss_mask_0: 1.1  loss_dice_0: 2.932  loss_ce_1: 0  loss_mask_1: 1.094  loss_dice_1: 2.899  loss_ce_2: 0  loss_mask_2: 1.103  loss_dice_2: 2.888  loss_ce_3: 0  loss_mask_3: 1.117  loss_dice_3: 2.891  loss_ce_4: 0  loss_mask_4: 1.113  loss_dice_4: 2.888  loss_ce_5: 0  loss_mask_5: 1.122  loss_dice_5: 2.895  loss_ce_6: 0  loss_mask_6: 1.122  loss_dice_6: 2.894  loss_ce_7: 0  loss_mask_7: 1.116  loss_dice_7: 2.892  loss_ce_8: 0  loss_mask_8: 1.112  loss_dice_8: 2.893  time: 2.8440  data_time: 0.0346  lr: 9.2984e-05  max_mem: 5999M
[02/18 02:58:03] d2.utils.events INFO:  eta: 2 days, 12:48:02  iter: 4679  total_loss: 39.84  loss_ce: 0  loss_mask: 1.067  loss_dice: 2.819  loss_seg: 0.9407  loss_ce_0: 0  loss_mask_0: 1.062  loss_dice_0: 2.861  loss_ce_1: 0  loss_mask_1: 1.067  loss_dice_1: 2.805  loss_ce_2: 0  loss_mask_2: 1.069  loss_dice_2: 2.796  loss_ce_3: 0  loss_mask_3: 1.076  loss_dice_3: 2.788  loss_ce_4: 0  loss_mask_4: 1.071  loss_dice_4: 2.788  loss_ce_5: 0  loss_mask_5: 1.07  loss_dice_5: 2.796  loss_ce_6: 0  loss_mask_6: 1.074  loss_dice_6: 2.8  loss_ce_7: 0  loss_mask_7: 1.072  loss_dice_7: 2.798  loss_ce_8: 0  loss_mask_8: 1.077  loss_dice_8: 2.804  time: 2.8483  data_time: 0.0376  lr: 9.2953e-05  max_mem: 5999M
[02/18 02:59:18] d2.utils.events INFO:  eta: 2 days, 12:38:15  iter: 4699  total_loss: 40.3  loss_ce: 0  loss_mask: 1.071  loss_dice: 2.836  loss_seg: 0.9806  loss_ce_0: 0  loss_mask_0: 1.057  loss_dice_0: 2.892  loss_ce_1: 0  loss_mask_1: 1.078  loss_dice_1: 2.816  loss_ce_2: 0  loss_mask_2: 1.079  loss_dice_2: 2.808  loss_ce_3: 0  loss_mask_3: 1.08  loss_dice_3: 2.802  loss_ce_4: 0  loss_mask_4: 1.082  loss_dice_4: 2.807  loss_ce_5: 0  loss_mask_5: 1.096  loss_dice_5: 2.806  loss_ce_6: 0  loss_mask_6: 1.086  loss_dice_6: 2.814  loss_ce_7: 0  loss_mask_7: 1.088  loss_dice_7: 2.807  loss_ce_8: 0  loss_mask_8: 1.086  loss_dice_8: 2.813  time: 2.8521  data_time: 0.0299  lr: 9.2923e-05  max_mem: 5999M
[02/18 03:00:36] d2.utils.events INFO:  eta: 2 days, 12:29:23  iter: 4719  total_loss: 40.17  loss_ce: 0  loss_mask: 1.043  loss_dice: 2.849  loss_seg: 1.408  loss_ce_0: 0  loss_mask_0: 1.044  loss_dice_0: 2.891  loss_ce_1: 0  loss_mask_1: 1.053  loss_dice_1: 2.832  loss_ce_2: 0  loss_mask_2: 1.053  loss_dice_2: 2.822  loss_ce_3: 0  loss_mask_3: 1.054  loss_dice_3: 2.821  loss_ce_4: 0  loss_mask_4: 1.051  loss_dice_4: 2.815  loss_ce_5: 0  loss_mask_5: 1.051  loss_dice_5: 2.824  loss_ce_6: 0  loss_mask_6: 1.048  loss_dice_6: 2.821  loss_ce_7: 0  loss_mask_7: 1.049  loss_dice_7: 2.821  loss_ce_8: 0  loss_mask_8: 1.049  loss_dice_8: 2.824  time: 2.8565  data_time: 0.0366  lr: 9.2893e-05  max_mem: 5999M
[02/18 03:01:51] d2.utils.events INFO:  eta: 2 days, 12:20:48  iter: 4739  total_loss: 38.9  loss_ce: 0  loss_mask: 1.053  loss_dice: 2.769  loss_seg: 0.9167  loss_ce_0: 0  loss_mask_0: 1.054  loss_dice_0: 2.806  loss_ce_1: 0  loss_mask_1: 1.05  loss_dice_1: 2.748  loss_ce_2: 0  loss_mask_2: 1.049  loss_dice_2: 2.736  loss_ce_3: 0  loss_mask_3: 1.053  loss_dice_3: 2.741  loss_ce_4: 0  loss_mask_4: 1.054  loss_dice_4: 2.739  loss_ce_5: 0  loss_mask_5: 1.056  loss_dice_5: 2.734  loss_ce_6: 0  loss_mask_6: 1.059  loss_dice_6: 2.742  loss_ce_7: 0  loss_mask_7: 1.05  loss_dice_7: 2.745  loss_ce_8: 0  loss_mask_8: 1.05  loss_dice_8: 2.746  time: 2.8602  data_time: 0.0362  lr: 9.2863e-05  max_mem: 5999M
[02/18 03:03:07] d2.utils.events INFO:  eta: 2 days, 12:16:32  iter: 4759  total_loss: 41.19  loss_ce: 0  loss_mask: 1.061  loss_dice: 2.881  loss_seg: 1.171  loss_ce_0: 0  loss_mask_0: 1.032  loss_dice_0: 2.958  loss_ce_1: 0  loss_mask_1: 1.065  loss_dice_1: 2.852  loss_ce_2: 0  loss_mask_2: 1.073  loss_dice_2: 2.85  loss_ce_3: 0  loss_mask_3: 1.074  loss_dice_3: 2.851  loss_ce_4: 0  loss_mask_4: 1.075  loss_dice_4: 2.848  loss_ce_5: 0  loss_mask_5: 1.073  loss_dice_5: 2.856  loss_ce_6: 0  loss_mask_6: 1.077  loss_dice_6: 2.842  loss_ce_7: 0  loss_mask_7: 1.079  loss_dice_7: 2.852  loss_ce_8: 0  loss_mask_8: 1.075  loss_dice_8: 2.856  time: 2.8641  data_time: 0.0380  lr: 9.2832e-05  max_mem: 5999M
[02/18 03:04:27] d2.utils.events INFO:  eta: 2 days, 12:21:02  iter: 4779  total_loss: 40.4  loss_ce: 0  loss_mask: 1.116  loss_dice: 2.834  loss_seg: 1.072  loss_ce_0: 0  loss_mask_0: 1.135  loss_dice_0: 2.884  loss_ce_1: 0  loss_mask_1: 1.119  loss_dice_1: 2.822  loss_ce_2: 0  loss_mask_2: 1.116  loss_dice_2: 2.814  loss_ce_3: 0  loss_mask_3: 1.12  loss_dice_3: 2.815  loss_ce_4: 0  loss_mask_4: 1.118  loss_dice_4: 2.805  loss_ce_5: 0  loss_mask_5: 1.115  loss_dice_5: 2.812  loss_ce_6: 0  loss_mask_6: 1.12  loss_dice_6: 2.814  loss_ce_7: 0  loss_mask_7: 1.119  loss_dice_7: 2.812  loss_ce_8: 0  loss_mask_8: 1.115  loss_dice_8: 2.814  time: 2.8688  data_time: 0.0363  lr: 9.2802e-05  max_mem: 5999M
[02/18 03:05:43] d2.utils.events INFO:  eta: 2 days, 12:18:44  iter: 4799  total_loss: 40.27  loss_ce: 0  loss_mask: 1.123  loss_dice: 2.782  loss_seg: 1.16  loss_ce_0: 0  loss_mask_0: 1.117  loss_dice_0: 2.81  loss_ce_1: 0  loss_mask_1: 1.121  loss_dice_1: 2.764  loss_ce_2: 0  loss_mask_2: 1.122  loss_dice_2: 2.757  loss_ce_3: 0  loss_mask_3: 1.123  loss_dice_3: 2.755  loss_ce_4: 0  loss_mask_4: 1.124  loss_dice_4: 2.761  loss_ce_5: 0  loss_mask_5: 1.129  loss_dice_5: 2.767  loss_ce_6: 0  loss_mask_6: 1.128  loss_dice_6: 2.763  loss_ce_7: 0  loss_mask_7: 1.12  loss_dice_7: 2.764  loss_ce_8: 0  loss_mask_8: 1.123  loss_dice_8: 2.766  time: 2.8727  data_time: 0.0330  lr: 9.2772e-05  max_mem: 5999M
[02/18 03:06:58] d2.utils.events INFO:  eta: 2 days, 12:17:25  iter: 4819  total_loss: 40.24  loss_ce: 0  loss_mask: 1.069  loss_dice: 2.847  loss_seg: 1.021  loss_ce_0: 0  loss_mask_0: 1.072  loss_dice_0: 2.889  loss_ce_1: 0  loss_mask_1: 1.074  loss_dice_1: 2.836  loss_ce_2: 0  loss_mask_2: 1.074  loss_dice_2: 2.821  loss_ce_3: 0  loss_mask_3: 1.071  loss_dice_3: 2.821  loss_ce_4: 0  loss_mask_4: 1.074  loss_dice_4: 2.83  loss_ce_5: 0  loss_mask_5: 1.074  loss_dice_5: 2.831  loss_ce_6: 0  loss_mask_6: 1.075  loss_dice_6: 2.828  loss_ce_7: 0  loss_mask_7: 1.072  loss_dice_7: 2.824  loss_ce_8: 0  loss_mask_8: 1.075  loss_dice_8: 2.834  time: 2.8764  data_time: 0.0393  lr: 9.2742e-05  max_mem: 5999M
[02/18 03:08:15] d2.utils.events INFO:  eta: 2 days, 12:23:04  iter: 4839  total_loss: 39.59  loss_ce: 0  loss_mask: 1.072  loss_dice: 2.804  loss_seg: 1.09  loss_ce_0: 0  loss_mask_0: 1.065  loss_dice_0: 2.836  loss_ce_1: 0  loss_mask_1: 1.08  loss_dice_1: 2.791  loss_ce_2: 0  loss_mask_2: 1.081  loss_dice_2: 2.795  loss_ce_3: 0  loss_mask_3: 1.081  loss_dice_3: 2.785  loss_ce_4: 0  loss_mask_4: 1.079  loss_dice_4: 2.791  loss_ce_5: 0  loss_mask_5: 1.077  loss_dice_5: 2.79  loss_ce_6: 0  loss_mask_6: 1.076  loss_dice_6: 2.785  loss_ce_7: 0  loss_mask_7: 1.082  loss_dice_7: 2.784  loss_ce_8: 0  loss_mask_8: 1.084  loss_dice_8: 2.785  time: 2.8805  data_time: 0.0396  lr: 9.2711e-05  max_mem: 5999M
[02/18 03:09:36] d2.utils.events INFO:  eta: 2 days, 12:34:59  iter: 4859  total_loss: 40.77  loss_ce: 0  loss_mask: 1.039  loss_dice: 2.821  loss_seg: 0.9173  loss_ce_0: 0  loss_mask_0: 1.033  loss_dice_0: 2.869  loss_ce_1: 0  loss_mask_1: 1.029  loss_dice_1: 2.808  loss_ce_2: 0  loss_mask_2: 1.034  loss_dice_2: 2.795  loss_ce_3: 0  loss_mask_3: 1.047  loss_dice_3: 2.788  loss_ce_4: 0  loss_mask_4: 1.048  loss_dice_4: 2.8  loss_ce_5: 0  loss_mask_5: 1.049  loss_dice_5: 2.79  loss_ce_6: 0  loss_mask_6: 1.057  loss_dice_6: 2.797  loss_ce_7: 0  loss_mask_7: 1.056  loss_dice_7: 2.803  loss_ce_8: 0  loss_mask_8: 1.049  loss_dice_8: 2.8  time: 2.8852  data_time: 0.0422  lr: 9.2681e-05  max_mem: 5999M
[02/18 03:10:51] d2.utils.events INFO:  eta: 2 days, 12:31:21  iter: 4879  total_loss: 40.74  loss_ce: 0  loss_mask: 1.061  loss_dice: 2.891  loss_seg: 0.7832  loss_ce_0: 0  loss_mask_0: 1.053  loss_dice_0: 2.965  loss_ce_1: 0  loss_mask_1: 1.064  loss_dice_1: 2.894  loss_ce_2: 0  loss_mask_2: 1.062  loss_dice_2: 2.877  loss_ce_3: 0  loss_mask_3: 1.065  loss_dice_3: 2.862  loss_ce_4: 0  loss_mask_4: 1.064  loss_dice_4: 2.87  loss_ce_5: 0  loss_mask_5: 1.064  loss_dice_5: 2.872  loss_ce_6: 0  loss_mask_6: 1.069  loss_dice_6: 2.865  loss_ce_7: 0  loss_mask_7: 1.067  loss_dice_7: 2.867  loss_ce_8: 0  loss_mask_8: 1.065  loss_dice_8: 2.873  time: 2.8888  data_time: 0.0518  lr: 9.2651e-05  max_mem: 5999M
[02/18 03:12:07] d2.utils.events INFO:  eta: 2 days, 12:30:02  iter: 4899  total_loss: 40.1  loss_ce: 0  loss_mask: 1.066  loss_dice: 2.807  loss_seg: 1.181  loss_ce_0: 0  loss_mask_0: 1.062  loss_dice_0: 2.883  loss_ce_1: 0  loss_mask_1: 1.077  loss_dice_1: 2.809  loss_ce_2: 0  loss_mask_2: 1.083  loss_dice_2: 2.8  loss_ce_3: 0  loss_mask_3: 1.085  loss_dice_3: 2.791  loss_ce_4: 0  loss_mask_4: 1.088  loss_dice_4: 2.795  loss_ce_5: 0  loss_mask_5: 1.089  loss_dice_5: 2.795  loss_ce_6: 0  loss_mask_6: 1.09  loss_dice_6: 2.796  loss_ce_7: 0  loss_mask_7: 1.089  loss_dice_7: 2.794  loss_ce_8: 0  loss_mask_8: 1.089  loss_dice_8: 2.789  time: 2.8925  data_time: 0.0405  lr: 9.2621e-05  max_mem: 5999M
[02/18 03:13:27] d2.utils.events INFO:  eta: 2 days, 12:23:03  iter: 4919  total_loss: 39.75  loss_ce: 0  loss_mask: 1.094  loss_dice: 2.825  loss_seg: 1.005  loss_ce_0: 0  loss_mask_0: 1.1  loss_dice_0: 2.916  loss_ce_1: 0  loss_mask_1: 1.106  loss_dice_1: 2.813  loss_ce_2: 0  loss_mask_2: 1.106  loss_dice_2: 2.8  loss_ce_3: 0  loss_mask_3: 1.104  loss_dice_3: 2.795  loss_ce_4: 0  loss_mask_4: 1.099  loss_dice_4: 2.79  loss_ce_5: 0  loss_mask_5: 1.103  loss_dice_5: 2.799  loss_ce_6: 0  loss_mask_6: 1.104  loss_dice_6: 2.802  loss_ce_7: 0  loss_mask_7: 1.103  loss_dice_7: 2.799  loss_ce_8: 0  loss_mask_8: 1.105  loss_dice_8: 2.804  time: 2.8968  data_time: 0.0464  lr: 9.259e-05  max_mem: 5999M
[02/18 03:14:51] d2.utils.events INFO:  eta: 2 days, 12:32:40  iter: 4939  total_loss: 39.46  loss_ce: 0  loss_mask: 1.077  loss_dice: 2.777  loss_seg: 0.7191  loss_ce_0: 0  loss_mask_0: 1.084  loss_dice_0: 2.852  loss_ce_1: 0  loss_mask_1: 1.091  loss_dice_1: 2.767  loss_ce_2: 0  loss_mask_2: 1.093  loss_dice_2: 2.749  loss_ce_3: 0  loss_mask_3: 1.092  loss_dice_3: 2.74  loss_ce_4: 0  loss_mask_4: 1.094  loss_dice_4: 2.741  loss_ce_5: 0  loss_mask_5: 1.096  loss_dice_5: 2.75  loss_ce_6: 0  loss_mask_6: 1.092  loss_dice_6: 2.742  loss_ce_7: 0  loss_mask_7: 1.096  loss_dice_7: 2.749  loss_ce_8: 0  loss_mask_8: 1.093  loss_dice_8: 2.746  time: 2.9022  data_time: 0.0368  lr: 9.256e-05  max_mem: 5999M
[02/18 03:16:09] d2.utils.events INFO:  eta: 2 days, 12:31:20  iter: 4959  total_loss: 38.99  loss_ce: 0  loss_mask: 1.099  loss_dice: 2.781  loss_seg: 0.9969  loss_ce_0: 0  loss_mask_0: 1.117  loss_dice_0: 2.874  loss_ce_1: 0  loss_mask_1: 1.1  loss_dice_1: 2.76  loss_ce_2: 0  loss_mask_2: 1.101  loss_dice_2: 2.757  loss_ce_3: 0  loss_mask_3: 1.097  loss_dice_3: 2.756  loss_ce_4: 0  loss_mask_4: 1.102  loss_dice_4: 2.751  loss_ce_5: 0  loss_mask_5: 1.11  loss_dice_5: 2.754  loss_ce_6: 0  loss_mask_6: 1.104  loss_dice_6: 2.757  loss_ce_7: 0  loss_mask_7: 1.108  loss_dice_7: 2.758  loss_ce_8: 0  loss_mask_8: 1.112  loss_dice_8: 2.763  time: 2.9062  data_time: 0.0456  lr: 9.253e-05  max_mem: 5999M
[02/18 03:17:27] d2.utils.events INFO:  eta: 2 days, 12:29:04  iter: 4979  total_loss: 38.91  loss_ce: 0  loss_mask: 1.018  loss_dice: 2.738  loss_seg: 0.9961  loss_ce_0: 0  loss_mask_0: 1.007  loss_dice_0: 2.799  loss_ce_1: 0  loss_mask_1: 1.023  loss_dice_1: 2.717  loss_ce_2: 0  loss_mask_2: 1.026  loss_dice_2: 2.702  loss_ce_3: 0  loss_mask_3: 1.022  loss_dice_3: 2.695  loss_ce_4: 0  loss_mask_4: 1.031  loss_dice_4: 2.698  loss_ce_5: 0  loss_mask_5: 1.025  loss_dice_5: 2.707  loss_ce_6: 0  loss_mask_6: 1.025  loss_dice_6: 2.699  loss_ce_7: 0  loss_mask_7: 1.026  loss_dice_7: 2.696  loss_ce_8: 0  loss_mask_8: 1.026  loss_dice_8: 2.698  time: 2.9101  data_time: 0.0447  lr: 9.25e-05  max_mem: 5999M
[02/18 03:18:44] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0004999.pth
[02/18 03:18:46] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 03:18:47] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 03:18:47] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 03:19:05] mask2former INFO: Inference done 11/1093. Dataloading: 0.0045 s/iter. Inference: 0.3945 s/iter. Eval: 0.1473 s/iter. Total: 0.5463 s/iter. ETA=0:09:51
[02/18 03:19:10] mask2former INFO: Inference done 19/1093. Dataloading: 0.0062 s/iter. Inference: 0.4476 s/iter. Eval: 0.1645 s/iter. Total: 0.6184 s/iter. ETA=0:11:04
[02/18 03:19:16] mask2former INFO: Inference done 27/1093. Dataloading: 0.0075 s/iter. Inference: 0.4529 s/iter. Eval: 0.1749 s/iter. Total: 0.6354 s/iter. ETA=0:11:17
[02/18 03:19:21] mask2former INFO: Inference done 35/1093. Dataloading: 0.0080 s/iter. Inference: 0.4497 s/iter. Eval: 0.1755 s/iter. Total: 0.6333 s/iter. ETA=0:11:10
[02/18 03:19:26] mask2former INFO: Inference done 43/1093. Dataloading: 0.0088 s/iter. Inference: 0.4425 s/iter. Eval: 0.1875 s/iter. Total: 0.6390 s/iter. ETA=0:11:10
[02/18 03:19:32] mask2former INFO: Inference done 51/1093. Dataloading: 0.0091 s/iter. Inference: 0.4434 s/iter. Eval: 0.1932 s/iter. Total: 0.6459 s/iter. ETA=0:11:12
[02/18 03:19:37] mask2former INFO: Inference done 60/1093. Dataloading: 0.0088 s/iter. Inference: 0.4393 s/iter. Eval: 0.1915 s/iter. Total: 0.6398 s/iter. ETA=0:11:00
[02/18 03:19:42] mask2former INFO: Inference done 68/1093. Dataloading: 0.0092 s/iter. Inference: 0.4415 s/iter. Eval: 0.1914 s/iter. Total: 0.6422 s/iter. ETA=0:10:58
[02/18 03:19:47] mask2former INFO: Inference done 76/1093. Dataloading: 0.0089 s/iter. Inference: 0.4411 s/iter. Eval: 0.1908 s/iter. Total: 0.6409 s/iter. ETA=0:10:51
[02/18 03:19:53] mask2former INFO: Inference done 85/1093. Dataloading: 0.0086 s/iter. Inference: 0.4419 s/iter. Eval: 0.1865 s/iter. Total: 0.6372 s/iter. ETA=0:10:42
[02/18 03:19:58] mask2former INFO: Inference done 94/1093. Dataloading: 0.0086 s/iter. Inference: 0.4416 s/iter. Eval: 0.1859 s/iter. Total: 0.6362 s/iter. ETA=0:10:35
[02/18 03:20:04] mask2former INFO: Inference done 102/1093. Dataloading: 0.0086 s/iter. Inference: 0.4431 s/iter. Eval: 0.1857 s/iter. Total: 0.6376 s/iter. ETA=0:10:31
[02/18 03:20:09] mask2former INFO: Inference done 110/1093. Dataloading: 0.0087 s/iter. Inference: 0.4448 s/iter. Eval: 0.1841 s/iter. Total: 0.6378 s/iter. ETA=0:10:26
[02/18 03:20:14] mask2former INFO: Inference done 118/1093. Dataloading: 0.0090 s/iter. Inference: 0.4458 s/iter. Eval: 0.1829 s/iter. Total: 0.6379 s/iter. ETA=0:10:21
[02/18 03:20:19] mask2former INFO: Inference done 127/1093. Dataloading: 0.0089 s/iter. Inference: 0.4443 s/iter. Eval: 0.1820 s/iter. Total: 0.6356 s/iter. ETA=0:10:14
[02/18 03:20:25] mask2former INFO: Inference done 136/1093. Dataloading: 0.0091 s/iter. Inference: 0.4443 s/iter. Eval: 0.1812 s/iter. Total: 0.6350 s/iter. ETA=0:10:07
[02/18 03:20:31] mask2former INFO: Inference done 145/1093. Dataloading: 0.0091 s/iter. Inference: 0.4432 s/iter. Eval: 0.1812 s/iter. Total: 0.6339 s/iter. ETA=0:10:00
[02/18 03:20:36] mask2former INFO: Inference done 154/1093. Dataloading: 0.0090 s/iter. Inference: 0.4419 s/iter. Eval: 0.1796 s/iter. Total: 0.6309 s/iter. ETA=0:09:52
[02/18 03:20:41] mask2former INFO: Inference done 162/1093. Dataloading: 0.0099 s/iter. Inference: 0.4441 s/iter. Eval: 0.1797 s/iter. Total: 0.6341 s/iter. ETA=0:09:50
[02/18 03:20:47] mask2former INFO: Inference done 170/1093. Dataloading: 0.0097 s/iter. Inference: 0.4458 s/iter. Eval: 0.1805 s/iter. Total: 0.6363 s/iter. ETA=0:09:47
[02/18 03:20:52] mask2former INFO: Inference done 177/1093. Dataloading: 0.0097 s/iter. Inference: 0.4475 s/iter. Eval: 0.1824 s/iter. Total: 0.6400 s/iter. ETA=0:09:46
[02/18 03:20:57] mask2former INFO: Inference done 186/1093. Dataloading: 0.0096 s/iter. Inference: 0.4462 s/iter. Eval: 0.1822 s/iter. Total: 0.6383 s/iter. ETA=0:09:38
[02/18 03:21:03] mask2former INFO: Inference done 193/1093. Dataloading: 0.0095 s/iter. Inference: 0.4489 s/iter. Eval: 0.1839 s/iter. Total: 0.6426 s/iter. ETA=0:09:38
[02/18 03:21:08] mask2former INFO: Inference done 200/1093. Dataloading: 0.0095 s/iter. Inference: 0.4501 s/iter. Eval: 0.1861 s/iter. Total: 0.6461 s/iter. ETA=0:09:36
[02/18 03:21:13] mask2former INFO: Inference done 208/1093. Dataloading: 0.0094 s/iter. Inference: 0.4510 s/iter. Eval: 0.1855 s/iter. Total: 0.6462 s/iter. ETA=0:09:31
[02/18 03:21:18] mask2former INFO: Inference done 217/1093. Dataloading: 0.0092 s/iter. Inference: 0.4499 s/iter. Eval: 0.1847 s/iter. Total: 0.6441 s/iter. ETA=0:09:24
[02/18 03:21:24] mask2former INFO: Inference done 225/1093. Dataloading: 0.0094 s/iter. Inference: 0.4499 s/iter. Eval: 0.1859 s/iter. Total: 0.6455 s/iter. ETA=0:09:20
[02/18 03:21:29] mask2former INFO: Inference done 233/1093. Dataloading: 0.0096 s/iter. Inference: 0.4512 s/iter. Eval: 0.1849 s/iter. Total: 0.6460 s/iter. ETA=0:09:15
[02/18 03:21:34] mask2former INFO: Inference done 241/1093. Dataloading: 0.0096 s/iter. Inference: 0.4511 s/iter. Eval: 0.1855 s/iter. Total: 0.6465 s/iter. ETA=0:09:10
[02/18 03:21:40] mask2former INFO: Inference done 249/1093. Dataloading: 0.0095 s/iter. Inference: 0.4516 s/iter. Eval: 0.1858 s/iter. Total: 0.6471 s/iter. ETA=0:09:06
[02/18 03:21:45] mask2former INFO: Inference done 258/1093. Dataloading: 0.0094 s/iter. Inference: 0.4508 s/iter. Eval: 0.1849 s/iter. Total: 0.6454 s/iter. ETA=0:08:58
[02/18 03:21:50] mask2former INFO: Inference done 266/1093. Dataloading: 0.0094 s/iter. Inference: 0.4506 s/iter. Eval: 0.1849 s/iter. Total: 0.6452 s/iter. ETA=0:08:53
[02/18 03:21:56] mask2former INFO: Inference done 274/1093. Dataloading: 0.0094 s/iter. Inference: 0.4503 s/iter. Eval: 0.1857 s/iter. Total: 0.6458 s/iter. ETA=0:08:48
[02/18 03:22:01] mask2former INFO: Inference done 282/1093. Dataloading: 0.0094 s/iter. Inference: 0.4515 s/iter. Eval: 0.1854 s/iter. Total: 0.6465 s/iter. ETA=0:08:44
[02/18 03:22:06] mask2former INFO: Inference done 291/1093. Dataloading: 0.0092 s/iter. Inference: 0.4509 s/iter. Eval: 0.1846 s/iter. Total: 0.6450 s/iter. ETA=0:08:37
[02/18 03:22:12] mask2former INFO: Inference done 299/1093. Dataloading: 0.0096 s/iter. Inference: 0.4507 s/iter. Eval: 0.1849 s/iter. Total: 0.6454 s/iter. ETA=0:08:32
[02/18 03:22:17] mask2former INFO: Inference done 307/1093. Dataloading: 0.0096 s/iter. Inference: 0.4514 s/iter. Eval: 0.1842 s/iter. Total: 0.6455 s/iter. ETA=0:08:27
[02/18 03:22:22] mask2former INFO: Inference done 315/1093. Dataloading: 0.0095 s/iter. Inference: 0.4516 s/iter. Eval: 0.1842 s/iter. Total: 0.6456 s/iter. ETA=0:08:22
[02/18 03:22:27] mask2former INFO: Inference done 323/1093. Dataloading: 0.0095 s/iter. Inference: 0.4518 s/iter. Eval: 0.1841 s/iter. Total: 0.6457 s/iter. ETA=0:08:17
[02/18 03:22:33] mask2former INFO: Inference done 331/1093. Dataloading: 0.0094 s/iter. Inference: 0.4520 s/iter. Eval: 0.1849 s/iter. Total: 0.6466 s/iter. ETA=0:08:12
[02/18 03:22:38] mask2former INFO: Inference done 339/1093. Dataloading: 0.0094 s/iter. Inference: 0.4515 s/iter. Eval: 0.1854 s/iter. Total: 0.6465 s/iter. ETA=0:08:07
[02/18 03:22:43] mask2former INFO: Inference done 347/1093. Dataloading: 0.0093 s/iter. Inference: 0.4514 s/iter. Eval: 0.1850 s/iter. Total: 0.6460 s/iter. ETA=0:08:01
[02/18 03:22:48] mask2former INFO: Inference done 355/1093. Dataloading: 0.0092 s/iter. Inference: 0.4517 s/iter. Eval: 0.1844 s/iter. Total: 0.6456 s/iter. ETA=0:07:56
[02/18 03:22:53] mask2former INFO: Inference done 363/1093. Dataloading: 0.0092 s/iter. Inference: 0.4513 s/iter. Eval: 0.1845 s/iter. Total: 0.6452 s/iter. ETA=0:07:51
[02/18 03:22:58] mask2former INFO: Inference done 371/1093. Dataloading: 0.0092 s/iter. Inference: 0.4506 s/iter. Eval: 0.1849 s/iter. Total: 0.6450 s/iter. ETA=0:07:45
[02/18 03:23:03] mask2former INFO: Inference done 380/1093. Dataloading: 0.0092 s/iter. Inference: 0.4499 s/iter. Eval: 0.1843 s/iter. Total: 0.6437 s/iter. ETA=0:07:38
[02/18 03:23:08] mask2former INFO: Inference done 387/1093. Dataloading: 0.0093 s/iter. Inference: 0.4514 s/iter. Eval: 0.1843 s/iter. Total: 0.6453 s/iter. ETA=0:07:35
[02/18 03:23:14] mask2former INFO: Inference done 396/1093. Dataloading: 0.0092 s/iter. Inference: 0.4511 s/iter. Eval: 0.1832 s/iter. Total: 0.6438 s/iter. ETA=0:07:28
[02/18 03:23:19] mask2former INFO: Inference done 404/1093. Dataloading: 0.0092 s/iter. Inference: 0.4508 s/iter. Eval: 0.1838 s/iter. Total: 0.6441 s/iter. ETA=0:07:23
[02/18 03:23:24] mask2former INFO: Inference done 412/1093. Dataloading: 0.0092 s/iter. Inference: 0.4509 s/iter. Eval: 0.1844 s/iter. Total: 0.6447 s/iter. ETA=0:07:19
[02/18 03:23:30] mask2former INFO: Inference done 421/1093. Dataloading: 0.0091 s/iter. Inference: 0.4506 s/iter. Eval: 0.1840 s/iter. Total: 0.6441 s/iter. ETA=0:07:12
[02/18 03:23:35] mask2former INFO: Inference done 430/1093. Dataloading: 0.0091 s/iter. Inference: 0.4497 s/iter. Eval: 0.1843 s/iter. Total: 0.6434 s/iter. ETA=0:07:06
[02/18 03:23:41] mask2former INFO: Inference done 439/1093. Dataloading: 0.0091 s/iter. Inference: 0.4494 s/iter. Eval: 0.1836 s/iter. Total: 0.6424 s/iter. ETA=0:07:00
[02/18 03:23:46] mask2former INFO: Inference done 447/1093. Dataloading: 0.0090 s/iter. Inference: 0.4492 s/iter. Eval: 0.1839 s/iter. Total: 0.6424 s/iter. ETA=0:06:54
[02/18 03:23:51] mask2former INFO: Inference done 455/1093. Dataloading: 0.0090 s/iter. Inference: 0.4494 s/iter. Eval: 0.1836 s/iter. Total: 0.6422 s/iter. ETA=0:06:49
[02/18 03:23:56] mask2former INFO: Inference done 463/1093. Dataloading: 0.0090 s/iter. Inference: 0.4493 s/iter. Eval: 0.1839 s/iter. Total: 0.6424 s/iter. ETA=0:06:44
[02/18 03:24:02] mask2former INFO: Inference done 471/1093. Dataloading: 0.0091 s/iter. Inference: 0.4502 s/iter. Eval: 0.1844 s/iter. Total: 0.6440 s/iter. ETA=0:06:40
[02/18 03:24:07] mask2former INFO: Inference done 480/1093. Dataloading: 0.0091 s/iter. Inference: 0.4499 s/iter. Eval: 0.1840 s/iter. Total: 0.6433 s/iter. ETA=0:06:34
[02/18 03:24:13] mask2former INFO: Inference done 488/1093. Dataloading: 0.0091 s/iter. Inference: 0.4495 s/iter. Eval: 0.1847 s/iter. Total: 0.6435 s/iter. ETA=0:06:29
[02/18 03:24:18] mask2former INFO: Inference done 496/1093. Dataloading: 0.0090 s/iter. Inference: 0.4504 s/iter. Eval: 0.1847 s/iter. Total: 0.6444 s/iter. ETA=0:06:24
[02/18 03:24:24] mask2former INFO: Inference done 504/1093. Dataloading: 0.0090 s/iter. Inference: 0.4500 s/iter. Eval: 0.1856 s/iter. Total: 0.6448 s/iter. ETA=0:06:19
[02/18 03:24:29] mask2former INFO: Inference done 512/1093. Dataloading: 0.0090 s/iter. Inference: 0.4503 s/iter. Eval: 0.1855 s/iter. Total: 0.6450 s/iter. ETA=0:06:14
[02/18 03:24:34] mask2former INFO: Inference done 520/1093. Dataloading: 0.0090 s/iter. Inference: 0.4504 s/iter. Eval: 0.1857 s/iter. Total: 0.6454 s/iter. ETA=0:06:09
[02/18 03:24:40] mask2former INFO: Inference done 528/1093. Dataloading: 0.0091 s/iter. Inference: 0.4503 s/iter. Eval: 0.1863 s/iter. Total: 0.6460 s/iter. ETA=0:06:04
[02/18 03:24:45] mask2former INFO: Inference done 536/1093. Dataloading: 0.0090 s/iter. Inference: 0.4502 s/iter. Eval: 0.1864 s/iter. Total: 0.6459 s/iter. ETA=0:05:59
[02/18 03:24:51] mask2former INFO: Inference done 545/1093. Dataloading: 0.0090 s/iter. Inference: 0.4504 s/iter. Eval: 0.1864 s/iter. Total: 0.6460 s/iter. ETA=0:05:54
[02/18 03:24:56] mask2former INFO: Inference done 553/1093. Dataloading: 0.0090 s/iter. Inference: 0.4507 s/iter. Eval: 0.1860 s/iter. Total: 0.6460 s/iter. ETA=0:05:48
[02/18 03:25:01] mask2former INFO: Inference done 561/1093. Dataloading: 0.0091 s/iter. Inference: 0.4512 s/iter. Eval: 0.1858 s/iter. Total: 0.6463 s/iter. ETA=0:05:43
[02/18 03:25:07] mask2former INFO: Inference done 570/1093. Dataloading: 0.0090 s/iter. Inference: 0.4507 s/iter. Eval: 0.1857 s/iter. Total: 0.6456 s/iter. ETA=0:05:37
[02/18 03:25:12] mask2former INFO: Inference done 579/1093. Dataloading: 0.0090 s/iter. Inference: 0.4506 s/iter. Eval: 0.1853 s/iter. Total: 0.6451 s/iter. ETA=0:05:31
[02/18 03:25:17] mask2former INFO: Inference done 588/1093. Dataloading: 0.0089 s/iter. Inference: 0.4500 s/iter. Eval: 0.1849 s/iter. Total: 0.6441 s/iter. ETA=0:05:25
[02/18 03:25:23] mask2former INFO: Inference done 597/1093. Dataloading: 0.0090 s/iter. Inference: 0.4499 s/iter. Eval: 0.1848 s/iter. Total: 0.6439 s/iter. ETA=0:05:19
[02/18 03:25:28] mask2former INFO: Inference done 607/1093. Dataloading: 0.0089 s/iter. Inference: 0.4490 s/iter. Eval: 0.1842 s/iter. Total: 0.6423 s/iter. ETA=0:05:12
[02/18 03:25:34] mask2former INFO: Inference done 615/1093. Dataloading: 0.0090 s/iter. Inference: 0.4493 s/iter. Eval: 0.1840 s/iter. Total: 0.6426 s/iter. ETA=0:05:07
[02/18 03:25:39] mask2former INFO: Inference done 624/1093. Dataloading: 0.0090 s/iter. Inference: 0.4494 s/iter. Eval: 0.1835 s/iter. Total: 0.6421 s/iter. ETA=0:05:01
[02/18 03:25:44] mask2former INFO: Inference done 631/1093. Dataloading: 0.0090 s/iter. Inference: 0.4500 s/iter. Eval: 0.1837 s/iter. Total: 0.6430 s/iter. ETA=0:04:57
[02/18 03:25:49] mask2former INFO: Inference done 639/1093. Dataloading: 0.0090 s/iter. Inference: 0.4502 s/iter. Eval: 0.1836 s/iter. Total: 0.6430 s/iter. ETA=0:04:51
[02/18 03:25:55] mask2former INFO: Inference done 647/1093. Dataloading: 0.0089 s/iter. Inference: 0.4506 s/iter. Eval: 0.1838 s/iter. Total: 0.6436 s/iter. ETA=0:04:47
[02/18 03:26:00] mask2former INFO: Inference done 656/1093. Dataloading: 0.0089 s/iter. Inference: 0.4502 s/iter. Eval: 0.1836 s/iter. Total: 0.6430 s/iter. ETA=0:04:41
[02/18 03:26:05] mask2former INFO: Inference done 664/1093. Dataloading: 0.0089 s/iter. Inference: 0.4503 s/iter. Eval: 0.1834 s/iter. Total: 0.6428 s/iter. ETA=0:04:35
[02/18 03:26:11] mask2former INFO: Inference done 672/1093. Dataloading: 0.0089 s/iter. Inference: 0.4507 s/iter. Eval: 0.1832 s/iter. Total: 0.6430 s/iter. ETA=0:04:30
[02/18 03:26:16] mask2former INFO: Inference done 681/1093. Dataloading: 0.0089 s/iter. Inference: 0.4503 s/iter. Eval: 0.1833 s/iter. Total: 0.6428 s/iter. ETA=0:04:24
[02/18 03:26:21] mask2former INFO: Inference done 688/1093. Dataloading: 0.0089 s/iter. Inference: 0.4509 s/iter. Eval: 0.1836 s/iter. Total: 0.6435 s/iter. ETA=0:04:20
[02/18 03:26:27] mask2former INFO: Inference done 697/1093. Dataloading: 0.0089 s/iter. Inference: 0.4508 s/iter. Eval: 0.1832 s/iter. Total: 0.6431 s/iter. ETA=0:04:14
[02/18 03:26:32] mask2former INFO: Inference done 706/1093. Dataloading: 0.0089 s/iter. Inference: 0.4503 s/iter. Eval: 0.1829 s/iter. Total: 0.6423 s/iter. ETA=0:04:08
[02/18 03:26:37] mask2former INFO: Inference done 714/1093. Dataloading: 0.0089 s/iter. Inference: 0.4502 s/iter. Eval: 0.1828 s/iter. Total: 0.6421 s/iter. ETA=0:04:03
[02/18 03:26:42] mask2former INFO: Inference done 722/1093. Dataloading: 0.0090 s/iter. Inference: 0.4506 s/iter. Eval: 0.1826 s/iter. Total: 0.6424 s/iter. ETA=0:03:58
[02/18 03:26:48] mask2former INFO: Inference done 730/1093. Dataloading: 0.0090 s/iter. Inference: 0.4509 s/iter. Eval: 0.1830 s/iter. Total: 0.6430 s/iter. ETA=0:03:53
[02/18 03:26:53] mask2former INFO: Inference done 737/1093. Dataloading: 0.0090 s/iter. Inference: 0.4513 s/iter. Eval: 0.1835 s/iter. Total: 0.6440 s/iter. ETA=0:03:49
[02/18 03:26:58] mask2former INFO: Inference done 745/1093. Dataloading: 0.0089 s/iter. Inference: 0.4513 s/iter. Eval: 0.1834 s/iter. Total: 0.6439 s/iter. ETA=0:03:44
[02/18 03:27:04] mask2former INFO: Inference done 753/1093. Dataloading: 0.0090 s/iter. Inference: 0.4513 s/iter. Eval: 0.1835 s/iter. Total: 0.6440 s/iter. ETA=0:03:38
[02/18 03:27:09] mask2former INFO: Inference done 760/1093. Dataloading: 0.0090 s/iter. Inference: 0.4516 s/iter. Eval: 0.1839 s/iter. Total: 0.6447 s/iter. ETA=0:03:34
[02/18 03:27:14] mask2former INFO: Inference done 767/1093. Dataloading: 0.0090 s/iter. Inference: 0.4521 s/iter. Eval: 0.1842 s/iter. Total: 0.6455 s/iter. ETA=0:03:30
[02/18 03:27:19] mask2former INFO: Inference done 775/1093. Dataloading: 0.0090 s/iter. Inference: 0.4521 s/iter. Eval: 0.1843 s/iter. Total: 0.6457 s/iter. ETA=0:03:25
[02/18 03:27:24] mask2former INFO: Inference done 783/1093. Dataloading: 0.0090 s/iter. Inference: 0.4520 s/iter. Eval: 0.1848 s/iter. Total: 0.6460 s/iter. ETA=0:03:20
[02/18 03:27:30] mask2former INFO: Inference done 791/1093. Dataloading: 0.0090 s/iter. Inference: 0.4522 s/iter. Eval: 0.1850 s/iter. Total: 0.6465 s/iter. ETA=0:03:15
[02/18 03:27:35] mask2former INFO: Inference done 800/1093. Dataloading: 0.0090 s/iter. Inference: 0.4519 s/iter. Eval: 0.1848 s/iter. Total: 0.6459 s/iter. ETA=0:03:09
[02/18 03:27:41] mask2former INFO: Inference done 809/1093. Dataloading: 0.0090 s/iter. Inference: 0.4517 s/iter. Eval: 0.1848 s/iter. Total: 0.6457 s/iter. ETA=0:03:03
[02/18 03:27:46] mask2former INFO: Inference done 817/1093. Dataloading: 0.0090 s/iter. Inference: 0.4518 s/iter. Eval: 0.1849 s/iter. Total: 0.6459 s/iter. ETA=0:02:58
[02/18 03:27:51] mask2former INFO: Inference done 825/1093. Dataloading: 0.0089 s/iter. Inference: 0.4519 s/iter. Eval: 0.1846 s/iter. Total: 0.6457 s/iter. ETA=0:02:53
[02/18 03:27:57] mask2former INFO: Inference done 833/1093. Dataloading: 0.0090 s/iter. Inference: 0.4520 s/iter. Eval: 0.1846 s/iter. Total: 0.6458 s/iter. ETA=0:02:47
[02/18 03:28:02] mask2former INFO: Inference done 841/1093. Dataloading: 0.0090 s/iter. Inference: 0.4524 s/iter. Eval: 0.1844 s/iter. Total: 0.6459 s/iter. ETA=0:02:42
[02/18 03:28:07] mask2former INFO: Inference done 849/1093. Dataloading: 0.0092 s/iter. Inference: 0.4524 s/iter. Eval: 0.1839 s/iter. Total: 0.6457 s/iter. ETA=0:02:37
[02/18 03:28:12] mask2former INFO: Inference done 857/1093. Dataloading: 0.0092 s/iter. Inference: 0.4525 s/iter. Eval: 0.1837 s/iter. Total: 0.6456 s/iter. ETA=0:02:32
[02/18 03:28:17] mask2former INFO: Inference done 865/1093. Dataloading: 0.0092 s/iter. Inference: 0.4525 s/iter. Eval: 0.1836 s/iter. Total: 0.6456 s/iter. ETA=0:02:27
[02/18 03:28:23] mask2former INFO: Inference done 873/1093. Dataloading: 0.0092 s/iter. Inference: 0.4530 s/iter. Eval: 0.1836 s/iter. Total: 0.6460 s/iter. ETA=0:02:22
[02/18 03:28:28] mask2former INFO: Inference done 882/1093. Dataloading: 0.0092 s/iter. Inference: 0.4528 s/iter. Eval: 0.1831 s/iter. Total: 0.6453 s/iter. ETA=0:02:16
[02/18 03:28:33] mask2former INFO: Inference done 891/1093. Dataloading: 0.0092 s/iter. Inference: 0.4528 s/iter. Eval: 0.1828 s/iter. Total: 0.6450 s/iter. ETA=0:02:10
[02/18 03:28:38] mask2former INFO: Inference done 899/1093. Dataloading: 0.0092 s/iter. Inference: 0.4526 s/iter. Eval: 0.1829 s/iter. Total: 0.6449 s/iter. ETA=0:02:05
[02/18 03:28:44] mask2former INFO: Inference done 907/1093. Dataloading: 0.0092 s/iter. Inference: 0.4526 s/iter. Eval: 0.1830 s/iter. Total: 0.6451 s/iter. ETA=0:01:59
[02/18 03:28:49] mask2former INFO: Inference done 915/1093. Dataloading: 0.0092 s/iter. Inference: 0.4527 s/iter. Eval: 0.1831 s/iter. Total: 0.6453 s/iter. ETA=0:01:54
[02/18 03:28:55] mask2former INFO: Inference done 924/1093. Dataloading: 0.0092 s/iter. Inference: 0.4525 s/iter. Eval: 0.1830 s/iter. Total: 0.6450 s/iter. ETA=0:01:49
[02/18 03:29:00] mask2former INFO: Inference done 932/1093. Dataloading: 0.0093 s/iter. Inference: 0.4525 s/iter. Eval: 0.1829 s/iter. Total: 0.6449 s/iter. ETA=0:01:43
[02/18 03:29:05] mask2former INFO: Inference done 940/1093. Dataloading: 0.0092 s/iter. Inference: 0.4524 s/iter. Eval: 0.1831 s/iter. Total: 0.6450 s/iter. ETA=0:01:38
[02/18 03:29:10] mask2former INFO: Inference done 948/1093. Dataloading: 0.0092 s/iter. Inference: 0.4526 s/iter. Eval: 0.1831 s/iter. Total: 0.6451 s/iter. ETA=0:01:33
[02/18 03:29:16] mask2former INFO: Inference done 956/1093. Dataloading: 0.0092 s/iter. Inference: 0.4527 s/iter. Eval: 0.1833 s/iter. Total: 0.6454 s/iter. ETA=0:01:28
[02/18 03:29:21] mask2former INFO: Inference done 963/1093. Dataloading: 0.0092 s/iter. Inference: 0.4532 s/iter. Eval: 0.1835 s/iter. Total: 0.6462 s/iter. ETA=0:01:24
[02/18 03:29:26] mask2former INFO: Inference done 971/1093. Dataloading: 0.0092 s/iter. Inference: 0.4532 s/iter. Eval: 0.1835 s/iter. Total: 0.6461 s/iter. ETA=0:01:18
[02/18 03:29:31] mask2former INFO: Inference done 979/1093. Dataloading: 0.0092 s/iter. Inference: 0.4531 s/iter. Eval: 0.1835 s/iter. Total: 0.6460 s/iter. ETA=0:01:13
[02/18 03:29:37] mask2former INFO: Inference done 987/1093. Dataloading: 0.0092 s/iter. Inference: 0.4534 s/iter. Eval: 0.1835 s/iter. Total: 0.6463 s/iter. ETA=0:01:08
[02/18 03:29:42] mask2former INFO: Inference done 995/1093. Dataloading: 0.0092 s/iter. Inference: 0.4532 s/iter. Eval: 0.1836 s/iter. Total: 0.6462 s/iter. ETA=0:01:03
[02/18 03:29:47] mask2former INFO: Inference done 1003/1093. Dataloading: 0.0092 s/iter. Inference: 0.4533 s/iter. Eval: 0.1837 s/iter. Total: 0.6464 s/iter. ETA=0:00:58
[02/18 03:29:52] mask2former INFO: Inference done 1011/1093. Dataloading: 0.0092 s/iter. Inference: 0.4534 s/iter. Eval: 0.1836 s/iter. Total: 0.6464 s/iter. ETA=0:00:53
[02/18 03:29:58] mask2former INFO: Inference done 1020/1093. Dataloading: 0.0092 s/iter. Inference: 0.4531 s/iter. Eval: 0.1838 s/iter. Total: 0.6463 s/iter. ETA=0:00:47
[02/18 03:30:03] mask2former INFO: Inference done 1029/1093. Dataloading: 0.0092 s/iter. Inference: 0.4530 s/iter. Eval: 0.1836 s/iter. Total: 0.6459 s/iter. ETA=0:00:41
[02/18 03:30:08] mask2former INFO: Inference done 1037/1093. Dataloading: 0.0091 s/iter. Inference: 0.4531 s/iter. Eval: 0.1834 s/iter. Total: 0.6459 s/iter. ETA=0:00:36
[02/18 03:30:14] mask2former INFO: Inference done 1046/1093. Dataloading: 0.0091 s/iter. Inference: 0.4529 s/iter. Eval: 0.1831 s/iter. Total: 0.6453 s/iter. ETA=0:00:30
[02/18 03:30:19] mask2former INFO: Inference done 1055/1093. Dataloading: 0.0091 s/iter. Inference: 0.4527 s/iter. Eval: 0.1829 s/iter. Total: 0.6449 s/iter. ETA=0:00:24
[02/18 03:30:25] mask2former INFO: Inference done 1064/1093. Dataloading: 0.0091 s/iter. Inference: 0.4527 s/iter. Eval: 0.1827 s/iter. Total: 0.6447 s/iter. ETA=0:00:18
[02/18 03:30:30] mask2former INFO: Inference done 1071/1093. Dataloading: 0.0091 s/iter. Inference: 0.4532 s/iter. Eval: 0.1829 s/iter. Total: 0.6454 s/iter. ETA=0:00:14
[02/18 03:30:36] mask2former INFO: Inference done 1079/1093. Dataloading: 0.0091 s/iter. Inference: 0.4535 s/iter. Eval: 0.1832 s/iter. Total: 0.6460 s/iter. ETA=0:00:09
[02/18 03:30:42] mask2former INFO: Inference done 1085/1093. Dataloading: 0.0091 s/iter. Inference: 0.4549 s/iter. Eval: 0.1836 s/iter. Total: 0.6479 s/iter. ETA=0:00:05
[02/18 03:30:47] mask2former INFO: Inference done 1092/1093. Dataloading: 0.0091 s/iter. Inference: 0.4555 s/iter. Eval: 0.1840 s/iter. Total: 0.6488 s/iter. ETA=0:00:00
[02/18 03:31:58] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.326646225539005, 'error_1pix': 0.5849155092283326, 'error_3pix': 0.3444111146955073, 'mIoU': 9.929967614147232, 'fwIoU': 33.76345740860206, 'IoU-1': 89.86343592248788, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.4764812078943698, 'IoU-10': 10.93162210062624, 'IoU-11': 10.359993465679752, 'IoU-12': 30.052255386670296, 'IoU-13': 17.384097875852174, 'IoU-14': 12.516997406280254, 'IoU-15': 9.619200331987178, 'IoU-16': 6.13690774607837, 'IoU-17': 3.7157652917528887, 'IoU-18': 2.7681428517146287, 'IoU-19': 1.8181393443356613, 'IoU-20': 1.589761019821849, 'IoU-21': 1.7697274915570722, 'IoU-22': 3.2765513655846568, 'IoU-23': 9.02932879675928, 'IoU-24': 14.050538884900131, 'IoU-25': 21.013259163354924, 'IoU-26': 16.739387080307228, 'IoU-27': 3.378374170888607, 'IoU-28': 2.8994145179092223, 'IoU-29': 6.243094647979299, 'IoU-30': 14.608201612000727, 'IoU-31': 22.235137198669655, 'IoU-32': 30.083980431987733, 'IoU-33': 15.657527000759774, 'IoU-34': 7.574573084165875, 'IoU-35': 4.839993480827727, 'IoU-36': 23.354710718627118, 'IoU-37': 9.596843720027625, 'IoU-38': 9.341194144948782, 'IoU-39': 11.678348910605472, 'IoU-40': 9.137074417202475, 'IoU-41': 4.868926658451922, 'IoU-42': 3.7843587969370347, 'IoU-43': 16.6233930097103, 'IoU-44': 3.3181080757307786, 'IoU-45': 2.8238405832541673, 'IoU-46': 3.156658752642233, 'IoU-47': 3.803541839085535, 'IoU-48': 4.51955697301016, 'mACC': 18.42846853982442, 'pACC': 41.51384016174139, 'ACC-1': 95.86012147435939, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 31.17435737154055, 'ACC-10': 19.762476302252267, 'ACC-11': 12.552703987838996, 'ACC-12': 57.505554859023135, 'ACC-13': 36.57046222276869, 'ACC-14': 31.526312440964816, 'ACC-15': 24.73937354761578, 'ACC-16': 13.657723441330822, 'ACC-17': 7.017426956550474, 'ACC-18': 4.314920234928736, 'ACC-19': 2.6264454184394146, 'ACC-20': 2.1993535997659417, 'ACC-21': 2.440981124600322, 'ACC-22': 4.3947487852506315, 'ACC-23': 12.298122424748913, 'ACC-24': 21.062228537007535, 'ACC-25': 39.87544720607463, 'ACC-26': 53.590512246582165, 'ACC-27': 6.2675128746810485, 'ACC-28': 4.256049664708966, 'ACC-29': 8.467567869981025, 'ACC-30': 18.97994542342218, 'ACC-31': 30.715685051575004, 'ACC-32': 49.21550743408174, 'ACC-33': 20.28671575987163, 'ACC-34': 9.979045834800841, 'ACC-35': 7.043150028627286, 'ACC-36': 77.23503967074895, 'ACC-37': 17.020859622356163, 'ACC-38': 13.42327862531986, 'ACC-39': 15.262579399833806, 'ACC-40': 12.007864884411974, 'ACC-41': 6.924240968540301, 'ACC-42': 6.3629241855365875, 'ACC-43': 80.27850599035742, 'ACC-44': 6.45458027288849, 'ACC-45': 4.44129911165212, 'ACC-46': 4.674039807075396, 'ACC-47': 5.559776059572313, 'ACC-48': 6.5410491898858005})])
[02/18 03:31:58] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 03:31:58] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 03:31:58] d2.evaluation.testing INFO: copypaste: 4.3266,0.5849,0.3444,9.9300,33.7635,18.4285,41.5138
[02/18 03:31:58] d2.utils.events INFO:  eta: 2 days, 12:28:42  iter: 4999  total_loss: 40.42  loss_ce: 0  loss_mask: 1.113  loss_dice: 2.863  loss_seg: 0.9707  loss_ce_0: 0  loss_mask_0: 1.104  loss_dice_0: 2.914  loss_ce_1: 0  loss_mask_1: 1.119  loss_dice_1: 2.848  loss_ce_2: 0  loss_mask_2: 1.112  loss_dice_2: 2.835  loss_ce_3: 0  loss_mask_3: 1.114  loss_dice_3: 2.826  loss_ce_4: 0  loss_mask_4: 1.117  loss_dice_4: 2.832  loss_ce_5: 0  loss_mask_5: 1.119  loss_dice_5: 2.836  loss_ce_6: 0  loss_mask_6: 1.118  loss_dice_6: 2.832  loss_ce_7: 0  loss_mask_7: 1.119  loss_dice_7: 2.827  loss_ce_8: 0  loss_mask_8: 1.115  loss_dice_8: 2.832  time: 2.9140  data_time: 0.0365  lr: 9.2469e-05  max_mem: 5999M
[02/18 03:33:10] d2.utils.events INFO:  eta: 2 days, 12:26:26  iter: 5019  total_loss: 39.85  loss_ce: 0  loss_mask: 1.071  loss_dice: 2.8  loss_seg: 0.914  loss_ce_0: 0  loss_mask_0: 1.082  loss_dice_0: 2.852  loss_ce_1: 0  loss_mask_1: 1.074  loss_dice_1: 2.788  loss_ce_2: 0  loss_mask_2: 1.081  loss_dice_2: 2.779  loss_ce_3: 0  loss_mask_3: 1.08  loss_dice_3: 2.759  loss_ce_4: 0  loss_mask_4: 1.084  loss_dice_4: 2.761  loss_ce_5: 0  loss_mask_5: 1.082  loss_dice_5: 2.775  loss_ce_6: 0  loss_mask_6: 1.085  loss_dice_6: 2.764  loss_ce_7: 0  loss_mask_7: 1.081  loss_dice_7: 2.773  loss_ce_8: 0  loss_mask_8: 1.08  loss_dice_8: 2.774  time: 2.9166  data_time: 0.0543  lr: 9.2439e-05  max_mem: 5999M
[02/18 03:34:21] d2.utils.events INFO:  eta: 2 days, 12:17:48  iter: 5039  total_loss: 41.49  loss_ce: 0  loss_mask: 1.003  loss_dice: 3.014  loss_seg: 0.9545  loss_ce_0: 0  loss_mask_0: 1.004  loss_dice_0: 3.082  loss_ce_1: 0  loss_mask_1: 1.001  loss_dice_1: 3.006  loss_ce_2: 0  loss_mask_2: 1.008  loss_dice_2: 2.992  loss_ce_3: 0  loss_mask_3: 1.011  loss_dice_3: 2.983  loss_ce_4: 0  loss_mask_4: 1.016  loss_dice_4: 2.986  loss_ce_5: 0  loss_mask_5: 1.018  loss_dice_5: 2.994  loss_ce_6: 0  loss_mask_6: 1.014  loss_dice_6: 2.998  loss_ce_7: 0  loss_mask_7: 1.008  loss_dice_7: 2.998  loss_ce_8: 0  loss_mask_8: 1.014  loss_dice_8: 2.997  time: 2.9191  data_time: 0.0544  lr: 9.2409e-05  max_mem: 5999M
[02/18 03:35:18] d2.utils.events INFO:  eta: 2 days, 11:55:34  iter: 5059  total_loss: 39.22  loss_ce: 0  loss_mask: 1.049  loss_dice: 2.707  loss_seg: 0.8083  loss_ce_0: 0  loss_mask_0: 1.043  loss_dice_0: 2.767  loss_ce_1: 0  loss_mask_1: 1.047  loss_dice_1: 2.682  loss_ce_2: 0  loss_mask_2: 1.042  loss_dice_2: 2.683  loss_ce_3: 0  loss_mask_3: 1.051  loss_dice_3: 2.673  loss_ce_4: 0  loss_mask_4: 1.047  loss_dice_4: 2.671  loss_ce_5: 0  loss_mask_5: 1.054  loss_dice_5: 2.675  loss_ce_6: 0  loss_mask_6: 1.049  loss_dice_6: 2.687  loss_ce_7: 0  loss_mask_7: 1.056  loss_dice_7: 2.676  loss_ce_8: 0  loss_mask_8: 1.053  loss_dice_8: 2.686  time: 2.9187  data_time: 0.0449  lr: 9.2378e-05  max_mem: 5999M
[02/18 03:36:07] d2.utils.events INFO:  eta: 2 days, 11:39:32  iter: 5079  total_loss: 38.72  loss_ce: 0  loss_mask: 1.046  loss_dice: 2.718  loss_seg: 1.266  loss_ce_0: 0  loss_mask_0: 1.034  loss_dice_0: 2.768  loss_ce_1: 0  loss_mask_1: 1.038  loss_dice_1: 2.706  loss_ce_2: 0  loss_mask_2: 1.052  loss_dice_2: 2.688  loss_ce_3: 0  loss_mask_3: 1.047  loss_dice_3: 2.688  loss_ce_4: 0  loss_mask_4: 1.051  loss_dice_4: 2.693  loss_ce_5: 0  loss_mask_5: 1.053  loss_dice_5: 2.693  loss_ce_6: 0  loss_mask_6: 1.051  loss_dice_6: 2.686  loss_ce_7: 0  loss_mask_7: 1.047  loss_dice_7: 2.697  loss_ce_8: 0  loss_mask_8: 1.048  loss_dice_8: 2.694  time: 2.9168  data_time: 0.0599  lr: 9.2348e-05  max_mem: 5999M
[02/18 03:36:57] d2.utils.events INFO:  eta: 2 days, 11:23:04  iter: 5099  total_loss: 39.75  loss_ce: 0  loss_mask: 1.042  loss_dice: 2.839  loss_seg: 0.9246  loss_ce_0: 0  loss_mask_0: 1.039  loss_dice_0: 2.865  loss_ce_1: 0  loss_mask_1: 1.044  loss_dice_1: 2.824  loss_ce_2: 0  loss_mask_2: 1.048  loss_dice_2: 2.821  loss_ce_3: 0  loss_mask_3: 1.043  loss_dice_3: 2.813  loss_ce_4: 0  loss_mask_4: 1.041  loss_dice_4: 2.813  loss_ce_5: 0  loss_mask_5: 1.046  loss_dice_5: 2.813  loss_ce_6: 0  loss_mask_6: 1.046  loss_dice_6: 2.819  loss_ce_7: 0  loss_mask_7: 1.047  loss_dice_7: 2.817  loss_ce_8: 0  loss_mask_8: 1.054  loss_dice_8: 2.82  time: 2.9152  data_time: 0.0495  lr: 9.2318e-05  max_mem: 5999M
[02/18 03:37:31] d2.utils.events INFO:  eta: 2 days, 10:57:36  iter: 5119  total_loss: 38.93  loss_ce: 0  loss_mask: 1.011  loss_dice: 2.785  loss_seg: 1.045  loss_ce_0: 0  loss_mask_0: 1.018  loss_dice_0: 2.882  loss_ce_1: 0  loss_mask_1: 1.014  loss_dice_1: 2.772  loss_ce_2: 0  loss_mask_2: 1.014  loss_dice_2: 2.762  loss_ce_3: 0  loss_mask_3: 1.014  loss_dice_3: 2.754  loss_ce_4: 0  loss_mask_4: 1.02  loss_dice_4: 2.756  loss_ce_5: 0  loss_mask_5: 1.016  loss_dice_5: 2.771  loss_ce_6: 0  loss_mask_6: 1.02  loss_dice_6: 2.762  loss_ce_7: 0  loss_mask_7: 1.023  loss_dice_7: 2.766  loss_ce_8: 0  loss_mask_8: 1.021  loss_dice_8: 2.764  time: 2.9105  data_time: 0.0483  lr: 9.2288e-05  max_mem: 5999M
[02/18 03:38:05] d2.utils.events INFO:  eta: 2 days, 10:37:32  iter: 5139  total_loss: 39.25  loss_ce: 0  loss_mask: 1.064  loss_dice: 2.735  loss_seg: 1.082  loss_ce_0: 0  loss_mask_0: 1.07  loss_dice_0: 2.785  loss_ce_1: 0  loss_mask_1: 1.076  loss_dice_1: 2.725  loss_ce_2: 0  loss_mask_2: 1.074  loss_dice_2: 2.707  loss_ce_3: 0  loss_mask_3: 1.078  loss_dice_3: 2.703  loss_ce_4: 0  loss_mask_4: 1.077  loss_dice_4: 2.71  loss_ce_5: 0  loss_mask_5: 1.082  loss_dice_5: 2.708  loss_ce_6: 0  loss_mask_6: 1.083  loss_dice_6: 2.707  loss_ce_7: 0  loss_mask_7: 1.074  loss_dice_7: 2.708  loss_ce_8: 0  loss_mask_8: 1.075  loss_dice_8: 2.711  time: 2.9057  data_time: 0.0498  lr: 9.2257e-05  max_mem: 5999M
[02/18 03:38:40] d2.utils.events INFO:  eta: 2 days, 10:16:17  iter: 5159  total_loss: 40.4  loss_ce: 0  loss_mask: 1.071  loss_dice: 2.854  loss_seg: 1.08  loss_ce_0: 0  loss_mask_0: 1.091  loss_dice_0: 2.879  loss_ce_1: 0  loss_mask_1: 1.068  loss_dice_1: 2.836  loss_ce_2: 0  loss_mask_2: 1.06  loss_dice_2: 2.833  loss_ce_3: 0  loss_mask_3: 1.063  loss_dice_3: 2.825  loss_ce_4: 0  loss_mask_4: 1.067  loss_dice_4: 2.826  loss_ce_5: 0  loss_mask_5: 1.067  loss_dice_5: 2.829  loss_ce_6: 0  loss_mask_6: 1.065  loss_dice_6: 2.823  loss_ce_7: 0  loss_mask_7: 1.063  loss_dice_7: 2.833  loss_ce_8: 0  loss_mask_8: 1.071  loss_dice_8: 2.823  time: 2.9012  data_time: 0.0526  lr: 9.2227e-05  max_mem: 5999M
[02/18 03:39:12] d2.utils.events INFO:  eta: 2 days, 9:47:32  iter: 5179  total_loss: 40.07  loss_ce: 0  loss_mask: 1.052  loss_dice: 2.734  loss_seg: 1.044  loss_ce_0: 0  loss_mask_0: 1.039  loss_dice_0: 2.785  loss_ce_1: 0  loss_mask_1: 1.062  loss_dice_1: 2.736  loss_ce_2: 0  loss_mask_2: 1.06  loss_dice_2: 2.72  loss_ce_3: 0  loss_mask_3: 1.057  loss_dice_3: 2.709  loss_ce_4: 0  loss_mask_4: 1.064  loss_dice_4: 2.711  loss_ce_5: 0  loss_mask_5: 1.059  loss_dice_5: 2.709  loss_ce_6: 0  loss_mask_6: 1.062  loss_dice_6: 2.703  loss_ce_7: 0  loss_mask_7: 1.064  loss_dice_7: 2.715  loss_ce_8: 0  loss_mask_8: 1.068  loss_dice_8: 2.714  time: 2.8962  data_time: 0.0352  lr: 9.2197e-05  max_mem: 5999M
[02/18 03:39:43] d2.utils.events INFO:  eta: 2 days, 9:24:20  iter: 5199  total_loss: 40.45  loss_ce: 0  loss_mask: 1.052  loss_dice: 2.828  loss_seg: 0.888  loss_ce_0: 0  loss_mask_0: 1.036  loss_dice_0: 2.863  loss_ce_1: 0  loss_mask_1: 1.052  loss_dice_1: 2.819  loss_ce_2: 0  loss_mask_2: 1.064  loss_dice_2: 2.804  loss_ce_3: 0  loss_mask_3: 1.061  loss_dice_3: 2.797  loss_ce_4: 0  loss_mask_4: 1.064  loss_dice_4: 2.791  loss_ce_5: 0  loss_mask_5: 1.067  loss_dice_5: 2.791  loss_ce_6: 0  loss_mask_6: 1.06  loss_dice_6: 2.797  loss_ce_7: 0  loss_mask_7: 1.067  loss_dice_7: 2.801  loss_ce_8: 0  loss_mask_8: 1.059  loss_dice_8: 2.8  time: 2.8911  data_time: 0.0334  lr: 9.2167e-05  max_mem: 5999M
[02/18 03:40:18] d2.utils.events INFO:  eta: 2 days, 8:53:23  iter: 5219  total_loss: 39.14  loss_ce: 0  loss_mask: 1.03  loss_dice: 2.733  loss_seg: 0.9612  loss_ce_0: 0  loss_mask_0: 1.037  loss_dice_0: 2.806  loss_ce_1: 0  loss_mask_1: 1.036  loss_dice_1: 2.725  loss_ce_2: 0  loss_mask_2: 1.035  loss_dice_2: 2.719  loss_ce_3: 0  loss_mask_3: 1.038  loss_dice_3: 2.712  loss_ce_4: 0  loss_mask_4: 1.035  loss_dice_4: 2.716  loss_ce_5: 0  loss_mask_5: 1.035  loss_dice_5: 2.715  loss_ce_6: 0  loss_mask_6: 1.04  loss_dice_6: 2.714  loss_ce_7: 0  loss_mask_7: 1.04  loss_dice_7: 2.715  loss_ce_8: 0  loss_mask_8: 1.038  loss_dice_8: 2.716  time: 2.8867  data_time: 0.0327  lr: 9.2136e-05  max_mem: 5999M
[02/18 03:40:52] d2.utils.events INFO:  eta: 2 days, 8:23:20  iter: 5239  total_loss: 40.73  loss_ce: 0  loss_mask: 1.077  loss_dice: 2.896  loss_seg: 1.136  loss_ce_0: 0  loss_mask_0: 1.068  loss_dice_0: 2.941  loss_ce_1: 0  loss_mask_1: 1.083  loss_dice_1: 2.87  loss_ce_2: 0  loss_mask_2: 1.084  loss_dice_2: 2.871  loss_ce_3: 0  loss_mask_3: 1.086  loss_dice_3: 2.867  loss_ce_4: 0  loss_mask_4: 1.086  loss_dice_4: 2.869  loss_ce_5: 0  loss_mask_5: 1.084  loss_dice_5: 2.87  loss_ce_6: 0  loss_mask_6: 1.083  loss_dice_6: 2.871  loss_ce_7: 0  loss_mask_7: 1.087  loss_dice_7: 2.873  loss_ce_8: 0  loss_mask_8: 1.09  loss_dice_8: 2.877  time: 2.8820  data_time: 0.0302  lr: 9.2106e-05  max_mem: 5999M
[02/18 03:41:25] d2.utils.events INFO:  eta: 2 days, 7:55:47  iter: 5259  total_loss: 40.36  loss_ce: 0  loss_mask: 1.057  loss_dice: 2.841  loss_seg: 0.9668  loss_ce_0: 0  loss_mask_0: 1.065  loss_dice_0: 2.848  loss_ce_1: 0  loss_mask_1: 1.058  loss_dice_1: 2.836  loss_ce_2: 0  loss_mask_2: 1.069  loss_dice_2: 2.813  loss_ce_3: 0  loss_mask_3: 1.071  loss_dice_3: 2.813  loss_ce_4: 0  loss_mask_4: 1.072  loss_dice_4: 2.807  loss_ce_5: 0  loss_mask_5: 1.07  loss_dice_5: 2.821  loss_ce_6: 0  loss_mask_6: 1.076  loss_dice_6: 2.817  loss_ce_7: 0  loss_mask_7: 1.07  loss_dice_7: 2.824  loss_ce_8: 0  loss_mask_8: 1.064  loss_dice_8: 2.824  time: 2.8773  data_time: 0.0282  lr: 9.2076e-05  max_mem: 5999M
[02/18 03:41:59] d2.utils.events INFO:  eta: 2 days, 7:21:00  iter: 5279  total_loss: 40.94  loss_ce: 0  loss_mask: 1.083  loss_dice: 2.914  loss_seg: 1.008  loss_ce_0: 0  loss_mask_0: 1.082  loss_dice_0: 2.937  loss_ce_1: 0  loss_mask_1: 1.088  loss_dice_1: 2.907  loss_ce_2: 0  loss_mask_2: 1.085  loss_dice_2: 2.902  loss_ce_3: 0  loss_mask_3: 1.088  loss_dice_3: 2.896  loss_ce_4: 0  loss_mask_4: 1.089  loss_dice_4: 2.894  loss_ce_5: 0  loss_mask_5: 1.088  loss_dice_5: 2.898  loss_ce_6: 0  loss_mask_6: 1.085  loss_dice_6: 2.896  loss_ce_7: 0  loss_mask_7: 1.084  loss_dice_7: 2.9  loss_ce_8: 0  loss_mask_8: 1.087  loss_dice_8: 2.898  time: 2.8729  data_time: 0.0323  lr: 9.2045e-05  max_mem: 5999M
[02/18 03:42:29] d2.utils.events INFO:  eta: 2 days, 6:35:38  iter: 5299  total_loss: 40.81  loss_ce: 0  loss_mask: 1.058  loss_dice: 2.95  loss_seg: 1.214  loss_ce_0: 0  loss_mask_0: 1.052  loss_dice_0: 2.985  loss_ce_1: 0  loss_mask_1: 1.058  loss_dice_1: 2.939  loss_ce_2: 0  loss_mask_2: 1.067  loss_dice_2: 2.92  loss_ce_3: 0  loss_mask_3: 1.071  loss_dice_3: 2.911  loss_ce_4: 0  loss_mask_4: 1.077  loss_dice_4: 2.915  loss_ce_5: 0  loss_mask_5: 1.075  loss_dice_5: 2.917  loss_ce_6: 0  loss_mask_6: 1.076  loss_dice_6: 2.916  loss_ce_7: 0  loss_mask_7: 1.076  loss_dice_7: 2.922  loss_ce_8: 0  loss_mask_8: 1.079  loss_dice_8: 2.926  time: 2.8677  data_time: 0.0324  lr: 9.2015e-05  max_mem: 5999M
[02/18 03:43:01] d2.utils.events INFO:  eta: 2 days, 5:41:43  iter: 5319  total_loss: 39.68  loss_ce: 0  loss_mask: 1.096  loss_dice: 2.746  loss_seg: 1.104  loss_ce_0: 0  loss_mask_0: 1.089  loss_dice_0: 2.816  loss_ce_1: 0  loss_mask_1: 1.092  loss_dice_1: 2.752  loss_ce_2: 0  loss_mask_2: 1.096  loss_dice_2: 2.745  loss_ce_3: 0  loss_mask_3: 1.098  loss_dice_3: 2.738  loss_ce_4: 0  loss_mask_4: 1.109  loss_dice_4: 2.741  loss_ce_5: 0  loss_mask_5: 1.108  loss_dice_5: 2.736  loss_ce_6: 0  loss_mask_6: 1.103  loss_dice_6: 2.736  loss_ce_7: 0  loss_mask_7: 1.106  loss_dice_7: 2.741  loss_ce_8: 0  loss_mask_8: 1.107  loss_dice_8: 2.734  time: 2.8630  data_time: 0.0381  lr: 9.1985e-05  max_mem: 5999M
[02/18 03:43:35] d2.utils.events INFO:  eta: 2 days, 5:00:16  iter: 5339  total_loss: 39.54  loss_ce: 0  loss_mask: 1.038  loss_dice: 2.798  loss_seg: 0.932  loss_ce_0: 0  loss_mask_0: 1.034  loss_dice_0: 2.822  loss_ce_1: 0  loss_mask_1: 1.042  loss_dice_1: 2.782  loss_ce_2: 0  loss_mask_2: 1.047  loss_dice_2: 2.783  loss_ce_3: 0  loss_mask_3: 1.045  loss_dice_3: 2.77  loss_ce_4: 0  loss_mask_4: 1.041  loss_dice_4: 2.77  loss_ce_5: 0  loss_mask_5: 1.044  loss_dice_5: 2.772  loss_ce_6: 0  loss_mask_6: 1.043  loss_dice_6: 2.763  loss_ce_7: 0  loss_mask_7: 1.045  loss_dice_7: 2.776  loss_ce_8: 0  loss_mask_8: 1.038  loss_dice_8: 2.782  time: 2.8585  data_time: 0.0306  lr: 9.1955e-05  max_mem: 5999M
[02/18 03:44:07] d2.utils.events INFO:  eta: 2 days, 4:18:20  iter: 5359  total_loss: 40.81  loss_ce: 0  loss_mask: 1.11  loss_dice: 2.879  loss_seg: 0.9266  loss_ce_0: 0  loss_mask_0: 1.105  loss_dice_0: 2.919  loss_ce_1: 0  loss_mask_1: 1.105  loss_dice_1: 2.876  loss_ce_2: 0  loss_mask_2: 1.104  loss_dice_2: 2.87  loss_ce_3: 0  loss_mask_3: 1.101  loss_dice_3: 2.861  loss_ce_4: 0  loss_mask_4: 1.106  loss_dice_4: 2.866  loss_ce_5: 0  loss_mask_5: 1.107  loss_dice_5: 2.872  loss_ce_6: 0  loss_mask_6: 1.11  loss_dice_6: 2.868  loss_ce_7: 0  loss_mask_7: 1.111  loss_dice_7: 2.864  loss_ce_8: 0  loss_mask_8: 1.11  loss_dice_8: 2.859  time: 2.8539  data_time: 0.0245  lr: 9.1924e-05  max_mem: 5999M
[02/18 03:44:40] d2.utils.events INFO:  eta: 2 days, 3:38:21  iter: 5379  total_loss: 40  loss_ce: 0  loss_mask: 1.041  loss_dice: 2.878  loss_seg: 1.763  loss_ce_0: 0  loss_mask_0: 1.031  loss_dice_0: 2.951  loss_ce_1: 0  loss_mask_1: 1.043  loss_dice_1: 2.876  loss_ce_2: 0  loss_mask_2: 1.049  loss_dice_2: 2.862  loss_ce_3: 0  loss_mask_3: 1.049  loss_dice_3: 2.859  loss_ce_4: 0  loss_mask_4: 1.056  loss_dice_4: 2.868  loss_ce_5: 0  loss_mask_5: 1.058  loss_dice_5: 2.868  loss_ce_6: 0  loss_mask_6: 1.06  loss_dice_6: 2.866  loss_ce_7: 0  loss_mask_7: 1.059  loss_dice_7: 2.864  loss_ce_8: 0  loss_mask_8: 1.055  loss_dice_8: 2.869  time: 2.8493  data_time: 0.0283  lr: 9.1894e-05  max_mem: 5999M
[02/18 03:45:13] d2.utils.events INFO:  eta: 2 days, 2:47:01  iter: 5399  total_loss: 38.68  loss_ce: 0  loss_mask: 1.062  loss_dice: 2.753  loss_seg: 0.8515  loss_ce_0: 0  loss_mask_0: 1.073  loss_dice_0: 2.801  loss_ce_1: 0  loss_mask_1: 1.075  loss_dice_1: 2.73  loss_ce_2: 0  loss_mask_2: 1.073  loss_dice_2: 2.723  loss_ce_3: 0  loss_mask_3: 1.072  loss_dice_3: 2.721  loss_ce_4: 0  loss_mask_4: 1.075  loss_dice_4: 2.725  loss_ce_5: 0  loss_mask_5: 1.076  loss_dice_5: 2.728  loss_ce_6: 0  loss_mask_6: 1.075  loss_dice_6: 2.726  loss_ce_7: 0  loss_mask_7: 1.076  loss_dice_7: 2.737  loss_ce_8: 0  loss_mask_8: 1.074  loss_dice_8: 2.742  time: 2.8448  data_time: 0.0281  lr: 9.1864e-05  max_mem: 5999M
[02/18 03:45:45] d2.utils.events INFO:  eta: 2 days, 2:08:41  iter: 5419  total_loss: 38.75  loss_ce: 0  loss_mask: 0.9833  loss_dice: 2.813  loss_seg: 1.008  loss_ce_0: 0  loss_mask_0: 0.9876  loss_dice_0: 2.854  loss_ce_1: 0  loss_mask_1: 0.9956  loss_dice_1: 2.793  loss_ce_2: 0  loss_mask_2: 0.9983  loss_dice_2: 2.785  loss_ce_3: 0  loss_mask_3: 0.9959  loss_dice_3: 2.788  loss_ce_4: 0  loss_mask_4: 0.994  loss_dice_4: 2.781  loss_ce_5: 0  loss_mask_5: 0.9992  loss_dice_5: 2.785  loss_ce_6: 0  loss_mask_6: 0.9938  loss_dice_6: 2.779  loss_ce_7: 0  loss_mask_7: 0.9945  loss_dice_7: 2.789  loss_ce_8: 0  loss_mask_8: 0.9951  loss_dice_8: 2.785  time: 2.8403  data_time: 0.0308  lr: 9.1834e-05  max_mem: 5999M
[02/18 03:46:19] d2.utils.events INFO:  eta: 2 days, 0:32:08  iter: 5439  total_loss: 39.08  loss_ce: 0  loss_mask: 1.04  loss_dice: 2.722  loss_seg: 0.9771  loss_ce_0: 0  loss_mask_0: 1.044  loss_dice_0: 2.796  loss_ce_1: 0  loss_mask_1: 1.038  loss_dice_1: 2.714  loss_ce_2: 0  loss_mask_2: 1.034  loss_dice_2: 2.703  loss_ce_3: 0  loss_mask_3: 1.038  loss_dice_3: 2.701  loss_ce_4: 0  loss_mask_4: 1.038  loss_dice_4: 2.704  loss_ce_5: 0  loss_mask_5: 1.038  loss_dice_5: 2.701  loss_ce_6: 0  loss_mask_6: 1.034  loss_dice_6: 2.706  loss_ce_7: 0  loss_mask_7: 1.04  loss_dice_7: 2.703  loss_ce_8: 0  loss_mask_8: 1.038  loss_dice_8: 2.701  time: 2.8361  data_time: 0.0273  lr: 9.1803e-05  max_mem: 5999M
[02/18 03:46:49] d2.utils.events INFO:  eta: 1 day, 23:23:01  iter: 5459  total_loss: 39.31  loss_ce: 0  loss_mask: 1.033  loss_dice: 2.75  loss_seg: 1.126  loss_ce_0: 0  loss_mask_0: 1.025  loss_dice_0: 2.759  loss_ce_1: 0  loss_mask_1: 1.049  loss_dice_1: 2.726  loss_ce_2: 0  loss_mask_2: 1.055  loss_dice_2: 2.725  loss_ce_3: 0  loss_mask_3: 1.053  loss_dice_3: 2.715  loss_ce_4: 0  loss_mask_4: 1.048  loss_dice_4: 2.72  loss_ce_5: 0  loss_mask_5: 1.043  loss_dice_5: 2.725  loss_ce_6: 0  loss_mask_6: 1.044  loss_dice_6: 2.725  loss_ce_7: 0  loss_mask_7: 1.047  loss_dice_7: 2.729  loss_ce_8: 0  loss_mask_8: 1.046  loss_dice_8: 2.731  time: 2.8312  data_time: 0.0318  lr: 9.1773e-05  max_mem: 5999M
[02/18 03:47:22] d2.utils.events INFO:  eta: 1 day, 21:50:17  iter: 5479  total_loss: 40.46  loss_ce: 0  loss_mask: 1.056  loss_dice: 2.891  loss_seg: 1.043  loss_ce_0: 0  loss_mask_0: 1.085  loss_dice_0: 2.912  loss_ce_1: 0  loss_mask_1: 1.066  loss_dice_1: 2.883  loss_ce_2: 0  loss_mask_2: 1.063  loss_dice_2: 2.88  loss_ce_3: 0  loss_mask_3: 1.064  loss_dice_3: 2.875  loss_ce_4: 0  loss_mask_4: 1.069  loss_dice_4: 2.87  loss_ce_5: 0  loss_mask_5: 1.067  loss_dice_5: 2.875  loss_ce_6: 0  loss_mask_6: 1.062  loss_dice_6: 2.871  loss_ce_7: 0  loss_mask_7: 1.072  loss_dice_7: 2.874  loss_ce_8: 0  loss_mask_8: 1.066  loss_dice_8: 2.871  time: 2.8269  data_time: 0.0322  lr: 9.1743e-05  max_mem: 5999M
[02/18 03:47:55] d2.utils.events INFO:  eta: 1 day, 20:49:04  iter: 5499  total_loss: 39.06  loss_ce: 0  loss_mask: 1.031  loss_dice: 2.732  loss_seg: 0.903  loss_ce_0: 0  loss_mask_0: 1.02  loss_dice_0: 2.765  loss_ce_1: 0  loss_mask_1: 1.029  loss_dice_1: 2.713  loss_ce_2: 0  loss_mask_2: 1.032  loss_dice_2: 2.705  loss_ce_3: 0  loss_mask_3: 1.039  loss_dice_3: 2.7  loss_ce_4: 0  loss_mask_4: 1.043  loss_dice_4: 2.708  loss_ce_5: 0  loss_mask_5: 1.043  loss_dice_5: 2.707  loss_ce_6: 0  loss_mask_6: 1.039  loss_dice_6: 2.709  loss_ce_7: 0  loss_mask_7: 1.038  loss_dice_7: 2.709  loss_ce_8: 0  loss_mask_8: 1.043  loss_dice_8: 2.707  time: 2.8226  data_time: 0.0262  lr: 9.1712e-05  max_mem: 5999M
[02/18 03:48:31] d2.utils.events INFO:  eta: 1 day, 19:23:24  iter: 5519  total_loss: 39.53  loss_ce: 0  loss_mask: 1.051  loss_dice: 2.854  loss_seg: 0.8688  loss_ce_0: 0  loss_mask_0: 1.073  loss_dice_0: 2.917  loss_ce_1: 0  loss_mask_1: 1.067  loss_dice_1: 2.841  loss_ce_2: 0  loss_mask_2: 1.06  loss_dice_2: 2.835  loss_ce_3: 0  loss_mask_3: 1.058  loss_dice_3: 2.839  loss_ce_4: 0  loss_mask_4: 1.059  loss_dice_4: 2.838  loss_ce_5: 0  loss_mask_5: 1.06  loss_dice_5: 2.842  loss_ce_6: 0  loss_mask_6: 1.059  loss_dice_6: 2.84  loss_ce_7: 0  loss_mask_7: 1.061  loss_dice_7: 2.844  loss_ce_8: 0  loss_mask_8: 1.06  loss_dice_8: 2.844  time: 2.8188  data_time: 0.0357  lr: 9.1682e-05  max_mem: 5999M
[02/18 03:49:06] d2.utils.events INFO:  eta: 1 day, 17:25:09  iter: 5539  total_loss: 38.98  loss_ce: 0  loss_mask: 1.033  loss_dice: 2.745  loss_seg: 1.115  loss_ce_0: 0  loss_mask_0: 1.03  loss_dice_0: 2.812  loss_ce_1: 0  loss_mask_1: 1.032  loss_dice_1: 2.74  loss_ce_2: 0  loss_mask_2: 1.038  loss_dice_2: 2.725  loss_ce_3: 0  loss_mask_3: 1.043  loss_dice_3: 2.71  loss_ce_4: 0  loss_mask_4: 1.045  loss_dice_4: 2.714  loss_ce_5: 0  loss_mask_5: 1.043  loss_dice_5: 2.719  loss_ce_6: 0  loss_mask_6: 1.047  loss_dice_6: 2.716  loss_ce_7: 0  loss_mask_7: 1.045  loss_dice_7: 2.712  loss_ce_8: 0  loss_mask_8: 1.044  loss_dice_8: 2.717  time: 2.8150  data_time: 0.0352  lr: 9.1652e-05  max_mem: 5999M
[02/18 03:49:38] d2.utils.events INFO:  eta: 1 day, 15:44:55  iter: 5559  total_loss: 40.34  loss_ce: 0  loss_mask: 1.026  loss_dice: 2.849  loss_seg: 1.194  loss_ce_0: 0  loss_mask_0: 1.032  loss_dice_0: 2.892  loss_ce_1: 0  loss_mask_1: 1.033  loss_dice_1: 2.831  loss_ce_2: 0  loss_mask_2: 1.033  loss_dice_2: 2.817  loss_ce_3: 0  loss_mask_3: 1.037  loss_dice_3: 2.819  loss_ce_4: 0  loss_mask_4: 1.036  loss_dice_4: 2.82  loss_ce_5: 0  loss_mask_5: 1.034  loss_dice_5: 2.821  loss_ce_6: 0  loss_mask_6: 1.039  loss_dice_6: 2.817  loss_ce_7: 0  loss_mask_7: 1.037  loss_dice_7: 2.815  loss_ce_8: 0  loss_mask_8: 1.039  loss_dice_8: 2.823  time: 2.8106  data_time: 0.0271  lr: 9.1621e-05  max_mem: 5999M
[02/18 03:50:11] d2.utils.events INFO:  eta: 1 day, 11:10:34  iter: 5579  total_loss: 39.36  loss_ce: 0  loss_mask: 1.035  loss_dice: 2.809  loss_seg: 1.058  loss_ce_0: 0  loss_mask_0: 1.042  loss_dice_0: 2.836  loss_ce_1: 0  loss_mask_1: 1.041  loss_dice_1: 2.804  loss_ce_2: 0  loss_mask_2: 1.04  loss_dice_2: 2.79  loss_ce_3: 0  loss_mask_3: 1.038  loss_dice_3: 2.777  loss_ce_4: 0  loss_mask_4: 1.041  loss_dice_4: 2.777  loss_ce_5: 0  loss_mask_5: 1.04  loss_dice_5: 2.777  loss_ce_6: 0  loss_mask_6: 1.04  loss_dice_6: 2.769  loss_ce_7: 0  loss_mask_7: 1.04  loss_dice_7: 2.781  loss_ce_8: 0  loss_mask_8: 1.042  loss_dice_8: 2.785  time: 2.8064  data_time: 0.0299  lr: 9.1591e-05  max_mem: 5999M
[02/18 03:50:44] d2.utils.events INFO:  eta: 1 day, 9:15:47  iter: 5599  total_loss: 39.34  loss_ce: 0  loss_mask: 1.069  loss_dice: 2.82  loss_seg: 0.9354  loss_ce_0: 0  loss_mask_0: 1.062  loss_dice_0: 2.841  loss_ce_1: 0  loss_mask_1: 1.07  loss_dice_1: 2.811  loss_ce_2: 0  loss_mask_2: 1.073  loss_dice_2: 2.796  loss_ce_3: 0  loss_mask_3: 1.077  loss_dice_3: 2.794  loss_ce_4: 0  loss_mask_4: 1.074  loss_dice_4: 2.802  loss_ce_5: 0  loss_mask_5: 1.076  loss_dice_5: 2.801  loss_ce_6: 0  loss_mask_6: 1.073  loss_dice_6: 2.796  loss_ce_7: 0  loss_mask_7: 1.072  loss_dice_7: 2.795  loss_ce_8: 0  loss_mask_8: 1.074  loss_dice_8: 2.8  time: 2.8022  data_time: 0.0317  lr: 9.1561e-05  max_mem: 5999M
[02/18 03:51:20] d2.utils.events INFO:  eta: 1 day, 7:55:55  iter: 5619  total_loss: 39.34  loss_ce: 0  loss_mask: 1.051  loss_dice: 2.796  loss_seg: 0.8956  loss_ce_0: 0  loss_mask_0: 1.076  loss_dice_0: 2.84  loss_ce_1: 0  loss_mask_1: 1.063  loss_dice_1: 2.777  loss_ce_2: 0  loss_mask_2: 1.061  loss_dice_2: 2.775  loss_ce_3: 0  loss_mask_3: 1.061  loss_dice_3: 2.771  loss_ce_4: 0  loss_mask_4: 1.062  loss_dice_4: 2.777  loss_ce_5: 0  loss_mask_5: 1.063  loss_dice_5: 2.776  loss_ce_6: 0  loss_mask_6: 1.063  loss_dice_6: 2.779  loss_ce_7: 0  loss_mask_7: 1.062  loss_dice_7: 2.775  loss_ce_8: 0  loss_mask_8: 1.069  loss_dice_8: 2.773  time: 2.7986  data_time: 0.0308  lr: 9.1531e-05  max_mem: 5999M
[02/18 03:51:53] d2.utils.events INFO:  eta: 1 day, 7:07:19  iter: 5639  total_loss: 39.77  loss_ce: 0  loss_mask: 1.079  loss_dice: 2.757  loss_seg: 0.7336  loss_ce_0: 0  loss_mask_0: 1.088  loss_dice_0: 2.798  loss_ce_1: 0  loss_mask_1: 1.074  loss_dice_1: 2.753  loss_ce_2: 0  loss_mask_2: 1.081  loss_dice_2: 2.744  loss_ce_3: 0  loss_mask_3: 1.087  loss_dice_3: 2.742  loss_ce_4: 0  loss_mask_4: 1.085  loss_dice_4: 2.739  loss_ce_5: 0  loss_mask_5: 1.088  loss_dice_5: 2.742  loss_ce_6: 0  loss_mask_6: 1.087  loss_dice_6: 2.743  loss_ce_7: 0  loss_mask_7: 1.09  loss_dice_7: 2.742  loss_ce_8: 0  loss_mask_8: 1.088  loss_dice_8: 2.741  time: 2.7945  data_time: 0.0371  lr: 9.15e-05  max_mem: 5999M
[02/18 03:52:26] d2.utils.events INFO:  eta: 1 day, 6:05:20  iter: 5659  total_loss: 39.51  loss_ce: 0  loss_mask: 1.023  loss_dice: 2.816  loss_seg: 1.249  loss_ce_0: 0  loss_mask_0: 1.031  loss_dice_0: 2.861  loss_ce_1: 0  loss_mask_1: 1.028  loss_dice_1: 2.819  loss_ce_2: 0  loss_mask_2: 1.035  loss_dice_2: 2.814  loss_ce_3: 0  loss_mask_3: 1.038  loss_dice_3: 2.797  loss_ce_4: 0  loss_mask_4: 1.041  loss_dice_4: 2.797  loss_ce_5: 0  loss_mask_5: 1.038  loss_dice_5: 2.804  loss_ce_6: 0  loss_mask_6: 1.042  loss_dice_6: 2.8  loss_ce_7: 0  loss_mask_7: 1.042  loss_dice_7: 2.795  loss_ce_8: 0  loss_mask_8: 1.038  loss_dice_8: 2.792  time: 2.7904  data_time: 0.0305  lr: 9.147e-05  max_mem: 5999M
[02/18 03:53:00] d2.utils.events INFO:  eta: 1 day, 5:38:32  iter: 5679  total_loss: 37.73  loss_ce: 0  loss_mask: 1.033  loss_dice: 2.621  loss_seg: 0.9214  loss_ce_0: 0  loss_mask_0: 1.037  loss_dice_0: 2.671  loss_ce_1: 0  loss_mask_1: 1.037  loss_dice_1: 2.619  loss_ce_2: 0  loss_mask_2: 1.048  loss_dice_2: 2.611  loss_ce_3: 0  loss_mask_3: 1.048  loss_dice_3: 2.599  loss_ce_4: 0  loss_mask_4: 1.043  loss_dice_4: 2.603  loss_ce_5: 0  loss_mask_5: 1.04  loss_dice_5: 2.602  loss_ce_6: 0  loss_mask_6: 1.042  loss_dice_6: 2.6  loss_ce_7: 0  loss_mask_7: 1.041  loss_dice_7: 2.606  loss_ce_8: 0  loss_mask_8: 1.04  loss_dice_8: 2.608  time: 2.7866  data_time: 0.0305  lr: 9.144e-05  max_mem: 5999M
[02/18 03:53:34] d2.utils.events INFO:  eta: 1 day, 5:02:19  iter: 5699  total_loss: 39.11  loss_ce: 0  loss_mask: 1.051  loss_dice: 2.793  loss_seg: 0.9826  loss_ce_0: 0  loss_mask_0: 1.056  loss_dice_0: 2.837  loss_ce_1: 0  loss_mask_1: 1.054  loss_dice_1: 2.773  loss_ce_2: 0  loss_mask_2: 1.055  loss_dice_2: 2.764  loss_ce_3: 0  loss_mask_3: 1.054  loss_dice_3: 2.767  loss_ce_4: 0  loss_mask_4: 1.059  loss_dice_4: 2.768  loss_ce_5: 0  loss_mask_5: 1.057  loss_dice_5: 2.773  loss_ce_6: 0  loss_mask_6: 1.05  loss_dice_6: 2.771  loss_ce_7: 0  loss_mask_7: 1.06  loss_dice_7: 2.774  loss_ce_8: 0  loss_mask_8: 1.063  loss_dice_8: 2.772  time: 2.7828  data_time: 0.0285  lr: 9.1409e-05  max_mem: 5999M
[02/18 03:54:07] d2.utils.events INFO:  eta: 1 day, 4:27:50  iter: 5719  total_loss: 40.16  loss_ce: 0  loss_mask: 1.073  loss_dice: 2.791  loss_seg: 0.8626  loss_ce_0: 0  loss_mask_0: 1.074  loss_dice_0: 2.822  loss_ce_1: 0  loss_mask_1: 1.079  loss_dice_1: 2.783  loss_ce_2: 0  loss_mask_2: 1.075  loss_dice_2: 2.779  loss_ce_3: 0  loss_mask_3: 1.079  loss_dice_3: 2.771  loss_ce_4: 0  loss_mask_4: 1.081  loss_dice_4: 2.769  loss_ce_5: 0  loss_mask_5: 1.085  loss_dice_5: 2.777  loss_ce_6: 0  loss_mask_6: 1.083  loss_dice_6: 2.779  loss_ce_7: 0  loss_mask_7: 1.083  loss_dice_7: 2.771  loss_ce_8: 0  loss_mask_8: 1.079  loss_dice_8: 2.771  time: 2.7788  data_time: 0.0318  lr: 9.1379e-05  max_mem: 5999M
[02/18 03:54:40] d2.utils.events INFO:  eta: 1 day, 4:07:14  iter: 5739  total_loss: 38.98  loss_ce: 0  loss_mask: 1.051  loss_dice: 2.756  loss_seg: 1.008  loss_ce_0: 0  loss_mask_0: 1.046  loss_dice_0: 2.773  loss_ce_1: 0  loss_mask_1: 1.047  loss_dice_1: 2.739  loss_ce_2: 0  loss_mask_2: 1.05  loss_dice_2: 2.737  loss_ce_3: 0  loss_mask_3: 1.057  loss_dice_3: 2.732  loss_ce_4: 0  loss_mask_4: 1.057  loss_dice_4: 2.727  loss_ce_5: 0  loss_mask_5: 1.061  loss_dice_5: 2.729  loss_ce_6: 0  loss_mask_6: 1.056  loss_dice_6: 2.728  loss_ce_7: 0  loss_mask_7: 1.056  loss_dice_7: 2.74  loss_ce_8: 0  loss_mask_8: 1.054  loss_dice_8: 2.733  time: 2.7749  data_time: 0.0396  lr: 9.1349e-05  max_mem: 5999M
[02/18 03:55:14] d2.utils.events INFO:  eta: 1 day, 3:43:45  iter: 5759  total_loss: 40.3  loss_ce: 0  loss_mask: 1.059  loss_dice: 2.836  loss_seg: 0.8913  loss_ce_0: 0  loss_mask_0: 1.056  loss_dice_0: 2.878  loss_ce_1: 0  loss_mask_1: 1.057  loss_dice_1: 2.831  loss_ce_2: 0  loss_mask_2: 1.066  loss_dice_2: 2.823  loss_ce_3: 0  loss_mask_3: 1.067  loss_dice_3: 2.81  loss_ce_4: 0  loss_mask_4: 1.068  loss_dice_4: 2.811  loss_ce_5: 0  loss_mask_5: 1.065  loss_dice_5: 2.824  loss_ce_6: 0  loss_mask_6: 1.061  loss_dice_6: 2.821  loss_ce_7: 0  loss_mask_7: 1.07  loss_dice_7: 2.818  loss_ce_8: 0  loss_mask_8: 1.075  loss_dice_8: 2.824  time: 2.7711  data_time: 0.0370  lr: 9.1319e-05  max_mem: 5999M
[02/18 03:55:48] d2.utils.events INFO:  eta: 1 day, 3:20:53  iter: 5779  total_loss: 40.96  loss_ce: 0  loss_mask: 1.096  loss_dice: 2.877  loss_seg: 0.9121  loss_ce_0: 0  loss_mask_0: 1.125  loss_dice_0: 2.898  loss_ce_1: 0  loss_mask_1: 1.095  loss_dice_1: 2.865  loss_ce_2: 0  loss_mask_2: 1.095  loss_dice_2: 2.86  loss_ce_3: 0  loss_mask_3: 1.097  loss_dice_3: 2.848  loss_ce_4: 0  loss_mask_4: 1.097  loss_dice_4: 2.849  loss_ce_5: 0  loss_mask_5: 1.103  loss_dice_5: 2.855  loss_ce_6: 0  loss_mask_6: 1.105  loss_dice_6: 2.844  loss_ce_7: 0  loss_mask_7: 1.102  loss_dice_7: 2.854  loss_ce_8: 0  loss_mask_8: 1.103  loss_dice_8: 2.86  time: 2.7673  data_time: 0.0310  lr: 9.1288e-05  max_mem: 5999M
[02/18 03:56:21] d2.utils.events INFO:  eta: 1 day, 3:08:43  iter: 5799  total_loss: 38.63  loss_ce: 0  loss_mask: 1.051  loss_dice: 2.7  loss_seg: 0.6769  loss_ce_0: 0  loss_mask_0: 1.051  loss_dice_0: 2.732  loss_ce_1: 0  loss_mask_1: 1.069  loss_dice_1: 2.684  loss_ce_2: 0  loss_mask_2: 1.065  loss_dice_2: 2.674  loss_ce_3: 0  loss_mask_3: 1.064  loss_dice_3: 2.667  loss_ce_4: 0  loss_mask_4: 1.069  loss_dice_4: 2.672  loss_ce_5: 0  loss_mask_5: 1.073  loss_dice_5: 2.672  loss_ce_6: 0  loss_mask_6: 1.067  loss_dice_6: 2.67  loss_ce_7: 0  loss_mask_7: 1.069  loss_dice_7: 2.677  loss_ce_8: 0  loss_mask_8: 1.07  loss_dice_8: 2.668  time: 2.7636  data_time: 0.0272  lr: 9.1258e-05  max_mem: 5999M
[02/18 03:56:54] d2.utils.events INFO:  eta: 1 day, 2:52:13  iter: 5819  total_loss: 39.92  loss_ce: 0  loss_mask: 1.068  loss_dice: 2.8  loss_seg: 1.062  loss_ce_0: 0  loss_mask_0: 1.079  loss_dice_0: 2.824  loss_ce_1: 0  loss_mask_1: 1.075  loss_dice_1: 2.79  loss_ce_2: 0  loss_mask_2: 1.075  loss_dice_2: 2.784  loss_ce_3: 0  loss_mask_3: 1.076  loss_dice_3: 2.782  loss_ce_4: 0  loss_mask_4: 1.08  loss_dice_4: 2.788  loss_ce_5: 0  loss_mask_5: 1.079  loss_dice_5: 2.785  loss_ce_6: 0  loss_mask_6: 1.073  loss_dice_6: 2.791  loss_ce_7: 0  loss_mask_7: 1.073  loss_dice_7: 2.786  loss_ce_8: 0  loss_mask_8: 1.074  loss_dice_8: 2.785  time: 2.7597  data_time: 0.0305  lr: 9.1228e-05  max_mem: 5999M
[02/18 03:57:26] d2.utils.events INFO:  eta: 1 day, 2:27:07  iter: 5839  total_loss: 38.68  loss_ce: 0  loss_mask: 1.072  loss_dice: 2.757  loss_seg: 0.8631  loss_ce_0: 0  loss_mask_0: 1.079  loss_dice_0: 2.805  loss_ce_1: 0  loss_mask_1: 1.077  loss_dice_1: 2.746  loss_ce_2: 0  loss_mask_2: 1.073  loss_dice_2: 2.74  loss_ce_3: 0  loss_mask_3: 1.082  loss_dice_3: 2.731  loss_ce_4: 0  loss_mask_4: 1.082  loss_dice_4: 2.736  loss_ce_5: 0  loss_mask_5: 1.082  loss_dice_5: 2.737  loss_ce_6: 0  loss_mask_6: 1.081  loss_dice_6: 2.725  loss_ce_7: 0  loss_mask_7: 1.079  loss_dice_7: 2.732  loss_ce_8: 0  loss_mask_8: 1.08  loss_dice_8: 2.731  time: 2.7558  data_time: 0.0361  lr: 9.1197e-05  max_mem: 5999M
[02/18 03:57:58] d2.utils.events INFO:  eta: 1 day, 2:04:13  iter: 5859  total_loss: 39.97  loss_ce: 0  loss_mask: 1.117  loss_dice: 2.801  loss_seg: 1.001  loss_ce_0: 0  loss_mask_0: 1.114  loss_dice_0: 2.844  loss_ce_1: 0  loss_mask_1: 1.107  loss_dice_1: 2.807  loss_ce_2: 0  loss_mask_2: 1.112  loss_dice_2: 2.79  loss_ce_3: 0  loss_mask_3: 1.116  loss_dice_3: 2.779  loss_ce_4: 0  loss_mask_4: 1.117  loss_dice_4: 2.79  loss_ce_5: 0  loss_mask_5: 1.12  loss_dice_5: 2.791  loss_ce_6: 0  loss_mask_6: 1.119  loss_dice_6: 2.787  loss_ce_7: 0  loss_mask_7: 1.126  loss_dice_7: 2.793  loss_ce_8: 0  loss_mask_8: 1.118  loss_dice_8: 2.788  time: 2.7517  data_time: 0.0297  lr: 9.1167e-05  max_mem: 5999M
[02/18 03:58:30] d2.utils.events INFO:  eta: 1 day, 1:47:41  iter: 5879  total_loss: 38.52  loss_ce: 0  loss_mask: 1.039  loss_dice: 2.707  loss_seg: 0.8314  loss_ce_0: 0  loss_mask_0: 1.058  loss_dice_0: 2.746  loss_ce_1: 0  loss_mask_1: 1.049  loss_dice_1: 2.685  loss_ce_2: 0  loss_mask_2: 1.04  loss_dice_2: 2.678  loss_ce_3: 0  loss_mask_3: 1.048  loss_dice_3: 2.67  loss_ce_4: 0  loss_mask_4: 1.046  loss_dice_4: 2.676  loss_ce_5: 0  loss_mask_5: 1.044  loss_dice_5: 2.68  loss_ce_6: 0  loss_mask_6: 1.047  loss_dice_6: 2.673  loss_ce_7: 0  loss_mask_7: 1.049  loss_dice_7: 2.675  loss_ce_8: 0  loss_mask_8: 1.046  loss_dice_8: 2.675  time: 2.7479  data_time: 0.0291  lr: 9.1137e-05  max_mem: 5999M
[02/18 03:59:04] d2.utils.events INFO:  eta: 1 day, 1:40:41  iter: 5899  total_loss: 37.38  loss_ce: 0  loss_mask: 0.9624  loss_dice: 2.642  loss_seg: 1.088  loss_ce_0: 0  loss_mask_0: 0.9573  loss_dice_0: 2.672  loss_ce_1: 0  loss_mask_1: 0.9698  loss_dice_1: 2.623  loss_ce_2: 0  loss_mask_2: 0.9696  loss_dice_2: 2.618  loss_ce_3: 0  loss_mask_3: 0.9733  loss_dice_3: 2.61  loss_ce_4: 0  loss_mask_4: 0.9702  loss_dice_4: 2.617  loss_ce_5: 0  loss_mask_5: 0.9711  loss_dice_5: 2.616  loss_ce_6: 0  loss_mask_6: 0.9743  loss_dice_6: 2.612  loss_ce_7: 0  loss_mask_7: 0.9717  loss_dice_7: 2.617  loss_ce_8: 0  loss_mask_8: 0.9712  loss_dice_8: 2.622  time: 2.7442  data_time: 0.0332  lr: 9.1106e-05  max_mem: 5999M
[02/18 03:59:36] d2.utils.events INFO:  eta: 1 day, 1:29:55  iter: 5919  total_loss: 38.46  loss_ce: 0  loss_mask: 1.012  loss_dice: 2.656  loss_seg: 0.8129  loss_ce_0: 0  loss_mask_0: 1.047  loss_dice_0: 2.705  loss_ce_1: 0  loss_mask_1: 1.031  loss_dice_1: 2.658  loss_ce_2: 0  loss_mask_2: 1.024  loss_dice_2: 2.643  loss_ce_3: 0  loss_mask_3: 1.021  loss_dice_3: 2.631  loss_ce_4: 0  loss_mask_4: 1.025  loss_dice_4: 2.641  loss_ce_5: 0  loss_mask_5: 1.03  loss_dice_5: 2.633  loss_ce_6: 0  loss_mask_6: 1.026  loss_dice_6: 2.641  loss_ce_7: 0  loss_mask_7: 1.024  loss_dice_7: 2.639  loss_ce_8: 0  loss_mask_8: 1.022  loss_dice_8: 2.639  time: 2.7404  data_time: 0.0288  lr: 9.1076e-05  max_mem: 5999M
[02/18 04:00:10] d2.utils.events INFO:  eta: 1 day, 1:19:40  iter: 5939  total_loss: 38.92  loss_ce: 0  loss_mask: 1.05  loss_dice: 2.791  loss_seg: 0.9437  loss_ce_0: 0  loss_mask_0: 1.055  loss_dice_0: 2.835  loss_ce_1: 0  loss_mask_1: 1.055  loss_dice_1: 2.775  loss_ce_2: 0  loss_mask_2: 1.061  loss_dice_2: 2.768  loss_ce_3: 0  loss_mask_3: 1.062  loss_dice_3: 2.763  loss_ce_4: 0  loss_mask_4: 1.063  loss_dice_4: 2.768  loss_ce_5: 0  loss_mask_5: 1.062  loss_dice_5: 2.769  loss_ce_6: 0  loss_mask_6: 1.063  loss_dice_6: 2.771  loss_ce_7: 0  loss_mask_7: 1.064  loss_dice_7: 2.769  loss_ce_8: 0  loss_mask_8: 1.067  loss_dice_8: 2.775  time: 2.7368  data_time: 0.0275  lr: 9.1046e-05  max_mem: 5999M
[02/18 04:00:43] d2.utils.events INFO:  eta: 1 day, 1:10:52  iter: 5959  total_loss: 39.62  loss_ce: 0  loss_mask: 1.044  loss_dice: 2.743  loss_seg: 1.016  loss_ce_0: 0  loss_mask_0: 1.025  loss_dice_0: 2.836  loss_ce_1: 0  loss_mask_1: 1.041  loss_dice_1: 2.742  loss_ce_2: 0  loss_mask_2: 1.046  loss_dice_2: 2.726  loss_ce_3: 0  loss_mask_3: 1.055  loss_dice_3: 2.72  loss_ce_4: 0  loss_mask_4: 1.058  loss_dice_4: 2.723  loss_ce_5: 0  loss_mask_5: 1.056  loss_dice_5: 2.727  loss_ce_6: 0  loss_mask_6: 1.047  loss_dice_6: 2.731  loss_ce_7: 0  loss_mask_7: 1.047  loss_dice_7: 2.73  loss_ce_8: 0  loss_mask_8: 1.051  loss_dice_8: 2.728  time: 2.7333  data_time: 0.0353  lr: 9.1015e-05  max_mem: 5999M
[02/18 04:01:16] d2.utils.events INFO:  eta: 1 day, 0:57:26  iter: 5979  total_loss: 41.01  loss_ce: 0  loss_mask: 1.089  loss_dice: 2.85  loss_seg: 0.9392  loss_ce_0: 0  loss_mask_0: 1.102  loss_dice_0: 2.857  loss_ce_1: 0  loss_mask_1: 1.093  loss_dice_1: 2.854  loss_ce_2: 0  loss_mask_2: 1.09  loss_dice_2: 2.849  loss_ce_3: 0  loss_mask_3: 1.101  loss_dice_3: 2.841  loss_ce_4: 0  loss_mask_4: 1.107  loss_dice_4: 2.84  loss_ce_5: 0  loss_mask_5: 1.102  loss_dice_5: 2.842  loss_ce_6: 0  loss_mask_6: 1.103  loss_dice_6: 2.838  loss_ce_7: 0  loss_mask_7: 1.102  loss_dice_7: 2.842  loss_ce_8: 0  loss_mask_8: 1.098  loss_dice_8: 2.842  time: 2.7296  data_time: 0.0323  lr: 9.0985e-05  max_mem: 5999M
[02/18 04:01:51] d2.utils.events INFO:  eta: 1 day, 0:51:57  iter: 5999  total_loss: 38.88  loss_ce: 0  loss_mask: 1.041  loss_dice: 2.727  loss_seg: 1.037  loss_ce_0: 0  loss_mask_0: 1.039  loss_dice_0: 2.774  loss_ce_1: 0  loss_mask_1: 1.047  loss_dice_1: 2.718  loss_ce_2: 0  loss_mask_2: 1.051  loss_dice_2: 2.704  loss_ce_3: 0  loss_mask_3: 1.051  loss_dice_3: 2.698  loss_ce_4: 0  loss_mask_4: 1.047  loss_dice_4: 2.706  loss_ce_5: 0  loss_mask_5: 1.053  loss_dice_5: 2.707  loss_ce_6: 0  loss_mask_6: 1.051  loss_dice_6: 2.704  loss_ce_7: 0  loss_mask_7: 1.053  loss_dice_7: 2.707  loss_ce_8: 0  loss_mask_8: 1.054  loss_dice_8: 2.694  time: 2.7263  data_time: 0.0262  lr: 9.0955e-05  max_mem: 5999M
[02/18 04:02:25] d2.utils.events INFO:  eta: 1 day, 0:47:31  iter: 6019  total_loss: 40.38  loss_ce: 0  loss_mask: 1.064  loss_dice: 2.837  loss_seg: 1.298  loss_ce_0: 0  loss_mask_0: 1.066  loss_dice_0: 2.881  loss_ce_1: 0  loss_mask_1: 1.074  loss_dice_1: 2.817  loss_ce_2: 0  loss_mask_2: 1.07  loss_dice_2: 2.806  loss_ce_3: 0  loss_mask_3: 1.069  loss_dice_3: 2.81  loss_ce_4: 0  loss_mask_4: 1.072  loss_dice_4: 2.811  loss_ce_5: 0  loss_mask_5: 1.072  loss_dice_5: 2.813  loss_ce_6: 0  loss_mask_6: 1.076  loss_dice_6: 2.816  loss_ce_7: 0  loss_mask_7: 1.075  loss_dice_7: 2.814  loss_ce_8: 0  loss_mask_8: 1.076  loss_dice_8: 2.815  time: 2.7227  data_time: 0.0283  lr: 9.0924e-05  max_mem: 5999M
[02/18 04:03:00] d2.utils.events INFO:  eta: 1 day, 0:43:09  iter: 6039  total_loss: 39.46  loss_ce: 0  loss_mask: 1.029  loss_dice: 2.784  loss_seg: 1.051  loss_ce_0: 0  loss_mask_0: 1.041  loss_dice_0: 2.835  loss_ce_1: 0  loss_mask_1: 1.029  loss_dice_1: 2.785  loss_ce_2: 0  loss_mask_2: 1.032  loss_dice_2: 2.782  loss_ce_3: 0  loss_mask_3: 1.032  loss_dice_3: 2.759  loss_ce_4: 0  loss_mask_4: 1.033  loss_dice_4: 2.759  loss_ce_5: 0  loss_mask_5: 1.033  loss_dice_5: 2.761  loss_ce_6: 0  loss_mask_6: 1.032  loss_dice_6: 2.756  loss_ce_7: 0  loss_mask_7: 1.037  loss_dice_7: 2.757  loss_ce_8: 0  loss_mask_8: 1.036  loss_dice_8: 2.762  time: 2.7196  data_time: 0.0323  lr: 9.0894e-05  max_mem: 5999M
[02/18 04:03:33] d2.utils.events INFO:  eta: 1 day, 0:30:27  iter: 6059  total_loss: 39.16  loss_ce: 0  loss_mask: 1.002  loss_dice: 2.79  loss_seg: 1.022  loss_ce_0: 0  loss_mask_0: 1.013  loss_dice_0: 2.847  loss_ce_1: 0  loss_mask_1: 1.001  loss_dice_1: 2.778  loss_ce_2: 0  loss_mask_2: 1.001  loss_dice_2: 2.765  loss_ce_3: 0  loss_mask_3: 1.004  loss_dice_3: 2.762  loss_ce_4: 0  loss_mask_4: 1.006  loss_dice_4: 2.766  loss_ce_5: 0  loss_mask_5: 1.006  loss_dice_5: 2.774  loss_ce_6: 0  loss_mask_6: 1.009  loss_dice_6: 2.77  loss_ce_7: 0  loss_mask_7: 1.013  loss_dice_7: 2.771  loss_ce_8: 0  loss_mask_8: 1.004  loss_dice_8: 2.759  time: 2.7160  data_time: 0.0295  lr: 9.0864e-05  max_mem: 5999M
[02/18 04:04:07] d2.utils.events INFO:  eta: 1 day, 0:26:08  iter: 6079  total_loss: 40.69  loss_ce: 0  loss_mask: 1.07  loss_dice: 2.855  loss_seg: 0.8222  loss_ce_0: 0  loss_mask_0: 1.075  loss_dice_0: 2.89  loss_ce_1: 0  loss_mask_1: 1.079  loss_dice_1: 2.843  loss_ce_2: 0  loss_mask_2: 1.068  loss_dice_2: 2.835  loss_ce_3: 0  loss_mask_3: 1.07  loss_dice_3: 2.837  loss_ce_4: 0  loss_mask_4: 1.073  loss_dice_4: 2.84  loss_ce_5: 0  loss_mask_5: 1.073  loss_dice_5: 2.834  loss_ce_6: 0  loss_mask_6: 1.076  loss_dice_6: 2.837  loss_ce_7: 0  loss_mask_7: 1.079  loss_dice_7: 2.834  loss_ce_8: 0  loss_mask_8: 1.071  loss_dice_8: 2.838  time: 2.7127  data_time: 0.0337  lr: 9.0833e-05  max_mem: 5999M
[02/18 04:04:39] d2.utils.events INFO:  eta: 1 day, 0:19:14  iter: 6099  total_loss: 39  loss_ce: 0  loss_mask: 1.009  loss_dice: 2.741  loss_seg: 1.145  loss_ce_0: 0  loss_mask_0: 0.9985  loss_dice_0: 2.811  loss_ce_1: 0  loss_mask_1: 1.027  loss_dice_1: 2.718  loss_ce_2: 0  loss_mask_2: 1.024  loss_dice_2: 2.708  loss_ce_3: 0  loss_mask_3: 1.024  loss_dice_3: 2.703  loss_ce_4: 0  loss_mask_4: 1.016  loss_dice_4: 2.709  loss_ce_5: 0  loss_mask_5: 1.016  loss_dice_5: 2.712  loss_ce_6: 0  loss_mask_6: 1.015  loss_dice_6: 2.715  loss_ce_7: 0  loss_mask_7: 1.017  loss_dice_7: 2.712  loss_ce_8: 0  loss_mask_8: 1.02  loss_dice_8: 2.71  time: 2.7090  data_time: 0.0290  lr: 9.0803e-05  max_mem: 5999M
[02/18 04:05:11] d2.utils.events INFO:  eta: 1 day, 0:16:20  iter: 6119  total_loss: 37.7  loss_ce: 0  loss_mask: 1.049  loss_dice: 2.634  loss_seg: 0.8228  loss_ce_0: 0  loss_mask_0: 1.077  loss_dice_0: 2.675  loss_ce_1: 0  loss_mask_1: 1.051  loss_dice_1: 2.603  loss_ce_2: 0  loss_mask_2: 1.053  loss_dice_2: 2.603  loss_ce_3: 0  loss_mask_3: 1.045  loss_dice_3: 2.596  loss_ce_4: 0  loss_mask_4: 1.052  loss_dice_4: 2.598  loss_ce_5: 0  loss_mask_5: 1.051  loss_dice_5: 2.603  loss_ce_6: 0  loss_mask_6: 1.05  loss_dice_6: 2.602  loss_ce_7: 0  loss_mask_7: 1.053  loss_dice_7: 2.609  loss_ce_8: 0  loss_mask_8: 1.05  loss_dice_8: 2.612  time: 2.7054  data_time: 0.0327  lr: 9.0773e-05  max_mem: 5999M
[02/18 04:05:43] d2.utils.events INFO:  eta: 1 day, 0:13:29  iter: 6139  total_loss: 38.05  loss_ce: 0  loss_mask: 1.012  loss_dice: 2.679  loss_seg: 0.9506  loss_ce_0: 0  loss_mask_0: 1.017  loss_dice_0: 2.744  loss_ce_1: 0  loss_mask_1: 1.013  loss_dice_1: 2.672  loss_ce_2: 0  loss_mask_2: 1.01  loss_dice_2: 2.662  loss_ce_3: 0  loss_mask_3: 1.012  loss_dice_3: 2.661  loss_ce_4: 0  loss_mask_4: 1.016  loss_dice_4: 2.654  loss_ce_5: 0  loss_mask_5: 1.016  loss_dice_5: 2.662  loss_ce_6: 0  loss_mask_6: 1.019  loss_dice_6: 2.657  loss_ce_7: 0  loss_mask_7: 1.016  loss_dice_7: 2.661  loss_ce_8: 0  loss_mask_8: 1.016  loss_dice_8: 2.659  time: 2.7017  data_time: 0.0298  lr: 9.0743e-05  max_mem: 5999M
[02/18 04:06:16] d2.utils.events INFO:  eta: 1 day, 0:12:18  iter: 6159  total_loss: 37.71  loss_ce: 0  loss_mask: 1.047  loss_dice: 2.723  loss_seg: 0.807  loss_ce_0: 0  loss_mask_0: 1.054  loss_dice_0: 2.721  loss_ce_1: 0  loss_mask_1: 1.053  loss_dice_1: 2.698  loss_ce_2: 0  loss_mask_2: 1.052  loss_dice_2: 2.695  loss_ce_3: 0  loss_mask_3: 1.056  loss_dice_3: 2.694  loss_ce_4: 0  loss_mask_4: 1.06  loss_dice_4: 2.687  loss_ce_5: 0  loss_mask_5: 1.058  loss_dice_5: 2.691  loss_ce_6: 0  loss_mask_6: 1.053  loss_dice_6: 2.7  loss_ce_7: 0  loss_mask_7: 1.053  loss_dice_7: 2.698  loss_ce_8: 0  loss_mask_8: 1.052  loss_dice_8: 2.703  time: 2.6983  data_time: 0.0307  lr: 9.0712e-05  max_mem: 5999M
[02/18 04:06:50] d2.utils.events INFO:  eta: 1 day, 0:14:43  iter: 6179  total_loss: 37.17  loss_ce: 0  loss_mask: 0.9863  loss_dice: 2.639  loss_seg: 0.8085  loss_ce_0: 0  loss_mask_0: 0.9887  loss_dice_0: 2.718  loss_ce_1: 0  loss_mask_1: 0.9947  loss_dice_1: 2.629  loss_ce_2: 0  loss_mask_2: 0.9975  loss_dice_2: 2.621  loss_ce_3: 0  loss_mask_3: 0.9977  loss_dice_3: 2.617  loss_ce_4: 0  loss_mask_4: 1.001  loss_dice_4: 2.615  loss_ce_5: 0  loss_mask_5: 1.001  loss_dice_5: 2.615  loss_ce_6: 0  loss_mask_6: 0.9936  loss_dice_6: 2.616  loss_ce_7: 0  loss_mask_7: 0.9971  loss_dice_7: 2.618  loss_ce_8: 0  loss_mask_8: 0.9933  loss_dice_8: 2.62  time: 2.6951  data_time: 0.0300  lr: 9.0682e-05  max_mem: 5999M
[02/18 04:07:21] d2.utils.events INFO:  eta: 1 day, 0:12:08  iter: 6199  total_loss: 39.55  loss_ce: 0  loss_mask: 1.077  loss_dice: 2.8  loss_seg: 0.8772  loss_ce_0: 0  loss_mask_0: 1.083  loss_dice_0: 2.81  loss_ce_1: 0  loss_mask_1: 1.076  loss_dice_1: 2.788  loss_ce_2: 0  loss_mask_2: 1.077  loss_dice_2: 2.786  loss_ce_3: 0  loss_mask_3: 1.075  loss_dice_3: 2.779  loss_ce_4: 0  loss_mask_4: 1.077  loss_dice_4: 2.791  loss_ce_5: 0  loss_mask_5: 1.07  loss_dice_5: 2.79  loss_ce_6: 0  loss_mask_6: 1.076  loss_dice_6: 2.785  loss_ce_7: 0  loss_mask_7: 1.078  loss_dice_7: 2.786  loss_ce_8: 0  loss_mask_8: 1.078  loss_dice_8: 2.789  time: 2.6914  data_time: 0.0326  lr: 9.0652e-05  max_mem: 5999M
[02/18 04:07:54] d2.utils.events INFO:  eta: 1 day, 0:06:56  iter: 6219  total_loss: 37.92  loss_ce: 0  loss_mask: 0.9837  loss_dice: 2.685  loss_seg: 0.9444  loss_ce_0: 0  loss_mask_0: 0.971  loss_dice_0: 2.769  loss_ce_1: 0  loss_mask_1: 0.993  loss_dice_1: 2.675  loss_ce_2: 0  loss_mask_2: 0.9958  loss_dice_2: 2.66  loss_ce_3: 0  loss_mask_3: 0.9946  loss_dice_3: 2.65  loss_ce_4: 0  loss_mask_4: 0.9945  loss_dice_4: 2.661  loss_ce_5: 0  loss_mask_5: 0.9974  loss_dice_5: 2.66  loss_ce_6: 0  loss_mask_6: 0.998  loss_dice_6: 2.657  loss_ce_7: 0  loss_mask_7: 0.9889  loss_dice_7: 2.659  loss_ce_8: 0  loss_mask_8: 0.9906  loss_dice_8: 2.663  time: 2.6881  data_time: 0.0302  lr: 9.0621e-05  max_mem: 5999M
[02/18 04:08:28] d2.utils.events INFO:  eta: 1 day, 0:06:23  iter: 6239  total_loss: 38.2  loss_ce: 0  loss_mask: 1.08  loss_dice: 2.625  loss_seg: 0.8634  loss_ce_0: 0  loss_mask_0: 1.07  loss_dice_0: 2.7  loss_ce_1: 0  loss_mask_1: 1.08  loss_dice_1: 2.614  loss_ce_2: 0  loss_mask_2: 1.087  loss_dice_2: 2.603  loss_ce_3: 0  loss_mask_3: 1.097  loss_dice_3: 2.591  loss_ce_4: 0  loss_mask_4: 1.093  loss_dice_4: 2.601  loss_ce_5: 0  loss_mask_5: 1.101  loss_dice_5: 2.606  loss_ce_6: 0  loss_mask_6: 1.097  loss_dice_6: 2.609  loss_ce_7: 0  loss_mask_7: 1.106  loss_dice_7: 2.598  loss_ce_8: 0  loss_mask_8: 1.101  loss_dice_8: 2.607  time: 2.6849  data_time: 0.0295  lr: 9.0591e-05  max_mem: 5999M
[02/18 04:09:03] d2.utils.events INFO:  eta: 1 day, 0:11:11  iter: 6259  total_loss: 39.18  loss_ce: 0  loss_mask: 1.013  loss_dice: 2.752  loss_seg: 1.016  loss_ce_0: 0  loss_mask_0: 1.038  loss_dice_0: 2.807  loss_ce_1: 0  loss_mask_1: 1.026  loss_dice_1: 2.74  loss_ce_2: 0  loss_mask_2: 1.023  loss_dice_2: 2.74  loss_ce_3: 0  loss_mask_3: 1.026  loss_dice_3: 2.737  loss_ce_4: 0  loss_mask_4: 1.029  loss_dice_4: 2.741  loss_ce_5: 0  loss_mask_5: 1.035  loss_dice_5: 2.741  loss_ce_6: 0  loss_mask_6: 1.031  loss_dice_6: 2.737  loss_ce_7: 0  loss_mask_7: 1.028  loss_dice_7: 2.743  loss_ce_8: 0  loss_mask_8: 1.025  loss_dice_8: 2.745  time: 2.6818  data_time: 0.0278  lr: 9.0561e-05  max_mem: 5999M
[02/18 04:09:36] d2.utils.events INFO:  eta: 1 day, 0:05:19  iter: 6279  total_loss: 37.97  loss_ce: 0  loss_mask: 1.007  loss_dice: 2.633  loss_seg: 0.745  loss_ce_0: 0  loss_mask_0: 1.018  loss_dice_0: 2.68  loss_ce_1: 0  loss_mask_1: 1.013  loss_dice_1: 2.619  loss_ce_2: 0  loss_mask_2: 1.014  loss_dice_2: 2.617  loss_ce_3: 0  loss_mask_3: 1.02  loss_dice_3: 2.613  loss_ce_4: 0  loss_mask_4: 1.015  loss_dice_4: 2.61  loss_ce_5: 0  loss_mask_5: 1.014  loss_dice_5: 2.618  loss_ce_6: 0  loss_mask_6: 1.016  loss_dice_6: 2.622  loss_ce_7: 0  loss_mask_7: 1.016  loss_dice_7: 2.616  loss_ce_8: 0  loss_mask_8: 1.009  loss_dice_8: 2.62  time: 2.6786  data_time: 0.0299  lr: 9.053e-05  max_mem: 5999M
[02/18 04:10:08] d2.utils.events INFO:  eta: 1 day, 0:08:48  iter: 6299  total_loss: 38.2  loss_ce: 0  loss_mask: 0.9991  loss_dice: 2.702  loss_seg: 1.028  loss_ce_0: 0  loss_mask_0: 1.017  loss_dice_0: 2.747  loss_ce_1: 0  loss_mask_1: 1.003  loss_dice_1: 2.701  loss_ce_2: 0  loss_mask_2: 1.002  loss_dice_2: 2.681  loss_ce_3: 0  loss_mask_3: 1  loss_dice_3: 2.673  loss_ce_4: 0  loss_mask_4: 1.008  loss_dice_4: 2.675  loss_ce_5: 0  loss_mask_5: 1.005  loss_dice_5: 2.677  loss_ce_6: 0  loss_mask_6: 1.004  loss_dice_6: 2.673  loss_ce_7: 0  loss_mask_7: 1.001  loss_dice_7: 2.678  loss_ce_8: 0  loss_mask_8: 0.9979  loss_dice_8: 2.678  time: 2.6750  data_time: 0.0308  lr: 9.05e-05  max_mem: 5999M
[02/18 04:10:40] d2.utils.events INFO:  eta: 1 day, 0:06:04  iter: 6319  total_loss: 38.45  loss_ce: 0  loss_mask: 1.016  loss_dice: 2.74  loss_seg: 0.8142  loss_ce_0: 0  loss_mask_0: 1.021  loss_dice_0: 2.813  loss_ce_1: 0  loss_mask_1: 1.017  loss_dice_1: 2.728  loss_ce_2: 0  loss_mask_2: 1.015  loss_dice_2: 2.715  loss_ce_3: 0  loss_mask_3: 1.019  loss_dice_3: 2.709  loss_ce_4: 0  loss_mask_4: 1.02  loss_dice_4: 2.712  loss_ce_5: 0  loss_mask_5: 1.024  loss_dice_5: 2.716  loss_ce_6: 0  loss_mask_6: 1.024  loss_dice_6: 2.708  loss_ce_7: 0  loss_mask_7: 1.029  loss_dice_7: 2.714  loss_ce_8: 0  loss_mask_8: 1.02  loss_dice_8: 2.715  time: 2.6717  data_time: 0.0237  lr: 9.047e-05  max_mem: 5999M
[02/18 04:11:15] d2.utils.events INFO:  eta: 1 day, 0:04:04  iter: 6339  total_loss: 37.92  loss_ce: 0  loss_mask: 1.024  loss_dice: 2.667  loss_seg: 0.9486  loss_ce_0: 0  loss_mask_0: 1.023  loss_dice_0: 2.694  loss_ce_1: 0  loss_mask_1: 1.018  loss_dice_1: 2.658  loss_ce_2: 0  loss_mask_2: 1.023  loss_dice_2: 2.645  loss_ce_3: 0  loss_mask_3: 1.027  loss_dice_3: 2.641  loss_ce_4: 0  loss_mask_4: 1.029  loss_dice_4: 2.642  loss_ce_5: 0  loss_mask_5: 1.026  loss_dice_5: 2.646  loss_ce_6: 0  loss_mask_6: 1.032  loss_dice_6: 2.644  loss_ce_7: 0  loss_mask_7: 1.029  loss_dice_7: 2.648  loss_ce_8: 0  loss_mask_8: 1.029  loss_dice_8: 2.648  time: 2.6688  data_time: 0.0305  lr: 9.0439e-05  max_mem: 5999M
[02/18 04:11:49] d2.utils.events INFO:  eta: 1 day, 0:09:51  iter: 6359  total_loss: 38.85  loss_ce: 0  loss_mask: 0.9479  loss_dice: 2.691  loss_seg: 1.508  loss_ce_0: 0  loss_mask_0: 0.93  loss_dice_0: 2.792  loss_ce_1: 0  loss_mask_1: 0.9453  loss_dice_1: 2.698  loss_ce_2: 0  loss_mask_2: 0.9567  loss_dice_2: 2.678  loss_ce_3: 0  loss_mask_3: 0.9601  loss_dice_3: 2.662  loss_ce_4: 0  loss_mask_4: 0.9553  loss_dice_4: 2.664  loss_ce_5: 0  loss_mask_5: 0.9579  loss_dice_5: 2.669  loss_ce_6: 0  loss_mask_6: 0.9633  loss_dice_6: 2.666  loss_ce_7: 0  loss_mask_7: 0.9569  loss_dice_7: 2.671  loss_ce_8: 0  loss_mask_8: 0.9515  loss_dice_8: 2.674  time: 2.6656  data_time: 0.0305  lr: 9.0409e-05  max_mem: 5999M
[02/18 04:12:24] d2.utils.events INFO:  eta: 1 day, 0:10:42  iter: 6379  total_loss: 38.43  loss_ce: 0  loss_mask: 0.9966  loss_dice: 2.766  loss_seg: 1.036  loss_ce_0: 0  loss_mask_0: 1.012  loss_dice_0: 2.803  loss_ce_1: 0  loss_mask_1: 1.007  loss_dice_1: 2.745  loss_ce_2: 0  loss_mask_2: 1.007  loss_dice_2: 2.728  loss_ce_3: 0  loss_mask_3: 1.004  loss_dice_3: 2.734  loss_ce_4: 0  loss_mask_4: 1.002  loss_dice_4: 2.724  loss_ce_5: 0  loss_mask_5: 1.002  loss_dice_5: 2.73  loss_ce_6: 0  loss_mask_6: 1.005  loss_dice_6: 2.72  loss_ce_7: 0  loss_mask_7: 1.003  loss_dice_7: 2.733  loss_ce_8: 0  loss_mask_8: 1.001  loss_dice_8: 2.731  time: 2.6628  data_time: 0.0315  lr: 9.0379e-05  max_mem: 5999M
[02/18 04:12:53] d2.utils.events INFO:  eta: 1 day, 0:09:51  iter: 6399  total_loss: 38.68  loss_ce: 0  loss_mask: 1.064  loss_dice: 2.719  loss_seg: 1.184  loss_ce_0: 0  loss_mask_0: 1.081  loss_dice_0: 2.765  loss_ce_1: 0  loss_mask_1: 1.071  loss_dice_1: 2.719  loss_ce_2: 0  loss_mask_2: 1.072  loss_dice_2: 2.702  loss_ce_3: 0  loss_mask_3: 1.056  loss_dice_3: 2.703  loss_ce_4: 0  loss_mask_4: 1.061  loss_dice_4: 2.708  loss_ce_5: 0  loss_mask_5: 1.055  loss_dice_5: 2.712  loss_ce_6: 0  loss_mask_6: 1.058  loss_dice_6: 2.702  loss_ce_7: 0  loss_mask_7: 1.062  loss_dice_7: 2.7  loss_ce_8: 0  loss_mask_8: 1.063  loss_dice_8: 2.703  time: 2.6590  data_time: 0.0386  lr: 9.0348e-05  max_mem: 5999M
[02/18 04:13:25] d2.utils.events INFO:  eta: 1 day, 0:09:14  iter: 6419  total_loss: 38.52  loss_ce: 0  loss_mask: 1.036  loss_dice: 2.708  loss_seg: 1.01  loss_ce_0: 0  loss_mask_0: 1.047  loss_dice_0: 2.736  loss_ce_1: 0  loss_mask_1: 1.049  loss_dice_1: 2.702  loss_ce_2: 0  loss_mask_2: 1.041  loss_dice_2: 2.69  loss_ce_3: 0  loss_mask_3: 1.043  loss_dice_3: 2.683  loss_ce_4: 0  loss_mask_4: 1.053  loss_dice_4: 2.684  loss_ce_5: 0  loss_mask_5: 1.053  loss_dice_5: 2.681  loss_ce_6: 0  loss_mask_6: 1.048  loss_dice_6: 2.678  loss_ce_7: 0  loss_mask_7: 1.043  loss_dice_7: 2.687  loss_ce_8: 0  loss_mask_8: 1.04  loss_dice_8: 2.688  time: 2.6557  data_time: 0.0361  lr: 9.0318e-05  max_mem: 5999M
[02/18 04:13:56] d2.utils.events INFO:  eta: 1 day, 0:06:19  iter: 6439  total_loss: 38.96  loss_ce: 0  loss_mask: 1.014  loss_dice: 2.736  loss_seg: 1  loss_ce_0: 0  loss_mask_0: 1.026  loss_dice_0: 2.789  loss_ce_1: 0  loss_mask_1: 1.014  loss_dice_1: 2.733  loss_ce_2: 0  loss_mask_2: 1.019  loss_dice_2: 2.723  loss_ce_3: 0  loss_mask_3: 1.024  loss_dice_3: 2.72  loss_ce_4: 0  loss_mask_4: 1.022  loss_dice_4: 2.724  loss_ce_5: 0  loss_mask_5: 1.025  loss_dice_5: 2.723  loss_ce_6: 0  loss_mask_6: 1.031  loss_dice_6: 2.717  loss_ce_7: 0  loss_mask_7: 1.032  loss_dice_7: 2.719  loss_ce_8: 0  loss_mask_8: 1.024  loss_dice_8: 2.722  time: 2.6522  data_time: 0.0354  lr: 9.0288e-05  max_mem: 5999M
[02/18 04:14:27] d2.utils.events INFO:  eta: 1 day, 0:02:17  iter: 6459  total_loss: 39.73  loss_ce: 0  loss_mask: 1.063  loss_dice: 2.847  loss_seg: 0.912  loss_ce_0: 0  loss_mask_0: 1.06  loss_dice_0: 2.917  loss_ce_1: 0  loss_mask_1: 1.064  loss_dice_1: 2.852  loss_ce_2: 0  loss_mask_2: 1.065  loss_dice_2: 2.83  loss_ce_3: 0  loss_mask_3: 1.07  loss_dice_3: 2.812  loss_ce_4: 0  loss_mask_4: 1.074  loss_dice_4: 2.819  loss_ce_5: 0  loss_mask_5: 1.07  loss_dice_5: 2.824  loss_ce_6: 0  loss_mask_6: 1.069  loss_dice_6: 2.829  loss_ce_7: 0  loss_mask_7: 1.069  loss_dice_7: 2.821  loss_ce_8: 0  loss_mask_8: 1.074  loss_dice_8: 2.826  time: 2.6488  data_time: 0.0226  lr: 9.0257e-05  max_mem: 5999M
[02/18 04:15:00] d2.utils.events INFO:  eta: 1 day, 0:05:14  iter: 6479  total_loss: 37.02  loss_ce: 0  loss_mask: 1.05  loss_dice: 2.576  loss_seg: 0.8671  loss_ce_0: 0  loss_mask_0: 1.065  loss_dice_0: 2.621  loss_ce_1: 0  loss_mask_1: 1.061  loss_dice_1: 2.563  loss_ce_2: 0  loss_mask_2: 1.054  loss_dice_2: 2.552  loss_ce_3: 0  loss_mask_3: 1.059  loss_dice_3: 2.552  loss_ce_4: 0  loss_mask_4: 1.065  loss_dice_4: 2.554  loss_ce_5: 0  loss_mask_5: 1.059  loss_dice_5: 2.551  loss_ce_6: 0  loss_mask_6: 1.062  loss_dice_6: 2.552  loss_ce_7: 0  loss_mask_7: 1.057  loss_dice_7: 2.55  loss_ce_8: 0  loss_mask_8: 1.063  loss_dice_8: 2.545  time: 2.6458  data_time: 0.0260  lr: 9.0227e-05  max_mem: 5999M
[02/18 04:15:34] d2.utils.events INFO:  eta: 1 day, 0:06:04  iter: 6499  total_loss: 39.14  loss_ce: 0  loss_mask: 1.019  loss_dice: 2.798  loss_seg: 0.8962  loss_ce_0: 0  loss_mask_0: 1.017  loss_dice_0: 2.828  loss_ce_1: 0  loss_mask_1: 1.025  loss_dice_1: 2.791  loss_ce_2: 0  loss_mask_2: 1.028  loss_dice_2: 2.782  loss_ce_3: 0  loss_mask_3: 1.028  loss_dice_3: 2.772  loss_ce_4: 0  loss_mask_4: 1.028  loss_dice_4: 2.777  loss_ce_5: 0  loss_mask_5: 1.023  loss_dice_5: 2.78  loss_ce_6: 0  loss_mask_6: 1.024  loss_dice_6: 2.775  loss_ce_7: 0  loss_mask_7: 1.021  loss_dice_7: 2.783  loss_ce_8: 0  loss_mask_8: 1.025  loss_dice_8: 2.778  time: 2.6428  data_time: 0.0321  lr: 9.0196e-05  max_mem: 5999M
[02/18 04:16:06] d2.utils.events INFO:  eta: 23:57:02  iter: 6519  total_loss: 37.73  loss_ce: 0  loss_mask: 0.9957  loss_dice: 2.696  loss_seg: 1.124  loss_ce_0: 0  loss_mask_0: 0.978  loss_dice_0: 2.757  loss_ce_1: 0  loss_mask_1: 0.9918  loss_dice_1: 2.688  loss_ce_2: 0  loss_mask_2: 1.003  loss_dice_2: 2.67  loss_ce_3: 0  loss_mask_3: 1.007  loss_dice_3: 2.664  loss_ce_4: 0  loss_mask_4: 1.006  loss_dice_4: 2.659  loss_ce_5: 0  loss_mask_5: 1.015  loss_dice_5: 2.662  loss_ce_6: 0  loss_mask_6: 1.011  loss_dice_6: 2.665  loss_ce_7: 0  loss_mask_7: 1.005  loss_dice_7: 2.667  loss_ce_8: 0  loss_mask_8: 1.007  loss_dice_8: 2.672  time: 2.6395  data_time: 0.0287  lr: 9.0166e-05  max_mem: 5999M
[02/18 04:16:39] d2.utils.events INFO:  eta: 23:52:14  iter: 6539  total_loss: 37.66  loss_ce: 0  loss_mask: 1.041  loss_dice: 2.656  loss_seg: 0.8446  loss_ce_0: 0  loss_mask_0: 1.04  loss_dice_0: 2.684  loss_ce_1: 0  loss_mask_1: 1.042  loss_dice_1: 2.636  loss_ce_2: 0  loss_mask_2: 1.049  loss_dice_2: 2.629  loss_ce_3: 0  loss_mask_3: 1.054  loss_dice_3: 2.619  loss_ce_4: 0  loss_mask_4: 1.048  loss_dice_4: 2.636  loss_ce_5: 0  loss_mask_5: 1.045  loss_dice_5: 2.642  loss_ce_6: 0  loss_mask_6: 1.048  loss_dice_6: 2.639  loss_ce_7: 0  loss_mask_7: 1.05  loss_dice_7: 2.637  loss_ce_8: 0  loss_mask_8: 1.051  loss_dice_8: 2.637  time: 2.6365  data_time: 0.0280  lr: 9.0136e-05  max_mem: 5999M
[02/18 04:17:12] d2.utils.events INFO:  eta: 23:52:18  iter: 6559  total_loss: 37.84  loss_ce: 0  loss_mask: 0.9882  loss_dice: 2.74  loss_seg: 0.8909  loss_ce_0: 0  loss_mask_0: 1.002  loss_dice_0: 2.793  loss_ce_1: 0  loss_mask_1: 0.9906  loss_dice_1: 2.731  loss_ce_2: 0  loss_mask_2: 0.996  loss_dice_2: 2.72  loss_ce_3: 0  loss_mask_3: 0.9989  loss_dice_3: 2.701  loss_ce_4: 0  loss_mask_4: 1.005  loss_dice_4: 2.708  loss_ce_5: 0  loss_mask_5: 1  loss_dice_5: 2.706  loss_ce_6: 0  loss_mask_6: 0.9993  loss_dice_6: 2.708  loss_ce_7: 0  loss_mask_7: 0.9982  loss_dice_7: 2.711  loss_ce_8: 0  loss_mask_8: 1.002  loss_dice_8: 2.716  time: 2.6334  data_time: 0.0279  lr: 9.0105e-05  max_mem: 5999M
[02/18 04:17:45] d2.utils.events INFO:  eta: 23:52:13  iter: 6579  total_loss: 38.82  loss_ce: 0  loss_mask: 1.009  loss_dice: 2.671  loss_seg: 1.167  loss_ce_0: 0  loss_mask_0: 1.034  loss_dice_0: 2.718  loss_ce_1: 0  loss_mask_1: 1.007  loss_dice_1: 2.658  loss_ce_2: 0  loss_mask_2: 1.004  loss_dice_2: 2.653  loss_ce_3: 0  loss_mask_3: 1.01  loss_dice_3: 2.645  loss_ce_4: 0  loss_mask_4: 1.009  loss_dice_4: 2.644  loss_ce_5: 0  loss_mask_5: 1.006  loss_dice_5: 2.647  loss_ce_6: 0  loss_mask_6: 1.011  loss_dice_6: 2.649  loss_ce_7: 0  loss_mask_7: 1.01  loss_dice_7: 2.644  loss_ce_8: 0  loss_mask_8: 1.006  loss_dice_8: 2.653  time: 2.6304  data_time: 0.0253  lr: 9.0075e-05  max_mem: 5999M
[02/18 04:18:20] d2.utils.events INFO:  eta: 23:53:03  iter: 6599  total_loss: 38  loss_ce: 0  loss_mask: 1.03  loss_dice: 2.682  loss_seg: 0.9468  loss_ce_0: 0  loss_mask_0: 1.037  loss_dice_0: 2.704  loss_ce_1: 0  loss_mask_1: 1.041  loss_dice_1: 2.668  loss_ce_2: 0  loss_mask_2: 1.042  loss_dice_2: 2.655  loss_ce_3: 0  loss_mask_3: 1.041  loss_dice_3: 2.648  loss_ce_4: 0  loss_mask_4: 1.034  loss_dice_4: 2.661  loss_ce_5: 0  loss_mask_5: 1.036  loss_dice_5: 2.655  loss_ce_6: 0  loss_mask_6: 1.037  loss_dice_6: 2.658  loss_ce_7: 0  loss_mask_7: 1.04  loss_dice_7: 2.656  loss_ce_8: 0  loss_mask_8: 1.033  loss_dice_8: 2.659  time: 2.6278  data_time: 0.0334  lr: 9.0045e-05  max_mem: 5999M
[02/18 04:18:53] d2.utils.events INFO:  eta: 23:51:09  iter: 6619  total_loss: 39.85  loss_ce: 0  loss_mask: 1.04  loss_dice: 2.728  loss_seg: 1.328  loss_ce_0: 0  loss_mask_0: 1.048  loss_dice_0: 2.772  loss_ce_1: 0  loss_mask_1: 1.035  loss_dice_1: 2.723  loss_ce_2: 0  loss_mask_2: 1.041  loss_dice_2: 2.717  loss_ce_3: 0  loss_mask_3: 1.041  loss_dice_3: 2.708  loss_ce_4: 0  loss_mask_4: 1.047  loss_dice_4: 2.704  loss_ce_5: 0  loss_mask_5: 1.044  loss_dice_5: 2.709  loss_ce_6: 0  loss_mask_6: 1.045  loss_dice_6: 2.704  loss_ce_7: 0  loss_mask_7: 1.05  loss_dice_7: 2.705  loss_ce_8: 0  loss_mask_8: 1.046  loss_dice_8: 2.715  time: 2.6248  data_time: 0.0312  lr: 9.0014e-05  max_mem: 5999M
[02/18 04:19:26] d2.utils.events INFO:  eta: 23:49:34  iter: 6639  total_loss: 38.77  loss_ce: 0  loss_mask: 1.008  loss_dice: 2.782  loss_seg: 1.157  loss_ce_0: 0  loss_mask_0: 1.023  loss_dice_0: 2.815  loss_ce_1: 0  loss_mask_1: 1.012  loss_dice_1: 2.77  loss_ce_2: 0  loss_mask_2: 1.023  loss_dice_2: 2.753  loss_ce_3: 0  loss_mask_3: 1.025  loss_dice_3: 2.749  loss_ce_4: 0  loss_mask_4: 1.028  loss_dice_4: 2.755  loss_ce_5: 0  loss_mask_5: 1.03  loss_dice_5: 2.749  loss_ce_6: 0  loss_mask_6: 1.026  loss_dice_6: 2.753  loss_ce_7: 0  loss_mask_7: 1.018  loss_dice_7: 2.754  loss_ce_8: 0  loss_mask_8: 1.021  loss_dice_8: 2.758  time: 2.6219  data_time: 0.0316  lr: 8.9984e-05  max_mem: 5999M
[02/18 04:19:59] d2.utils.events INFO:  eta: 23:49:37  iter: 6659  total_loss: 37.95  loss_ce: 0  loss_mask: 1.073  loss_dice: 2.633  loss_seg: 0.9313  loss_ce_0: 0  loss_mask_0: 1.055  loss_dice_0: 2.695  loss_ce_1: 0  loss_mask_1: 1.054  loss_dice_1: 2.619  loss_ce_2: 0  loss_mask_2: 1.072  loss_dice_2: 2.605  loss_ce_3: 0  loss_mask_3: 1.078  loss_dice_3: 2.603  loss_ce_4: 0  loss_mask_4: 1.083  loss_dice_4: 2.608  loss_ce_5: 0  loss_mask_5: 1.08  loss_dice_5: 2.617  loss_ce_6: 0  loss_mask_6: 1.084  loss_dice_6: 2.611  loss_ce_7: 0  loss_mask_7: 1.081  loss_dice_7: 2.616  loss_ce_8: 0  loss_mask_8: 1.083  loss_dice_8: 2.609  time: 2.6189  data_time: 0.0330  lr: 8.9954e-05  max_mem: 5999M
[02/18 04:20:30] d2.utils.events INFO:  eta: 23:47:49  iter: 6679  total_loss: 38.91  loss_ce: 0  loss_mask: 0.9717  loss_dice: 2.738  loss_seg: 1.785  loss_ce_0: 0  loss_mask_0: 0.9837  loss_dice_0: 2.768  loss_ce_1: 0  loss_mask_1: 0.9736  loss_dice_1: 2.715  loss_ce_2: 0  loss_mask_2: 0.974  loss_dice_2: 2.704  loss_ce_3: 0  loss_mask_3: 0.9785  loss_dice_3: 2.7  loss_ce_4: 0  loss_mask_4: 0.978  loss_dice_4: 2.697  loss_ce_5: 0  loss_mask_5: 0.9752  loss_dice_5: 2.702  loss_ce_6: 0  loss_mask_6: 0.9798  loss_dice_6: 2.698  loss_ce_7: 0  loss_mask_7: 0.9772  loss_dice_7: 2.696  loss_ce_8: 0  loss_mask_8: 0.9825  loss_dice_8: 2.697  time: 2.6157  data_time: 0.0282  lr: 8.9923e-05  max_mem: 5999M
[02/18 04:21:03] d2.utils.events INFO:  eta: 23:46:28  iter: 6699  total_loss: 37.31  loss_ce: 0  loss_mask: 1.031  loss_dice: 2.66  loss_seg: 0.8803  loss_ce_0: 0  loss_mask_0: 1.036  loss_dice_0: 2.715  loss_ce_1: 0  loss_mask_1: 1.036  loss_dice_1: 2.65  loss_ce_2: 0  loss_mask_2: 1.032  loss_dice_2: 2.63  loss_ce_3: 0  loss_mask_3: 1.038  loss_dice_3: 2.62  loss_ce_4: 0  loss_mask_4: 1.035  loss_dice_4: 2.628  loss_ce_5: 0  loss_mask_5: 1.042  loss_dice_5: 2.634  loss_ce_6: 0  loss_mask_6: 1.04  loss_dice_6: 2.631  loss_ce_7: 0  loss_mask_7: 1.034  loss_dice_7: 2.634  loss_ce_8: 0  loss_mask_8: 1.036  loss_dice_8: 2.632  time: 2.6129  data_time: 0.0288  lr: 8.9893e-05  max_mem: 5999M
[02/18 04:21:36] d2.utils.events INFO:  eta: 23:45:10  iter: 6719  total_loss: 39.77  loss_ce: 0  loss_mask: 1.051  loss_dice: 2.763  loss_seg: 1.139  loss_ce_0: 0  loss_mask_0: 1.072  loss_dice_0: 2.815  loss_ce_1: 0  loss_mask_1: 1.055  loss_dice_1: 2.757  loss_ce_2: 0  loss_mask_2: 1.056  loss_dice_2: 2.749  loss_ce_3: 0  loss_mask_3: 1.054  loss_dice_3: 2.749  loss_ce_4: 0  loss_mask_4: 1.044  loss_dice_4: 2.759  loss_ce_5: 0  loss_mask_5: 1.05  loss_dice_5: 2.759  loss_ce_6: 0  loss_mask_6: 1.049  loss_dice_6: 2.755  loss_ce_7: 0  loss_mask_7: 1.052  loss_dice_7: 2.75  loss_ce_8: 0  loss_mask_8: 1.05  loss_dice_8: 2.748  time: 2.6101  data_time: 0.0343  lr: 8.9863e-05  max_mem: 5999M
[02/18 04:22:08] d2.utils.events INFO:  eta: 23:44:38  iter: 6739  total_loss: 37.05  loss_ce: 0  loss_mask: 0.9611  loss_dice: 2.66  loss_seg: 0.9596  loss_ce_0: 0  loss_mask_0: 0.9613  loss_dice_0: 2.683  loss_ce_1: 0  loss_mask_1: 0.9601  loss_dice_1: 2.649  loss_ce_2: 0  loss_mask_2: 0.9643  loss_dice_2: 2.637  loss_ce_3: 0  loss_mask_3: 0.9726  loss_dice_3: 2.621  loss_ce_4: 0  loss_mask_4: 0.9733  loss_dice_4: 2.629  loss_ce_5: 0  loss_mask_5: 0.9702  loss_dice_5: 2.624  loss_ce_6: 0  loss_mask_6: 0.9701  loss_dice_6: 2.63  loss_ce_7: 0  loss_mask_7: 0.9705  loss_dice_7: 2.632  loss_ce_8: 0  loss_mask_8: 0.9728  loss_dice_8: 2.636  time: 2.6069  data_time: 0.0340  lr: 8.9832e-05  max_mem: 5999M
[02/18 04:22:40] d2.utils.events INFO:  eta: 23:44:06  iter: 6759  total_loss: 39.19  loss_ce: 0  loss_mask: 1.015  loss_dice: 2.685  loss_seg: 0.9052  loss_ce_0: 0  loss_mask_0: 1.022  loss_dice_0: 2.718  loss_ce_1: 0  loss_mask_1: 1.016  loss_dice_1: 2.692  loss_ce_2: 0  loss_mask_2: 1.022  loss_dice_2: 2.676  loss_ce_3: 0  loss_mask_3: 1.029  loss_dice_3: 2.671  loss_ce_4: 0  loss_mask_4: 1.031  loss_dice_4: 2.667  loss_ce_5: 0  loss_mask_5: 1.029  loss_dice_5: 2.668  loss_ce_6: 0  loss_mask_6: 1.03  loss_dice_6: 2.663  loss_ce_7: 0  loss_mask_7: 1.031  loss_dice_7: 2.666  loss_ce_8: 0  loss_mask_8: 1.031  loss_dice_8: 2.67  time: 2.6040  data_time: 0.0360  lr: 8.9802e-05  max_mem: 5999M
[02/18 04:23:11] d2.utils.events INFO:  eta: 23:42:29  iter: 6779  total_loss: 38.73  loss_ce: 0  loss_mask: 1.061  loss_dice: 2.711  loss_seg: 0.8495  loss_ce_0: 0  loss_mask_0: 1.069  loss_dice_0: 2.746  loss_ce_1: 0  loss_mask_1: 1.071  loss_dice_1: 2.704  loss_ce_2: 0  loss_mask_2: 1.064  loss_dice_2: 2.699  loss_ce_3: 0  loss_mask_3: 1.062  loss_dice_3: 2.691  loss_ce_4: 0  loss_mask_4: 1.07  loss_dice_4: 2.7  loss_ce_5: 0  loss_mask_5: 1.069  loss_dice_5: 2.7  loss_ce_6: 0  loss_mask_6: 1.069  loss_dice_6: 2.695  loss_ce_7: 0  loss_mask_7: 1.069  loss_dice_7: 2.701  loss_ce_8: 0  loss_mask_8: 1.067  loss_dice_8: 2.699  time: 2.6009  data_time: 0.0339  lr: 8.9772e-05  max_mem: 5999M
[02/18 04:23:45] d2.utils.events INFO:  eta: 23:42:39  iter: 6799  total_loss: 38.15  loss_ce: 0  loss_mask: 1.013  loss_dice: 2.772  loss_seg: 1.026  loss_ce_0: 0  loss_mask_0: 1.03  loss_dice_0: 2.851  loss_ce_1: 0  loss_mask_1: 1.011  loss_dice_1: 2.763  loss_ce_2: 0  loss_mask_2: 1.018  loss_dice_2: 2.744  loss_ce_3: 0  loss_mask_3: 1.018  loss_dice_3: 2.737  loss_ce_4: 0  loss_mask_4: 1.017  loss_dice_4: 2.743  loss_ce_5: 0  loss_mask_5: 1.015  loss_dice_5: 2.749  loss_ce_6: 0  loss_mask_6: 1.02  loss_dice_6: 2.75  loss_ce_7: 0  loss_mask_7: 1.018  loss_dice_7: 2.756  loss_ce_8: 0  loss_mask_8: 1.016  loss_dice_8: 2.753  time: 2.5982  data_time: 0.0291  lr: 8.9741e-05  max_mem: 5999M
[02/18 04:24:20] d2.utils.events INFO:  eta: 23:43:49  iter: 6819  total_loss: 38.2  loss_ce: 0  loss_mask: 1.036  loss_dice: 2.733  loss_seg: 0.9896  loss_ce_0: 0  loss_mask_0: 1.033  loss_dice_0: 2.75  loss_ce_1: 0  loss_mask_1: 1.041  loss_dice_1: 2.725  loss_ce_2: 0  loss_mask_2: 1.046  loss_dice_2: 2.722  loss_ce_3: 0  loss_mask_3: 1.042  loss_dice_3: 2.719  loss_ce_4: 0  loss_mask_4: 1.046  loss_dice_4: 2.724  loss_ce_5: 0  loss_mask_5: 1.047  loss_dice_5: 2.719  loss_ce_6: 0  loss_mask_6: 1.048  loss_dice_6: 2.719  loss_ce_7: 0  loss_mask_7: 1.044  loss_dice_7: 2.718  loss_ce_8: 0  loss_mask_8: 1.045  loss_dice_8: 2.719  time: 2.5957  data_time: 0.0330  lr: 8.9711e-05  max_mem: 5999M
[02/18 04:24:52] d2.utils.events INFO:  eta: 23:43:51  iter: 6839  total_loss: 38.96  loss_ce: 0  loss_mask: 1.054  loss_dice: 2.698  loss_seg: 1.158  loss_ce_0: 0  loss_mask_0: 1.075  loss_dice_0: 2.717  loss_ce_1: 0  loss_mask_1: 1.073  loss_dice_1: 2.684  loss_ce_2: 0  loss_mask_2: 1.074  loss_dice_2: 2.682  loss_ce_3: 0  loss_mask_3: 1.08  loss_dice_3: 2.678  loss_ce_4: 0  loss_mask_4: 1.073  loss_dice_4: 2.684  loss_ce_5: 0  loss_mask_5: 1.076  loss_dice_5: 2.686  loss_ce_6: 0  loss_mask_6: 1.076  loss_dice_6: 2.677  loss_ce_7: 0  loss_mask_7: 1.076  loss_dice_7: 2.681  loss_ce_8: 0  loss_mask_8: 1.069  loss_dice_8: 2.683  time: 2.5928  data_time: 0.0254  lr: 8.968e-05  max_mem: 5999M
[02/18 04:25:25] d2.utils.events INFO:  eta: 23:45:47  iter: 6859  total_loss: 37.9  loss_ce: 0  loss_mask: 0.9667  loss_dice: 2.646  loss_seg: 1.081  loss_ce_0: 0  loss_mask_0: 0.9722  loss_dice_0: 2.692  loss_ce_1: 0  loss_mask_1: 0.9693  loss_dice_1: 2.648  loss_ce_2: 0  loss_mask_2: 0.9705  loss_dice_2: 2.634  loss_ce_3: 0  loss_mask_3: 0.9728  loss_dice_3: 2.623  loss_ce_4: 0  loss_mask_4: 0.9737  loss_dice_4: 2.623  loss_ce_5: 0  loss_mask_5: 0.97  loss_dice_5: 2.622  loss_ce_6: 0  loss_mask_6: 0.969  loss_dice_6: 2.628  loss_ce_7: 0  loss_mask_7: 0.9806  loss_dice_7: 2.627  loss_ce_8: 0  loss_mask_8: 0.9758  loss_dice_8: 2.629  time: 2.5900  data_time: 0.0285  lr: 8.965e-05  max_mem: 5999M
[02/18 04:25:57] d2.utils.events INFO:  eta: 23:45:52  iter: 6879  total_loss: 37.3  loss_ce: 0  loss_mask: 1.021  loss_dice: 2.613  loss_seg: 0.8656  loss_ce_0: 0  loss_mask_0: 1.027  loss_dice_0: 2.649  loss_ce_1: 0  loss_mask_1: 1.027  loss_dice_1: 2.616  loss_ce_2: 0  loss_mask_2: 1.026  loss_dice_2: 2.609  loss_ce_3: 0  loss_mask_3: 1.028  loss_dice_3: 2.6  loss_ce_4: 0  loss_mask_4: 1.034  loss_dice_4: 2.603  loss_ce_5: 0  loss_mask_5: 1.031  loss_dice_5: 2.597  loss_ce_6: 0  loss_mask_6: 1.031  loss_dice_6: 2.598  loss_ce_7: 0  loss_mask_7: 1.034  loss_dice_7: 2.603  loss_ce_8: 0  loss_mask_8: 1.033  loss_dice_8: 2.593  time: 2.5871  data_time: 0.0376  lr: 8.962e-05  max_mem: 5999M
[02/18 04:26:28] d2.utils.events INFO:  eta: 23:43:11  iter: 6899  total_loss: 36.18  loss_ce: 0  loss_mask: 0.9928  loss_dice: 2.547  loss_seg: 0.8951  loss_ce_0: 0  loss_mask_0: 0.9941  loss_dice_0: 2.629  loss_ce_1: 0  loss_mask_1: 1.007  loss_dice_1: 2.536  loss_ce_2: 0  loss_mask_2: 1.007  loss_dice_2: 2.529  loss_ce_3: 0  loss_mask_3: 1.006  loss_dice_3: 2.527  loss_ce_4: 0  loss_mask_4: 1.004  loss_dice_4: 2.527  loss_ce_5: 0  loss_mask_5: 1.002  loss_dice_5: 2.532  loss_ce_6: 0  loss_mask_6: 1.003  loss_dice_6: 2.532  loss_ce_7: 0  loss_mask_7: 0.9972  loss_dice_7: 2.539  loss_ce_8: 0  loss_mask_8: 1.004  loss_dice_8: 2.532  time: 2.5841  data_time: 0.0284  lr: 8.9589e-05  max_mem: 5999M
[02/18 04:27:01] d2.utils.events INFO:  eta: 23:41:42  iter: 6919  total_loss: 36.97  loss_ce: 0  loss_mask: 0.964  loss_dice: 2.614  loss_seg: 1.179  loss_ce_0: 0  loss_mask_0: 0.9704  loss_dice_0: 2.695  loss_ce_1: 0  loss_mask_1: 0.9696  loss_dice_1: 2.601  loss_ce_2: 0  loss_mask_2: 0.9724  loss_dice_2: 2.591  loss_ce_3: 0  loss_mask_3: 0.9734  loss_dice_3: 2.583  loss_ce_4: 0  loss_mask_4: 0.9758  loss_dice_4: 2.584  loss_ce_5: 0  loss_mask_5: 0.975  loss_dice_5: 2.59  loss_ce_6: 0  loss_mask_6: 0.9719  loss_dice_6: 2.591  loss_ce_7: 0  loss_mask_7: 0.976  loss_dice_7: 2.597  loss_ce_8: 0  loss_mask_8: 0.9806  loss_dice_8: 2.598  time: 2.5813  data_time: 0.0339  lr: 8.9559e-05  max_mem: 5999M
[02/18 04:27:33] d2.utils.events INFO:  eta: 23:39:17  iter: 6939  total_loss: 37.75  loss_ce: 0  loss_mask: 1.05  loss_dice: 2.614  loss_seg: 1.072  loss_ce_0: 0  loss_mask_0: 1.049  loss_dice_0: 2.654  loss_ce_1: 0  loss_mask_1: 1.047  loss_dice_1: 2.608  loss_ce_2: 0  loss_mask_2: 1.046  loss_dice_2: 2.599  loss_ce_3: 0  loss_mask_3: 1.056  loss_dice_3: 2.594  loss_ce_4: 0  loss_mask_4: 1.053  loss_dice_4: 2.597  loss_ce_5: 0  loss_mask_5: 1.054  loss_dice_5: 2.599  loss_ce_6: 0  loss_mask_6: 1.056  loss_dice_6: 2.598  loss_ce_7: 0  loss_mask_7: 1.054  loss_dice_7: 2.598  loss_ce_8: 0  loss_mask_8: 1.052  loss_dice_8: 2.597  time: 2.5785  data_time: 0.0326  lr: 8.9529e-05  max_mem: 5999M
[02/18 04:28:06] d2.utils.events INFO:  eta: 23:39:11  iter: 6959  total_loss: 37.33  loss_ce: 0  loss_mask: 0.9901  loss_dice: 2.619  loss_seg: 0.847  loss_ce_0: 0  loss_mask_0: 0.994  loss_dice_0: 2.672  loss_ce_1: 0  loss_mask_1: 1.003  loss_dice_1: 2.606  loss_ce_2: 0  loss_mask_2: 1.001  loss_dice_2: 2.595  loss_ce_3: 0  loss_mask_3: 1.004  loss_dice_3: 2.587  loss_ce_4: 0  loss_mask_4: 1.007  loss_dice_4: 2.593  loss_ce_5: 0  loss_mask_5: 1.009  loss_dice_5: 2.59  loss_ce_6: 0  loss_mask_6: 0.9956  loss_dice_6: 2.599  loss_ce_7: 0  loss_mask_7: 0.9974  loss_dice_7: 2.594  loss_ce_8: 0  loss_mask_8: 1.001  loss_dice_8: 2.597  time: 2.5759  data_time: 0.0299  lr: 8.9498e-05  max_mem: 5999M
[02/18 04:28:37] d2.utils.events INFO:  eta: 23:37:08  iter: 6979  total_loss: 38.96  loss_ce: 0  loss_mask: 1.008  loss_dice: 2.731  loss_seg: 0.7622  loss_ce_0: 0  loss_mask_0: 1.022  loss_dice_0: 2.755  loss_ce_1: 0  loss_mask_1: 1.013  loss_dice_1: 2.722  loss_ce_2: 0  loss_mask_2: 1.017  loss_dice_2: 2.711  loss_ce_3: 0  loss_mask_3: 1.022  loss_dice_3: 2.708  loss_ce_4: 0  loss_mask_4: 1.021  loss_dice_4: 2.712  loss_ce_5: 0  loss_mask_5: 1.019  loss_dice_5: 2.717  loss_ce_6: 0  loss_mask_6: 1.023  loss_dice_6: 2.71  loss_ce_7: 0  loss_mask_7: 1.015  loss_dice_7: 2.708  loss_ce_8: 0  loss_mask_8: 1.016  loss_dice_8: 2.712  time: 2.5729  data_time: 0.0286  lr: 8.9468e-05  max_mem: 5999M
[02/18 04:29:11] d2.utils.events INFO:  eta: 23:36:36  iter: 6999  total_loss: 37.4  loss_ce: 0  loss_mask: 0.9953  loss_dice: 2.608  loss_seg: 0.9587  loss_ce_0: 0  loss_mask_0: 0.9734  loss_dice_0: 2.696  loss_ce_1: 0  loss_mask_1: 0.9806  loss_dice_1: 2.605  loss_ce_2: 0  loss_mask_2: 0.9874  loss_dice_2: 2.587  loss_ce_3: 0  loss_mask_3: 0.9993  loss_dice_3: 2.584  loss_ce_4: 0  loss_mask_4: 0.9973  loss_dice_4: 2.585  loss_ce_5: 0  loss_mask_5: 0.9961  loss_dice_5: 2.592  loss_ce_6: 0  loss_mask_6: 1.002  loss_dice_6: 2.583  loss_ce_7: 0  loss_mask_7: 0.997  loss_dice_7: 2.589  loss_ce_8: 0  loss_mask_8: 1.002  loss_dice_8: 2.584  time: 2.5704  data_time: 0.0292  lr: 8.9437e-05  max_mem: 5999M
[02/18 04:29:44] d2.utils.events INFO:  eta: 23:34:42  iter: 7019  total_loss: 37.41  loss_ce: 0  loss_mask: 0.9733  loss_dice: 2.653  loss_seg: 0.9763  loss_ce_0: 0  loss_mask_0: 0.9698  loss_dice_0: 2.733  loss_ce_1: 0  loss_mask_1: 0.9796  loss_dice_1: 2.652  loss_ce_2: 0  loss_mask_2: 0.9806  loss_dice_2: 2.636  loss_ce_3: 0  loss_mask_3: 0.9779  loss_dice_3: 2.626  loss_ce_4: 0  loss_mask_4: 0.9815  loss_dice_4: 2.635  loss_ce_5: 0  loss_mask_5: 0.9816  loss_dice_5: 2.632  loss_ce_6: 0  loss_mask_6: 0.9817  loss_dice_6: 2.63  loss_ce_7: 0  loss_mask_7: 0.9835  loss_dice_7: 2.635  loss_ce_8: 0  loss_mask_8: 0.9819  loss_dice_8: 2.635  time: 2.5678  data_time: 0.0308  lr: 8.9407e-05  max_mem: 5999M
[02/18 04:30:20] d2.utils.events INFO:  eta: 23:34:10  iter: 7039  total_loss: 37.25  loss_ce: 0  loss_mask: 0.9672  loss_dice: 2.642  loss_seg: 1.198  loss_ce_0: 0  loss_mask_0: 0.9727  loss_dice_0: 2.698  loss_ce_1: 0  loss_mask_1: 0.9676  loss_dice_1: 2.634  loss_ce_2: 0  loss_mask_2: 0.9627  loss_dice_2: 2.622  loss_ce_3: 0  loss_mask_3: 0.9693  loss_dice_3: 2.621  loss_ce_4: 0  loss_mask_4: 0.9686  loss_dice_4: 2.621  loss_ce_5: 0  loss_mask_5: 0.9725  loss_dice_5: 2.624  loss_ce_6: 0  loss_mask_6: 0.9788  loss_dice_6: 2.618  loss_ce_7: 0  loss_mask_7: 0.9713  loss_dice_7: 2.621  loss_ce_8: 0  loss_mask_8: 0.9756  loss_dice_8: 2.627  time: 2.5656  data_time: 0.0325  lr: 8.9377e-05  max_mem: 5999M
[02/18 04:30:53] d2.utils.events INFO:  eta: 23:34:22  iter: 7059  total_loss: 37.49  loss_ce: 0  loss_mask: 0.9816  loss_dice: 2.623  loss_seg: 0.8914  loss_ce_0: 0  loss_mask_0: 0.9975  loss_dice_0: 2.68  loss_ce_1: 0  loss_mask_1: 0.9763  loss_dice_1: 2.613  loss_ce_2: 0  loss_mask_2: 0.9769  loss_dice_2: 2.602  loss_ce_3: 0  loss_mask_3: 0.9794  loss_dice_3: 2.589  loss_ce_4: 0  loss_mask_4: 0.9856  loss_dice_4: 2.592  loss_ce_5: 0  loss_mask_5: 0.9828  loss_dice_5: 2.6  loss_ce_6: 0  loss_mask_6: 0.9859  loss_dice_6: 2.591  loss_ce_7: 0  loss_mask_7: 0.9864  loss_dice_7: 2.596  loss_ce_8: 0  loss_mask_8: 0.988  loss_dice_8: 2.601  time: 2.5630  data_time: 0.0270  lr: 8.9346e-05  max_mem: 5999M
[02/18 04:31:24] d2.utils.events INFO:  eta: 23:31:10  iter: 7079  total_loss: 37.02  loss_ce: 0  loss_mask: 1.024  loss_dice: 2.61  loss_seg: 1.081  loss_ce_0: 0  loss_mask_0: 1  loss_dice_0: 2.63  loss_ce_1: 0  loss_mask_1: 1.018  loss_dice_1: 2.599  loss_ce_2: 0  loss_mask_2: 1.026  loss_dice_2: 2.594  loss_ce_3: 0  loss_mask_3: 1.026  loss_dice_3: 2.585  loss_ce_4: 0  loss_mask_4: 1.021  loss_dice_4: 2.585  loss_ce_5: 0  loss_mask_5: 1.023  loss_dice_5: 2.592  loss_ce_6: 0  loss_mask_6: 1.023  loss_dice_6: 2.588  loss_ce_7: 0  loss_mask_7: 1.023  loss_dice_7: 2.589  loss_ce_8: 0  loss_mask_8: 1.027  loss_dice_8: 2.591  time: 2.5600  data_time: 0.0480  lr: 8.9316e-05  max_mem: 5999M
[02/18 04:31:56] d2.utils.events INFO:  eta: 23:29:30  iter: 7099  total_loss: 37.76  loss_ce: 0  loss_mask: 1.024  loss_dice: 2.651  loss_seg: 0.8077  loss_ce_0: 0  loss_mask_0: 1.013  loss_dice_0: 2.687  loss_ce_1: 0  loss_mask_1: 1.03  loss_dice_1: 2.64  loss_ce_2: 0  loss_mask_2: 1.019  loss_dice_2: 2.632  loss_ce_3: 0  loss_mask_3: 1.023  loss_dice_3: 2.619  loss_ce_4: 0  loss_mask_4: 1.026  loss_dice_4: 2.627  loss_ce_5: 0  loss_mask_5: 1.029  loss_dice_5: 2.628  loss_ce_6: 0  loss_mask_6: 1.036  loss_dice_6: 2.632  loss_ce_7: 0  loss_mask_7: 1.036  loss_dice_7: 2.636  loss_ce_8: 0  loss_mask_8: 1.035  loss_dice_8: 2.639  time: 2.5573  data_time: 0.0356  lr: 8.9286e-05  max_mem: 5999M
[02/18 04:32:28] d2.utils.events INFO:  eta: 23:28:58  iter: 7119  total_loss: 37.97  loss_ce: 0  loss_mask: 1.008  loss_dice: 2.679  loss_seg: 0.7426  loss_ce_0: 0  loss_mask_0: 1.019  loss_dice_0: 2.707  loss_ce_1: 0  loss_mask_1: 1.006  loss_dice_1: 2.663  loss_ce_2: 0  loss_mask_2: 0.9987  loss_dice_2: 2.663  loss_ce_3: 0  loss_mask_3: 1.007  loss_dice_3: 2.656  loss_ce_4: 0  loss_mask_4: 1.01  loss_dice_4: 2.654  loss_ce_5: 0  loss_mask_5: 1.012  loss_dice_5: 2.654  loss_ce_6: 0  loss_mask_6: 1.011  loss_dice_6: 2.655  loss_ce_7: 0  loss_mask_7: 1.012  loss_dice_7: 2.653  loss_ce_8: 0  loss_mask_8: 1.012  loss_dice_8: 2.659  time: 2.5547  data_time: 0.0318  lr: 8.9255e-05  max_mem: 5999M
[02/18 04:33:00] d2.utils.events INFO:  eta: 23:28:26  iter: 7139  total_loss: 38.14  loss_ce: 0  loss_mask: 1.02  loss_dice: 2.712  loss_seg: 0.9772  loss_ce_0: 0  loss_mask_0: 1.02  loss_dice_0: 2.758  loss_ce_1: 0  loss_mask_1: 1.028  loss_dice_1: 2.71  loss_ce_2: 0  loss_mask_2: 1.029  loss_dice_2: 2.692  loss_ce_3: 0  loss_mask_3: 1.029  loss_dice_3: 2.688  loss_ce_4: 0  loss_mask_4: 1.026  loss_dice_4: 2.698  loss_ce_5: 0  loss_mask_5: 1.022  loss_dice_5: 2.705  loss_ce_6: 0  loss_mask_6: 1.023  loss_dice_6: 2.698  loss_ce_7: 0  loss_mask_7: 1.022  loss_dice_7: 2.691  loss_ce_8: 0  loss_mask_8: 1.022  loss_dice_8: 2.692  time: 2.5520  data_time: 0.0295  lr: 8.9225e-05  max_mem: 6000M
[02/18 04:33:35] d2.utils.events INFO:  eta: 23:29:02  iter: 7159  total_loss: 36.61  loss_ce: 0  loss_mask: 0.9999  loss_dice: 2.57  loss_seg: 0.788  loss_ce_0: 0  loss_mask_0: 1.003  loss_dice_0: 2.643  loss_ce_1: 0  loss_mask_1: 1.012  loss_dice_1: 2.549  loss_ce_2: 0  loss_mask_2: 1.006  loss_dice_2: 2.546  loss_ce_3: 0  loss_mask_3: 1.014  loss_dice_3: 2.542  loss_ce_4: 0  loss_mask_4: 1.012  loss_dice_4: 2.539  loss_ce_5: 0  loss_mask_5: 1.012  loss_dice_5: 2.54  loss_ce_6: 0  loss_mask_6: 1.011  loss_dice_6: 2.539  loss_ce_7: 0  loss_mask_7: 1.002  loss_dice_7: 2.543  loss_ce_8: 0  loss_mask_8: 1.008  loss_dice_8: 2.547  time: 2.5497  data_time: 0.0337  lr: 8.9194e-05  max_mem: 6000M
[02/18 04:34:07] d2.utils.events INFO:  eta: 23:24:23  iter: 7179  total_loss: 37.36  loss_ce: 0  loss_mask: 1.003  loss_dice: 2.626  loss_seg: 0.7589  loss_ce_0: 0  loss_mask_0: 1.013  loss_dice_0: 2.671  loss_ce_1: 0  loss_mask_1: 1.014  loss_dice_1: 2.62  loss_ce_2: 0  loss_mask_2: 1.011  loss_dice_2: 2.606  loss_ce_3: 0  loss_mask_3: 1.009  loss_dice_3: 2.598  loss_ce_4: 0  loss_mask_4: 1.01  loss_dice_4: 2.596  loss_ce_5: 0  loss_mask_5: 1.009  loss_dice_5: 2.603  loss_ce_6: 0  loss_mask_6: 1.01  loss_dice_6: 2.605  loss_ce_7: 0  loss_mask_7: 1.008  loss_dice_7: 2.609  loss_ce_8: 0  loss_mask_8: 1.009  loss_dice_8: 2.607  time: 2.5470  data_time: 0.0309  lr: 8.9164e-05  max_mem: 6000M
[02/18 04:34:40] d2.utils.events INFO:  eta: 23:27:58  iter: 7199  total_loss: 39.05  loss_ce: 0  loss_mask: 1.029  loss_dice: 2.775  loss_seg: 0.8722  loss_ce_0: 0  loss_mask_0: 1.03  loss_dice_0: 2.816  loss_ce_1: 0  loss_mask_1: 1.034  loss_dice_1: 2.772  loss_ce_2: 0  loss_mask_2: 1.038  loss_dice_2: 2.754  loss_ce_3: 0  loss_mask_3: 1.045  loss_dice_3: 2.738  loss_ce_4: 0  loss_mask_4: 1.037  loss_dice_4: 2.744  loss_ce_5: 0  loss_mask_5: 1.041  loss_dice_5: 2.745  loss_ce_6: 0  loss_mask_6: 1.043  loss_dice_6: 2.746  loss_ce_7: 0  loss_mask_7: 1.042  loss_dice_7: 2.751  loss_ce_8: 0  loss_mask_8: 1.04  loss_dice_8: 2.754  time: 2.5445  data_time: 0.0274  lr: 8.9134e-05  max_mem: 6000M
[02/18 04:35:12] d2.utils.events INFO:  eta: 23:27:26  iter: 7219  total_loss: 37.18  loss_ce: 0  loss_mask: 0.9959  loss_dice: 2.649  loss_seg: 0.915  loss_ce_0: 0  loss_mask_0: 1.007  loss_dice_0: 2.678  loss_ce_1: 0  loss_mask_1: 1.005  loss_dice_1: 2.643  loss_ce_2: 0  loss_mask_2: 1.004  loss_dice_2: 2.632  loss_ce_3: 0  loss_mask_3: 1.003  loss_dice_3: 2.633  loss_ce_4: 0  loss_mask_4: 1.001  loss_dice_4: 2.635  loss_ce_5: 0  loss_mask_5: 1.005  loss_dice_5: 2.632  loss_ce_6: 0  loss_mask_6: 1.002  loss_dice_6: 2.635  loss_ce_7: 0  loss_mask_7: 1.004  loss_dice_7: 2.632  loss_ce_8: 0  loss_mask_8: 1.007  loss_dice_8: 2.63  time: 2.5419  data_time: 0.0314  lr: 8.9103e-05  max_mem: 6000M
[02/18 04:35:45] d2.utils.events INFO:  eta: 23:27:43  iter: 7239  total_loss: 38.14  loss_ce: 0  loss_mask: 1.004  loss_dice: 2.678  loss_seg: 1.115  loss_ce_0: 0  loss_mask_0: 1.002  loss_dice_0: 2.719  loss_ce_1: 0  loss_mask_1: 1.012  loss_dice_1: 2.673  loss_ce_2: 0  loss_mask_2: 1.015  loss_dice_2: 2.666  loss_ce_3: 0  loss_mask_3: 1.013  loss_dice_3: 2.654  loss_ce_4: 0  loss_mask_4: 1.017  loss_dice_4: 2.656  loss_ce_5: 0  loss_mask_5: 1.02  loss_dice_5: 2.657  loss_ce_6: 0  loss_mask_6: 1.023  loss_dice_6: 2.656  loss_ce_7: 0  loss_mask_7: 1.021  loss_dice_7: 2.663  loss_ce_8: 0  loss_mask_8: 1.023  loss_dice_8: 2.666  time: 2.5395  data_time: 0.0311  lr: 8.9073e-05  max_mem: 6000M
[02/18 04:36:16] d2.utils.events INFO:  eta: 23:22:48  iter: 7259  total_loss: 37.05  loss_ce: 0  loss_mask: 0.9987  loss_dice: 2.633  loss_seg: 1  loss_ce_0: 0  loss_mask_0: 0.9969  loss_dice_0: 2.681  loss_ce_1: 0  loss_mask_1: 0.997  loss_dice_1: 2.619  loss_ce_2: 0  loss_mask_2: 1.005  loss_dice_2: 2.611  loss_ce_3: 0  loss_mask_3: 1.01  loss_dice_3: 2.603  loss_ce_4: 0  loss_mask_4: 1.01  loss_dice_4: 2.607  loss_ce_5: 0  loss_mask_5: 1.012  loss_dice_5: 2.606  loss_ce_6: 0  loss_mask_6: 1.015  loss_dice_6: 2.611  loss_ce_7: 0  loss_mask_7: 1.012  loss_dice_7: 2.614  loss_ce_8: 0  loss_mask_8: 1.015  loss_dice_8: 2.62  time: 2.5367  data_time: 0.0339  lr: 8.9043e-05  max_mem: 6000M
[02/18 04:36:51] d2.utils.events INFO:  eta: 23:23:44  iter: 7279  total_loss: 37.01  loss_ce: 0  loss_mask: 0.9092  loss_dice: 2.608  loss_seg: 0.9659  loss_ce_0: 0  loss_mask_0: 0.9115  loss_dice_0: 2.693  loss_ce_1: 0  loss_mask_1: 0.9143  loss_dice_1: 2.606  loss_ce_2: 0  loss_mask_2: 0.9156  loss_dice_2: 2.591  loss_ce_3: 0  loss_mask_3: 0.9161  loss_dice_3: 2.592  loss_ce_4: 0  loss_mask_4: 0.919  loss_dice_4: 2.587  loss_ce_5: 0  loss_mask_5: 0.92  loss_dice_5: 2.591  loss_ce_6: 0  loss_mask_6: 0.9231  loss_dice_6: 2.59  loss_ce_7: 0  loss_mask_7: 0.9166  loss_dice_7: 2.594  loss_ce_8: 0  loss_mask_8: 0.9134  loss_dice_8: 2.597  time: 2.5344  data_time: 0.0291  lr: 8.9012e-05  max_mem: 6000M
[02/18 04:37:23] d2.utils.events INFO:  eta: 23:24:02  iter: 7299  total_loss: 37.02  loss_ce: 0  loss_mask: 1.013  loss_dice: 2.636  loss_seg: 0.8259  loss_ce_0: 0  loss_mask_0: 1.018  loss_dice_0: 2.67  loss_ce_1: 0  loss_mask_1: 1.018  loss_dice_1: 2.632  loss_ce_2: 0  loss_mask_2: 1.018  loss_dice_2: 2.62  loss_ce_3: 0  loss_mask_3: 1.021  loss_dice_3: 2.618  loss_ce_4: 0  loss_mask_4: 1.017  loss_dice_4: 2.618  loss_ce_5: 0  loss_mask_5: 1.023  loss_dice_5: 2.619  loss_ce_6: 0  loss_mask_6: 1.026  loss_dice_6: 2.615  loss_ce_7: 0  loss_mask_7: 1.023  loss_dice_7: 2.617  loss_ce_8: 0  loss_mask_8: 1.019  loss_dice_8: 2.619  time: 2.5319  data_time: 0.0344  lr: 8.8982e-05  max_mem: 6000M
[02/18 04:37:56] d2.utils.events INFO:  eta: 23:25:08  iter: 7319  total_loss: 38.24  loss_ce: 0  loss_mask: 1.05  loss_dice: 2.597  loss_seg: 0.9473  loss_ce_0: 0  loss_mask_0: 1.068  loss_dice_0: 2.641  loss_ce_1: 0  loss_mask_1: 1.054  loss_dice_1: 2.607  loss_ce_2: 0  loss_mask_2: 1.058  loss_dice_2: 2.591  loss_ce_3: 0  loss_mask_3: 1.059  loss_dice_3: 2.574  loss_ce_4: 0  loss_mask_4: 1.061  loss_dice_4: 2.574  loss_ce_5: 0  loss_mask_5: 1.061  loss_dice_5: 2.582  loss_ce_6: 0  loss_mask_6: 1.054  loss_dice_6: 2.578  loss_ce_7: 0  loss_mask_7: 1.054  loss_dice_7: 2.581  loss_ce_8: 0  loss_mask_8: 1.056  loss_dice_8: 2.577  time: 2.5295  data_time: 0.0316  lr: 8.8951e-05  max_mem: 6000M
[02/18 04:38:31] d2.utils.events INFO:  eta: 23:26:59  iter: 7339  total_loss: 36.98  loss_ce: 0  loss_mask: 0.9626  loss_dice: 2.578  loss_seg: 0.8177  loss_ce_0: 0  loss_mask_0: 0.9823  loss_dice_0: 2.659  loss_ce_1: 0  loss_mask_1: 0.9677  loss_dice_1: 2.569  loss_ce_2: 0  loss_mask_2: 0.9704  loss_dice_2: 2.559  loss_ce_3: 0  loss_mask_3: 0.977  loss_dice_3: 2.555  loss_ce_4: 0  loss_mask_4: 0.9788  loss_dice_4: 2.549  loss_ce_5: 0  loss_mask_5: 0.9774  loss_dice_5: 2.563  loss_ce_6: 0  loss_mask_6: 0.9735  loss_dice_6: 2.559  loss_ce_7: 0  loss_mask_7: 0.9744  loss_dice_7: 2.552  loss_ce_8: 0  loss_mask_8: 0.9733  loss_dice_8: 2.557  time: 2.5273  data_time: 0.0297  lr: 8.8921e-05  max_mem: 6000M
[02/18 04:39:02] d2.utils.events INFO:  eta: 23:25:37  iter: 7359  total_loss: 37.31  loss_ce: 0  loss_mask: 1.013  loss_dice: 2.654  loss_seg: 0.9335  loss_ce_0: 0  loss_mask_0: 1.021  loss_dice_0: 2.675  loss_ce_1: 0  loss_mask_1: 1.008  loss_dice_1: 2.657  loss_ce_2: 0  loss_mask_2: 1.01  loss_dice_2: 2.642  loss_ce_3: 0  loss_mask_3: 1.014  loss_dice_3: 2.626  loss_ce_4: 0  loss_mask_4: 1.016  loss_dice_4: 2.634  loss_ce_5: 0  loss_mask_5: 1.014  loss_dice_5: 2.63  loss_ce_6: 0  loss_mask_6: 1.017  loss_dice_6: 2.627  loss_ce_7: 0  loss_mask_7: 1.016  loss_dice_7: 2.635  loss_ce_8: 0  loss_mask_8: 1.012  loss_dice_8: 2.633  time: 2.5246  data_time: 0.0282  lr: 8.8891e-05  max_mem: 6000M
[02/18 04:39:34] d2.utils.events INFO:  eta: 23:23:32  iter: 7379  total_loss: 36.93  loss_ce: 0  loss_mask: 0.9631  loss_dice: 2.583  loss_seg: 0.8215  loss_ce_0: 0  loss_mask_0: 0.9755  loss_dice_0: 2.667  loss_ce_1: 0  loss_mask_1: 0.9685  loss_dice_1: 2.582  loss_ce_2: 0  loss_mask_2: 0.9735  loss_dice_2: 2.575  loss_ce_3: 0  loss_mask_3: 0.9756  loss_dice_3: 2.575  loss_ce_4: 0  loss_mask_4: 0.9708  loss_dice_4: 2.57  loss_ce_5: 0  loss_mask_5: 0.9717  loss_dice_5: 2.576  loss_ce_6: 0  loss_mask_6: 0.9656  loss_dice_6: 2.579  loss_ce_7: 0  loss_mask_7: 0.9686  loss_dice_7: 2.576  loss_ce_8: 0  loss_mask_8: 0.9687  loss_dice_8: 2.573  time: 2.5222  data_time: 0.0326  lr: 8.886e-05  max_mem: 6000M
[02/18 04:40:08] d2.utils.events INFO:  eta: 23:27:25  iter: 7399  total_loss: 36.56  loss_ce: 0  loss_mask: 0.9948  loss_dice: 2.595  loss_seg: 0.8758  loss_ce_0: 0  loss_mask_0: 0.9862  loss_dice_0: 2.646  loss_ce_1: 0  loss_mask_1: 0.9986  loss_dice_1: 2.586  loss_ce_2: 0  loss_mask_2: 0.9967  loss_dice_2: 2.582  loss_ce_3: 0  loss_mask_3: 0.9916  loss_dice_3: 2.572  loss_ce_4: 0  loss_mask_4: 0.9938  loss_dice_4: 2.574  loss_ce_5: 0  loss_mask_5: 0.9938  loss_dice_5: 2.578  loss_ce_6: 0  loss_mask_6: 0.9913  loss_dice_6: 2.577  loss_ce_7: 0  loss_mask_7: 0.9953  loss_dice_7: 2.572  loss_ce_8: 0  loss_mask_8: 0.9939  loss_dice_8: 2.571  time: 2.5200  data_time: 0.0284  lr: 8.883e-05  max_mem: 6000M
[02/18 04:40:43] d2.utils.events INFO:  eta: 23:29:39  iter: 7419  total_loss: 37.54  loss_ce: 0  loss_mask: 0.9908  loss_dice: 2.67  loss_seg: 0.7713  loss_ce_0: 0  loss_mask_0: 0.9954  loss_dice_0: 2.742  loss_ce_1: 0  loss_mask_1: 0.9966  loss_dice_1: 2.669  loss_ce_2: 0  loss_mask_2: 0.9983  loss_dice_2: 2.656  loss_ce_3: 0  loss_mask_3: 1.006  loss_dice_3: 2.648  loss_ce_4: 0  loss_mask_4: 1.005  loss_dice_4: 2.65  loss_ce_5: 0  loss_mask_5: 1.001  loss_dice_5: 2.654  loss_ce_6: 0  loss_mask_6: 1.003  loss_dice_6: 2.648  loss_ce_7: 0  loss_mask_7: 1.005  loss_dice_7: 2.649  loss_ce_8: 0  loss_mask_8: 1.001  loss_dice_8: 2.654  time: 2.5178  data_time: 0.0339  lr: 8.8799e-05  max_mem: 6000M
[02/18 04:41:16] d2.utils.events INFO:  eta: 23:32:55  iter: 7439  total_loss: 36.13  loss_ce: 0  loss_mask: 0.9786  loss_dice: 2.551  loss_seg: 1.053  loss_ce_0: 0  loss_mask_0: 0.9916  loss_dice_0: 2.615  loss_ce_1: 0  loss_mask_1: 0.9874  loss_dice_1: 2.548  loss_ce_2: 0  loss_mask_2: 0.9846  loss_dice_2: 2.541  loss_ce_3: 0  loss_mask_3: 0.9843  loss_dice_3: 2.528  loss_ce_4: 0  loss_mask_4: 0.9829  loss_dice_4: 2.535  loss_ce_5: 0  loss_mask_5: 0.9825  loss_dice_5: 2.537  loss_ce_6: 0  loss_mask_6: 0.9849  loss_dice_6: 2.534  loss_ce_7: 0  loss_mask_7: 0.9898  loss_dice_7: 2.54  loss_ce_8: 0  loss_mask_8: 0.9907  loss_dice_8: 2.533  time: 2.5156  data_time: 0.0329  lr: 8.8769e-05  max_mem: 6000M
[02/18 04:41:49] d2.utils.events INFO:  eta: 23:39:44  iter: 7459  total_loss: 36.95  loss_ce: 0  loss_mask: 0.983  loss_dice: 2.587  loss_seg: 1.153  loss_ce_0: 0  loss_mask_0: 0.996  loss_dice_0: 2.629  loss_ce_1: 0  loss_mask_1: 0.9872  loss_dice_1: 2.583  loss_ce_2: 0  loss_mask_2: 0.9896  loss_dice_2: 2.57  loss_ce_3: 0  loss_mask_3: 0.9983  loss_dice_3: 2.565  loss_ce_4: 0  loss_mask_4: 0.9945  loss_dice_4: 2.571  loss_ce_5: 0  loss_mask_5: 0.9946  loss_dice_5: 2.572  loss_ce_6: 0  loss_mask_6: 0.9922  loss_dice_6: 2.57  loss_ce_7: 0  loss_mask_7: 0.9909  loss_dice_7: 2.566  loss_ce_8: 0  loss_mask_8: 0.9864  loss_dice_8: 2.57  time: 2.5132  data_time: 0.0323  lr: 8.8739e-05  max_mem: 6000M
[02/18 04:42:22] d2.utils.events INFO:  eta: 23:39:11  iter: 7479  total_loss: 37.32  loss_ce: 0  loss_mask: 0.982  loss_dice: 2.656  loss_seg: 0.9153  loss_ce_0: 0  loss_mask_0: 0.9731  loss_dice_0: 2.702  loss_ce_1: 0  loss_mask_1: 0.9864  loss_dice_1: 2.654  loss_ce_2: 0  loss_mask_2: 0.9852  loss_dice_2: 2.641  loss_ce_3: 0  loss_mask_3: 0.9854  loss_dice_3: 2.631  loss_ce_4: 0  loss_mask_4: 0.986  loss_dice_4: 2.633  loss_ce_5: 0  loss_mask_5: 0.9846  loss_dice_5: 2.635  loss_ce_6: 0  loss_mask_6: 0.9855  loss_dice_6: 2.628  loss_ce_7: 0  loss_mask_7: 0.9884  loss_dice_7: 2.638  loss_ce_8: 0  loss_mask_8: 0.9864  loss_dice_8: 2.633  time: 2.5109  data_time: 0.0297  lr: 8.8708e-05  max_mem: 6000M
[02/18 04:42:56] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 04:42:57] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 04:42:57] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 04:43:11] mask2former INFO: Inference done 11/1093. Dataloading: 0.0036 s/iter. Inference: 0.2184 s/iter. Eval: 0.1062 s/iter. Total: 0.3282 s/iter. ETA=0:05:55
[02/18 04:43:16] mask2former INFO: Inference done 25/1093. Dataloading: 0.0049 s/iter. Inference: 0.2408 s/iter. Eval: 0.1194 s/iter. Total: 0.3652 s/iter. ETA=0:06:30
[02/18 04:43:21] mask2former INFO: Inference done 39/1093. Dataloading: 0.0055 s/iter. Inference: 0.2452 s/iter. Eval: 0.1193 s/iter. Total: 0.3701 s/iter. ETA=0:06:30
[02/18 04:43:26] mask2former INFO: Inference done 54/1093. Dataloading: 0.0053 s/iter. Inference: 0.2403 s/iter. Eval: 0.1182 s/iter. Total: 0.3639 s/iter. ETA=0:06:18
[02/18 04:43:32] mask2former INFO: Inference done 68/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1177 s/iter. Total: 0.3640 s/iter. ETA=0:06:13
[02/18 04:43:37] mask2former INFO: Inference done 83/1093. Dataloading: 0.0054 s/iter. Inference: 0.2393 s/iter. Eval: 0.1155 s/iter. Total: 0.3603 s/iter. ETA=0:06:03
[02/18 04:43:42] mask2former INFO: Inference done 97/1093. Dataloading: 0.0059 s/iter. Inference: 0.2405 s/iter. Eval: 0.1166 s/iter. Total: 0.3631 s/iter. ETA=0:06:01
[02/18 04:43:47] mask2former INFO: Inference done 110/1093. Dataloading: 0.0059 s/iter. Inference: 0.2430 s/iter. Eval: 0.1175 s/iter. Total: 0.3665 s/iter. ETA=0:06:00
[02/18 04:43:52] mask2former INFO: Inference done 124/1093. Dataloading: 0.0059 s/iter. Inference: 0.2446 s/iter. Eval: 0.1169 s/iter. Total: 0.3675 s/iter. ETA=0:05:56
[02/18 04:43:58] mask2former INFO: Inference done 138/1093. Dataloading: 0.0058 s/iter. Inference: 0.2449 s/iter. Eval: 0.1174 s/iter. Total: 0.3682 s/iter. ETA=0:05:51
[02/18 04:44:03] mask2former INFO: Inference done 153/1093. Dataloading: 0.0058 s/iter. Inference: 0.2433 s/iter. Eval: 0.1173 s/iter. Total: 0.3666 s/iter. ETA=0:05:44
[02/18 04:44:08] mask2former INFO: Inference done 167/1093. Dataloading: 0.0058 s/iter. Inference: 0.2422 s/iter. Eval: 0.1181 s/iter. Total: 0.3662 s/iter. ETA=0:05:39
[02/18 04:44:13] mask2former INFO: Inference done 181/1093. Dataloading: 0.0058 s/iter. Inference: 0.2421 s/iter. Eval: 0.1193 s/iter. Total: 0.3672 s/iter. ETA=0:05:34
[02/18 04:44:18] mask2former INFO: Inference done 194/1093. Dataloading: 0.0058 s/iter. Inference: 0.2441 s/iter. Eval: 0.1186 s/iter. Total: 0.3687 s/iter. ETA=0:05:31
[02/18 04:44:23] mask2former INFO: Inference done 208/1093. Dataloading: 0.0057 s/iter. Inference: 0.2438 s/iter. Eval: 0.1185 s/iter. Total: 0.3681 s/iter. ETA=0:05:25
[02/18 04:44:28] mask2former INFO: Inference done 221/1093. Dataloading: 0.0057 s/iter. Inference: 0.2449 s/iter. Eval: 0.1187 s/iter. Total: 0.3694 s/iter. ETA=0:05:22
[02/18 04:44:33] mask2former INFO: Inference done 235/1093. Dataloading: 0.0057 s/iter. Inference: 0.2443 s/iter. Eval: 0.1187 s/iter. Total: 0.3688 s/iter. ETA=0:05:16
[02/18 04:44:39] mask2former INFO: Inference done 249/1093. Dataloading: 0.0057 s/iter. Inference: 0.2444 s/iter. Eval: 0.1187 s/iter. Total: 0.3688 s/iter. ETA=0:05:11
[02/18 04:44:44] mask2former INFO: Inference done 263/1093. Dataloading: 0.0057 s/iter. Inference: 0.2446 s/iter. Eval: 0.1185 s/iter. Total: 0.3688 s/iter. ETA=0:05:06
[02/18 04:44:49] mask2former INFO: Inference done 277/1093. Dataloading: 0.0057 s/iter. Inference: 0.2442 s/iter. Eval: 0.1184 s/iter. Total: 0.3683 s/iter. ETA=0:05:00
[02/18 04:44:54] mask2former INFO: Inference done 292/1093. Dataloading: 0.0057 s/iter. Inference: 0.2434 s/iter. Eval: 0.1179 s/iter. Total: 0.3671 s/iter. ETA=0:04:54
[02/18 04:44:59] mask2former INFO: Inference done 306/1093. Dataloading: 0.0057 s/iter. Inference: 0.2428 s/iter. Eval: 0.1183 s/iter. Total: 0.3669 s/iter. ETA=0:04:48
[02/18 04:45:04] mask2former INFO: Inference done 321/1093. Dataloading: 0.0056 s/iter. Inference: 0.2428 s/iter. Eval: 0.1181 s/iter. Total: 0.3667 s/iter. ETA=0:04:43
[02/18 04:45:10] mask2former INFO: Inference done 335/1093. Dataloading: 0.0056 s/iter. Inference: 0.2425 s/iter. Eval: 0.1183 s/iter. Total: 0.3665 s/iter. ETA=0:04:37
[02/18 04:45:15] mask2former INFO: Inference done 350/1093. Dataloading: 0.0057 s/iter. Inference: 0.2420 s/iter. Eval: 0.1179 s/iter. Total: 0.3656 s/iter. ETA=0:04:31
[02/18 04:45:20] mask2former INFO: Inference done 365/1093. Dataloading: 0.0056 s/iter. Inference: 0.2414 s/iter. Eval: 0.1178 s/iter. Total: 0.3650 s/iter. ETA=0:04:25
[02/18 04:45:25] mask2former INFO: Inference done 379/1093. Dataloading: 0.0057 s/iter. Inference: 0.2420 s/iter. Eval: 0.1175 s/iter. Total: 0.3653 s/iter. ETA=0:04:20
[02/18 04:45:30] mask2former INFO: Inference done 393/1093. Dataloading: 0.0056 s/iter. Inference: 0.2419 s/iter. Eval: 0.1181 s/iter. Total: 0.3658 s/iter. ETA=0:04:16
[02/18 04:45:36] mask2former INFO: Inference done 408/1093. Dataloading: 0.0056 s/iter. Inference: 0.2417 s/iter. Eval: 0.1177 s/iter. Total: 0.3651 s/iter. ETA=0:04:10
[02/18 04:45:41] mask2former INFO: Inference done 422/1093. Dataloading: 0.0056 s/iter. Inference: 0.2418 s/iter. Eval: 0.1174 s/iter. Total: 0.3649 s/iter. ETA=0:04:04
[02/18 04:45:46] mask2former INFO: Inference done 437/1093. Dataloading: 0.0056 s/iter. Inference: 0.2416 s/iter. Eval: 0.1173 s/iter. Total: 0.3646 s/iter. ETA=0:03:59
[02/18 04:45:51] mask2former INFO: Inference done 452/1093. Dataloading: 0.0056 s/iter. Inference: 0.2411 s/iter. Eval: 0.1175 s/iter. Total: 0.3643 s/iter. ETA=0:03:53
[02/18 04:45:57] mask2former INFO: Inference done 466/1093. Dataloading: 0.0056 s/iter. Inference: 0.2416 s/iter. Eval: 0.1171 s/iter. Total: 0.3644 s/iter. ETA=0:03:48
[02/18 04:46:02] mask2former INFO: Inference done 480/1093. Dataloading: 0.0056 s/iter. Inference: 0.2414 s/iter. Eval: 0.1173 s/iter. Total: 0.3645 s/iter. ETA=0:03:43
[02/18 04:46:07] mask2former INFO: Inference done 495/1093. Dataloading: 0.0056 s/iter. Inference: 0.2413 s/iter. Eval: 0.1172 s/iter. Total: 0.3642 s/iter. ETA=0:03:37
[02/18 04:46:12] mask2former INFO: Inference done 509/1093. Dataloading: 0.0056 s/iter. Inference: 0.2417 s/iter. Eval: 0.1172 s/iter. Total: 0.3646 s/iter. ETA=0:03:32
[02/18 04:46:17] mask2former INFO: Inference done 523/1093. Dataloading: 0.0056 s/iter. Inference: 0.2419 s/iter. Eval: 0.1170 s/iter. Total: 0.3645 s/iter. ETA=0:03:27
[02/18 04:46:22] mask2former INFO: Inference done 537/1093. Dataloading: 0.0056 s/iter. Inference: 0.2423 s/iter. Eval: 0.1166 s/iter. Total: 0.3645 s/iter. ETA=0:03:22
[02/18 04:46:28] mask2former INFO: Inference done 551/1093. Dataloading: 0.0056 s/iter. Inference: 0.2427 s/iter. Eval: 0.1164 s/iter. Total: 0.3647 s/iter. ETA=0:03:17
[02/18 04:46:33] mask2former INFO: Inference done 566/1093. Dataloading: 0.0056 s/iter. Inference: 0.2423 s/iter. Eval: 0.1163 s/iter. Total: 0.3643 s/iter. ETA=0:03:11
[02/18 04:46:38] mask2former INFO: Inference done 580/1093. Dataloading: 0.0056 s/iter. Inference: 0.2424 s/iter. Eval: 0.1161 s/iter. Total: 0.3642 s/iter. ETA=0:03:06
[02/18 04:46:43] mask2former INFO: Inference done 593/1093. Dataloading: 0.0056 s/iter. Inference: 0.2426 s/iter. Eval: 0.1166 s/iter. Total: 0.3649 s/iter. ETA=0:03:02
[02/18 04:46:49] mask2former INFO: Inference done 607/1093. Dataloading: 0.0057 s/iter. Inference: 0.2428 s/iter. Eval: 0.1167 s/iter. Total: 0.3653 s/iter. ETA=0:02:57
[02/18 04:46:54] mask2former INFO: Inference done 621/1093. Dataloading: 0.0057 s/iter. Inference: 0.2429 s/iter. Eval: 0.1167 s/iter. Total: 0.3654 s/iter. ETA=0:02:52
[02/18 04:46:59] mask2former INFO: Inference done 635/1093. Dataloading: 0.0057 s/iter. Inference: 0.2429 s/iter. Eval: 0.1166 s/iter. Total: 0.3653 s/iter. ETA=0:02:47
[02/18 04:47:04] mask2former INFO: Inference done 649/1093. Dataloading: 0.0057 s/iter. Inference: 0.2426 s/iter. Eval: 0.1167 s/iter. Total: 0.3651 s/iter. ETA=0:02:42
[02/18 04:47:09] mask2former INFO: Inference done 663/1093. Dataloading: 0.0057 s/iter. Inference: 0.2425 s/iter. Eval: 0.1169 s/iter. Total: 0.3652 s/iter. ETA=0:02:37
[02/18 04:47:14] mask2former INFO: Inference done 677/1093. Dataloading: 0.0057 s/iter. Inference: 0.2422 s/iter. Eval: 0.1172 s/iter. Total: 0.3652 s/iter. ETA=0:02:31
[02/18 04:47:19] mask2former INFO: Inference done 691/1093. Dataloading: 0.0057 s/iter. Inference: 0.2422 s/iter. Eval: 0.1172 s/iter. Total: 0.3653 s/iter. ETA=0:02:26
[02/18 04:47:24] mask2former INFO: Inference done 705/1093. Dataloading: 0.0057 s/iter. Inference: 0.2423 s/iter. Eval: 0.1170 s/iter. Total: 0.3651 s/iter. ETA=0:02:21
[02/18 04:47:29] mask2former INFO: Inference done 720/1093. Dataloading: 0.0057 s/iter. Inference: 0.2420 s/iter. Eval: 0.1171 s/iter. Total: 0.3649 s/iter. ETA=0:02:16
[02/18 04:47:35] mask2former INFO: Inference done 735/1093. Dataloading: 0.0057 s/iter. Inference: 0.2419 s/iter. Eval: 0.1170 s/iter. Total: 0.3647 s/iter. ETA=0:02:10
[02/18 04:47:40] mask2former INFO: Inference done 749/1093. Dataloading: 0.0057 s/iter. Inference: 0.2422 s/iter. Eval: 0.1168 s/iter. Total: 0.3648 s/iter. ETA=0:02:05
[02/18 04:47:45] mask2former INFO: Inference done 763/1093. Dataloading: 0.0058 s/iter. Inference: 0.2422 s/iter. Eval: 0.1167 s/iter. Total: 0.3648 s/iter. ETA=0:02:00
[02/18 04:47:50] mask2former INFO: Inference done 777/1093. Dataloading: 0.0058 s/iter. Inference: 0.2423 s/iter. Eval: 0.1165 s/iter. Total: 0.3647 s/iter. ETA=0:01:55
[02/18 04:47:55] mask2former INFO: Inference done 791/1093. Dataloading: 0.0057 s/iter. Inference: 0.2425 s/iter. Eval: 0.1164 s/iter. Total: 0.3647 s/iter. ETA=0:01:50
[02/18 04:48:00] mask2former INFO: Inference done 805/1093. Dataloading: 0.0057 s/iter. Inference: 0.2422 s/iter. Eval: 0.1167 s/iter. Total: 0.3647 s/iter. ETA=0:01:45
[02/18 04:48:06] mask2former INFO: Inference done 819/1093. Dataloading: 0.0057 s/iter. Inference: 0.2425 s/iter. Eval: 0.1166 s/iter. Total: 0.3649 s/iter. ETA=0:01:39
[02/18 04:48:11] mask2former INFO: Inference done 833/1093. Dataloading: 0.0057 s/iter. Inference: 0.2426 s/iter. Eval: 0.1165 s/iter. Total: 0.3649 s/iter. ETA=0:01:34
[02/18 04:48:16] mask2former INFO: Inference done 848/1093. Dataloading: 0.0057 s/iter. Inference: 0.2424 s/iter. Eval: 0.1166 s/iter. Total: 0.3648 s/iter. ETA=0:01:29
[02/18 04:48:21] mask2former INFO: Inference done 862/1093. Dataloading: 0.0057 s/iter. Inference: 0.2426 s/iter. Eval: 0.1165 s/iter. Total: 0.3649 s/iter. ETA=0:01:24
[02/18 04:48:26] mask2former INFO: Inference done 876/1093. Dataloading: 0.0057 s/iter. Inference: 0.2426 s/iter. Eval: 0.1165 s/iter. Total: 0.3650 s/iter. ETA=0:01:19
[02/18 04:48:32] mask2former INFO: Inference done 890/1093. Dataloading: 0.0057 s/iter. Inference: 0.2425 s/iter. Eval: 0.1166 s/iter. Total: 0.3649 s/iter. ETA=0:01:14
[02/18 04:48:37] mask2former INFO: Inference done 904/1093. Dataloading: 0.0057 s/iter. Inference: 0.2427 s/iter. Eval: 0.1165 s/iter. Total: 0.3650 s/iter. ETA=0:01:08
[02/18 04:48:42] mask2former INFO: Inference done 919/1093. Dataloading: 0.0057 s/iter. Inference: 0.2427 s/iter. Eval: 0.1163 s/iter. Total: 0.3648 s/iter. ETA=0:01:03
[02/18 04:48:47] mask2former INFO: Inference done 933/1093. Dataloading: 0.0058 s/iter. Inference: 0.2427 s/iter. Eval: 0.1163 s/iter. Total: 0.3648 s/iter. ETA=0:00:58
[02/18 04:48:52] mask2former INFO: Inference done 947/1093. Dataloading: 0.0058 s/iter. Inference: 0.2428 s/iter. Eval: 0.1162 s/iter. Total: 0.3649 s/iter. ETA=0:00:53
[02/18 04:48:57] mask2former INFO: Inference done 962/1093. Dataloading: 0.0058 s/iter. Inference: 0.2425 s/iter. Eval: 0.1161 s/iter. Total: 0.3645 s/iter. ETA=0:00:47
[02/18 04:49:03] mask2former INFO: Inference done 976/1093. Dataloading: 0.0058 s/iter. Inference: 0.2424 s/iter. Eval: 0.1163 s/iter. Total: 0.3646 s/iter. ETA=0:00:42
[02/18 04:49:08] mask2former INFO: Inference done 987/1093. Dataloading: 0.0058 s/iter. Inference: 0.2428 s/iter. Eval: 0.1171 s/iter. Total: 0.3657 s/iter. ETA=0:00:38
[02/18 04:49:13] mask2former INFO: Inference done 993/1093. Dataloading: 0.0059 s/iter. Inference: 0.2443 s/iter. Eval: 0.1183 s/iter. Total: 0.3686 s/iter. ETA=0:00:36
[02/18 04:49:18] mask2former INFO: Inference done 1000/1093. Dataloading: 0.0060 s/iter. Inference: 0.2457 s/iter. Eval: 0.1198 s/iter. Total: 0.3716 s/iter. ETA=0:00:34
[02/18 04:49:23] mask2former INFO: Inference done 1012/1093. Dataloading: 0.0060 s/iter. Inference: 0.2461 s/iter. Eval: 0.1200 s/iter. Total: 0.3722 s/iter. ETA=0:00:30
[02/18 04:49:29] mask2former INFO: Inference done 1021/1093. Dataloading: 0.0060 s/iter. Inference: 0.2470 s/iter. Eval: 0.1209 s/iter. Total: 0.3740 s/iter. ETA=0:00:26
[02/18 04:49:34] mask2former INFO: Inference done 1032/1093. Dataloading: 0.0061 s/iter. Inference: 0.2476 s/iter. Eval: 0.1212 s/iter. Total: 0.3750 s/iter. ETA=0:00:22
[02/18 04:49:39] mask2former INFO: Inference done 1046/1093. Dataloading: 0.0061 s/iter. Inference: 0.2475 s/iter. Eval: 0.1212 s/iter. Total: 0.3748 s/iter. ETA=0:00:17
[02/18 04:49:44] mask2former INFO: Inference done 1060/1093. Dataloading: 0.0061 s/iter. Inference: 0.2475 s/iter. Eval: 0.1210 s/iter. Total: 0.3747 s/iter. ETA=0:00:12
[02/18 04:49:49] mask2former INFO: Inference done 1075/1093. Dataloading: 0.0061 s/iter. Inference: 0.2472 s/iter. Eval: 0.1209 s/iter. Total: 0.3744 s/iter. ETA=0:00:06
[02/18 04:49:55] mask2former INFO: Inference done 1090/1093. Dataloading: 0.0060 s/iter. Inference: 0.2471 s/iter. Eval: 0.1209 s/iter. Total: 0.3742 s/iter. ETA=0:00:01
[02/18 04:50:34] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.9070399798456386, 'error_1pix': 0.471589774851239, 'error_3pix': 0.24262274516875082, 'mIoU': 11.64930904037971, 'fwIoU': 34.51745858368322, 'IoU-1': 88.77381952839825, 'IoU-2': 0.11757802143901276, 'IoU-3': 0.003532680410871512, 'IoU-4': 0.002207489275281271, 'IoU-5': 0.0017287105691923608, 'IoU-6': 0.0022466356630945162, 'IoU-7': 0.0033508045458072616, 'IoU-8': 0.005428658976468573, 'IoU-9': 0.6722690931711709, 'IoU-10': 11.777237127254372, 'IoU-11': 11.356193663175011, 'IoU-12': 34.15393956686435, 'IoU-13': 19.244619695735523, 'IoU-14': 17.422590582267674, 'IoU-15': 16.500795754453954, 'IoU-16': 12.429706958054606, 'IoU-17': 8.023019444098974, 'IoU-18': 8.449174380090373, 'IoU-19': 9.4887571067462, 'IoU-20': 10.972981013797673, 'IoU-21': 9.653136290712206, 'IoU-22': 9.24266802776974, 'IoU-23': 9.342939572828818, 'IoU-24': 9.72506518162922, 'IoU-25': 10.780513896347356, 'IoU-26': 11.288022871396043, 'IoU-27': 12.578042184047582, 'IoU-28': 11.363081321727295, 'IoU-29': 8.43438299963393, 'IoU-30': 7.490306449245635, 'IoU-31': 8.027414915737623, 'IoU-32': 25.93529912634025, 'IoU-33': 7.14135373706232, 'IoU-34': 11.489125185026024, 'IoU-35': 15.73592575355317, 'IoU-36': 27.92731393049936, 'IoU-37': 10.649953099138497, 'IoU-38': 10.77760016132084, 'IoU-39': 13.379167776444687, 'IoU-40': 14.498796739674018, 'IoU-41': 13.49623583453368, 'IoU-42': 12.966188405714977, 'IoU-43': 19.916914047397928, 'IoU-44': 3.535767751183818, 'IoU-45': 2.587410272257416, 'IoU-46': 3.25270112545757, 'IoU-47': 4.210821227888137, 'IoU-48': 4.339509138670108, 'mACC': 21.477701347652285, 'pACC': 41.893722775319084, 'ACC-1': 90.78970208045362, 'ACC-2': 0.11758042131841163, 'ACC-3': 0.0035947073221016352, 'ACC-4': 0.0022390120483726118, 'ACC-5': 0.0017646280311162743, 'ACC-6': 0.002305809652119204, 'ACC-7': 0.003456418204772768, 'ACC-8': 0.005553827698049496, 'ACC-9': 45.94803601214077, 'ACC-10': 18.115564593645963, 'ACC-11': 13.888037427759176, 'ACC-12': 80.01839402785387, 'ACC-13': 30.702638036284526, 'ACC-14': 24.20736701495319, 'ACC-15': 23.328242944766956, 'ACC-16': 19.237675584691, 'ACC-17': 14.19416048129771, 'ACC-18': 15.359153328798842, 'ACC-19': 18.92510633717583, 'ACC-20': 22.14583745329168, 'ACC-21': 18.461544241286564, 'ACC-22': 15.147956737036964, 'ACC-23': 14.830420569376884, 'ACC-24': 15.960572791528607, 'ACC-25': 18.89492874544362, 'ACC-26': 21.890822840817346, 'ACC-27': 23.013033688794547, 'ACC-28': 19.844825490524137, 'ACC-29': 14.365826373619662, 'ACC-30': 13.282636808067627, 'ACC-31': 15.409906164373199, 'ACC-32': 83.70433525720333, 'ACC-33': 10.564552291800867, 'ACC-34': 15.309560712625084, 'ACC-35': 22.358894876240633, 'ACC-36': 68.87314088475, 'ACC-37': 19.563348309849214, 'ACC-38': 17.240323686134772, 'ACC-39': 19.778858414529196, 'ACC-40': 20.752586687147424, 'ACC-41': 19.891360309780158, 'ACC-42': 21.80498804320071, 'ACC-43': 69.86497745874745, 'ACC-44': 7.345684090405966, 'ACC-45': 4.709767055265155, 'ACC-46': 5.791086887258358, 'ACC-47': 7.5564453798555755, 'ACC-48': 7.720869744258509})])
[02/18 04:50:34] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 04:50:34] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 04:50:34] d2.evaluation.testing INFO: copypaste: 2.9070,0.4716,0.2426,11.6493,34.5175,21.4777,41.8937
[02/18 04:50:35] d2.utils.events INFO:  eta: 23:38:39  iter: 7499  total_loss: 37.63  loss_ce: 0  loss_mask: 0.9817  loss_dice: 2.656  loss_seg: 1.048  loss_ce_0: 0  loss_mask_0: 0.9923  loss_dice_0: 2.711  loss_ce_1: 0  loss_mask_1: 0.988  loss_dice_1: 2.645  loss_ce_2: 0  loss_mask_2: 0.9861  loss_dice_2: 2.645  loss_ce_3: 0  loss_mask_3: 0.9925  loss_dice_3: 2.636  loss_ce_4: 0  loss_mask_4: 0.9941  loss_dice_4: 2.635  loss_ce_5: 0  loss_mask_5: 0.9926  loss_dice_5: 2.645  loss_ce_6: 0  loss_mask_6: 0.9909  loss_dice_6: 2.64  loss_ce_7: 0  loss_mask_7: 0.9965  loss_dice_7: 2.64  loss_ce_8: 0  loss_mask_8: 0.9951  loss_dice_8: 2.642  time: 2.5087  data_time: 0.0392  lr: 8.8678e-05  max_mem: 6000M
[02/18 04:51:08] d2.utils.events INFO:  eta: 23:39:24  iter: 7519  total_loss: 37.51  loss_ce: 0  loss_mask: 1.015  loss_dice: 2.615  loss_seg: 0.7971  loss_ce_0: 0  loss_mask_0: 1.027  loss_dice_0: 2.665  loss_ce_1: 0  loss_mask_1: 1.012  loss_dice_1: 2.611  loss_ce_2: 0  loss_mask_2: 1.009  loss_dice_2: 2.607  loss_ce_3: 0  loss_mask_3: 1.014  loss_dice_3: 2.598  loss_ce_4: 0  loss_mask_4: 1.018  loss_dice_4: 2.597  loss_ce_5: 0  loss_mask_5: 1.023  loss_dice_5: 2.6  loss_ce_6: 0  loss_mask_6: 1.022  loss_dice_6: 2.606  loss_ce_7: 0  loss_mask_7: 1.023  loss_dice_7: 2.603  loss_ce_8: 0  loss_mask_8: 1.018  loss_dice_8: 2.608  time: 2.5065  data_time: 0.0376  lr: 8.8647e-05  max_mem: 6000M
[02/18 04:51:40] d2.utils.events INFO:  eta: 23:38:10  iter: 7539  total_loss: 38.06  loss_ce: 0  loss_mask: 0.9692  loss_dice: 2.638  loss_seg: 0.9127  loss_ce_0: 0  loss_mask_0: 0.9771  loss_dice_0: 2.696  loss_ce_1: 0  loss_mask_1: 0.9632  loss_dice_1: 2.643  loss_ce_2: 0  loss_mask_2: 0.9707  loss_dice_2: 2.63  loss_ce_3: 0  loss_mask_3: 0.9752  loss_dice_3: 2.619  loss_ce_4: 0  loss_mask_4: 0.9765  loss_dice_4: 2.622  loss_ce_5: 0  loss_mask_5: 0.9735  loss_dice_5: 2.626  loss_ce_6: 0  loss_mask_6: 0.972  loss_dice_6: 2.614  loss_ce_7: 0  loss_mask_7: 0.9733  loss_dice_7: 2.615  loss_ce_8: 0  loss_mask_8: 0.9729  loss_dice_8: 2.616  time: 2.5040  data_time: 0.0330  lr: 8.8617e-05  max_mem: 6000M
[02/18 04:52:13] d2.utils.events INFO:  eta: 23:38:13  iter: 7559  total_loss: 37.53  loss_ce: 0  loss_mask: 0.9799  loss_dice: 2.632  loss_seg: 1.218  loss_ce_0: 0  loss_mask_0: 0.9966  loss_dice_0: 2.709  loss_ce_1: 0  loss_mask_1: 0.9912  loss_dice_1: 2.631  loss_ce_2: 0  loss_mask_2: 0.9931  loss_dice_2: 2.613  loss_ce_3: 0  loss_mask_3: 0.995  loss_dice_3: 2.609  loss_ce_4: 0  loss_mask_4: 1.001  loss_dice_4: 2.609  loss_ce_5: 0  loss_mask_5: 1.003  loss_dice_5: 2.613  loss_ce_6: 0  loss_mask_6: 0.9986  loss_dice_6: 2.613  loss_ce_7: 0  loss_mask_7: 0.9988  loss_dice_7: 2.619  loss_ce_8: 0  loss_mask_8: 0.9984  loss_dice_8: 2.619  time: 2.5018  data_time: 0.0328  lr: 8.8587e-05  max_mem: 6000M
[02/18 04:52:48] d2.utils.events INFO:  eta: 23:39:58  iter: 7579  total_loss: 37.24  loss_ce: 0  loss_mask: 0.998  loss_dice: 2.627  loss_seg: 0.8385  loss_ce_0: 0  loss_mask_0: 0.9913  loss_dice_0: 2.686  loss_ce_1: 0  loss_mask_1: 0.9982  loss_dice_1: 2.626  loss_ce_2: 0  loss_mask_2: 0.9964  loss_dice_2: 2.609  loss_ce_3: 0  loss_mask_3: 0.9965  loss_dice_3: 2.604  loss_ce_4: 0  loss_mask_4: 0.9949  loss_dice_4: 2.607  loss_ce_5: 0  loss_mask_5: 0.9963  loss_dice_5: 2.611  loss_ce_6: 0  loss_mask_6: 1  loss_dice_6: 2.605  loss_ce_7: 0  loss_mask_7: 0.9964  loss_dice_7: 2.608  loss_ce_8: 0  loss_mask_8: 1.002  loss_dice_8: 2.604  time: 2.4998  data_time: 0.0263  lr: 8.8556e-05  max_mem: 6000M
[02/18 04:53:21] d2.utils.events INFO:  eta: 23:38:27  iter: 7599  total_loss: 37.29  loss_ce: 0  loss_mask: 1.035  loss_dice: 2.656  loss_seg: 0.7065  loss_ce_0: 0  loss_mask_0: 1.057  loss_dice_0: 2.692  loss_ce_1: 0  loss_mask_1: 1.04  loss_dice_1: 2.645  loss_ce_2: 0  loss_mask_2: 1.039  loss_dice_2: 2.64  loss_ce_3: 0  loss_mask_3: 1.046  loss_dice_3: 2.631  loss_ce_4: 0  loss_mask_4: 1.041  loss_dice_4: 2.633  loss_ce_5: 0  loss_mask_5: 1.037  loss_dice_5: 2.639  loss_ce_6: 0  loss_mask_6: 1.037  loss_dice_6: 2.639  loss_ce_7: 0  loss_mask_7: 1.044  loss_dice_7: 2.631  loss_ce_8: 0  loss_mask_8: 1.038  loss_dice_8: 2.64  time: 2.4976  data_time: 0.0411  lr: 8.8526e-05  max_mem: 6000M
[02/18 04:53:55] d2.utils.events INFO:  eta: 23:37:54  iter: 7619  total_loss: 36.32  loss_ce: 0  loss_mask: 0.9898  loss_dice: 2.58  loss_seg: 0.8987  loss_ce_0: 0  loss_mask_0: 0.995  loss_dice_0: 2.634  loss_ce_1: 0  loss_mask_1: 0.9975  loss_dice_1: 2.566  loss_ce_2: 0  loss_mask_2: 0.9989  loss_dice_2: 2.558  loss_ce_3: 0  loss_mask_3: 0.9985  loss_dice_3: 2.55  loss_ce_4: 0  loss_mask_4: 1.004  loss_dice_4: 2.562  loss_ce_5: 0  loss_mask_5: 0.998  loss_dice_5: 2.558  loss_ce_6: 0  loss_mask_6: 0.9999  loss_dice_6: 2.556  loss_ce_7: 0  loss_mask_7: 0.9981  loss_dice_7: 2.563  loss_ce_8: 0  loss_mask_8: 0.9986  loss_dice_8: 2.556  time: 2.4955  data_time: 0.0334  lr: 8.8495e-05  max_mem: 6000M
[02/18 04:54:28] d2.utils.events INFO:  eta: 23:36:22  iter: 7639  total_loss: 36.78  loss_ce: 0  loss_mask: 1.008  loss_dice: 2.601  loss_seg: 0.9181  loss_ce_0: 0  loss_mask_0: 1.01  loss_dice_0: 2.615  loss_ce_1: 0  loss_mask_1: 1.01  loss_dice_1: 2.582  loss_ce_2: 0  loss_mask_2: 1.017  loss_dice_2: 2.581  loss_ce_3: 0  loss_mask_3: 1.021  loss_dice_3: 2.58  loss_ce_4: 0  loss_mask_4: 1.018  loss_dice_4: 2.579  loss_ce_5: 0  loss_mask_5: 1.013  loss_dice_5: 2.573  loss_ce_6: 0  loss_mask_6: 1.014  loss_dice_6: 2.577  loss_ce_7: 0  loss_mask_7: 1.014  loss_dice_7: 2.579  loss_ce_8: 0  loss_mask_8: 1.02  loss_dice_8: 2.58  time: 2.4932  data_time: 0.0233  lr: 8.8465e-05  max_mem: 6000M
[02/18 04:55:01] d2.utils.events INFO:  eta: 23:35:50  iter: 7659  total_loss: 34.86  loss_ce: 0  loss_mask: 0.9717  loss_dice: 2.448  loss_seg: 0.8262  loss_ce_0: 0  loss_mask_0: 0.9607  loss_dice_0: 2.525  loss_ce_1: 0  loss_mask_1: 0.9681  loss_dice_1: 2.451  loss_ce_2: 0  loss_mask_2: 0.97  loss_dice_2: 2.425  loss_ce_3: 0  loss_mask_3: 0.9717  loss_dice_3: 2.414  loss_ce_4: 0  loss_mask_4: 0.9752  loss_dice_4: 2.424  loss_ce_5: 0  loss_mask_5: 0.9726  loss_dice_5: 2.421  loss_ce_6: 0  loss_mask_6: 0.9698  loss_dice_6: 2.424  loss_ce_7: 0  loss_mask_7: 0.9751  loss_dice_7: 2.421  loss_ce_8: 0  loss_mask_8: 0.9753  loss_dice_8: 2.43  time: 2.4910  data_time: 0.0302  lr: 8.8434e-05  max_mem: 6000M
[02/18 04:55:33] d2.utils.events INFO:  eta: 23:37:15  iter: 7679  total_loss: 35.23  loss_ce: 0  loss_mask: 0.9562  loss_dice: 2.523  loss_seg: 0.8178  loss_ce_0: 0  loss_mask_0: 0.9579  loss_dice_0: 2.588  loss_ce_1: 0  loss_mask_1: 0.9587  loss_dice_1: 2.504  loss_ce_2: 0  loss_mask_2: 0.9607  loss_dice_2: 2.498  loss_ce_3: 0  loss_mask_3: 0.9683  loss_dice_3: 2.495  loss_ce_4: 0  loss_mask_4: 0.9618  loss_dice_4: 2.494  loss_ce_5: 0  loss_mask_5: 0.9679  loss_dice_5: 2.497  loss_ce_6: 0  loss_mask_6: 0.9631  loss_dice_6: 2.491  loss_ce_7: 0  loss_mask_7: 0.9679  loss_dice_7: 2.498  loss_ce_8: 0  loss_mask_8: 0.9642  loss_dice_8: 2.497  time: 2.4887  data_time: 0.0302  lr: 8.8404e-05  max_mem: 6000M
[02/18 04:56:07] d2.utils.events INFO:  eta: 23:34:51  iter: 7699  total_loss: 34.51  loss_ce: 0  loss_mask: 0.9666  loss_dice: 2.4  loss_seg: 0.8917  loss_ce_0: 0  loss_mask_0: 0.9774  loss_dice_0: 2.486  loss_ce_1: 0  loss_mask_1: 0.9668  loss_dice_1: 2.394  loss_ce_2: 0  loss_mask_2: 0.9711  loss_dice_2: 2.386  loss_ce_3: 0  loss_mask_3: 0.9803  loss_dice_3: 2.383  loss_ce_4: 0  loss_mask_4: 0.977  loss_dice_4: 2.379  loss_ce_5: 0  loss_mask_5: 0.9743  loss_dice_5: 2.385  loss_ce_6: 0  loss_mask_6: 0.9798  loss_dice_6: 2.387  loss_ce_7: 0  loss_mask_7: 0.9817  loss_dice_7: 2.384  loss_ce_8: 0  loss_mask_8: 0.9795  loss_dice_8: 2.383  time: 2.4866  data_time: 0.0327  lr: 8.8374e-05  max_mem: 6000M
[02/18 04:56:38] d2.utils.events INFO:  eta: 23:33:32  iter: 7719  total_loss: 38.41  loss_ce: 0  loss_mask: 1.019  loss_dice: 2.777  loss_seg: 0.9604  loss_ce_0: 0  loss_mask_0: 1.022  loss_dice_0: 2.831  loss_ce_1: 0  loss_mask_1: 1.022  loss_dice_1: 2.771  loss_ce_2: 0  loss_mask_2: 1.021  loss_dice_2: 2.765  loss_ce_3: 0  loss_mask_3: 1.024  loss_dice_3: 2.753  loss_ce_4: 0  loss_mask_4: 1.031  loss_dice_4: 2.759  loss_ce_5: 0  loss_mask_5: 1.025  loss_dice_5: 2.758  loss_ce_6: 0  loss_mask_6: 1.025  loss_dice_6: 2.753  loss_ce_7: 0  loss_mask_7: 1.02  loss_dice_7: 2.757  loss_ce_8: 0  loss_mask_8: 1.016  loss_dice_8: 2.763  time: 2.4842  data_time: 0.0260  lr: 8.8343e-05  max_mem: 6000M
[02/18 04:57:12] d2.utils.events INFO:  eta: 23:34:39  iter: 7739  total_loss: 37.25  loss_ce: 0  loss_mask: 1.01  loss_dice: 2.638  loss_seg: 0.7676  loss_ce_0: 0  loss_mask_0: 1.026  loss_dice_0: 2.655  loss_ce_1: 0  loss_mask_1: 1.022  loss_dice_1: 2.627  loss_ce_2: 0  loss_mask_2: 1.019  loss_dice_2: 2.617  loss_ce_3: 0  loss_mask_3: 1.022  loss_dice_3: 2.613  loss_ce_4: 0  loss_mask_4: 1.023  loss_dice_4: 2.613  loss_ce_5: 0  loss_mask_5: 1.017  loss_dice_5: 2.616  loss_ce_6: 0  loss_mask_6: 1.019  loss_dice_6: 2.613  loss_ce_7: 0  loss_mask_7: 1.022  loss_dice_7: 2.609  loss_ce_8: 0  loss_mask_8: 1.019  loss_dice_8: 2.619  time: 2.4821  data_time: 0.0336  lr: 8.8313e-05  max_mem: 6000M
[02/18 04:57:45] d2.utils.events INFO:  eta: 23:35:05  iter: 7759  total_loss: 37.03  loss_ce: 0  loss_mask: 0.9822  loss_dice: 2.649  loss_seg: 0.9474  loss_ce_0: 0  loss_mask_0: 0.9833  loss_dice_0: 2.712  loss_ce_1: 0  loss_mask_1: 0.9853  loss_dice_1: 2.635  loss_ce_2: 0  loss_mask_2: 0.9892  loss_dice_2: 2.63  loss_ce_3: 0  loss_mask_3: 0.9846  loss_dice_3: 2.632  loss_ce_4: 0  loss_mask_4: 0.9882  loss_dice_4: 2.626  loss_ce_5: 0  loss_mask_5: 0.9879  loss_dice_5: 2.631  loss_ce_6: 0  loss_mask_6: 0.9845  loss_dice_6: 2.636  loss_ce_7: 0  loss_mask_7: 0.9847  loss_dice_7: 2.634  loss_ce_8: 0  loss_mask_8: 0.9887  loss_dice_8: 2.636  time: 2.4800  data_time: 0.0289  lr: 8.8282e-05  max_mem: 6000M
[02/18 04:58:20] d2.utils.events INFO:  eta: 23:36:46  iter: 7779  total_loss: 38.12  loss_ce: 0  loss_mask: 1.014  loss_dice: 2.644  loss_seg: 1.123  loss_ce_0: 0  loss_mask_0: 1.023  loss_dice_0: 2.708  loss_ce_1: 0  loss_mask_1: 1.028  loss_dice_1: 2.646  loss_ce_2: 0  loss_mask_2: 1.027  loss_dice_2: 2.63  loss_ce_3: 0  loss_mask_3: 1.033  loss_dice_3: 2.622  loss_ce_4: 0  loss_mask_4: 1.034  loss_dice_4: 2.626  loss_ce_5: 0  loss_mask_5: 1.04  loss_dice_5: 2.62  loss_ce_6: 0  loss_mask_6: 1.039  loss_dice_6: 2.616  loss_ce_7: 0  loss_mask_7: 1.037  loss_dice_7: 2.621  loss_ce_8: 0  loss_mask_8: 1.036  loss_dice_8: 2.62  time: 2.4782  data_time: 0.0314  lr: 8.8252e-05  max_mem: 6000M
[02/18 04:58:54] d2.utils.events INFO:  eta: 23:34:41  iter: 7799  total_loss: 37.85  loss_ce: 0  loss_mask: 0.9865  loss_dice: 2.689  loss_seg: 1.018  loss_ce_0: 0  loss_mask_0: 0.9894  loss_dice_0: 2.73  loss_ce_1: 0  loss_mask_1: 0.9894  loss_dice_1: 2.686  loss_ce_2: 0  loss_mask_2: 0.9859  loss_dice_2: 2.67  loss_ce_3: 0  loss_mask_3: 0.9854  loss_dice_3: 2.668  loss_ce_4: 0  loss_mask_4: 0.9869  loss_dice_4: 2.671  loss_ce_5: 0  loss_mask_5: 0.9843  loss_dice_5: 2.673  loss_ce_6: 0  loss_mask_6: 0.9873  loss_dice_6: 2.67  loss_ce_7: 0  loss_mask_7: 0.9864  loss_dice_7: 2.672  loss_ce_8: 0  loss_mask_8: 0.9868  loss_dice_8: 2.669  time: 2.4761  data_time: 0.0263  lr: 8.8222e-05  max_mem: 6000M
[02/18 04:59:30] d2.utils.events INFO:  eta: 23:34:40  iter: 7819  total_loss: 36.51  loss_ce: 0  loss_mask: 0.9683  loss_dice: 2.576  loss_seg: 0.896  loss_ce_0: 0  loss_mask_0: 0.9772  loss_dice_0: 2.63  loss_ce_1: 0  loss_mask_1: 0.9626  loss_dice_1: 2.558  loss_ce_2: 0  loss_mask_2: 0.957  loss_dice_2: 2.556  loss_ce_3: 0  loss_mask_3: 0.9575  loss_dice_3: 2.552  loss_ce_4: 0  loss_mask_4: 0.962  loss_dice_4: 2.55  loss_ce_5: 0  loss_mask_5: 0.962  loss_dice_5: 2.552  loss_ce_6: 0  loss_mask_6: 0.9678  loss_dice_6: 2.552  loss_ce_7: 0  loss_mask_7: 0.9716  loss_dice_7: 2.556  loss_ce_8: 0  loss_mask_8: 0.971  loss_dice_8: 2.556  time: 2.4743  data_time: 0.0256  lr: 8.8191e-05  max_mem: 6000M
[02/18 05:00:05] d2.utils.events INFO:  eta: 23:39:22  iter: 7839  total_loss: 36.73  loss_ce: 0  loss_mask: 1.026  loss_dice: 2.551  loss_seg: 0.9473  loss_ce_0: 0  loss_mask_0: 1.024  loss_dice_0: 2.617  loss_ce_1: 0  loss_mask_1: 1.022  loss_dice_1: 2.548  loss_ce_2: 0  loss_mask_2: 1.029  loss_dice_2: 2.528  loss_ce_3: 0  loss_mask_3: 1.025  loss_dice_3: 2.528  loss_ce_4: 0  loss_mask_4: 1.025  loss_dice_4: 2.53  loss_ce_5: 0  loss_mask_5: 1.031  loss_dice_5: 2.527  loss_ce_6: 0  loss_mask_6: 1.033  loss_dice_6: 2.527  loss_ce_7: 0  loss_mask_7: 1.03  loss_dice_7: 2.529  loss_ce_8: 0  loss_mask_8: 1.034  loss_dice_8: 2.535  time: 2.4725  data_time: 0.0275  lr: 8.8161e-05  max_mem: 6000M
[02/18 05:00:37] d2.utils.events INFO:  eta: 23:37:45  iter: 7859  total_loss: 36.72  loss_ce: 0  loss_mask: 0.9926  loss_dice: 2.569  loss_seg: 0.9106  loss_ce_0: 0  loss_mask_0: 0.9982  loss_dice_0: 2.616  loss_ce_1: 0  loss_mask_1: 0.9943  loss_dice_1: 2.56  loss_ce_2: 0  loss_mask_2: 1.001  loss_dice_2: 2.543  loss_ce_3: 0  loss_mask_3: 1.009  loss_dice_3: 2.539  loss_ce_4: 0  loss_mask_4: 1.009  loss_dice_4: 2.542  loss_ce_5: 0  loss_mask_5: 1.01  loss_dice_5: 2.546  loss_ce_6: 0  loss_mask_6: 1.007  loss_dice_6: 2.552  loss_ce_7: 0  loss_mask_7: 1.009  loss_dice_7: 2.549  loss_ce_8: 0  loss_mask_8: 1.013  loss_dice_8: 2.549  time: 2.4703  data_time: 0.0323  lr: 8.813e-05  max_mem: 6000M
[02/18 05:01:10] d2.utils.events INFO:  eta: 23:38:16  iter: 7879  total_loss: 37.1  loss_ce: 0  loss_mask: 0.9987  loss_dice: 2.611  loss_seg: 0.9181  loss_ce_0: 0  loss_mask_0: 1.02  loss_dice_0: 2.663  loss_ce_1: 0  loss_mask_1: 1.004  loss_dice_1: 2.605  loss_ce_2: 0  loss_mask_2: 0.9986  loss_dice_2: 2.606  loss_ce_3: 0  loss_mask_3: 1.002  loss_dice_3: 2.589  loss_ce_4: 0  loss_mask_4: 1.005  loss_dice_4: 2.588  loss_ce_5: 0  loss_mask_5: 1.009  loss_dice_5: 2.595  loss_ce_6: 0  loss_mask_6: 0.999  loss_dice_6: 2.601  loss_ce_7: 0  loss_mask_7: 1.009  loss_dice_7: 2.589  loss_ce_8: 0  loss_mask_8: 1.007  loss_dice_8: 2.594  time: 2.4682  data_time: 0.0280  lr: 8.81e-05  max_mem: 6000M
[02/18 05:01:42] d2.utils.events INFO:  eta: 23:37:59  iter: 7899  total_loss: 36.02  loss_ce: 0  loss_mask: 0.9407  loss_dice: 2.545  loss_seg: 0.9772  loss_ce_0: 0  loss_mask_0: 0.9418  loss_dice_0: 2.619  loss_ce_1: 0  loss_mask_1: 0.9453  loss_dice_1: 2.534  loss_ce_2: 0  loss_mask_2: 0.9487  loss_dice_2: 2.524  loss_ce_3: 0  loss_mask_3: 0.9536  loss_dice_3: 2.519  loss_ce_4: 0  loss_mask_4: 0.9505  loss_dice_4: 2.522  loss_ce_5: 0  loss_mask_5: 0.9511  loss_dice_5: 2.526  loss_ce_6: 0  loss_mask_6: 0.9521  loss_dice_6: 2.518  loss_ce_7: 0  loss_mask_7: 0.9503  loss_dice_7: 2.521  loss_ce_8: 0  loss_mask_8: 0.9529  loss_dice_8: 2.521  time: 2.4660  data_time: 0.0356  lr: 8.8069e-05  max_mem: 6000M
[02/18 05:02:14] d2.utils.events INFO:  eta: 23:38:20  iter: 7919  total_loss: 36.15  loss_ce: 0  loss_mask: 0.996  loss_dice: 2.57  loss_seg: 0.9649  loss_ce_0: 0  loss_mask_0: 0.986  loss_dice_0: 2.617  loss_ce_1: 0  loss_mask_1: 0.9949  loss_dice_1: 2.553  loss_ce_2: 0  loss_mask_2: 1.001  loss_dice_2: 2.548  loss_ce_3: 0  loss_mask_3: 1.006  loss_dice_3: 2.55  loss_ce_4: 0  loss_mask_4: 1.009  loss_dice_4: 2.544  loss_ce_5: 0  loss_mask_5: 1.006  loss_dice_5: 2.54  loss_ce_6: 0  loss_mask_6: 1.002  loss_dice_6: 2.547  loss_ce_7: 0  loss_mask_7: 0.9986  loss_dice_7: 2.547  loss_ce_8: 0  loss_mask_8: 1.001  loss_dice_8: 2.547  time: 2.4638  data_time: 0.0313  lr: 8.8039e-05  max_mem: 6000M
[02/18 05:02:47] d2.utils.events INFO:  eta: 23:38:39  iter: 7939  total_loss: 36.26  loss_ce: 0  loss_mask: 0.9937  loss_dice: 2.503  loss_seg: 0.8272  loss_ce_0: 0  loss_mask_0: 1.007  loss_dice_0: 2.542  loss_ce_1: 0  loss_mask_1: 0.9932  loss_dice_1: 2.495  loss_ce_2: 0  loss_mask_2: 0.9973  loss_dice_2: 2.486  loss_ce_3: 0  loss_mask_3: 0.9942  loss_dice_3: 2.48  loss_ce_4: 0  loss_mask_4: 0.9923  loss_dice_4: 2.484  loss_ce_5: 0  loss_mask_5: 0.9977  loss_dice_5: 2.483  loss_ce_6: 0  loss_mask_6: 0.9987  loss_dice_6: 2.483  loss_ce_7: 0  loss_mask_7: 0.9974  loss_dice_7: 2.486  loss_ce_8: 0  loss_mask_8: 0.9939  loss_dice_8: 2.489  time: 2.4617  data_time: 0.0302  lr: 8.8009e-05  max_mem: 6000M
[02/18 05:03:19] d2.utils.events INFO:  eta: 23:36:45  iter: 7959  total_loss: 38.55  loss_ce: 0  loss_mask: 1.014  loss_dice: 2.718  loss_seg: 0.8164  loss_ce_0: 0  loss_mask_0: 1.022  loss_dice_0: 2.747  loss_ce_1: 0  loss_mask_1: 1.016  loss_dice_1: 2.703  loss_ce_2: 0  loss_mask_2: 1.021  loss_dice_2: 2.693  loss_ce_3: 0  loss_mask_3: 1.026  loss_dice_3: 2.688  loss_ce_4: 0  loss_mask_4: 1.026  loss_dice_4: 2.696  loss_ce_5: 0  loss_mask_5: 1.025  loss_dice_5: 2.703  loss_ce_6: 0  loss_mask_6: 1.02  loss_dice_6: 2.7  loss_ce_7: 0  loss_mask_7: 1.021  loss_dice_7: 2.698  loss_ce_8: 0  loss_mask_8: 1.024  loss_dice_8: 2.693  time: 2.4596  data_time: 0.0300  lr: 8.7978e-05  max_mem: 6000M
[02/18 05:03:50] d2.utils.events INFO:  eta: 23:35:36  iter: 7979  total_loss: 37.17  loss_ce: 0  loss_mask: 0.9578  loss_dice: 2.611  loss_seg: 0.918  loss_ce_0: 0  loss_mask_0: 0.9542  loss_dice_0: 2.652  loss_ce_1: 0  loss_mask_1: 0.9685  loss_dice_1: 2.603  loss_ce_2: 0  loss_mask_2: 0.9695  loss_dice_2: 2.598  loss_ce_3: 0  loss_mask_3: 0.9739  loss_dice_3: 2.584  loss_ce_4: 0  loss_mask_4: 0.9748  loss_dice_4: 2.592  loss_ce_5: 0  loss_mask_5: 0.9704  loss_dice_5: 2.591  loss_ce_6: 0  loss_mask_6: 0.9721  loss_dice_6: 2.592  loss_ce_7: 0  loss_mask_7: 0.971  loss_dice_7: 2.592  loss_ce_8: 0  loss_mask_8: 0.9714  loss_dice_8: 2.596  time: 2.4572  data_time: 0.0370  lr: 8.7948e-05  max_mem: 6000M
[02/18 05:04:24] d2.utils.events INFO:  eta: 23:36:15  iter: 7999  total_loss: 37.26  loss_ce: 0  loss_mask: 1.013  loss_dice: 2.556  loss_seg: 1.099  loss_ce_0: 0  loss_mask_0: 1.028  loss_dice_0: 2.588  loss_ce_1: 0  loss_mask_1: 1.009  loss_dice_1: 2.561  loss_ce_2: 0  loss_mask_2: 1.01  loss_dice_2: 2.552  loss_ce_3: 0  loss_mask_3: 1.014  loss_dice_3: 2.535  loss_ce_4: 0  loss_mask_4: 1.017  loss_dice_4: 2.534  loss_ce_5: 0  loss_mask_5: 1.016  loss_dice_5: 2.531  loss_ce_6: 0  loss_mask_6: 1.02  loss_dice_6: 2.536  loss_ce_7: 0  loss_mask_7: 1.017  loss_dice_7: 2.533  loss_ce_8: 0  loss_mask_8: 1.014  loss_dice_8: 2.546  time: 2.4554  data_time: 0.0372  lr: 8.7917e-05  max_mem: 6000M
[02/18 05:04:59] d2.utils.events INFO:  eta: 23:36:28  iter: 8019  total_loss: 37.79  loss_ce: 0  loss_mask: 0.9717  loss_dice: 2.62  loss_seg: 0.793  loss_ce_0: 0  loss_mask_0: 0.9683  loss_dice_0: 2.668  loss_ce_1: 0  loss_mask_1: 0.9722  loss_dice_1: 2.622  loss_ce_2: 0  loss_mask_2: 0.9697  loss_dice_2: 2.604  loss_ce_3: 0  loss_mask_3: 0.977  loss_dice_3: 2.602  loss_ce_4: 0  loss_mask_4: 0.9697  loss_dice_4: 2.611  loss_ce_5: 0  loss_mask_5: 0.969  loss_dice_5: 2.614  loss_ce_6: 0  loss_mask_6: 0.9727  loss_dice_6: 2.613  loss_ce_7: 0  loss_mask_7: 0.968  loss_dice_7: 2.611  loss_ce_8: 0  loss_mask_8: 0.9727  loss_dice_8: 2.608  time: 2.4535  data_time: 0.0286  lr: 8.7887e-05  max_mem: 6000M
[02/18 05:05:29] d2.utils.events INFO:  eta: 23:31:53  iter: 8039  total_loss: 38.76  loss_ce: 0  loss_mask: 1.011  loss_dice: 2.777  loss_seg: 0.9854  loss_ce_0: 0  loss_mask_0: 1.005  loss_dice_0: 2.807  loss_ce_1: 0  loss_mask_1: 1.007  loss_dice_1: 2.78  loss_ce_2: 0  loss_mask_2: 1.014  loss_dice_2: 2.768  loss_ce_3: 0  loss_mask_3: 1.014  loss_dice_3: 2.761  loss_ce_4: 0  loss_mask_4: 1.01  loss_dice_4: 2.754  loss_ce_5: 0  loss_mask_5: 1.009  loss_dice_5: 2.759  loss_ce_6: 0  loss_mask_6: 1.009  loss_dice_6: 2.761  loss_ce_7: 0  loss_mask_7: 1.01  loss_dice_7: 2.757  loss_ce_8: 0  loss_mask_8: 1.014  loss_dice_8: 2.764  time: 2.4512  data_time: 0.0297  lr: 8.7856e-05  max_mem: 6000M
[02/18 05:06:00] d2.utils.events INFO:  eta: 23:26:58  iter: 8059  total_loss: 38.21  loss_ce: 0  loss_mask: 1.03  loss_dice: 2.664  loss_seg: 1.018  loss_ce_0: 0  loss_mask_0: 1.04  loss_dice_0: 2.707  loss_ce_1: 0  loss_mask_1: 1.02  loss_dice_1: 2.645  loss_ce_2: 0  loss_mask_2: 1.028  loss_dice_2: 2.636  loss_ce_3: 0  loss_mask_3: 1.026  loss_dice_3: 2.629  loss_ce_4: 0  loss_mask_4: 1.027  loss_dice_4: 2.638  loss_ce_5: 0  loss_mask_5: 1.029  loss_dice_5: 2.637  loss_ce_6: 0  loss_mask_6: 1.032  loss_dice_6: 2.633  loss_ce_7: 0  loss_mask_7: 1.033  loss_dice_7: 2.638  loss_ce_8: 0  loss_mask_8: 1.031  loss_dice_8: 2.643  time: 2.4490  data_time: 0.0327  lr: 8.7826e-05  max_mem: 6000M
[02/18 05:06:33] d2.utils.events INFO:  eta: 23:27:21  iter: 8079  total_loss: 37.76  loss_ce: 0  loss_mask: 0.948  loss_dice: 2.684  loss_seg: 1.238  loss_ce_0: 0  loss_mask_0: 0.9508  loss_dice_0: 2.759  loss_ce_1: 0  loss_mask_1: 0.9468  loss_dice_1: 2.676  loss_ce_2: 0  loss_mask_2: 0.949  loss_dice_2: 2.672  loss_ce_3: 0  loss_mask_3: 0.9562  loss_dice_3: 2.662  loss_ce_4: 0  loss_mask_4: 0.958  loss_dice_4: 2.664  loss_ce_5: 0  loss_mask_5: 0.9541  loss_dice_5: 2.664  loss_ce_6: 0  loss_mask_6: 0.9573  loss_dice_6: 2.661  loss_ce_7: 0  loss_mask_7: 0.9572  loss_dice_7: 2.662  loss_ce_8: 0  loss_mask_8: 0.9613  loss_dice_8: 2.663  time: 2.4469  data_time: 0.0353  lr: 8.7796e-05  max_mem: 6000M
[02/18 05:07:06] d2.utils.events INFO:  eta: 23:29:13  iter: 8099  total_loss: 37.23  loss_ce: 0  loss_mask: 0.9737  loss_dice: 2.646  loss_seg: 0.9209  loss_ce_0: 0  loss_mask_0: 1.004  loss_dice_0: 2.68  loss_ce_1: 0  loss_mask_1: 0.9786  loss_dice_1: 2.622  loss_ce_2: 0  loss_mask_2: 0.976  loss_dice_2: 2.625  loss_ce_3: 0  loss_mask_3: 0.9698  loss_dice_3: 2.619  loss_ce_4: 0  loss_mask_4: 0.9716  loss_dice_4: 2.623  loss_ce_5: 0  loss_mask_5: 0.9746  loss_dice_5: 2.621  loss_ce_6: 0  loss_mask_6: 0.9751  loss_dice_6: 2.62  loss_ce_7: 0  loss_mask_7: 0.9793  loss_dice_7: 2.628  loss_ce_8: 0  loss_mask_8: 0.9792  loss_dice_8: 2.621  time: 2.4449  data_time: 0.0274  lr: 8.7765e-05  max_mem: 6000M
[02/18 05:07:42] d2.utils.events INFO:  eta: 23:30:01  iter: 8119  total_loss: 36.53  loss_ce: 0  loss_mask: 0.9461  loss_dice: 2.606  loss_seg: 0.8654  loss_ce_0: 0  loss_mask_0: 0.9521  loss_dice_0: 2.647  loss_ce_1: 0  loss_mask_1: 0.94  loss_dice_1: 2.615  loss_ce_2: 0  loss_mask_2: 0.9416  loss_dice_2: 2.603  loss_ce_3: 0  loss_mask_3: 0.9462  loss_dice_3: 2.592  loss_ce_4: 0  loss_mask_4: 0.9525  loss_dice_4: 2.589  loss_ce_5: 0  loss_mask_5: 0.953  loss_dice_5: 2.586  loss_ce_6: 0  loss_mask_6: 0.9562  loss_dice_6: 2.586  loss_ce_7: 0  loss_mask_7: 0.952  loss_dice_7: 2.585  loss_ce_8: 0  loss_mask_8: 0.9482  loss_dice_8: 2.588  time: 2.4433  data_time: 0.0546  lr: 8.7735e-05  max_mem: 6000M
[02/18 05:08:13] d2.utils.events INFO:  eta: 23:29:28  iter: 8139  total_loss: 36.78  loss_ce: 0  loss_mask: 1.006  loss_dice: 2.604  loss_seg: 0.7837  loss_ce_0: 0  loss_mask_0: 1.013  loss_dice_0: 2.672  loss_ce_1: 0  loss_mask_1: 1.006  loss_dice_1: 2.596  loss_ce_2: 0  loss_mask_2: 1.011  loss_dice_2: 2.581  loss_ce_3: 0  loss_mask_3: 1.016  loss_dice_3: 2.568  loss_ce_4: 0  loss_mask_4: 1.011  loss_dice_4: 2.578  loss_ce_5: 0  loss_mask_5: 1.01  loss_dice_5: 2.59  loss_ce_6: 0  loss_mask_6: 1.01  loss_dice_6: 2.573  loss_ce_7: 0  loss_mask_7: 1.01  loss_dice_7: 2.578  loss_ce_8: 0  loss_mask_8: 1.009  loss_dice_8: 2.589  time: 2.4411  data_time: 0.0360  lr: 8.7704e-05  max_mem: 6000M
[02/18 05:08:45] d2.utils.events INFO:  eta: 23:28:37  iter: 8159  total_loss: 37.76  loss_ce: 0  loss_mask: 1.017  loss_dice: 2.659  loss_seg: 0.9474  loss_ce_0: 0  loss_mask_0: 1.026  loss_dice_0: 2.707  loss_ce_1: 0  loss_mask_1: 1.021  loss_dice_1: 2.653  loss_ce_2: 0  loss_mask_2: 1.02  loss_dice_2: 2.641  loss_ce_3: 0  loss_mask_3: 1.028  loss_dice_3: 2.632  loss_ce_4: 0  loss_mask_4: 1.031  loss_dice_4: 2.632  loss_ce_5: 0  loss_mask_5: 1.034  loss_dice_5: 2.63  loss_ce_6: 0  loss_mask_6: 1.03  loss_dice_6: 2.639  loss_ce_7: 0  loss_mask_7: 1.034  loss_dice_7: 2.64  loss_ce_8: 0  loss_mask_8: 1.028  loss_dice_8: 2.64  time: 2.4391  data_time: 0.0347  lr: 8.7674e-05  max_mem: 6000M
[02/18 05:09:18] d2.utils.events INFO:  eta: 23:28:05  iter: 8179  total_loss: 38.47  loss_ce: 0  loss_mask: 0.9565  loss_dice: 2.783  loss_seg: 1.074  loss_ce_0: 0  loss_mask_0: 0.9487  loss_dice_0: 2.804  loss_ce_1: 0  loss_mask_1: 0.9602  loss_dice_1: 2.782  loss_ce_2: 0  loss_mask_2: 0.9618  loss_dice_2: 2.773  loss_ce_3: 0  loss_mask_3: 0.964  loss_dice_3: 2.773  loss_ce_4: 0  loss_mask_4: 0.9641  loss_dice_4: 2.769  loss_ce_5: 0  loss_mask_5: 0.967  loss_dice_5: 2.771  loss_ce_6: 0  loss_mask_6: 0.9665  loss_dice_6: 2.768  loss_ce_7: 0  loss_mask_7: 0.9705  loss_dice_7: 2.772  loss_ce_8: 0  loss_mask_8: 0.9726  loss_dice_8: 2.764  time: 2.4372  data_time: 0.0275  lr: 8.7643e-05  max_mem: 6000M
[02/18 05:09:51] d2.utils.events INFO:  eta: 23:27:50  iter: 8199  total_loss: 35.65  loss_ce: 0  loss_mask: 0.9271  loss_dice: 2.533  loss_seg: 0.9109  loss_ce_0: 0  loss_mask_0: 0.9266  loss_dice_0: 2.611  loss_ce_1: 0  loss_mask_1: 0.9318  loss_dice_1: 2.533  loss_ce_2: 0  loss_mask_2: 0.9419  loss_dice_2: 2.515  loss_ce_3: 0  loss_mask_3: 0.9505  loss_dice_3: 2.508  loss_ce_4: 0  loss_mask_4: 0.9509  loss_dice_4: 2.507  loss_ce_5: 0  loss_mask_5: 0.951  loss_dice_5: 2.507  loss_ce_6: 0  loss_mask_6: 0.9515  loss_dice_6: 2.509  loss_ce_7: 0  loss_mask_7: 0.9439  loss_dice_7: 2.516  loss_ce_8: 0  loss_mask_8: 0.9408  loss_dice_8: 2.515  time: 2.4353  data_time: 0.0266  lr: 8.7613e-05  max_mem: 6000M
[02/18 05:10:25] d2.utils.events INFO:  eta: 23:27:48  iter: 8219  total_loss: 38.96  loss_ce: 0  loss_mask: 1.005  loss_dice: 2.725  loss_seg: 1.464  loss_ce_0: 0  loss_mask_0: 0.9964  loss_dice_0: 2.782  loss_ce_1: 0  loss_mask_1: 1.001  loss_dice_1: 2.723  loss_ce_2: 0  loss_mask_2: 1.006  loss_dice_2: 2.712  loss_ce_3: 0  loss_mask_3: 1.007  loss_dice_3: 2.706  loss_ce_4: 0  loss_mask_4: 1.009  loss_dice_4: 2.699  loss_ce_5: 0  loss_mask_5: 1.006  loss_dice_5: 2.701  loss_ce_6: 0  loss_mask_6: 1.005  loss_dice_6: 2.7  loss_ce_7: 0  loss_mask_7: 1.012  loss_dice_7: 2.698  loss_ce_8: 0  loss_mask_8: 1.015  loss_dice_8: 2.701  time: 2.4334  data_time: 0.0319  lr: 8.7582e-05  max_mem: 6000M
[02/18 05:10:58] d2.utils.events INFO:  eta: 23:26:45  iter: 8239  total_loss: 36.23  loss_ce: 0  loss_mask: 0.963  loss_dice: 2.541  loss_seg: 0.9826  loss_ce_0: 0  loss_mask_0: 0.9607  loss_dice_0: 2.623  loss_ce_1: 0  loss_mask_1: 0.9718  loss_dice_1: 2.53  loss_ce_2: 0  loss_mask_2: 0.9724  loss_dice_2: 2.524  loss_ce_3: 0  loss_mask_3: 0.9687  loss_dice_3: 2.519  loss_ce_4: 0  loss_mask_4: 0.9646  loss_dice_4: 2.521  loss_ce_5: 0  loss_mask_5: 0.9654  loss_dice_5: 2.53  loss_ce_6: 0  loss_mask_6: 0.9671  loss_dice_6: 2.525  loss_ce_7: 0  loss_mask_7: 0.9684  loss_dice_7: 2.527  loss_ce_8: 0  loss_mask_8: 0.9683  loss_dice_8: 2.53  time: 2.4315  data_time: 0.0307  lr: 8.7552e-05  max_mem: 6000M
[02/18 05:11:30] d2.utils.events INFO:  eta: 23:27:04  iter: 8259  total_loss: 37.44  loss_ce: 0  loss_mask: 0.9978  loss_dice: 2.61  loss_seg: 0.8592  loss_ce_0: 0  loss_mask_0: 1.027  loss_dice_0: 2.666  loss_ce_1: 0  loss_mask_1: 1.001  loss_dice_1: 2.614  loss_ce_2: 0  loss_mask_2: 1.003  loss_dice_2: 2.601  loss_ce_3: 0  loss_mask_3: 1.006  loss_dice_3: 2.59  loss_ce_4: 0  loss_mask_4: 1.011  loss_dice_4: 2.588  loss_ce_5: 0  loss_mask_5: 1.009  loss_dice_5: 2.591  loss_ce_6: 0  loss_mask_6: 1.006  loss_dice_6: 2.586  loss_ce_7: 0  loss_mask_7: 1.006  loss_dice_7: 2.59  loss_ce_8: 0  loss_mask_8: 1.01  loss_dice_8: 2.599  time: 2.4295  data_time: 0.0385  lr: 8.7522e-05  max_mem: 6000M
[02/18 05:12:03] d2.utils.events INFO:  eta: 23:26:10  iter: 8279  total_loss: 35.32  loss_ce: 0  loss_mask: 0.9192  loss_dice: 2.482  loss_seg: 0.9955  loss_ce_0: 0  loss_mask_0: 0.9254  loss_dice_0: 2.563  loss_ce_1: 0  loss_mask_1: 0.927  loss_dice_1: 2.481  loss_ce_2: 0  loss_mask_2: 0.9265  loss_dice_2: 2.468  loss_ce_3: 0  loss_mask_3: 0.9283  loss_dice_3: 2.463  loss_ce_4: 0  loss_mask_4: 0.9304  loss_dice_4: 2.469  loss_ce_5: 0  loss_mask_5: 0.9256  loss_dice_5: 2.474  loss_ce_6: 0  loss_mask_6: 0.9252  loss_dice_6: 2.462  loss_ce_7: 0  loss_mask_7: 0.9284  loss_dice_7: 2.472  loss_ce_8: 0  loss_mask_8: 0.9239  loss_dice_8: 2.465  time: 2.4276  data_time: 0.0301  lr: 8.7491e-05  max_mem: 6000M
[02/18 05:12:35] d2.utils.events INFO:  eta: 23:25:59  iter: 8299  total_loss: 37.13  loss_ce: 0  loss_mask: 0.9853  loss_dice: 2.654  loss_seg: 1.055  loss_ce_0: 0  loss_mask_0: 0.9929  loss_dice_0: 2.694  loss_ce_1: 0  loss_mask_1: 0.9834  loss_dice_1: 2.64  loss_ce_2: 0  loss_mask_2: 0.9897  loss_dice_2: 2.631  loss_ce_3: 0  loss_mask_3: 0.9928  loss_dice_3: 2.629  loss_ce_4: 0  loss_mask_4: 0.993  loss_dice_4: 2.631  loss_ce_5: 0  loss_mask_5: 0.992  loss_dice_5: 2.632  loss_ce_6: 0  loss_mask_6: 0.9995  loss_dice_6: 2.635  loss_ce_7: 0  loss_mask_7: 0.9991  loss_dice_7: 2.629  loss_ce_8: 0  loss_mask_8: 0.9988  loss_dice_8: 2.63  time: 2.4256  data_time: 0.0309  lr: 8.7461e-05  max_mem: 6000M
[02/18 05:13:08] d2.utils.events INFO:  eta: 23:25:05  iter: 8319  total_loss: 36.05  loss_ce: 0  loss_mask: 0.954  loss_dice: 2.547  loss_seg: 0.8102  loss_ce_0: 0  loss_mask_0: 0.9475  loss_dice_0: 2.605  loss_ce_1: 0  loss_mask_1: 0.9496  loss_dice_1: 2.527  loss_ce_2: 0  loss_mask_2: 0.9524  loss_dice_2: 2.529  loss_ce_3: 0  loss_mask_3: 0.9525  loss_dice_3: 2.519  loss_ce_4: 0  loss_mask_4: 0.9522  loss_dice_4: 2.524  loss_ce_5: 0  loss_mask_5: 0.9526  loss_dice_5: 2.529  loss_ce_6: 0  loss_mask_6: 0.95  loss_dice_6: 2.528  loss_ce_7: 0  loss_mask_7: 0.9545  loss_dice_7: 2.532  loss_ce_8: 0  loss_mask_8: 0.9524  loss_dice_8: 2.532  time: 2.4237  data_time: 0.0288  lr: 8.743e-05  max_mem: 6000M
[02/18 05:13:41] d2.utils.events INFO:  eta: 23:23:25  iter: 8339  total_loss: 37.09  loss_ce: 0  loss_mask: 0.9615  loss_dice: 2.602  loss_seg: 1.29  loss_ce_0: 0  loss_mask_0: 0.9671  loss_dice_0: 2.642  loss_ce_1: 0  loss_mask_1: 0.9644  loss_dice_1: 2.594  loss_ce_2: 0  loss_mask_2: 0.9699  loss_dice_2: 2.58  loss_ce_3: 0  loss_mask_3: 0.9733  loss_dice_3: 2.573  loss_ce_4: 0  loss_mask_4: 0.9736  loss_dice_4: 2.572  loss_ce_5: 0  loss_mask_5: 0.9715  loss_dice_5: 2.579  loss_ce_6: 0  loss_mask_6: 0.9686  loss_dice_6: 2.575  loss_ce_7: 0  loss_mask_7: 0.969  loss_dice_7: 2.571  loss_ce_8: 0  loss_mask_8: 0.9646  loss_dice_8: 2.581  time: 2.4219  data_time: 0.0261  lr: 8.74e-05  max_mem: 6000M
[02/18 05:14:15] d2.utils.events INFO:  eta: 23:23:30  iter: 8359  total_loss: 37.52  loss_ce: 0  loss_mask: 0.9683  loss_dice: 2.707  loss_seg: 1.111  loss_ce_0: 0  loss_mask_0: 0.9657  loss_dice_0: 2.711  loss_ce_1: 0  loss_mask_1: 0.9772  loss_dice_1: 2.702  loss_ce_2: 0  loss_mask_2: 0.9779  loss_dice_2: 2.68  loss_ce_3: 0  loss_mask_3: 0.9729  loss_dice_3: 2.681  loss_ce_4: 0  loss_mask_4: 0.975  loss_dice_4: 2.683  loss_ce_5: 0  loss_mask_5: 0.974  loss_dice_5: 2.687  loss_ce_6: 0  loss_mask_6: 0.9728  loss_dice_6: 2.689  loss_ce_7: 0  loss_mask_7: 0.9674  loss_dice_7: 2.693  loss_ce_8: 0  loss_mask_8: 0.9719  loss_dice_8: 2.69  time: 2.4202  data_time: 0.0303  lr: 8.7369e-05  max_mem: 6000M
[02/18 05:14:47] d2.utils.events INFO:  eta: 23:21:26  iter: 8379  total_loss: 36.35  loss_ce: 0  loss_mask: 0.959  loss_dice: 2.552  loss_seg: 0.8475  loss_ce_0: 0  loss_mask_0: 0.9621  loss_dice_0: 2.593  loss_ce_1: 0  loss_mask_1: 0.9492  loss_dice_1: 2.544  loss_ce_2: 0  loss_mask_2: 0.9516  loss_dice_2: 2.54  loss_ce_3: 0  loss_mask_3: 0.9494  loss_dice_3: 2.535  loss_ce_4: 0  loss_mask_4: 0.9487  loss_dice_4: 2.536  loss_ce_5: 0  loss_mask_5: 0.9502  loss_dice_5: 2.537  loss_ce_6: 0  loss_mask_6: 0.9515  loss_dice_6: 2.543  loss_ce_7: 0  loss_mask_7: 0.9567  loss_dice_7: 2.537  loss_ce_8: 0  loss_mask_8: 0.9577  loss_dice_8: 2.537  time: 2.4182  data_time: 0.0295  lr: 8.7339e-05  max_mem: 6000M
[02/18 05:15:18] d2.utils.events INFO:  eta: 23:15:49  iter: 8399  total_loss: 36.76  loss_ce: 0  loss_mask: 0.9252  loss_dice: 2.626  loss_seg: 1.131  loss_ce_0: 0  loss_mask_0: 0.932  loss_dice_0: 2.682  loss_ce_1: 0  loss_mask_1: 0.9325  loss_dice_1: 2.624  loss_ce_2: 0  loss_mask_2: 0.927  loss_dice_2: 2.614  loss_ce_3: 0  loss_mask_3: 0.9371  loss_dice_3: 2.611  loss_ce_4: 0  loss_mask_4: 0.9396  loss_dice_4: 2.607  loss_ce_5: 0  loss_mask_5: 0.9379  loss_dice_5: 2.614  loss_ce_6: 0  loss_mask_6: 0.9421  loss_dice_6: 2.607  loss_ce_7: 0  loss_mask_7: 0.9333  loss_dice_7: 2.609  loss_ce_8: 0  loss_mask_8: 0.932  loss_dice_8: 2.609  time: 2.4161  data_time: 0.0307  lr: 8.7308e-05  max_mem: 6000M
[02/18 05:15:50] d2.utils.events INFO:  eta: 23:11:20  iter: 8419  total_loss: 37.45  loss_ce: 0  loss_mask: 0.9666  loss_dice: 2.627  loss_seg: 1.33  loss_ce_0: 0  loss_mask_0: 0.9587  loss_dice_0: 2.685  loss_ce_1: 0  loss_mask_1: 0.9651  loss_dice_1: 2.624  loss_ce_2: 0  loss_mask_2: 0.9678  loss_dice_2: 2.613  loss_ce_3: 0  loss_mask_3: 0.9777  loss_dice_3: 2.603  loss_ce_4: 0  loss_mask_4: 0.9807  loss_dice_4: 2.603  loss_ce_5: 0  loss_mask_5: 0.9827  loss_dice_5: 2.607  loss_ce_6: 0  loss_mask_6: 0.9848  loss_dice_6: 2.598  loss_ce_7: 0  loss_mask_7: 0.9805  loss_dice_7: 2.601  loss_ce_8: 0  loss_mask_8: 0.984  loss_dice_8: 2.606  time: 2.4142  data_time: 0.0277  lr: 8.7278e-05  max_mem: 6000M
[02/18 05:16:23] d2.utils.events INFO:  eta: 23:06:58  iter: 8439  total_loss: 38.01  loss_ce: 0  loss_mask: 0.9832  loss_dice: 2.623  loss_seg: 0.996  loss_ce_0: 0  loss_mask_0: 1.002  loss_dice_0: 2.669  loss_ce_1: 0  loss_mask_1: 0.9889  loss_dice_1: 2.629  loss_ce_2: 0  loss_mask_2: 0.9896  loss_dice_2: 2.621  loss_ce_3: 0  loss_mask_3: 0.9929  loss_dice_3: 2.605  loss_ce_4: 0  loss_mask_4: 0.9918  loss_dice_4: 2.607  loss_ce_5: 0  loss_mask_5: 0.989  loss_dice_5: 2.61  loss_ce_6: 0  loss_mask_6: 0.9933  loss_dice_6: 2.596  loss_ce_7: 0  loss_mask_7: 0.9948  loss_dice_7: 2.595  loss_ce_8: 0  loss_mask_8: 0.9909  loss_dice_8: 2.615  time: 2.4123  data_time: 0.0406  lr: 8.7248e-05  max_mem: 6000M
[02/18 05:16:54] d2.utils.events INFO:  eta: 23:04:31  iter: 8459  total_loss: 37.31  loss_ce: 0  loss_mask: 0.9878  loss_dice: 2.625  loss_seg: 0.8739  loss_ce_0: 0  loss_mask_0: 1.009  loss_dice_0: 2.655  loss_ce_1: 0  loss_mask_1: 0.9908  loss_dice_1: 2.619  loss_ce_2: 0  loss_mask_2: 0.9847  loss_dice_2: 2.619  loss_ce_3: 0  loss_mask_3: 0.9927  loss_dice_3: 2.607  loss_ce_4: 0  loss_mask_4: 0.9939  loss_dice_4: 2.61  loss_ce_5: 0  loss_mask_5: 0.99  loss_dice_5: 2.614  loss_ce_6: 0  loss_mask_6: 0.9923  loss_dice_6: 2.611  loss_ce_7: 0  loss_mask_7: 0.9916  loss_dice_7: 2.615  loss_ce_8: 0  loss_mask_8: 0.9948  loss_dice_8: 2.606  time: 2.4103  data_time: 0.0316  lr: 8.7217e-05  max_mem: 6000M
[02/18 05:17:27] d2.utils.events INFO:  eta: 23:03:50  iter: 8479  total_loss: 37.19  loss_ce: 0  loss_mask: 1.01  loss_dice: 2.653  loss_seg: 1.043  loss_ce_0: 0  loss_mask_0: 1.019  loss_dice_0: 2.718  loss_ce_1: 0  loss_mask_1: 1.003  loss_dice_1: 2.652  loss_ce_2: 0  loss_mask_2: 1.002  loss_dice_2: 2.639  loss_ce_3: 0  loss_mask_3: 1.006  loss_dice_3: 2.633  loss_ce_4: 0  loss_mask_4: 1.01  loss_dice_4: 2.639  loss_ce_5: 0  loss_mask_5: 1.008  loss_dice_5: 2.639  loss_ce_6: 0  loss_mask_6: 1.009  loss_dice_6: 2.646  loss_ce_7: 0  loss_mask_7: 1.009  loss_dice_7: 2.64  loss_ce_8: 0  loss_mask_8: 1.009  loss_dice_8: 2.637  time: 2.4084  data_time: 0.0241  lr: 8.7187e-05  max_mem: 6000M
[02/18 05:18:00] d2.utils.events INFO:  eta: 23:03:18  iter: 8499  total_loss: 36.84  loss_ce: 0  loss_mask: 0.9896  loss_dice: 2.574  loss_seg: 0.9081  loss_ce_0: 0  loss_mask_0: 1.012  loss_dice_0: 2.641  loss_ce_1: 0  loss_mask_1: 0.9926  loss_dice_1: 2.565  loss_ce_2: 0  loss_mask_2: 0.9909  loss_dice_2: 2.554  loss_ce_3: 0  loss_mask_3: 0.9948  loss_dice_3: 2.546  loss_ce_4: 0  loss_mask_4: 0.9916  loss_dice_4: 2.544  loss_ce_5: 0  loss_mask_5: 0.9926  loss_dice_5: 2.551  loss_ce_6: 0  loss_mask_6: 0.9928  loss_dice_6: 2.555  loss_ce_7: 0  loss_mask_7: 0.9939  loss_dice_7: 2.552  loss_ce_8: 0  loss_mask_8: 0.9913  loss_dice_8: 2.555  time: 2.4066  data_time: 0.0294  lr: 8.7156e-05  max_mem: 6000M
[02/18 05:18:34] d2.utils.events INFO:  eta: 23:03:09  iter: 8519  total_loss: 36.53  loss_ce: 0  loss_mask: 0.9932  loss_dice: 2.622  loss_seg: 0.7518  loss_ce_0: 0  loss_mask_0: 1.007  loss_dice_0: 2.664  loss_ce_1: 0  loss_mask_1: 0.9908  loss_dice_1: 2.623  loss_ce_2: 0  loss_mask_2: 0.9941  loss_dice_2: 2.605  loss_ce_3: 0  loss_mask_3: 0.9954  loss_dice_3: 2.598  loss_ce_4: 0  loss_mask_4: 0.9933  loss_dice_4: 2.596  loss_ce_5: 0  loss_mask_5: 0.9923  loss_dice_5: 2.593  loss_ce_6: 0  loss_mask_6: 0.995  loss_dice_6: 2.601  loss_ce_7: 0  loss_mask_7: 0.99  loss_dice_7: 2.603  loss_ce_8: 0  loss_mask_8: 0.9931  loss_dice_8: 2.604  time: 2.4051  data_time: 0.0324  lr: 8.7126e-05  max_mem: 6000M
[02/18 05:19:07] d2.utils.events INFO:  eta: 23:04:17  iter: 8539  total_loss: 37.28  loss_ce: 0  loss_mask: 1.023  loss_dice: 2.583  loss_seg: 1.038  loss_ce_0: 0  loss_mask_0: 1.025  loss_dice_0: 2.65  loss_ce_1: 0  loss_mask_1: 1.037  loss_dice_1: 2.579  loss_ce_2: 0  loss_mask_2: 1.035  loss_dice_2: 2.57  loss_ce_3: 0  loss_mask_3: 1.033  loss_dice_3: 2.565  loss_ce_4: 0  loss_mask_4: 1.041  loss_dice_4: 2.573  loss_ce_5: 0  loss_mask_5: 1.039  loss_dice_5: 2.57  loss_ce_6: 0  loss_mask_6: 1.035  loss_dice_6: 2.563  loss_ce_7: 0  loss_mask_7: 1.038  loss_dice_7: 2.559  loss_ce_8: 0  loss_mask_8: 1.034  loss_dice_8: 2.561  time: 2.4033  data_time: 0.0423  lr: 8.7095e-05  max_mem: 6000M
[02/18 05:19:40] d2.utils.events INFO:  eta: 23:03:14  iter: 8559  total_loss: 35.44  loss_ce: 0  loss_mask: 0.9749  loss_dice: 2.518  loss_seg: 0.8012  loss_ce_0: 0  loss_mask_0: 0.9932  loss_dice_0: 2.563  loss_ce_1: 0  loss_mask_1: 0.9771  loss_dice_1: 2.506  loss_ce_2: 0  loss_mask_2: 0.9808  loss_dice_2: 2.491  loss_ce_3: 0  loss_mask_3: 0.9886  loss_dice_3: 2.489  loss_ce_4: 0  loss_mask_4: 0.9864  loss_dice_4: 2.495  loss_ce_5: 0  loss_mask_5: 0.9854  loss_dice_5: 2.494  loss_ce_6: 0  loss_mask_6: 0.9898  loss_dice_6: 2.498  loss_ce_7: 0  loss_mask_7: 0.9933  loss_dice_7: 2.497  loss_ce_8: 0  loss_mask_8: 0.9858  loss_dice_8: 2.499  time: 2.4014  data_time: 0.0277  lr: 8.7065e-05  max_mem: 6000M
[02/18 05:20:12] d2.utils.events INFO:  eta: 23:01:25  iter: 8579  total_loss: 35.91  loss_ce: 0  loss_mask: 0.9385  loss_dice: 2.532  loss_seg: 1.09  loss_ce_0: 0  loss_mask_0: 0.9256  loss_dice_0: 2.614  loss_ce_1: 0  loss_mask_1: 0.9315  loss_dice_1: 2.518  loss_ce_2: 0  loss_mask_2: 0.9373  loss_dice_2: 2.512  loss_ce_3: 0  loss_mask_3: 0.9379  loss_dice_3: 2.501  loss_ce_4: 0  loss_mask_4: 0.9336  loss_dice_4: 2.51  loss_ce_5: 0  loss_mask_5: 0.9306  loss_dice_5: 2.512  loss_ce_6: 0  loss_mask_6: 0.9349  loss_dice_6: 2.518  loss_ce_7: 0  loss_mask_7: 0.9347  loss_dice_7: 2.517  loss_ce_8: 0  loss_mask_8: 0.9357  loss_dice_8: 2.519  time: 2.3996  data_time: 0.0309  lr: 8.7034e-05  max_mem: 6000M
[02/18 05:20:44] d2.utils.events INFO:  eta: 23:00:36  iter: 8599  total_loss: 37.13  loss_ce: 0  loss_mask: 0.9834  loss_dice: 2.551  loss_seg: 0.9755  loss_ce_0: 0  loss_mask_0: 0.9794  loss_dice_0: 2.623  loss_ce_1: 0  loss_mask_1: 0.9804  loss_dice_1: 2.559  loss_ce_2: 0  loss_mask_2: 0.9797  loss_dice_2: 2.541  loss_ce_3: 0  loss_mask_3: 0.9787  loss_dice_3: 2.534  loss_ce_4: 0  loss_mask_4: 0.9885  loss_dice_4: 2.531  loss_ce_5: 0  loss_mask_5: 0.9849  loss_dice_5: 2.534  loss_ce_6: 0  loss_mask_6: 0.9868  loss_dice_6: 2.535  loss_ce_7: 0  loss_mask_7: 0.9881  loss_dice_7: 2.537  loss_ce_8: 0  loss_mask_8: 0.9851  loss_dice_8: 2.537  time: 2.3977  data_time: 0.0245  lr: 8.7004e-05  max_mem: 6000M
[02/18 05:21:15] d2.utils.events INFO:  eta: 22:57:27  iter: 8619  total_loss: 37.13  loss_ce: 0  loss_mask: 0.9963  loss_dice: 2.584  loss_seg: 0.9155  loss_ce_0: 0  loss_mask_0: 0.9954  loss_dice_0: 2.611  loss_ce_1: 0  loss_mask_1: 0.9946  loss_dice_1: 2.583  loss_ce_2: 0  loss_mask_2: 1.002  loss_dice_2: 2.564  loss_ce_3: 0  loss_mask_3: 1.002  loss_dice_3: 2.559  loss_ce_4: 0  loss_mask_4: 1.002  loss_dice_4: 2.558  loss_ce_5: 0  loss_mask_5: 0.9982  loss_dice_5: 2.559  loss_ce_6: 0  loss_mask_6: 1.004  loss_dice_6: 2.56  loss_ce_7: 0  loss_mask_7: 1.002  loss_dice_7: 2.562  loss_ce_8: 0  loss_mask_8: 1.005  loss_dice_8: 2.56  time: 2.3958  data_time: 0.0333  lr: 8.6973e-05  max_mem: 6000M
[02/18 05:21:47] d2.utils.events INFO:  eta: 22:58:59  iter: 8639  total_loss: 36.26  loss_ce: 0  loss_mask: 0.9748  loss_dice: 2.554  loss_seg: 1.027  loss_ce_0: 0  loss_mask_0: 0.9921  loss_dice_0: 2.607  loss_ce_1: 0  loss_mask_1: 0.9812  loss_dice_1: 2.55  loss_ce_2: 0  loss_mask_2: 0.9825  loss_dice_2: 2.53  loss_ce_3: 0  loss_mask_3: 0.9794  loss_dice_3: 2.529  loss_ce_4: 0  loss_mask_4: 0.9851  loss_dice_4: 2.526  loss_ce_5: 0  loss_mask_5: 0.9841  loss_dice_5: 2.533  loss_ce_6: 0  loss_mask_6: 0.983  loss_dice_6: 2.53  loss_ce_7: 0  loss_mask_7: 0.9806  loss_dice_7: 2.533  loss_ce_8: 0  loss_mask_8: 0.9817  loss_dice_8: 2.535  time: 2.3939  data_time: 0.0292  lr: 8.6943e-05  max_mem: 6000M
[02/18 05:22:21] d2.utils.events INFO:  eta: 22:57:52  iter: 8659  total_loss: 36.49  loss_ce: 0  loss_mask: 1.02  loss_dice: 2.558  loss_seg: 0.8948  loss_ce_0: 0  loss_mask_0: 1.032  loss_dice_0: 2.603  loss_ce_1: 0  loss_mask_1: 1.016  loss_dice_1: 2.555  loss_ce_2: 0  loss_mask_2: 1.02  loss_dice_2: 2.541  loss_ce_3: 0  loss_mask_3: 1.02  loss_dice_3: 2.531  loss_ce_4: 0  loss_mask_4: 1.019  loss_dice_4: 2.536  loss_ce_5: 0  loss_mask_5: 1.015  loss_dice_5: 2.535  loss_ce_6: 0  loss_mask_6: 1.02  loss_dice_6: 2.539  loss_ce_7: 0  loss_mask_7: 1.022  loss_dice_7: 2.533  loss_ce_8: 0  loss_mask_8: 1.024  loss_dice_8: 2.532  time: 2.3923  data_time: 0.0306  lr: 8.6912e-05  max_mem: 6000M
[02/18 05:22:56] d2.utils.events INFO:  eta: 22:58:27  iter: 8679  total_loss: 34.77  loss_ce: 0  loss_mask: 0.9164  loss_dice: 2.46  loss_seg: 0.7581  loss_ce_0: 0  loss_mask_0: 0.9144  loss_dice_0: 2.535  loss_ce_1: 0  loss_mask_1: 0.9285  loss_dice_1: 2.457  loss_ce_2: 0  loss_mask_2: 0.9273  loss_dice_2: 2.443  loss_ce_3: 0  loss_mask_3: 0.9272  loss_dice_3: 2.438  loss_ce_4: 0  loss_mask_4: 0.9329  loss_dice_4: 2.442  loss_ce_5: 0  loss_mask_5: 0.9314  loss_dice_5: 2.446  loss_ce_6: 0  loss_mask_6: 0.9292  loss_dice_6: 2.441  loss_ce_7: 0  loss_mask_7: 0.9245  loss_dice_7: 2.446  loss_ce_8: 0  loss_mask_8: 0.9285  loss_dice_8: 2.447  time: 2.3907  data_time: 0.0249  lr: 8.6882e-05  max_mem: 6000M
[02/18 05:23:31] d2.utils.events INFO:  eta: 22:58:03  iter: 8699  total_loss: 36.91  loss_ce: 0  loss_mask: 0.9328  loss_dice: 2.577  loss_seg: 1.372  loss_ce_0: 0  loss_mask_0: 0.9186  loss_dice_0: 2.636  loss_ce_1: 0  loss_mask_1: 0.9341  loss_dice_1: 2.562  loss_ce_2: 0  loss_mask_2: 0.9257  loss_dice_2: 2.56  loss_ce_3: 0  loss_mask_3: 0.9325  loss_dice_3: 2.555  loss_ce_4: 0  loss_mask_4: 0.9335  loss_dice_4: 2.556  loss_ce_5: 0  loss_mask_5: 0.9331  loss_dice_5: 2.557  loss_ce_6: 0  loss_mask_6: 0.9377  loss_dice_6: 2.558  loss_ce_7: 0  loss_mask_7: 0.9378  loss_dice_7: 2.557  loss_ce_8: 0  loss_mask_8: 0.9355  loss_dice_8: 2.56  time: 2.3893  data_time: 0.0355  lr: 8.6851e-05  max_mem: 6000M
[02/18 05:24:04] d2.utils.events INFO:  eta: 22:57:45  iter: 8719  total_loss: 35.98  loss_ce: 0  loss_mask: 0.9773  loss_dice: 2.58  loss_seg: 0.6984  loss_ce_0: 0  loss_mask_0: 0.9639  loss_dice_0: 2.647  loss_ce_1: 0  loss_mask_1: 0.9767  loss_dice_1: 2.579  loss_ce_2: 0  loss_mask_2: 0.9802  loss_dice_2: 2.563  loss_ce_3: 0  loss_mask_3: 0.9847  loss_dice_3: 2.554  loss_ce_4: 0  loss_mask_4: 0.9844  loss_dice_4: 2.55  loss_ce_5: 0  loss_mask_5: 0.9856  loss_dice_5: 2.555  loss_ce_6: 0  loss_mask_6: 0.9914  loss_dice_6: 2.557  loss_ce_7: 0  loss_mask_7: 0.9896  loss_dice_7: 2.554  loss_ce_8: 0  loss_mask_8: 0.9873  loss_dice_8: 2.556  time: 2.3876  data_time: 0.0242  lr: 8.6821e-05  max_mem: 6000M
[02/18 05:24:35] d2.utils.events INFO:  eta: 22:56:59  iter: 8739  total_loss: 35.12  loss_ce: 0  loss_mask: 0.9294  loss_dice: 2.506  loss_seg: 0.7072  loss_ce_0: 0  loss_mask_0: 0.9226  loss_dice_0: 2.571  loss_ce_1: 0  loss_mask_1: 0.9277  loss_dice_1: 2.495  loss_ce_2: 0  loss_mask_2: 0.9284  loss_dice_2: 2.486  loss_ce_3: 0  loss_mask_3: 0.9335  loss_dice_3: 2.476  loss_ce_4: 0  loss_mask_4: 0.9355  loss_dice_4: 2.479  loss_ce_5: 0  loss_mask_5: 0.9327  loss_dice_5: 2.487  loss_ce_6: 0  loss_mask_6: 0.9406  loss_dice_6: 2.483  loss_ce_7: 0  loss_mask_7: 0.9449  loss_dice_7: 2.492  loss_ce_8: 0  loss_mask_8: 0.9383  loss_dice_8: 2.495  time: 2.3857  data_time: 0.0342  lr: 8.6791e-05  max_mem: 6000M
[02/18 05:25:07] d2.utils.events INFO:  eta: 22:56:27  iter: 8759  total_loss: 36.37  loss_ce: 0  loss_mask: 0.9615  loss_dice: 2.55  loss_seg: 0.8734  loss_ce_0: 0  loss_mask_0: 0.9692  loss_dice_0: 2.603  loss_ce_1: 0  loss_mask_1: 0.9672  loss_dice_1: 2.554  loss_ce_2: 0  loss_mask_2: 0.97  loss_dice_2: 2.542  loss_ce_3: 0  loss_mask_3: 0.9706  loss_dice_3: 2.537  loss_ce_4: 0  loss_mask_4: 0.9667  loss_dice_4: 2.543  loss_ce_5: 0  loss_mask_5: 0.9679  loss_dice_5: 2.54  loss_ce_6: 0  loss_mask_6: 0.9741  loss_dice_6: 2.54  loss_ce_7: 0  loss_mask_7: 0.9698  loss_dice_7: 2.539  loss_ce_8: 0  loss_mask_8: 0.9655  loss_dice_8: 2.542  time: 2.3839  data_time: 0.0298  lr: 8.676e-05  max_mem: 6000M
[02/18 05:25:42] d2.utils.events INFO:  eta: 22:56:03  iter: 8779  total_loss: 36.63  loss_ce: 0  loss_mask: 0.9791  loss_dice: 2.581  loss_seg: 1.076  loss_ce_0: 0  loss_mask_0: 0.9824  loss_dice_0: 2.618  loss_ce_1: 0  loss_mask_1: 0.9769  loss_dice_1: 2.581  loss_ce_2: 0  loss_mask_2: 0.9711  loss_dice_2: 2.56  loss_ce_3: 0  loss_mask_3: 0.9794  loss_dice_3: 2.553  loss_ce_4: 0  loss_mask_4: 0.9864  loss_dice_4: 2.553  loss_ce_5: 0  loss_mask_5: 0.9862  loss_dice_5: 2.557  loss_ce_6: 0  loss_mask_6: 0.9868  loss_dice_6: 2.552  loss_ce_7: 0  loss_mask_7: 0.9882  loss_dice_7: 2.561  loss_ce_8: 0  loss_mask_8: 0.9871  loss_dice_8: 2.56  time: 2.3824  data_time: 0.0258  lr: 8.673e-05  max_mem: 6000M
[02/18 05:26:13] d2.utils.events INFO:  eta: 22:55:02  iter: 8799  total_loss: 36.85  loss_ce: 0  loss_mask: 0.96  loss_dice: 2.631  loss_seg: 1.082  loss_ce_0: 0  loss_mask_0: 0.9727  loss_dice_0: 2.679  loss_ce_1: 0  loss_mask_1: 0.9632  loss_dice_1: 2.626  loss_ce_2: 0  loss_mask_2: 0.9615  loss_dice_2: 2.608  loss_ce_3: 0  loss_mask_3: 0.9682  loss_dice_3: 2.605  loss_ce_4: 0  loss_mask_4: 0.9736  loss_dice_4: 2.602  loss_ce_5: 0  loss_mask_5: 0.972  loss_dice_5: 2.607  loss_ce_6: 0  loss_mask_6: 0.9673  loss_dice_6: 2.604  loss_ce_7: 0  loss_mask_7: 0.9648  loss_dice_7: 2.603  loss_ce_8: 0  loss_mask_8: 0.9678  loss_dice_8: 2.609  time: 2.3805  data_time: 0.0406  lr: 8.6699e-05  max_mem: 6000M
[02/18 05:26:46] d2.utils.events INFO:  eta: 22:53:09  iter: 8819  total_loss: 35.41  loss_ce: 0  loss_mask: 0.9736  loss_dice: 2.543  loss_seg: 0.7328  loss_ce_0: 0  loss_mask_0: 0.9834  loss_dice_0: 2.605  loss_ce_1: 0  loss_mask_1: 0.9729  loss_dice_1: 2.546  loss_ce_2: 0  loss_mask_2: 0.9679  loss_dice_2: 2.529  loss_ce_3: 0  loss_mask_3: 0.9757  loss_dice_3: 2.511  loss_ce_4: 0  loss_mask_4: 0.9727  loss_dice_4: 2.517  loss_ce_5: 0  loss_mask_5: 0.976  loss_dice_5: 2.518  loss_ce_6: 0  loss_mask_6: 0.9806  loss_dice_6: 2.509  loss_ce_7: 0  loss_mask_7: 0.9794  loss_dice_7: 2.516  loss_ce_8: 0  loss_mask_8: 0.9804  loss_dice_8: 2.517  time: 2.3788  data_time: 0.0310  lr: 8.6669e-05  max_mem: 6000M
[02/18 05:27:19] d2.utils.events INFO:  eta: 22:48:25  iter: 8839  total_loss: 35.72  loss_ce: 0  loss_mask: 0.9787  loss_dice: 2.544  loss_seg: 0.7392  loss_ce_0: 0  loss_mask_0: 0.9894  loss_dice_0: 2.572  loss_ce_1: 0  loss_mask_1: 0.9806  loss_dice_1: 2.539  loss_ce_2: 0  loss_mask_2: 0.9858  loss_dice_2: 2.527  loss_ce_3: 0  loss_mask_3: 0.9847  loss_dice_3: 2.518  loss_ce_4: 0  loss_mask_4: 0.9866  loss_dice_4: 2.518  loss_ce_5: 0  loss_mask_5: 0.9831  loss_dice_5: 2.519  loss_ce_6: 0  loss_mask_6: 0.9823  loss_dice_6: 2.521  loss_ce_7: 0  loss_mask_7: 0.9851  loss_dice_7: 2.528  loss_ce_8: 0  loss_mask_8: 0.9827  loss_dice_8: 2.524  time: 2.3772  data_time: 0.0292  lr: 8.6638e-05  max_mem: 6000M
[02/18 05:27:52] d2.utils.events INFO:  eta: 22:48:31  iter: 8859  total_loss: 35.64  loss_ce: 0  loss_mask: 0.9689  loss_dice: 2.5  loss_seg: 0.7861  loss_ce_0: 0  loss_mask_0: 0.9874  loss_dice_0: 2.581  loss_ce_1: 0  loss_mask_1: 0.9792  loss_dice_1: 2.501  loss_ce_2: 0  loss_mask_2: 0.9772  loss_dice_2: 2.492  loss_ce_3: 0  loss_mask_3: 0.9804  loss_dice_3: 2.484  loss_ce_4: 0  loss_mask_4: 0.9833  loss_dice_4: 2.483  loss_ce_5: 0  loss_mask_5: 0.9797  loss_dice_5: 2.485  loss_ce_6: 0  loss_mask_6: 0.9823  loss_dice_6: 2.488  loss_ce_7: 0  loss_mask_7: 0.9795  loss_dice_7: 2.485  loss_ce_8: 0  loss_mask_8: 0.9771  loss_dice_8: 2.478  time: 2.3755  data_time: 0.0263  lr: 8.6608e-05  max_mem: 6000M
[02/18 05:28:24] d2.utils.events INFO:  eta: 22:47:10  iter: 8879  total_loss: 35.39  loss_ce: 0  loss_mask: 0.9245  loss_dice: 2.534  loss_seg: 0.7801  loss_ce_0: 0  loss_mask_0: 0.9245  loss_dice_0: 2.613  loss_ce_1: 0  loss_mask_1: 0.9276  loss_dice_1: 2.54  loss_ce_2: 0  loss_mask_2: 0.9322  loss_dice_2: 2.526  loss_ce_3: 0  loss_mask_3: 0.9371  loss_dice_3: 2.51  loss_ce_4: 0  loss_mask_4: 0.9409  loss_dice_4: 2.515  loss_ce_5: 0  loss_mask_5: 0.9412  loss_dice_5: 2.519  loss_ce_6: 0  loss_mask_6: 0.9462  loss_dice_6: 2.511  loss_ce_7: 0  loss_mask_7: 0.9471  loss_dice_7: 2.514  loss_ce_8: 0  loss_mask_8: 0.9457  loss_dice_8: 2.51  time: 2.3738  data_time: 0.0267  lr: 8.6577e-05  max_mem: 6000M
[02/18 05:28:56] d2.utils.events INFO:  eta: 22:46:37  iter: 8899  total_loss: 36.68  loss_ce: 0  loss_mask: 0.9755  loss_dice: 2.57  loss_seg: 1.363  loss_ce_0: 0  loss_mask_0: 0.9766  loss_dice_0: 2.624  loss_ce_1: 0  loss_mask_1: 0.9779  loss_dice_1: 2.57  loss_ce_2: 0  loss_mask_2: 0.9821  loss_dice_2: 2.565  loss_ce_3: 0  loss_mask_3: 0.9851  loss_dice_3: 2.551  loss_ce_4: 0  loss_mask_4: 0.9861  loss_dice_4: 2.551  loss_ce_5: 0  loss_mask_5: 0.9869  loss_dice_5: 2.557  loss_ce_6: 0  loss_mask_6: 0.9866  loss_dice_6: 2.553  loss_ce_7: 0  loss_mask_7: 0.9804  loss_dice_7: 2.555  loss_ce_8: 0  loss_mask_8: 0.9799  loss_dice_8: 2.558  time: 2.3721  data_time: 0.0319  lr: 8.6547e-05  max_mem: 6000M
[02/18 05:29:28] d2.utils.events INFO:  eta: 22:46:05  iter: 8919  total_loss: 35.87  loss_ce: 0  loss_mask: 0.9629  loss_dice: 2.499  loss_seg: 0.8696  loss_ce_0: 0  loss_mask_0: 0.9802  loss_dice_0: 2.557  loss_ce_1: 0  loss_mask_1: 0.9708  loss_dice_1: 2.488  loss_ce_2: 0  loss_mask_2: 0.9716  loss_dice_2: 2.473  loss_ce_3: 0  loss_mask_3: 0.9737  loss_dice_3: 2.468  loss_ce_4: 0  loss_mask_4: 0.9702  loss_dice_4: 2.468  loss_ce_5: 0  loss_mask_5: 0.9743  loss_dice_5: 2.466  loss_ce_6: 0  loss_mask_6: 0.9689  loss_dice_6: 2.471  loss_ce_7: 0  loss_mask_7: 0.9734  loss_dice_7: 2.473  loss_ce_8: 0  loss_mask_8: 0.9713  loss_dice_8: 2.471  time: 2.3703  data_time: 0.0322  lr: 8.6516e-05  max_mem: 6000M
[02/18 05:30:02] d2.utils.events INFO:  eta: 22:45:33  iter: 8939  total_loss: 34.85  loss_ce: 0  loss_mask: 0.9167  loss_dice: 2.474  loss_seg: 0.8419  loss_ce_0: 0  loss_mask_0: 0.9126  loss_dice_0: 2.543  loss_ce_1: 0  loss_mask_1: 0.9111  loss_dice_1: 2.479  loss_ce_2: 0  loss_mask_2: 0.9156  loss_dice_2: 2.461  loss_ce_3: 0  loss_mask_3: 0.9228  loss_dice_3: 2.452  loss_ce_4: 0  loss_mask_4: 0.9261  loss_dice_4: 2.454  loss_ce_5: 0  loss_mask_5: 0.929  loss_dice_5: 2.458  loss_ce_6: 0  loss_mask_6: 0.9284  loss_dice_6: 2.453  loss_ce_7: 0  loss_mask_7: 0.9259  loss_dice_7: 2.452  loss_ce_8: 0  loss_mask_8: 0.9229  loss_dice_8: 2.449  time: 2.3687  data_time: 0.0418  lr: 8.6486e-05  max_mem: 6000M
[02/18 05:30:37] d2.utils.events INFO:  eta: 22:47:39  iter: 8959  total_loss: 37.18  loss_ce: 0  loss_mask: 0.9735  loss_dice: 2.625  loss_seg: 1.035  loss_ce_0: 0  loss_mask_0: 0.9716  loss_dice_0: 2.675  loss_ce_1: 0  loss_mask_1: 0.979  loss_dice_1: 2.631  loss_ce_2: 0  loss_mask_2: 0.9801  loss_dice_2: 2.61  loss_ce_3: 0  loss_mask_3: 0.9846  loss_dice_3: 2.596  loss_ce_4: 0  loss_mask_4: 0.9792  loss_dice_4: 2.604  loss_ce_5: 0  loss_mask_5: 0.9781  loss_dice_5: 2.603  loss_ce_6: 0  loss_mask_6: 0.9834  loss_dice_6: 2.606  loss_ce_7: 0  loss_mask_7: 0.9835  loss_dice_7: 2.603  loss_ce_8: 0  loss_mask_8: 0.9815  loss_dice_8: 2.602  time: 2.3674  data_time: 0.0421  lr: 8.6455e-05  max_mem: 6000M
[02/18 05:31:10] d2.utils.events INFO:  eta: 22:50:39  iter: 8979  total_loss: 35.17  loss_ce: 0  loss_mask: 0.9463  loss_dice: 2.483  loss_seg: 0.9328  loss_ce_0: 0  loss_mask_0: 0.9678  loss_dice_0: 2.51  loss_ce_1: 0  loss_mask_1: 0.9537  loss_dice_1: 2.482  loss_ce_2: 0  loss_mask_2: 0.9499  loss_dice_2: 2.468  loss_ce_3: 0  loss_mask_3: 0.9523  loss_dice_3: 2.465  loss_ce_4: 0  loss_mask_4: 0.9533  loss_dice_4: 2.457  loss_ce_5: 0  loss_mask_5: 0.9488  loss_dice_5: 2.46  loss_ce_6: 0  loss_mask_6: 0.9527  loss_dice_6: 2.456  loss_ce_7: 0  loss_mask_7: 0.9521  loss_dice_7: 2.456  loss_ce_8: 0  loss_mask_8: 0.9519  loss_dice_8: 2.469  time: 2.3658  data_time: 0.0428  lr: 8.6425e-05  max_mem: 6000M
[02/18 05:31:44] d2.utils.events INFO:  eta: 22:49:19  iter: 8999  total_loss: 37.15  loss_ce: 0  loss_mask: 0.9452  loss_dice: 2.616  loss_seg: 0.9257  loss_ce_0: 0  loss_mask_0: 0.9454  loss_dice_0: 2.655  loss_ce_1: 0  loss_mask_1: 0.9488  loss_dice_1: 2.602  loss_ce_2: 0  loss_mask_2: 0.9567  loss_dice_2: 2.597  loss_ce_3: 0  loss_mask_3: 0.9655  loss_dice_3: 2.584  loss_ce_4: 0  loss_mask_4: 0.967  loss_dice_4: 2.586  loss_ce_5: 0  loss_mask_5: 0.964  loss_dice_5: 2.584  loss_ce_6: 0  loss_mask_6: 0.9674  loss_dice_6: 2.583  loss_ce_7: 0  loss_mask_7: 0.9659  loss_dice_7: 2.59  loss_ce_8: 0  loss_mask_8: 0.9618  loss_dice_8: 2.588  time: 2.3642  data_time: 0.0363  lr: 8.6394e-05  max_mem: 6000M
[02/18 05:32:18] d2.utils.events INFO:  eta: 22:48:47  iter: 9019  total_loss: 34.15  loss_ce: 0  loss_mask: 0.932  loss_dice: 2.402  loss_seg: 0.9509  loss_ce_0: 0  loss_mask_0: 0.937  loss_dice_0: 2.463  loss_ce_1: 0  loss_mask_1: 0.9437  loss_dice_1: 2.399  loss_ce_2: 0  loss_mask_2: 0.9431  loss_dice_2: 2.383  loss_ce_3: 0  loss_mask_3: 0.9436  loss_dice_3: 2.384  loss_ce_4: 0  loss_mask_4: 0.9461  loss_dice_4: 2.384  loss_ce_5: 0  loss_mask_5: 0.9447  loss_dice_5: 2.376  loss_ce_6: 0  loss_mask_6: 0.9448  loss_dice_6: 2.379  loss_ce_7: 0  loss_mask_7: 0.9432  loss_dice_7: 2.38  loss_ce_8: 0  loss_mask_8: 0.9396  loss_dice_8: 2.386  time: 2.3627  data_time: 0.0485  lr: 8.6364e-05  max_mem: 6000M
[02/18 05:32:51] d2.utils.events INFO:  eta: 22:49:44  iter: 9039  total_loss: 36.08  loss_ce: 0  loss_mask: 0.9596  loss_dice: 2.571  loss_seg: 0.9515  loss_ce_0: 0  loss_mask_0: 0.9632  loss_dice_0: 2.611  loss_ce_1: 0  loss_mask_1: 0.9615  loss_dice_1: 2.58  loss_ce_2: 0  loss_mask_2: 0.9649  loss_dice_2: 2.569  loss_ce_3: 0  loss_mask_3: 0.9682  loss_dice_3: 2.553  loss_ce_4: 0  loss_mask_4: 0.9691  loss_dice_4: 2.547  loss_ce_5: 0  loss_mask_5: 0.9655  loss_dice_5: 2.549  loss_ce_6: 0  loss_mask_6: 0.9722  loss_dice_6: 2.544  loss_ce_7: 0  loss_mask_7: 0.969  loss_dice_7: 2.547  loss_ce_8: 0  loss_mask_8: 0.9676  loss_dice_8: 2.554  time: 2.3612  data_time: 0.0372  lr: 8.6333e-05  max_mem: 6000M
[02/18 05:33:25] d2.utils.events INFO:  eta: 22:54:26  iter: 9059  total_loss: 37.59  loss_ce: 0  loss_mask: 0.9669  loss_dice: 2.657  loss_seg: 0.9676  loss_ce_0: 0  loss_mask_0: 0.981  loss_dice_0: 2.688  loss_ce_1: 0  loss_mask_1: 0.9728  loss_dice_1: 2.666  loss_ce_2: 0  loss_mask_2: 0.975  loss_dice_2: 2.653  loss_ce_3: 0  loss_mask_3: 0.975  loss_dice_3: 2.65  loss_ce_4: 0  loss_mask_4: 0.9766  loss_dice_4: 2.652  loss_ce_5: 0  loss_mask_5: 0.9805  loss_dice_5: 2.65  loss_ce_6: 0  loss_mask_6: 0.9763  loss_dice_6: 2.645  loss_ce_7: 0  loss_mask_7: 0.9749  loss_dice_7: 2.644  loss_ce_8: 0  loss_mask_8: 0.9726  loss_dice_8: 2.644  time: 2.3598  data_time: 0.0436  lr: 8.6303e-05  max_mem: 6000M
[02/18 05:34:00] d2.utils.events INFO:  eta: 22:53:57  iter: 9079  total_loss: 35.17  loss_ce: 0  loss_mask: 0.942  loss_dice: 2.491  loss_seg: 1.075  loss_ce_0: 0  loss_mask_0: 0.9322  loss_dice_0: 2.568  loss_ce_1: 0  loss_mask_1: 0.9441  loss_dice_1: 2.484  loss_ce_2: 0  loss_mask_2: 0.9424  loss_dice_2: 2.479  loss_ce_3: 0  loss_mask_3: 0.952  loss_dice_3: 2.478  loss_ce_4: 0  loss_mask_4: 0.9499  loss_dice_4: 2.478  loss_ce_5: 0  loss_mask_5: 0.9479  loss_dice_5: 2.476  loss_ce_6: 0  loss_mask_6: 0.9486  loss_dice_6: 2.475  loss_ce_7: 0  loss_mask_7: 0.9538  loss_dice_7: 2.482  loss_ce_8: 0  loss_mask_8: 0.9543  loss_dice_8: 2.474  time: 2.3583  data_time: 0.0362  lr: 8.6272e-05  max_mem: 6000M
[02/18 05:34:35] d2.utils.events INFO:  eta: 22:54:13  iter: 9099  total_loss: 36.76  loss_ce: 0  loss_mask: 0.9662  loss_dice: 2.599  loss_seg: 0.8622  loss_ce_0: 0  loss_mask_0: 0.993  loss_dice_0: 2.647  loss_ce_1: 0  loss_mask_1: 0.9706  loss_dice_1: 2.595  loss_ce_2: 0  loss_mask_2: 0.9705  loss_dice_2: 2.589  loss_ce_3: 0  loss_mask_3: 0.9702  loss_dice_3: 2.586  loss_ce_4: 0  loss_mask_4: 0.9678  loss_dice_4: 2.592  loss_ce_5: 0  loss_mask_5: 0.972  loss_dice_5: 2.59  loss_ce_6: 0  loss_mask_6: 0.9696  loss_dice_6: 2.591  loss_ce_7: 0  loss_mask_7: 0.975  loss_dice_7: 2.588  loss_ce_8: 0  loss_mask_8: 0.9716  loss_dice_8: 2.59  time: 2.3570  data_time: 0.0357  lr: 8.6242e-05  max_mem: 6000M
[02/18 05:35:08] d2.utils.events INFO:  eta: 22:53:08  iter: 9119  total_loss: 37.84  loss_ce: 0  loss_mask: 0.9957  loss_dice: 2.632  loss_seg: 1.061  loss_ce_0: 0  loss_mask_0: 0.999  loss_dice_0: 2.677  loss_ce_1: 0  loss_mask_1: 0.9916  loss_dice_1: 2.627  loss_ce_2: 0  loss_mask_2: 0.9944  loss_dice_2: 2.626  loss_ce_3: 0  loss_mask_3: 0.9985  loss_dice_3: 2.612  loss_ce_4: 0  loss_mask_4: 1.001  loss_dice_4: 2.611  loss_ce_5: 0  loss_mask_5: 0.9981  loss_dice_5: 2.61  loss_ce_6: 0  loss_mask_6: 1.002  loss_dice_6: 2.609  loss_ce_7: 0  loss_mask_7: 0.9997  loss_dice_7: 2.614  loss_ce_8: 0  loss_mask_8: 0.9955  loss_dice_8: 2.612  time: 2.3554  data_time: 0.0393  lr: 8.6211e-05  max_mem: 6000M
[02/18 05:35:40] d2.utils.events INFO:  eta: 22:52:36  iter: 9139  total_loss: 35.57  loss_ce: 0  loss_mask: 0.9274  loss_dice: 2.545  loss_seg: 0.9997  loss_ce_0: 0  loss_mask_0: 0.9264  loss_dice_0: 2.611  loss_ce_1: 0  loss_mask_1: 0.926  loss_dice_1: 2.551  loss_ce_2: 0  loss_mask_2: 0.9212  loss_dice_2: 2.536  loss_ce_3: 0  loss_mask_3: 0.9352  loss_dice_3: 2.52  loss_ce_4: 0  loss_mask_4: 0.9304  loss_dice_4: 2.521  loss_ce_5: 0  loss_mask_5: 0.9304  loss_dice_5: 2.525  loss_ce_6: 0  loss_mask_6: 0.9311  loss_dice_6: 2.525  loss_ce_7: 0  loss_mask_7: 0.9323  loss_dice_7: 2.519  loss_ce_8: 0  loss_mask_8: 0.9316  loss_dice_8: 2.517  time: 2.3538  data_time: 0.0418  lr: 8.6181e-05  max_mem: 6000M
[02/18 05:36:14] d2.utils.events INFO:  eta: 22:53:30  iter: 9159  total_loss: 37.71  loss_ce: 0  loss_mask: 0.9595  loss_dice: 2.618  loss_seg: 1.088  loss_ce_0: 0  loss_mask_0: 0.9796  loss_dice_0: 2.682  loss_ce_1: 0  loss_mask_1: 0.9622  loss_dice_1: 2.631  loss_ce_2: 0  loss_mask_2: 0.9634  loss_dice_2: 2.607  loss_ce_3: 0  loss_mask_3: 0.9637  loss_dice_3: 2.603  loss_ce_4: 0  loss_mask_4: 0.9625  loss_dice_4: 2.6  loss_ce_5: 0  loss_mask_5: 0.9673  loss_dice_5: 2.6  loss_ce_6: 0  loss_mask_6: 0.9638  loss_dice_6: 2.603  loss_ce_7: 0  loss_mask_7: 0.9611  loss_dice_7: 2.6  loss_ce_8: 0  loss_mask_8: 0.9618  loss_dice_8: 2.601  time: 2.3524  data_time: 0.0362  lr: 8.615e-05  max_mem: 6000M
[02/18 05:36:48] d2.utils.events INFO:  eta: 22:52:58  iter: 9179  total_loss: 36.49  loss_ce: 0  loss_mask: 0.9293  loss_dice: 2.575  loss_seg: 1.115  loss_ce_0: 0  loss_mask_0: 0.9434  loss_dice_0: 2.646  loss_ce_1: 0  loss_mask_1: 0.9405  loss_dice_1: 2.589  loss_ce_2: 0  loss_mask_2: 0.9454  loss_dice_2: 2.57  loss_ce_3: 0  loss_mask_3: 0.9447  loss_dice_3: 2.556  loss_ce_4: 0  loss_mask_4: 0.9418  loss_dice_4: 2.557  loss_ce_5: 0  loss_mask_5: 0.944  loss_dice_5: 2.556  loss_ce_6: 0  loss_mask_6: 0.9505  loss_dice_6: 2.552  loss_ce_7: 0  loss_mask_7: 0.9484  loss_dice_7: 2.557  loss_ce_8: 0  loss_mask_8: 0.9491  loss_dice_8: 2.557  time: 2.3509  data_time: 0.0478  lr: 8.612e-05  max_mem: 6000M
[02/18 05:37:21] d2.utils.events INFO:  eta: 22:52:26  iter: 9199  total_loss: 35  loss_ce: 0  loss_mask: 0.9489  loss_dice: 2.44  loss_seg: 0.9445  loss_ce_0: 0  loss_mask_0: 0.9637  loss_dice_0: 2.513  loss_ce_1: 0  loss_mask_1: 0.9511  loss_dice_1: 2.432  loss_ce_2: 0  loss_mask_2: 0.9539  loss_dice_2: 2.416  loss_ce_3: 0  loss_mask_3: 0.9519  loss_dice_3: 2.415  loss_ce_4: 0  loss_mask_4: 0.9509  loss_dice_4: 2.417  loss_ce_5: 0  loss_mask_5: 0.9503  loss_dice_5: 2.418  loss_ce_6: 0  loss_mask_6: 0.9559  loss_dice_6: 2.421  loss_ce_7: 0  loss_mask_7: 0.9536  loss_dice_7: 2.425  loss_ce_8: 0  loss_mask_8: 0.9549  loss_dice_8: 2.419  time: 2.3494  data_time: 0.0363  lr: 8.6089e-05  max_mem: 6000M
[02/18 05:37:54] d2.utils.events INFO:  eta: 22:50:11  iter: 9219  total_loss: 35.68  loss_ce: 0  loss_mask: 0.9072  loss_dice: 2.56  loss_seg: 1.245  loss_ce_0: 0  loss_mask_0: 0.8982  loss_dice_0: 2.625  loss_ce_1: 0  loss_mask_1: 0.9119  loss_dice_1: 2.549  loss_ce_2: 0  loss_mask_2: 0.9178  loss_dice_2: 2.542  loss_ce_3: 0  loss_mask_3: 0.9129  loss_dice_3: 2.535  loss_ce_4: 0  loss_mask_4: 0.9114  loss_dice_4: 2.535  loss_ce_5: 0  loss_mask_5: 0.9119  loss_dice_5: 2.539  loss_ce_6: 0  loss_mask_6: 0.911  loss_dice_6: 2.539  loss_ce_7: 0  loss_mask_7: 0.9136  loss_dice_7: 2.537  loss_ce_8: 0  loss_mask_8: 0.9139  loss_dice_8: 2.54  time: 2.3478  data_time: 0.0289  lr: 8.6059e-05  max_mem: 6000M
[02/18 05:38:28] d2.utils.events INFO:  eta: 22:50:02  iter: 9239  total_loss: 37.16  loss_ce: 0  loss_mask: 0.9665  loss_dice: 2.607  loss_seg: 0.9997  loss_ce_0: 0  loss_mask_0: 0.9895  loss_dice_0: 2.662  loss_ce_1: 0  loss_mask_1: 0.9768  loss_dice_1: 2.598  loss_ce_2: 0  loss_mask_2: 0.9749  loss_dice_2: 2.59  loss_ce_3: 0  loss_mask_3: 0.9693  loss_dice_3: 2.584  loss_ce_4: 0  loss_mask_4: 0.974  loss_dice_4: 2.586  loss_ce_5: 0  loss_mask_5: 0.9754  loss_dice_5: 2.592  loss_ce_6: 0  loss_mask_6: 0.9726  loss_dice_6: 2.587  loss_ce_7: 0  loss_mask_7: 0.9739  loss_dice_7: 2.588  loss_ce_8: 0  loss_mask_8: 0.9744  loss_dice_8: 2.588  time: 2.3464  data_time: 0.0283  lr: 8.6028e-05  max_mem: 6000M
[02/18 05:39:00] d2.utils.events INFO:  eta: 22:51:53  iter: 9259  total_loss: 36.14  loss_ce: 0  loss_mask: 0.9585  loss_dice: 2.555  loss_seg: 0.9413  loss_ce_0: 0  loss_mask_0: 0.9548  loss_dice_0: 2.594  loss_ce_1: 0  loss_mask_1: 0.9603  loss_dice_1: 2.542  loss_ce_2: 0  loss_mask_2: 0.955  loss_dice_2: 2.529  loss_ce_3: 0  loss_mask_3: 0.9617  loss_dice_3: 2.525  loss_ce_4: 0  loss_mask_4: 0.9642  loss_dice_4: 2.522  loss_ce_5: 0  loss_mask_5: 0.9599  loss_dice_5: 2.529  loss_ce_6: 0  loss_mask_6: 0.9578  loss_dice_6: 2.529  loss_ce_7: 0  loss_mask_7: 0.957  loss_dice_7: 2.531  loss_ce_8: 0  loss_mask_8: 0.9614  loss_dice_8: 2.531  time: 2.3449  data_time: 0.0314  lr: 8.5998e-05  max_mem: 6000M
[02/18 05:39:34] d2.utils.events INFO:  eta: 22:51:21  iter: 9279  total_loss: 37.3  loss_ce: 0  loss_mask: 0.9501  loss_dice: 2.612  loss_seg: 1.201  loss_ce_0: 0  loss_mask_0: 0.9545  loss_dice_0: 2.663  loss_ce_1: 0  loss_mask_1: 0.9496  loss_dice_1: 2.611  loss_ce_2: 0  loss_mask_2: 0.9532  loss_dice_2: 2.609  loss_ce_3: 0  loss_mask_3: 0.9557  loss_dice_3: 2.604  loss_ce_4: 0  loss_mask_4: 0.9609  loss_dice_4: 2.602  loss_ce_5: 0  loss_mask_5: 0.9564  loss_dice_5: 2.601  loss_ce_6: 0  loss_mask_6: 0.9528  loss_dice_6: 2.605  loss_ce_7: 0  loss_mask_7: 0.9566  loss_dice_7: 2.604  loss_ce_8: 0  loss_mask_8: 0.9523  loss_dice_8: 2.602  time: 2.3434  data_time: 0.0267  lr: 8.5967e-05  max_mem: 6000M
[02/18 05:40:07] d2.utils.events INFO:  eta: 22:49:19  iter: 9299  total_loss: 35.08  loss_ce: 0  loss_mask: 0.8846  loss_dice: 2.479  loss_seg: 1.213  loss_ce_0: 0  loss_mask_0: 0.8944  loss_dice_0: 2.556  loss_ce_1: 0  loss_mask_1: 0.8842  loss_dice_1: 2.484  loss_ce_2: 0  loss_mask_2: 0.8858  loss_dice_2: 2.47  loss_ce_3: 0  loss_mask_3: 0.8894  loss_dice_3: 2.464  loss_ce_4: 0  loss_mask_4: 0.8856  loss_dice_4: 2.463  loss_ce_5: 0  loss_mask_5: 0.8881  loss_dice_5: 2.465  loss_ce_6: 0  loss_mask_6: 0.8874  loss_dice_6: 2.461  loss_ce_7: 0  loss_mask_7: 0.886  loss_dice_7: 2.458  loss_ce_8: 0  loss_mask_8: 0.8883  loss_dice_8: 2.461  time: 2.3419  data_time: 0.0252  lr: 8.5937e-05  max_mem: 6000M
[02/18 05:40:40] d2.utils.events INFO:  eta: 22:50:34  iter: 9319  total_loss: 35.36  loss_ce: 0  loss_mask: 0.9331  loss_dice: 2.473  loss_seg: 1.049  loss_ce_0: 0  loss_mask_0: 0.9436  loss_dice_0: 2.542  loss_ce_1: 0  loss_mask_1: 0.9181  loss_dice_1: 2.471  loss_ce_2: 0  loss_mask_2: 0.9226  loss_dice_2: 2.461  loss_ce_3: 0  loss_mask_3: 0.9373  loss_dice_3: 2.448  loss_ce_4: 0  loss_mask_4: 0.9309  loss_dice_4: 2.446  loss_ce_5: 0  loss_mask_5: 0.9301  loss_dice_5: 2.45  loss_ce_6: 0  loss_mask_6: 0.9347  loss_dice_6: 2.451  loss_ce_7: 0  loss_mask_7: 0.9404  loss_dice_7: 2.455  loss_ce_8: 0  loss_mask_8: 0.933  loss_dice_8: 2.458  time: 2.3405  data_time: 0.0303  lr: 8.5906e-05  max_mem: 6000M
[02/18 05:41:15] d2.utils.events INFO:  eta: 22:51:53  iter: 9339  total_loss: 33.74  loss_ce: 0  loss_mask: 0.9101  loss_dice: 2.413  loss_seg: 0.7492  loss_ce_0: 0  loss_mask_0: 0.9122  loss_dice_0: 2.472  loss_ce_1: 0  loss_mask_1: 0.9284  loss_dice_1: 2.418  loss_ce_2: 0  loss_mask_2: 0.9249  loss_dice_2: 2.408  loss_ce_3: 0  loss_mask_3: 0.9178  loss_dice_3: 2.389  loss_ce_4: 0  loss_mask_4: 0.9186  loss_dice_4: 2.396  loss_ce_5: 0  loss_mask_5: 0.9184  loss_dice_5: 2.399  loss_ce_6: 0  loss_mask_6: 0.9189  loss_dice_6: 2.393  loss_ce_7: 0  loss_mask_7: 0.9214  loss_dice_7: 2.397  loss_ce_8: 0  loss_mask_8: 0.9163  loss_dice_8: 2.4  time: 2.3392  data_time: 0.0330  lr: 8.5876e-05  max_mem: 6000M
[02/18 05:41:52] d2.utils.events INFO:  eta: 22:53:44  iter: 9359  total_loss: 36.31  loss_ce: 0  loss_mask: 0.9359  loss_dice: 2.565  loss_seg: 0.866  loss_ce_0: 0  loss_mask_0: 0.9406  loss_dice_0: 2.622  loss_ce_1: 0  loss_mask_1: 0.9343  loss_dice_1: 2.568  loss_ce_2: 0  loss_mask_2: 0.938  loss_dice_2: 2.555  loss_ce_3: 0  loss_mask_3: 0.9401  loss_dice_3: 2.541  loss_ce_4: 0  loss_mask_4: 0.9427  loss_dice_4: 2.54  loss_ce_5: 0  loss_mask_5: 0.9388  loss_dice_5: 2.538  loss_ce_6: 0  loss_mask_6: 0.9389  loss_dice_6: 2.532  loss_ce_7: 0  loss_mask_7: 0.9413  loss_dice_7: 2.536  loss_ce_8: 0  loss_mask_8: 0.9405  loss_dice_8: 2.536  time: 2.3381  data_time: 0.0346  lr: 8.5845e-05  max_mem: 6000M
[02/18 05:42:25] d2.utils.events INFO:  eta: 22:56:04  iter: 9379  total_loss: 35.77  loss_ce: 0  loss_mask: 0.947  loss_dice: 2.567  loss_seg: 0.8733  loss_ce_0: 0  loss_mask_0: 0.9561  loss_dice_0: 2.609  loss_ce_1: 0  loss_mask_1: 0.9525  loss_dice_1: 2.563  loss_ce_2: 0  loss_mask_2: 0.9512  loss_dice_2: 2.556  loss_ce_3: 0  loss_mask_3: 0.952  loss_dice_3: 2.55  loss_ce_4: 0  loss_mask_4: 0.9503  loss_dice_4: 2.547  loss_ce_5: 0  loss_mask_5: 0.9505  loss_dice_5: 2.548  loss_ce_6: 0  loss_mask_6: 0.9504  loss_dice_6: 2.544  loss_ce_7: 0  loss_mask_7: 0.9532  loss_dice_7: 2.541  loss_ce_8: 0  loss_mask_8: 0.9524  loss_dice_8: 2.551  time: 2.3366  data_time: 0.0286  lr: 8.5815e-05  max_mem: 6000M
[02/18 05:42:57] d2.utils.events INFO:  eta: 22:59:46  iter: 9399  total_loss: 34.71  loss_ce: 0  loss_mask: 0.8981  loss_dice: 2.46  loss_seg: 0.9943  loss_ce_0: 0  loss_mask_0: 0.9132  loss_dice_0: 2.517  loss_ce_1: 0  loss_mask_1: 0.9096  loss_dice_1: 2.445  loss_ce_2: 0  loss_mask_2: 0.9102  loss_dice_2: 2.437  loss_ce_3: 0  loss_mask_3: 0.9142  loss_dice_3: 2.44  loss_ce_4: 0  loss_mask_4: 0.9159  loss_dice_4: 2.436  loss_ce_5: 0  loss_mask_5: 0.9157  loss_dice_5: 2.442  loss_ce_6: 0  loss_mask_6: 0.9148  loss_dice_6: 2.44  loss_ce_7: 0  loss_mask_7: 0.9098  loss_dice_7: 2.439  loss_ce_8: 0  loss_mask_8: 0.9081  loss_dice_8: 2.444  time: 2.3351  data_time: 0.0298  lr: 8.5784e-05  max_mem: 6000M
[02/18 05:43:29] d2.utils.events INFO:  eta: 22:59:41  iter: 9419  total_loss: 36.15  loss_ce: 0  loss_mask: 0.9597  loss_dice: 2.591  loss_seg: 0.8207  loss_ce_0: 0  loss_mask_0: 0.9782  loss_dice_0: 2.628  loss_ce_1: 0  loss_mask_1: 0.9592  loss_dice_1: 2.595  loss_ce_2: 0  loss_mask_2: 0.9577  loss_dice_2: 2.587  loss_ce_3: 0  loss_mask_3: 0.9595  loss_dice_3: 2.575  loss_ce_4: 0  loss_mask_4: 0.9626  loss_dice_4: 2.579  loss_ce_5: 0  loss_mask_5: 0.9604  loss_dice_5: 2.582  loss_ce_6: 0  loss_mask_6: 0.9652  loss_dice_6: 2.579  loss_ce_7: 0  loss_mask_7: 0.9678  loss_dice_7: 2.582  loss_ce_8: 0  loss_mask_8: 0.9676  loss_dice_8: 2.581  time: 2.3335  data_time: 0.0334  lr: 8.5754e-05  max_mem: 6000M
[02/18 05:44:02] d2.utils.events INFO:  eta: 22:59:09  iter: 9439  total_loss: 36.97  loss_ce: 0  loss_mask: 0.9654  loss_dice: 2.643  loss_seg: 1.1  loss_ce_0: 0  loss_mask_0: 0.9852  loss_dice_0: 2.684  loss_ce_1: 0  loss_mask_1: 0.9763  loss_dice_1: 2.637  loss_ce_2: 0  loss_mask_2: 0.9767  loss_dice_2: 2.634  loss_ce_3: 0  loss_mask_3: 0.9768  loss_dice_3: 2.63  loss_ce_4: 0  loss_mask_4: 0.9752  loss_dice_4: 2.628  loss_ce_5: 0  loss_mask_5: 0.9735  loss_dice_5: 2.634  loss_ce_6: 0  loss_mask_6: 0.9734  loss_dice_6: 2.628  loss_ce_7: 0  loss_mask_7: 0.977  loss_dice_7: 2.632  loss_ce_8: 0  loss_mask_8: 0.9773  loss_dice_8: 2.631  time: 2.3321  data_time: 0.0407  lr: 8.5723e-05  max_mem: 6000M
[02/18 05:44:36] d2.utils.events INFO:  eta: 23:00:25  iter: 9459  total_loss: 34.67  loss_ce: 0  loss_mask: 0.9348  loss_dice: 2.45  loss_seg: 0.762  loss_ce_0: 0  loss_mask_0: 0.9339  loss_dice_0: 2.5  loss_ce_1: 0  loss_mask_1: 0.932  loss_dice_1: 2.443  loss_ce_2: 0  loss_mask_2: 0.9383  loss_dice_2: 2.44  loss_ce_3: 0  loss_mask_3: 0.9444  loss_dice_3: 2.426  loss_ce_4: 0  loss_mask_4: 0.9426  loss_dice_4: 2.429  loss_ce_5: 0  loss_mask_5: 0.9412  loss_dice_5: 2.435  loss_ce_6: 0  loss_mask_6: 0.944  loss_dice_6: 2.43  loss_ce_7: 0  loss_mask_7: 0.9474  loss_dice_7: 2.433  loss_ce_8: 0  loss_mask_8: 0.9472  loss_dice_8: 2.436  time: 2.3307  data_time: 0.0336  lr: 8.5693e-05  max_mem: 6000M
[02/18 05:45:08] d2.utils.events INFO:  eta: 23:00:04  iter: 9479  total_loss: 36.87  loss_ce: 0  loss_mask: 0.9458  loss_dice: 2.636  loss_seg: 1.006  loss_ce_0: 0  loss_mask_0: 0.9521  loss_dice_0: 2.695  loss_ce_1: 0  loss_mask_1: 0.9495  loss_dice_1: 2.635  loss_ce_2: 0  loss_mask_2: 0.9503  loss_dice_2: 2.621  loss_ce_3: 0  loss_mask_3: 0.9557  loss_dice_3: 2.628  loss_ce_4: 0  loss_mask_4: 0.9521  loss_dice_4: 2.624  loss_ce_5: 0  loss_mask_5: 0.9517  loss_dice_5: 2.625  loss_ce_6: 0  loss_mask_6: 0.9531  loss_dice_6: 2.627  loss_ce_7: 0  loss_mask_7: 0.9545  loss_dice_7: 2.62  loss_ce_8: 0  loss_mask_8: 0.9579  loss_dice_8: 2.617  time: 2.3291  data_time: 0.0229  lr: 8.5662e-05  max_mem: 6000M
[02/18 05:45:40] d2.utils.events INFO:  eta: 22:58:42  iter: 9499  total_loss: 37.19  loss_ce: 0  loss_mask: 1.001  loss_dice: 2.587  loss_seg: 0.8641  loss_ce_0: 0  loss_mask_0: 1.004  loss_dice_0: 2.654  loss_ce_1: 0  loss_mask_1: 1.004  loss_dice_1: 2.592  loss_ce_2: 0  loss_mask_2: 1.009  loss_dice_2: 2.58  loss_ce_3: 0  loss_mask_3: 1.009  loss_dice_3: 2.567  loss_ce_4: 0  loss_mask_4: 1.014  loss_dice_4: 2.565  loss_ce_5: 0  loss_mask_5: 1.017  loss_dice_5: 2.566  loss_ce_6: 0  loss_mask_6: 1.014  loss_dice_6: 2.567  loss_ce_7: 0  loss_mask_7: 1.011  loss_dice_7: 2.572  loss_ce_8: 0  loss_mask_8: 1.015  loss_dice_8: 2.569  time: 2.3276  data_time: 0.0326  lr: 8.5632e-05  max_mem: 6000M
[02/18 05:46:11] d2.utils.events INFO:  eta: 22:55:39  iter: 9519  total_loss: 35.44  loss_ce: 0  loss_mask: 0.9607  loss_dice: 2.5  loss_seg: 0.7975  loss_ce_0: 0  loss_mask_0: 0.9745  loss_dice_0: 2.546  loss_ce_1: 0  loss_mask_1: 0.9635  loss_dice_1: 2.5  loss_ce_2: 0  loss_mask_2: 0.9607  loss_dice_2: 2.485  loss_ce_3: 0  loss_mask_3: 0.9622  loss_dice_3: 2.478  loss_ce_4: 0  loss_mask_4: 0.9631  loss_dice_4: 2.478  loss_ce_5: 0  loss_mask_5: 0.965  loss_dice_5: 2.478  loss_ce_6: 0  loss_mask_6: 0.9646  loss_dice_6: 2.481  loss_ce_7: 0  loss_mask_7: 0.9659  loss_dice_7: 2.481  loss_ce_8: 0  loss_mask_8: 0.968  loss_dice_8: 2.476  time: 2.3260  data_time: 0.0308  lr: 8.5601e-05  max_mem: 6000M
[02/18 05:46:45] d2.utils.events INFO:  eta: 22:56:25  iter: 9539  total_loss: 34.06  loss_ce: 0  loss_mask: 0.9233  loss_dice: 2.341  loss_seg: 0.9453  loss_ce_0: 0  loss_mask_0: 0.9177  loss_dice_0: 2.421  loss_ce_1: 0  loss_mask_1: 0.9262  loss_dice_1: 2.339  loss_ce_2: 0  loss_mask_2: 0.9188  loss_dice_2: 2.33  loss_ce_3: 0  loss_mask_3: 0.9252  loss_dice_3: 2.318  loss_ce_4: 0  loss_mask_4: 0.9217  loss_dice_4: 2.322  loss_ce_5: 0  loss_mask_5: 0.9228  loss_dice_5: 2.327  loss_ce_6: 0  loss_mask_6: 0.9249  loss_dice_6: 2.317  loss_ce_7: 0  loss_mask_7: 0.9239  loss_dice_7: 2.311  loss_ce_8: 0  loss_mask_8: 0.9278  loss_dice_8: 2.323  time: 2.3246  data_time: 0.0333  lr: 8.5571e-05  max_mem: 6000M
[02/18 05:47:15] d2.utils.events INFO:  eta: 22:51:55  iter: 9559  total_loss: 36.37  loss_ce: 0  loss_mask: 0.9651  loss_dice: 2.612  loss_seg: 0.7526  loss_ce_0: 0  loss_mask_0: 0.9815  loss_dice_0: 2.653  loss_ce_1: 0  loss_mask_1: 0.9743  loss_dice_1: 2.608  loss_ce_2: 0  loss_mask_2: 0.9695  loss_dice_2: 2.599  loss_ce_3: 0  loss_mask_3: 0.9741  loss_dice_3: 2.599  loss_ce_4: 0  loss_mask_4: 0.9755  loss_dice_4: 2.598  loss_ce_5: 0  loss_mask_5: 0.9723  loss_dice_5: 2.595  loss_ce_6: 0  loss_mask_6: 0.9784  loss_dice_6: 2.592  loss_ce_7: 0  loss_mask_7: 0.9764  loss_dice_7: 2.592  loss_ce_8: 0  loss_mask_8: 0.9767  loss_dice_8: 2.591  time: 2.3229  data_time: 0.0323  lr: 8.554e-05  max_mem: 6000M
[02/18 05:47:48] d2.utils.events INFO:  eta: 22:54:01  iter: 9579  total_loss: 35.68  loss_ce: 0  loss_mask: 0.9925  loss_dice: 2.509  loss_seg: 0.8074  loss_ce_0: 0  loss_mask_0: 1.016  loss_dice_0: 2.563  loss_ce_1: 0  loss_mask_1: 0.9995  loss_dice_1: 2.498  loss_ce_2: 0  loss_mask_2: 0.9961  loss_dice_2: 2.486  loss_ce_3: 0  loss_mask_3: 0.9941  loss_dice_3: 2.484  loss_ce_4: 0  loss_mask_4: 0.9943  loss_dice_4: 2.489  loss_ce_5: 0  loss_mask_5: 0.9942  loss_dice_5: 2.491  loss_ce_6: 0  loss_mask_6: 0.9922  loss_dice_6: 2.497  loss_ce_7: 0  loss_mask_7: 0.9937  loss_dice_7: 2.497  loss_ce_8: 0  loss_mask_8: 0.9914  loss_dice_8: 2.495  time: 2.3215  data_time: 0.0306  lr: 8.5509e-05  max_mem: 6000M
[02/18 05:48:21] d2.utils.events INFO:  eta: 22:54:01  iter: 9599  total_loss: 36.81  loss_ce: 0  loss_mask: 0.9432  loss_dice: 2.541  loss_seg: 1.094  loss_ce_0: 0  loss_mask_0: 0.949  loss_dice_0: 2.584  loss_ce_1: 0  loss_mask_1: 0.9457  loss_dice_1: 2.552  loss_ce_2: 0  loss_mask_2: 0.9463  loss_dice_2: 2.54  loss_ce_3: 0  loss_mask_3: 0.9529  loss_dice_3: 2.528  loss_ce_4: 0  loss_mask_4: 0.9528  loss_dice_4: 2.531  loss_ce_5: 0  loss_mask_5: 0.9539  loss_dice_5: 2.534  loss_ce_6: 0  loss_mask_6: 0.9531  loss_dice_6: 2.533  loss_ce_7: 0  loss_mask_7: 0.9535  loss_dice_7: 2.534  loss_ce_8: 0  loss_mask_8: 0.9457  loss_dice_8: 2.53  time: 2.3201  data_time: 0.0313  lr: 8.5479e-05  max_mem: 6000M
[02/18 05:48:53] d2.utils.events INFO:  eta: 22:54:45  iter: 9619  total_loss: 37.42  loss_ce: 0  loss_mask: 0.9692  loss_dice: 2.636  loss_seg: 0.9613  loss_ce_0: 0  loss_mask_0: 0.989  loss_dice_0: 2.656  loss_ce_1: 0  loss_mask_1: 0.9685  loss_dice_1: 2.633  loss_ce_2: 0  loss_mask_2: 0.9672  loss_dice_2: 2.625  loss_ce_3: 0  loss_mask_3: 0.9844  loss_dice_3: 2.616  loss_ce_4: 0  loss_mask_4: 0.988  loss_dice_4: 2.611  loss_ce_5: 0  loss_mask_5: 0.9878  loss_dice_5: 2.62  loss_ce_6: 0  loss_mask_6: 0.9898  loss_dice_6: 2.616  loss_ce_7: 0  loss_mask_7: 0.9829  loss_dice_7: 2.624  loss_ce_8: 0  loss_mask_8: 0.9807  loss_dice_8: 2.618  time: 2.3186  data_time: 0.0352  lr: 8.5448e-05  max_mem: 6000M
[02/18 05:49:27] d2.utils.events INFO:  eta: 22:53:41  iter: 9639  total_loss: 34.48  loss_ce: 0  loss_mask: 0.9092  loss_dice: 2.416  loss_seg: 1.017  loss_ce_0: 0  loss_mask_0: 0.9113  loss_dice_0: 2.495  loss_ce_1: 0  loss_mask_1: 0.9176  loss_dice_1: 2.418  loss_ce_2: 0  loss_mask_2: 0.9172  loss_dice_2: 2.398  loss_ce_3: 0  loss_mask_3: 0.9169  loss_dice_3: 2.397  loss_ce_4: 0  loss_mask_4: 0.92  loss_dice_4: 2.402  loss_ce_5: 0  loss_mask_5: 0.917  loss_dice_5: 2.406  loss_ce_6: 0  loss_mask_6: 0.9138  loss_dice_6: 2.406  loss_ce_7: 0  loss_mask_7: 0.9142  loss_dice_7: 2.405  loss_ce_8: 0  loss_mask_8: 0.9189  loss_dice_8: 2.405  time: 2.3173  data_time: 0.0303  lr: 8.5418e-05  max_mem: 6000M
[02/18 05:49:58] d2.utils.events INFO:  eta: 22:52:23  iter: 9659  total_loss: 34.86  loss_ce: 0  loss_mask: 0.9681  loss_dice: 2.48  loss_seg: 0.8784  loss_ce_0: 0  loss_mask_0: 0.9709  loss_dice_0: 2.515  loss_ce_1: 0  loss_mask_1: 0.9639  loss_dice_1: 2.479  loss_ce_2: 0  loss_mask_2: 0.9638  loss_dice_2: 2.463  loss_ce_3: 0  loss_mask_3: 0.9652  loss_dice_3: 2.458  loss_ce_4: 0  loss_mask_4: 0.9652  loss_dice_4: 2.46  loss_ce_5: 0  loss_mask_5: 0.9652  loss_dice_5: 2.466  loss_ce_6: 0  loss_mask_6: 0.9673  loss_dice_6: 2.459  loss_ce_7: 0  loss_mask_7: 0.9694  loss_dice_7: 2.46  loss_ce_8: 0  loss_mask_8: 0.9673  loss_dice_8: 2.462  time: 2.3157  data_time: 0.0273  lr: 8.5387e-05  max_mem: 6000M
[02/18 05:50:31] d2.utils.events INFO:  eta: 22:48:39  iter: 9679  total_loss: 36.01  loss_ce: 0  loss_mask: 0.9363  loss_dice: 2.529  loss_seg: 0.9124  loss_ce_0: 0  loss_mask_0: 0.9409  loss_dice_0: 2.581  loss_ce_1: 0  loss_mask_1: 0.9395  loss_dice_1: 2.533  loss_ce_2: 0  loss_mask_2: 0.9425  loss_dice_2: 2.514  loss_ce_3: 0  loss_mask_3: 0.9419  loss_dice_3: 2.507  loss_ce_4: 0  loss_mask_4: 0.9394  loss_dice_4: 2.509  loss_ce_5: 0  loss_mask_5: 0.9415  loss_dice_5: 2.512  loss_ce_6: 0  loss_mask_6: 0.9455  loss_dice_6: 2.507  loss_ce_7: 0  loss_mask_7: 0.9469  loss_dice_7: 2.513  loss_ce_8: 0  loss_mask_8: 0.9467  loss_dice_8: 2.513  time: 2.3144  data_time: 0.0314  lr: 8.5357e-05  max_mem: 6000M
[02/18 05:51:05] d2.utils.events INFO:  eta: 22:46:34  iter: 9699  total_loss: 35.05  loss_ce: 0  loss_mask: 0.8901  loss_dice: 2.509  loss_seg: 0.9153  loss_ce_0: 0  loss_mask_0: 0.8983  loss_dice_0: 2.585  loss_ce_1: 0  loss_mask_1: 0.8893  loss_dice_1: 2.511  loss_ce_2: 0  loss_mask_2: 0.894  loss_dice_2: 2.5  loss_ce_3: 0  loss_mask_3: 0.8953  loss_dice_3: 2.491  loss_ce_4: 0  loss_mask_4: 0.8952  loss_dice_4: 2.503  loss_ce_5: 0  loss_mask_5: 0.8929  loss_dice_5: 2.498  loss_ce_6: 0  loss_mask_6: 0.8929  loss_dice_6: 2.496  loss_ce_7: 0  loss_mask_7: 0.8928  loss_dice_7: 2.491  loss_ce_8: 0  loss_mask_8: 0.898  loss_dice_8: 2.493  time: 2.3130  data_time: 0.0286  lr: 8.5326e-05  max_mem: 6000M
[02/18 05:51:35] d2.utils.events INFO:  eta: 22:44:34  iter: 9719  total_loss: 36.42  loss_ce: 0  loss_mask: 0.9527  loss_dice: 2.603  loss_seg: 1.159  loss_ce_0: 0  loss_mask_0: 0.9641  loss_dice_0: 2.697  loss_ce_1: 0  loss_mask_1: 0.9509  loss_dice_1: 2.631  loss_ce_2: 0  loss_mask_2: 0.9507  loss_dice_2: 2.615  loss_ce_3: 0  loss_mask_3: 0.9529  loss_dice_3: 2.605  loss_ce_4: 0  loss_mask_4: 0.9556  loss_dice_4: 2.597  loss_ce_5: 0  loss_mask_5: 0.9558  loss_dice_5: 2.601  loss_ce_6: 0  loss_mask_6: 0.959  loss_dice_6: 2.596  loss_ce_7: 0  loss_mask_7: 0.9569  loss_dice_7: 2.603  loss_ce_8: 0  loss_mask_8: 0.9595  loss_dice_8: 2.605  time: 2.3114  data_time: 0.0242  lr: 8.5296e-05  max_mem: 6000M
[02/18 05:52:09] d2.utils.events INFO:  eta: 22:47:54  iter: 9739  total_loss: 36.44  loss_ce: 0  loss_mask: 0.9134  loss_dice: 2.608  loss_seg: 0.9836  loss_ce_0: 0  loss_mask_0: 0.9147  loss_dice_0: 2.665  loss_ce_1: 0  loss_mask_1: 0.9176  loss_dice_1: 2.617  loss_ce_2: 0  loss_mask_2: 0.9216  loss_dice_2: 2.603  loss_ce_3: 0  loss_mask_3: 0.9169  loss_dice_3: 2.591  loss_ce_4: 0  loss_mask_4: 0.9127  loss_dice_4: 2.595  loss_ce_5: 0  loss_mask_5: 0.9178  loss_dice_5: 2.599  loss_ce_6: 0  loss_mask_6: 0.9146  loss_dice_6: 2.594  loss_ce_7: 0  loss_mask_7: 0.9159  loss_dice_7: 2.587  loss_ce_8: 0  loss_mask_8: 0.9215  loss_dice_8: 2.587  time: 2.3101  data_time: 0.0283  lr: 8.5265e-05  max_mem: 6000M
[02/18 05:52:44] d2.utils.events INFO:  eta: 22:50:56  iter: 9759  total_loss: 35.56  loss_ce: 0  loss_mask: 0.9305  loss_dice: 2.448  loss_seg: 0.7502  loss_ce_0: 0  loss_mask_0: 0.9258  loss_dice_0: 2.499  loss_ce_1: 0  loss_mask_1: 0.9347  loss_dice_1: 2.454  loss_ce_2: 0  loss_mask_2: 0.9284  loss_dice_2: 2.445  loss_ce_3: 0  loss_mask_3: 0.9323  loss_dice_3: 2.441  loss_ce_4: 0  loss_mask_4: 0.9396  loss_dice_4: 2.441  loss_ce_5: 0  loss_mask_5: 0.944  loss_dice_5: 2.434  loss_ce_6: 0  loss_mask_6: 0.9362  loss_dice_6: 2.43  loss_ce_7: 0  loss_mask_7: 0.9429  loss_dice_7: 2.432  loss_ce_8: 0  loss_mask_8: 0.9385  loss_dice_8: 2.432  time: 2.3089  data_time: 0.0273  lr: 8.5235e-05  max_mem: 6000M
[02/18 05:53:18] d2.utils.events INFO:  eta: 22:50:23  iter: 9779  total_loss: 35.74  loss_ce: 0  loss_mask: 0.9356  loss_dice: 2.541  loss_seg: 0.8539  loss_ce_0: 0  loss_mask_0: 0.9443  loss_dice_0: 2.627  loss_ce_1: 0  loss_mask_1: 0.932  loss_dice_1: 2.543  loss_ce_2: 0  loss_mask_2: 0.941  loss_dice_2: 2.531  loss_ce_3: 0  loss_mask_3: 0.9465  loss_dice_3: 2.519  loss_ce_4: 0  loss_mask_4: 0.9487  loss_dice_4: 2.514  loss_ce_5: 0  loss_mask_5: 0.9501  loss_dice_5: 2.52  loss_ce_6: 0  loss_mask_6: 0.9423  loss_dice_6: 2.524  loss_ce_7: 0  loss_mask_7: 0.9443  loss_dice_7: 2.519  loss_ce_8: 0  loss_mask_8: 0.9451  loss_dice_8: 2.521  time: 2.3077  data_time: 0.0235  lr: 8.5204e-05  max_mem: 6000M
[02/18 05:53:50] d2.utils.events INFO:  eta: 22:50:07  iter: 9799  total_loss: 35.23  loss_ce: 0  loss_mask: 0.8956  loss_dice: 2.51  loss_seg: 0.7677  loss_ce_0: 0  loss_mask_0: 0.8994  loss_dice_0: 2.536  loss_ce_1: 0  loss_mask_1: 0.9039  loss_dice_1: 2.502  loss_ce_2: 0  loss_mask_2: 0.9111  loss_dice_2: 2.489  loss_ce_3: 0  loss_mask_3: 0.9051  loss_dice_3: 2.484  loss_ce_4: 0  loss_mask_4: 0.9009  loss_dice_4: 2.491  loss_ce_5: 0  loss_mask_5: 0.8997  loss_dice_5: 2.495  loss_ce_6: 0  loss_mask_6: 0.9053  loss_dice_6: 2.485  loss_ce_7: 0  loss_mask_7: 0.9108  loss_dice_7: 2.48  loss_ce_8: 0  loss_mask_8: 0.9068  loss_dice_8: 2.485  time: 2.3062  data_time: 0.0331  lr: 8.5174e-05  max_mem: 6000M
[02/18 05:54:24] d2.utils.events INFO:  eta: 22:49:35  iter: 9819  total_loss: 33.64  loss_ce: 0  loss_mask: 0.8947  loss_dice: 2.41  loss_seg: 0.8317  loss_ce_0: 0  loss_mask_0: 0.9014  loss_dice_0: 2.478  loss_ce_1: 0  loss_mask_1: 0.8964  loss_dice_1: 2.404  loss_ce_2: 0  loss_mask_2: 0.8962  loss_dice_2: 2.398  loss_ce_3: 0  loss_mask_3: 0.9048  loss_dice_3: 2.383  loss_ce_4: 0  loss_mask_4: 0.8974  loss_dice_4: 2.386  loss_ce_5: 0  loss_mask_5: 0.899  loss_dice_5: 2.389  loss_ce_6: 0  loss_mask_6: 0.9019  loss_dice_6: 2.389  loss_ce_7: 0  loss_mask_7: 0.8974  loss_dice_7: 2.39  loss_ce_8: 0  loss_mask_8: 0.9  loss_dice_8: 2.387  time: 2.3050  data_time: 0.0298  lr: 8.5143e-05  max_mem: 6000M
[02/18 05:54:57] d2.utils.events INFO:  eta: 22:49:25  iter: 9839  total_loss: 35.62  loss_ce: 0  loss_mask: 0.9436  loss_dice: 2.467  loss_seg: 0.9652  loss_ce_0: 0  loss_mask_0: 0.9422  loss_dice_0: 2.517  loss_ce_1: 0  loss_mask_1: 0.9441  loss_dice_1: 2.459  loss_ce_2: 0  loss_mask_2: 0.9486  loss_dice_2: 2.457  loss_ce_3: 0  loss_mask_3: 0.9515  loss_dice_3: 2.445  loss_ce_4: 0  loss_mask_4: 0.9603  loss_dice_4: 2.447  loss_ce_5: 0  loss_mask_5: 0.9533  loss_dice_5: 2.451  loss_ce_6: 0  loss_mask_6: 0.9577  loss_dice_6: 2.447  loss_ce_7: 0  loss_mask_7: 0.9554  loss_dice_7: 2.446  loss_ce_8: 0  loss_mask_8: 0.9556  loss_dice_8: 2.446  time: 2.3037  data_time: 0.0343  lr: 8.5113e-05  max_mem: 6000M
[02/18 05:55:33] d2.utils.events INFO:  eta: 22:49:50  iter: 9859  total_loss: 35.62  loss_ce: 0  loss_mask: 0.9379  loss_dice: 2.503  loss_seg: 0.9958  loss_ce_0: 0  loss_mask_0: 0.9485  loss_dice_0: 2.566  loss_ce_1: 0  loss_mask_1: 0.9425  loss_dice_1: 2.495  loss_ce_2: 0  loss_mask_2: 0.9407  loss_dice_2: 2.485  loss_ce_3: 0  loss_mask_3: 0.9463  loss_dice_3: 2.474  loss_ce_4: 0  loss_mask_4: 0.9467  loss_dice_4: 2.478  loss_ce_5: 0  loss_mask_5: 0.9433  loss_dice_5: 2.484  loss_ce_6: 0  loss_mask_6: 0.9461  loss_dice_6: 2.488  loss_ce_7: 0  loss_mask_7: 0.9456  loss_dice_7: 2.482  loss_ce_8: 0  loss_mask_8: 0.9388  loss_dice_8: 2.485  time: 2.3026  data_time: 0.0358  lr: 8.5082e-05  max_mem: 6000M
[02/18 05:56:06] d2.utils.events INFO:  eta: 22:49:17  iter: 9879  total_loss: 34.44  loss_ce: 0  loss_mask: 0.9694  loss_dice: 2.389  loss_seg: 0.8673  loss_ce_0: 0  loss_mask_0: 0.9791  loss_dice_0: 2.467  loss_ce_1: 0  loss_mask_1: 0.9607  loss_dice_1: 2.396  loss_ce_2: 0  loss_mask_2: 0.9637  loss_dice_2: 2.373  loss_ce_3: 0  loss_mask_3: 0.9654  loss_dice_3: 2.365  loss_ce_4: 0  loss_mask_4: 0.967  loss_dice_4: 2.366  loss_ce_5: 0  loss_mask_5: 0.9714  loss_dice_5: 2.362  loss_ce_6: 0  loss_mask_6: 0.9697  loss_dice_6: 2.366  loss_ce_7: 0  loss_mask_7: 0.9702  loss_dice_7: 2.368  loss_ce_8: 0  loss_mask_8: 0.9691  loss_dice_8: 2.378  time: 2.3013  data_time: 0.0285  lr: 8.5051e-05  max_mem: 6000M
[02/18 05:56:37] d2.utils.events INFO:  eta: 22:48:44  iter: 9899  total_loss: 35.14  loss_ce: 0  loss_mask: 0.9025  loss_dice: 2.52  loss_seg: 0.823  loss_ce_0: 0  loss_mask_0: 0.9135  loss_dice_0: 2.557  loss_ce_1: 0  loss_mask_1: 0.9073  loss_dice_1: 2.523  loss_ce_2: 0  loss_mask_2: 0.9071  loss_dice_2: 2.505  loss_ce_3: 0  loss_mask_3: 0.9097  loss_dice_3: 2.5  loss_ce_4: 0  loss_mask_4: 0.9083  loss_dice_4: 2.506  loss_ce_5: 0  loss_mask_5: 0.9083  loss_dice_5: 2.507  loss_ce_6: 0  loss_mask_6: 0.9133  loss_dice_6: 2.499  loss_ce_7: 0  loss_mask_7: 0.9141  loss_dice_7: 2.5  loss_ce_8: 0  loss_mask_8: 0.9125  loss_dice_8: 2.5  time: 2.2998  data_time: 0.0301  lr: 8.5021e-05  max_mem: 6000M
[02/18 05:57:08] d2.utils.events INFO:  eta: 22:47:34  iter: 9919  total_loss: 36.71  loss_ce: 0  loss_mask: 0.9216  loss_dice: 2.57  loss_seg: 1.081  loss_ce_0: 0  loss_mask_0: 0.922  loss_dice_0: 2.64  loss_ce_1: 0  loss_mask_1: 0.9193  loss_dice_1: 2.579  loss_ce_2: 0  loss_mask_2: 0.9215  loss_dice_2: 2.56  loss_ce_3: 0  loss_mask_3: 0.9295  loss_dice_3: 2.559  loss_ce_4: 0  loss_mask_4: 0.9328  loss_dice_4: 2.569  loss_ce_5: 0  loss_mask_5: 0.9285  loss_dice_5: 2.571  loss_ce_6: 0  loss_mask_6: 0.9287  loss_dice_6: 2.558  loss_ce_7: 0  loss_mask_7: 0.924  loss_dice_7: 2.558  loss_ce_8: 0  loss_mask_8: 0.925  loss_dice_8: 2.562  time: 2.2982  data_time: 0.0254  lr: 8.499e-05  max_mem: 6000M
[02/18 05:57:40] d2.utils.events INFO:  eta: 22:47:18  iter: 9939  total_loss: 33.99  loss_ce: 0  loss_mask: 0.9151  loss_dice: 2.408  loss_seg: 0.6848  loss_ce_0: 0  loss_mask_0: 0.9251  loss_dice_0: 2.472  loss_ce_1: 0  loss_mask_1: 0.9112  loss_dice_1: 2.412  loss_ce_2: 0  loss_mask_2: 0.9122  loss_dice_2: 2.394  loss_ce_3: 0  loss_mask_3: 0.9203  loss_dice_3: 2.389  loss_ce_4: 0  loss_mask_4: 0.9176  loss_dice_4: 2.388  loss_ce_5: 0  loss_mask_5: 0.919  loss_dice_5: 2.39  loss_ce_6: 0  loss_mask_6: 0.9175  loss_dice_6: 2.387  loss_ce_7: 0  loss_mask_7: 0.9193  loss_dice_7: 2.391  loss_ce_8: 0  loss_mask_8: 0.9177  loss_dice_8: 2.39  time: 2.2968  data_time: 0.0305  lr: 8.496e-05  max_mem: 6000M
[02/18 05:58:14] d2.utils.events INFO:  eta: 22:45:29  iter: 9959  total_loss: 34.06  loss_ce: 0  loss_mask: 0.9316  loss_dice: 2.382  loss_seg: 0.9246  loss_ce_0: 0  loss_mask_0: 0.9484  loss_dice_0: 2.47  loss_ce_1: 0  loss_mask_1: 0.9429  loss_dice_1: 2.391  loss_ce_2: 0  loss_mask_2: 0.937  loss_dice_2: 2.38  loss_ce_3: 0  loss_mask_3: 0.9355  loss_dice_3: 2.365  loss_ce_4: 0  loss_mask_4: 0.9379  loss_dice_4: 2.369  loss_ce_5: 0  loss_mask_5: 0.939  loss_dice_5: 2.37  loss_ce_6: 0  loss_mask_6: 0.9378  loss_dice_6: 2.372  loss_ce_7: 0  loss_mask_7: 0.9357  loss_dice_7: 2.369  loss_ce_8: 0  loss_mask_8: 0.9413  loss_dice_8: 2.367  time: 2.2956  data_time: 0.0315  lr: 8.4929e-05  max_mem: 6000M
[02/18 05:58:48] d2.utils.events INFO:  eta: 22:43:40  iter: 9979  total_loss: 35.79  loss_ce: 0  loss_mask: 0.9463  loss_dice: 2.559  loss_seg: 0.9946  loss_ce_0: 0  loss_mask_0: 0.9402  loss_dice_0: 2.586  loss_ce_1: 0  loss_mask_1: 0.9531  loss_dice_1: 2.553  loss_ce_2: 0  loss_mask_2: 0.956  loss_dice_2: 2.536  loss_ce_3: 0  loss_mask_3: 0.9551  loss_dice_3: 2.529  loss_ce_4: 0  loss_mask_4: 0.9545  loss_dice_4: 2.534  loss_ce_5: 0  loss_mask_5: 0.9537  loss_dice_5: 2.529  loss_ce_6: 0  loss_mask_6: 0.9547  loss_dice_6: 2.532  loss_ce_7: 0  loss_mask_7: 0.9546  loss_dice_7: 2.537  loss_ce_8: 0  loss_mask_8: 0.949  loss_dice_8: 2.542  time: 2.2944  data_time: 0.0277  lr: 8.4899e-05  max_mem: 6000M
[02/18 05:59:23] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0009999.pth
[02/18 05:59:24] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 05:59:25] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 05:59:25] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 05:59:39] mask2former INFO: Inference done 11/1093. Dataloading: 0.0042 s/iter. Inference: 0.2497 s/iter. Eval: 0.1035 s/iter. Total: 0.3574 s/iter. ETA=0:06:26
[02/18 05:59:44] mask2former INFO: Inference done 26/1093. Dataloading: 0.0049 s/iter. Inference: 0.2324 s/iter. Eval: 0.1149 s/iter. Total: 0.3522 s/iter. ETA=0:06:15
[02/18 05:59:50] mask2former INFO: Inference done 41/1093. Dataloading: 0.0048 s/iter. Inference: 0.2297 s/iter. Eval: 0.1129 s/iter. Total: 0.3475 s/iter. ETA=0:06:05
[02/18 05:59:55] mask2former INFO: Inference done 55/1093. Dataloading: 0.0050 s/iter. Inference: 0.2314 s/iter. Eval: 0.1173 s/iter. Total: 0.3538 s/iter. ETA=0:06:07
[02/18 06:00:00] mask2former INFO: Inference done 69/1093. Dataloading: 0.0051 s/iter. Inference: 0.2328 s/iter. Eval: 0.1169 s/iter. Total: 0.3548 s/iter. ETA=0:06:03
[02/18 06:00:05] mask2former INFO: Inference done 82/1093. Dataloading: 0.0053 s/iter. Inference: 0.2389 s/iter. Eval: 0.1160 s/iter. Total: 0.3604 s/iter. ETA=0:06:04
[02/18 06:00:10] mask2former INFO: Inference done 96/1093. Dataloading: 0.0054 s/iter. Inference: 0.2387 s/iter. Eval: 0.1165 s/iter. Total: 0.3606 s/iter. ETA=0:05:59
[02/18 06:00:15] mask2former INFO: Inference done 110/1093. Dataloading: 0.0054 s/iter. Inference: 0.2378 s/iter. Eval: 0.1182 s/iter. Total: 0.3615 s/iter. ETA=0:05:55
[02/18 06:00:20] mask2former INFO: Inference done 125/1093. Dataloading: 0.0054 s/iter. Inference: 0.2375 s/iter. Eval: 0.1175 s/iter. Total: 0.3604 s/iter. ETA=0:05:48
[02/18 06:00:26] mask2former INFO: Inference done 139/1093. Dataloading: 0.0054 s/iter. Inference: 0.2375 s/iter. Eval: 0.1192 s/iter. Total: 0.3622 s/iter. ETA=0:05:45
[02/18 06:00:31] mask2former INFO: Inference done 154/1093. Dataloading: 0.0053 s/iter. Inference: 0.2369 s/iter. Eval: 0.1179 s/iter. Total: 0.3603 s/iter. ETA=0:05:38
[02/18 06:00:36] mask2former INFO: Inference done 169/1093. Dataloading: 0.0054 s/iter. Inference: 0.2369 s/iter. Eval: 0.1175 s/iter. Total: 0.3598 s/iter. ETA=0:05:32
[02/18 06:00:41] mask2former INFO: Inference done 184/1093. Dataloading: 0.0054 s/iter. Inference: 0.2370 s/iter. Eval: 0.1170 s/iter. Total: 0.3594 s/iter. ETA=0:05:26
[02/18 06:00:47] mask2former INFO: Inference done 198/1093. Dataloading: 0.0054 s/iter. Inference: 0.2377 s/iter. Eval: 0.1171 s/iter. Total: 0.3603 s/iter. ETA=0:05:22
[02/18 06:00:52] mask2former INFO: Inference done 213/1093. Dataloading: 0.0054 s/iter. Inference: 0.2378 s/iter. Eval: 0.1163 s/iter. Total: 0.3596 s/iter. ETA=0:05:16
[02/18 06:00:57] mask2former INFO: Inference done 227/1093. Dataloading: 0.0054 s/iter. Inference: 0.2377 s/iter. Eval: 0.1167 s/iter. Total: 0.3599 s/iter. ETA=0:05:11
[02/18 06:01:02] mask2former INFO: Inference done 241/1093. Dataloading: 0.0054 s/iter. Inference: 0.2380 s/iter. Eval: 0.1163 s/iter. Total: 0.3598 s/iter. ETA=0:05:06
[02/18 06:01:07] mask2former INFO: Inference done 256/1093. Dataloading: 0.0054 s/iter. Inference: 0.2371 s/iter. Eval: 0.1164 s/iter. Total: 0.3591 s/iter. ETA=0:05:00
[02/18 06:01:12] mask2former INFO: Inference done 271/1093. Dataloading: 0.0054 s/iter. Inference: 0.2366 s/iter. Eval: 0.1161 s/iter. Total: 0.3583 s/iter. ETA=0:04:54
[02/18 06:01:17] mask2former INFO: Inference done 285/1093. Dataloading: 0.0054 s/iter. Inference: 0.2367 s/iter. Eval: 0.1164 s/iter. Total: 0.3586 s/iter. ETA=0:04:49
[02/18 06:01:23] mask2former INFO: Inference done 299/1093. Dataloading: 0.0055 s/iter. Inference: 0.2369 s/iter. Eval: 0.1170 s/iter. Total: 0.3594 s/iter. ETA=0:04:45
[02/18 06:01:28] mask2former INFO: Inference done 314/1093. Dataloading: 0.0054 s/iter. Inference: 0.2371 s/iter. Eval: 0.1169 s/iter. Total: 0.3596 s/iter. ETA=0:04:40
[02/18 06:01:34] mask2former INFO: Inference done 329/1093. Dataloading: 0.0054 s/iter. Inference: 0.2377 s/iter. Eval: 0.1162 s/iter. Total: 0.3594 s/iter. ETA=0:04:34
[02/18 06:01:39] mask2former INFO: Inference done 343/1093. Dataloading: 0.0055 s/iter. Inference: 0.2375 s/iter. Eval: 0.1165 s/iter. Total: 0.3596 s/iter. ETA=0:04:29
[02/18 06:01:44] mask2former INFO: Inference done 358/1093. Dataloading: 0.0055 s/iter. Inference: 0.2371 s/iter. Eval: 0.1161 s/iter. Total: 0.3588 s/iter. ETA=0:04:23
[02/18 06:01:49] mask2former INFO: Inference done 372/1093. Dataloading: 0.0054 s/iter. Inference: 0.2377 s/iter. Eval: 0.1159 s/iter. Total: 0.3592 s/iter. ETA=0:04:18
[02/18 06:01:54] mask2former INFO: Inference done 386/1093. Dataloading: 0.0054 s/iter. Inference: 0.2378 s/iter. Eval: 0.1163 s/iter. Total: 0.3596 s/iter. ETA=0:04:14
[02/18 06:01:59] mask2former INFO: Inference done 401/1093. Dataloading: 0.0054 s/iter. Inference: 0.2373 s/iter. Eval: 0.1159 s/iter. Total: 0.3588 s/iter. ETA=0:04:08
[02/18 06:02:04] mask2former INFO: Inference done 416/1093. Dataloading: 0.0054 s/iter. Inference: 0.2369 s/iter. Eval: 0.1157 s/iter. Total: 0.3581 s/iter. ETA=0:04:02
[02/18 06:02:10] mask2former INFO: Inference done 431/1093. Dataloading: 0.0054 s/iter. Inference: 0.2369 s/iter. Eval: 0.1156 s/iter. Total: 0.3579 s/iter. ETA=0:03:56
[02/18 06:02:15] mask2former INFO: Inference done 439/1093. Dataloading: 0.0056 s/iter. Inference: 0.2394 s/iter. Eval: 0.1179 s/iter. Total: 0.3629 s/iter. ETA=0:03:57
[02/18 06:02:20] mask2former INFO: Inference done 445/1093. Dataloading: 0.0056 s/iter. Inference: 0.2431 s/iter. Eval: 0.1210 s/iter. Total: 0.3698 s/iter. ETA=0:03:59
[02/18 06:02:25] mask2former INFO: Inference done 452/1093. Dataloading: 0.0057 s/iter. Inference: 0.2461 s/iter. Eval: 0.1238 s/iter. Total: 0.3757 s/iter. ETA=0:04:00
[02/18 06:02:30] mask2former INFO: Inference done 465/1093. Dataloading: 0.0057 s/iter. Inference: 0.2459 s/iter. Eval: 0.1243 s/iter. Total: 0.3760 s/iter. ETA=0:03:56
[02/18 06:02:35] mask2former INFO: Inference done 475/1093. Dataloading: 0.0058 s/iter. Inference: 0.2480 s/iter. Eval: 0.1254 s/iter. Total: 0.3793 s/iter. ETA=0:03:54
[02/18 06:02:40] mask2former INFO: Inference done 488/1093. Dataloading: 0.0058 s/iter. Inference: 0.2484 s/iter. Eval: 0.1253 s/iter. Total: 0.3796 s/iter. ETA=0:03:49
[02/18 06:02:45] mask2former INFO: Inference done 502/1093. Dataloading: 0.0058 s/iter. Inference: 0.2480 s/iter. Eval: 0.1251 s/iter. Total: 0.3791 s/iter. ETA=0:03:44
[02/18 06:02:51] mask2former INFO: Inference done 517/1093. Dataloading: 0.0058 s/iter. Inference: 0.2477 s/iter. Eval: 0.1246 s/iter. Total: 0.3782 s/iter. ETA=0:03:37
[02/18 06:02:56] mask2former INFO: Inference done 531/1093. Dataloading: 0.0058 s/iter. Inference: 0.2472 s/iter. Eval: 0.1246 s/iter. Total: 0.3777 s/iter. ETA=0:03:32
[02/18 06:03:01] mask2former INFO: Inference done 546/1093. Dataloading: 0.0057 s/iter. Inference: 0.2470 s/iter. Eval: 0.1244 s/iter. Total: 0.3772 s/iter. ETA=0:03:26
[02/18 06:03:06] mask2former INFO: Inference done 560/1093. Dataloading: 0.0057 s/iter. Inference: 0.2466 s/iter. Eval: 0.1243 s/iter. Total: 0.3768 s/iter. ETA=0:03:20
[02/18 06:03:12] mask2former INFO: Inference done 575/1093. Dataloading: 0.0057 s/iter. Inference: 0.2463 s/iter. Eval: 0.1241 s/iter. Total: 0.3762 s/iter. ETA=0:03:14
[02/18 06:03:17] mask2former INFO: Inference done 588/1093. Dataloading: 0.0057 s/iter. Inference: 0.2468 s/iter. Eval: 0.1241 s/iter. Total: 0.3768 s/iter. ETA=0:03:10
[02/18 06:03:22] mask2former INFO: Inference done 602/1093. Dataloading: 0.0057 s/iter. Inference: 0.2470 s/iter. Eval: 0.1240 s/iter. Total: 0.3768 s/iter. ETA=0:03:05
[02/18 06:03:27] mask2former INFO: Inference done 617/1093. Dataloading: 0.0057 s/iter. Inference: 0.2465 s/iter. Eval: 0.1239 s/iter. Total: 0.3762 s/iter. ETA=0:02:59
[02/18 06:03:32] mask2former INFO: Inference done 631/1093. Dataloading: 0.0057 s/iter. Inference: 0.2465 s/iter. Eval: 0.1236 s/iter. Total: 0.3759 s/iter. ETA=0:02:53
[02/18 06:03:38] mask2former INFO: Inference done 645/1093. Dataloading: 0.0057 s/iter. Inference: 0.2462 s/iter. Eval: 0.1236 s/iter. Total: 0.3757 s/iter. ETA=0:02:48
[02/18 06:03:43] mask2former INFO: Inference done 658/1093. Dataloading: 0.0057 s/iter. Inference: 0.2464 s/iter. Eval: 0.1239 s/iter. Total: 0.3762 s/iter. ETA=0:02:43
[02/18 06:03:48] mask2former INFO: Inference done 672/1093. Dataloading: 0.0057 s/iter. Inference: 0.2463 s/iter. Eval: 0.1238 s/iter. Total: 0.3760 s/iter. ETA=0:02:38
[02/18 06:03:53] mask2former INFO: Inference done 687/1093. Dataloading: 0.0057 s/iter. Inference: 0.2461 s/iter. Eval: 0.1234 s/iter. Total: 0.3753 s/iter. ETA=0:02:32
[02/18 06:03:58] mask2former INFO: Inference done 701/1093. Dataloading: 0.0057 s/iter. Inference: 0.2460 s/iter. Eval: 0.1234 s/iter. Total: 0.3752 s/iter. ETA=0:02:27
[02/18 06:04:03] mask2former INFO: Inference done 715/1093. Dataloading: 0.0057 s/iter. Inference: 0.2457 s/iter. Eval: 0.1233 s/iter. Total: 0.3748 s/iter. ETA=0:02:21
[02/18 06:04:08] mask2former INFO: Inference done 729/1093. Dataloading: 0.0057 s/iter. Inference: 0.2455 s/iter. Eval: 0.1233 s/iter. Total: 0.3746 s/iter. ETA=0:02:16
[02/18 06:04:14] mask2former INFO: Inference done 744/1093. Dataloading: 0.0057 s/iter. Inference: 0.2452 s/iter. Eval: 0.1232 s/iter. Total: 0.3741 s/iter. ETA=0:02:10
[02/18 06:04:19] mask2former INFO: Inference done 758/1093. Dataloading: 0.0057 s/iter. Inference: 0.2452 s/iter. Eval: 0.1230 s/iter. Total: 0.3740 s/iter. ETA=0:02:05
[02/18 06:04:24] mask2former INFO: Inference done 773/1093. Dataloading: 0.0057 s/iter. Inference: 0.2451 s/iter. Eval: 0.1227 s/iter. Total: 0.3735 s/iter. ETA=0:01:59
[02/18 06:04:29] mask2former INFO: Inference done 788/1093. Dataloading: 0.0057 s/iter. Inference: 0.2448 s/iter. Eval: 0.1227 s/iter. Total: 0.3733 s/iter. ETA=0:01:53
[02/18 06:04:35] mask2former INFO: Inference done 802/1093. Dataloading: 0.0057 s/iter. Inference: 0.2449 s/iter. Eval: 0.1226 s/iter. Total: 0.3733 s/iter. ETA=0:01:48
[02/18 06:04:40] mask2former INFO: Inference done 816/1093. Dataloading: 0.0057 s/iter. Inference: 0.2448 s/iter. Eval: 0.1225 s/iter. Total: 0.3731 s/iter. ETA=0:01:43
[02/18 06:04:45] mask2former INFO: Inference done 831/1093. Dataloading: 0.0057 s/iter. Inference: 0.2447 s/iter. Eval: 0.1223 s/iter. Total: 0.3727 s/iter. ETA=0:01:37
[02/18 06:04:50] mask2former INFO: Inference done 845/1093. Dataloading: 0.0056 s/iter. Inference: 0.2446 s/iter. Eval: 0.1221 s/iter. Total: 0.3725 s/iter. ETA=0:01:32
[02/18 06:04:55] mask2former INFO: Inference done 859/1093. Dataloading: 0.0056 s/iter. Inference: 0.2445 s/iter. Eval: 0.1220 s/iter. Total: 0.3723 s/iter. ETA=0:01:27
[02/18 06:05:00] mask2former INFO: Inference done 874/1093. Dataloading: 0.0056 s/iter. Inference: 0.2442 s/iter. Eval: 0.1222 s/iter. Total: 0.3720 s/iter. ETA=0:01:21
[02/18 06:05:06] mask2former INFO: Inference done 889/1093. Dataloading: 0.0056 s/iter. Inference: 0.2438 s/iter. Eval: 0.1220 s/iter. Total: 0.3716 s/iter. ETA=0:01:15
[02/18 06:05:11] mask2former INFO: Inference done 904/1093. Dataloading: 0.0056 s/iter. Inference: 0.2437 s/iter. Eval: 0.1219 s/iter. Total: 0.3713 s/iter. ETA=0:01:10
[02/18 06:05:16] mask2former INFO: Inference done 918/1093. Dataloading: 0.0056 s/iter. Inference: 0.2437 s/iter. Eval: 0.1219 s/iter. Total: 0.3713 s/iter. ETA=0:01:04
[02/18 06:05:21] mask2former INFO: Inference done 933/1093. Dataloading: 0.0056 s/iter. Inference: 0.2436 s/iter. Eval: 0.1215 s/iter. Total: 0.3709 s/iter. ETA=0:00:59
[02/18 06:05:26] mask2former INFO: Inference done 948/1093. Dataloading: 0.0056 s/iter. Inference: 0.2433 s/iter. Eval: 0.1214 s/iter. Total: 0.3704 s/iter. ETA=0:00:53
[02/18 06:05:32] mask2former INFO: Inference done 963/1093. Dataloading: 0.0056 s/iter. Inference: 0.2432 s/iter. Eval: 0.1212 s/iter. Total: 0.3701 s/iter. ETA=0:00:48
[02/18 06:05:37] mask2former INFO: Inference done 977/1093. Dataloading: 0.0056 s/iter. Inference: 0.2431 s/iter. Eval: 0.1213 s/iter. Total: 0.3701 s/iter. ETA=0:00:42
[02/18 06:05:42] mask2former INFO: Inference done 991/1093. Dataloading: 0.0056 s/iter. Inference: 0.2429 s/iter. Eval: 0.1213 s/iter. Total: 0.3699 s/iter. ETA=0:00:37
[02/18 06:05:47] mask2former INFO: Inference done 1005/1093. Dataloading: 0.0056 s/iter. Inference: 0.2429 s/iter. Eval: 0.1214 s/iter. Total: 0.3701 s/iter. ETA=0:00:32
[02/18 06:05:52] mask2former INFO: Inference done 1020/1093. Dataloading: 0.0056 s/iter. Inference: 0.2428 s/iter. Eval: 0.1212 s/iter. Total: 0.3697 s/iter. ETA=0:00:26
[02/18 06:05:58] mask2former INFO: Inference done 1035/1093. Dataloading: 0.0056 s/iter. Inference: 0.2428 s/iter. Eval: 0.1210 s/iter. Total: 0.3696 s/iter. ETA=0:00:21
[02/18 06:06:03] mask2former INFO: Inference done 1050/1093. Dataloading: 0.0056 s/iter. Inference: 0.2427 s/iter. Eval: 0.1209 s/iter. Total: 0.3692 s/iter. ETA=0:00:15
[02/18 06:06:08] mask2former INFO: Inference done 1065/1093. Dataloading: 0.0056 s/iter. Inference: 0.2424 s/iter. Eval: 0.1208 s/iter. Total: 0.3689 s/iter. ETA=0:00:10
[02/18 06:06:13] mask2former INFO: Inference done 1080/1093. Dataloading: 0.0056 s/iter. Inference: 0.2421 s/iter. Eval: 0.1208 s/iter. Total: 0.3686 s/iter. ETA=0:00:04
[02/18 06:06:48] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.51937259003353, 'error_1pix': 0.4900732248990258, 'error_3pix': 0.24768655860362593, 'mIoU': 14.428758509601739, 'fwIoU': 37.814743966328784, 'IoU-1': 93.45063136026927, 'IoU-2': 0.09469080640900648, 'IoU-3': 0.012257615537911618, 'IoU-4': 0.002029853169973934, 'IoU-5': 0.0036397947155780413, 'IoU-6': 0.006090238596809027, 'IoU-7': 0.007068088099408349, 'IoU-8': 0.00977679109024336, 'IoU-9': 1.1196014573386106, 'IoU-10': 4.891946776728316, 'IoU-11': 16.257185524383548, 'IoU-12': 25.719445919948498, 'IoU-13': 4.268295742375879, 'IoU-14': 5.127168552180349, 'IoU-15': 6.885261489330487, 'IoU-16': 3.4654426518472556, 'IoU-17': 3.72710033352947, 'IoU-18': 5.112083764577939, 'IoU-19': 4.627194237684189, 'IoU-20': 3.4992922696321274, 'IoU-21': 5.388391612662293, 'IoU-22': 10.76585003403487, 'IoU-23': 15.749209552937115, 'IoU-24': 19.929431439894625, 'IoU-25': 24.587499380427595, 'IoU-26': 32.36094137455823, 'IoU-27': 28.09802729280348, 'IoU-28': 22.722457764102703, 'IoU-29': 20.53436292993295, 'IoU-30': 21.287087555029423, 'IoU-31': 24.345967071605585, 'IoU-32': 35.18543299636107, 'IoU-33': 18.64992932363092, 'IoU-34': 9.815537911810676, 'IoU-35': 4.766877296341706, 'IoU-36': 26.78649344929463, 'IoU-37': 16.237680541005613, 'IoU-38': 15.700416840292455, 'IoU-39': 17.976428578740872, 'IoU-40': 17.889021767925513, 'IoU-41': 15.00592678246791, 'IoU-42': 13.397186471116433, 'IoU-43': 27.085956276175267, 'IoU-44': 16.960501064131968, 'IoU-45': 11.872424215298311, 'IoU-46': 12.851864440910923, 'IoU-47': 13.90552238786054, 'IoU-48': 14.437778842084931, 'mACC': 25.41661909163759, 'pACC': 46.0394815628225, 'ACC-1': 97.68159512595605, 'ACC-2': 0.09469226631660921, 'ACC-3': 0.013110608067887575, 'ACC-4': 0.0021146067080300324, 'ACC-5': 0.0038236250023897652, 'ACC-6': 0.006423686603154523, 'ACC-7': 0.007458803753415586, 'ACC-8': 0.010122107175833346, 'ACC-9': 79.15887557614188, 'ACC-10': 10.285552170796764, 'ACC-11': 21.619946297672573, 'ACC-12': 71.99406337304238, 'ACC-13': 7.876922274276955, 'ACC-14': 10.584591955525664, 'ACC-15': 12.350956201599901, 'ACC-16': 6.212096623795401, 'ACC-17': 7.4014408106751794, 'ACC-18': 9.339511525237242, 'ACC-19': 7.734062905987754, 'ACC-20': 5.6680137370866355, 'ACC-21': 8.552923259582846, 'ACC-22': 15.36057536455979, 'ACC-23': 22.122650100874594, 'ACC-24': 29.279751768443624, 'ACC-25': 38.7305383635157, 'ACC-26': 58.48945256134491, 'ACC-27': 46.74919848300641, 'ACC-28': 32.67160154577494, 'ACC-29': 27.833574238406573, 'ACC-30': 31.56987025822572, 'ACC-31': 38.804793992508415, 'ACC-32': 67.90829681429513, 'ACC-33': 23.91879598304803, 'ACC-34': 12.474416193683965, 'ACC-35': 6.719235779241293, 'ACC-36': 79.05839255315955, 'ACC-37': 29.2356225887022, 'ACC-38': 23.80789769385982, 'ACC-39': 25.690794053292525, 'ACC-40': 25.931178165666363, 'ACC-41': 22.945928509880755, 'ACC-42': 22.54449378781087, 'ACC-43': 67.96464687098312, 'ACC-44': 32.56333461264716, 'ACC-45': 18.61386842545556, 'ACC-46': 19.140635706539047, 'ACC-47': 21.10090520515331, 'ACC-48': 22.16896923752005})])
[02/18 06:06:48] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 06:06:48] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 06:06:48] d2.evaluation.testing INFO: copypaste: 3.5194,0.4901,0.2477,14.4288,37.8147,25.4166,46.0395
[02/18 06:06:48] d2.utils.events INFO:  eta: 22:44:40  iter: 9999  total_loss: 34.64  loss_ce: 0  loss_mask: 0.928  loss_dice: 2.451  loss_seg: 0.8163  loss_ce_0: 0  loss_mask_0: 0.9458  loss_dice_0: 2.518  loss_ce_1: 0  loss_mask_1: 0.9309  loss_dice_1: 2.459  loss_ce_2: 0  loss_mask_2: 0.9356  loss_dice_2: 2.436  loss_ce_3: 0  loss_mask_3: 0.9379  loss_dice_3: 2.429  loss_ce_4: 0  loss_mask_4: 0.9347  loss_dice_4: 2.431  loss_ce_5: 0  loss_mask_5: 0.9363  loss_dice_5: 2.436  loss_ce_6: 0  loss_mask_6: 0.941  loss_dice_6: 2.426  loss_ce_7: 0  loss_mask_7: 0.9388  loss_dice_7: 2.429  loss_ce_8: 0  loss_mask_8: 0.9406  loss_dice_8: 2.433  time: 2.2933  data_time: 0.0305  lr: 8.4868e-05  max_mem: 6000M
[02/18 06:07:21] d2.utils.events INFO:  eta: 22:42:34  iter: 10019  total_loss: 34.31  loss_ce: 0  loss_mask: 0.907  loss_dice: 2.468  loss_seg: 0.958  loss_ce_0: 0  loss_mask_0: 0.9148  loss_dice_0: 2.529  loss_ce_1: 0  loss_mask_1: 0.8988  loss_dice_1: 2.465  loss_ce_2: 0  loss_mask_2: 0.911  loss_dice_2: 2.455  loss_ce_3: 0  loss_mask_3: 0.9144  loss_dice_3: 2.445  loss_ce_4: 0  loss_mask_4: 0.9122  loss_dice_4: 2.444  loss_ce_5: 0  loss_mask_5: 0.9137  loss_dice_5: 2.448  loss_ce_6: 0  loss_mask_6: 0.9124  loss_dice_6: 2.45  loss_ce_7: 0  loss_mask_7: 0.9128  loss_dice_7: 2.452  loss_ce_8: 0  loss_mask_8: 0.9095  loss_dice_8: 2.452  time: 2.2920  data_time: 0.0378  lr: 8.4838e-05  max_mem: 6000M
[02/18 06:07:52] d2.utils.events INFO:  eta: 22:34:22  iter: 10039  total_loss: 34.53  loss_ce: 0  loss_mask: 0.9354  loss_dice: 2.407  loss_seg: 0.8545  loss_ce_0: 0  loss_mask_0: 0.9306  loss_dice_0: 2.462  loss_ce_1: 0  loss_mask_1: 0.9463  loss_dice_1: 2.409  loss_ce_2: 0  loss_mask_2: 0.9435  loss_dice_2: 2.394  loss_ce_3: 0  loss_mask_3: 0.94  loss_dice_3: 2.391  loss_ce_4: 0  loss_mask_4: 0.9444  loss_dice_4: 2.385  loss_ce_5: 0  loss_mask_5: 0.9428  loss_dice_5: 2.392  loss_ce_6: 0  loss_mask_6: 0.9407  loss_dice_6: 2.39  loss_ce_7: 0  loss_mask_7: 0.948  loss_dice_7: 2.387  loss_ce_8: 0  loss_mask_8: 0.9477  loss_dice_8: 2.39  time: 2.2905  data_time: 0.0255  lr: 8.4807e-05  max_mem: 6000M
[02/18 06:08:24] d2.utils.events INFO:  eta: 22:30:31  iter: 10059  total_loss: 35.87  loss_ce: 0  loss_mask: 0.9745  loss_dice: 2.551  loss_seg: 0.7453  loss_ce_0: 0  loss_mask_0: 0.9882  loss_dice_0: 2.583  loss_ce_1: 0  loss_mask_1: 0.9774  loss_dice_1: 2.55  loss_ce_2: 0  loss_mask_2: 0.9779  loss_dice_2: 2.539  loss_ce_3: 0  loss_mask_3: 0.9792  loss_dice_3: 2.522  loss_ce_4: 0  loss_mask_4: 0.9772  loss_dice_4: 2.52  loss_ce_5: 0  loss_mask_5: 0.9756  loss_dice_5: 2.521  loss_ce_6: 0  loss_mask_6: 0.9811  loss_dice_6: 2.525  loss_ce_7: 0  loss_mask_7: 0.9776  loss_dice_7: 2.53  loss_ce_8: 0  loss_mask_8: 0.9785  loss_dice_8: 2.531  time: 2.2891  data_time: 0.0257  lr: 8.4776e-05  max_mem: 6000M
[02/18 06:08:56] d2.utils.events INFO:  eta: 22:26:03  iter: 10079  total_loss: 36.15  loss_ce: 0  loss_mask: 0.9268  loss_dice: 2.547  loss_seg: 1.007  loss_ce_0: 0  loss_mask_0: 0.9325  loss_dice_0: 2.607  loss_ce_1: 0  loss_mask_1: 0.9381  loss_dice_1: 2.541  loss_ce_2: 0  loss_mask_2: 0.9374  loss_dice_2: 2.526  loss_ce_3: 0  loss_mask_3: 0.9382  loss_dice_3: 2.521  loss_ce_4: 0  loss_mask_4: 0.9376  loss_dice_4: 2.521  loss_ce_5: 0  loss_mask_5: 0.9352  loss_dice_5: 2.518  loss_ce_6: 0  loss_mask_6: 0.9356  loss_dice_6: 2.522  loss_ce_7: 0  loss_mask_7: 0.9359  loss_dice_7: 2.529  loss_ce_8: 0  loss_mask_8: 0.9292  loss_dice_8: 2.53  time: 2.2877  data_time: 0.0273  lr: 8.4746e-05  max_mem: 6000M
[02/18 06:09:31] d2.utils.events INFO:  eta: 22:23:15  iter: 10099  total_loss: 35.75  loss_ce: 0  loss_mask: 0.9398  loss_dice: 2.524  loss_seg: 0.8059  loss_ce_0: 0  loss_mask_0: 0.9525  loss_dice_0: 2.569  loss_ce_1: 0  loss_mask_1: 0.9419  loss_dice_1: 2.537  loss_ce_2: 0  loss_mask_2: 0.943  loss_dice_2: 2.518  loss_ce_3: 0  loss_mask_3: 0.9463  loss_dice_3: 2.509  loss_ce_4: 0  loss_mask_4: 0.9503  loss_dice_4: 2.514  loss_ce_5: 0  loss_mask_5: 0.9514  loss_dice_5: 2.515  loss_ce_6: 0  loss_mask_6: 0.9493  loss_dice_6: 2.515  loss_ce_7: 0  loss_mask_7: 0.95  loss_dice_7: 2.516  loss_ce_8: 0  loss_mask_8: 0.9534  loss_dice_8: 2.509  time: 2.2866  data_time: 0.0341  lr: 8.4715e-05  max_mem: 6000M
[02/18 06:10:03] d2.utils.events INFO:  eta: 22:21:50  iter: 10119  total_loss: 35.17  loss_ce: 0  loss_mask: 0.9472  loss_dice: 2.465  loss_seg: 0.8474  loss_ce_0: 0  loss_mask_0: 0.9696  loss_dice_0: 2.485  loss_ce_1: 0  loss_mask_1: 0.952  loss_dice_1: 2.459  loss_ce_2: 0  loss_mask_2: 0.9528  loss_dice_2: 2.449  loss_ce_3: 0  loss_mask_3: 0.9537  loss_dice_3: 2.444  loss_ce_4: 0  loss_mask_4: 0.9557  loss_dice_4: 2.443  loss_ce_5: 0  loss_mask_5: 0.953  loss_dice_5: 2.443  loss_ce_6: 0  loss_mask_6: 0.9557  loss_dice_6: 2.443  loss_ce_7: 0  loss_mask_7: 0.9512  loss_dice_7: 2.451  loss_ce_8: 0  loss_mask_8: 0.9484  loss_dice_8: 2.453  time: 2.2852  data_time: 0.0317  lr: 8.4685e-05  max_mem: 6000M
[02/18 06:10:35] d2.utils.events INFO:  eta: 22:23:16  iter: 10139  total_loss: 36.83  loss_ce: 0  loss_mask: 0.922  loss_dice: 2.612  loss_seg: 0.954  loss_ce_0: 0  loss_mask_0: 0.9224  loss_dice_0: 2.669  loss_ce_1: 0  loss_mask_1: 0.9162  loss_dice_1: 2.622  loss_ce_2: 0  loss_mask_2: 0.923  loss_dice_2: 2.608  loss_ce_3: 0  loss_mask_3: 0.9275  loss_dice_3: 2.591  loss_ce_4: 0  loss_mask_4: 0.9253  loss_dice_4: 2.594  loss_ce_5: 0  loss_mask_5: 0.9245  loss_dice_5: 2.597  loss_ce_6: 0  loss_mask_6: 0.9256  loss_dice_6: 2.599  loss_ce_7: 0  loss_mask_7: 0.9259  loss_dice_7: 2.603  loss_ce_8: 0  loss_mask_8: 0.9264  loss_dice_8: 2.598  time: 2.2839  data_time: 0.0268  lr: 8.4654e-05  max_mem: 6000M
[02/18 06:11:08] d2.utils.events INFO:  eta: 22:21:38  iter: 10159  total_loss: 35.5  loss_ce: 0  loss_mask: 0.9238  loss_dice: 2.523  loss_seg: 0.9158  loss_ce_0: 0  loss_mask_0: 0.9218  loss_dice_0: 2.611  loss_ce_1: 0  loss_mask_1: 0.9233  loss_dice_1: 2.529  loss_ce_2: 0  loss_mask_2: 0.9254  loss_dice_2: 2.512  loss_ce_3: 0  loss_mask_3: 0.9252  loss_dice_3: 2.503  loss_ce_4: 0  loss_mask_4: 0.9272  loss_dice_4: 2.503  loss_ce_5: 0  loss_mask_5: 0.9275  loss_dice_5: 2.505  loss_ce_6: 0  loss_mask_6: 0.9277  loss_dice_6: 2.502  loss_ce_7: 0  loss_mask_7: 0.927  loss_dice_7: 2.504  loss_ce_8: 0  loss_mask_8: 0.9269  loss_dice_8: 2.505  time: 2.2827  data_time: 0.0281  lr: 8.4624e-05  max_mem: 6000M
[02/18 06:11:41] d2.utils.events INFO:  eta: 22:19:34  iter: 10179  total_loss: 34.09  loss_ce: 0  loss_mask: 0.9052  loss_dice: 2.374  loss_seg: 0.9188  loss_ce_0: 0  loss_mask_0: 0.9243  loss_dice_0: 2.388  loss_ce_1: 0  loss_mask_1: 0.9109  loss_dice_1: 2.354  loss_ce_2: 0  loss_mask_2: 0.9081  loss_dice_2: 2.362  loss_ce_3: 0  loss_mask_3: 0.9139  loss_dice_3: 2.34  loss_ce_4: 0  loss_mask_4: 0.9171  loss_dice_4: 2.339  loss_ce_5: 0  loss_mask_5: 0.9146  loss_dice_5: 2.336  loss_ce_6: 0  loss_mask_6: 0.9096  loss_dice_6: 2.331  loss_ce_7: 0  loss_mask_7: 0.9144  loss_dice_7: 2.338  loss_ce_8: 0  loss_mask_8: 0.9098  loss_dice_8: 2.34  time: 2.2814  data_time: 0.0275  lr: 8.4593e-05  max_mem: 6000M
[02/18 06:12:13] d2.utils.events INFO:  eta: 22:18:23  iter: 10199  total_loss: 35.1  loss_ce: 0  loss_mask: 0.9059  loss_dice: 2.504  loss_seg: 1.124  loss_ce_0: 0  loss_mask_0: 0.9217  loss_dice_0: 2.565  loss_ce_1: 0  loss_mask_1: 0.8995  loss_dice_1: 2.517  loss_ce_2: 0  loss_mask_2: 0.9022  loss_dice_2: 2.504  loss_ce_3: 0  loss_mask_3: 0.898  loss_dice_3: 2.503  loss_ce_4: 0  loss_mask_4: 0.8992  loss_dice_4: 2.501  loss_ce_5: 0  loss_mask_5: 0.9004  loss_dice_5: 2.5  loss_ce_6: 0  loss_mask_6: 0.9033  loss_dice_6: 2.488  loss_ce_7: 0  loss_mask_7: 0.9032  loss_dice_7: 2.49  loss_ce_8: 0  loss_mask_8: 0.9045  loss_dice_8: 2.493  time: 2.2801  data_time: 0.0239  lr: 8.4563e-05  max_mem: 6000M
[02/18 06:12:48] d2.utils.events INFO:  eta: 22:20:22  iter: 10219  total_loss: 34.89  loss_ce: 0  loss_mask: 0.8937  loss_dice: 2.436  loss_seg: 0.842  loss_ce_0: 0  loss_mask_0: 0.9099  loss_dice_0: 2.516  loss_ce_1: 0  loss_mask_1: 0.9048  loss_dice_1: 2.435  loss_ce_2: 0  loss_mask_2: 0.9045  loss_dice_2: 2.423  loss_ce_3: 0  loss_mask_3: 0.9074  loss_dice_3: 2.413  loss_ce_4: 0  loss_mask_4: 0.9073  loss_dice_4: 2.413  loss_ce_5: 0  loss_mask_5: 0.9038  loss_dice_5: 2.416  loss_ce_6: 0  loss_mask_6: 0.9082  loss_dice_6: 2.417  loss_ce_7: 0  loss_mask_7: 0.9105  loss_dice_7: 2.413  loss_ce_8: 0  loss_mask_8: 0.9057  loss_dice_8: 2.414  time: 2.2790  data_time: 0.0289  lr: 8.4532e-05  max_mem: 6000M
[02/18 06:13:22] d2.utils.events INFO:  eta: 22:19:50  iter: 10239  total_loss: 34.61  loss_ce: 0  loss_mask: 0.9227  loss_dice: 2.444  loss_seg: 0.7603  loss_ce_0: 0  loss_mask_0: 0.9219  loss_dice_0: 2.503  loss_ce_1: 0  loss_mask_1: 0.9219  loss_dice_1: 2.452  loss_ce_2: 0  loss_mask_2: 0.9261  loss_dice_2: 2.432  loss_ce_3: 0  loss_mask_3: 0.9237  loss_dice_3: 2.424  loss_ce_4: 0  loss_mask_4: 0.9228  loss_dice_4: 2.425  loss_ce_5: 0  loss_mask_5: 0.9299  loss_dice_5: 2.426  loss_ce_6: 0  loss_mask_6: 0.9327  loss_dice_6: 2.419  loss_ce_7: 0  loss_mask_7: 0.9305  loss_dice_7: 2.427  loss_ce_8: 0  loss_mask_8: 0.9272  loss_dice_8: 2.426  time: 2.2779  data_time: 0.0291  lr: 8.4501e-05  max_mem: 6000M
[02/18 06:13:54] d2.utils.events INFO:  eta: 22:18:56  iter: 10259  total_loss: 36.49  loss_ce: 0  loss_mask: 0.9515  loss_dice: 2.577  loss_seg: 0.8401  loss_ce_0: 0  loss_mask_0: 0.9528  loss_dice_0: 2.637  loss_ce_1: 0  loss_mask_1: 0.9579  loss_dice_1: 2.587  loss_ce_2: 0  loss_mask_2: 0.9597  loss_dice_2: 2.574  loss_ce_3: 0  loss_mask_3: 0.9581  loss_dice_3: 2.57  loss_ce_4: 0  loss_mask_4: 0.9575  loss_dice_4: 2.568  loss_ce_5: 0  loss_mask_5: 0.9539  loss_dice_5: 2.58  loss_ce_6: 0  loss_mask_6: 0.9565  loss_dice_6: 2.573  loss_ce_7: 0  loss_mask_7: 0.9535  loss_dice_7: 2.568  loss_ce_8: 0  loss_mask_8: 0.9537  loss_dice_8: 2.572  time: 2.2766  data_time: 0.0286  lr: 8.4471e-05  max_mem: 6000M
[02/18 06:14:27] d2.utils.events INFO:  eta: 22:16:52  iter: 10279  total_loss: 35.75  loss_ce: 0  loss_mask: 0.9473  loss_dice: 2.539  loss_seg: 0.8481  loss_ce_0: 0  loss_mask_0: 0.9527  loss_dice_0: 2.597  loss_ce_1: 0  loss_mask_1: 0.9547  loss_dice_1: 2.537  loss_ce_2: 0  loss_mask_2: 0.9541  loss_dice_2: 2.516  loss_ce_3: 0  loss_mask_3: 0.9514  loss_dice_3: 2.513  loss_ce_4: 0  loss_mask_4: 0.9521  loss_dice_4: 2.51  loss_ce_5: 0  loss_mask_5: 0.956  loss_dice_5: 2.505  loss_ce_6: 0  loss_mask_6: 0.9548  loss_dice_6: 2.515  loss_ce_7: 0  loss_mask_7: 0.9563  loss_dice_7: 2.515  loss_ce_8: 0  loss_mask_8: 0.9547  loss_dice_8: 2.512  time: 2.2754  data_time: 0.0347  lr: 8.444e-05  max_mem: 6000M
[02/18 06:14:59] d2.utils.events INFO:  eta: 22:15:42  iter: 10299  total_loss: 35.48  loss_ce: 0  loss_mask: 0.932  loss_dice: 2.494  loss_seg: 0.8254  loss_ce_0: 0  loss_mask_0: 0.9395  loss_dice_0: 2.533  loss_ce_1: 0  loss_mask_1: 0.9356  loss_dice_1: 2.487  loss_ce_2: 0  loss_mask_2: 0.9357  loss_dice_2: 2.477  loss_ce_3: 0  loss_mask_3: 0.9298  loss_dice_3: 2.471  loss_ce_4: 0  loss_mask_4: 0.9344  loss_dice_4: 2.472  loss_ce_5: 0  loss_mask_5: 0.9319  loss_dice_5: 2.474  loss_ce_6: 0  loss_mask_6: 0.9311  loss_dice_6: 2.47  loss_ce_7: 0  loss_mask_7: 0.9343  loss_dice_7: 2.472  loss_ce_8: 0  loss_mask_8: 0.9373  loss_dice_8: 2.479  time: 2.2740  data_time: 0.0217  lr: 8.441e-05  max_mem: 6000M
[02/18 06:15:32] d2.utils.events INFO:  eta: 22:14:23  iter: 10319  total_loss: 35.41  loss_ce: 0  loss_mask: 0.9506  loss_dice: 2.449  loss_seg: 1.025  loss_ce_0: 0  loss_mask_0: 0.9519  loss_dice_0: 2.505  loss_ce_1: 0  loss_mask_1: 0.9499  loss_dice_1: 2.46  loss_ce_2: 0  loss_mask_2: 0.9518  loss_dice_2: 2.449  loss_ce_3: 0  loss_mask_3: 0.9535  loss_dice_3: 2.447  loss_ce_4: 0  loss_mask_4: 0.956  loss_dice_4: 2.443  loss_ce_5: 0  loss_mask_5: 0.9552  loss_dice_5: 2.442  loss_ce_6: 0  loss_mask_6: 0.9591  loss_dice_6: 2.432  loss_ce_7: 0  loss_mask_7: 0.9584  loss_dice_7: 2.442  loss_ce_8: 0  loss_mask_8: 0.9533  loss_dice_8: 2.44  time: 2.2728  data_time: 0.0315  lr: 8.4379e-05  max_mem: 6000M
[02/18 06:16:04] d2.utils.events INFO:  eta: 22:03:55  iter: 10339  total_loss: 36.12  loss_ce: 0  loss_mask: 0.9777  loss_dice: 2.5  loss_seg: 0.7938  loss_ce_0: 0  loss_mask_0: 0.9955  loss_dice_0: 2.523  loss_ce_1: 0  loss_mask_1: 0.9799  loss_dice_1: 2.514  loss_ce_2: 0  loss_mask_2: 0.976  loss_dice_2: 2.505  loss_ce_3: 0  loss_mask_3: 0.9833  loss_dice_3: 2.503  loss_ce_4: 0  loss_mask_4: 0.9844  loss_dice_4: 2.493  loss_ce_5: 0  loss_mask_5: 0.9797  loss_dice_5: 2.495  loss_ce_6: 0  loss_mask_6: 0.984  loss_dice_6: 2.494  loss_ce_7: 0  loss_mask_7: 0.9825  loss_dice_7: 2.498  loss_ce_8: 0  loss_mask_8: 0.9846  loss_dice_8: 2.494  time: 2.2714  data_time: 0.0297  lr: 8.4349e-05  max_mem: 6000M
[02/18 06:16:37] d2.utils.events INFO:  eta: 22:00:15  iter: 10359  total_loss: 34.47  loss_ce: 0  loss_mask: 0.9097  loss_dice: 2.443  loss_seg: 0.8704  loss_ce_0: 0  loss_mask_0: 0.9256  loss_dice_0: 2.494  loss_ce_1: 0  loss_mask_1: 0.9153  loss_dice_1: 2.431  loss_ce_2: 0  loss_mask_2: 0.9173  loss_dice_2: 2.42  loss_ce_3: 0  loss_mask_3: 0.9193  loss_dice_3: 2.411  loss_ce_4: 0  loss_mask_4: 0.9228  loss_dice_4: 2.412  loss_ce_5: 0  loss_mask_5: 0.9147  loss_dice_5: 2.416  loss_ce_6: 0  loss_mask_6: 0.9164  loss_dice_6: 2.415  loss_ce_7: 0  loss_mask_7: 0.9185  loss_dice_7: 2.418  loss_ce_8: 0  loss_mask_8: 0.9223  loss_dice_8: 2.42  time: 2.2703  data_time: 0.0303  lr: 8.4318e-05  max_mem: 6000M
[02/18 06:17:10] d2.utils.events INFO:  eta: 21:59:13  iter: 10379  total_loss: 34.72  loss_ce: 0  loss_mask: 0.9136  loss_dice: 2.431  loss_seg: 1.043  loss_ce_0: 0  loss_mask_0: 0.8972  loss_dice_0: 2.481  loss_ce_1: 0  loss_mask_1: 0.9147  loss_dice_1: 2.441  loss_ce_2: 0  loss_mask_2: 0.9276  loss_dice_2: 2.432  loss_ce_3: 0  loss_mask_3: 0.9269  loss_dice_3: 2.423  loss_ce_4: 0  loss_mask_4: 0.9273  loss_dice_4: 2.423  loss_ce_5: 0  loss_mask_5: 0.9271  loss_dice_5: 2.426  loss_ce_6: 0  loss_mask_6: 0.9234  loss_dice_6: 2.416  loss_ce_7: 0  loss_mask_7: 0.919  loss_dice_7: 2.422  loss_ce_8: 0  loss_mask_8: 0.9233  loss_dice_8: 2.424  time: 2.2691  data_time: 0.0343  lr: 8.4287e-05  max_mem: 6000M
[02/18 06:17:41] d2.utils.events INFO:  eta: 21:58:00  iter: 10399  total_loss: 36.31  loss_ce: 0  loss_mask: 0.9315  loss_dice: 2.542  loss_seg: 1.06  loss_ce_0: 0  loss_mask_0: 0.9376  loss_dice_0: 2.597  loss_ce_1: 0  loss_mask_1: 0.9353  loss_dice_1: 2.544  loss_ce_2: 0  loss_mask_2: 0.9443  loss_dice_2: 2.53  loss_ce_3: 0  loss_mask_3: 0.951  loss_dice_3: 2.516  loss_ce_4: 0  loss_mask_4: 0.9441  loss_dice_4: 2.523  loss_ce_5: 0  loss_mask_5: 0.9428  loss_dice_5: 2.527  loss_ce_6: 0  loss_mask_6: 0.9433  loss_dice_6: 2.522  loss_ce_7: 0  loss_mask_7: 0.9405  loss_dice_7: 2.527  loss_ce_8: 0  loss_mask_8: 0.9398  loss_dice_8: 2.521  time: 2.2677  data_time: 0.0321  lr: 8.4257e-05  max_mem: 6003M
[02/18 06:18:15] d2.utils.events INFO:  eta: 22:01:47  iter: 10419  total_loss: 35.43  loss_ce: 0  loss_mask: 0.9174  loss_dice: 2.48  loss_seg: 1.073  loss_ce_0: 0  loss_mask_0: 0.9339  loss_dice_0: 2.554  loss_ce_1: 0  loss_mask_1: 0.9229  loss_dice_1: 2.487  loss_ce_2: 0  loss_mask_2: 0.9138  loss_dice_2: 2.477  loss_ce_3: 0  loss_mask_3: 0.9175  loss_dice_3: 2.46  loss_ce_4: 0  loss_mask_4: 0.9196  loss_dice_4: 2.465  loss_ce_5: 0  loss_mask_5: 0.9179  loss_dice_5: 2.469  loss_ce_6: 0  loss_mask_6: 0.9235  loss_dice_6: 2.464  loss_ce_7: 0  loss_mask_7: 0.9244  loss_dice_7: 2.468  loss_ce_8: 0  loss_mask_8: 0.9198  loss_dice_8: 2.464  time: 2.2666  data_time: 0.0303  lr: 8.4226e-05  max_mem: 6003M
[02/18 06:18:49] d2.utils.events INFO:  eta: 22:03:02  iter: 10439  total_loss: 34.79  loss_ce: 0  loss_mask: 0.9288  loss_dice: 2.494  loss_seg: 0.8926  loss_ce_0: 0  loss_mask_0: 0.9336  loss_dice_0: 2.557  loss_ce_1: 0  loss_mask_1: 0.934  loss_dice_1: 2.487  loss_ce_2: 0  loss_mask_2: 0.9371  loss_dice_2: 2.469  loss_ce_3: 0  loss_mask_3: 0.9379  loss_dice_3: 2.462  loss_ce_4: 0  loss_mask_4: 0.9328  loss_dice_4: 2.468  loss_ce_5: 0  loss_mask_5: 0.9352  loss_dice_5: 2.468  loss_ce_6: 0  loss_mask_6: 0.9369  loss_dice_6: 2.466  loss_ce_7: 0  loss_mask_7: 0.9369  loss_dice_7: 2.465  loss_ce_8: 0  loss_mask_8: 0.94  loss_dice_8: 2.469  time: 2.2655  data_time: 0.0413  lr: 8.4196e-05  max_mem: 6003M
[02/18 06:19:25] d2.utils.events INFO:  eta: 22:07:09  iter: 10459  total_loss: 35.14  loss_ce: 0  loss_mask: 0.9525  loss_dice: 2.463  loss_seg: 0.9165  loss_ce_0: 0  loss_mask_0: 0.9803  loss_dice_0: 2.497  loss_ce_1: 0  loss_mask_1: 0.9491  loss_dice_1: 2.458  loss_ce_2: 0  loss_mask_2: 0.9484  loss_dice_2: 2.452  loss_ce_3: 0  loss_mask_3: 0.9511  loss_dice_3: 2.438  loss_ce_4: 0  loss_mask_4: 0.954  loss_dice_4: 2.439  loss_ce_5: 0  loss_mask_5: 0.9527  loss_dice_5: 2.444  loss_ce_6: 0  loss_mask_6: 0.9529  loss_dice_6: 2.444  loss_ce_7: 0  loss_mask_7: 0.9505  loss_dice_7: 2.442  loss_ce_8: 0  loss_mask_8: 0.9502  loss_dice_8: 2.451  time: 2.2646  data_time: 0.0299  lr: 8.4165e-05  max_mem: 6003M
[02/18 06:19:58] d2.utils.events INFO:  eta: 22:09:13  iter: 10479  total_loss: 36.32  loss_ce: 0  loss_mask: 0.9187  loss_dice: 2.532  loss_seg: 0.8808  loss_ce_0: 0  loss_mask_0: 0.917  loss_dice_0: 2.584  loss_ce_1: 0  loss_mask_1: 0.9127  loss_dice_1: 2.524  loss_ce_2: 0  loss_mask_2: 0.9199  loss_dice_2: 2.51  loss_ce_3: 0  loss_mask_3: 0.9266  loss_dice_3: 2.509  loss_ce_4: 0  loss_mask_4: 0.9272  loss_dice_4: 2.516  loss_ce_5: 0  loss_mask_5: 0.9292  loss_dice_5: 2.515  loss_ce_6: 0  loss_mask_6: 0.9245  loss_dice_6: 2.515  loss_ce_7: 0  loss_mask_7: 0.924  loss_dice_7: 2.513  loss_ce_8: 0  loss_mask_8: 0.9285  loss_dice_8: 2.515  time: 2.2634  data_time: 0.0274  lr: 8.4135e-05  max_mem: 6003M
[02/18 06:20:31] d2.utils.events INFO:  eta: 22:09:33  iter: 10499  total_loss: 34.52  loss_ce: 0  loss_mask: 0.9302  loss_dice: 2.477  loss_seg: 1.199  loss_ce_0: 0  loss_mask_0: 0.932  loss_dice_0: 2.51  loss_ce_1: 0  loss_mask_1: 0.9354  loss_dice_1: 2.465  loss_ce_2: 0  loss_mask_2: 0.9311  loss_dice_2: 2.457  loss_ce_3: 0  loss_mask_3: 0.9317  loss_dice_3: 2.448  loss_ce_4: 0  loss_mask_4: 0.9296  loss_dice_4: 2.452  loss_ce_5: 0  loss_mask_5: 0.9283  loss_dice_5: 2.452  loss_ce_6: 0  loss_mask_6: 0.9293  loss_dice_6: 2.451  loss_ce_7: 0  loss_mask_7: 0.9332  loss_dice_7: 2.451  loss_ce_8: 0  loss_mask_8: 0.9262  loss_dice_8: 2.456  time: 2.2622  data_time: 0.0356  lr: 8.4104e-05  max_mem: 6003M
[02/18 06:21:02] d2.utils.events INFO:  eta: 22:09:01  iter: 10519  total_loss: 34.72  loss_ce: 0  loss_mask: 0.9517  loss_dice: 2.398  loss_seg: 0.7394  loss_ce_0: 0  loss_mask_0: 0.9471  loss_dice_0: 2.464  loss_ce_1: 0  loss_mask_1: 0.9496  loss_dice_1: 2.398  loss_ce_2: 0  loss_mask_2: 0.9545  loss_dice_2: 2.378  loss_ce_3: 0  loss_mask_3: 0.9569  loss_dice_3: 2.375  loss_ce_4: 0  loss_mask_4: 0.9571  loss_dice_4: 2.373  loss_ce_5: 0  loss_mask_5: 0.9578  loss_dice_5: 2.378  loss_ce_6: 0  loss_mask_6: 0.9583  loss_dice_6: 2.368  loss_ce_7: 0  loss_mask_7: 0.9616  loss_dice_7: 2.369  loss_ce_8: 0  loss_mask_8: 0.9645  loss_dice_8: 2.374  time: 2.2609  data_time: 0.0364  lr: 8.4073e-05  max_mem: 6003M
[02/18 06:21:36] d2.utils.events INFO:  eta: 22:07:58  iter: 10539  total_loss: 36.54  loss_ce: 0  loss_mask: 0.9319  loss_dice: 2.573  loss_seg: 0.9872  loss_ce_0: 0  loss_mask_0: 0.9459  loss_dice_0: 2.626  loss_ce_1: 0  loss_mask_1: 0.9328  loss_dice_1: 2.575  loss_ce_2: 0  loss_mask_2: 0.9347  loss_dice_2: 2.551  loss_ce_3: 0  loss_mask_3: 0.9357  loss_dice_3: 2.544  loss_ce_4: 0  loss_mask_4: 0.9354  loss_dice_4: 2.543  loss_ce_5: 0  loss_mask_5: 0.9377  loss_dice_5: 2.55  loss_ce_6: 0  loss_mask_6: 0.9329  loss_dice_6: 2.548  loss_ce_7: 0  loss_mask_7: 0.9339  loss_dice_7: 2.55  loss_ce_8: 0  loss_mask_8: 0.9377  loss_dice_8: 2.555  time: 2.2598  data_time: 0.0344  lr: 8.4043e-05  max_mem: 6003M
[02/18 06:22:09] d2.utils.events INFO:  eta: 22:10:00  iter: 10559  total_loss: 35.1  loss_ce: 0  loss_mask: 0.9235  loss_dice: 2.433  loss_seg: 1.105  loss_ce_0: 0  loss_mask_0: 0.9377  loss_dice_0: 2.484  loss_ce_1: 0  loss_mask_1: 0.9247  loss_dice_1: 2.437  loss_ce_2: 0  loss_mask_2: 0.9252  loss_dice_2: 2.416  loss_ce_3: 0  loss_mask_3: 0.926  loss_dice_3: 2.412  loss_ce_4: 0  loss_mask_4: 0.9298  loss_dice_4: 2.416  loss_ce_5: 0  loss_mask_5: 0.9317  loss_dice_5: 2.412  loss_ce_6: 0  loss_mask_6: 0.9294  loss_dice_6: 2.414  loss_ce_7: 0  loss_mask_7: 0.9266  loss_dice_7: 2.415  loss_ce_8: 0  loss_mask_8: 0.9294  loss_dice_8: 2.418  time: 2.2587  data_time: 0.0315  lr: 8.4012e-05  max_mem: 6003M
[02/18 06:22:43] d2.utils.events INFO:  eta: 22:08:31  iter: 10579  total_loss: 33.88  loss_ce: 0  loss_mask: 0.8986  loss_dice: 2.382  loss_seg: 0.8654  loss_ce_0: 0  loss_mask_0: 0.8942  loss_dice_0: 2.454  loss_ce_1: 0  loss_mask_1: 0.8981  loss_dice_1: 2.389  loss_ce_2: 0  loss_mask_2: 0.9074  loss_dice_2: 2.378  loss_ce_3: 0  loss_mask_3: 0.9109  loss_dice_3: 2.371  loss_ce_4: 0  loss_mask_4: 0.9112  loss_dice_4: 2.363  loss_ce_5: 0  loss_mask_5: 0.9059  loss_dice_5: 2.366  loss_ce_6: 0  loss_mask_6: 0.9133  loss_dice_6: 2.367  loss_ce_7: 0  loss_mask_7: 0.9119  loss_dice_7: 2.367  loss_ce_8: 0  loss_mask_8: 0.9116  loss_dice_8: 2.365  time: 2.2575  data_time: 0.0314  lr: 8.3982e-05  max_mem: 6003M
[02/18 06:23:15] d2.utils.events INFO:  eta: 22:07:59  iter: 10599  total_loss: 35.57  loss_ce: 0  loss_mask: 0.922  loss_dice: 2.554  loss_seg: 1.012  loss_ce_0: 0  loss_mask_0: 0.9257  loss_dice_0: 2.597  loss_ce_1: 0  loss_mask_1: 0.9336  loss_dice_1: 2.559  loss_ce_2: 0  loss_mask_2: 0.9328  loss_dice_2: 2.542  loss_ce_3: 0  loss_mask_3: 0.9294  loss_dice_3: 2.531  loss_ce_4: 0  loss_mask_4: 0.9236  loss_dice_4: 2.538  loss_ce_5: 0  loss_mask_5: 0.9242  loss_dice_5: 2.537  loss_ce_6: 0  loss_mask_6: 0.9275  loss_dice_6: 2.535  loss_ce_7: 0  loss_mask_7: 0.9288  loss_dice_7: 2.534  loss_ce_8: 0  loss_mask_8: 0.926  loss_dice_8: 2.538  time: 2.2563  data_time: 0.0320  lr: 8.3951e-05  max_mem: 6003M
[02/18 06:23:47] d2.utils.events INFO:  eta: 22:06:55  iter: 10619  total_loss: 34.64  loss_ce: 0  loss_mask: 0.8871  loss_dice: 2.412  loss_seg: 1.028  loss_ce_0: 0  loss_mask_0: 0.9013  loss_dice_0: 2.456  loss_ce_1: 0  loss_mask_1: 0.8995  loss_dice_1: 2.414  loss_ce_2: 0  loss_mask_2: 0.8956  loss_dice_2: 2.406  loss_ce_3: 0  loss_mask_3: 0.8955  loss_dice_3: 2.4  loss_ce_4: 0  loss_mask_4: 0.8959  loss_dice_4: 2.4  loss_ce_5: 0  loss_mask_5: 0.8969  loss_dice_5: 2.4  loss_ce_6: 0  loss_mask_6: 0.8983  loss_dice_6: 2.398  loss_ce_7: 0  loss_mask_7: 0.8942  loss_dice_7: 2.407  loss_ce_8: 0  loss_mask_8: 0.8997  loss_dice_8: 2.405  time: 2.2551  data_time: 0.0311  lr: 8.392e-05  max_mem: 6003M
[02/18 06:24:18] d2.utils.events INFO:  eta: 22:06:42  iter: 10639  total_loss: 35.38  loss_ce: 0  loss_mask: 0.9486  loss_dice: 2.523  loss_seg: 0.9134  loss_ce_0: 0  loss_mask_0: 0.9589  loss_dice_0: 2.583  loss_ce_1: 0  loss_mask_1: 0.9493  loss_dice_1: 2.528  loss_ce_2: 0  loss_mask_2: 0.9526  loss_dice_2: 2.508  loss_ce_3: 0  loss_mask_3: 0.9555  loss_dice_3: 2.502  loss_ce_4: 0  loss_mask_4: 0.9563  loss_dice_4: 2.501  loss_ce_5: 0  loss_mask_5: 0.9566  loss_dice_5: 2.502  loss_ce_6: 0  loss_mask_6: 0.954  loss_dice_6: 2.499  loss_ce_7: 0  loss_mask_7: 0.9588  loss_dice_7: 2.502  loss_ce_8: 0  loss_mask_8: 0.9569  loss_dice_8: 2.505  time: 2.2538  data_time: 0.0268  lr: 8.389e-05  max_mem: 6003M
[02/18 06:24:51] d2.utils.events INFO:  eta: 22:05:48  iter: 10659  total_loss: 34.59  loss_ce: 0  loss_mask: 0.9353  loss_dice: 2.398  loss_seg: 0.746  loss_ce_0: 0  loss_mask_0: 0.9225  loss_dice_0: 2.458  loss_ce_1: 0  loss_mask_1: 0.9339  loss_dice_1: 2.415  loss_ce_2: 0  loss_mask_2: 0.944  loss_dice_2: 2.398  loss_ce_3: 0  loss_mask_3: 0.948  loss_dice_3: 2.392  loss_ce_4: 0  loss_mask_4: 0.9481  loss_dice_4: 2.391  loss_ce_5: 0  loss_mask_5: 0.9499  loss_dice_5: 2.391  loss_ce_6: 0  loss_mask_6: 0.9458  loss_dice_6: 2.39  loss_ce_7: 0  loss_mask_7: 0.9424  loss_dice_7: 2.383  loss_ce_8: 0  loss_mask_8: 0.9431  loss_dice_8: 2.39  time: 2.2526  data_time: 0.0323  lr: 8.3859e-05  max_mem: 6003M
[02/18 06:25:24] d2.utils.events INFO:  eta: 22:05:16  iter: 10679  total_loss: 33.98  loss_ce: 0  loss_mask: 0.913  loss_dice: 2.341  loss_seg: 0.9043  loss_ce_0: 0  loss_mask_0: 0.9147  loss_dice_0: 2.438  loss_ce_1: 0  loss_mask_1: 0.9167  loss_dice_1: 2.339  loss_ce_2: 0  loss_mask_2: 0.9134  loss_dice_2: 2.328  loss_ce_3: 0  loss_mask_3: 0.916  loss_dice_3: 2.311  loss_ce_4: 0  loss_mask_4: 0.916  loss_dice_4: 2.312  loss_ce_5: 0  loss_mask_5: 0.9159  loss_dice_5: 2.32  loss_ce_6: 0  loss_mask_6: 0.9169  loss_dice_6: 2.322  loss_ce_7: 0  loss_mask_7: 0.9207  loss_dice_7: 2.322  loss_ce_8: 0  loss_mask_8: 0.9209  loss_dice_8: 2.32  time: 2.2515  data_time: 0.0301  lr: 8.3829e-05  max_mem: 6003M
[02/18 06:25:55] d2.utils.events INFO:  eta: 22:04:43  iter: 10699  total_loss: 34.6  loss_ce: 0  loss_mask: 0.924  loss_dice: 2.435  loss_seg: 0.8005  loss_ce_0: 0  loss_mask_0: 0.9517  loss_dice_0: 2.441  loss_ce_1: 0  loss_mask_1: 0.9384  loss_dice_1: 2.424  loss_ce_2: 0  loss_mask_2: 0.9374  loss_dice_2: 2.423  loss_ce_3: 0  loss_mask_3: 0.937  loss_dice_3: 2.412  loss_ce_4: 0  loss_mask_4: 0.9356  loss_dice_4: 2.416  loss_ce_5: 0  loss_mask_5: 0.9377  loss_dice_5: 2.419  loss_ce_6: 0  loss_mask_6: 0.9348  loss_dice_6: 2.413  loss_ce_7: 0  loss_mask_7: 0.9332  loss_dice_7: 2.416  loss_ce_8: 0  loss_mask_8: 0.9305  loss_dice_8: 2.416  time: 2.2502  data_time: 0.0323  lr: 8.3798e-05  max_mem: 6003M
[02/18 06:26:28] d2.utils.events INFO:  eta: 22:04:56  iter: 10719  total_loss: 34.19  loss_ce: 0  loss_mask: 0.9599  loss_dice: 2.354  loss_seg: 0.8386  loss_ce_0: 0  loss_mask_0: 0.9523  loss_dice_0: 2.438  loss_ce_1: 0  loss_mask_1: 0.9513  loss_dice_1: 2.349  loss_ce_2: 0  loss_mask_2: 0.95  loss_dice_2: 2.342  loss_ce_3: 0  loss_mask_3: 0.959  loss_dice_3: 2.338  loss_ce_4: 0  loss_mask_4: 0.9596  loss_dice_4: 2.33  loss_ce_5: 0  loss_mask_5: 0.9578  loss_dice_5: 2.338  loss_ce_6: 0  loss_mask_6: 0.9591  loss_dice_6: 2.338  loss_ce_7: 0  loss_mask_7: 0.9618  loss_dice_7: 2.335  loss_ce_8: 0  loss_mask_8: 0.9588  loss_dice_8: 2.338  time: 2.2490  data_time: 0.0259  lr: 8.3767e-05  max_mem: 6003M
[02/18 06:27:00] d2.utils.events INFO:  eta: 22:03:39  iter: 10739  total_loss: 34.49  loss_ce: 0  loss_mask: 0.9186  loss_dice: 2.465  loss_seg: 0.9234  loss_ce_0: 0  loss_mask_0: 0.9269  loss_dice_0: 2.482  loss_ce_1: 0  loss_mask_1: 0.9227  loss_dice_1: 2.461  loss_ce_2: 0  loss_mask_2: 0.921  loss_dice_2: 2.452  loss_ce_3: 0  loss_mask_3: 0.9231  loss_dice_3: 2.452  loss_ce_4: 0  loss_mask_4: 0.926  loss_dice_4: 2.447  loss_ce_5: 0  loss_mask_5: 0.9205  loss_dice_5: 2.45  loss_ce_6: 0  loss_mask_6: 0.9249  loss_dice_6: 2.449  loss_ce_7: 0  loss_mask_7: 0.9262  loss_dice_7: 2.451  loss_ce_8: 0  loss_mask_8: 0.9293  loss_dice_8: 2.447  time: 2.2478  data_time: 0.0314  lr: 8.3737e-05  max_mem: 6003M
[02/18 06:27:34] d2.utils.events INFO:  eta: 22:01:22  iter: 10759  total_loss: 34.97  loss_ce: 0  loss_mask: 0.9573  loss_dice: 2.458  loss_seg: 0.9144  loss_ce_0: 0  loss_mask_0: 0.9596  loss_dice_0: 2.506  loss_ce_1: 0  loss_mask_1: 0.9583  loss_dice_1: 2.46  loss_ce_2: 0  loss_mask_2: 0.9631  loss_dice_2: 2.442  loss_ce_3: 0  loss_mask_3: 0.9683  loss_dice_3: 2.432  loss_ce_4: 0  loss_mask_4: 0.9664  loss_dice_4: 2.436  loss_ce_5: 0  loss_mask_5: 0.9633  loss_dice_5: 2.438  loss_ce_6: 0  loss_mask_6: 0.9634  loss_dice_6: 2.436  loss_ce_7: 0  loss_mask_7: 0.9659  loss_dice_7: 2.442  loss_ce_8: 0  loss_mask_8: 0.9675  loss_dice_8: 2.438  time: 2.2468  data_time: 0.0330  lr: 8.3706e-05  max_mem: 6003M
[02/18 06:28:06] d2.utils.events INFO:  eta: 21:55:22  iter: 10779  total_loss: 37.43  loss_ce: 0  loss_mask: 0.9013  loss_dice: 2.642  loss_seg: 1.246  loss_ce_0: 0  loss_mask_0: 0.9296  loss_dice_0: 2.693  loss_ce_1: 0  loss_mask_1: 0.9269  loss_dice_1: 2.638  loss_ce_2: 0  loss_mask_2: 0.9208  loss_dice_2: 2.623  loss_ce_3: 0  loss_mask_3: 0.9159  loss_dice_3: 2.615  loss_ce_4: 0  loss_mask_4: 0.9157  loss_dice_4: 2.617  loss_ce_5: 0  loss_mask_5: 0.9147  loss_dice_5: 2.617  loss_ce_6: 0  loss_mask_6: 0.9123  loss_dice_6: 2.622  loss_ce_7: 0  loss_mask_7: 0.9173  loss_dice_7: 2.623  loss_ce_8: 0  loss_mask_8: 0.9213  loss_dice_8: 2.619  time: 2.2455  data_time: 0.0281  lr: 8.3676e-05  max_mem: 6003M
[02/18 06:28:38] d2.utils.events INFO:  eta: 21:55:27  iter: 10799  total_loss: 35.19  loss_ce: 0  loss_mask: 0.9046  loss_dice: 2.46  loss_seg: 1.053  loss_ce_0: 0  loss_mask_0: 0.9021  loss_dice_0: 2.528  loss_ce_1: 0  loss_mask_1: 0.9046  loss_dice_1: 2.468  loss_ce_2: 0  loss_mask_2: 0.9048  loss_dice_2: 2.459  loss_ce_3: 0  loss_mask_3: 0.9095  loss_dice_3: 2.446  loss_ce_4: 0  loss_mask_4: 0.9052  loss_dice_4: 2.442  loss_ce_5: 0  loss_mask_5: 0.9068  loss_dice_5: 2.444  loss_ce_6: 0  loss_mask_6: 0.9087  loss_dice_6: 2.441  loss_ce_7: 0  loss_mask_7: 0.9071  loss_dice_7: 2.442  loss_ce_8: 0  loss_mask_8: 0.9093  loss_dice_8: 2.445  time: 2.2444  data_time: 0.0276  lr: 8.3645e-05  max_mem: 6003M
[02/18 06:29:13] d2.utils.events INFO:  eta: 21:57:13  iter: 10819  total_loss: 36.13  loss_ce: 0  loss_mask: 0.9525  loss_dice: 2.559  loss_seg: 1.116  loss_ce_0: 0  loss_mask_0: 0.961  loss_dice_0: 2.617  loss_ce_1: 0  loss_mask_1: 0.9499  loss_dice_1: 2.557  loss_ce_2: 0  loss_mask_2: 0.9545  loss_dice_2: 2.542  loss_ce_3: 0  loss_mask_3: 0.9583  loss_dice_3: 2.543  loss_ce_4: 0  loss_mask_4: 0.9555  loss_dice_4: 2.543  loss_ce_5: 0  loss_mask_5: 0.957  loss_dice_5: 2.548  loss_ce_6: 0  loss_mask_6: 0.9571  loss_dice_6: 2.547  loss_ce_7: 0  loss_mask_7: 0.9485  loss_dice_7: 2.545  loss_ce_8: 0  loss_mask_8: 0.9543  loss_dice_8: 2.549  time: 2.2434  data_time: 0.0314  lr: 8.3614e-05  max_mem: 6003M
[02/18 06:29:46] d2.utils.events INFO:  eta: 21:58:15  iter: 10839  total_loss: 36.06  loss_ce: 0  loss_mask: 0.9509  loss_dice: 2.514  loss_seg: 0.9332  loss_ce_0: 0  loss_mask_0: 0.9634  loss_dice_0: 2.584  loss_ce_1: 0  loss_mask_1: 0.9548  loss_dice_1: 2.52  loss_ce_2: 0  loss_mask_2: 0.9514  loss_dice_2: 2.504  loss_ce_3: 0  loss_mask_3: 0.9524  loss_dice_3: 2.495  loss_ce_4: 0  loss_mask_4: 0.9565  loss_dice_4: 2.498  loss_ce_5: 0  loss_mask_5: 0.9603  loss_dice_5: 2.497  loss_ce_6: 0  loss_mask_6: 0.9597  loss_dice_6: 2.5  loss_ce_7: 0  loss_mask_7: 0.9584  loss_dice_7: 2.498  loss_ce_8: 0  loss_mask_8: 0.9586  loss_dice_8: 2.497  time: 2.2423  data_time: 0.0284  lr: 8.3584e-05  max_mem: 6003M
[02/18 06:30:20] d2.utils.events INFO:  eta: 21:54:21  iter: 10859  total_loss: 35.2  loss_ce: 0  loss_mask: 0.9361  loss_dice: 2.441  loss_seg: 0.7414  loss_ce_0: 0  loss_mask_0: 0.9586  loss_dice_0: 2.49  loss_ce_1: 0  loss_mask_1: 0.9456  loss_dice_1: 2.439  loss_ce_2: 0  loss_mask_2: 0.9444  loss_dice_2: 2.424  loss_ce_3: 0  loss_mask_3: 0.9501  loss_dice_3: 2.414  loss_ce_4: 0  loss_mask_4: 0.9473  loss_dice_4: 2.417  loss_ce_5: 0  loss_mask_5: 0.9465  loss_dice_5: 2.421  loss_ce_6: 0  loss_mask_6: 0.9414  loss_dice_6: 2.42  loss_ce_7: 0  loss_mask_7: 0.9473  loss_dice_7: 2.416  loss_ce_8: 0  loss_mask_8: 0.9496  loss_dice_8: 2.417  time: 2.2413  data_time: 0.0267  lr: 8.3553e-05  max_mem: 6003M
[02/18 06:30:53] d2.utils.events INFO:  eta: 21:55:37  iter: 10879  total_loss: 35.59  loss_ce: 0  loss_mask: 0.9345  loss_dice: 2.537  loss_seg: 0.7765  loss_ce_0: 0  loss_mask_0: 0.9514  loss_dice_0: 2.578  loss_ce_1: 0  loss_mask_1: 0.9418  loss_dice_1: 2.541  loss_ce_2: 0  loss_mask_2: 0.9498  loss_dice_2: 2.52  loss_ce_3: 0  loss_mask_3: 0.9477  loss_dice_3: 2.504  loss_ce_4: 0  loss_mask_4: 0.9456  loss_dice_4: 2.511  loss_ce_5: 0  loss_mask_5: 0.9422  loss_dice_5: 2.507  loss_ce_6: 0  loss_mask_6: 0.9409  loss_dice_6: 2.503  loss_ce_7: 0  loss_mask_7: 0.9435  loss_dice_7: 2.511  loss_ce_8: 0  loss_mask_8: 0.9407  loss_dice_8: 2.517  time: 2.2402  data_time: 0.0292  lr: 8.3523e-05  max_mem: 6003M
[02/18 06:31:24] d2.utils.events INFO:  eta: 21:53:36  iter: 10899  total_loss: 33.75  loss_ce: 0  loss_mask: 0.896  loss_dice: 2.328  loss_seg: 0.7402  loss_ce_0: 0  loss_mask_0: 0.8933  loss_dice_0: 2.383  loss_ce_1: 0  loss_mask_1: 0.9014  loss_dice_1: 2.324  loss_ce_2: 0  loss_mask_2: 0.8984  loss_dice_2: 2.312  loss_ce_3: 0  loss_mask_3: 0.898  loss_dice_3: 2.309  loss_ce_4: 0  loss_mask_4: 0.8951  loss_dice_4: 2.311  loss_ce_5: 0  loss_mask_5: 0.8949  loss_dice_5: 2.313  loss_ce_6: 0  loss_mask_6: 0.8977  loss_dice_6: 2.305  loss_ce_7: 0  loss_mask_7: 0.8971  loss_dice_7: 2.31  loss_ce_8: 0  loss_mask_8: 0.9027  loss_dice_8: 2.312  time: 2.2390  data_time: 0.0254  lr: 8.3492e-05  max_mem: 6003M
[02/18 06:31:56] d2.utils.events INFO:  eta: 21:56:06  iter: 10919  total_loss: 35.38  loss_ce: 0  loss_mask: 0.9068  loss_dice: 2.438  loss_seg: 0.8899  loss_ce_0: 0  loss_mask_0: 0.9053  loss_dice_0: 2.511  loss_ce_1: 0  loss_mask_1: 0.9115  loss_dice_1: 2.431  loss_ce_2: 0  loss_mask_2: 0.9154  loss_dice_2: 2.426  loss_ce_3: 0  loss_mask_3: 0.9079  loss_dice_3: 2.417  loss_ce_4: 0  loss_mask_4: 0.9155  loss_dice_4: 2.416  loss_ce_5: 0  loss_mask_5: 0.9142  loss_dice_5: 2.417  loss_ce_6: 0  loss_mask_6: 0.9168  loss_dice_6: 2.411  loss_ce_7: 0  loss_mask_7: 0.9205  loss_dice_7: 2.425  loss_ce_8: 0  loss_mask_8: 0.9187  loss_dice_8: 2.424  time: 2.2378  data_time: 0.0240  lr: 8.3461e-05  max_mem: 6003M
[02/18 06:32:26] d2.utils.events INFO:  eta: 21:52:13  iter: 10939  total_loss: 35.38  loss_ce: 0  loss_mask: 0.9474  loss_dice: 2.477  loss_seg: 0.8896  loss_ce_0: 0  loss_mask_0: 0.9714  loss_dice_0: 2.513  loss_ce_1: 0  loss_mask_1: 0.956  loss_dice_1: 2.475  loss_ce_2: 0  loss_mask_2: 0.9589  loss_dice_2: 2.467  loss_ce_3: 0  loss_mask_3: 0.9588  loss_dice_3: 2.454  loss_ce_4: 0  loss_mask_4: 0.9591  loss_dice_4: 2.463  loss_ce_5: 0  loss_mask_5: 0.9574  loss_dice_5: 2.468  loss_ce_6: 0  loss_mask_6: 0.9585  loss_dice_6: 2.459  loss_ce_7: 0  loss_mask_7: 0.9588  loss_dice_7: 2.466  loss_ce_8: 0  loss_mask_8: 0.9537  loss_dice_8: 2.465  time: 2.2365  data_time: 0.0286  lr: 8.3431e-05  max_mem: 6003M
[02/18 06:32:59] d2.utils.events INFO:  eta: 21:49:43  iter: 10959  total_loss: 35.37  loss_ce: 0  loss_mask: 0.9709  loss_dice: 2.483  loss_seg: 0.8156  loss_ce_0: 0  loss_mask_0: 0.9889  loss_dice_0: 2.516  loss_ce_1: 0  loss_mask_1: 0.9738  loss_dice_1: 2.506  loss_ce_2: 0  loss_mask_2: 0.9737  loss_dice_2: 2.492  loss_ce_3: 0  loss_mask_3: 0.9704  loss_dice_3: 2.477  loss_ce_4: 0  loss_mask_4: 0.9753  loss_dice_4: 2.481  loss_ce_5: 0  loss_mask_5: 0.9767  loss_dice_5: 2.488  loss_ce_6: 0  loss_mask_6: 0.9758  loss_dice_6: 2.48  loss_ce_7: 0  loss_mask_7: 0.9752  loss_dice_7: 2.48  loss_ce_8: 0  loss_mask_8: 0.9713  loss_dice_8: 2.472  time: 2.2353  data_time: 0.0278  lr: 8.34e-05  max_mem: 6003M
[02/18 06:33:31] d2.utils.events INFO:  eta: 21:47:46  iter: 10979  total_loss: 37.68  loss_ce: 0  loss_mask: 0.9409  loss_dice: 2.645  loss_seg: 1.119  loss_ce_0: 0  loss_mask_0: 0.952  loss_dice_0: 2.705  loss_ce_1: 0  loss_mask_1: 0.9533  loss_dice_1: 2.652  loss_ce_2: 0  loss_mask_2: 0.9567  loss_dice_2: 2.639  loss_ce_3: 0  loss_mask_3: 0.9591  loss_dice_3: 2.635  loss_ce_4: 0  loss_mask_4: 0.9594  loss_dice_4: 2.632  loss_ce_5: 0  loss_mask_5: 0.9634  loss_dice_5: 2.63  loss_ce_6: 0  loss_mask_6: 0.9619  loss_dice_6: 2.633  loss_ce_7: 0  loss_mask_7: 0.9581  loss_dice_7: 2.626  loss_ce_8: 0  loss_mask_8: 0.9555  loss_dice_8: 2.638  time: 2.2342  data_time: 0.0270  lr: 8.337e-05  max_mem: 6003M
[02/18 06:34:04] d2.utils.events INFO:  eta: 21:44:57  iter: 10999  total_loss: 35.13  loss_ce: 0  loss_mask: 0.9274  loss_dice: 2.493  loss_seg: 0.795  loss_ce_0: 0  loss_mask_0: 0.9424  loss_dice_0: 2.526  loss_ce_1: 0  loss_mask_1: 0.937  loss_dice_1: 2.497  loss_ce_2: 0  loss_mask_2: 0.9361  loss_dice_2: 2.489  loss_ce_3: 0  loss_mask_3: 0.9298  loss_dice_3: 2.479  loss_ce_4: 0  loss_mask_4: 0.9343  loss_dice_4: 2.489  loss_ce_5: 0  loss_mask_5: 0.9284  loss_dice_5: 2.486  loss_ce_6: 0  loss_mask_6: 0.9266  loss_dice_6: 2.484  loss_ce_7: 0  loss_mask_7: 0.9316  loss_dice_7: 2.489  loss_ce_8: 0  loss_mask_8: 0.9352  loss_dice_8: 2.483  time: 2.2331  data_time: 0.0317  lr: 8.3339e-05  max_mem: 6003M
[02/18 06:34:34] d2.utils.events INFO:  eta: 21:42:27  iter: 11019  total_loss: 37.15  loss_ce: 0  loss_mask: 0.9937  loss_dice: 2.599  loss_seg: 0.8845  loss_ce_0: 0  loss_mask_0: 1.011  loss_dice_0: 2.635  loss_ce_1: 0  loss_mask_1: 1.001  loss_dice_1: 2.604  loss_ce_2: 0  loss_mask_2: 1.001  loss_dice_2: 2.596  loss_ce_3: 0  loss_mask_3: 1.009  loss_dice_3: 2.588  loss_ce_4: 0  loss_mask_4: 1.01  loss_dice_4: 2.588  loss_ce_5: 0  loss_mask_5: 1.008  loss_dice_5: 2.586  loss_ce_6: 0  loss_mask_6: 1.006  loss_dice_6: 2.577  loss_ce_7: 0  loss_mask_7: 1.01  loss_dice_7: 2.586  loss_ce_8: 0  loss_mask_8: 1.008  loss_dice_8: 2.583  time: 2.2318  data_time: 0.0298  lr: 8.3308e-05  max_mem: 6003M
[02/18 06:35:07] d2.utils.events INFO:  eta: 21:46:10  iter: 11039  total_loss: 34.01  loss_ce: 0  loss_mask: 0.953  loss_dice: 2.378  loss_seg: 0.6795  loss_ce_0: 0  loss_mask_0: 0.9593  loss_dice_0: 2.431  loss_ce_1: 0  loss_mask_1: 0.9537  loss_dice_1: 2.382  loss_ce_2: 0  loss_mask_2: 0.9617  loss_dice_2: 2.364  loss_ce_3: 0  loss_mask_3: 0.9642  loss_dice_3: 2.355  loss_ce_4: 0  loss_mask_4: 0.9625  loss_dice_4: 2.355  loss_ce_5: 0  loss_mask_5: 0.9631  loss_dice_5: 2.355  loss_ce_6: 0  loss_mask_6: 0.9638  loss_dice_6: 2.359  loss_ce_7: 0  loss_mask_7: 0.9637  loss_dice_7: 2.36  loss_ce_8: 0  loss_mask_8: 0.9609  loss_dice_8: 2.355  time: 2.2308  data_time: 0.0268  lr: 8.3278e-05  max_mem: 6003M
[02/18 06:35:39] d2.utils.events INFO:  eta: 21:45:38  iter: 11059  total_loss: 33.2  loss_ce: 0  loss_mask: 0.9  loss_dice: 2.319  loss_seg: 0.7033  loss_ce_0: 0  loss_mask_0: 0.9139  loss_dice_0: 2.377  loss_ce_1: 0  loss_mask_1: 0.9085  loss_dice_1: 2.321  loss_ce_2: 0  loss_mask_2: 0.9073  loss_dice_2: 2.301  loss_ce_3: 0  loss_mask_3: 0.906  loss_dice_3: 2.297  loss_ce_4: 0  loss_mask_4: 0.9075  loss_dice_4: 2.303  loss_ce_5: 0  loss_mask_5: 0.9029  loss_dice_5: 2.302  loss_ce_6: 0  loss_mask_6: 0.902  loss_dice_6: 2.304  loss_ce_7: 0  loss_mask_7: 0.9071  loss_dice_7: 2.302  loss_ce_8: 0  loss_mask_8: 0.9041  loss_dice_8: 2.301  time: 2.2296  data_time: 0.0281  lr: 8.3247e-05  max_mem: 6003M
[02/18 06:36:13] d2.utils.events INFO:  eta: 21:46:45  iter: 11079  total_loss: 34.58  loss_ce: 0  loss_mask: 0.9188  loss_dice: 2.42  loss_seg: 1.139  loss_ce_0: 0  loss_mask_0: 0.9121  loss_dice_0: 2.51  loss_ce_1: 0  loss_mask_1: 0.9165  loss_dice_1: 2.432  loss_ce_2: 0  loss_mask_2: 0.9267  loss_dice_2: 2.412  loss_ce_3: 0  loss_mask_3: 0.926  loss_dice_3: 2.407  loss_ce_4: 0  loss_mask_4: 0.9287  loss_dice_4: 2.405  loss_ce_5: 0  loss_mask_5: 0.9254  loss_dice_5: 2.408  loss_ce_6: 0  loss_mask_6: 0.9244  loss_dice_6: 2.408  loss_ce_7: 0  loss_mask_7: 0.9304  loss_dice_7: 2.407  loss_ce_8: 0  loss_mask_8: 0.9274  loss_dice_8: 2.41  time: 2.2286  data_time: 0.0295  lr: 8.3217e-05  max_mem: 6003M
[02/18 06:36:45] d2.utils.events INFO:  eta: 21:45:38  iter: 11099  total_loss: 36.63  loss_ce: 0  loss_mask: 0.9417  loss_dice: 2.607  loss_seg: 0.9142  loss_ce_0: 0  loss_mask_0: 0.9504  loss_dice_0: 2.642  loss_ce_1: 0  loss_mask_1: 0.9429  loss_dice_1: 2.613  loss_ce_2: 0  loss_mask_2: 0.9497  loss_dice_2: 2.591  loss_ce_3: 0  loss_mask_3: 0.9526  loss_dice_3: 2.581  loss_ce_4: 0  loss_mask_4: 0.9538  loss_dice_4: 2.589  loss_ce_5: 0  loss_mask_5: 0.956  loss_dice_5: 2.591  loss_ce_6: 0  loss_mask_6: 0.9551  loss_dice_6: 2.588  loss_ce_7: 0  loss_mask_7: 0.9571  loss_dice_7: 2.588  loss_ce_8: 0  loss_mask_8: 0.9562  loss_dice_8: 2.587  time: 2.2275  data_time: 0.0261  lr: 8.3186e-05  max_mem: 6003M
[02/18 06:37:17] d2.utils.events INFO:  eta: 21:45:41  iter: 11119  total_loss: 34.05  loss_ce: 0  loss_mask: 0.9028  loss_dice: 2.385  loss_seg: 0.858  loss_ce_0: 0  loss_mask_0: 0.9116  loss_dice_0: 2.483  loss_ce_1: 0  loss_mask_1: 0.9102  loss_dice_1: 2.388  loss_ce_2: 0  loss_mask_2: 0.9065  loss_dice_2: 2.377  loss_ce_3: 0  loss_mask_3: 0.9071  loss_dice_3: 2.362  loss_ce_4: 0  loss_mask_4: 0.9138  loss_dice_4: 2.362  loss_ce_5: 0  loss_mask_5: 0.9165  loss_dice_5: 2.366  loss_ce_6: 0  loss_mask_6: 0.9193  loss_dice_6: 2.362  loss_ce_7: 0  loss_mask_7: 0.9168  loss_dice_7: 2.363  loss_ce_8: 0  loss_mask_8: 0.9155  loss_dice_8: 2.361  time: 2.2264  data_time: 0.0264  lr: 8.3155e-05  max_mem: 6003M
[02/18 06:37:51] d2.utils.events INFO:  eta: 21:43:57  iter: 11139  total_loss: 34.72  loss_ce: 0  loss_mask: 0.8848  loss_dice: 2.489  loss_seg: 0.7412  loss_ce_0: 0  loss_mask_0: 0.8879  loss_dice_0: 2.565  loss_ce_1: 0  loss_mask_1: 0.8985  loss_dice_1: 2.496  loss_ce_2: 0  loss_mask_2: 0.8967  loss_dice_2: 2.482  loss_ce_3: 0  loss_mask_3: 0.895  loss_dice_3: 2.474  loss_ce_4: 0  loss_mask_4: 0.897  loss_dice_4: 2.475  loss_ce_5: 0  loss_mask_5: 0.8962  loss_dice_5: 2.472  loss_ce_6: 0  loss_mask_6: 0.8946  loss_dice_6: 2.47  loss_ce_7: 0  loss_mask_7: 0.8969  loss_dice_7: 2.474  loss_ce_8: 0  loss_mask_8: 0.8944  loss_dice_8: 2.475  time: 2.2254  data_time: 0.0248  lr: 8.3125e-05  max_mem: 6003M
[02/18 06:38:24] d2.utils.events INFO:  eta: 21:43:04  iter: 11159  total_loss: 33.93  loss_ce: 0  loss_mask: 0.9146  loss_dice: 2.353  loss_seg: 0.7898  loss_ce_0: 0  loss_mask_0: 0.9197  loss_dice_0: 2.417  loss_ce_1: 0  loss_mask_1: 0.9196  loss_dice_1: 2.347  loss_ce_2: 0  loss_mask_2: 0.9193  loss_dice_2: 2.345  loss_ce_3: 0  loss_mask_3: 0.9234  loss_dice_3: 2.338  loss_ce_4: 0  loss_mask_4: 0.9223  loss_dice_4: 2.343  loss_ce_5: 0  loss_mask_5: 0.9205  loss_dice_5: 2.335  loss_ce_6: 0  loss_mask_6: 0.9202  loss_dice_6: 2.333  loss_ce_7: 0  loss_mask_7: 0.9246  loss_dice_7: 2.331  loss_ce_8: 0  loss_mask_8: 0.9258  loss_dice_8: 2.34  time: 2.2244  data_time: 0.0295  lr: 8.3094e-05  max_mem: 6003M
[02/18 06:38:56] d2.utils.events INFO:  eta: 21:42:59  iter: 11179  total_loss: 33.7  loss_ce: 0  loss_mask: 0.9019  loss_dice: 2.339  loss_seg: 0.8405  loss_ce_0: 0  loss_mask_0: 0.878  loss_dice_0: 2.427  loss_ce_1: 0  loss_mask_1: 0.8994  loss_dice_1: 2.342  loss_ce_2: 0  loss_mask_2: 0.8989  loss_dice_2: 2.327  loss_ce_3: 0  loss_mask_3: 0.9043  loss_dice_3: 2.316  loss_ce_4: 0  loss_mask_4: 0.9054  loss_dice_4: 2.318  loss_ce_5: 0  loss_mask_5: 0.8992  loss_dice_5: 2.324  loss_ce_6: 0  loss_mask_6: 0.9019  loss_dice_6: 2.326  loss_ce_7: 0  loss_mask_7: 0.9017  loss_dice_7: 2.327  loss_ce_8: 0  loss_mask_8: 0.9058  loss_dice_8: 2.333  time: 2.2232  data_time: 0.0354  lr: 8.3063e-05  max_mem: 6003M
[02/18 06:39:28] d2.utils.events INFO:  eta: 21:42:21  iter: 11199  total_loss: 35.16  loss_ce: 0  loss_mask: 0.8649  loss_dice: 2.401  loss_seg: 1.141  loss_ce_0: 0  loss_mask_0: 0.8833  loss_dice_0: 2.457  loss_ce_1: 0  loss_mask_1: 0.8715  loss_dice_1: 2.411  loss_ce_2: 0  loss_mask_2: 0.8737  loss_dice_2: 2.389  loss_ce_3: 0  loss_mask_3: 0.8744  loss_dice_3: 2.383  loss_ce_4: 0  loss_mask_4: 0.8751  loss_dice_4: 2.383  loss_ce_5: 0  loss_mask_5: 0.872  loss_dice_5: 2.389  loss_ce_6: 0  loss_mask_6: 0.8734  loss_dice_6: 2.385  loss_ce_7: 0  loss_mask_7: 0.8731  loss_dice_7: 2.385  loss_ce_8: 0  loss_mask_8: 0.8718  loss_dice_8: 2.394  time: 2.2221  data_time: 0.0329  lr: 8.3033e-05  max_mem: 6003M
[02/18 06:39:59] d2.utils.events INFO:  eta: 21:37:08  iter: 11219  total_loss: 35.38  loss_ce: 0  loss_mask: 0.9115  loss_dice: 2.536  loss_seg: 1.012  loss_ce_0: 0  loss_mask_0: 0.9236  loss_dice_0: 2.579  loss_ce_1: 0  loss_mask_1: 0.9004  loss_dice_1: 2.539  loss_ce_2: 0  loss_mask_2: 0.9027  loss_dice_2: 2.523  loss_ce_3: 0  loss_mask_3: 0.9125  loss_dice_3: 2.519  loss_ce_4: 0  loss_mask_4: 0.9137  loss_dice_4: 2.516  loss_ce_5: 0  loss_mask_5: 0.909  loss_dice_5: 2.519  loss_ce_6: 0  loss_mask_6: 0.9136  loss_dice_6: 2.516  loss_ce_7: 0  loss_mask_7: 0.9131  loss_dice_7: 2.515  loss_ce_8: 0  loss_mask_8: 0.9104  loss_dice_8: 2.519  time: 2.2209  data_time: 0.0291  lr: 8.3002e-05  max_mem: 6003M
[02/18 06:40:33] d2.utils.events INFO:  eta: 21:36:36  iter: 11239  total_loss: 34.34  loss_ce: 0  loss_mask: 0.9566  loss_dice: 2.38  loss_seg: 0.7504  loss_ce_0: 0  loss_mask_0: 0.9527  loss_dice_0: 2.421  loss_ce_1: 0  loss_mask_1: 0.9659  loss_dice_1: 2.377  loss_ce_2: 0  loss_mask_2: 0.9631  loss_dice_2: 2.375  loss_ce_3: 0  loss_mask_3: 0.9588  loss_dice_3: 2.382  loss_ce_4: 0  loss_mask_4: 0.9599  loss_dice_4: 2.382  loss_ce_5: 0  loss_mask_5: 0.9544  loss_dice_5: 2.378  loss_ce_6: 0  loss_mask_6: 0.9581  loss_dice_6: 2.376  loss_ce_7: 0  loss_mask_7: 0.9596  loss_dice_7: 2.381  loss_ce_8: 0  loss_mask_8: 0.9615  loss_dice_8: 2.375  time: 2.2200  data_time: 0.0329  lr: 8.2972e-05  max_mem: 6003M
[02/18 06:41:05] d2.utils.events INFO:  eta: 21:35:27  iter: 11259  total_loss: 34.67  loss_ce: 0  loss_mask: 0.9314  loss_dice: 2.424  loss_seg: 0.7684  loss_ce_0: 0  loss_mask_0: 0.9404  loss_dice_0: 2.49  loss_ce_1: 0  loss_mask_1: 0.9294  loss_dice_1: 2.424  loss_ce_2: 0  loss_mask_2: 0.9355  loss_dice_2: 2.41  loss_ce_3: 0  loss_mask_3: 0.9395  loss_dice_3: 2.403  loss_ce_4: 0  loss_mask_4: 0.9407  loss_dice_4: 2.404  loss_ce_5: 0  loss_mask_5: 0.9384  loss_dice_5: 2.403  loss_ce_6: 0  loss_mask_6: 0.9404  loss_dice_6: 2.403  loss_ce_7: 0  loss_mask_7: 0.9415  loss_dice_7: 2.411  loss_ce_8: 0  loss_mask_8: 0.9401  loss_dice_8: 2.414  time: 2.2188  data_time: 0.0311  lr: 8.2941e-05  max_mem: 6003M
[02/18 06:41:36] d2.utils.events INFO:  eta: 21:34:56  iter: 11279  total_loss: 34.4  loss_ce: 0  loss_mask: 0.9232  loss_dice: 2.459  loss_seg: 0.9009  loss_ce_0: 0  loss_mask_0: 0.9309  loss_dice_0: 2.549  loss_ce_1: 0  loss_mask_1: 0.9188  loss_dice_1: 2.466  loss_ce_2: 0  loss_mask_2: 0.9214  loss_dice_2: 2.453  loss_ce_3: 0  loss_mask_3: 0.9207  loss_dice_3: 2.45  loss_ce_4: 0  loss_mask_4: 0.9214  loss_dice_4: 2.445  loss_ce_5: 0  loss_mask_5: 0.9241  loss_dice_5: 2.445  loss_ce_6: 0  loss_mask_6: 0.925  loss_dice_6: 2.44  loss_ce_7: 0  loss_mask_7: 0.9232  loss_dice_7: 2.439  loss_ce_8: 0  loss_mask_8: 0.9285  loss_dice_8: 2.437  time: 2.2177  data_time: 0.0313  lr: 8.291e-05  max_mem: 6003M
[02/18 06:42:07] d2.utils.events INFO:  eta: 21:34:24  iter: 11299  total_loss: 34.34  loss_ce: 0  loss_mask: 0.8617  loss_dice: 2.45  loss_seg: 1.002  loss_ce_0: 0  loss_mask_0: 0.8673  loss_dice_0: 2.524  loss_ce_1: 0  loss_mask_1: 0.8655  loss_dice_1: 2.454  loss_ce_2: 0  loss_mask_2: 0.8672  loss_dice_2: 2.432  loss_ce_3: 0  loss_mask_3: 0.8715  loss_dice_3: 2.428  loss_ce_4: 0  loss_mask_4: 0.8728  loss_dice_4: 2.432  loss_ce_5: 0  loss_mask_5: 0.8717  loss_dice_5: 2.433  loss_ce_6: 0  loss_mask_6: 0.872  loss_dice_6: 2.43  loss_ce_7: 0  loss_mask_7: 0.8665  loss_dice_7: 2.433  loss_ce_8: 0  loss_mask_8: 0.8676  loss_dice_8: 2.439  time: 2.2165  data_time: 0.0284  lr: 8.288e-05  max_mem: 6003M
[02/18 06:42:39] d2.utils.events INFO:  eta: 21:33:17  iter: 11319  total_loss: 34.39  loss_ce: 0  loss_mask: 0.9167  loss_dice: 2.444  loss_seg: 0.8644  loss_ce_0: 0  loss_mask_0: 0.912  loss_dice_0: 2.504  loss_ce_1: 0  loss_mask_1: 0.9293  loss_dice_1: 2.439  loss_ce_2: 0  loss_mask_2: 0.9271  loss_dice_2: 2.427  loss_ce_3: 0  loss_mask_3: 0.9227  loss_dice_3: 2.423  loss_ce_4: 0  loss_mask_4: 0.9179  loss_dice_4: 2.424  loss_ce_5: 0  loss_mask_5: 0.9163  loss_dice_5: 2.43  loss_ce_6: 0  loss_mask_6: 0.9221  loss_dice_6: 2.423  loss_ce_7: 0  loss_mask_7: 0.9233  loss_dice_7: 2.425  loss_ce_8: 0  loss_mask_8: 0.9215  loss_dice_8: 2.428  time: 2.2153  data_time: 0.0308  lr: 8.2849e-05  max_mem: 6003M
[02/18 06:43:11] d2.utils.events INFO:  eta: 21:35:12  iter: 11339  total_loss: 35.52  loss_ce: 0  loss_mask: 0.9452  loss_dice: 2.464  loss_seg: 0.9574  loss_ce_0: 0  loss_mask_0: 0.955  loss_dice_0: 2.531  loss_ce_1: 0  loss_mask_1: 0.9504  loss_dice_1: 2.472  loss_ce_2: 0  loss_mask_2: 0.9453  loss_dice_2: 2.46  loss_ce_3: 0  loss_mask_3: 0.9544  loss_dice_3: 2.449  loss_ce_4: 0  loss_mask_4: 0.9547  loss_dice_4: 2.447  loss_ce_5: 0  loss_mask_5: 0.9548  loss_dice_5: 2.451  loss_ce_6: 0  loss_mask_6: 0.9576  loss_dice_6: 2.448  loss_ce_7: 0  loss_mask_7: 0.9559  loss_dice_7: 2.446  loss_ce_8: 0  loss_mask_8: 0.9541  loss_dice_8: 2.449  time: 2.2143  data_time: 0.0376  lr: 8.2818e-05  max_mem: 6003M
[02/18 06:43:41] d2.utils.events INFO:  eta: 21:31:44  iter: 11359  total_loss: 34.53  loss_ce: 0  loss_mask: 0.9276  loss_dice: 2.396  loss_seg: 0.8629  loss_ce_0: 0  loss_mask_0: 0.937  loss_dice_0: 2.461  loss_ce_1: 0  loss_mask_1: 0.9268  loss_dice_1: 2.409  loss_ce_2: 0  loss_mask_2: 0.9302  loss_dice_2: 2.388  loss_ce_3: 0  loss_mask_3: 0.933  loss_dice_3: 2.383  loss_ce_4: 0  loss_mask_4: 0.9372  loss_dice_4: 2.387  loss_ce_5: 0  loss_mask_5: 0.9339  loss_dice_5: 2.387  loss_ce_6: 0  loss_mask_6: 0.9326  loss_dice_6: 2.384  loss_ce_7: 0  loss_mask_7: 0.9309  loss_dice_7: 2.389  loss_ce_8: 0  loss_mask_8: 0.9309  loss_dice_8: 2.384  time: 2.2131  data_time: 0.0318  lr: 8.2788e-05  max_mem: 6003M
[02/18 06:44:15] d2.utils.events INFO:  eta: 21:31:42  iter: 11379  total_loss: 35.49  loss_ce: 0  loss_mask: 0.9249  loss_dice: 2.459  loss_seg: 0.9347  loss_ce_0: 0  loss_mask_0: 0.9469  loss_dice_0: 2.511  loss_ce_1: 0  loss_mask_1: 0.923  loss_dice_1: 2.458  loss_ce_2: 0  loss_mask_2: 0.9296  loss_dice_2: 2.45  loss_ce_3: 0  loss_mask_3: 0.9323  loss_dice_3: 2.442  loss_ce_4: 0  loss_mask_4: 0.9313  loss_dice_4: 2.44  loss_ce_5: 0  loss_mask_5: 0.9281  loss_dice_5: 2.448  loss_ce_6: 0  loss_mask_6: 0.9376  loss_dice_6: 2.442  loss_ce_7: 0  loss_mask_7: 0.9292  loss_dice_7: 2.45  loss_ce_8: 0  loss_mask_8: 0.9303  loss_dice_8: 2.449  time: 2.2121  data_time: 0.0294  lr: 8.2757e-05  max_mem: 6003M
[02/18 06:44:47] d2.utils.events INFO:  eta: 21:30:40  iter: 11399  total_loss: 36.12  loss_ce: 0  loss_mask: 0.9294  loss_dice: 2.559  loss_seg: 1.044  loss_ce_0: 0  loss_mask_0: 0.9487  loss_dice_0: 2.582  loss_ce_1: 0  loss_mask_1: 0.9244  loss_dice_1: 2.563  loss_ce_2: 0  loss_mask_2: 0.9256  loss_dice_2: 2.549  loss_ce_3: 0  loss_mask_3: 0.9351  loss_dice_3: 2.538  loss_ce_4: 0  loss_mask_4: 0.9349  loss_dice_4: 2.536  loss_ce_5: 0  loss_mask_5: 0.931  loss_dice_5: 2.536  loss_ce_6: 0  loss_mask_6: 0.9287  loss_dice_6: 2.537  loss_ce_7: 0  loss_mask_7: 0.9327  loss_dice_7: 2.542  loss_ce_8: 0  loss_mask_8: 0.9336  loss_dice_8: 2.541  time: 2.2110  data_time: 0.0291  lr: 8.2726e-05  max_mem: 6003M
[02/18 06:45:20] d2.utils.events INFO:  eta: 21:29:11  iter: 11419  total_loss: 35.2  loss_ce: 0  loss_mask: 0.9218  loss_dice: 2.505  loss_seg: 1.016  loss_ce_0: 0  loss_mask_0: 0.9206  loss_dice_0: 2.572  loss_ce_1: 0  loss_mask_1: 0.9236  loss_dice_1: 2.507  loss_ce_2: 0  loss_mask_2: 0.9223  loss_dice_2: 2.493  loss_ce_3: 0  loss_mask_3: 0.923  loss_dice_3: 2.49  loss_ce_4: 0  loss_mask_4: 0.9264  loss_dice_4: 2.489  loss_ce_5: 0  loss_mask_5: 0.9237  loss_dice_5: 2.492  loss_ce_6: 0  loss_mask_6: 0.9213  loss_dice_6: 2.486  loss_ce_7: 0  loss_mask_7: 0.9245  loss_dice_7: 2.487  loss_ce_8: 0  loss_mask_8: 0.9223  loss_dice_8: 2.492  time: 2.2101  data_time: 0.0322  lr: 8.2696e-05  max_mem: 6003M
[02/18 06:45:53] d2.utils.events INFO:  eta: 21:28:39  iter: 11439  total_loss: 33.86  loss_ce: 0  loss_mask: 0.9161  loss_dice: 2.423  loss_seg: 0.6459  loss_ce_0: 0  loss_mask_0: 0.928  loss_dice_0: 2.494  loss_ce_1: 0  loss_mask_1: 0.9263  loss_dice_1: 2.418  loss_ce_2: 0  loss_mask_2: 0.9216  loss_dice_2: 2.413  loss_ce_3: 0  loss_mask_3: 0.9302  loss_dice_3: 2.398  loss_ce_4: 0  loss_mask_4: 0.9259  loss_dice_4: 2.401  loss_ce_5: 0  loss_mask_5: 0.9296  loss_dice_5: 2.401  loss_ce_6: 0  loss_mask_6: 0.9308  loss_dice_6: 2.395  loss_ce_7: 0  loss_mask_7: 0.9295  loss_dice_7: 2.402  loss_ce_8: 0  loss_mask_8: 0.9272  loss_dice_8: 2.403  time: 2.2090  data_time: 0.0339  lr: 8.2665e-05  max_mem: 6003M
[02/18 06:46:26] d2.utils.events INFO:  eta: 21:25:17  iter: 11459  total_loss: 34.81  loss_ce: 0  loss_mask: 0.9404  loss_dice: 2.467  loss_seg: 0.9904  loss_ce_0: 0  loss_mask_0: 0.9669  loss_dice_0: 2.521  loss_ce_1: 0  loss_mask_1: 0.9447  loss_dice_1: 2.479  loss_ce_2: 0  loss_mask_2: 0.949  loss_dice_2: 2.468  loss_ce_3: 0  loss_mask_3: 0.9515  loss_dice_3: 2.459  loss_ce_4: 0  loss_mask_4: 0.955  loss_dice_4: 2.46  loss_ce_5: 0  loss_mask_5: 0.956  loss_dice_5: 2.456  loss_ce_6: 0  loss_mask_6: 0.9529  loss_dice_6: 2.465  loss_ce_7: 0  loss_mask_7: 0.9563  loss_dice_7: 2.457  loss_ce_8: 0  loss_mask_8: 0.955  loss_dice_8: 2.452  time: 2.2081  data_time: 0.0359  lr: 8.2635e-05  max_mem: 6003M
[02/18 06:46:58] d2.utils.events INFO:  eta: 21:25:26  iter: 11479  total_loss: 34.91  loss_ce: 0  loss_mask: 0.8817  loss_dice: 2.448  loss_seg: 1.196  loss_ce_0: 0  loss_mask_0: 0.8998  loss_dice_0: 2.499  loss_ce_1: 0  loss_mask_1: 0.8899  loss_dice_1: 2.455  loss_ce_2: 0  loss_mask_2: 0.8919  loss_dice_2: 2.438  loss_ce_3: 0  loss_mask_3: 0.8906  loss_dice_3: 2.434  loss_ce_4: 0  loss_mask_4: 0.8903  loss_dice_4: 2.427  loss_ce_5: 0  loss_mask_5: 0.8956  loss_dice_5: 2.429  loss_ce_6: 0  loss_mask_6: 0.8894  loss_dice_6: 2.433  loss_ce_7: 0  loss_mask_7: 0.8943  loss_dice_7: 2.438  loss_ce_8: 0  loss_mask_8: 0.8959  loss_dice_8: 2.439  time: 2.2070  data_time: 0.0292  lr: 8.2604e-05  max_mem: 6003M
[02/18 06:47:30] d2.utils.events INFO:  eta: 21:25:02  iter: 11499  total_loss: 35.75  loss_ce: 0  loss_mask: 0.9597  loss_dice: 2.428  loss_seg: 1.136  loss_ce_0: 0  loss_mask_0: 0.9469  loss_dice_0: 2.493  loss_ce_1: 0  loss_mask_1: 0.9475  loss_dice_1: 2.429  loss_ce_2: 0  loss_mask_2: 0.9576  loss_dice_2: 2.416  loss_ce_3: 0  loss_mask_3: 0.9675  loss_dice_3: 2.41  loss_ce_4: 0  loss_mask_4: 0.9645  loss_dice_4: 2.413  loss_ce_5: 0  loss_mask_5: 0.9624  loss_dice_5: 2.416  loss_ce_6: 0  loss_mask_6: 0.9565  loss_dice_6: 2.413  loss_ce_7: 0  loss_mask_7: 0.9628  loss_dice_7: 2.415  loss_ce_8: 0  loss_mask_8: 0.9613  loss_dice_8: 2.415  time: 2.2060  data_time: 0.0249  lr: 8.2573e-05  max_mem: 6003M
[02/18 06:48:01] d2.utils.events INFO:  eta: 21:24:22  iter: 11519  total_loss: 34.42  loss_ce: 0  loss_mask: 0.8751  loss_dice: 2.434  loss_seg: 0.9261  loss_ce_0: 0  loss_mask_0: 0.8801  loss_dice_0: 2.493  loss_ce_1: 0  loss_mask_1: 0.8864  loss_dice_1: 2.439  loss_ce_2: 0  loss_mask_2: 0.8825  loss_dice_2: 2.427  loss_ce_3: 0  loss_mask_3: 0.8768  loss_dice_3: 2.42  loss_ce_4: 0  loss_mask_4: 0.875  loss_dice_4: 2.421  loss_ce_5: 0  loss_mask_5: 0.8786  loss_dice_5: 2.429  loss_ce_6: 0  loss_mask_6: 0.8751  loss_dice_6: 2.424  loss_ce_7: 0  loss_mask_7: 0.881  loss_dice_7: 2.42  loss_ce_8: 0  loss_mask_8: 0.8804  loss_dice_8: 2.428  time: 2.2048  data_time: 0.0332  lr: 8.2543e-05  max_mem: 6003M
[02/18 06:48:34] d2.utils.events INFO:  eta: 21:22:11  iter: 11539  total_loss: 34.29  loss_ce: 0  loss_mask: 0.9297  loss_dice: 2.353  loss_seg: 0.7688  loss_ce_0: 0  loss_mask_0: 0.9179  loss_dice_0: 2.406  loss_ce_1: 0  loss_mask_1: 0.9299  loss_dice_1: 2.362  loss_ce_2: 0  loss_mask_2: 0.929  loss_dice_2: 2.346  loss_ce_3: 0  loss_mask_3: 0.9309  loss_dice_3: 2.335  loss_ce_4: 0  loss_mask_4: 0.9335  loss_dice_4: 2.334  loss_ce_5: 0  loss_mask_5: 0.9324  loss_dice_5: 2.336  loss_ce_6: 0  loss_mask_6: 0.9383  loss_dice_6: 2.343  loss_ce_7: 0  loss_mask_7: 0.9325  loss_dice_7: 2.342  loss_ce_8: 0  loss_mask_8: 0.9298  loss_dice_8: 2.347  time: 2.2038  data_time: 0.0278  lr: 8.2512e-05  max_mem: 6003M
[02/18 06:49:05] d2.utils.events INFO:  eta: 21:17:36  iter: 11559  total_loss: 33.73  loss_ce: 0  loss_mask: 0.8977  loss_dice: 2.39  loss_seg: 0.8569  loss_ce_0: 0  loss_mask_0: 0.9014  loss_dice_0: 2.449  loss_ce_1: 0  loss_mask_1: 0.9068  loss_dice_1: 2.397  loss_ce_2: 0  loss_mask_2: 0.9026  loss_dice_2: 2.381  loss_ce_3: 0  loss_mask_3: 0.9031  loss_dice_3: 2.368  loss_ce_4: 0  loss_mask_4: 0.9056  loss_dice_4: 2.368  loss_ce_5: 0  loss_mask_5: 0.9073  loss_dice_5: 2.372  loss_ce_6: 0  loss_mask_6: 0.9044  loss_dice_6: 2.375  loss_ce_7: 0  loss_mask_7: 0.9049  loss_dice_7: 2.375  loss_ce_8: 0  loss_mask_8: 0.9056  loss_dice_8: 2.374  time: 2.2027  data_time: 0.0322  lr: 8.2481e-05  max_mem: 6003M
[02/18 06:49:38] d2.utils.events INFO:  eta: 21:20:25  iter: 11579  total_loss: 35.01  loss_ce: 0  loss_mask: 0.9113  loss_dice: 2.472  loss_seg: 0.9994  loss_ce_0: 0  loss_mask_0: 0.9075  loss_dice_0: 2.504  loss_ce_1: 0  loss_mask_1: 0.9142  loss_dice_1: 2.473  loss_ce_2: 0  loss_mask_2: 0.9101  loss_dice_2: 2.462  loss_ce_3: 0  loss_mask_3: 0.9119  loss_dice_3: 2.457  loss_ce_4: 0  loss_mask_4: 0.9193  loss_dice_4: 2.459  loss_ce_5: 0  loss_mask_5: 0.9203  loss_dice_5: 2.458  loss_ce_6: 0  loss_mask_6: 0.921  loss_dice_6: 2.462  loss_ce_7: 0  loss_mask_7: 0.924  loss_dice_7: 2.459  loss_ce_8: 0  loss_mask_8: 0.9214  loss_dice_8: 2.456  time: 2.2018  data_time: 0.0320  lr: 8.2451e-05  max_mem: 6003M
[02/18 06:50:11] d2.utils.events INFO:  eta: 21:19:19  iter: 11599  total_loss: 33.94  loss_ce: 0  loss_mask: 0.8956  loss_dice: 2.387  loss_seg: 0.8521  loss_ce_0: 0  loss_mask_0: 0.8964  loss_dice_0: 2.444  loss_ce_1: 0  loss_mask_1: 0.8979  loss_dice_1: 2.403  loss_ce_2: 0  loss_mask_2: 0.8963  loss_dice_2: 2.378  loss_ce_3: 0  loss_mask_3: 0.8957  loss_dice_3: 2.365  loss_ce_4: 0  loss_mask_4: 0.8986  loss_dice_4: 2.364  loss_ce_5: 0  loss_mask_5: 0.8989  loss_dice_5: 2.374  loss_ce_6: 0  loss_mask_6: 0.8968  loss_dice_6: 2.369  loss_ce_7: 0  loss_mask_7: 0.8991  loss_dice_7: 2.369  loss_ce_8: 0  loss_mask_8: 0.8983  loss_dice_8: 2.373  time: 2.2008  data_time: 0.0273  lr: 8.242e-05  max_mem: 6003M
[02/18 06:50:42] d2.utils.events INFO:  eta: 21:17:32  iter: 11619  total_loss: 34.67  loss_ce: 0  loss_mask: 0.8974  loss_dice: 2.415  loss_seg: 0.7887  loss_ce_0: 0  loss_mask_0: 0.9083  loss_dice_0: 2.473  loss_ce_1: 0  loss_mask_1: 0.9092  loss_dice_1: 2.413  loss_ce_2: 0  loss_mask_2: 0.8999  loss_dice_2: 2.399  loss_ce_3: 0  loss_mask_3: 0.9054  loss_dice_3: 2.392  loss_ce_4: 0  loss_mask_4: 0.9014  loss_dice_4: 2.395  loss_ce_5: 0  loss_mask_5: 0.9028  loss_dice_5: 2.398  loss_ce_6: 0  loss_mask_6: 0.9035  loss_dice_6: 2.393  loss_ce_7: 0  loss_mask_7: 0.9029  loss_dice_7: 2.393  loss_ce_8: 0  loss_mask_8: 0.9008  loss_dice_8: 2.393  time: 2.1997  data_time: 0.0309  lr: 8.2389e-05  max_mem: 6003M
[02/18 06:51:15] d2.utils.events INFO:  eta: 21:19:32  iter: 11639  total_loss: 36.03  loss_ce: 0  loss_mask: 0.9178  loss_dice: 2.552  loss_seg: 1.089  loss_ce_0: 0  loss_mask_0: 0.9233  loss_dice_0: 2.601  loss_ce_1: 0  loss_mask_1: 0.913  loss_dice_1: 2.561  loss_ce_2: 0  loss_mask_2: 0.917  loss_dice_2: 2.544  loss_ce_3: 0  loss_mask_3: 0.9192  loss_dice_3: 2.535  loss_ce_4: 0  loss_mask_4: 0.9194  loss_dice_4: 2.54  loss_ce_5: 0  loss_mask_5: 0.9198  loss_dice_5: 2.531  loss_ce_6: 0  loss_mask_6: 0.9248  loss_dice_6: 2.537  loss_ce_7: 0  loss_mask_7: 0.9241  loss_dice_7: 2.533  loss_ce_8: 0  loss_mask_8: 0.9266  loss_dice_8: 2.538  time: 2.1987  data_time: 0.0306  lr: 8.2359e-05  max_mem: 6003M
[02/18 06:51:47] d2.utils.events INFO:  eta: 21:20:40  iter: 11659  total_loss: 33.31  loss_ce: 0  loss_mask: 0.9098  loss_dice: 2.337  loss_seg: 0.7923  loss_ce_0: 0  loss_mask_0: 0.9172  loss_dice_0: 2.408  loss_ce_1: 0  loss_mask_1: 0.9152  loss_dice_1: 2.358  loss_ce_2: 0  loss_mask_2: 0.9129  loss_dice_2: 2.338  loss_ce_3: 0  loss_mask_3: 0.92  loss_dice_3: 2.322  loss_ce_4: 0  loss_mask_4: 0.9194  loss_dice_4: 2.33  loss_ce_5: 0  loss_mask_5: 0.9225  loss_dice_5: 2.327  loss_ce_6: 0  loss_mask_6: 0.918  loss_dice_6: 2.323  loss_ce_7: 0  loss_mask_7: 0.918  loss_dice_7: 2.327  loss_ce_8: 0  loss_mask_8: 0.9176  loss_dice_8: 2.327  time: 2.1977  data_time: 0.0332  lr: 8.2328e-05  max_mem: 6003M
[02/18 06:52:20] d2.utils.events INFO:  eta: 21:20:46  iter: 11679  total_loss: 35.9  loss_ce: 0  loss_mask: 0.8812  loss_dice: 2.57  loss_seg: 1.036  loss_ce_0: 0  loss_mask_0: 0.8913  loss_dice_0: 2.614  loss_ce_1: 0  loss_mask_1: 0.8847  loss_dice_1: 2.583  loss_ce_2: 0  loss_mask_2: 0.888  loss_dice_2: 2.574  loss_ce_3: 0  loss_mask_3: 0.8891  loss_dice_3: 2.565  loss_ce_4: 0  loss_mask_4: 0.89  loss_dice_4: 2.573  loss_ce_5: 0  loss_mask_5: 0.8889  loss_dice_5: 2.559  loss_ce_6: 0  loss_mask_6: 0.8883  loss_dice_6: 2.558  loss_ce_7: 0  loss_mask_7: 0.8891  loss_dice_7: 2.555  loss_ce_8: 0  loss_mask_8: 0.8894  loss_dice_8: 2.554  time: 2.1967  data_time: 0.0358  lr: 8.2297e-05  max_mem: 6003M
[02/18 06:52:53] d2.utils.events INFO:  eta: 21:21:33  iter: 11699  total_loss: 33.95  loss_ce: 0  loss_mask: 0.8971  loss_dice: 2.335  loss_seg: 0.8363  loss_ce_0: 0  loss_mask_0: 0.901  loss_dice_0: 2.384  loss_ce_1: 0  loss_mask_1: 0.8977  loss_dice_1: 2.331  loss_ce_2: 0  loss_mask_2: 0.8968  loss_dice_2: 2.322  loss_ce_3: 0  loss_mask_3: 0.9047  loss_dice_3: 2.313  loss_ce_4: 0  loss_mask_4: 0.9046  loss_dice_4: 2.317  loss_ce_5: 0  loss_mask_5: 0.9005  loss_dice_5: 2.324  loss_ce_6: 0  loss_mask_6: 0.9019  loss_dice_6: 2.315  loss_ce_7: 0  loss_mask_7: 0.9036  loss_dice_7: 2.32  loss_ce_8: 0  loss_mask_8: 0.9029  loss_dice_8: 2.322  time: 2.1958  data_time: 0.0328  lr: 8.2267e-05  max_mem: 6003M
[02/18 06:53:25] d2.utils.events INFO:  eta: 21:20:01  iter: 11719  total_loss: 35.17  loss_ce: 0  loss_mask: 0.896  loss_dice: 2.406  loss_seg: 1.267  loss_ce_0: 0  loss_mask_0: 0.8963  loss_dice_0: 2.454  loss_ce_1: 0  loss_mask_1: 0.9036  loss_dice_1: 2.413  loss_ce_2: 0  loss_mask_2: 0.9042  loss_dice_2: 2.397  loss_ce_3: 0  loss_mask_3: 0.9052  loss_dice_3: 2.39  loss_ce_4: 0  loss_mask_4: 0.9038  loss_dice_4: 2.395  loss_ce_5: 0  loss_mask_5: 0.9006  loss_dice_5: 2.391  loss_ce_6: 0  loss_mask_6: 0.9013  loss_dice_6: 2.388  loss_ce_7: 0  loss_mask_7: 0.8985  loss_dice_7: 2.396  loss_ce_8: 0  loss_mask_8: 0.8999  loss_dice_8: 2.398  time: 2.1948  data_time: 0.0296  lr: 8.2236e-05  max_mem: 6003M
[02/18 06:53:59] d2.utils.events INFO:  eta: 21:20:37  iter: 11739  total_loss: 33.88  loss_ce: 0  loss_mask: 0.9181  loss_dice: 2.429  loss_seg: 0.8595  loss_ce_0: 0  loss_mask_0: 0.9456  loss_dice_0: 2.497  loss_ce_1: 0  loss_mask_1: 0.9159  loss_dice_1: 2.438  loss_ce_2: 0  loss_mask_2: 0.9159  loss_dice_2: 2.42  loss_ce_3: 0  loss_mask_3: 0.9207  loss_dice_3: 2.414  loss_ce_4: 0  loss_mask_4: 0.9195  loss_dice_4: 2.414  loss_ce_5: 0  loss_mask_5: 0.9177  loss_dice_5: 2.415  loss_ce_6: 0  loss_mask_6: 0.9239  loss_dice_6: 2.413  loss_ce_7: 0  loss_mask_7: 0.9203  loss_dice_7: 2.423  loss_ce_8: 0  loss_mask_8: 0.9219  loss_dice_8: 2.418  time: 2.1939  data_time: 0.0325  lr: 8.2205e-05  max_mem: 6003M
[02/18 06:54:32] d2.utils.events INFO:  eta: 21:18:58  iter: 11759  total_loss: 33.43  loss_ce: 0  loss_mask: 0.9056  loss_dice: 2.35  loss_seg: 0.6505  loss_ce_0: 0  loss_mask_0: 0.9052  loss_dice_0: 2.418  loss_ce_1: 0  loss_mask_1: 0.9114  loss_dice_1: 2.36  loss_ce_2: 0  loss_mask_2: 0.9122  loss_dice_2: 2.344  loss_ce_3: 0  loss_mask_3: 0.9135  loss_dice_3: 2.337  loss_ce_4: 0  loss_mask_4: 0.9125  loss_dice_4: 2.333  loss_ce_5: 0  loss_mask_5: 0.912  loss_dice_5: 2.331  loss_ce_6: 0  loss_mask_6: 0.9037  loss_dice_6: 2.326  loss_ce_7: 0  loss_mask_7: 0.9106  loss_dice_7: 2.333  loss_ce_8: 0  loss_mask_8: 0.9151  loss_dice_8: 2.325  time: 2.1929  data_time: 0.0300  lr: 8.2175e-05  max_mem: 6003M
[02/18 06:55:05] d2.utils.events INFO:  eta: 21:21:29  iter: 11779  total_loss: 32.91  loss_ce: 0  loss_mask: 0.882  loss_dice: 2.244  loss_seg: 0.8736  loss_ce_0: 0  loss_mask_0: 0.8854  loss_dice_0: 2.316  loss_ce_1: 0  loss_mask_1: 0.8824  loss_dice_1: 2.233  loss_ce_2: 0  loss_mask_2: 0.8843  loss_dice_2: 2.232  loss_ce_3: 0  loss_mask_3: 0.8882  loss_dice_3: 2.225  loss_ce_4: 0  loss_mask_4: 0.8916  loss_dice_4: 2.229  loss_ce_5: 0  loss_mask_5: 0.89  loss_dice_5: 2.228  loss_ce_6: 0  loss_mask_6: 0.8923  loss_dice_6: 2.225  loss_ce_7: 0  loss_mask_7: 0.8904  loss_dice_7: 2.232  loss_ce_8: 0  loss_mask_8: 0.8886  loss_dice_8: 2.234  time: 2.1921  data_time: 0.0270  lr: 8.2144e-05  max_mem: 6003M
[02/18 06:55:37] d2.utils.events INFO:  eta: 21:21:06  iter: 11799  total_loss: 35.68  loss_ce: 0  loss_mask: 0.9173  loss_dice: 2.526  loss_seg: 1.07  loss_ce_0: 0  loss_mask_0: 0.9301  loss_dice_0: 2.563  loss_ce_1: 0  loss_mask_1: 0.9118  loss_dice_1: 2.541  loss_ce_2: 0  loss_mask_2: 0.9201  loss_dice_2: 2.529  loss_ce_3: 0  loss_mask_3: 0.9232  loss_dice_3: 2.513  loss_ce_4: 0  loss_mask_4: 0.9233  loss_dice_4: 2.511  loss_ce_5: 0  loss_mask_5: 0.9217  loss_dice_5: 2.516  loss_ce_6: 0  loss_mask_6: 0.9244  loss_dice_6: 2.512  loss_ce_7: 0  loss_mask_7: 0.925  loss_dice_7: 2.512  loss_ce_8: 0  loss_mask_8: 0.9235  loss_dice_8: 2.51  time: 2.1910  data_time: 0.0401  lr: 8.2113e-05  max_mem: 6003M
[02/18 06:56:09] d2.utils.events INFO:  eta: 21:18:29  iter: 11819  total_loss: 34.28  loss_ce: 0  loss_mask: 0.8835  loss_dice: 2.459  loss_seg: 0.8571  loss_ce_0: 0  loss_mask_0: 0.8895  loss_dice_0: 2.538  loss_ce_1: 0  loss_mask_1: 0.8835  loss_dice_1: 2.465  loss_ce_2: 0  loss_mask_2: 0.8799  loss_dice_2: 2.452  loss_ce_3: 0  loss_mask_3: 0.874  loss_dice_3: 2.449  loss_ce_4: 0  loss_mask_4: 0.8732  loss_dice_4: 2.456  loss_ce_5: 0  loss_mask_5: 0.871  loss_dice_5: 2.458  loss_ce_6: 0  loss_mask_6: 0.8724  loss_dice_6: 2.45  loss_ce_7: 0  loss_mask_7: 0.879  loss_dice_7: 2.45  loss_ce_8: 0  loss_mask_8: 0.8784  loss_dice_8: 2.45  time: 2.1900  data_time: 0.0293  lr: 8.2083e-05  max_mem: 6003M
[02/18 06:56:42] d2.utils.events INFO:  eta: 21:18:48  iter: 11839  total_loss: 34.2  loss_ce: 0  loss_mask: 0.8676  loss_dice: 2.395  loss_seg: 0.8955  loss_ce_0: 0  loss_mask_0: 0.8754  loss_dice_0: 2.449  loss_ce_1: 0  loss_mask_1: 0.8692  loss_dice_1: 2.417  loss_ce_2: 0  loss_mask_2: 0.8725  loss_dice_2: 2.399  loss_ce_3: 0  loss_mask_3: 0.8703  loss_dice_3: 2.381  loss_ce_4: 0  loss_mask_4: 0.8768  loss_dice_4: 2.379  loss_ce_5: 0  loss_mask_5: 0.8722  loss_dice_5: 2.381  loss_ce_6: 0  loss_mask_6: 0.8687  loss_dice_6: 2.373  loss_ce_7: 0  loss_mask_7: 0.8682  loss_dice_7: 2.373  loss_ce_8: 0  loss_mask_8: 0.8641  loss_dice_8: 2.375  time: 2.1891  data_time: 0.0235  lr: 8.2052e-05  max_mem: 6003M
[02/18 06:57:14] d2.utils.events INFO:  eta: 21:18:16  iter: 11859  total_loss: 33.41  loss_ce: 0  loss_mask: 0.9174  loss_dice: 2.348  loss_seg: 0.7832  loss_ce_0: 0  loss_mask_0: 0.9202  loss_dice_0: 2.425  loss_ce_1: 0  loss_mask_1: 0.9275  loss_dice_1: 2.352  loss_ce_2: 0  loss_mask_2: 0.9191  loss_dice_2: 2.334  loss_ce_3: 0  loss_mask_3: 0.9169  loss_dice_3: 2.334  loss_ce_4: 0  loss_mask_4: 0.9207  loss_dice_4: 2.34  loss_ce_5: 0  loss_mask_5: 0.9273  loss_dice_5: 2.339  loss_ce_6: 0  loss_mask_6: 0.9236  loss_dice_6: 2.333  loss_ce_7: 0  loss_mask_7: 0.9278  loss_dice_7: 2.336  loss_ce_8: 0  loss_mask_8: 0.9251  loss_dice_8: 2.334  time: 2.1881  data_time: 0.0403  lr: 8.2021e-05  max_mem: 6003M
[02/18 06:57:50] d2.utils.events INFO:  eta: 21:18:14  iter: 11879  total_loss: 34.86  loss_ce: 0  loss_mask: 0.9104  loss_dice: 2.433  loss_seg: 0.7505  loss_ce_0: 0  loss_mask_0: 0.9208  loss_dice_0: 2.473  loss_ce_1: 0  loss_mask_1: 0.9129  loss_dice_1: 2.431  loss_ce_2: 0  loss_mask_2: 0.9116  loss_dice_2: 2.42  loss_ce_3: 0  loss_mask_3: 0.9185  loss_dice_3: 2.415  loss_ce_4: 0  loss_mask_4: 0.9164  loss_dice_4: 2.418  loss_ce_5: 0  loss_mask_5: 0.9147  loss_dice_5: 2.417  loss_ce_6: 0  loss_mask_6: 0.9136  loss_dice_6: 2.414  loss_ce_7: 0  loss_mask_7: 0.9155  loss_dice_7: 2.415  loss_ce_8: 0  loss_mask_8: 0.9184  loss_dice_8: 2.42  time: 2.1874  data_time: 0.0315  lr: 8.1991e-05  max_mem: 6003M
[02/18 06:58:21] d2.utils.events INFO:  eta: 21:18:54  iter: 11899  total_loss: 34.39  loss_ce: 0  loss_mask: 0.8752  loss_dice: 2.472  loss_seg: 1.041  loss_ce_0: 0  loss_mask_0: 0.8856  loss_dice_0: 2.519  loss_ce_1: 0  loss_mask_1: 0.8788  loss_dice_1: 2.474  loss_ce_2: 0  loss_mask_2: 0.8742  loss_dice_2: 2.468  loss_ce_3: 0  loss_mask_3: 0.8826  loss_dice_3: 2.452  loss_ce_4: 0  loss_mask_4: 0.8821  loss_dice_4: 2.451  loss_ce_5: 0  loss_mask_5: 0.8813  loss_dice_5: 2.457  loss_ce_6: 0  loss_mask_6: 0.8828  loss_dice_6: 2.451  loss_ce_7: 0  loss_mask_7: 0.889  loss_dice_7: 2.45  loss_ce_8: 0  loss_mask_8: 0.8842  loss_dice_8: 2.453  time: 2.1864  data_time: 0.0230  lr: 8.196e-05  max_mem: 6003M
[02/18 06:58:55] d2.utils.events INFO:  eta: 21:18:22  iter: 11919  total_loss: 34.07  loss_ce: 0  loss_mask: 0.8699  loss_dice: 2.402  loss_seg: 0.9601  loss_ce_0: 0  loss_mask_0: 0.877  loss_dice_0: 2.435  loss_ce_1: 0  loss_mask_1: 0.8687  loss_dice_1: 2.4  loss_ce_2: 0  loss_mask_2: 0.8723  loss_dice_2: 2.389  loss_ce_3: 0  loss_mask_3: 0.8702  loss_dice_3: 2.389  loss_ce_4: 0  loss_mask_4: 0.8697  loss_dice_4: 2.384  loss_ce_5: 0  loss_mask_5: 0.8665  loss_dice_5: 2.396  loss_ce_6: 0  loss_mask_6: 0.8668  loss_dice_6: 2.396  loss_ce_7: 0  loss_mask_7: 0.8708  loss_dice_7: 2.387  loss_ce_8: 0  loss_mask_8: 0.8732  loss_dice_8: 2.386  time: 2.1855  data_time: 0.0303  lr: 8.1929e-05  max_mem: 6003M
[02/18 06:59:26] d2.utils.events INFO:  eta: 21:18:16  iter: 11939  total_loss: 33.51  loss_ce: 0  loss_mask: 0.9245  loss_dice: 2.336  loss_seg: 0.7767  loss_ce_0: 0  loss_mask_0: 0.94  loss_dice_0: 2.412  loss_ce_1: 0  loss_mask_1: 0.9207  loss_dice_1: 2.343  loss_ce_2: 0  loss_mask_2: 0.9318  loss_dice_2: 2.33  loss_ce_3: 0  loss_mask_3: 0.9349  loss_dice_3: 2.318  loss_ce_4: 0  loss_mask_4: 0.9343  loss_dice_4: 2.315  loss_ce_5: 0  loss_mask_5: 0.9382  loss_dice_5: 2.322  loss_ce_6: 0  loss_mask_6: 0.9392  loss_dice_6: 2.311  loss_ce_7: 0  loss_mask_7: 0.9337  loss_dice_7: 2.315  loss_ce_8: 0  loss_mask_8: 0.9365  loss_dice_8: 2.313  time: 2.1845  data_time: 0.0249  lr: 8.1899e-05  max_mem: 6003M
[02/18 07:00:01] d2.utils.events INFO:  eta: 21:20:37  iter: 11959  total_loss: 35.51  loss_ce: 0  loss_mask: 0.9167  loss_dice: 2.539  loss_seg: 0.9661  loss_ce_0: 0  loss_mask_0: 0.9517  loss_dice_0: 2.606  loss_ce_1: 0  loss_mask_1: 0.9229  loss_dice_1: 2.541  loss_ce_2: 0  loss_mask_2: 0.9187  loss_dice_2: 2.524  loss_ce_3: 0  loss_mask_3: 0.9168  loss_dice_3: 2.512  loss_ce_4: 0  loss_mask_4: 0.9174  loss_dice_4: 2.516  loss_ce_5: 0  loss_mask_5: 0.918  loss_dice_5: 2.518  loss_ce_6: 0  loss_mask_6: 0.9222  loss_dice_6: 2.514  loss_ce_7: 0  loss_mask_7: 0.9218  loss_dice_7: 2.515  loss_ce_8: 0  loss_mask_8: 0.9212  loss_dice_8: 2.516  time: 2.1837  data_time: 0.0342  lr: 8.1868e-05  max_mem: 6003M
[02/18 07:00:34] d2.utils.events INFO:  eta: 21:21:30  iter: 11979  total_loss: 35.2  loss_ce: 0  loss_mask: 0.8812  loss_dice: 2.391  loss_seg: 1.433  loss_ce_0: 0  loss_mask_0: 0.8984  loss_dice_0: 2.448  loss_ce_1: 0  loss_mask_1: 0.8869  loss_dice_1: 2.389  loss_ce_2: 0  loss_mask_2: 0.8904  loss_dice_2: 2.374  loss_ce_3: 0  loss_mask_3: 0.8934  loss_dice_3: 2.372  loss_ce_4: 0  loss_mask_4: 0.8901  loss_dice_4: 2.372  loss_ce_5: 0  loss_mask_5: 0.895  loss_dice_5: 2.37  loss_ce_6: 0  loss_mask_6: 0.8975  loss_dice_6: 2.364  loss_ce_7: 0  loss_mask_7: 0.8941  loss_dice_7: 2.364  loss_ce_8: 0  loss_mask_8: 0.8885  loss_dice_8: 2.369  time: 2.1828  data_time: 0.0251  lr: 8.1837e-05  max_mem: 6003M
[02/18 07:01:08] d2.utils.events INFO:  eta: 21:22:27  iter: 11999  total_loss: 33.66  loss_ce: 0  loss_mask: 0.8794  loss_dice: 2.374  loss_seg: 0.8577  loss_ce_0: 0  loss_mask_0: 0.9014  loss_dice_0: 2.428  loss_ce_1: 0  loss_mask_1: 0.8918  loss_dice_1: 2.372  loss_ce_2: 0  loss_mask_2: 0.8933  loss_dice_2: 2.363  loss_ce_3: 0  loss_mask_3: 0.8942  loss_dice_3: 2.36  loss_ce_4: 0  loss_mask_4: 0.8977  loss_dice_4: 2.362  loss_ce_5: 0  loss_mask_5: 0.8932  loss_dice_5: 2.368  loss_ce_6: 0  loss_mask_6: 0.8931  loss_dice_6: 2.366  loss_ce_7: 0  loss_mask_7: 0.8936  loss_dice_7: 2.361  loss_ce_8: 0  loss_mask_8: 0.8903  loss_dice_8: 2.366  time: 2.1820  data_time: 0.0246  lr: 8.1807e-05  max_mem: 6003M
[02/18 07:01:41] d2.utils.events INFO:  eta: 21:22:40  iter: 12019  total_loss: 35.29  loss_ce: 0  loss_mask: 0.9136  loss_dice: 2.529  loss_seg: 0.887  loss_ce_0: 0  loss_mask_0: 0.9079  loss_dice_0: 2.589  loss_ce_1: 0  loss_mask_1: 0.9174  loss_dice_1: 2.535  loss_ce_2: 0  loss_mask_2: 0.9182  loss_dice_2: 2.53  loss_ce_3: 0  loss_mask_3: 0.9215  loss_dice_3: 2.512  loss_ce_4: 0  loss_mask_4: 0.9232  loss_dice_4: 2.515  loss_ce_5: 0  loss_mask_5: 0.9256  loss_dice_5: 2.521  loss_ce_6: 0  loss_mask_6: 0.9265  loss_dice_6: 2.517  loss_ce_7: 0  loss_mask_7: 0.9238  loss_dice_7: 2.515  loss_ce_8: 0  loss_mask_8: 0.9239  loss_dice_8: 2.512  time: 2.1811  data_time: 0.0315  lr: 8.1776e-05  max_mem: 6003M
[02/18 07:02:13] d2.utils.events INFO:  eta: 21:21:35  iter: 12039  total_loss: 34.97  loss_ce: 0  loss_mask: 0.9233  loss_dice: 2.434  loss_seg: 0.8337  loss_ce_0: 0  loss_mask_0: 0.9171  loss_dice_0: 2.476  loss_ce_1: 0  loss_mask_1: 0.9195  loss_dice_1: 2.441  loss_ce_2: 0  loss_mask_2: 0.929  loss_dice_2: 2.419  loss_ce_3: 0  loss_mask_3: 0.9344  loss_dice_3: 2.407  loss_ce_4: 0  loss_mask_4: 0.9315  loss_dice_4: 2.419  loss_ce_5: 0  loss_mask_5: 0.9312  loss_dice_5: 2.419  loss_ce_6: 0  loss_mask_6: 0.9302  loss_dice_6: 2.416  loss_ce_7: 0  loss_mask_7: 0.9299  loss_dice_7: 2.415  loss_ce_8: 0  loss_mask_8: 0.9341  loss_dice_8: 2.42  time: 2.1802  data_time: 0.0287  lr: 8.1745e-05  max_mem: 6003M
[02/18 07:02:47] d2.utils.events INFO:  eta: 21:21:29  iter: 12059  total_loss: 34.33  loss_ce: 0  loss_mask: 0.9089  loss_dice: 2.376  loss_seg: 0.8201  loss_ce_0: 0  loss_mask_0: 0.9187  loss_dice_0: 2.435  loss_ce_1: 0  loss_mask_1: 0.92  loss_dice_1: 2.379  loss_ce_2: 0  loss_mask_2: 0.9221  loss_dice_2: 2.362  loss_ce_3: 0  loss_mask_3: 0.9197  loss_dice_3: 2.358  loss_ce_4: 0  loss_mask_4: 0.9174  loss_dice_4: 2.357  loss_ce_5: 0  loss_mask_5: 0.9184  loss_dice_5: 2.355  loss_ce_6: 0  loss_mask_6: 0.9195  loss_dice_6: 2.355  loss_ce_7: 0  loss_mask_7: 0.9255  loss_dice_7: 2.354  loss_ce_8: 0  loss_mask_8: 0.9225  loss_dice_8: 2.359  time: 2.1794  data_time: 0.0270  lr: 8.1715e-05  max_mem: 6003M
[02/18 07:03:21] d2.utils.events INFO:  eta: 21:21:32  iter: 12079  total_loss: 34.87  loss_ce: 0  loss_mask: 0.8883  loss_dice: 2.467  loss_seg: 1.001  loss_ce_0: 0  loss_mask_0: 0.8856  loss_dice_0: 2.508  loss_ce_1: 0  loss_mask_1: 0.8851  loss_dice_1: 2.472  loss_ce_2: 0  loss_mask_2: 0.888  loss_dice_2: 2.462  loss_ce_3: 0  loss_mask_3: 0.8926  loss_dice_3: 2.459  loss_ce_4: 0  loss_mask_4: 0.8922  loss_dice_4: 2.451  loss_ce_5: 0  loss_mask_5: 0.89  loss_dice_5: 2.457  loss_ce_6: 0  loss_mask_6: 0.8875  loss_dice_6: 2.449  loss_ce_7: 0  loss_mask_7: 0.8869  loss_dice_7: 2.451  loss_ce_8: 0  loss_mask_8: 0.89  loss_dice_8: 2.452  time: 2.1785  data_time: 0.0315  lr: 8.1684e-05  max_mem: 6003M
[02/18 07:03:50] d2.utils.events INFO:  eta: 21:17:59  iter: 12099  total_loss: 34.47  loss_ce: 0  loss_mask: 0.899  loss_dice: 2.461  loss_seg: 1.155  loss_ce_0: 0  loss_mask_0: 0.8878  loss_dice_0: 2.523  loss_ce_1: 0  loss_mask_1: 0.8954  loss_dice_1: 2.472  loss_ce_2: 0  loss_mask_2: 0.899  loss_dice_2: 2.451  loss_ce_3: 0  loss_mask_3: 0.9053  loss_dice_3: 2.444  loss_ce_4: 0  loss_mask_4: 0.9051  loss_dice_4: 2.44  loss_ce_5: 0  loss_mask_5: 0.902  loss_dice_5: 2.442  loss_ce_6: 0  loss_mask_6: 0.9069  loss_dice_6: 2.436  loss_ce_7: 0  loss_mask_7: 0.9032  loss_dice_7: 2.438  loss_ce_8: 0  loss_mask_8: 0.9029  loss_dice_8: 2.445  time: 2.1774  data_time: 0.0325  lr: 8.1653e-05  max_mem: 6003M
[02/18 07:04:23] d2.utils.events INFO:  eta: 21:18:23  iter: 12119  total_loss: 34.69  loss_ce: 0  loss_mask: 0.8905  loss_dice: 2.519  loss_seg: 0.8628  loss_ce_0: 0  loss_mask_0: 0.8921  loss_dice_0: 2.566  loss_ce_1: 0  loss_mask_1: 0.8911  loss_dice_1: 2.526  loss_ce_2: 0  loss_mask_2: 0.8995  loss_dice_2: 2.514  loss_ce_3: 0  loss_mask_3: 0.8988  loss_dice_3: 2.497  loss_ce_4: 0  loss_mask_4: 0.8992  loss_dice_4: 2.503  loss_ce_5: 0  loss_mask_5: 0.9015  loss_dice_5: 2.498  loss_ce_6: 0  loss_mask_6: 0.898  loss_dice_6: 2.507  loss_ce_7: 0  loss_mask_7: 0.8989  loss_dice_7: 2.502  loss_ce_8: 0  loss_mask_8: 0.8975  loss_dice_8: 2.497  time: 2.1765  data_time: 0.0306  lr: 8.1623e-05  max_mem: 6003M
[02/18 07:04:55] d2.utils.events INFO:  eta: 21:17:04  iter: 12139  total_loss: 34.34  loss_ce: 0  loss_mask: 0.8674  loss_dice: 2.46  loss_seg: 1.068  loss_ce_0: 0  loss_mask_0: 0.8523  loss_dice_0: 2.54  loss_ce_1: 0  loss_mask_1: 0.8663  loss_dice_1: 2.463  loss_ce_2: 0  loss_mask_2: 0.8692  loss_dice_2: 2.444  loss_ce_3: 0  loss_mask_3: 0.8745  loss_dice_3: 2.442  loss_ce_4: 0  loss_mask_4: 0.8705  loss_dice_4: 2.448  loss_ce_5: 0  loss_mask_5: 0.8743  loss_dice_5: 2.44  loss_ce_6: 0  loss_mask_6: 0.8775  loss_dice_6: 2.445  loss_ce_7: 0  loss_mask_7: 0.8736  loss_dice_7: 2.442  loss_ce_8: 0  loss_mask_8: 0.8752  loss_dice_8: 2.446  time: 2.1755  data_time: 0.0271  lr: 8.1592e-05  max_mem: 6003M
[02/18 07:05:29] d2.utils.events INFO:  eta: 21:18:48  iter: 12159  total_loss: 36.13  loss_ce: 0  loss_mask: 0.9471  loss_dice: 2.509  loss_seg: 1.001  loss_ce_0: 0  loss_mask_0: 0.9448  loss_dice_0: 2.533  loss_ce_1: 0  loss_mask_1: 0.9511  loss_dice_1: 2.521  loss_ce_2: 0  loss_mask_2: 0.954  loss_dice_2: 2.499  loss_ce_3: 0  loss_mask_3: 0.9596  loss_dice_3: 2.48  loss_ce_4: 0  loss_mask_4: 0.9645  loss_dice_4: 2.487  loss_ce_5: 0  loss_mask_5: 0.9548  loss_dice_5: 2.489  loss_ce_6: 0  loss_mask_6: 0.9601  loss_dice_6: 2.486  loss_ce_7: 0  loss_mask_7: 0.9563  loss_dice_7: 2.494  loss_ce_8: 0  loss_mask_8: 0.9554  loss_dice_8: 2.491  time: 2.1747  data_time: 0.0322  lr: 8.1561e-05  max_mem: 6003M
[02/18 07:06:04] d2.utils.events INFO:  eta: 21:18:43  iter: 12179  total_loss: 33.47  loss_ce: 0  loss_mask: 0.8998  loss_dice: 2.339  loss_seg: 0.8384  loss_ce_0: 0  loss_mask_0: 0.9029  loss_dice_0: 2.397  loss_ce_1: 0  loss_mask_1: 0.9101  loss_dice_1: 2.344  loss_ce_2: 0  loss_mask_2: 0.9076  loss_dice_2: 2.335  loss_ce_3: 0  loss_mask_3: 0.9045  loss_dice_3: 2.328  loss_ce_4: 0  loss_mask_4: 0.8999  loss_dice_4: 2.332  loss_ce_5: 0  loss_mask_5: 0.9053  loss_dice_5: 2.331  loss_ce_6: 0  loss_mask_6: 0.9045  loss_dice_6: 2.327  loss_ce_7: 0  loss_mask_7: 0.9082  loss_dice_7: 2.33  loss_ce_8: 0  loss_mask_8: 0.9064  loss_dice_8: 2.329  time: 2.1740  data_time: 0.0287  lr: 8.1531e-05  max_mem: 6003M
[02/18 07:06:34] d2.utils.events INFO:  eta: 21:16:15  iter: 12199  total_loss: 34.88  loss_ce: 0  loss_mask: 0.8989  loss_dice: 2.504  loss_seg: 0.9359  loss_ce_0: 0  loss_mask_0: 0.9112  loss_dice_0: 2.548  loss_ce_1: 0  loss_mask_1: 0.9072  loss_dice_1: 2.509  loss_ce_2: 0  loss_mask_2: 0.9024  loss_dice_2: 2.504  loss_ce_3: 0  loss_mask_3: 0.9103  loss_dice_3: 2.484  loss_ce_4: 0  loss_mask_4: 0.9072  loss_dice_4: 2.488  loss_ce_5: 0  loss_mask_5: 0.9004  loss_dice_5: 2.49  loss_ce_6: 0  loss_mask_6: 0.9031  loss_dice_6: 2.491  loss_ce_7: 0  loss_mask_7: 0.9077  loss_dice_7: 2.496  loss_ce_8: 0  loss_mask_8: 0.9058  loss_dice_8: 2.493  time: 2.1729  data_time: 0.0314  lr: 8.15e-05  max_mem: 6003M
[02/18 07:07:06] d2.utils.events INFO:  eta: 21:17:12  iter: 12219  total_loss: 32.92  loss_ce: 0  loss_mask: 0.8475  loss_dice: 2.309  loss_seg: 0.8129  loss_ce_0: 0  loss_mask_0: 0.852  loss_dice_0: 2.367  loss_ce_1: 0  loss_mask_1: 0.8518  loss_dice_1: 2.307  loss_ce_2: 0  loss_mask_2: 0.8495  loss_dice_2: 2.301  loss_ce_3: 0  loss_mask_3: 0.8558  loss_dice_3: 2.287  loss_ce_4: 0  loss_mask_4: 0.8588  loss_dice_4: 2.291  loss_ce_5: 0  loss_mask_5: 0.8545  loss_dice_5: 2.293  loss_ce_6: 0  loss_mask_6: 0.8548  loss_dice_6: 2.293  loss_ce_7: 0  loss_mask_7: 0.8541  loss_dice_7: 2.294  loss_ce_8: 0  loss_mask_8: 0.8511  loss_dice_8: 2.299  time: 2.1720  data_time: 0.0277  lr: 8.1469e-05  max_mem: 6003M
[02/18 07:07:38] d2.utils.events INFO:  eta: 21:17:06  iter: 12239  total_loss: 32.02  loss_ce: 0  loss_mask: 0.8629  loss_dice: 2.247  loss_seg: 0.82  loss_ce_0: 0  loss_mask_0: 0.8618  loss_dice_0: 2.319  loss_ce_1: 0  loss_mask_1: 0.8592  loss_dice_1: 2.265  loss_ce_2: 0  loss_mask_2: 0.8542  loss_dice_2: 2.256  loss_ce_3: 0  loss_mask_3: 0.8588  loss_dice_3: 2.243  loss_ce_4: 0  loss_mask_4: 0.8649  loss_dice_4: 2.251  loss_ce_5: 0  loss_mask_5: 0.8636  loss_dice_5: 2.255  loss_ce_6: 0  loss_mask_6: 0.8655  loss_dice_6: 2.246  loss_ce_7: 0  loss_mask_7: 0.8655  loss_dice_7: 2.241  loss_ce_8: 0  loss_mask_8: 0.867  loss_dice_8: 2.241  time: 2.1710  data_time: 0.0251  lr: 8.1439e-05  max_mem: 6003M
[02/18 07:08:10] d2.utils.events INFO:  eta: 21:18:50  iter: 12259  total_loss: 36.02  loss_ce: 0  loss_mask: 0.9194  loss_dice: 2.456  loss_seg: 0.9275  loss_ce_0: 0  loss_mask_0: 0.9067  loss_dice_0: 2.518  loss_ce_1: 0  loss_mask_1: 0.9244  loss_dice_1: 2.472  loss_ce_2: 0  loss_mask_2: 0.9347  loss_dice_2: 2.443  loss_ce_3: 0  loss_mask_3: 0.9337  loss_dice_3: 2.433  loss_ce_4: 0  loss_mask_4: 0.9319  loss_dice_4: 2.436  loss_ce_5: 0  loss_mask_5: 0.9341  loss_dice_5: 2.437  loss_ce_6: 0  loss_mask_6: 0.9302  loss_dice_6: 2.434  loss_ce_7: 0  loss_mask_7: 0.9211  loss_dice_7: 2.44  loss_ce_8: 0  loss_mask_8: 0.9238  loss_dice_8: 2.442  time: 2.1701  data_time: 0.0299  lr: 8.1408e-05  max_mem: 6003M
[02/18 07:08:46] d2.utils.events INFO:  eta: 21:19:26  iter: 12279  total_loss: 36.42  loss_ce: 0  loss_mask: 0.912  loss_dice: 2.555  loss_seg: 1.108  loss_ce_0: 0  loss_mask_0: 0.927  loss_dice_0: 2.589  loss_ce_1: 0  loss_mask_1: 0.9171  loss_dice_1: 2.578  loss_ce_2: 0  loss_mask_2: 0.9164  loss_dice_2: 2.56  loss_ce_3: 0  loss_mask_3: 0.9111  loss_dice_3: 2.553  loss_ce_4: 0  loss_mask_4: 0.909  loss_dice_4: 2.552  loss_ce_5: 0  loss_mask_5: 0.9091  loss_dice_5: 2.547  loss_ce_6: 0  loss_mask_6: 0.9101  loss_dice_6: 2.547  loss_ce_7: 0  loss_mask_7: 0.9147  loss_dice_7: 2.55  loss_ce_8: 0  loss_mask_8: 0.9122  loss_dice_8: 2.55  time: 2.1695  data_time: 0.0286  lr: 8.1377e-05  max_mem: 6003M
[02/18 07:09:19] d2.utils.events INFO:  eta: 21:19:30  iter: 12299  total_loss: 34.59  loss_ce: 0  loss_mask: 0.8914  loss_dice: 2.428  loss_seg: 1.035  loss_ce_0: 0  loss_mask_0: 0.8903  loss_dice_0: 2.505  loss_ce_1: 0  loss_mask_1: 0.8978  loss_dice_1: 2.437  loss_ce_2: 0  loss_mask_2: 0.8965  loss_dice_2: 2.419  loss_ce_3: 0  loss_mask_3: 0.8994  loss_dice_3: 2.415  loss_ce_4: 0  loss_mask_4: 0.894  loss_dice_4: 2.412  loss_ce_5: 0  loss_mask_5: 0.8967  loss_dice_5: 2.413  loss_ce_6: 0  loss_mask_6: 0.9002  loss_dice_6: 2.42  loss_ce_7: 0  loss_mask_7: 0.9019  loss_dice_7: 2.413  loss_ce_8: 0  loss_mask_8: 0.8982  loss_dice_8: 2.419  time: 2.1687  data_time: 0.0346  lr: 8.1346e-05  max_mem: 6003M
[02/18 07:09:53] d2.utils.events INFO:  eta: 21:19:25  iter: 12319  total_loss: 33.82  loss_ce: 0  loss_mask: 0.8989  loss_dice: 2.384  loss_seg: 0.7661  loss_ce_0: 0  loss_mask_0: 0.8926  loss_dice_0: 2.449  loss_ce_1: 0  loss_mask_1: 0.8982  loss_dice_1: 2.402  loss_ce_2: 0  loss_mask_2: 0.9069  loss_dice_2: 2.382  loss_ce_3: 0  loss_mask_3: 0.9066  loss_dice_3: 2.371  loss_ce_4: 0  loss_mask_4: 0.9044  loss_dice_4: 2.375  loss_ce_5: 0  loss_mask_5: 0.9099  loss_dice_5: 2.374  loss_ce_6: 0  loss_mask_6: 0.908  loss_dice_6: 2.371  loss_ce_7: 0  loss_mask_7: 0.9128  loss_dice_7: 2.374  loss_ce_8: 0  loss_mask_8: 0.9183  loss_dice_8: 2.376  time: 2.1679  data_time: 0.0293  lr: 8.1316e-05  max_mem: 6003M
[02/18 07:10:27] d2.utils.events INFO:  eta: 21:18:53  iter: 12339  total_loss: 34.07  loss_ce: 0  loss_mask: 0.8918  loss_dice: 2.39  loss_seg: 0.8805  loss_ce_0: 0  loss_mask_0: 0.8866  loss_dice_0: 2.465  loss_ce_1: 0  loss_mask_1: 0.9074  loss_dice_1: 2.396  loss_ce_2: 0  loss_mask_2: 0.9028  loss_dice_2: 2.379  loss_ce_3: 0  loss_mask_3: 0.904  loss_dice_3: 2.372  loss_ce_4: 0  loss_mask_4: 0.9035  loss_dice_4: 2.381  loss_ce_5: 0  loss_mask_5: 0.9027  loss_dice_5: 2.384  loss_ce_6: 0  loss_mask_6: 0.9024  loss_dice_6: 2.374  loss_ce_7: 0  loss_mask_7: 0.9003  loss_dice_7: 2.38  loss_ce_8: 0  loss_mask_8: 0.8991  loss_dice_8: 2.382  time: 2.1671  data_time: 0.0313  lr: 8.1285e-05  max_mem: 6003M
[02/18 07:11:00] d2.utils.events INFO:  eta: 21:19:49  iter: 12359  total_loss: 33.35  loss_ce: 0  loss_mask: 0.8977  loss_dice: 2.316  loss_seg: 0.9449  loss_ce_0: 0  loss_mask_0: 0.8845  loss_dice_0: 2.373  loss_ce_1: 0  loss_mask_1: 0.8959  loss_dice_1: 2.314  loss_ce_2: 0  loss_mask_2: 0.8964  loss_dice_2: 2.304  loss_ce_3: 0  loss_mask_3: 0.8958  loss_dice_3: 2.299  loss_ce_4: 0  loss_mask_4: 0.8962  loss_dice_4: 2.296  loss_ce_5: 0  loss_mask_5: 0.8999  loss_dice_5: 2.303  loss_ce_6: 0  loss_mask_6: 0.8978  loss_dice_6: 2.298  loss_ce_7: 0  loss_mask_7: 0.8993  loss_dice_7: 2.296  loss_ce_8: 0  loss_mask_8: 0.8961  loss_dice_8: 2.303  time: 2.1662  data_time: 0.0242  lr: 8.1254e-05  max_mem: 6003M
[02/18 07:11:34] d2.utils.events INFO:  eta: 21:18:37  iter: 12379  total_loss: 34.5  loss_ce: 0  loss_mask: 0.9159  loss_dice: 2.451  loss_seg: 0.7334  loss_ce_0: 0  loss_mask_0: 0.9265  loss_dice_0: 2.527  loss_ce_1: 0  loss_mask_1: 0.9178  loss_dice_1: 2.458  loss_ce_2: 0  loss_mask_2: 0.9153  loss_dice_2: 2.439  loss_ce_3: 0  loss_mask_3: 0.9154  loss_dice_3: 2.44  loss_ce_4: 0  loss_mask_4: 0.9134  loss_dice_4: 2.437  loss_ce_5: 0  loss_mask_5: 0.919  loss_dice_5: 2.435  loss_ce_6: 0  loss_mask_6: 0.911  loss_dice_6: 2.428  loss_ce_7: 0  loss_mask_7: 0.9134  loss_dice_7: 2.429  loss_ce_8: 0  loss_mask_8: 0.913  loss_dice_8: 2.431  time: 2.1655  data_time: 0.0329  lr: 8.1224e-05  max_mem: 6003M
[02/18 07:12:06] d2.utils.events INFO:  eta: 21:18:30  iter: 12399  total_loss: 34.52  loss_ce: 0  loss_mask: 0.9369  loss_dice: 2.37  loss_seg: 0.8508  loss_ce_0: 0  loss_mask_0: 0.9515  loss_dice_0: 2.432  loss_ce_1: 0  loss_mask_1: 0.9469  loss_dice_1: 2.37  loss_ce_2: 0  loss_mask_2: 0.9486  loss_dice_2: 2.369  loss_ce_3: 0  loss_mask_3: 0.9453  loss_dice_3: 2.34  loss_ce_4: 0  loss_mask_4: 0.9469  loss_dice_4: 2.341  loss_ce_5: 0  loss_mask_5: 0.9435  loss_dice_5: 2.342  loss_ce_6: 0  loss_mask_6: 0.9395  loss_dice_6: 2.341  loss_ce_7: 0  loss_mask_7: 0.9384  loss_dice_7: 2.346  loss_ce_8: 0  loss_mask_8: 0.9374  loss_dice_8: 2.346  time: 2.1646  data_time: 0.0302  lr: 8.1193e-05  max_mem: 6003M
[02/18 07:12:39] d2.utils.events INFO:  eta: 21:17:32  iter: 12419  total_loss: 33.98  loss_ce: 0  loss_mask: 0.8615  loss_dice: 2.38  loss_seg: 1.034  loss_ce_0: 0  loss_mask_0: 0.8601  loss_dice_0: 2.439  loss_ce_1: 0  loss_mask_1: 0.8676  loss_dice_1: 2.386  loss_ce_2: 0  loss_mask_2: 0.8659  loss_dice_2: 2.371  loss_ce_3: 0  loss_mask_3: 0.8654  loss_dice_3: 2.365  loss_ce_4: 0  loss_mask_4: 0.8685  loss_dice_4: 2.361  loss_ce_5: 0  loss_mask_5: 0.8686  loss_dice_5: 2.366  loss_ce_6: 0  loss_mask_6: 0.8676  loss_dice_6: 2.357  loss_ce_7: 0  loss_mask_7: 0.8724  loss_dice_7: 2.361  loss_ce_8: 0  loss_mask_8: 0.8747  loss_dice_8: 2.365  time: 2.1637  data_time: 0.0291  lr: 8.1162e-05  max_mem: 6003M
[02/18 07:13:12] d2.utils.events INFO:  eta: 21:16:31  iter: 12439  total_loss: 32.09  loss_ce: 0  loss_mask: 0.8518  loss_dice: 2.265  loss_seg: 0.8093  loss_ce_0: 0  loss_mask_0: 0.8539  loss_dice_0: 2.325  loss_ce_1: 0  loss_mask_1: 0.8607  loss_dice_1: 2.27  loss_ce_2: 0  loss_mask_2: 0.8605  loss_dice_2: 2.252  loss_ce_3: 0  loss_mask_3: 0.8597  loss_dice_3: 2.239  loss_ce_4: 0  loss_mask_4: 0.8616  loss_dice_4: 2.239  loss_ce_5: 0  loss_mask_5: 0.8632  loss_dice_5: 2.239  loss_ce_6: 0  loss_mask_6: 0.8615  loss_dice_6: 2.239  loss_ce_7: 0  loss_mask_7: 0.8586  loss_dice_7: 2.246  loss_ce_8: 0  loss_mask_8: 0.8644  loss_dice_8: 2.251  time: 2.1629  data_time: 0.0277  lr: 8.1132e-05  max_mem: 6003M
[02/18 07:13:43] d2.utils.events INFO:  eta: 21:15:23  iter: 12459  total_loss: 33.62  loss_ce: 0  loss_mask: 0.8914  loss_dice: 2.434  loss_seg: 0.8503  loss_ce_0: 0  loss_mask_0: 0.8966  loss_dice_0: 2.478  loss_ce_1: 0  loss_mask_1: 0.8985  loss_dice_1: 2.44  loss_ce_2: 0  loss_mask_2: 0.8981  loss_dice_2: 2.43  loss_ce_3: 0  loss_mask_3: 0.8998  loss_dice_3: 2.415  loss_ce_4: 0  loss_mask_4: 0.9005  loss_dice_4: 2.423  loss_ce_5: 0  loss_mask_5: 0.9028  loss_dice_5: 2.423  loss_ce_6: 0  loss_mask_6: 0.9005  loss_dice_6: 2.414  loss_ce_7: 0  loss_mask_7: 0.899  loss_dice_7: 2.423  loss_ce_8: 0  loss_mask_8: 0.9011  loss_dice_8: 2.416  time: 2.1619  data_time: 0.0222  lr: 8.1101e-05  max_mem: 6003M
[02/18 07:14:14] d2.utils.events INFO:  eta: 21:13:42  iter: 12479  total_loss: 34.32  loss_ce: 0  loss_mask: 0.9281  loss_dice: 2.422  loss_seg: 0.7993  loss_ce_0: 0  loss_mask_0: 0.9493  loss_dice_0: 2.487  loss_ce_1: 0  loss_mask_1: 0.9282  loss_dice_1: 2.431  loss_ce_2: 0  loss_mask_2: 0.9297  loss_dice_2: 2.416  loss_ce_3: 0  loss_mask_3: 0.9248  loss_dice_3: 2.405  loss_ce_4: 0  loss_mask_4: 0.9248  loss_dice_4: 2.41  loss_ce_5: 0  loss_mask_5: 0.9236  loss_dice_5: 2.41  loss_ce_6: 0  loss_mask_6: 0.9235  loss_dice_6: 2.409  loss_ce_7: 0  loss_mask_7: 0.923  loss_dice_7: 2.408  loss_ce_8: 0  loss_mask_8: 0.9234  loss_dice_8: 2.415  time: 2.1610  data_time: 0.0266  lr: 8.107e-05  max_mem: 6003M
[02/18 07:14:46] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 07:14:47] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 07:14:47] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 07:15:00] mask2former INFO: Inference done 11/1093. Dataloading: 0.0042 s/iter. Inference: 0.2245 s/iter. Eval: 0.1072 s/iter. Total: 0.3358 s/iter. ETA=0:06:03
[02/18 07:15:05] mask2former INFO: Inference done 26/1093. Dataloading: 0.0049 s/iter. Inference: 0.2247 s/iter. Eval: 0.1092 s/iter. Total: 0.3389 s/iter. ETA=0:06:01
[02/18 07:15:10] mask2former INFO: Inference done 36/1093. Dataloading: 0.0061 s/iter. Inference: 0.2472 s/iter. Eval: 0.1402 s/iter. Total: 0.3936 s/iter. ETA=0:06:56
[02/18 07:15:15] mask2former INFO: Inference done 43/1093. Dataloading: 0.0072 s/iter. Inference: 0.2836 s/iter. Eval: 0.1677 s/iter. Total: 0.4585 s/iter. ETA=0:08:01
[02/18 07:15:21] mask2former INFO: Inference done 50/1093. Dataloading: 0.0077 s/iter. Inference: 0.3111 s/iter. Eval: 0.1860 s/iter. Total: 0.5049 s/iter. ETA=0:08:46
[02/18 07:15:26] mask2former INFO: Inference done 64/1093. Dataloading: 0.0072 s/iter. Inference: 0.2944 s/iter. Eval: 0.1714 s/iter. Total: 0.4731 s/iter. ETA=0:08:06
[02/18 07:15:31] mask2former INFO: Inference done 74/1093. Dataloading: 0.0086 s/iter. Inference: 0.2970 s/iter. Eval: 0.1739 s/iter. Total: 0.4796 s/iter. ETA=0:08:08
[02/18 07:15:36] mask2former INFO: Inference done 88/1093. Dataloading: 0.0081 s/iter. Inference: 0.2880 s/iter. Eval: 0.1649 s/iter. Total: 0.4612 s/iter. ETA=0:07:43
[02/18 07:15:41] mask2former INFO: Inference done 102/1093. Dataloading: 0.0077 s/iter. Inference: 0.2787 s/iter. Eval: 0.1602 s/iter. Total: 0.4467 s/iter. ETA=0:07:22
[02/18 07:15:46] mask2former INFO: Inference done 116/1093. Dataloading: 0.0074 s/iter. Inference: 0.2738 s/iter. Eval: 0.1547 s/iter. Total: 0.4360 s/iter. ETA=0:07:05
[02/18 07:15:51] mask2former INFO: Inference done 131/1093. Dataloading: 0.0071 s/iter. Inference: 0.2671 s/iter. Eval: 0.1503 s/iter. Total: 0.4246 s/iter. ETA=0:06:48
[02/18 07:15:56] mask2former INFO: Inference done 145/1093. Dataloading: 0.0069 s/iter. Inference: 0.2636 s/iter. Eval: 0.1474 s/iter. Total: 0.4179 s/iter. ETA=0:06:36
[02/18 07:16:02] mask2former INFO: Inference done 160/1093. Dataloading: 0.0067 s/iter. Inference: 0.2604 s/iter. Eval: 0.1440 s/iter. Total: 0.4113 s/iter. ETA=0:06:23
[02/18 07:16:07] mask2former INFO: Inference done 174/1093. Dataloading: 0.0066 s/iter. Inference: 0.2589 s/iter. Eval: 0.1423 s/iter. Total: 0.4079 s/iter. ETA=0:06:14
[02/18 07:16:12] mask2former INFO: Inference done 189/1093. Dataloading: 0.0065 s/iter. Inference: 0.2567 s/iter. Eval: 0.1400 s/iter. Total: 0.4033 s/iter. ETA=0:06:04
[02/18 07:16:18] mask2former INFO: Inference done 204/1093. Dataloading: 0.0064 s/iter. Inference: 0.2561 s/iter. Eval: 0.1377 s/iter. Total: 0.4003 s/iter. ETA=0:05:55
[02/18 07:16:23] mask2former INFO: Inference done 218/1093. Dataloading: 0.0063 s/iter. Inference: 0.2559 s/iter. Eval: 0.1357 s/iter. Total: 0.3980 s/iter. ETA=0:05:48
[02/18 07:16:28] mask2former INFO: Inference done 232/1093. Dataloading: 0.0063 s/iter. Inference: 0.2550 s/iter. Eval: 0.1342 s/iter. Total: 0.3956 s/iter. ETA=0:05:40
[02/18 07:16:33] mask2former INFO: Inference done 245/1093. Dataloading: 0.0063 s/iter. Inference: 0.2560 s/iter. Eval: 0.1326 s/iter. Total: 0.3950 s/iter. ETA=0:05:34
[02/18 07:16:38] mask2former INFO: Inference done 258/1093. Dataloading: 0.0064 s/iter. Inference: 0.2565 s/iter. Eval: 0.1321 s/iter. Total: 0.3951 s/iter. ETA=0:05:29
[02/18 07:16:43] mask2former INFO: Inference done 272/1093. Dataloading: 0.0063 s/iter. Inference: 0.2567 s/iter. Eval: 0.1308 s/iter. Total: 0.3940 s/iter. ETA=0:05:23
[02/18 07:16:48] mask2former INFO: Inference done 287/1093. Dataloading: 0.0063 s/iter. Inference: 0.2553 s/iter. Eval: 0.1296 s/iter. Total: 0.3913 s/iter. ETA=0:05:15
[02/18 07:16:53] mask2former INFO: Inference done 301/1093. Dataloading: 0.0063 s/iter. Inference: 0.2545 s/iter. Eval: 0.1290 s/iter. Total: 0.3898 s/iter. ETA=0:05:08
[02/18 07:16:59] mask2former INFO: Inference done 316/1093. Dataloading: 0.0062 s/iter. Inference: 0.2532 s/iter. Eval: 0.1283 s/iter. Total: 0.3877 s/iter. ETA=0:05:01
[02/18 07:17:04] mask2former INFO: Inference done 331/1093. Dataloading: 0.0061 s/iter. Inference: 0.2524 s/iter. Eval: 0.1277 s/iter. Total: 0.3862 s/iter. ETA=0:04:54
[02/18 07:17:09] mask2former INFO: Inference done 345/1093. Dataloading: 0.0061 s/iter. Inference: 0.2518 s/iter. Eval: 0.1272 s/iter. Total: 0.3853 s/iter. ETA=0:04:48
[02/18 07:17:14] mask2former INFO: Inference done 359/1093. Dataloading: 0.0061 s/iter. Inference: 0.2520 s/iter. Eval: 0.1268 s/iter. Total: 0.3850 s/iter. ETA=0:04:42
[02/18 07:17:20] mask2former INFO: Inference done 374/1093. Dataloading: 0.0061 s/iter. Inference: 0.2511 s/iter. Eval: 0.1264 s/iter. Total: 0.3837 s/iter. ETA=0:04:35
[02/18 07:17:25] mask2former INFO: Inference done 388/1093. Dataloading: 0.0061 s/iter. Inference: 0.2514 s/iter. Eval: 0.1260 s/iter. Total: 0.3836 s/iter. ETA=0:04:30
[02/18 07:17:30] mask2former INFO: Inference done 402/1093. Dataloading: 0.0061 s/iter. Inference: 0.2515 s/iter. Eval: 0.1256 s/iter. Total: 0.3833 s/iter. ETA=0:04:24
[02/18 07:17:35] mask2former INFO: Inference done 416/1093. Dataloading: 0.0060 s/iter. Inference: 0.2517 s/iter. Eval: 0.1254 s/iter. Total: 0.3832 s/iter. ETA=0:04:19
[02/18 07:17:41] mask2former INFO: Inference done 430/1093. Dataloading: 0.0060 s/iter. Inference: 0.2515 s/iter. Eval: 0.1252 s/iter. Total: 0.3828 s/iter. ETA=0:04:13
[02/18 07:17:46] mask2former INFO: Inference done 444/1093. Dataloading: 0.0060 s/iter. Inference: 0.2508 s/iter. Eval: 0.1254 s/iter. Total: 0.3823 s/iter. ETA=0:04:08
[02/18 07:17:51] mask2former INFO: Inference done 458/1093. Dataloading: 0.0060 s/iter. Inference: 0.2505 s/iter. Eval: 0.1252 s/iter. Total: 0.3818 s/iter. ETA=0:04:02
[02/18 07:17:56] mask2former INFO: Inference done 473/1093. Dataloading: 0.0059 s/iter. Inference: 0.2499 s/iter. Eval: 0.1246 s/iter. Total: 0.3806 s/iter. ETA=0:03:55
[02/18 07:18:01] mask2former INFO: Inference done 487/1093. Dataloading: 0.0059 s/iter. Inference: 0.2497 s/iter. Eval: 0.1245 s/iter. Total: 0.3802 s/iter. ETA=0:03:50
[02/18 07:18:06] mask2former INFO: Inference done 501/1093. Dataloading: 0.0059 s/iter. Inference: 0.2494 s/iter. Eval: 0.1242 s/iter. Total: 0.3796 s/iter. ETA=0:03:44
[02/18 07:18:11] mask2former INFO: Inference done 514/1093. Dataloading: 0.0059 s/iter. Inference: 0.2497 s/iter. Eval: 0.1245 s/iter. Total: 0.3803 s/iter. ETA=0:03:40
[02/18 07:18:17] mask2former INFO: Inference done 528/1093. Dataloading: 0.0059 s/iter. Inference: 0.2495 s/iter. Eval: 0.1243 s/iter. Total: 0.3797 s/iter. ETA=0:03:34
[02/18 07:18:22] mask2former INFO: Inference done 542/1093. Dataloading: 0.0059 s/iter. Inference: 0.2496 s/iter. Eval: 0.1240 s/iter. Total: 0.3797 s/iter. ETA=0:03:29
[02/18 07:18:27] mask2former INFO: Inference done 555/1093. Dataloading: 0.0059 s/iter. Inference: 0.2499 s/iter. Eval: 0.1240 s/iter. Total: 0.3799 s/iter. ETA=0:03:24
[02/18 07:18:32] mask2former INFO: Inference done 569/1093. Dataloading: 0.0059 s/iter. Inference: 0.2496 s/iter. Eval: 0.1243 s/iter. Total: 0.3799 s/iter. ETA=0:03:19
[02/18 07:18:37] mask2former INFO: Inference done 584/1093. Dataloading: 0.0059 s/iter. Inference: 0.2493 s/iter. Eval: 0.1238 s/iter. Total: 0.3791 s/iter. ETA=0:03:12
[02/18 07:18:43] mask2former INFO: Inference done 598/1093. Dataloading: 0.0059 s/iter. Inference: 0.2492 s/iter. Eval: 0.1237 s/iter. Total: 0.3789 s/iter. ETA=0:03:07
[02/18 07:18:48] mask2former INFO: Inference done 612/1093. Dataloading: 0.0059 s/iter. Inference: 0.2490 s/iter. Eval: 0.1239 s/iter. Total: 0.3788 s/iter. ETA=0:03:02
[02/18 07:18:53] mask2former INFO: Inference done 627/1093. Dataloading: 0.0059 s/iter. Inference: 0.2483 s/iter. Eval: 0.1239 s/iter. Total: 0.3782 s/iter. ETA=0:02:56
[02/18 07:18:58] mask2former INFO: Inference done 642/1093. Dataloading: 0.0058 s/iter. Inference: 0.2479 s/iter. Eval: 0.1236 s/iter. Total: 0.3775 s/iter. ETA=0:02:50
[02/18 07:19:03] mask2former INFO: Inference done 656/1093. Dataloading: 0.0058 s/iter. Inference: 0.2478 s/iter. Eval: 0.1234 s/iter. Total: 0.3772 s/iter. ETA=0:02:44
[02/18 07:19:09] mask2former INFO: Inference done 671/1093. Dataloading: 0.0058 s/iter. Inference: 0.2476 s/iter. Eval: 0.1231 s/iter. Total: 0.3766 s/iter. ETA=0:02:38
[02/18 07:19:14] mask2former INFO: Inference done 685/1093. Dataloading: 0.0058 s/iter. Inference: 0.2475 s/iter. Eval: 0.1230 s/iter. Total: 0.3764 s/iter. ETA=0:02:33
[02/18 07:19:19] mask2former INFO: Inference done 700/1093. Dataloading: 0.0058 s/iter. Inference: 0.2473 s/iter. Eval: 0.1227 s/iter. Total: 0.3759 s/iter. ETA=0:02:27
[02/18 07:19:25] mask2former INFO: Inference done 715/1093. Dataloading: 0.0058 s/iter. Inference: 0.2472 s/iter. Eval: 0.1225 s/iter. Total: 0.3756 s/iter. ETA=0:02:21
[02/18 07:19:30] mask2former INFO: Inference done 729/1093. Dataloading: 0.0059 s/iter. Inference: 0.2471 s/iter. Eval: 0.1223 s/iter. Total: 0.3754 s/iter. ETA=0:02:16
[02/18 07:19:35] mask2former INFO: Inference done 744/1093. Dataloading: 0.0058 s/iter. Inference: 0.2469 s/iter. Eval: 0.1221 s/iter. Total: 0.3749 s/iter. ETA=0:02:10
[02/18 07:19:40] mask2former INFO: Inference done 758/1093. Dataloading: 0.0059 s/iter. Inference: 0.2471 s/iter. Eval: 0.1216 s/iter. Total: 0.3747 s/iter. ETA=0:02:05
[02/18 07:19:45] mask2former INFO: Inference done 773/1093. Dataloading: 0.0058 s/iter. Inference: 0.2468 s/iter. Eval: 0.1216 s/iter. Total: 0.3743 s/iter. ETA=0:01:59
[02/18 07:19:51] mask2former INFO: Inference done 788/1093. Dataloading: 0.0058 s/iter. Inference: 0.2465 s/iter. Eval: 0.1213 s/iter. Total: 0.3737 s/iter. ETA=0:01:53
[02/18 07:19:56] mask2former INFO: Inference done 802/1093. Dataloading: 0.0058 s/iter. Inference: 0.2467 s/iter. Eval: 0.1212 s/iter. Total: 0.3738 s/iter. ETA=0:01:48
[02/18 07:20:01] mask2former INFO: Inference done 816/1093. Dataloading: 0.0058 s/iter. Inference: 0.2467 s/iter. Eval: 0.1211 s/iter. Total: 0.3737 s/iter. ETA=0:01:43
[02/18 07:20:06] mask2former INFO: Inference done 830/1093. Dataloading: 0.0058 s/iter. Inference: 0.2467 s/iter. Eval: 0.1212 s/iter. Total: 0.3738 s/iter. ETA=0:01:38
[02/18 07:20:12] mask2former INFO: Inference done 844/1093. Dataloading: 0.0058 s/iter. Inference: 0.2467 s/iter. Eval: 0.1212 s/iter. Total: 0.3739 s/iter. ETA=0:01:33
[02/18 07:20:17] mask2former INFO: Inference done 858/1093. Dataloading: 0.0058 s/iter. Inference: 0.2466 s/iter. Eval: 0.1211 s/iter. Total: 0.3736 s/iter. ETA=0:01:27
[02/18 07:20:22] mask2former INFO: Inference done 872/1093. Dataloading: 0.0058 s/iter. Inference: 0.2465 s/iter. Eval: 0.1210 s/iter. Total: 0.3734 s/iter. ETA=0:01:22
[02/18 07:20:27] mask2former INFO: Inference done 887/1093. Dataloading: 0.0058 s/iter. Inference: 0.2464 s/iter. Eval: 0.1208 s/iter. Total: 0.3730 s/iter. ETA=0:01:16
[02/18 07:20:32] mask2former INFO: Inference done 901/1093. Dataloading: 0.0058 s/iter. Inference: 0.2465 s/iter. Eval: 0.1206 s/iter. Total: 0.3730 s/iter. ETA=0:01:11
[02/18 07:20:37] mask2former INFO: Inference done 915/1093. Dataloading: 0.0058 s/iter. Inference: 0.2464 s/iter. Eval: 0.1206 s/iter. Total: 0.3729 s/iter. ETA=0:01:06
[02/18 07:20:43] mask2former INFO: Inference done 930/1093. Dataloading: 0.0058 s/iter. Inference: 0.2463 s/iter. Eval: 0.1204 s/iter. Total: 0.3726 s/iter. ETA=0:01:00
[02/18 07:20:48] mask2former INFO: Inference done 945/1093. Dataloading: 0.0058 s/iter. Inference: 0.2460 s/iter. Eval: 0.1203 s/iter. Total: 0.3722 s/iter. ETA=0:00:55
[02/18 07:20:53] mask2former INFO: Inference done 960/1093. Dataloading: 0.0058 s/iter. Inference: 0.2461 s/iter. Eval: 0.1201 s/iter. Total: 0.3721 s/iter. ETA=0:00:49
[02/18 07:20:58] mask2former INFO: Inference done 975/1093. Dataloading: 0.0058 s/iter. Inference: 0.2457 s/iter. Eval: 0.1200 s/iter. Total: 0.3716 s/iter. ETA=0:00:43
[02/18 07:21:03] mask2former INFO: Inference done 989/1093. Dataloading: 0.0058 s/iter. Inference: 0.2454 s/iter. Eval: 0.1202 s/iter. Total: 0.3714 s/iter. ETA=0:00:38
[02/18 07:21:09] mask2former INFO: Inference done 1003/1093. Dataloading: 0.0058 s/iter. Inference: 0.2454 s/iter. Eval: 0.1201 s/iter. Total: 0.3714 s/iter. ETA=0:00:33
[02/18 07:21:14] mask2former INFO: Inference done 1017/1093. Dataloading: 0.0057 s/iter. Inference: 0.2454 s/iter. Eval: 0.1202 s/iter. Total: 0.3714 s/iter. ETA=0:00:28
[02/18 07:21:19] mask2former INFO: Inference done 1032/1093. Dataloading: 0.0057 s/iter. Inference: 0.2452 s/iter. Eval: 0.1201 s/iter. Total: 0.3712 s/iter. ETA=0:00:22
[02/18 07:21:24] mask2former INFO: Inference done 1047/1093. Dataloading: 0.0057 s/iter. Inference: 0.2451 s/iter. Eval: 0.1199 s/iter. Total: 0.3708 s/iter. ETA=0:00:17
[02/18 07:21:30] mask2former INFO: Inference done 1061/1093. Dataloading: 0.0057 s/iter. Inference: 0.2452 s/iter. Eval: 0.1199 s/iter. Total: 0.3709 s/iter. ETA=0:00:11
[02/18 07:21:35] mask2former INFO: Inference done 1076/1093. Dataloading: 0.0057 s/iter. Inference: 0.2451 s/iter. Eval: 0.1197 s/iter. Total: 0.3706 s/iter. ETA=0:00:06
[02/18 07:21:40] mask2former INFO: Inference done 1092/1093. Dataloading: 0.0057 s/iter. Inference: 0.2447 s/iter. Eval: 0.1195 s/iter. Total: 0.3699 s/iter. ETA=0:00:00
[02/18 07:22:10] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.9235634178069603, 'error_1pix': 0.3995840672499239, 'error_3pix': 0.21457347723413617, 'mIoU': 16.143653966583052, 'fwIoU': 38.756723438978234, 'IoU-1': 92.24730926946873, 'IoU-2': 0.021651020104111525, 'IoU-3': 0.04320984320228148, 'IoU-4': 0.017776270915077694, 'IoU-5': 0.006617038875103391, 'IoU-6': 0.007142393351081098, 'IoU-7': 0.004489466812963425, 'IoU-8': 0.001711834646555055, 'IoU-9': 0.7820738242523921, 'IoU-10': 10.814391340338508, 'IoU-11': 4.679006187284399, 'IoU-12': 32.18049257052124, 'IoU-13': 13.95341992133607, 'IoU-14': 17.11086174965397, 'IoU-15': 20.51837557957179, 'IoU-16': 19.553426185559722, 'IoU-17': 16.66787141802076, 'IoU-18': 16.739700470425255, 'IoU-19': 15.180674313265621, 'IoU-20': 16.505300243110977, 'IoU-21': 16.297729167175692, 'IoU-22': 18.02365273509534, 'IoU-23': 18.90571288211618, 'IoU-24': 20.393883184815614, 'IoU-25': 27.518395478283853, 'IoU-26': 31.698446498113142, 'IoU-27': 23.410801040562347, 'IoU-28': 21.47890729944383, 'IoU-29': 23.40777121726113, 'IoU-30': 26.006787603724003, 'IoU-31': 22.28011259736001, 'IoU-32': 30.479373904250583, 'IoU-33': 7.248741495134463, 'IoU-34': 12.927111907771852, 'IoU-35': 17.88036581274854, 'IoU-36': 34.72060586010075, 'IoU-37': 21.58655729680303, 'IoU-38': 16.92217422252243, 'IoU-39': 10.800321877607866, 'IoU-40': 6.4320742343743245, 'IoU-41': 3.530541294803032, 'IoU-42': 2.798576354484005, 'IoU-43': 20.573208470983122, 'IoU-44': 16.993933318450893, 'IoU-45': 10.667080087884473, 'IoU-46': 11.212239418840246, 'IoU-47': 11.89518823274988, 'IoU-48': 11.769595961809252, 'mACC': 28.129058469220166, 'pACC': 47.873198804117756, 'ACC-1': 95.49820156326702, 'ACC-2': 0.021651090269904465, 'ACC-3': 0.05075390699346543, 'ACC-4': 0.018784178496967164, 'ACC-5': 0.0067653525704662945, 'ACC-6': 0.007247892757543162, 'ACC-7': 0.004549118653752022, 'ACC-8': 0.001728516698088631, 'ACC-9': 52.7393413864795, 'ACC-10': 15.427242020027029, 'ACC-11': 5.336015903258381, 'ACC-12': 81.09006825117531, 'ACC-13': 21.570992992520406, 'ACC-14': 24.387997530980186, 'ACC-15': 32.969106438687604, 'ACC-16': 32.930613986040974, 'ACC-17': 26.837551920769958, 'ACC-18': 25.53786844382156, 'ACC-19': 25.51062600295123, 'ACC-20': 29.075902893916094, 'ACC-21': 28.152792465722886, 'ACC-22': 28.748071412154964, 'ACC-23': 32.4222780617923, 'ACC-24': 36.11058423013993, 'ACC-25': 48.532567332819006, 'ACC-26': 59.13771596428696, 'ACC-27': 39.01541890145033, 'ACC-28': 31.625714453832725, 'ACC-29': 31.31506056915139, 'ACC-30': 35.267542531417, 'ACC-31': 31.587892624595053, 'ACC-32': 80.95310990948776, 'ACC-33': 10.440066205176482, 'ACC-34': 16.236771663749796, 'ACC-35': 23.02708244324561, 'ACC-36': 71.08704560888765, 'ACC-37': 31.58933951083256, 'ACC-38': 22.305048957553254, 'ACC-39': 14.82737247906245, 'ACC-40': 9.693177496335826, 'ACC-41': 6.052313160608193, 'ACC-42': 5.538462191733848, 'ACC-43': 71.45573951341984, 'ACC-44': 36.87993876413004, 'ACC-45': 18.55874013994655, 'ACC-46': 18.628754336326928, 'ACC-47': 20.429141319162262, 'ACC-48': 21.55405488521072})])
[02/18 07:22:10] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 07:22:10] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 07:22:10] d2.evaluation.testing INFO: copypaste: 2.9236,0.3996,0.2146,16.1437,38.7567,28.1291,47.8732
[02/18 07:22:10] d2.utils.events INFO:  eta: 21:11:39  iter: 12499  total_loss: 32.63  loss_ce: 0  loss_mask: 0.844  loss_dice: 2.295  loss_seg: 0.8517  loss_ce_0: 0  loss_mask_0: 0.83  loss_dice_0: 2.399  loss_ce_1: 0  loss_mask_1: 0.8551  loss_dice_1: 2.311  loss_ce_2: 0  loss_mask_2: 0.8569  loss_dice_2: 2.294  loss_ce_3: 0  loss_mask_3: 0.8565  loss_dice_3: 2.277  loss_ce_4: 0  loss_mask_4: 0.8532  loss_dice_4: 2.278  loss_ce_5: 0  loss_mask_5: 0.8527  loss_dice_5: 2.284  loss_ce_6: 0  loss_mask_6: 0.8502  loss_dice_6: 2.276  loss_ce_7: 0  loss_mask_7: 0.8558  loss_dice_7: 2.28  loss_ce_8: 0  loss_mask_8: 0.852  loss_dice_8: 2.277  time: 2.1600  data_time: 0.0258  lr: 8.1039e-05  max_mem: 6003M
[02/18 07:22:44] d2.utils.events INFO:  eta: 21:12:32  iter: 12519  total_loss: 32.99  loss_ce: 0  loss_mask: 0.8695  loss_dice: 2.311  loss_seg: 0.8483  loss_ce_0: 0  loss_mask_0: 0.8656  loss_dice_0: 2.368  loss_ce_1: 0  loss_mask_1: 0.8734  loss_dice_1: 2.315  loss_ce_2: 0  loss_mask_2: 0.8742  loss_dice_2: 2.308  loss_ce_3: 0  loss_mask_3: 0.8767  loss_dice_3: 2.299  loss_ce_4: 0  loss_mask_4: 0.8774  loss_dice_4: 2.298  loss_ce_5: 0  loss_mask_5: 0.8782  loss_dice_5: 2.298  loss_ce_6: 0  loss_mask_6: 0.8775  loss_dice_6: 2.295  loss_ce_7: 0  loss_mask_7: 0.8795  loss_dice_7: 2.3  loss_ce_8: 0  loss_mask_8: 0.8807  loss_dice_8: 2.296  time: 2.1593  data_time: 0.0267  lr: 8.1009e-05  max_mem: 6003M
[02/18 07:23:15] d2.utils.events INFO:  eta: 21:11:54  iter: 12539  total_loss: 33.34  loss_ce: 0  loss_mask: 0.8912  loss_dice: 2.302  loss_seg: 0.8097  loss_ce_0: 0  loss_mask_0: 0.9019  loss_dice_0: 2.354  loss_ce_1: 0  loss_mask_1: 0.898  loss_dice_1: 2.301  loss_ce_2: 0  loss_mask_2: 0.8962  loss_dice_2: 2.299  loss_ce_3: 0  loss_mask_3: 0.8974  loss_dice_3: 2.294  loss_ce_4: 0  loss_mask_4: 0.8973  loss_dice_4: 2.293  loss_ce_5: 0  loss_mask_5: 0.8987  loss_dice_5: 2.288  loss_ce_6: 0  loss_mask_6: 0.8979  loss_dice_6: 2.287  loss_ce_7: 0  loss_mask_7: 0.8948  loss_dice_7: 2.287  loss_ce_8: 0  loss_mask_8: 0.8929  loss_dice_8: 2.287  time: 2.1583  data_time: 0.0283  lr: 8.0978e-05  max_mem: 6003M
[02/18 07:23:49] d2.utils.events INFO:  eta: 21:12:43  iter: 12559  total_loss: 35.12  loss_ce: 0  loss_mask: 0.9327  loss_dice: 2.401  loss_seg: 1.003  loss_ce_0: 0  loss_mask_0: 0.9413  loss_dice_0: 2.468  loss_ce_1: 0  loss_mask_1: 0.9335  loss_dice_1: 2.417  loss_ce_2: 0  loss_mask_2: 0.9329  loss_dice_2: 2.397  loss_ce_3: 0  loss_mask_3: 0.9387  loss_dice_3: 2.373  loss_ce_4: 0  loss_mask_4: 0.9355  loss_dice_4: 2.38  loss_ce_5: 0  loss_mask_5: 0.9358  loss_dice_5: 2.382  loss_ce_6: 0  loss_mask_6: 0.938  loss_dice_6: 2.381  loss_ce_7: 0  loss_mask_7: 0.9387  loss_dice_7: 2.381  loss_ce_8: 0  loss_mask_8: 0.9365  loss_dice_8: 2.385  time: 2.1575  data_time: 0.0292  lr: 8.0947e-05  max_mem: 6003M
[02/18 07:24:23] d2.utils.events INFO:  eta: 21:12:46  iter: 12579  total_loss: 32.7  loss_ce: 0  loss_mask: 0.862  loss_dice: 2.319  loss_seg: 0.7493  loss_ce_0: 0  loss_mask_0: 0.8659  loss_dice_0: 2.389  loss_ce_1: 0  loss_mask_1: 0.8603  loss_dice_1: 2.328  loss_ce_2: 0  loss_mask_2: 0.8595  loss_dice_2: 2.316  loss_ce_3: 0  loss_mask_3: 0.8632  loss_dice_3: 2.307  loss_ce_4: 0  loss_mask_4: 0.8657  loss_dice_4: 2.312  loss_ce_5: 0  loss_mask_5: 0.8635  loss_dice_5: 2.31  loss_ce_6: 0  loss_mask_6: 0.8629  loss_dice_6: 2.303  loss_ce_7: 0  loss_mask_7: 0.859  loss_dice_7: 2.298  loss_ce_8: 0  loss_mask_8: 0.8639  loss_dice_8: 2.302  time: 2.1569  data_time: 0.0316  lr: 8.0917e-05  max_mem: 6003M
[02/18 07:24:56] d2.utils.events INFO:  eta: 21:12:14  iter: 12599  total_loss: 34.19  loss_ce: 0  loss_mask: 0.8685  loss_dice: 2.464  loss_seg: 0.8505  loss_ce_0: 0  loss_mask_0: 0.8637  loss_dice_0: 2.527  loss_ce_1: 0  loss_mask_1: 0.875  loss_dice_1: 2.462  loss_ce_2: 0  loss_mask_2: 0.8769  loss_dice_2: 2.452  loss_ce_3: 0  loss_mask_3: 0.8764  loss_dice_3: 2.451  loss_ce_4: 0  loss_mask_4: 0.8732  loss_dice_4: 2.447  loss_ce_5: 0  loss_mask_5: 0.8684  loss_dice_5: 2.448  loss_ce_6: 0  loss_mask_6: 0.8644  loss_dice_6: 2.45  loss_ce_7: 0  loss_mask_7: 0.8695  loss_dice_7: 2.453  loss_ce_8: 0  loss_mask_8: 0.8689  loss_dice_8: 2.454  time: 2.1561  data_time: 0.0307  lr: 8.0886e-05  max_mem: 6003M
[02/18 07:25:30] d2.utils.events INFO:  eta: 21:13:25  iter: 12619  total_loss: 33.76  loss_ce: 0  loss_mask: 0.8673  loss_dice: 2.418  loss_seg: 1.12  loss_ce_0: 0  loss_mask_0: 0.8804  loss_dice_0: 2.474  loss_ce_1: 0  loss_mask_1: 0.8632  loss_dice_1: 2.425  loss_ce_2: 0  loss_mask_2: 0.8682  loss_dice_2: 2.414  loss_ce_3: 0  loss_mask_3: 0.8648  loss_dice_3: 2.402  loss_ce_4: 0  loss_mask_4: 0.8694  loss_dice_4: 2.393  loss_ce_5: 0  loss_mask_5: 0.8693  loss_dice_5: 2.397  loss_ce_6: 0  loss_mask_6: 0.8708  loss_dice_6: 2.401  loss_ce_7: 0  loss_mask_7: 0.8728  loss_dice_7: 2.403  loss_ce_8: 0  loss_mask_8: 0.8717  loss_dice_8: 2.406  time: 2.1553  data_time: 0.0319  lr: 8.0855e-05  max_mem: 6003M
[02/18 07:26:03] d2.utils.events INFO:  eta: 21:12:28  iter: 12639  total_loss: 33.27  loss_ce: 0  loss_mask: 0.9042  loss_dice: 2.283  loss_seg: 0.7772  loss_ce_0: 0  loss_mask_0: 0.9157  loss_dice_0: 2.341  loss_ce_1: 0  loss_mask_1: 0.9032  loss_dice_1: 2.276  loss_ce_2: 0  loss_mask_2: 0.8998  loss_dice_2: 2.273  loss_ce_3: 0  loss_mask_3: 0.9029  loss_dice_3: 2.259  loss_ce_4: 0  loss_mask_4: 0.9081  loss_dice_4: 2.259  loss_ce_5: 0  loss_mask_5: 0.9076  loss_dice_5: 2.264  loss_ce_6: 0  loss_mask_6: 0.9105  loss_dice_6: 2.26  loss_ce_7: 0  loss_mask_7: 0.9087  loss_dice_7: 2.263  loss_ce_8: 0  loss_mask_8: 0.9101  loss_dice_8: 2.265  time: 2.1545  data_time: 0.0333  lr: 8.0824e-05  max_mem: 6003M
[02/18 07:26:36] d2.utils.events INFO:  eta: 21:12:34  iter: 12659  total_loss: 35.55  loss_ce: 0  loss_mask: 0.9499  loss_dice: 2.464  loss_seg: 0.9803  loss_ce_0: 0  loss_mask_0: 0.9511  loss_dice_0: 2.532  loss_ce_1: 0  loss_mask_1: 0.9455  loss_dice_1: 2.473  loss_ce_2: 0  loss_mask_2: 0.9547  loss_dice_2: 2.465  loss_ce_3: 0  loss_mask_3: 0.9521  loss_dice_3: 2.448  loss_ce_4: 0  loss_mask_4: 0.9528  loss_dice_4: 2.453  loss_ce_5: 0  loss_mask_5: 0.9513  loss_dice_5: 2.455  loss_ce_6: 0  loss_mask_6: 0.9534  loss_dice_6: 2.451  loss_ce_7: 0  loss_mask_7: 0.9558  loss_dice_7: 2.456  loss_ce_8: 0  loss_mask_8: 0.9549  loss_dice_8: 2.457  time: 2.1537  data_time: 0.0384  lr: 8.0794e-05  max_mem: 6003M
[02/18 07:27:10] d2.utils.events INFO:  eta: 21:14:26  iter: 12679  total_loss: 35.51  loss_ce: 0  loss_mask: 0.9668  loss_dice: 2.494  loss_seg: 0.8239  loss_ce_0: 0  loss_mask_0: 0.9845  loss_dice_0: 2.528  loss_ce_1: 0  loss_mask_1: 0.9668  loss_dice_1: 2.514  loss_ce_2: 0  loss_mask_2: 0.9701  loss_dice_2: 2.5  loss_ce_3: 0  loss_mask_3: 0.973  loss_dice_3: 2.484  loss_ce_4: 0  loss_mask_4: 0.976  loss_dice_4: 2.492  loss_ce_5: 0  loss_mask_5: 0.9772  loss_dice_5: 2.492  loss_ce_6: 0  loss_mask_6: 0.9731  loss_dice_6: 2.485  loss_ce_7: 0  loss_mask_7: 0.9782  loss_dice_7: 2.489  loss_ce_8: 0  loss_mask_8: 0.977  loss_dice_8: 2.486  time: 2.1530  data_time: 0.0377  lr: 8.0763e-05  max_mem: 6003M
[02/18 07:27:43] d2.utils.events INFO:  eta: 21:12:58  iter: 12699  total_loss: 31.34  loss_ce: 0  loss_mask: 0.8542  loss_dice: 2.186  loss_seg: 1.092  loss_ce_0: 0  loss_mask_0: 0.8499  loss_dice_0: 2.264  loss_ce_1: 0  loss_mask_1: 0.8655  loss_dice_1: 2.188  loss_ce_2: 0  loss_mask_2: 0.866  loss_dice_2: 2.171  loss_ce_3: 0  loss_mask_3: 0.8672  loss_dice_3: 2.156  loss_ce_4: 0  loss_mask_4: 0.8636  loss_dice_4: 2.163  loss_ce_5: 0  loss_mask_5: 0.8633  loss_dice_5: 2.169  loss_ce_6: 0  loss_mask_6: 0.8601  loss_dice_6: 2.172  loss_ce_7: 0  loss_mask_7: 0.8631  loss_dice_7: 2.171  loss_ce_8: 0  loss_mask_8: 0.8632  loss_dice_8: 2.168  time: 2.1521  data_time: 0.0347  lr: 8.0732e-05  max_mem: 6003M
[02/18 07:28:16] d2.utils.events INFO:  eta: 21:13:22  iter: 12719  total_loss: 32.45  loss_ce: 0  loss_mask: 0.8732  loss_dice: 2.315  loss_seg: 0.6407  loss_ce_0: 0  loss_mask_0: 0.8737  loss_dice_0: 2.348  loss_ce_1: 0  loss_mask_1: 0.8721  loss_dice_1: 2.313  loss_ce_2: 0  loss_mask_2: 0.8763  loss_dice_2: 2.303  loss_ce_3: 0  loss_mask_3: 0.8751  loss_dice_3: 2.29  loss_ce_4: 0  loss_mask_4: 0.8742  loss_dice_4: 2.293  loss_ce_5: 0  loss_mask_5: 0.8778  loss_dice_5: 2.287  loss_ce_6: 0  loss_mask_6: 0.8763  loss_dice_6: 2.292  loss_ce_7: 0  loss_mask_7: 0.8718  loss_dice_7: 2.297  loss_ce_8: 0  loss_mask_8: 0.873  loss_dice_8: 2.298  time: 2.1514  data_time: 0.0401  lr: 8.0702e-05  max_mem: 6003M
[02/18 07:28:49] d2.utils.events INFO:  eta: 21:14:04  iter: 12739  total_loss: 33.75  loss_ce: 0  loss_mask: 0.8922  loss_dice: 2.4  loss_seg: 0.6658  loss_ce_0: 0  loss_mask_0: 0.8966  loss_dice_0: 2.44  loss_ce_1: 0  loss_mask_1: 0.8962  loss_dice_1: 2.39  loss_ce_2: 0  loss_mask_2: 0.8975  loss_dice_2: 2.385  loss_ce_3: 0  loss_mask_3: 0.902  loss_dice_3: 2.379  loss_ce_4: 0  loss_mask_4: 0.9054  loss_dice_4: 2.377  loss_ce_5: 0  loss_mask_5: 0.9007  loss_dice_5: 2.381  loss_ce_6: 0  loss_mask_6: 0.9033  loss_dice_6: 2.379  loss_ce_7: 0  loss_mask_7: 0.902  loss_dice_7: 2.381  loss_ce_8: 0  loss_mask_8: 0.9022  loss_dice_8: 2.385  time: 2.1506  data_time: 0.0438  lr: 8.0671e-05  max_mem: 6003M
[02/18 07:29:20] d2.utils.events INFO:  eta: 21:12:29  iter: 12759  total_loss: 34.01  loss_ce: 0  loss_mask: 0.8654  loss_dice: 2.363  loss_seg: 0.9287  loss_ce_0: 0  loss_mask_0: 0.8626  loss_dice_0: 2.427  loss_ce_1: 0  loss_mask_1: 0.8598  loss_dice_1: 2.372  loss_ce_2: 0  loss_mask_2: 0.866  loss_dice_2: 2.357  loss_ce_3: 0  loss_mask_3: 0.8724  loss_dice_3: 2.347  loss_ce_4: 0  loss_mask_4: 0.8724  loss_dice_4: 2.346  loss_ce_5: 0  loss_mask_5: 0.8698  loss_dice_5: 2.351  loss_ce_6: 0  loss_mask_6: 0.874  loss_dice_6: 2.343  loss_ce_7: 0  loss_mask_7: 0.8725  loss_dice_7: 2.346  loss_ce_8: 0  loss_mask_8: 0.8735  loss_dice_8: 2.35  time: 2.1497  data_time: 0.0388  lr: 8.064e-05  max_mem: 6003M
[02/18 07:29:52] d2.utils.events INFO:  eta: 21:10:21  iter: 12779  total_loss: 33.47  loss_ce: 0  loss_mask: 0.9157  loss_dice: 2.374  loss_seg: 0.762  loss_ce_0: 0  loss_mask_0: 0.9147  loss_dice_0: 2.452  loss_ce_1: 0  loss_mask_1: 0.9217  loss_dice_1: 2.394  loss_ce_2: 0  loss_mask_2: 0.9183  loss_dice_2: 2.379  loss_ce_3: 0  loss_mask_3: 0.9251  loss_dice_3: 2.36  loss_ce_4: 0  loss_mask_4: 0.9258  loss_dice_4: 2.356  loss_ce_5: 0  loss_mask_5: 0.9291  loss_dice_5: 2.353  loss_ce_6: 0  loss_mask_6: 0.9335  loss_dice_6: 2.352  loss_ce_7: 0  loss_mask_7: 0.9315  loss_dice_7: 2.354  loss_ce_8: 0  loss_mask_8: 0.9292  loss_dice_8: 2.359  time: 2.1488  data_time: 0.0246  lr: 8.0609e-05  max_mem: 6003M
[02/18 07:30:26] d2.utils.events INFO:  eta: 21:11:24  iter: 12799  total_loss: 34.39  loss_ce: 0  loss_mask: 0.8873  loss_dice: 2.465  loss_seg: 1.004  loss_ce_0: 0  loss_mask_0: 0.901  loss_dice_0: 2.525  loss_ce_1: 0  loss_mask_1: 0.8886  loss_dice_1: 2.469  loss_ce_2: 0  loss_mask_2: 0.8901  loss_dice_2: 2.461  loss_ce_3: 0  loss_mask_3: 0.894  loss_dice_3: 2.452  loss_ce_4: 0  loss_mask_4: 0.8918  loss_dice_4: 2.449  loss_ce_5: 0  loss_mask_5: 0.8872  loss_dice_5: 2.455  loss_ce_6: 0  loss_mask_6: 0.888  loss_dice_6: 2.452  loss_ce_7: 0  loss_mask_7: 0.8927  loss_dice_7: 2.448  loss_ce_8: 0  loss_mask_8: 0.8933  loss_dice_8: 2.452  time: 2.1481  data_time: 0.0326  lr: 8.0579e-05  max_mem: 6003M
[02/18 07:31:00] d2.utils.events INFO:  eta: 21:11:31  iter: 12819  total_loss: 33.53  loss_ce: 0  loss_mask: 0.9043  loss_dice: 2.369  loss_seg: 0.8902  loss_ce_0: 0  loss_mask_0: 0.8884  loss_dice_0: 2.425  loss_ce_1: 0  loss_mask_1: 0.8959  loss_dice_1: 2.378  loss_ce_2: 0  loss_mask_2: 0.9085  loss_dice_2: 2.357  loss_ce_3: 0  loss_mask_3: 0.9144  loss_dice_3: 2.348  loss_ce_4: 0  loss_mask_4: 0.9125  loss_dice_4: 2.344  loss_ce_5: 0  loss_mask_5: 0.9123  loss_dice_5: 2.345  loss_ce_6: 0  loss_mask_6: 0.912  loss_dice_6: 2.351  loss_ce_7: 0  loss_mask_7: 0.9108  loss_dice_7: 2.351  loss_ce_8: 0  loss_mask_8: 0.9076  loss_dice_8: 2.351  time: 2.1473  data_time: 0.0374  lr: 8.0548e-05  max_mem: 6003M
[02/18 07:31:31] d2.utils.events INFO:  eta: 21:07:37  iter: 12839  total_loss: 33.15  loss_ce: 0  loss_mask: 0.8181  loss_dice: 2.342  loss_seg: 1.125  loss_ce_0: 0  loss_mask_0: 0.7965  loss_dice_0: 2.41  loss_ce_1: 0  loss_mask_1: 0.8219  loss_dice_1: 2.35  loss_ce_2: 0  loss_mask_2: 0.8226  loss_dice_2: 2.336  loss_ce_3: 0  loss_mask_3: 0.8167  loss_dice_3: 2.323  loss_ce_4: 0  loss_mask_4: 0.8172  loss_dice_4: 2.328  loss_ce_5: 0  loss_mask_5: 0.8203  loss_dice_5: 2.329  loss_ce_6: 0  loss_mask_6: 0.8159  loss_dice_6: 2.328  loss_ce_7: 0  loss_mask_7: 0.8165  loss_dice_7: 2.321  loss_ce_8: 0  loss_mask_8: 0.8142  loss_dice_8: 2.327  time: 2.1464  data_time: 0.0340  lr: 8.0517e-05  max_mem: 6003M
[02/18 07:32:06] d2.utils.events INFO:  eta: 21:09:47  iter: 12859  total_loss: 33.81  loss_ce: 0  loss_mask: 0.9062  loss_dice: 2.397  loss_seg: 0.8429  loss_ce_0: 0  loss_mask_0: 0.9169  loss_dice_0: 2.446  loss_ce_1: 0  loss_mask_1: 0.9164  loss_dice_1: 2.405  loss_ce_2: 0  loss_mask_2: 0.9106  loss_dice_2: 2.388  loss_ce_3: 0  loss_mask_3: 0.9093  loss_dice_3: 2.379  loss_ce_4: 0  loss_mask_4: 0.9157  loss_dice_4: 2.381  loss_ce_5: 0  loss_mask_5: 0.9153  loss_dice_5: 2.382  loss_ce_6: 0  loss_mask_6: 0.9149  loss_dice_6: 2.387  loss_ce_7: 0  loss_mask_7: 0.9204  loss_dice_7: 2.387  loss_ce_8: 0  loss_mask_8: 0.9231  loss_dice_8: 2.39  time: 2.1458  data_time: 0.0357  lr: 8.0486e-05  max_mem: 6003M
[02/18 07:32:40] d2.utils.events INFO:  eta: 21:07:29  iter: 12879  total_loss: 33.29  loss_ce: 0  loss_mask: 0.872  loss_dice: 2.351  loss_seg: 0.762  loss_ce_0: 0  loss_mask_0: 0.8772  loss_dice_0: 2.43  loss_ce_1: 0  loss_mask_1: 0.8754  loss_dice_1: 2.36  loss_ce_2: 0  loss_mask_2: 0.8699  loss_dice_2: 2.347  loss_ce_3: 0  loss_mask_3: 0.877  loss_dice_3: 2.34  loss_ce_4: 0  loss_mask_4: 0.8722  loss_dice_4: 2.334  loss_ce_5: 0  loss_mask_5: 0.8713  loss_dice_5: 2.335  loss_ce_6: 0  loss_mask_6: 0.8696  loss_dice_6: 2.338  loss_ce_7: 0  loss_mask_7: 0.8721  loss_dice_7: 2.334  loss_ce_8: 0  loss_mask_8: 0.8757  loss_dice_8: 2.343  time: 2.1451  data_time: 0.0350  lr: 8.0456e-05  max_mem: 6003M
[02/18 07:33:10] d2.utils.events INFO:  eta: 21:05:21  iter: 12899  total_loss: 33.87  loss_ce: 0  loss_mask: 0.8722  loss_dice: 2.36  loss_seg: 0.9682  loss_ce_0: 0  loss_mask_0: 0.8664  loss_dice_0: 2.428  loss_ce_1: 0  loss_mask_1: 0.867  loss_dice_1: 2.359  loss_ce_2: 0  loss_mask_2: 0.8743  loss_dice_2: 2.332  loss_ce_3: 0  loss_mask_3: 0.8823  loss_dice_3: 2.328  loss_ce_4: 0  loss_mask_4: 0.8822  loss_dice_4: 2.337  loss_ce_5: 0  loss_mask_5: 0.8856  loss_dice_5: 2.328  loss_ce_6: 0  loss_mask_6: 0.8851  loss_dice_6: 2.327  loss_ce_7: 0  loss_mask_7: 0.8791  loss_dice_7: 2.335  loss_ce_8: 0  loss_mask_8: 0.8798  loss_dice_8: 2.342  time: 2.1441  data_time: 0.0467  lr: 8.0425e-05  max_mem: 6003M
[02/18 07:33:44] d2.utils.events INFO:  eta: 21:07:31  iter: 12919  total_loss: 33.42  loss_ce: 0  loss_mask: 0.8613  loss_dice: 2.332  loss_seg: 1.18  loss_ce_0: 0  loss_mask_0: 0.8721  loss_dice_0: 2.38  loss_ce_1: 0  loss_mask_1: 0.865  loss_dice_1: 2.33  loss_ce_2: 0  loss_mask_2: 0.8645  loss_dice_2: 2.318  loss_ce_3: 0  loss_mask_3: 0.8639  loss_dice_3: 2.308  loss_ce_4: 0  loss_mask_4: 0.8624  loss_dice_4: 2.312  loss_ce_5: 0  loss_mask_5: 0.8662  loss_dice_5: 2.314  loss_ce_6: 0  loss_mask_6: 0.8577  loss_dice_6: 2.315  loss_ce_7: 0  loss_mask_7: 0.8619  loss_dice_7: 2.314  loss_ce_8: 0  loss_mask_8: 0.8604  loss_dice_8: 2.316  time: 2.1434  data_time: 0.0320  lr: 8.0394e-05  max_mem: 6003M
[02/18 07:34:17] d2.utils.events INFO:  eta: 21:09:45  iter: 12939  total_loss: 33.12  loss_ce: 0  loss_mask: 0.8471  loss_dice: 2.355  loss_seg: 0.9168  loss_ce_0: 0  loss_mask_0: 0.8439  loss_dice_0: 2.407  loss_ce_1: 0  loss_mask_1: 0.8534  loss_dice_1: 2.366  loss_ce_2: 0  loss_mask_2: 0.8559  loss_dice_2: 2.344  loss_ce_3: 0  loss_mask_3: 0.8572  loss_dice_3: 2.33  loss_ce_4: 0  loss_mask_4: 0.8588  loss_dice_4: 2.332  loss_ce_5: 0  loss_mask_5: 0.8546  loss_dice_5: 2.332  loss_ce_6: 0  loss_mask_6: 0.8601  loss_dice_6: 2.327  loss_ce_7: 0  loss_mask_7: 0.8548  loss_dice_7: 2.338  loss_ce_8: 0  loss_mask_8: 0.8536  loss_dice_8: 2.337  time: 2.1426  data_time: 0.0334  lr: 8.0364e-05  max_mem: 6003M
[02/18 07:34:49] d2.utils.events INFO:  eta: 21:08:10  iter: 12959  total_loss: 35.15  loss_ce: 0  loss_mask: 0.8998  loss_dice: 2.461  loss_seg: 1.266  loss_ce_0: 0  loss_mask_0: 0.8944  loss_dice_0: 2.526  loss_ce_1: 0  loss_mask_1: 0.9009  loss_dice_1: 2.469  loss_ce_2: 0  loss_mask_2: 0.9008  loss_dice_2: 2.456  loss_ce_3: 0  loss_mask_3: 0.9033  loss_dice_3: 2.45  loss_ce_4: 0  loss_mask_4: 0.9018  loss_dice_4: 2.452  loss_ce_5: 0  loss_mask_5: 0.9032  loss_dice_5: 2.449  loss_ce_6: 0  loss_mask_6: 0.9026  loss_dice_6: 2.455  loss_ce_7: 0  loss_mask_7: 0.9023  loss_dice_7: 2.45  loss_ce_8: 0  loss_mask_8: 0.9055  loss_dice_8: 2.444  time: 2.1418  data_time: 0.0339  lr: 8.0333e-05  max_mem: 6003M
[02/18 07:35:22] d2.utils.events INFO:  eta: 21:06:50  iter: 12979  total_loss: 32.27  loss_ce: 0  loss_mask: 0.829  loss_dice: 2.36  loss_seg: 1.036  loss_ce_0: 0  loss_mask_0: 0.8524  loss_dice_0: 2.42  loss_ce_1: 0  loss_mask_1: 0.832  loss_dice_1: 2.362  loss_ce_2: 0  loss_mask_2: 0.8331  loss_dice_2: 2.343  loss_ce_3: 0  loss_mask_3: 0.8365  loss_dice_3: 2.333  loss_ce_4: 0  loss_mask_4: 0.8311  loss_dice_4: 2.332  loss_ce_5: 0  loss_mask_5: 0.8312  loss_dice_5: 2.334  loss_ce_6: 0  loss_mask_6: 0.8417  loss_dice_6: 2.333  loss_ce_7: 0  loss_mask_7: 0.8354  loss_dice_7: 2.338  loss_ce_8: 0  loss_mask_8: 0.8372  loss_dice_8: 2.341  time: 2.1410  data_time: 0.0352  lr: 8.0302e-05  max_mem: 6003M
[02/18 07:35:56] d2.utils.events INFO:  eta: 21:05:21  iter: 12999  total_loss: 32.73  loss_ce: 0  loss_mask: 0.89  loss_dice: 2.319  loss_seg: 0.827  loss_ce_0: 0  loss_mask_0: 0.9083  loss_dice_0: 2.388  loss_ce_1: 0  loss_mask_1: 0.8994  loss_dice_1: 2.338  loss_ce_2: 0  loss_mask_2: 0.9004  loss_dice_2: 2.323  loss_ce_3: 0  loss_mask_3: 0.9035  loss_dice_3: 2.303  loss_ce_4: 0  loss_mask_4: 0.9052  loss_dice_4: 2.306  loss_ce_5: 0  loss_mask_5: 0.9029  loss_dice_5: 2.308  loss_ce_6: 0  loss_mask_6: 0.9042  loss_dice_6: 2.298  loss_ce_7: 0  loss_mask_7: 0.903  loss_dice_7: 2.299  loss_ce_8: 0  loss_mask_8: 0.9031  loss_dice_8: 2.306  time: 2.1403  data_time: 0.0374  lr: 8.0271e-05  max_mem: 6003M
[02/18 07:36:27] d2.utils.events INFO:  eta: 21:02:36  iter: 13019  total_loss: 33.58  loss_ce: 0  loss_mask: 0.8836  loss_dice: 2.389  loss_seg: 0.8627  loss_ce_0: 0  loss_mask_0: 0.8793  loss_dice_0: 2.444  loss_ce_1: 0  loss_mask_1: 0.876  loss_dice_1: 2.4  loss_ce_2: 0  loss_mask_2: 0.8852  loss_dice_2: 2.386  loss_ce_3: 0  loss_mask_3: 0.8921  loss_dice_3: 2.376  loss_ce_4: 0  loss_mask_4: 0.8912  loss_dice_4: 2.376  loss_ce_5: 0  loss_mask_5: 0.8942  loss_dice_5: 2.382  loss_ce_6: 0  loss_mask_6: 0.8896  loss_dice_6: 2.38  loss_ce_7: 0  loss_mask_7: 0.8859  loss_dice_7: 2.386  loss_ce_8: 0  loss_mask_8: 0.8853  loss_dice_8: 2.386  time: 2.1394  data_time: 0.0351  lr: 8.0241e-05  max_mem: 6003M
[02/18 07:37:01] d2.utils.events INFO:  eta: 21:03:00  iter: 13039  total_loss: 34.58  loss_ce: 0  loss_mask: 0.9051  loss_dice: 2.389  loss_seg: 1.143  loss_ce_0: 0  loss_mask_0: 0.9132  loss_dice_0: 2.445  loss_ce_1: 0  loss_mask_1: 0.9123  loss_dice_1: 2.396  loss_ce_2: 0  loss_mask_2: 0.9128  loss_dice_2: 2.372  loss_ce_3: 0  loss_mask_3: 0.9059  loss_dice_3: 2.37  loss_ce_4: 0  loss_mask_4: 0.9074  loss_dice_4: 2.372  loss_ce_5: 0  loss_mask_5: 0.9074  loss_dice_5: 2.374  loss_ce_6: 0  loss_mask_6: 0.9118  loss_dice_6: 2.369  loss_ce_7: 0  loss_mask_7: 0.9141  loss_dice_7: 2.367  loss_ce_8: 0  loss_mask_8: 0.9171  loss_dice_8: 2.377  time: 2.1387  data_time: 0.0293  lr: 8.021e-05  max_mem: 6003M
[02/18 07:37:33] d2.utils.events INFO:  eta: 21:01:31  iter: 13059  total_loss: 33.35  loss_ce: 0  loss_mask: 0.854  loss_dice: 2.361  loss_seg: 0.9028  loss_ce_0: 0  loss_mask_0: 0.8857  loss_dice_0: 2.445  loss_ce_1: 0  loss_mask_1: 0.8638  loss_dice_1: 2.371  loss_ce_2: 0  loss_mask_2: 0.8614  loss_dice_2: 2.352  loss_ce_3: 0  loss_mask_3: 0.8642  loss_dice_3: 2.348  loss_ce_4: 0  loss_mask_4: 0.868  loss_dice_4: 2.347  loss_ce_5: 0  loss_mask_5: 0.8646  loss_dice_5: 2.35  loss_ce_6: 0  loss_mask_6: 0.864  loss_dice_6: 2.347  loss_ce_7: 0  loss_mask_7: 0.8633  loss_dice_7: 2.357  loss_ce_8: 0  loss_mask_8: 0.8617  loss_dice_8: 2.354  time: 2.1379  data_time: 0.0304  lr: 8.0179e-05  max_mem: 6003M
[02/18 07:38:05] d2.utils.events INFO:  eta: 20:59:21  iter: 13079  total_loss: 33.32  loss_ce: 0  loss_mask: 0.9157  loss_dice: 2.371  loss_seg: 0.7396  loss_ce_0: 0  loss_mask_0: 0.9181  loss_dice_0: 2.428  loss_ce_1: 0  loss_mask_1: 0.9227  loss_dice_1: 2.375  loss_ce_2: 0  loss_mask_2: 0.9214  loss_dice_2: 2.366  loss_ce_3: 0  loss_mask_3: 0.9275  loss_dice_3: 2.363  loss_ce_4: 0  loss_mask_4: 0.9259  loss_dice_4: 2.361  loss_ce_5: 0  loss_mask_5: 0.926  loss_dice_5: 2.356  loss_ce_6: 0  loss_mask_6: 0.9312  loss_dice_6: 2.359  loss_ce_7: 0  loss_mask_7: 0.9217  loss_dice_7: 2.36  loss_ce_8: 0  loss_mask_8: 0.9251  loss_dice_8: 2.362  time: 2.1371  data_time: 0.0307  lr: 8.0148e-05  max_mem: 6003M
[02/18 07:38:39] d2.utils.events INFO:  eta: 21:03:58  iter: 13099  total_loss: 32.07  loss_ce: 0  loss_mask: 0.8872  loss_dice: 2.262  loss_seg: 0.8084  loss_ce_0: 0  loss_mask_0: 0.8803  loss_dice_0: 2.344  loss_ce_1: 0  loss_mask_1: 0.8821  loss_dice_1: 2.263  loss_ce_2: 0  loss_mask_2: 0.8911  loss_dice_2: 2.25  loss_ce_3: 0  loss_mask_3: 0.8914  loss_dice_3: 2.243  loss_ce_4: 0  loss_mask_4: 0.8915  loss_dice_4: 2.247  loss_ce_5: 0  loss_mask_5: 0.8868  loss_dice_5: 2.251  loss_ce_6: 0  loss_mask_6: 0.8872  loss_dice_6: 2.246  loss_ce_7: 0  loss_mask_7: 0.8886  loss_dice_7: 2.247  loss_ce_8: 0  loss_mask_8: 0.8902  loss_dice_8: 2.253  time: 2.1364  data_time: 0.0359  lr: 8.0118e-05  max_mem: 6003M
[02/18 07:39:10] d2.utils.events INFO:  eta: 20:59:26  iter: 13119  total_loss: 33.62  loss_ce: 0  loss_mask: 0.9106  loss_dice: 2.335  loss_seg: 0.7433  loss_ce_0: 0  loss_mask_0: 0.9309  loss_dice_0: 2.373  loss_ce_1: 0  loss_mask_1: 0.9213  loss_dice_1: 2.341  loss_ce_2: 0  loss_mask_2: 0.9185  loss_dice_2: 2.325  loss_ce_3: 0  loss_mask_3: 0.924  loss_dice_3: 2.314  loss_ce_4: 0  loss_mask_4: 0.9279  loss_dice_4: 2.316  loss_ce_5: 0  loss_mask_5: 0.9215  loss_dice_5: 2.316  loss_ce_6: 0  loss_mask_6: 0.9239  loss_dice_6: 2.317  loss_ce_7: 0  loss_mask_7: 0.9289  loss_dice_7: 2.321  loss_ce_8: 0  loss_mask_8: 0.9231  loss_dice_8: 2.328  time: 2.1355  data_time: 0.0300  lr: 8.0087e-05  max_mem: 6003M
[02/18 07:39:44] d2.utils.events INFO:  eta: 21:02:53  iter: 13139  total_loss: 33.64  loss_ce: 0  loss_mask: 0.9109  loss_dice: 2.36  loss_seg: 0.8127  loss_ce_0: 0  loss_mask_0: 0.9194  loss_dice_0: 2.402  loss_ce_1: 0  loss_mask_1: 0.9169  loss_dice_1: 2.366  loss_ce_2: 0  loss_mask_2: 0.9199  loss_dice_2: 2.353  loss_ce_3: 0  loss_mask_3: 0.9166  loss_dice_3: 2.349  loss_ce_4: 0  loss_mask_4: 0.9146  loss_dice_4: 2.346  loss_ce_5: 0  loss_mask_5: 0.9133  loss_dice_5: 2.346  loss_ce_6: 0  loss_mask_6: 0.916  loss_dice_6: 2.352  loss_ce_7: 0  loss_mask_7: 0.9142  loss_dice_7: 2.347  loss_ce_8: 0  loss_mask_8: 0.9154  loss_dice_8: 2.355  time: 2.1349  data_time: 0.0284  lr: 8.0056e-05  max_mem: 6003M
[02/18 07:40:17] d2.utils.events INFO:  eta: 21:00:25  iter: 13159  total_loss: 33.47  loss_ce: 0  loss_mask: 0.8615  loss_dice: 2.312  loss_seg: 0.8576  loss_ce_0: 0  loss_mask_0: 0.8631  loss_dice_0: 2.43  loss_ce_1: 0  loss_mask_1: 0.8552  loss_dice_1: 2.326  loss_ce_2: 0  loss_mask_2: 0.8633  loss_dice_2: 2.307  loss_ce_3: 0  loss_mask_3: 0.8655  loss_dice_3: 2.295  loss_ce_4: 0  loss_mask_4: 0.864  loss_dice_4: 2.301  loss_ce_5: 0  loss_mask_5: 0.8631  loss_dice_5: 2.306  loss_ce_6: 0  loss_mask_6: 0.8717  loss_dice_6: 2.293  loss_ce_7: 0  loss_mask_7: 0.8686  loss_dice_7: 2.298  loss_ce_8: 0  loss_mask_8: 0.868  loss_dice_8: 2.305  time: 2.1341  data_time: 0.0343  lr: 8.0025e-05  max_mem: 6003M
[02/18 07:40:50] d2.utils.events INFO:  eta: 21:01:16  iter: 13179  total_loss: 34.83  loss_ce: 0  loss_mask: 0.865  loss_dice: 2.455  loss_seg: 1.061  loss_ce_0: 0  loss_mask_0: 0.8773  loss_dice_0: 2.527  loss_ce_1: 0  loss_mask_1: 0.8734  loss_dice_1: 2.467  loss_ce_2: 0  loss_mask_2: 0.8686  loss_dice_2: 2.44  loss_ce_3: 0  loss_mask_3: 0.8723  loss_dice_3: 2.437  loss_ce_4: 0  loss_mask_4: 0.8656  loss_dice_4: 2.436  loss_ce_5: 0  loss_mask_5: 0.8656  loss_dice_5: 2.443  loss_ce_6: 0  loss_mask_6: 0.8644  loss_dice_6: 2.439  loss_ce_7: 0  loss_mask_7: 0.8692  loss_dice_7: 2.442  loss_ce_8: 0  loss_mask_8: 0.8698  loss_dice_8: 2.438  time: 2.1334  data_time: 0.0290  lr: 7.9995e-05  max_mem: 6003M
[02/18 07:41:23] d2.utils.events INFO:  eta: 21:02:44  iter: 13199  total_loss: 34.4  loss_ce: 0  loss_mask: 0.8703  loss_dice: 2.4  loss_seg: 0.744  loss_ce_0: 0  loss_mask_0: 0.8729  loss_dice_0: 2.469  loss_ce_1: 0  loss_mask_1: 0.8707  loss_dice_1: 2.418  loss_ce_2: 0  loss_mask_2: 0.8734  loss_dice_2: 2.404  loss_ce_3: 0  loss_mask_3: 0.8765  loss_dice_3: 2.388  loss_ce_4: 0  loss_mask_4: 0.878  loss_dice_4: 2.381  loss_ce_5: 0  loss_mask_5: 0.8803  loss_dice_5: 2.376  loss_ce_6: 0  loss_mask_6: 0.8775  loss_dice_6: 2.379  loss_ce_7: 0  loss_mask_7: 0.8762  loss_dice_7: 2.386  loss_ce_8: 0  loss_mask_8: 0.8774  loss_dice_8: 2.386  time: 2.1326  data_time: 0.0309  lr: 7.9964e-05  max_mem: 6003M
[02/18 07:41:56] d2.utils.events INFO:  eta: 21:04:35  iter: 13219  total_loss: 33.17  loss_ce: 0  loss_mask: 0.9078  loss_dice: 2.338  loss_seg: 0.794  loss_ce_0: 0  loss_mask_0: 0.9096  loss_dice_0: 2.391  loss_ce_1: 0  loss_mask_1: 0.9073  loss_dice_1: 2.339  loss_ce_2: 0  loss_mask_2: 0.9105  loss_dice_2: 2.33  loss_ce_3: 0  loss_mask_3: 0.9052  loss_dice_3: 2.327  loss_ce_4: 0  loss_mask_4: 0.9072  loss_dice_4: 2.323  loss_ce_5: 0  loss_mask_5: 0.9061  loss_dice_5: 2.322  loss_ce_6: 0  loss_mask_6: 0.9072  loss_dice_6: 2.328  loss_ce_7: 0  loss_mask_7: 0.9045  loss_dice_7: 2.328  loss_ce_8: 0  loss_mask_8: 0.9075  loss_dice_8: 2.332  time: 2.1319  data_time: 0.0351  lr: 7.9933e-05  max_mem: 6003M
[02/18 07:42:30] d2.utils.events INFO:  eta: 21:04:02  iter: 13239  total_loss: 33.15  loss_ce: 0  loss_mask: 0.8844  loss_dice: 2.352  loss_seg: 0.9527  loss_ce_0: 0  loss_mask_0: 0.8872  loss_dice_0: 2.396  loss_ce_1: 0  loss_mask_1: 0.8928  loss_dice_1: 2.355  loss_ce_2: 0  loss_mask_2: 0.894  loss_dice_2: 2.342  loss_ce_3: 0  loss_mask_3: 0.8896  loss_dice_3: 2.333  loss_ce_4: 0  loss_mask_4: 0.8866  loss_dice_4: 2.337  loss_ce_5: 0  loss_mask_5: 0.8896  loss_dice_5: 2.335  loss_ce_6: 0  loss_mask_6: 0.8896  loss_dice_6: 2.333  loss_ce_7: 0  loss_mask_7: 0.8909  loss_dice_7: 2.336  loss_ce_8: 0  loss_mask_8: 0.8858  loss_dice_8: 2.34  time: 2.1312  data_time: 0.0262  lr: 7.9902e-05  max_mem: 6003M
[02/18 07:43:02] d2.utils.events INFO:  eta: 21:02:46  iter: 13259  total_loss: 34.41  loss_ce: 0  loss_mask: 0.8541  loss_dice: 2.439  loss_seg: 1.05  loss_ce_0: 0  loss_mask_0: 0.8709  loss_dice_0: 2.501  loss_ce_1: 0  loss_mask_1: 0.8581  loss_dice_1: 2.439  loss_ce_2: 0  loss_mask_2: 0.8533  loss_dice_2: 2.43  loss_ce_3: 0  loss_mask_3: 0.8525  loss_dice_3: 2.419  loss_ce_4: 0  loss_mask_4: 0.8528  loss_dice_4: 2.425  loss_ce_5: 0  loss_mask_5: 0.8525  loss_dice_5: 2.428  loss_ce_6: 0  loss_mask_6: 0.8543  loss_dice_6: 2.429  loss_ce_7: 0  loss_mask_7: 0.8591  loss_dice_7: 2.431  loss_ce_8: 0  loss_mask_8: 0.8612  loss_dice_8: 2.422  time: 2.1304  data_time: 0.0302  lr: 7.9872e-05  max_mem: 6003M
[02/18 07:43:34] d2.utils.events INFO:  eta: 21:01:15  iter: 13279  total_loss: 35.37  loss_ce: 0  loss_mask: 0.9002  loss_dice: 2.527  loss_seg: 1.228  loss_ce_0: 0  loss_mask_0: 0.9046  loss_dice_0: 2.582  loss_ce_1: 0  loss_mask_1: 0.9034  loss_dice_1: 2.544  loss_ce_2: 0  loss_mask_2: 0.906  loss_dice_2: 2.529  loss_ce_3: 0  loss_mask_3: 0.9072  loss_dice_3: 2.519  loss_ce_4: 0  loss_mask_4: 0.9061  loss_dice_4: 2.517  loss_ce_5: 0  loss_mask_5: 0.9032  loss_dice_5: 2.524  loss_ce_6: 0  loss_mask_6: 0.9058  loss_dice_6: 2.517  loss_ce_7: 0  loss_mask_7: 0.9084  loss_dice_7: 2.523  loss_ce_8: 0  loss_mask_8: 0.906  loss_dice_8: 2.518  time: 2.1296  data_time: 0.0315  lr: 7.9841e-05  max_mem: 6003M
[02/18 07:44:07] d2.utils.events INFO:  eta: 21:00:43  iter: 13299  total_loss: 34.02  loss_ce: 0  loss_mask: 0.8848  loss_dice: 2.424  loss_seg: 0.7902  loss_ce_0: 0  loss_mask_0: 0.8912  loss_dice_0: 2.492  loss_ce_1: 0  loss_mask_1: 0.8934  loss_dice_1: 2.428  loss_ce_2: 0  loss_mask_2: 0.8885  loss_dice_2: 2.417  loss_ce_3: 0  loss_mask_3: 0.888  loss_dice_3: 2.41  loss_ce_4: 0  loss_mask_4: 0.8913  loss_dice_4: 2.416  loss_ce_5: 0  loss_mask_5: 0.8901  loss_dice_5: 2.413  loss_ce_6: 0  loss_mask_6: 0.8908  loss_dice_6: 2.406  loss_ce_7: 0  loss_mask_7: 0.8877  loss_dice_7: 2.415  loss_ce_8: 0  loss_mask_8: 0.8855  loss_dice_8: 2.412  time: 2.1288  data_time: 0.0327  lr: 7.981e-05  max_mem: 6003M
[02/18 07:44:38] d2.utils.events INFO:  eta: 20:58:50  iter: 13319  total_loss: 32.38  loss_ce: 0  loss_mask: 0.8656  loss_dice: 2.26  loss_seg: 0.8969  loss_ce_0: 0  loss_mask_0: 0.8721  loss_dice_0: 2.321  loss_ce_1: 0  loss_mask_1: 0.8678  loss_dice_1: 2.245  loss_ce_2: 0  loss_mask_2: 0.8674  loss_dice_2: 2.244  loss_ce_3: 0  loss_mask_3: 0.8698  loss_dice_3: 2.239  loss_ce_4: 0  loss_mask_4: 0.872  loss_dice_4: 2.245  loss_ce_5: 0  loss_mask_5: 0.8702  loss_dice_5: 2.247  loss_ce_6: 0  loss_mask_6: 0.8709  loss_dice_6: 2.25  loss_ce_7: 0  loss_mask_7: 0.8662  loss_dice_7: 2.251  loss_ce_8: 0  loss_mask_8: 0.8705  loss_dice_8: 2.247  time: 2.1280  data_time: 0.0251  lr: 7.9779e-05  max_mem: 6003M
[02/18 07:45:11] d2.utils.events INFO:  eta: 20:56:58  iter: 13339  total_loss: 33.76  loss_ce: 0  loss_mask: 0.866  loss_dice: 2.361  loss_seg: 0.871  loss_ce_0: 0  loss_mask_0: 0.8752  loss_dice_0: 2.407  loss_ce_1: 0  loss_mask_1: 0.8703  loss_dice_1: 2.36  loss_ce_2: 0  loss_mask_2: 0.8729  loss_dice_2: 2.353  loss_ce_3: 0  loss_mask_3: 0.8722  loss_dice_3: 2.351  loss_ce_4: 0  loss_mask_4: 0.8738  loss_dice_4: 2.346  loss_ce_5: 0  loss_mask_5: 0.8769  loss_dice_5: 2.348  loss_ce_6: 0  loss_mask_6: 0.8779  loss_dice_6: 2.349  loss_ce_7: 0  loss_mask_7: 0.8784  loss_dice_7: 2.347  loss_ce_8: 0  loss_mask_8: 0.8757  loss_dice_8: 2.346  time: 2.1273  data_time: 0.0275  lr: 7.9748e-05  max_mem: 6003M
[02/18 07:45:44] d2.utils.events INFO:  eta: 20:56:52  iter: 13359  total_loss: 32.87  loss_ce: 0  loss_mask: 0.8512  loss_dice: 2.286  loss_seg: 1.11  loss_ce_0: 0  loss_mask_0: 0.8478  loss_dice_0: 2.37  loss_ce_1: 0  loss_mask_1: 0.85  loss_dice_1: 2.302  loss_ce_2: 0  loss_mask_2: 0.8565  loss_dice_2: 2.283  loss_ce_3: 0  loss_mask_3: 0.86  loss_dice_3: 2.27  loss_ce_4: 0  loss_mask_4: 0.8615  loss_dice_4: 2.275  loss_ce_5: 0  loss_mask_5: 0.86  loss_dice_5: 2.275  loss_ce_6: 0  loss_mask_6: 0.8586  loss_dice_6: 2.272  loss_ce_7: 0  loss_mask_7: 0.8555  loss_dice_7: 2.28  loss_ce_8: 0  loss_mask_8: 0.8548  loss_dice_8: 2.279  time: 2.1265  data_time: 0.0295  lr: 7.9718e-05  max_mem: 6003M
[02/18 07:46:14] d2.utils.events INFO:  eta: 20:54:15  iter: 13379  total_loss: 34.56  loss_ce: 0  loss_mask: 0.8428  loss_dice: 2.48  loss_seg: 0.8035  loss_ce_0: 0  loss_mask_0: 0.8543  loss_dice_0: 2.532  loss_ce_1: 0  loss_mask_1: 0.8456  loss_dice_1: 2.492  loss_ce_2: 0  loss_mask_2: 0.843  loss_dice_2: 2.48  loss_ce_3: 0  loss_mask_3: 0.8461  loss_dice_3: 2.473  loss_ce_4: 0  loss_mask_4: 0.846  loss_dice_4: 2.472  loss_ce_5: 0  loss_mask_5: 0.8433  loss_dice_5: 2.47  loss_ce_6: 0  loss_mask_6: 0.8476  loss_dice_6: 2.464  loss_ce_7: 0  loss_mask_7: 0.8498  loss_dice_7: 2.47  loss_ce_8: 0  loss_mask_8: 0.8496  loss_dice_8: 2.469  time: 2.1257  data_time: 0.0391  lr: 7.9687e-05  max_mem: 6003M
[02/18 07:46:44] d2.utils.events INFO:  eta: 20:51:55  iter: 13399  total_loss: 33.89  loss_ce: 0  loss_mask: 0.8738  loss_dice: 2.365  loss_seg: 0.991  loss_ce_0: 0  loss_mask_0: 0.8773  loss_dice_0: 2.429  loss_ce_1: 0  loss_mask_1: 0.8779  loss_dice_1: 2.377  loss_ce_2: 0  loss_mask_2: 0.8822  loss_dice_2: 2.375  loss_ce_3: 0  loss_mask_3: 0.8886  loss_dice_3: 2.356  loss_ce_4: 0  loss_mask_4: 0.8884  loss_dice_4: 2.361  loss_ce_5: 0  loss_mask_5: 0.8919  loss_dice_5: 2.363  loss_ce_6: 0  loss_mask_6: 0.8883  loss_dice_6: 2.354  loss_ce_7: 0  loss_mask_7: 0.8825  loss_dice_7: 2.362  loss_ce_8: 0  loss_mask_8: 0.8857  loss_dice_8: 2.364  time: 2.1247  data_time: 0.0337  lr: 7.9656e-05  max_mem: 6003M
[02/18 07:47:17] d2.utils.events INFO:  eta: 20:49:44  iter: 13419  total_loss: 33.98  loss_ce: 0  loss_mask: 0.9032  loss_dice: 2.386  loss_seg: 0.7257  loss_ce_0: 0  loss_mask_0: 0.9103  loss_dice_0: 2.454  loss_ce_1: 0  loss_mask_1: 0.9077  loss_dice_1: 2.39  loss_ce_2: 0  loss_mask_2: 0.9055  loss_dice_2: 2.374  loss_ce_3: 0  loss_mask_3: 0.901  loss_dice_3: 2.38  loss_ce_4: 0  loss_mask_4: 0.9004  loss_dice_4: 2.38  loss_ce_5: 0  loss_mask_5: 0.8985  loss_dice_5: 2.383  loss_ce_6: 0  loss_mask_6: 0.8991  loss_dice_6: 2.382  loss_ce_7: 0  loss_mask_7: 0.9042  loss_dice_7: 2.385  loss_ce_8: 0  loss_mask_8: 0.9007  loss_dice_8: 2.377  time: 2.1239  data_time: 0.0258  lr: 7.9625e-05  max_mem: 6003M
[02/18 07:47:49] d2.utils.events INFO:  eta: 20:49:59  iter: 13439  total_loss: 35.68  loss_ce: 0  loss_mask: 0.8695  loss_dice: 2.525  loss_seg: 0.9622  loss_ce_0: 0  loss_mask_0: 0.8874  loss_dice_0: 2.552  loss_ce_1: 0  loss_mask_1: 0.8744  loss_dice_1: 2.529  loss_ce_2: 0  loss_mask_2: 0.877  loss_dice_2: 2.513  loss_ce_3: 0  loss_mask_3: 0.881  loss_dice_3: 2.513  loss_ce_4: 0  loss_mask_4: 0.877  loss_dice_4: 2.512  loss_ce_5: 0  loss_mask_5: 0.875  loss_dice_5: 2.514  loss_ce_6: 0  loss_mask_6: 0.8804  loss_dice_6: 2.513  loss_ce_7: 0  loss_mask_7: 0.8806  loss_dice_7: 2.513  loss_ce_8: 0  loss_mask_8: 0.8757  loss_dice_8: 2.513  time: 2.1232  data_time: 0.0272  lr: 7.9595e-05  max_mem: 6003M
[02/18 07:48:23] d2.utils.events INFO:  eta: 20:50:18  iter: 13459  total_loss: 33.25  loss_ce: 0  loss_mask: 0.8635  loss_dice: 2.378  loss_seg: 0.7175  loss_ce_0: 0  loss_mask_0: 0.8735  loss_dice_0: 2.427  loss_ce_1: 0  loss_mask_1: 0.869  loss_dice_1: 2.368  loss_ce_2: 0  loss_mask_2: 0.8674  loss_dice_2: 2.363  loss_ce_3: 0  loss_mask_3: 0.862  loss_dice_3: 2.362  loss_ce_4: 0  loss_mask_4: 0.8655  loss_dice_4: 2.364  loss_ce_5: 0  loss_mask_5: 0.8628  loss_dice_5: 2.366  loss_ce_6: 0  loss_mask_6: 0.8672  loss_dice_6: 2.368  loss_ce_7: 0  loss_mask_7: 0.8626  loss_dice_7: 2.363  loss_ce_8: 0  loss_mask_8: 0.8638  loss_dice_8: 2.368  time: 2.1226  data_time: 0.0229  lr: 7.9564e-05  max_mem: 6003M
[02/18 07:48:57] d2.utils.events INFO:  eta: 20:51:19  iter: 13479  total_loss: 34.11  loss_ce: 0  loss_mask: 0.897  loss_dice: 2.382  loss_seg: 0.8218  loss_ce_0: 0  loss_mask_0: 0.9142  loss_dice_0: 2.448  loss_ce_1: 0  loss_mask_1: 0.8992  loss_dice_1: 2.394  loss_ce_2: 0  loss_mask_2: 0.9011  loss_dice_2: 2.382  loss_ce_3: 0  loss_mask_3: 0.9075  loss_dice_3: 2.378  loss_ce_4: 0  loss_mask_4: 0.9082  loss_dice_4: 2.369  loss_ce_5: 0  loss_mask_5: 0.9092  loss_dice_5: 2.369  loss_ce_6: 0  loss_mask_6: 0.9139  loss_dice_6: 2.367  loss_ce_7: 0  loss_mask_7: 0.9088  loss_dice_7: 2.366  loss_ce_8: 0  loss_mask_8: 0.9071  loss_dice_8: 2.37  time: 2.1219  data_time: 0.0300  lr: 7.9533e-05  max_mem: 6003M
[02/18 07:49:29] d2.utils.events INFO:  eta: 20:51:28  iter: 13499  total_loss: 32.89  loss_ce: 0  loss_mask: 0.8785  loss_dice: 2.282  loss_seg: 0.605  loss_ce_0: 0  loss_mask_0: 0.8827  loss_dice_0: 2.352  loss_ce_1: 0  loss_mask_1: 0.89  loss_dice_1: 2.307  loss_ce_2: 0  loss_mask_2: 0.8901  loss_dice_2: 2.286  loss_ce_3: 0  loss_mask_3: 0.8907  loss_dice_3: 2.263  loss_ce_4: 0  loss_mask_4: 0.8966  loss_dice_4: 2.273  loss_ce_5: 0  loss_mask_5: 0.8913  loss_dice_5: 2.273  loss_ce_6: 0  loss_mask_6: 0.8926  loss_dice_6: 2.267  loss_ce_7: 0  loss_mask_7: 0.8952  loss_dice_7: 2.272  loss_ce_8: 0  loss_mask_8: 0.8889  loss_dice_8: 2.272  time: 2.1211  data_time: 0.0299  lr: 7.9502e-05  max_mem: 6003M
[02/18 07:50:01] d2.utils.events INFO:  eta: 20:50:56  iter: 13519  total_loss: 32.96  loss_ce: 0  loss_mask: 0.8926  loss_dice: 2.382  loss_seg: 0.9062  loss_ce_0: 0  loss_mask_0: 0.8786  loss_dice_0: 2.44  loss_ce_1: 0  loss_mask_1: 0.8897  loss_dice_1: 2.386  loss_ce_2: 0  loss_mask_2: 0.8856  loss_dice_2: 2.379  loss_ce_3: 0  loss_mask_3: 0.8878  loss_dice_3: 2.372  loss_ce_4: 0  loss_mask_4: 0.8915  loss_dice_4: 2.372  loss_ce_5: 0  loss_mask_5: 0.8898  loss_dice_5: 2.368  loss_ce_6: 0  loss_mask_6: 0.8953  loss_dice_6: 2.363  loss_ce_7: 0  loss_mask_7: 0.8965  loss_dice_7: 2.363  loss_ce_8: 0  loss_mask_8: 0.8937  loss_dice_8: 2.367  time: 2.1203  data_time: 0.0263  lr: 7.9472e-05  max_mem: 6003M
[02/18 07:50:33] d2.utils.events INFO:  eta: 20:50:23  iter: 13539  total_loss: 34.14  loss_ce: 0  loss_mask: 0.8776  loss_dice: 2.393  loss_seg: 0.945  loss_ce_0: 0  loss_mask_0: 0.8874  loss_dice_0: 2.463  loss_ce_1: 0  loss_mask_1: 0.8858  loss_dice_1: 2.406  loss_ce_2: 0  loss_mask_2: 0.8843  loss_dice_2: 2.392  loss_ce_3: 0  loss_mask_3: 0.889  loss_dice_3: 2.364  loss_ce_4: 0  loss_mask_4: 0.8861  loss_dice_4: 2.373  loss_ce_5: 0  loss_mask_5: 0.8788  loss_dice_5: 2.367  loss_ce_6: 0  loss_mask_6: 0.8831  loss_dice_6: 2.371  loss_ce_7: 0  loss_mask_7: 0.8841  loss_dice_7: 2.371  loss_ce_8: 0  loss_mask_8: 0.8798  loss_dice_8: 2.374  time: 2.1196  data_time: 0.0289  lr: 7.9441e-05  max_mem: 6003M
[02/18 07:51:06] d2.utils.events INFO:  eta: 20:48:37  iter: 13559  total_loss: 33.87  loss_ce: 0  loss_mask: 0.8895  loss_dice: 2.366  loss_seg: 1.031  loss_ce_0: 0  loss_mask_0: 0.8843  loss_dice_0: 2.431  loss_ce_1: 0  loss_mask_1: 0.8893  loss_dice_1: 2.377  loss_ce_2: 0  loss_mask_2: 0.8892  loss_dice_2: 2.364  loss_ce_3: 0  loss_mask_3: 0.8926  loss_dice_3: 2.355  loss_ce_4: 0  loss_mask_4: 0.8913  loss_dice_4: 2.356  loss_ce_5: 0  loss_mask_5: 0.895  loss_dice_5: 2.357  loss_ce_6: 0  loss_mask_6: 0.8922  loss_dice_6: 2.35  loss_ce_7: 0  loss_mask_7: 0.8972  loss_dice_7: 2.355  loss_ce_8: 0  loss_mask_8: 0.8938  loss_dice_8: 2.357  time: 2.1189  data_time: 0.0318  lr: 7.941e-05  max_mem: 6003M
[02/18 07:51:36] d2.utils.events INFO:  eta: 20:45:27  iter: 13579  total_loss: 33.15  loss_ce: 0  loss_mask: 0.856  loss_dice: 2.319  loss_seg: 0.833  loss_ce_0: 0  loss_mask_0: 0.866  loss_dice_0: 2.386  loss_ce_1: 0  loss_mask_1: 0.857  loss_dice_1: 2.327  loss_ce_2: 0  loss_mask_2: 0.8537  loss_dice_2: 2.315  loss_ce_3: 0  loss_mask_3: 0.859  loss_dice_3: 2.307  loss_ce_4: 0  loss_mask_4: 0.8662  loss_dice_4: 2.307  loss_ce_5: 0  loss_mask_5: 0.8605  loss_dice_5: 2.307  loss_ce_6: 0  loss_mask_6: 0.8677  loss_dice_6: 2.307  loss_ce_7: 0  loss_mask_7: 0.8662  loss_dice_7: 2.304  loss_ce_8: 0  loss_mask_8: 0.8623  loss_dice_8: 2.309  time: 2.1180  data_time: 0.0475  lr: 7.9379e-05  max_mem: 6003M
[02/18 07:52:08] d2.utils.events INFO:  eta: 20:44:41  iter: 13599  total_loss: 33.29  loss_ce: 0  loss_mask: 0.8745  loss_dice: 2.331  loss_seg: 0.7949  loss_ce_0: 0  loss_mask_0: 0.9007  loss_dice_0: 2.374  loss_ce_1: 0  loss_mask_1: 0.8886  loss_dice_1: 2.332  loss_ce_2: 0  loss_mask_2: 0.8859  loss_dice_2: 2.316  loss_ce_3: 0  loss_mask_3: 0.8875  loss_dice_3: 2.306  loss_ce_4: 0  loss_mask_4: 0.8858  loss_dice_4: 2.313  loss_ce_5: 0  loss_mask_5: 0.8851  loss_dice_5: 2.324  loss_ce_6: 0  loss_mask_6: 0.8863  loss_dice_6: 2.311  loss_ce_7: 0  loss_mask_7: 0.8844  loss_dice_7: 2.31  loss_ce_8: 0  loss_mask_8: 0.887  loss_dice_8: 2.316  time: 2.1172  data_time: 0.0267  lr: 7.9348e-05  max_mem: 6003M
[02/18 07:52:42] d2.utils.events INFO:  eta: 20:41:14  iter: 13619  total_loss: 35.15  loss_ce: 0  loss_mask: 0.8991  loss_dice: 2.437  loss_seg: 0.8307  loss_ce_0: 0  loss_mask_0: 0.9157  loss_dice_0: 2.501  loss_ce_1: 0  loss_mask_1: 0.9095  loss_dice_1: 2.454  loss_ce_2: 0  loss_mask_2: 0.9014  loss_dice_2: 2.438  loss_ce_3: 0  loss_mask_3: 0.899  loss_dice_3: 2.427  loss_ce_4: 0  loss_mask_4: 0.8996  loss_dice_4: 2.432  loss_ce_5: 0  loss_mask_5: 0.8995  loss_dice_5: 2.432  loss_ce_6: 0  loss_mask_6: 0.8983  loss_dice_6: 2.419  loss_ce_7: 0  loss_mask_7: 0.9009  loss_dice_7: 2.426  loss_ce_8: 0  loss_mask_8: 0.9063  loss_dice_8: 2.421  time: 2.1166  data_time: 0.0249  lr: 7.9318e-05  max_mem: 6003M
[02/18 07:53:15] d2.utils.events INFO:  eta: 20:42:08  iter: 13639  total_loss: 32.86  loss_ce: 0  loss_mask: 0.8716  loss_dice: 2.366  loss_seg: 0.739  loss_ce_0: 0  loss_mask_0: 0.8867  loss_dice_0: 2.408  loss_ce_1: 0  loss_mask_1: 0.8736  loss_dice_1: 2.355  loss_ce_2: 0  loss_mask_2: 0.8779  loss_dice_2: 2.351  loss_ce_3: 0  loss_mask_3: 0.8811  loss_dice_3: 2.341  loss_ce_4: 0  loss_mask_4: 0.8811  loss_dice_4: 2.341  loss_ce_5: 0  loss_mask_5: 0.8815  loss_dice_5: 2.347  loss_ce_6: 0  loss_mask_6: 0.8781  loss_dice_6: 2.346  loss_ce_7: 0  loss_mask_7: 0.8765  loss_dice_7: 2.345  loss_ce_8: 0  loss_mask_8: 0.8807  loss_dice_8: 2.344  time: 2.1159  data_time: 0.0316  lr: 7.9287e-05  max_mem: 6003M
[02/18 07:53:46] d2.utils.events INFO:  eta: 20:40:03  iter: 13659  total_loss: 33.42  loss_ce: 0  loss_mask: 0.8307  loss_dice: 2.327  loss_seg: 1.033  loss_ce_0: 0  loss_mask_0: 0.8388  loss_dice_0: 2.389  loss_ce_1: 0  loss_mask_1: 0.8403  loss_dice_1: 2.331  loss_ce_2: 0  loss_mask_2: 0.8463  loss_dice_2: 2.315  loss_ce_3: 0  loss_mask_3: 0.8444  loss_dice_3: 2.309  loss_ce_4: 0  loss_mask_4: 0.84  loss_dice_4: 2.309  loss_ce_5: 0  loss_mask_5: 0.8409  loss_dice_5: 2.307  loss_ce_6: 0  loss_mask_6: 0.8431  loss_dice_6: 2.308  loss_ce_7: 0  loss_mask_7: 0.8421  loss_dice_7: 2.311  loss_ce_8: 0  loss_mask_8: 0.8412  loss_dice_8: 2.311  time: 2.1151  data_time: 0.0294  lr: 7.9256e-05  max_mem: 6003M
[02/18 07:54:19] d2.utils.events INFO:  eta: 20:37:26  iter: 13679  total_loss: 33.72  loss_ce: 0  loss_mask: 0.8913  loss_dice: 2.416  loss_seg: 0.8026  loss_ce_0: 0  loss_mask_0: 0.9078  loss_dice_0: 2.481  loss_ce_1: 0  loss_mask_1: 0.8921  loss_dice_1: 2.441  loss_ce_2: 0  loss_mask_2: 0.8898  loss_dice_2: 2.412  loss_ce_3: 0  loss_mask_3: 0.8899  loss_dice_3: 2.399  loss_ce_4: 0  loss_mask_4: 0.891  loss_dice_4: 2.406  loss_ce_5: 0  loss_mask_5: 0.8913  loss_dice_5: 2.404  loss_ce_6: 0  loss_mask_6: 0.8959  loss_dice_6: 2.399  loss_ce_7: 0  loss_mask_7: 0.8965  loss_dice_7: 2.407  loss_ce_8: 0  loss_mask_8: 0.8948  loss_dice_8: 2.404  time: 2.1144  data_time: 0.0248  lr: 7.9225e-05  max_mem: 6003M
[02/18 07:54:51] d2.utils.events INFO:  eta: 20:36:16  iter: 13699  total_loss: 33.34  loss_ce: 0  loss_mask: 0.8318  loss_dice: 2.322  loss_seg: 1.146  loss_ce_0: 0  loss_mask_0: 0.8439  loss_dice_0: 2.408  loss_ce_1: 0  loss_mask_1: 0.8283  loss_dice_1: 2.325  loss_ce_2: 0  loss_mask_2: 0.8289  loss_dice_2: 2.305  loss_ce_3: 0  loss_mask_3: 0.8364  loss_dice_3: 2.295  loss_ce_4: 0  loss_mask_4: 0.8349  loss_dice_4: 2.294  loss_ce_5: 0  loss_mask_5: 0.8341  loss_dice_5: 2.297  loss_ce_6: 0  loss_mask_6: 0.8346  loss_dice_6: 2.296  loss_ce_7: 0  loss_mask_7: 0.8351  loss_dice_7: 2.295  loss_ce_8: 0  loss_mask_8: 0.833  loss_dice_8: 2.301  time: 2.1136  data_time: 0.0303  lr: 7.9195e-05  max_mem: 6003M
[02/18 07:55:23] d2.utils.events INFO:  eta: 20:35:09  iter: 13719  total_loss: 35.01  loss_ce: 0  loss_mask: 0.8831  loss_dice: 2.483  loss_seg: 1.055  loss_ce_0: 0  loss_mask_0: 0.8951  loss_dice_0: 2.532  loss_ce_1: 0  loss_mask_1: 0.8814  loss_dice_1: 2.502  loss_ce_2: 0  loss_mask_2: 0.885  loss_dice_2: 2.479  loss_ce_3: 0  loss_mask_3: 0.8891  loss_dice_3: 2.47  loss_ce_4: 0  loss_mask_4: 0.8857  loss_dice_4: 2.47  loss_ce_5: 0  loss_mask_5: 0.8845  loss_dice_5: 2.468  loss_ce_6: 0  loss_mask_6: 0.8865  loss_dice_6: 2.469  loss_ce_7: 0  loss_mask_7: 0.888  loss_dice_7: 2.471  loss_ce_8: 0  loss_mask_8: 0.8861  loss_dice_8: 2.467  time: 2.1129  data_time: 0.0318  lr: 7.9164e-05  max_mem: 6003M
[02/18 07:55:54] d2.utils.events INFO:  eta: 20:30:15  iter: 13739  total_loss: 33.54  loss_ce: 0  loss_mask: 0.9036  loss_dice: 2.329  loss_seg: 0.8373  loss_ce_0: 0  loss_mask_0: 0.9208  loss_dice_0: 2.384  loss_ce_1: 0  loss_mask_1: 0.918  loss_dice_1: 2.342  loss_ce_2: 0  loss_mask_2: 0.9085  loss_dice_2: 2.326  loss_ce_3: 0  loss_mask_3: 0.9103  loss_dice_3: 2.311  loss_ce_4: 0  loss_mask_4: 0.913  loss_dice_4: 2.307  loss_ce_5: 0  loss_mask_5: 0.916  loss_dice_5: 2.312  loss_ce_6: 0  loss_mask_6: 0.9154  loss_dice_6: 2.314  loss_ce_7: 0  loss_mask_7: 0.9167  loss_dice_7: 2.316  loss_ce_8: 0  loss_mask_8: 0.9188  loss_dice_8: 2.318  time: 2.1121  data_time: 0.0328  lr: 7.9133e-05  max_mem: 6006M
[02/18 07:56:27] d2.utils.events INFO:  eta: 20:34:39  iter: 13759  total_loss: 34.42  loss_ce: 0  loss_mask: 0.8954  loss_dice: 2.508  loss_seg: 0.8827  loss_ce_0: 0  loss_mask_0: 0.8942  loss_dice_0: 2.561  loss_ce_1: 0  loss_mask_1: 0.9003  loss_dice_1: 2.518  loss_ce_2: 0  loss_mask_2: 0.8971  loss_dice_2: 2.504  loss_ce_3: 0  loss_mask_3: 0.9071  loss_dice_3: 2.498  loss_ce_4: 0  loss_mask_4: 0.9064  loss_dice_4: 2.495  loss_ce_5: 0  loss_mask_5: 0.9028  loss_dice_5: 2.496  loss_ce_6: 0  loss_mask_6: 0.9054  loss_dice_6: 2.498  loss_ce_7: 0  loss_mask_7: 0.9054  loss_dice_7: 2.496  loss_ce_8: 0  loss_mask_8: 0.9006  loss_dice_8: 2.496  time: 2.1114  data_time: 0.0293  lr: 7.9102e-05  max_mem: 6006M
[02/18 07:57:01] d2.utils.events INFO:  eta: 20:34:35  iter: 13779  total_loss: 32.52  loss_ce: 0  loss_mask: 0.8654  loss_dice: 2.276  loss_seg: 0.8242  loss_ce_0: 0  loss_mask_0: 0.8587  loss_dice_0: 2.316  loss_ce_1: 0  loss_mask_1: 0.8697  loss_dice_1: 2.268  loss_ce_2: 0  loss_mask_2: 0.8659  loss_dice_2: 2.266  loss_ce_3: 0  loss_mask_3: 0.8706  loss_dice_3: 2.256  loss_ce_4: 0  loss_mask_4: 0.8712  loss_dice_4: 2.264  loss_ce_5: 0  loss_mask_5: 0.871  loss_dice_5: 2.265  loss_ce_6: 0  loss_mask_6: 0.8719  loss_dice_6: 2.263  loss_ce_7: 0  loss_mask_7: 0.8725  loss_dice_7: 2.267  loss_ce_8: 0  loss_mask_8: 0.8711  loss_dice_8: 2.265  time: 2.1108  data_time: 0.0357  lr: 7.9071e-05  max_mem: 6006M
[02/18 07:57:33] d2.utils.events INFO:  eta: 20:33:14  iter: 13799  total_loss: 32.85  loss_ce: 0  loss_mask: 0.8676  loss_dice: 2.351  loss_seg: 0.6648  loss_ce_0: 0  loss_mask_0: 0.8899  loss_dice_0: 2.392  loss_ce_1: 0  loss_mask_1: 0.8693  loss_dice_1: 2.35  loss_ce_2: 0  loss_mask_2: 0.874  loss_dice_2: 2.336  loss_ce_3: 0  loss_mask_3: 0.8771  loss_dice_3: 2.326  loss_ce_4: 0  loss_mask_4: 0.8759  loss_dice_4: 2.33  loss_ce_5: 0  loss_mask_5: 0.8792  loss_dice_5: 2.333  loss_ce_6: 0  loss_mask_6: 0.875  loss_dice_6: 2.338  loss_ce_7: 0  loss_mask_7: 0.8725  loss_dice_7: 2.336  loss_ce_8: 0  loss_mask_8: 0.8737  loss_dice_8: 2.343  time: 2.1100  data_time: 0.0397  lr: 7.9041e-05  max_mem: 6006M
[02/18 07:58:06] d2.utils.events INFO:  eta: 20:32:42  iter: 13819  total_loss: 32.75  loss_ce: 0  loss_mask: 0.8398  loss_dice: 2.277  loss_seg: 1.019  loss_ce_0: 0  loss_mask_0: 0.8499  loss_dice_0: 2.335  loss_ce_1: 0  loss_mask_1: 0.835  loss_dice_1: 2.278  loss_ce_2: 0  loss_mask_2: 0.8399  loss_dice_2: 2.264  loss_ce_3: 0  loss_mask_3: 0.8381  loss_dice_3: 2.258  loss_ce_4: 0  loss_mask_4: 0.8349  loss_dice_4: 2.253  loss_ce_5: 0  loss_mask_5: 0.8363  loss_dice_5: 2.249  loss_ce_6: 0  loss_mask_6: 0.8354  loss_dice_6: 2.247  loss_ce_7: 0  loss_mask_7: 0.8389  loss_dice_7: 2.249  loss_ce_8: 0  loss_mask_8: 0.8434  loss_dice_8: 2.252  time: 2.1093  data_time: 0.0298  lr: 7.901e-05  max_mem: 6006M
[02/18 07:58:38] d2.utils.events INFO:  eta: 20:33:33  iter: 13839  total_loss: 33.07  loss_ce: 0  loss_mask: 0.8511  loss_dice: 2.309  loss_seg: 0.769  loss_ce_0: 0  loss_mask_0: 0.8735  loss_dice_0: 2.386  loss_ce_1: 0  loss_mask_1: 0.8562  loss_dice_1: 2.327  loss_ce_2: 0  loss_mask_2: 0.8576  loss_dice_2: 2.312  loss_ce_3: 0  loss_mask_3: 0.8575  loss_dice_3: 2.303  loss_ce_4: 0  loss_mask_4: 0.8526  loss_dice_4: 2.307  loss_ce_5: 0  loss_mask_5: 0.8554  loss_dice_5: 2.306  loss_ce_6: 0  loss_mask_6: 0.8563  loss_dice_6: 2.302  loss_ce_7: 0  loss_mask_7: 0.8563  loss_dice_7: 2.303  loss_ce_8: 0  loss_mask_8: 0.8549  loss_dice_8: 2.303  time: 2.1086  data_time: 0.0335  lr: 7.8979e-05  max_mem: 6006M
[02/18 07:59:12] d2.utils.events INFO:  eta: 20:29:17  iter: 13859  total_loss: 33.89  loss_ce: 0  loss_mask: 0.9144  loss_dice: 2.352  loss_seg: 0.7856  loss_ce_0: 0  loss_mask_0: 0.9133  loss_dice_0: 2.416  loss_ce_1: 0  loss_mask_1: 0.9075  loss_dice_1: 2.355  loss_ce_2: 0  loss_mask_2: 0.9124  loss_dice_2: 2.352  loss_ce_3: 0  loss_mask_3: 0.9134  loss_dice_3: 2.336  loss_ce_4: 0  loss_mask_4: 0.9158  loss_dice_4: 2.338  loss_ce_5: 0  loss_mask_5: 0.9124  loss_dice_5: 2.335  loss_ce_6: 0  loss_mask_6: 0.9133  loss_dice_6: 2.334  loss_ce_7: 0  loss_mask_7: 0.9153  loss_dice_7: 2.334  loss_ce_8: 0  loss_mask_8: 0.914  loss_dice_8: 2.333  time: 2.1080  data_time: 0.0299  lr: 7.8948e-05  max_mem: 6006M
[02/18 07:59:48] d2.utils.events INFO:  eta: 20:31:55  iter: 13879  total_loss: 32.87  loss_ce: 0  loss_mask: 0.8489  loss_dice: 2.291  loss_seg: 0.9773  loss_ce_0: 0  loss_mask_0: 0.8402  loss_dice_0: 2.375  loss_ce_1: 0  loss_mask_1: 0.8533  loss_dice_1: 2.324  loss_ce_2: 0  loss_mask_2: 0.8543  loss_dice_2: 2.293  loss_ce_3: 0  loss_mask_3: 0.8544  loss_dice_3: 2.289  loss_ce_4: 0  loss_mask_4: 0.8543  loss_dice_4: 2.287  loss_ce_5: 0  loss_mask_5: 0.8568  loss_dice_5: 2.29  loss_ce_6: 0  loss_mask_6: 0.859  loss_dice_6: 2.281  loss_ce_7: 0  loss_mask_7: 0.853  loss_dice_7: 2.286  loss_ce_8: 0  loss_mask_8: 0.8538  loss_dice_8: 2.285  time: 2.1076  data_time: 0.0268  lr: 7.8917e-05  max_mem: 6006M
[02/18 08:00:20] d2.utils.events INFO:  eta: 20:31:23  iter: 13899  total_loss: 31.26  loss_ce: 0  loss_mask: 0.8347  loss_dice: 2.165  loss_seg: 0.7654  loss_ce_0: 0  loss_mask_0: 0.8493  loss_dice_0: 2.236  loss_ce_1: 0  loss_mask_1: 0.8379  loss_dice_1: 2.162  loss_ce_2: 0  loss_mask_2: 0.8359  loss_dice_2: 2.154  loss_ce_3: 0  loss_mask_3: 0.8449  loss_dice_3: 2.147  loss_ce_4: 0  loss_mask_4: 0.8448  loss_dice_4: 2.146  loss_ce_5: 0  loss_mask_5: 0.8484  loss_dice_5: 2.153  loss_ce_6: 0  loss_mask_6: 0.8489  loss_dice_6: 2.146  loss_ce_7: 0  loss_mask_7: 0.845  loss_dice_7: 2.147  loss_ce_8: 0  loss_mask_8: 0.8456  loss_dice_8: 2.144  time: 2.1068  data_time: 0.0254  lr: 7.8887e-05  max_mem: 6006M
[02/18 08:00:54] d2.utils.events INFO:  eta: 20:27:41  iter: 13919  total_loss: 33.47  loss_ce: 0  loss_mask: 0.8765  loss_dice: 2.295  loss_seg: 1.105  loss_ce_0: 0  loss_mask_0: 0.8816  loss_dice_0: 2.36  loss_ce_1: 0  loss_mask_1: 0.8795  loss_dice_1: 2.297  loss_ce_2: 0  loss_mask_2: 0.8756  loss_dice_2: 2.275  loss_ce_3: 0  loss_mask_3: 0.8812  loss_dice_3: 2.272  loss_ce_4: 0  loss_mask_4: 0.8816  loss_dice_4: 2.276  loss_ce_5: 0  loss_mask_5: 0.8851  loss_dice_5: 2.278  loss_ce_6: 0  loss_mask_6: 0.8809  loss_dice_6: 2.275  loss_ce_7: 0  loss_mask_7: 0.8803  loss_dice_7: 2.275  loss_ce_8: 0  loss_mask_8: 0.886  loss_dice_8: 2.28  time: 2.1062  data_time: 0.0307  lr: 7.8856e-05  max_mem: 6006M
[02/18 08:01:25] d2.utils.events INFO:  eta: 20:23:57  iter: 13939  total_loss: 33.25  loss_ce: 0  loss_mask: 0.8514  loss_dice: 2.365  loss_seg: 0.8001  loss_ce_0: 0  loss_mask_0: 0.8415  loss_dice_0: 2.409  loss_ce_1: 0  loss_mask_1: 0.8487  loss_dice_1: 2.383  loss_ce_2: 0  loss_mask_2: 0.8547  loss_dice_2: 2.367  loss_ce_3: 0  loss_mask_3: 0.8573  loss_dice_3: 2.363  loss_ce_4: 0  loss_mask_4: 0.8614  loss_dice_4: 2.354  loss_ce_5: 0  loss_mask_5: 0.8609  loss_dice_5: 2.363  loss_ce_6: 0  loss_mask_6: 0.8596  loss_dice_6: 2.358  loss_ce_7: 0  loss_mask_7: 0.8595  loss_dice_7: 2.362  loss_ce_8: 0  loss_mask_8: 0.8587  loss_dice_8: 2.349  time: 2.1054  data_time: 0.0361  lr: 7.8825e-05  max_mem: 6006M
[02/18 08:01:55] d2.utils.events INFO:  eta: 20:21:42  iter: 13959  total_loss: 33.02  loss_ce: 0  loss_mask: 0.8655  loss_dice: 2.385  loss_seg: 0.7986  loss_ce_0: 0  loss_mask_0: 0.8665  loss_dice_0: 2.443  loss_ce_1: 0  loss_mask_1: 0.8715  loss_dice_1: 2.388  loss_ce_2: 0  loss_mask_2: 0.8763  loss_dice_2: 2.374  loss_ce_3: 0  loss_mask_3: 0.8825  loss_dice_3: 2.37  loss_ce_4: 0  loss_mask_4: 0.8826  loss_dice_4: 2.37  loss_ce_5: 0  loss_mask_5: 0.8816  loss_dice_5: 2.371  loss_ce_6: 0  loss_mask_6: 0.8795  loss_dice_6: 2.364  loss_ce_7: 0  loss_mask_7: 0.8806  loss_dice_7: 2.371  loss_ce_8: 0  loss_mask_8: 0.8775  loss_dice_8: 2.37  time: 2.1046  data_time: 0.0288  lr: 7.8794e-05  max_mem: 6006M
[02/18 08:02:27] d2.utils.events INFO:  eta: 20:21:18  iter: 13979  total_loss: 32.27  loss_ce: 0  loss_mask: 0.8423  loss_dice: 2.302  loss_seg: 0.9616  loss_ce_0: 0  loss_mask_0: 0.8378  loss_dice_0: 2.382  loss_ce_1: 0  loss_mask_1: 0.8349  loss_dice_1: 2.309  loss_ce_2: 0  loss_mask_2: 0.8367  loss_dice_2: 2.299  loss_ce_3: 0  loss_mask_3: 0.8411  loss_dice_3: 2.287  loss_ce_4: 0  loss_mask_4: 0.8405  loss_dice_4: 2.287  loss_ce_5: 0  loss_mask_5: 0.8492  loss_dice_5: 2.292  loss_ce_6: 0  loss_mask_6: 0.856  loss_dice_6: 2.291  loss_ce_7: 0  loss_mask_7: 0.8528  loss_dice_7: 2.286  loss_ce_8: 0  loss_mask_8: 0.854  loss_dice_8: 2.284  time: 2.1038  data_time: 0.0300  lr: 7.8763e-05  max_mem: 6006M
[02/18 08:02:58] d2.utils.events INFO:  eta: 20:18:35  iter: 13999  total_loss: 32.72  loss_ce: 0  loss_mask: 0.8693  loss_dice: 2.279  loss_seg: 0.9575  loss_ce_0: 0  loss_mask_0: 0.8771  loss_dice_0: 2.359  loss_ce_1: 0  loss_mask_1: 0.8709  loss_dice_1: 2.299  loss_ce_2: 0  loss_mask_2: 0.8783  loss_dice_2: 2.273  loss_ce_3: 0  loss_mask_3: 0.8783  loss_dice_3: 2.261  loss_ce_4: 0  loss_mask_4: 0.8785  loss_dice_4: 2.264  loss_ce_5: 0  loss_mask_5: 0.8773  loss_dice_5: 2.266  loss_ce_6: 0  loss_mask_6: 0.8754  loss_dice_6: 2.261  loss_ce_7: 0  loss_mask_7: 0.8718  loss_dice_7: 2.263  loss_ce_8: 0  loss_mask_8: 0.8695  loss_dice_8: 2.264  time: 2.1030  data_time: 0.0320  lr: 7.8733e-05  max_mem: 6006M
[02/18 08:03:31] d2.utils.events INFO:  eta: 20:19:49  iter: 14019  total_loss: 33.86  loss_ce: 0  loss_mask: 0.8584  loss_dice: 2.334  loss_seg: 0.9906  loss_ce_0: 0  loss_mask_0: 0.8821  loss_dice_0: 2.36  loss_ce_1: 0  loss_mask_1: 0.8654  loss_dice_1: 2.339  loss_ce_2: 0  loss_mask_2: 0.8571  loss_dice_2: 2.335  loss_ce_3: 0  loss_mask_3: 0.8536  loss_dice_3: 2.319  loss_ce_4: 0  loss_mask_4: 0.8533  loss_dice_4: 2.322  loss_ce_5: 0  loss_mask_5: 0.8554  loss_dice_5: 2.324  loss_ce_6: 0  loss_mask_6: 0.8594  loss_dice_6: 2.314  loss_ce_7: 0  loss_mask_7: 0.8591  loss_dice_7: 2.318  loss_ce_8: 0  loss_mask_8: 0.86  loss_dice_8: 2.321  time: 2.1024  data_time: 0.0280  lr: 7.8702e-05  max_mem: 6006M
[02/18 08:04:04] d2.utils.events INFO:  eta: 20:19:31  iter: 14039  total_loss: 32.85  loss_ce: 0  loss_mask: 0.8722  loss_dice: 2.321  loss_seg: 0.8119  loss_ce_0: 0  loss_mask_0: 0.8787  loss_dice_0: 2.394  loss_ce_1: 0  loss_mask_1: 0.8789  loss_dice_1: 2.324  loss_ce_2: 0  loss_mask_2: 0.877  loss_dice_2: 2.31  loss_ce_3: 0  loss_mask_3: 0.8851  loss_dice_3: 2.307  loss_ce_4: 0  loss_mask_4: 0.8815  loss_dice_4: 2.309  loss_ce_5: 0  loss_mask_5: 0.8839  loss_dice_5: 2.311  loss_ce_6: 0  loss_mask_6: 0.879  loss_dice_6: 2.306  loss_ce_7: 0  loss_mask_7: 0.8748  loss_dice_7: 2.314  loss_ce_8: 0  loss_mask_8: 0.8744  loss_dice_8: 2.315  time: 2.1017  data_time: 0.0311  lr: 7.8671e-05  max_mem: 6006M
[02/18 08:04:34] d2.utils.events INFO:  eta: 20:17:21  iter: 14059  total_loss: 32.83  loss_ce: 0  loss_mask: 0.8596  loss_dice: 2.341  loss_seg: 0.8131  loss_ce_0: 0  loss_mask_0: 0.867  loss_dice_0: 2.392  loss_ce_1: 0  loss_mask_1: 0.8751  loss_dice_1: 2.342  loss_ce_2: 0  loss_mask_2: 0.8632  loss_dice_2: 2.328  loss_ce_3: 0  loss_mask_3: 0.8611  loss_dice_3: 2.325  loss_ce_4: 0  loss_mask_4: 0.8609  loss_dice_4: 2.326  loss_ce_5: 0  loss_mask_5: 0.8603  loss_dice_5: 2.332  loss_ce_6: 0  loss_mask_6: 0.8643  loss_dice_6: 2.329  loss_ce_7: 0  loss_mask_7: 0.8605  loss_dice_7: 2.33  loss_ce_8: 0  loss_mask_8: 0.8623  loss_dice_8: 2.329  time: 2.1009  data_time: 0.0282  lr: 7.864e-05  max_mem: 6006M
[02/18 08:05:06] d2.utils.events INFO:  eta: 20:16:49  iter: 14079  total_loss: 33.83  loss_ce: 0  loss_mask: 0.8657  loss_dice: 2.305  loss_seg: 1.604  loss_ce_0: 0  loss_mask_0: 0.8542  loss_dice_0: 2.379  loss_ce_1: 0  loss_mask_1: 0.8655  loss_dice_1: 2.309  loss_ce_2: 0  loss_mask_2: 0.8709  loss_dice_2: 2.292  loss_ce_3: 0  loss_mask_3: 0.876  loss_dice_3: 2.278  loss_ce_4: 0  loss_mask_4: 0.8763  loss_dice_4: 2.282  loss_ce_5: 0  loss_mask_5: 0.8702  loss_dice_5: 2.286  loss_ce_6: 0  loss_mask_6: 0.8744  loss_dice_6: 2.282  loss_ce_7: 0  loss_mask_7: 0.8757  loss_dice_7: 2.289  loss_ce_8: 0  loss_mask_8: 0.8742  loss_dice_8: 2.285  time: 2.1002  data_time: 0.0315  lr: 7.8609e-05  max_mem: 6006M
[02/18 08:05:41] d2.utils.events INFO:  eta: 20:16:44  iter: 14099  total_loss: 34.51  loss_ce: 0  loss_mask: 0.8704  loss_dice: 2.402  loss_seg: 1.112  loss_ce_0: 0  loss_mask_0: 0.865  loss_dice_0: 2.464  loss_ce_1: 0  loss_mask_1: 0.8777  loss_dice_1: 2.415  loss_ce_2: 0  loss_mask_2: 0.8833  loss_dice_2: 2.402  loss_ce_3: 0  loss_mask_3: 0.8881  loss_dice_3: 2.4  loss_ce_4: 0  loss_mask_4: 0.8816  loss_dice_4: 2.402  loss_ce_5: 0  loss_mask_5: 0.8809  loss_dice_5: 2.398  loss_ce_6: 0  loss_mask_6: 0.8831  loss_dice_6: 2.396  loss_ce_7: 0  loss_mask_7: 0.8847  loss_dice_7: 2.399  loss_ce_8: 0  loss_mask_8: 0.8812  loss_dice_8: 2.396  time: 2.0996  data_time: 0.0272  lr: 7.8579e-05  max_mem: 6006M
[02/18 08:06:13] d2.utils.events INFO:  eta: 20:17:24  iter: 14119  total_loss: 31.87  loss_ce: 0  loss_mask: 0.8219  loss_dice: 2.349  loss_seg: 0.8734  loss_ce_0: 0  loss_mask_0: 0.8335  loss_dice_0: 2.407  loss_ce_1: 0  loss_mask_1: 0.8293  loss_dice_1: 2.354  loss_ce_2: 0  loss_mask_2: 0.8315  loss_dice_2: 2.338  loss_ce_3: 0  loss_mask_3: 0.8264  loss_dice_3: 2.328  loss_ce_4: 0  loss_mask_4: 0.8267  loss_dice_4: 2.332  loss_ce_5: 0  loss_mask_5: 0.8287  loss_dice_5: 2.328  loss_ce_6: 0  loss_mask_6: 0.8239  loss_dice_6: 2.334  loss_ce_7: 0  loss_mask_7: 0.8241  loss_dice_7: 2.339  loss_ce_8: 0  loss_mask_8: 0.825  loss_dice_8: 2.335  time: 2.0990  data_time: 0.0276  lr: 7.8548e-05  max_mem: 6006M
[02/18 08:06:47] d2.utils.events INFO:  eta: 20:14:41  iter: 14139  total_loss: 32.83  loss_ce: 0  loss_mask: 0.8558  loss_dice: 2.327  loss_seg: 0.8115  loss_ce_0: 0  loss_mask_0: 0.8529  loss_dice_0: 2.411  loss_ce_1: 0  loss_mask_1: 0.8557  loss_dice_1: 2.333  loss_ce_2: 0  loss_mask_2: 0.8597  loss_dice_2: 2.316  loss_ce_3: 0  loss_mask_3: 0.8639  loss_dice_3: 2.302  loss_ce_4: 0  loss_mask_4: 0.8635  loss_dice_4: 2.31  loss_ce_5: 0  loss_mask_5: 0.8576  loss_dice_5: 2.306  loss_ce_6: 0  loss_mask_6: 0.864  loss_dice_6: 2.305  loss_ce_7: 0  loss_mask_7: 0.8654  loss_dice_7: 2.304  loss_ce_8: 0  loss_mask_8: 0.8611  loss_dice_8: 2.308  time: 2.0984  data_time: 0.0246  lr: 7.8517e-05  max_mem: 6006M
[02/18 08:07:20] d2.utils.events INFO:  eta: 20:14:09  iter: 14159  total_loss: 34.36  loss_ce: 0  loss_mask: 0.9249  loss_dice: 2.393  loss_seg: 0.6877  loss_ce_0: 0  loss_mask_0: 0.9371  loss_dice_0: 2.426  loss_ce_1: 0  loss_mask_1: 0.9312  loss_dice_1: 2.408  loss_ce_2: 0  loss_mask_2: 0.9321  loss_dice_2: 2.395  loss_ce_3: 0  loss_mask_3: 0.9309  loss_dice_3: 2.375  loss_ce_4: 0  loss_mask_4: 0.9371  loss_dice_4: 2.381  loss_ce_5: 0  loss_mask_5: 0.9358  loss_dice_5: 2.382  loss_ce_6: 0  loss_mask_6: 0.9344  loss_dice_6: 2.377  loss_ce_7: 0  loss_mask_7: 0.9317  loss_dice_7: 2.378  loss_ce_8: 0  loss_mask_8: 0.9273  loss_dice_8: 2.381  time: 2.0977  data_time: 0.0327  lr: 7.8486e-05  max_mem: 6006M
[02/18 08:07:53] d2.utils.events INFO:  eta: 20:13:49  iter: 14179  total_loss: 33.93  loss_ce: 0  loss_mask: 0.8817  loss_dice: 2.38  loss_seg: 1.13  loss_ce_0: 0  loss_mask_0: 0.8971  loss_dice_0: 2.42  loss_ce_1: 0  loss_mask_1: 0.8876  loss_dice_1: 2.377  loss_ce_2: 0  loss_mask_2: 0.8835  loss_dice_2: 2.368  loss_ce_3: 0  loss_mask_3: 0.8826  loss_dice_3: 2.362  loss_ce_4: 0  loss_mask_4: 0.8835  loss_dice_4: 2.365  loss_ce_5: 0  loss_mask_5: 0.8834  loss_dice_5: 2.374  loss_ce_6: 0  loss_mask_6: 0.8898  loss_dice_6: 2.368  loss_ce_7: 0  loss_mask_7: 0.8864  loss_dice_7: 2.367  loss_ce_8: 0  loss_mask_8: 0.8843  loss_dice_8: 2.369  time: 2.0971  data_time: 0.0363  lr: 7.8455e-05  max_mem: 6006M
[02/18 08:08:26] d2.utils.events INFO:  eta: 20:13:39  iter: 14199  total_loss: 34.35  loss_ce: 0  loss_mask: 0.8632  loss_dice: 2.447  loss_seg: 0.9869  loss_ce_0: 0  loss_mask_0: 0.8774  loss_dice_0: 2.51  loss_ce_1: 0  loss_mask_1: 0.8742  loss_dice_1: 2.456  loss_ce_2: 0  loss_mask_2: 0.8738  loss_dice_2: 2.441  loss_ce_3: 0  loss_mask_3: 0.8743  loss_dice_3: 2.434  loss_ce_4: 0  loss_mask_4: 0.8811  loss_dice_4: 2.433  loss_ce_5: 0  loss_mask_5: 0.8794  loss_dice_5: 2.428  loss_ce_6: 0  loss_mask_6: 0.8799  loss_dice_6: 2.432  loss_ce_7: 0  loss_mask_7: 0.8742  loss_dice_7: 2.435  loss_ce_8: 0  loss_mask_8: 0.8735  loss_dice_8: 2.434  time: 2.0965  data_time: 0.0342  lr: 7.8424e-05  max_mem: 6006M
[02/18 08:09:01] d2.utils.events INFO:  eta: 20:14:03  iter: 14219  total_loss: 32.46  loss_ce: 0  loss_mask: 0.818  loss_dice: 2.309  loss_seg: 1.118  loss_ce_0: 0  loss_mask_0: 0.8209  loss_dice_0: 2.389  loss_ce_1: 0  loss_mask_1: 0.8133  loss_dice_1: 2.311  loss_ce_2: 0  loss_mask_2: 0.8189  loss_dice_2: 2.298  loss_ce_3: 0  loss_mask_3: 0.8254  loss_dice_3: 2.29  loss_ce_4: 0  loss_mask_4: 0.8202  loss_dice_4: 2.29  loss_ce_5: 0  loss_mask_5: 0.8232  loss_dice_5: 2.29  loss_ce_6: 0  loss_mask_6: 0.8248  loss_dice_6: 2.291  loss_ce_7: 0  loss_mask_7: 0.8228  loss_dice_7: 2.289  loss_ce_8: 0  loss_mask_8: 0.8249  loss_dice_8: 2.296  time: 2.0960  data_time: 0.0366  lr: 7.8394e-05  max_mem: 6006M
[02/18 08:09:36] d2.utils.events INFO:  eta: 20:14:13  iter: 14239  total_loss: 33.68  loss_ce: 0  loss_mask: 0.864  loss_dice: 2.368  loss_seg: 0.6805  loss_ce_0: 0  loss_mask_0: 0.883  loss_dice_0: 2.419  loss_ce_1: 0  loss_mask_1: 0.8664  loss_dice_1: 2.383  loss_ce_2: 0  loss_mask_2: 0.8679  loss_dice_2: 2.357  loss_ce_3: 0  loss_mask_3: 0.8677  loss_dice_3: 2.35  loss_ce_4: 0  loss_mask_4: 0.8742  loss_dice_4: 2.36  loss_ce_5: 0  loss_mask_5: 0.8749  loss_dice_5: 2.356  loss_ce_6: 0  loss_mask_6: 0.8738  loss_dice_6: 2.354  loss_ce_7: 0  loss_mask_7: 0.8705  loss_dice_7: 2.362  loss_ce_8: 0  loss_mask_8: 0.8747  loss_dice_8: 2.354  time: 2.0955  data_time: 0.0403  lr: 7.8363e-05  max_mem: 6006M
[02/18 08:10:06] d2.utils.events INFO:  eta: 20:13:23  iter: 14259  total_loss: 32.93  loss_ce: 0  loss_mask: 0.8987  loss_dice: 2.281  loss_seg: 0.821  loss_ce_0: 0  loss_mask_0: 0.8999  loss_dice_0: 2.333  loss_ce_1: 0  loss_mask_1: 0.9013  loss_dice_1: 2.275  loss_ce_2: 0  loss_mask_2: 0.902  loss_dice_2: 2.267  loss_ce_3: 0  loss_mask_3: 0.9013  loss_dice_3: 2.267  loss_ce_4: 0  loss_mask_4: 0.9029  loss_dice_4: 2.261  loss_ce_5: 0  loss_mask_5: 0.9056  loss_dice_5: 2.265  loss_ce_6: 0  loss_mask_6: 0.9035  loss_dice_6: 2.266  loss_ce_7: 0  loss_mask_7: 0.9011  loss_dice_7: 2.263  loss_ce_8: 0  loss_mask_8: 0.9058  loss_dice_8: 2.267  time: 2.0947  data_time: 0.0326  lr: 7.8332e-05  max_mem: 6006M
[02/18 08:10:38] d2.utils.events INFO:  eta: 20:12:27  iter: 14279  total_loss: 31  loss_ce: 0  loss_mask: 0.8348  loss_dice: 2.187  loss_seg: 0.8019  loss_ce_0: 0  loss_mask_0: 0.8359  loss_dice_0: 2.261  loss_ce_1: 0  loss_mask_1: 0.8439  loss_dice_1: 2.199  loss_ce_2: 0  loss_mask_2: 0.8412  loss_dice_2: 2.186  loss_ce_3: 0  loss_mask_3: 0.8411  loss_dice_3: 2.175  loss_ce_4: 0  loss_mask_4: 0.8423  loss_dice_4: 2.174  loss_ce_5: 0  loss_mask_5: 0.842  loss_dice_5: 2.176  loss_ce_6: 0  loss_mask_6: 0.8406  loss_dice_6: 2.174  loss_ce_7: 0  loss_mask_7: 0.8413  loss_dice_7: 2.174  loss_ce_8: 0  loss_mask_8: 0.8405  loss_dice_8: 2.175  time: 2.0939  data_time: 0.0283  lr: 7.8301e-05  max_mem: 6006M
[02/18 08:11:08] d2.utils.events INFO:  eta: 20:09:59  iter: 14299  total_loss: 32.65  loss_ce: 0  loss_mask: 0.8727  loss_dice: 2.302  loss_seg: 1.016  loss_ce_0: 0  loss_mask_0: 0.8735  loss_dice_0: 2.366  loss_ce_1: 0  loss_mask_1: 0.8689  loss_dice_1: 2.307  loss_ce_2: 0  loss_mask_2: 0.8757  loss_dice_2: 2.3  loss_ce_3: 0  loss_mask_3: 0.8854  loss_dice_3: 2.282  loss_ce_4: 0  loss_mask_4: 0.8824  loss_dice_4: 2.284  loss_ce_5: 0  loss_mask_5: 0.8848  loss_dice_5: 2.291  loss_ce_6: 0  loss_mask_6: 0.8906  loss_dice_6: 2.283  loss_ce_7: 0  loss_mask_7: 0.8847  loss_dice_7: 2.282  loss_ce_8: 0  loss_mask_8: 0.8844  loss_dice_8: 2.288  time: 2.0931  data_time: 0.0261  lr: 7.827e-05  max_mem: 6006M
[02/18 08:11:42] d2.utils.events INFO:  eta: 20:10:17  iter: 14319  total_loss: 32.02  loss_ce: 0  loss_mask: 0.8747  loss_dice: 2.269  loss_seg: 0.8277  loss_ce_0: 0  loss_mask_0: 0.8861  loss_dice_0: 2.347  loss_ce_1: 0  loss_mask_1: 0.8737  loss_dice_1: 2.279  loss_ce_2: 0  loss_mask_2: 0.8744  loss_dice_2: 2.258  loss_ce_3: 0  loss_mask_3: 0.885  loss_dice_3: 2.253  loss_ce_4: 0  loss_mask_4: 0.8856  loss_dice_4: 2.251  loss_ce_5: 0  loss_mask_5: 0.8806  loss_dice_5: 2.257  loss_ce_6: 0  loss_mask_6: 0.8869  loss_dice_6: 2.258  loss_ce_7: 0  loss_mask_7: 0.8789  loss_dice_7: 2.26  loss_ce_8: 0  loss_mask_8: 0.8783  loss_dice_8: 2.255  time: 2.0926  data_time: 0.0242  lr: 7.8239e-05  max_mem: 6006M
[02/18 08:12:15] d2.utils.events INFO:  eta: 20:09:23  iter: 14339  total_loss: 32.72  loss_ce: 0  loss_mask: 0.8787  loss_dice: 2.281  loss_seg: 0.8798  loss_ce_0: 0  loss_mask_0: 0.8885  loss_dice_0: 2.341  loss_ce_1: 0  loss_mask_1: 0.8905  loss_dice_1: 2.283  loss_ce_2: 0  loss_mask_2: 0.8885  loss_dice_2: 2.265  loss_ce_3: 0  loss_mask_3: 0.8857  loss_dice_3: 2.258  loss_ce_4: 0  loss_mask_4: 0.8891  loss_dice_4: 2.261  loss_ce_5: 0  loss_mask_5: 0.8903  loss_dice_5: 2.266  loss_ce_6: 0  loss_mask_6: 0.8888  loss_dice_6: 2.262  loss_ce_7: 0  loss_mask_7: 0.8909  loss_dice_7: 2.261  loss_ce_8: 0  loss_mask_8: 0.8936  loss_dice_8: 2.257  time: 2.0919  data_time: 0.0291  lr: 7.8209e-05  max_mem: 6006M
[02/18 08:12:47] d2.utils.events INFO:  eta: 20:08:51  iter: 14359  total_loss: 34.8  loss_ce: 0  loss_mask: 0.8715  loss_dice: 2.508  loss_seg: 0.8432  loss_ce_0: 0  loss_mask_0: 0.8883  loss_dice_0: 2.56  loss_ce_1: 0  loss_mask_1: 0.8754  loss_dice_1: 2.516  loss_ce_2: 0  loss_mask_2: 0.8744  loss_dice_2: 2.508  loss_ce_3: 0  loss_mask_3: 0.8757  loss_dice_3: 2.496  loss_ce_4: 0  loss_mask_4: 0.8764  loss_dice_4: 2.498  loss_ce_5: 0  loss_mask_5: 0.8757  loss_dice_5: 2.503  loss_ce_6: 0  loss_mask_6: 0.8758  loss_dice_6: 2.499  loss_ce_7: 0  loss_mask_7: 0.8705  loss_dice_7: 2.499  loss_ce_8: 0  loss_mask_8: 0.8785  loss_dice_8: 2.5  time: 2.0913  data_time: 0.0323  lr: 7.8178e-05  max_mem: 6006M
[02/18 08:13:18] d2.utils.events INFO:  eta: 20:08:35  iter: 14379  total_loss: 33.78  loss_ce: 0  loss_mask: 0.8939  loss_dice: 2.381  loss_seg: 0.7515  loss_ce_0: 0  loss_mask_0: 0.9161  loss_dice_0: 2.456  loss_ce_1: 0  loss_mask_1: 0.8951  loss_dice_1: 2.377  loss_ce_2: 0  loss_mask_2: 0.9025  loss_dice_2: 2.37  loss_ce_3: 0  loss_mask_3: 0.9099  loss_dice_3: 2.362  loss_ce_4: 0  loss_mask_4: 0.9063  loss_dice_4: 2.365  loss_ce_5: 0  loss_mask_5: 0.9088  loss_dice_5: 2.368  loss_ce_6: 0  loss_mask_6: 0.9117  loss_dice_6: 2.366  loss_ce_7: 0  loss_mask_7: 0.9088  loss_dice_7: 2.367  loss_ce_8: 0  loss_mask_8: 0.9039  loss_dice_8: 2.368  time: 2.0905  data_time: 0.0319  lr: 7.8147e-05  max_mem: 6006M
[02/18 08:13:50] d2.utils.events INFO:  eta: 20:09:41  iter: 14399  total_loss: 33.94  loss_ce: 0  loss_mask: 0.8549  loss_dice: 2.4  loss_seg: 1.06  loss_ce_0: 0  loss_mask_0: 0.8707  loss_dice_0: 2.452  loss_ce_1: 0  loss_mask_1: 0.8553  loss_dice_1: 2.405  loss_ce_2: 0  loss_mask_2: 0.8541  loss_dice_2: 2.394  loss_ce_3: 0  loss_mask_3: 0.8579  loss_dice_3: 2.383  loss_ce_4: 0  loss_mask_4: 0.8569  loss_dice_4: 2.389  loss_ce_5: 0  loss_mask_5: 0.8589  loss_dice_5: 2.39  loss_ce_6: 0  loss_mask_6: 0.8592  loss_dice_6: 2.385  loss_ce_7: 0  loss_mask_7: 0.8619  loss_dice_7: 2.386  loss_ce_8: 0  loss_mask_8: 0.8652  loss_dice_8: 2.391  time: 2.0898  data_time: 0.0300  lr: 7.8116e-05  max_mem: 6006M
[02/18 08:14:24] d2.utils.events INFO:  eta: 20:09:31  iter: 14419  total_loss: 32.21  loss_ce: 0  loss_mask: 0.8467  loss_dice: 2.289  loss_seg: 0.8505  loss_ce_0: 0  loss_mask_0: 0.8469  loss_dice_0: 2.363  loss_ce_1: 0  loss_mask_1: 0.845  loss_dice_1: 2.293  loss_ce_2: 0  loss_mask_2: 0.8468  loss_dice_2: 2.274  loss_ce_3: 0  loss_mask_3: 0.8482  loss_dice_3: 2.265  loss_ce_4: 0  loss_mask_4: 0.8512  loss_dice_4: 2.269  loss_ce_5: 0  loss_mask_5: 0.8524  loss_dice_5: 2.273  loss_ce_6: 0  loss_mask_6: 0.8558  loss_dice_6: 2.266  loss_ce_7: 0  loss_mask_7: 0.854  loss_dice_7: 2.267  loss_ce_8: 0  loss_mask_8: 0.855  loss_dice_8: 2.264  time: 2.0893  data_time: 0.0336  lr: 7.8085e-05  max_mem: 6006M
[02/18 08:14:55] d2.utils.events INFO:  eta: 20:07:43  iter: 14439  total_loss: 32.82  loss_ce: 0  loss_mask: 0.8357  loss_dice: 2.306  loss_seg: 1.013  loss_ce_0: 0  loss_mask_0: 0.841  loss_dice_0: 2.381  loss_ce_1: 0  loss_mask_1: 0.8414  loss_dice_1: 2.329  loss_ce_2: 0  loss_mask_2: 0.8414  loss_dice_2: 2.304  loss_ce_3: 0  loss_mask_3: 0.8394  loss_dice_3: 2.285  loss_ce_4: 0  loss_mask_4: 0.839  loss_dice_4: 2.292  loss_ce_5: 0  loss_mask_5: 0.8419  loss_dice_5: 2.294  loss_ce_6: 0  loss_mask_6: 0.8344  loss_dice_6: 2.289  loss_ce_7: 0  loss_mask_7: 0.8357  loss_dice_7: 2.286  loss_ce_8: 0  loss_mask_8: 0.8379  loss_dice_8: 2.288  time: 2.0885  data_time: 0.0260  lr: 7.8054e-05  max_mem: 6006M
[02/18 08:15:28] d2.utils.events INFO:  eta: 20:07:41  iter: 14459  total_loss: 33.79  loss_ce: 0  loss_mask: 0.8871  loss_dice: 2.379  loss_seg: 1.018  loss_ce_0: 0  loss_mask_0: 0.8817  loss_dice_0: 2.432  loss_ce_1: 0  loss_mask_1: 0.8974  loss_dice_1: 2.402  loss_ce_2: 0  loss_mask_2: 0.8977  loss_dice_2: 2.392  loss_ce_3: 0  loss_mask_3: 0.897  loss_dice_3: 2.372  loss_ce_4: 0  loss_mask_4: 0.895  loss_dice_4: 2.373  loss_ce_5: 0  loss_mask_5: 0.8937  loss_dice_5: 2.377  loss_ce_6: 0  loss_mask_6: 0.8902  loss_dice_6: 2.374  loss_ce_7: 0  loss_mask_7: 0.8973  loss_dice_7: 2.372  loss_ce_8: 0  loss_mask_8: 0.8983  loss_dice_8: 2.367  time: 2.0879  data_time: 0.0247  lr: 7.8024e-05  max_mem: 6006M
[02/18 08:16:04] d2.utils.events INFO:  eta: 20:09:25  iter: 14479  total_loss: 32.9  loss_ce: 0  loss_mask: 0.9054  loss_dice: 2.342  loss_seg: 0.973  loss_ce_0: 0  loss_mask_0: 0.9254  loss_dice_0: 2.418  loss_ce_1: 0  loss_mask_1: 0.9139  loss_dice_1: 2.35  loss_ce_2: 0  loss_mask_2: 0.9127  loss_dice_2: 2.329  loss_ce_3: 0  loss_mask_3: 0.9036  loss_dice_3: 2.325  loss_ce_4: 0  loss_mask_4: 0.9103  loss_dice_4: 2.327  loss_ce_5: 0  loss_mask_5: 0.912  loss_dice_5: 2.325  loss_ce_6: 0  loss_mask_6: 0.9124  loss_dice_6: 2.323  loss_ce_7: 0  loss_mask_7: 0.9121  loss_dice_7: 2.324  loss_ce_8: 0  loss_mask_8: 0.9114  loss_dice_8: 2.32  time: 2.0875  data_time: 0.0328  lr: 7.7993e-05  max_mem: 6006M
[02/18 08:16:35] d2.utils.events INFO:  eta: 20:08:53  iter: 14499  total_loss: 32.4  loss_ce: 0  loss_mask: 0.8439  loss_dice: 2.267  loss_seg: 1.124  loss_ce_0: 0  loss_mask_0: 0.8455  loss_dice_0: 2.326  loss_ce_1: 0  loss_mask_1: 0.8446  loss_dice_1: 2.27  loss_ce_2: 0  loss_mask_2: 0.8453  loss_dice_2: 2.258  loss_ce_3: 0  loss_mask_3: 0.8465  loss_dice_3: 2.247  loss_ce_4: 0  loss_mask_4: 0.85  loss_dice_4: 2.248  loss_ce_5: 0  loss_mask_5: 0.8491  loss_dice_5: 2.253  loss_ce_6: 0  loss_mask_6: 0.8505  loss_dice_6: 2.254  loss_ce_7: 0  loss_mask_7: 0.8464  loss_dice_7: 2.262  loss_ce_8: 0  loss_mask_8: 0.845  loss_dice_8: 2.263  time: 2.0868  data_time: 0.0291  lr: 7.7962e-05  max_mem: 6006M
[02/18 08:17:10] d2.utils.events INFO:  eta: 20:09:12  iter: 14519  total_loss: 31.25  loss_ce: 0  loss_mask: 0.8433  loss_dice: 2.218  loss_seg: 0.7224  loss_ce_0: 0  loss_mask_0: 0.8352  loss_dice_0: 2.299  loss_ce_1: 0  loss_mask_1: 0.8366  loss_dice_1: 2.23  loss_ce_2: 0  loss_mask_2: 0.8455  loss_dice_2: 2.212  loss_ce_3: 0  loss_mask_3: 0.8521  loss_dice_3: 2.198  loss_ce_4: 0  loss_mask_4: 0.8504  loss_dice_4: 2.199  loss_ce_5: 0  loss_mask_5: 0.8524  loss_dice_5: 2.2  loss_ce_6: 0  loss_mask_6: 0.8544  loss_dice_6: 2.198  loss_ce_7: 0  loss_mask_7: 0.8507  loss_dice_7: 2.2  loss_ce_8: 0  loss_mask_8: 0.8515  loss_dice_8: 2.2  time: 2.0863  data_time: 0.0218  lr: 7.7931e-05  max_mem: 6006M
[02/18 08:17:43] d2.utils.events INFO:  eta: 20:08:00  iter: 14539  total_loss: 32.67  loss_ce: 0  loss_mask: 0.8644  loss_dice: 2.278  loss_seg: 0.8699  loss_ce_0: 0  loss_mask_0: 0.8695  loss_dice_0: 2.342  loss_ce_1: 0  loss_mask_1: 0.8673  loss_dice_1: 2.298  loss_ce_2: 0  loss_mask_2: 0.8668  loss_dice_2: 2.282  loss_ce_3: 0  loss_mask_3: 0.8714  loss_dice_3: 2.271  loss_ce_4: 0  loss_mask_4: 0.8696  loss_dice_4: 2.273  loss_ce_5: 0  loss_mask_5: 0.8706  loss_dice_5: 2.271  loss_ce_6: 0  loss_mask_6: 0.8667  loss_dice_6: 2.269  loss_ce_7: 0  loss_mask_7: 0.8683  loss_dice_7: 2.271  loss_ce_8: 0  loss_mask_8: 0.8701  loss_dice_8: 2.268  time: 2.0856  data_time: 0.0290  lr: 7.79e-05  max_mem: 6006M
[02/18 08:18:15] d2.utils.events INFO:  eta: 20:07:28  iter: 14559  total_loss: 30.78  loss_ce: 0  loss_mask: 0.8274  loss_dice: 2.147  loss_seg: 0.8935  loss_ce_0: 0  loss_mask_0: 0.8278  loss_dice_0: 2.225  loss_ce_1: 0  loss_mask_1: 0.822  loss_dice_1: 2.131  loss_ce_2: 0  loss_mask_2: 0.824  loss_dice_2: 2.127  loss_ce_3: 0  loss_mask_3: 0.8299  loss_dice_3: 2.119  loss_ce_4: 0  loss_mask_4: 0.8323  loss_dice_4: 2.122  loss_ce_5: 0  loss_mask_5: 0.8294  loss_dice_5: 2.128  loss_ce_6: 0  loss_mask_6: 0.8364  loss_dice_6: 2.124  loss_ce_7: 0  loss_mask_7: 0.8346  loss_dice_7: 2.125  loss_ce_8: 0  loss_mask_8: 0.8307  loss_dice_8: 2.133  time: 2.0850  data_time: 0.0295  lr: 7.7869e-05  max_mem: 6006M
[02/18 08:18:47] d2.utils.events INFO:  eta: 20:07:48  iter: 14579  total_loss: 33.08  loss_ce: 0  loss_mask: 0.8593  loss_dice: 2.302  loss_seg: 1.071  loss_ce_0: 0  loss_mask_0: 0.8629  loss_dice_0: 2.379  loss_ce_1: 0  loss_mask_1: 0.863  loss_dice_1: 2.3  loss_ce_2: 0  loss_mask_2: 0.8649  loss_dice_2: 2.296  loss_ce_3: 0  loss_mask_3: 0.8646  loss_dice_3: 2.291  loss_ce_4: 0  loss_mask_4: 0.862  loss_dice_4: 2.296  loss_ce_5: 0  loss_mask_5: 0.8606  loss_dice_5: 2.295  loss_ce_6: 0  loss_mask_6: 0.8651  loss_dice_6: 2.288  loss_ce_7: 0  loss_mask_7: 0.86  loss_dice_7: 2.293  loss_ce_8: 0  loss_mask_8: 0.86  loss_dice_8: 2.295  time: 2.0844  data_time: 0.0349  lr: 7.7839e-05  max_mem: 6006M
[02/18 08:19:20] d2.utils.events INFO:  eta: 20:07:05  iter: 14599  total_loss: 32.7  loss_ce: 0  loss_mask: 0.8323  loss_dice: 2.323  loss_seg: 0.9011  loss_ce_0: 0  loss_mask_0: 0.8466  loss_dice_0: 2.367  loss_ce_1: 0  loss_mask_1: 0.8351  loss_dice_1: 2.341  loss_ce_2: 0  loss_mask_2: 0.8295  loss_dice_2: 2.312  loss_ce_3: 0  loss_mask_3: 0.8307  loss_dice_3: 2.306  loss_ce_4: 0  loss_mask_4: 0.8317  loss_dice_4: 2.31  loss_ce_5: 0  loss_mask_5: 0.8287  loss_dice_5: 2.31  loss_ce_6: 0  loss_mask_6: 0.8361  loss_dice_6: 2.304  loss_ce_7: 0  loss_mask_7: 0.835  loss_dice_7: 2.311  loss_ce_8: 0  loss_mask_8: 0.8368  loss_dice_8: 2.31  time: 2.0837  data_time: 0.0303  lr: 7.7808e-05  max_mem: 6006M
[02/18 08:19:50] d2.utils.events INFO:  eta: 20:05:42  iter: 14619  total_loss: 33.74  loss_ce: 0  loss_mask: 0.8816  loss_dice: 2.36  loss_seg: 1.053  loss_ce_0: 0  loss_mask_0: 0.8887  loss_dice_0: 2.41  loss_ce_1: 0  loss_mask_1: 0.8903  loss_dice_1: 2.366  loss_ce_2: 0  loss_mask_2: 0.8889  loss_dice_2: 2.347  loss_ce_3: 0  loss_mask_3: 0.892  loss_dice_3: 2.337  loss_ce_4: 0  loss_mask_4: 0.8914  loss_dice_4: 2.333  loss_ce_5: 0  loss_mask_5: 0.8894  loss_dice_5: 2.341  loss_ce_6: 0  loss_mask_6: 0.8888  loss_dice_6: 2.342  loss_ce_7: 0  loss_mask_7: 0.8879  loss_dice_7: 2.348  loss_ce_8: 0  loss_mask_8: 0.8894  loss_dice_8: 2.343  time: 2.0829  data_time: 0.0330  lr: 7.7777e-05  max_mem: 6006M
[02/18 08:20:23] d2.utils.events INFO:  eta: 20:05:10  iter: 14639  total_loss: 32.3  loss_ce: 0  loss_mask: 0.8285  loss_dice: 2.273  loss_seg: 0.8617  loss_ce_0: 0  loss_mask_0: 0.8229  loss_dice_0: 2.361  loss_ce_1: 0  loss_mask_1: 0.8199  loss_dice_1: 2.268  loss_ce_2: 0  loss_mask_2: 0.8212  loss_dice_2: 2.266  loss_ce_3: 0  loss_mask_3: 0.8247  loss_dice_3: 2.264  loss_ce_4: 0  loss_mask_4: 0.8303  loss_dice_4: 2.257  loss_ce_5: 0  loss_mask_5: 0.8294  loss_dice_5: 2.257  loss_ce_6: 0  loss_mask_6: 0.8298  loss_dice_6: 2.266  loss_ce_7: 0  loss_mask_7: 0.8254  loss_dice_7: 2.258  loss_ce_8: 0  loss_mask_8: 0.8299  loss_dice_8: 2.26  time: 2.0823  data_time: 0.0324  lr: 7.7746e-05  max_mem: 6006M
[02/18 08:20:56] d2.utils.events INFO:  eta: 20:04:23  iter: 14659  total_loss: 33.78  loss_ce: 0  loss_mask: 0.8595  loss_dice: 2.404  loss_seg: 1.051  loss_ce_0: 0  loss_mask_0: 0.8604  loss_dice_0: 2.46  loss_ce_1: 0  loss_mask_1: 0.87  loss_dice_1: 2.413  loss_ce_2: 0  loss_mask_2: 0.8699  loss_dice_2: 2.393  loss_ce_3: 0  loss_mask_3: 0.8669  loss_dice_3: 2.381  loss_ce_4: 0  loss_mask_4: 0.8685  loss_dice_4: 2.383  loss_ce_5: 0  loss_mask_5: 0.8682  loss_dice_5: 2.396  loss_ce_6: 0  loss_mask_6: 0.8653  loss_dice_6: 2.39  loss_ce_7: 0  loss_mask_7: 0.8677  loss_dice_7: 2.387  loss_ce_8: 0  loss_mask_8: 0.8636  loss_dice_8: 2.392  time: 2.0817  data_time: 0.0302  lr: 7.7715e-05  max_mem: 6006M
[02/18 08:21:30] d2.utils.events INFO:  eta: 20:04:02  iter: 14679  total_loss: 34.46  loss_ce: 0  loss_mask: 0.909  loss_dice: 2.394  loss_seg: 0.9421  loss_ce_0: 0  loss_mask_0: 0.929  loss_dice_0: 2.436  loss_ce_1: 0  loss_mask_1: 0.9179  loss_dice_1: 2.394  loss_ce_2: 0  loss_mask_2: 0.9192  loss_dice_2: 2.389  loss_ce_3: 0  loss_mask_3: 0.9151  loss_dice_3: 2.382  loss_ce_4: 0  loss_mask_4: 0.9141  loss_dice_4: 2.384  loss_ce_5: 0  loss_mask_5: 0.9118  loss_dice_5: 2.387  loss_ce_6: 0  loss_mask_6: 0.9112  loss_dice_6: 2.385  loss_ce_7: 0  loss_mask_7: 0.9131  loss_dice_7: 2.385  loss_ce_8: 0  loss_mask_8: 0.9096  loss_dice_8: 2.385  time: 2.0812  data_time: 0.0265  lr: 7.7684e-05  max_mem: 6006M
[02/18 08:22:03] d2.utils.events INFO:  eta: 20:05:36  iter: 14699  total_loss: 33.38  loss_ce: 0  loss_mask: 0.8589  loss_dice: 2.361  loss_seg: 0.9644  loss_ce_0: 0  loss_mask_0: 0.8753  loss_dice_0: 2.408  loss_ce_1: 0  loss_mask_1: 0.8634  loss_dice_1: 2.379  loss_ce_2: 0  loss_mask_2: 0.8619  loss_dice_2: 2.362  loss_ce_3: 0  loss_mask_3: 0.8681  loss_dice_3: 2.355  loss_ce_4: 0  loss_mask_4: 0.8664  loss_dice_4: 2.35  loss_ce_5: 0  loss_mask_5: 0.8585  loss_dice_5: 2.352  loss_ce_6: 0  loss_mask_6: 0.8659  loss_dice_6: 2.343  loss_ce_7: 0  loss_mask_7: 0.8645  loss_dice_7: 2.35  loss_ce_8: 0  loss_mask_8: 0.8628  loss_dice_8: 2.34  time: 2.0806  data_time: 0.0273  lr: 7.7653e-05  max_mem: 6006M
[02/18 08:22:35] d2.utils.events INFO:  eta: 20:03:13  iter: 14719  total_loss: 32.59  loss_ce: 0  loss_mask: 0.8464  loss_dice: 2.331  loss_seg: 0.7875  loss_ce_0: 0  loss_mask_0: 0.8309  loss_dice_0: 2.405  loss_ce_1: 0  loss_mask_1: 0.8565  loss_dice_1: 2.34  loss_ce_2: 0  loss_mask_2: 0.8541  loss_dice_2: 2.331  loss_ce_3: 0  loss_mask_3: 0.8547  loss_dice_3: 2.318  loss_ce_4: 0  loss_mask_4: 0.8516  loss_dice_4: 2.315  loss_ce_5: 0  loss_mask_5: 0.8529  loss_dice_5: 2.323  loss_ce_6: 0  loss_mask_6: 0.8529  loss_dice_6: 2.32  loss_ce_7: 0  loss_mask_7: 0.8492  loss_dice_7: 2.318  loss_ce_8: 0  loss_mask_8: 0.8512  loss_dice_8: 2.322  time: 2.0799  data_time: 0.0338  lr: 7.7623e-05  max_mem: 6006M
[02/18 08:23:06] d2.utils.events INFO:  eta: 20:02:41  iter: 14739  total_loss: 32.67  loss_ce: 0  loss_mask: 0.8394  loss_dice: 2.289  loss_seg: 1.096  loss_ce_0: 0  loss_mask_0: 0.8447  loss_dice_0: 2.344  loss_ce_1: 0  loss_mask_1: 0.8417  loss_dice_1: 2.298  loss_ce_2: 0  loss_mask_2: 0.8388  loss_dice_2: 2.273  loss_ce_3: 0  loss_mask_3: 0.8451  loss_dice_3: 2.274  loss_ce_4: 0  loss_mask_4: 0.8505  loss_dice_4: 2.273  loss_ce_5: 0  loss_mask_5: 0.8485  loss_dice_5: 2.274  loss_ce_6: 0  loss_mask_6: 0.8491  loss_dice_6: 2.263  loss_ce_7: 0  loss_mask_7: 0.8525  loss_dice_7: 2.273  loss_ce_8: 0  loss_mask_8: 0.8488  loss_dice_8: 2.272  time: 2.0793  data_time: 0.0338  lr: 7.7592e-05  max_mem: 6006M
[02/18 08:23:39] d2.utils.events INFO:  eta: 20:01:44  iter: 14759  total_loss: 31.99  loss_ce: 0  loss_mask: 0.8423  loss_dice: 2.212  loss_seg: 1.091  loss_ce_0: 0  loss_mask_0: 0.8553  loss_dice_0: 2.284  loss_ce_1: 0  loss_mask_1: 0.8575  loss_dice_1: 2.212  loss_ce_2: 0  loss_mask_2: 0.8541  loss_dice_2: 2.202  loss_ce_3: 0  loss_mask_3: 0.8509  loss_dice_3: 2.199  loss_ce_4: 0  loss_mask_4: 0.8465  loss_dice_4: 2.195  loss_ce_5: 0  loss_mask_5: 0.8482  loss_dice_5: 2.195  loss_ce_6: 0  loss_mask_6: 0.8487  loss_dice_6: 2.196  loss_ce_7: 0  loss_mask_7: 0.8523  loss_dice_7: 2.193  loss_ce_8: 0  loss_mask_8: 0.8511  loss_dice_8: 2.196  time: 2.0786  data_time: 0.0279  lr: 7.7561e-05  max_mem: 6006M
[02/18 08:24:12] d2.utils.events INFO:  eta: 20:01:12  iter: 14779  total_loss: 33.77  loss_ce: 0  loss_mask: 0.8637  loss_dice: 2.39  loss_seg: 1.061  loss_ce_0: 0  loss_mask_0: 0.8835  loss_dice_0: 2.426  loss_ce_1: 0  loss_mask_1: 0.8747  loss_dice_1: 2.385  loss_ce_2: 0  loss_mask_2: 0.8738  loss_dice_2: 2.37  loss_ce_3: 0  loss_mask_3: 0.8716  loss_dice_3: 2.365  loss_ce_4: 0  loss_mask_4: 0.8726  loss_dice_4: 2.368  loss_ce_5: 0  loss_mask_5: 0.8754  loss_dice_5: 2.372  loss_ce_6: 0  loss_mask_6: 0.8756  loss_dice_6: 2.369  loss_ce_7: 0  loss_mask_7: 0.8743  loss_dice_7: 2.372  loss_ce_8: 0  loss_mask_8: 0.8725  loss_dice_8: 2.371  time: 2.0780  data_time: 0.0278  lr: 7.753e-05  max_mem: 6006M
[02/18 08:24:43] d2.utils.events INFO:  eta: 20:00:19  iter: 14799  total_loss: 33.19  loss_ce: 0  loss_mask: 0.8598  loss_dice: 2.304  loss_seg: 1.029  loss_ce_0: 0  loss_mask_0: 0.8575  loss_dice_0: 2.357  loss_ce_1: 0  loss_mask_1: 0.8589  loss_dice_1: 2.311  loss_ce_2: 0  loss_mask_2: 0.8558  loss_dice_2: 2.301  loss_ce_3: 0  loss_mask_3: 0.8566  loss_dice_3: 2.294  loss_ce_4: 0  loss_mask_4: 0.8556  loss_dice_4: 2.294  loss_ce_5: 0  loss_mask_5: 0.8586  loss_dice_5: 2.299  loss_ce_6: 0  loss_mask_6: 0.8571  loss_dice_6: 2.301  loss_ce_7: 0  loss_mask_7: 0.8574  loss_dice_7: 2.298  loss_ce_8: 0  loss_mask_8: 0.8627  loss_dice_8: 2.287  time: 2.0774  data_time: 0.0290  lr: 7.7499e-05  max_mem: 6006M
[02/18 08:25:17] d2.utils.events INFO:  eta: 20:00:18  iter: 14819  total_loss: 31.83  loss_ce: 0  loss_mask: 0.7963  loss_dice: 2.197  loss_seg: 0.9958  loss_ce_0: 0  loss_mask_0: 0.8004  loss_dice_0: 2.281  loss_ce_1: 0  loss_mask_1: 0.8022  loss_dice_1: 2.203  loss_ce_2: 0  loss_mask_2: 0.8023  loss_dice_2: 2.185  loss_ce_3: 0  loss_mask_3: 0.7987  loss_dice_3: 2.178  loss_ce_4: 0  loss_mask_4: 0.8009  loss_dice_4: 2.183  loss_ce_5: 0  loss_mask_5: 0.8047  loss_dice_5: 2.184  loss_ce_6: 0  loss_mask_6: 0.7995  loss_dice_6: 2.18  loss_ce_7: 0  loss_mask_7: 0.8003  loss_dice_7: 2.182  loss_ce_8: 0  loss_mask_8: 0.8028  loss_dice_8: 2.186  time: 2.0769  data_time: 0.0275  lr: 7.7468e-05  max_mem: 6006M
[02/18 08:25:50] d2.utils.events INFO:  eta: 19:59:46  iter: 14839  total_loss: 31.62  loss_ce: 0  loss_mask: 0.837  loss_dice: 2.233  loss_seg: 1.001  loss_ce_0: 0  loss_mask_0: 0.8318  loss_dice_0: 2.344  loss_ce_1: 0  loss_mask_1: 0.837  loss_dice_1: 2.252  loss_ce_2: 0  loss_mask_2: 0.839  loss_dice_2: 2.229  loss_ce_3: 0  loss_mask_3: 0.8444  loss_dice_3: 2.217  loss_ce_4: 0  loss_mask_4: 0.8446  loss_dice_4: 2.212  loss_ce_5: 0  loss_mask_5: 0.849  loss_dice_5: 2.21  loss_ce_6: 0  loss_mask_6: 0.8452  loss_dice_6: 2.209  loss_ce_7: 0  loss_mask_7: 0.8479  loss_dice_7: 2.213  loss_ce_8: 0  loss_mask_8: 0.8439  loss_dice_8: 2.214  time: 2.0762  data_time: 0.0366  lr: 7.7437e-05  max_mem: 6006M
[02/18 08:26:22] d2.utils.events INFO:  eta: 19:58:43  iter: 14859  total_loss: 31.88  loss_ce: 0  loss_mask: 0.8563  loss_dice: 2.252  loss_seg: 0.9063  loss_ce_0: 0  loss_mask_0: 0.8709  loss_dice_0: 2.317  loss_ce_1: 0  loss_mask_1: 0.8578  loss_dice_1: 2.274  loss_ce_2: 0  loss_mask_2: 0.8529  loss_dice_2: 2.245  loss_ce_3: 0  loss_mask_3: 0.8576  loss_dice_3: 2.237  loss_ce_4: 0  loss_mask_4: 0.8564  loss_dice_4: 2.234  loss_ce_5: 0  loss_mask_5: 0.8562  loss_dice_5: 2.237  loss_ce_6: 0  loss_mask_6: 0.859  loss_dice_6: 2.239  loss_ce_7: 0  loss_mask_7: 0.86  loss_dice_7: 2.245  loss_ce_8: 0  loss_mask_8: 0.8582  loss_dice_8: 2.236  time: 2.0756  data_time: 0.0289  lr: 7.7407e-05  max_mem: 6006M
[02/18 08:26:55] d2.utils.events INFO:  eta: 19:56:57  iter: 14879  total_loss: 32.71  loss_ce: 0  loss_mask: 0.8855  loss_dice: 2.253  loss_seg: 0.8465  loss_ce_0: 0  loss_mask_0: 0.8975  loss_dice_0: 2.291  loss_ce_1: 0  loss_mask_1: 0.8809  loss_dice_1: 2.258  loss_ce_2: 0  loss_mask_2: 0.8803  loss_dice_2: 2.247  loss_ce_3: 0  loss_mask_3: 0.8816  loss_dice_3: 2.24  loss_ce_4: 0  loss_mask_4: 0.8819  loss_dice_4: 2.238  loss_ce_5: 0  loss_mask_5: 0.8793  loss_dice_5: 2.245  loss_ce_6: 0  loss_mask_6: 0.8826  loss_dice_6: 2.237  loss_ce_7: 0  loss_mask_7: 0.8795  loss_dice_7: 2.24  loss_ce_8: 0  loss_mask_8: 0.8793  loss_dice_8: 2.246  time: 2.0750  data_time: 0.0307  lr: 7.7376e-05  max_mem: 6006M
[02/18 08:27:27] d2.utils.events INFO:  eta: 19:57:05  iter: 14899  total_loss: 31.8  loss_ce: 0  loss_mask: 0.8479  loss_dice: 2.243  loss_seg: 0.8514  loss_ce_0: 0  loss_mask_0: 0.8485  loss_dice_0: 2.297  loss_ce_1: 0  loss_mask_1: 0.8485  loss_dice_1: 2.248  loss_ce_2: 0  loss_mask_2: 0.8486  loss_dice_2: 2.231  loss_ce_3: 0  loss_mask_3: 0.8486  loss_dice_3: 2.23  loss_ce_4: 0  loss_mask_4: 0.8494  loss_dice_4: 2.23  loss_ce_5: 0  loss_mask_5: 0.851  loss_dice_5: 2.231  loss_ce_6: 0  loss_mask_6: 0.8521  loss_dice_6: 2.23  loss_ce_7: 0  loss_mask_7: 0.8498  loss_dice_7: 2.226  loss_ce_8: 0  loss_mask_8: 0.8511  loss_dice_8: 2.23  time: 2.0744  data_time: 0.0225  lr: 7.7345e-05  max_mem: 6006M
[02/18 08:27:56] d2.utils.events INFO:  eta: 19:55:53  iter: 14919  total_loss: 31.76  loss_ce: 0  loss_mask: 0.8618  loss_dice: 2.251  loss_seg: 0.5987  loss_ce_0: 0  loss_mask_0: 0.88  loss_dice_0: 2.279  loss_ce_1: 0  loss_mask_1: 0.8757  loss_dice_1: 2.27  loss_ce_2: 0  loss_mask_2: 0.877  loss_dice_2: 2.247  loss_ce_3: 0  loss_mask_3: 0.8718  loss_dice_3: 2.243  loss_ce_4: 0  loss_mask_4: 0.8678  loss_dice_4: 2.24  loss_ce_5: 0  loss_mask_5: 0.8692  loss_dice_5: 2.241  loss_ce_6: 0  loss_mask_6: 0.8644  loss_dice_6: 2.243  loss_ce_7: 0  loss_mask_7: 0.8686  loss_dice_7: 2.244  loss_ce_8: 0  loss_mask_8: 0.8719  loss_dice_8: 2.246  time: 2.0736  data_time: 0.0457  lr: 7.7314e-05  max_mem: 6006M
[02/18 08:28:29] d2.utils.events INFO:  eta: 19:56:46  iter: 14939  total_loss: 32.26  loss_ce: 0  loss_mask: 0.8661  loss_dice: 2.313  loss_seg: 0.6381  loss_ce_0: 0  loss_mask_0: 0.8854  loss_dice_0: 2.368  loss_ce_1: 0  loss_mask_1: 0.8709  loss_dice_1: 2.328  loss_ce_2: 0  loss_mask_2: 0.8737  loss_dice_2: 2.318  loss_ce_3: 0  loss_mask_3: 0.8787  loss_dice_3: 2.3  loss_ce_4: 0  loss_mask_4: 0.8747  loss_dice_4: 2.297  loss_ce_5: 0  loss_mask_5: 0.8722  loss_dice_5: 2.299  loss_ce_6: 0  loss_mask_6: 0.872  loss_dice_6: 2.291  loss_ce_7: 0  loss_mask_7: 0.8744  loss_dice_7: 2.288  loss_ce_8: 0  loss_mask_8: 0.8744  loss_dice_8: 2.292  time: 2.0729  data_time: 0.0281  lr: 7.7283e-05  max_mem: 6006M
[02/18 08:29:02] d2.utils.events INFO:  eta: 19:57:23  iter: 14959  total_loss: 30.6  loss_ce: 0  loss_mask: 0.8253  loss_dice: 2.151  loss_seg: 0.834  loss_ce_0: 0  loss_mask_0: 0.8215  loss_dice_0: 2.227  loss_ce_1: 0  loss_mask_1: 0.8319  loss_dice_1: 2.158  loss_ce_2: 0  loss_mask_2: 0.8351  loss_dice_2: 2.138  loss_ce_3: 0  loss_mask_3: 0.8356  loss_dice_3: 2.128  loss_ce_4: 0  loss_mask_4: 0.8401  loss_dice_4: 2.13  loss_ce_5: 0  loss_mask_5: 0.8333  loss_dice_5: 2.13  loss_ce_6: 0  loss_mask_6: 0.8364  loss_dice_6: 2.129  loss_ce_7: 0  loss_mask_7: 0.8344  loss_dice_7: 2.128  loss_ce_8: 0  loss_mask_8: 0.8322  loss_dice_8: 2.13  time: 2.0724  data_time: 0.0332  lr: 7.7252e-05  max_mem: 6006M
[02/18 08:29:34] d2.utils.events INFO:  eta: 19:55:53  iter: 14979  total_loss: 32.64  loss_ce: 0  loss_mask: 0.853  loss_dice: 2.297  loss_seg: 0.7561  loss_ce_0: 0  loss_mask_0: 0.8631  loss_dice_0: 2.353  loss_ce_1: 0  loss_mask_1: 0.8591  loss_dice_1: 2.303  loss_ce_2: 0  loss_mask_2: 0.8619  loss_dice_2: 2.282  loss_ce_3: 0  loss_mask_3: 0.865  loss_dice_3: 2.276  loss_ce_4: 0  loss_mask_4: 0.8666  loss_dice_4: 2.278  loss_ce_5: 0  loss_mask_5: 0.87  loss_dice_5: 2.286  loss_ce_6: 0  loss_mask_6: 0.8666  loss_dice_6: 2.278  loss_ce_7: 0  loss_mask_7: 0.8614  loss_dice_7: 2.28  loss_ce_8: 0  loss_mask_8: 0.8611  loss_dice_8: 2.278  time: 2.0718  data_time: 0.0301  lr: 7.7221e-05  max_mem: 6006M
[02/18 08:30:07] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0014999.pth
[02/18 08:30:08] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 08:30:09] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 08:30:09] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 08:30:23] mask2former INFO: Inference done 11/1093. Dataloading: 0.0035 s/iter. Inference: 0.2339 s/iter. Eval: 0.1102 s/iter. Total: 0.3476 s/iter. ETA=0:06:16
[02/18 08:30:28] mask2former INFO: Inference done 26/1093. Dataloading: 0.0053 s/iter. Inference: 0.2350 s/iter. Eval: 0.1114 s/iter. Total: 0.3517 s/iter. ETA=0:06:15
[02/18 08:30:33] mask2former INFO: Inference done 40/1093. Dataloading: 0.0051 s/iter. Inference: 0.2422 s/iter. Eval: 0.1115 s/iter. Total: 0.3588 s/iter. ETA=0:06:17
[02/18 08:30:38] mask2former INFO: Inference done 54/1093. Dataloading: 0.0049 s/iter. Inference: 0.2412 s/iter. Eval: 0.1126 s/iter. Total: 0.3587 s/iter. ETA=0:06:12
[02/18 08:30:43] mask2former INFO: Inference done 69/1093. Dataloading: 0.0049 s/iter. Inference: 0.2412 s/iter. Eval: 0.1102 s/iter. Total: 0.3563 s/iter. ETA=0:06:04
[02/18 08:30:49] mask2former INFO: Inference done 84/1093. Dataloading: 0.0056 s/iter. Inference: 0.2396 s/iter. Eval: 0.1092 s/iter. Total: 0.3545 s/iter. ETA=0:05:57
[02/18 08:30:54] mask2former INFO: Inference done 99/1093. Dataloading: 0.0055 s/iter. Inference: 0.2375 s/iter. Eval: 0.1094 s/iter. Total: 0.3525 s/iter. ETA=0:05:50
[02/18 08:30:59] mask2former INFO: Inference done 114/1093. Dataloading: 0.0054 s/iter. Inference: 0.2370 s/iter. Eval: 0.1087 s/iter. Total: 0.3511 s/iter. ETA=0:05:43
[02/18 08:31:04] mask2former INFO: Inference done 129/1093. Dataloading: 0.0053 s/iter. Inference: 0.2358 s/iter. Eval: 0.1088 s/iter. Total: 0.3501 s/iter. ETA=0:05:37
[02/18 08:31:09] mask2former INFO: Inference done 143/1093. Dataloading: 0.0054 s/iter. Inference: 0.2358 s/iter. Eval: 0.1102 s/iter. Total: 0.3514 s/iter. ETA=0:05:33
[02/18 08:31:14] mask2former INFO: Inference done 157/1093. Dataloading: 0.0054 s/iter. Inference: 0.2375 s/iter. Eval: 0.1099 s/iter. Total: 0.3529 s/iter. ETA=0:05:30
[02/18 08:31:19] mask2former INFO: Inference done 171/1093. Dataloading: 0.0054 s/iter. Inference: 0.2370 s/iter. Eval: 0.1109 s/iter. Total: 0.3534 s/iter. ETA=0:05:25
[02/18 08:31:24] mask2former INFO: Inference done 185/1093. Dataloading: 0.0054 s/iter. Inference: 0.2380 s/iter. Eval: 0.1112 s/iter. Total: 0.3546 s/iter. ETA=0:05:22
[02/18 08:31:30] mask2former INFO: Inference done 200/1093. Dataloading: 0.0054 s/iter. Inference: 0.2374 s/iter. Eval: 0.1115 s/iter. Total: 0.3543 s/iter. ETA=0:05:16
[02/18 08:31:35] mask2former INFO: Inference done 214/1093. Dataloading: 0.0054 s/iter. Inference: 0.2373 s/iter. Eval: 0.1124 s/iter. Total: 0.3551 s/iter. ETA=0:05:12
[02/18 08:31:40] mask2former INFO: Inference done 227/1093. Dataloading: 0.0053 s/iter. Inference: 0.2390 s/iter. Eval: 0.1133 s/iter. Total: 0.3577 s/iter. ETA=0:05:09
[02/18 08:31:45] mask2former INFO: Inference done 241/1093. Dataloading: 0.0053 s/iter. Inference: 0.2393 s/iter. Eval: 0.1134 s/iter. Total: 0.3581 s/iter. ETA=0:05:05
[02/18 08:31:50] mask2former INFO: Inference done 255/1093. Dataloading: 0.0053 s/iter. Inference: 0.2393 s/iter. Eval: 0.1136 s/iter. Total: 0.3583 s/iter. ETA=0:05:00
[02/18 08:31:55] mask2former INFO: Inference done 269/1093. Dataloading: 0.0053 s/iter. Inference: 0.2392 s/iter. Eval: 0.1137 s/iter. Total: 0.3583 s/iter. ETA=0:04:55
[02/18 08:32:00] mask2former INFO: Inference done 283/1093. Dataloading: 0.0053 s/iter. Inference: 0.2397 s/iter. Eval: 0.1139 s/iter. Total: 0.3591 s/iter. ETA=0:04:50
[02/18 08:32:05] mask2former INFO: Inference done 297/1093. Dataloading: 0.0054 s/iter. Inference: 0.2397 s/iter. Eval: 0.1139 s/iter. Total: 0.3591 s/iter. ETA=0:04:45
[02/18 08:32:11] mask2former INFO: Inference done 312/1093. Dataloading: 0.0054 s/iter. Inference: 0.2393 s/iter. Eval: 0.1137 s/iter. Total: 0.3584 s/iter. ETA=0:04:39
[02/18 08:32:16] mask2former INFO: Inference done 326/1093. Dataloading: 0.0055 s/iter. Inference: 0.2399 s/iter. Eval: 0.1140 s/iter. Total: 0.3595 s/iter. ETA=0:04:35
[02/18 08:32:21] mask2former INFO: Inference done 339/1093. Dataloading: 0.0056 s/iter. Inference: 0.2406 s/iter. Eval: 0.1146 s/iter. Total: 0.3608 s/iter. ETA=0:04:32
[02/18 08:32:26] mask2former INFO: Inference done 353/1093. Dataloading: 0.0056 s/iter. Inference: 0.2409 s/iter. Eval: 0.1148 s/iter. Total: 0.3614 s/iter. ETA=0:04:27
[02/18 08:32:32] mask2former INFO: Inference done 367/1093. Dataloading: 0.0055 s/iter. Inference: 0.2411 s/iter. Eval: 0.1148 s/iter. Total: 0.3616 s/iter. ETA=0:04:22
[02/18 08:32:37] mask2former INFO: Inference done 381/1093. Dataloading: 0.0055 s/iter. Inference: 0.2412 s/iter. Eval: 0.1148 s/iter. Total: 0.3616 s/iter. ETA=0:04:17
[02/18 08:32:42] mask2former INFO: Inference done 395/1093. Dataloading: 0.0055 s/iter. Inference: 0.2415 s/iter. Eval: 0.1150 s/iter. Total: 0.3621 s/iter. ETA=0:04:12
[02/18 08:32:47] mask2former INFO: Inference done 409/1093. Dataloading: 0.0055 s/iter. Inference: 0.2417 s/iter. Eval: 0.1149 s/iter. Total: 0.3621 s/iter. ETA=0:04:07
[02/18 08:32:52] mask2former INFO: Inference done 424/1093. Dataloading: 0.0054 s/iter. Inference: 0.2409 s/iter. Eval: 0.1148 s/iter. Total: 0.3612 s/iter. ETA=0:04:01
[02/18 08:32:57] mask2former INFO: Inference done 439/1093. Dataloading: 0.0055 s/iter. Inference: 0.2406 s/iter. Eval: 0.1150 s/iter. Total: 0.3612 s/iter. ETA=0:03:56
[02/18 08:33:02] mask2former INFO: Inference done 454/1093. Dataloading: 0.0054 s/iter. Inference: 0.2401 s/iter. Eval: 0.1147 s/iter. Total: 0.3604 s/iter. ETA=0:03:50
[02/18 08:33:08] mask2former INFO: Inference done 469/1093. Dataloading: 0.0054 s/iter. Inference: 0.2400 s/iter. Eval: 0.1147 s/iter. Total: 0.3603 s/iter. ETA=0:03:44
[02/18 08:33:13] mask2former INFO: Inference done 483/1093. Dataloading: 0.0054 s/iter. Inference: 0.2398 s/iter. Eval: 0.1149 s/iter. Total: 0.3603 s/iter. ETA=0:03:39
[02/18 08:33:18] mask2former INFO: Inference done 498/1093. Dataloading: 0.0054 s/iter. Inference: 0.2395 s/iter. Eval: 0.1148 s/iter. Total: 0.3599 s/iter. ETA=0:03:34
[02/18 08:33:23] mask2former INFO: Inference done 511/1093. Dataloading: 0.0054 s/iter. Inference: 0.2400 s/iter. Eval: 0.1150 s/iter. Total: 0.3606 s/iter. ETA=0:03:29
[02/18 08:33:28] mask2former INFO: Inference done 525/1093. Dataloading: 0.0054 s/iter. Inference: 0.2404 s/iter. Eval: 0.1150 s/iter. Total: 0.3609 s/iter. ETA=0:03:24
[02/18 08:33:33] mask2former INFO: Inference done 539/1093. Dataloading: 0.0055 s/iter. Inference: 0.2404 s/iter. Eval: 0.1151 s/iter. Total: 0.3612 s/iter. ETA=0:03:20
[02/18 08:33:39] mask2former INFO: Inference done 554/1093. Dataloading: 0.0055 s/iter. Inference: 0.2401 s/iter. Eval: 0.1151 s/iter. Total: 0.3609 s/iter. ETA=0:03:14
[02/18 08:33:44] mask2former INFO: Inference done 569/1093. Dataloading: 0.0054 s/iter. Inference: 0.2399 s/iter. Eval: 0.1152 s/iter. Total: 0.3607 s/iter. ETA=0:03:08
[02/18 08:33:49] mask2former INFO: Inference done 583/1093. Dataloading: 0.0054 s/iter. Inference: 0.2398 s/iter. Eval: 0.1156 s/iter. Total: 0.3609 s/iter. ETA=0:03:04
[02/18 08:33:54] mask2former INFO: Inference done 597/1093. Dataloading: 0.0054 s/iter. Inference: 0.2398 s/iter. Eval: 0.1159 s/iter. Total: 0.3612 s/iter. ETA=0:02:59
[02/18 08:34:00] mask2former INFO: Inference done 611/1093. Dataloading: 0.0054 s/iter. Inference: 0.2399 s/iter. Eval: 0.1161 s/iter. Total: 0.3616 s/iter. ETA=0:02:54
[02/18 08:34:05] mask2former INFO: Inference done 625/1093. Dataloading: 0.0055 s/iter. Inference: 0.2400 s/iter. Eval: 0.1162 s/iter. Total: 0.3617 s/iter. ETA=0:02:49
[02/18 08:34:10] mask2former INFO: Inference done 639/1093. Dataloading: 0.0054 s/iter. Inference: 0.2398 s/iter. Eval: 0.1163 s/iter. Total: 0.3617 s/iter. ETA=0:02:44
[02/18 08:34:15] mask2former INFO: Inference done 653/1093. Dataloading: 0.0054 s/iter. Inference: 0.2399 s/iter. Eval: 0.1164 s/iter. Total: 0.3618 s/iter. ETA=0:02:39
[02/18 08:34:20] mask2former INFO: Inference done 667/1093. Dataloading: 0.0054 s/iter. Inference: 0.2404 s/iter. Eval: 0.1163 s/iter. Total: 0.3622 s/iter. ETA=0:02:34
[02/18 08:34:26] mask2former INFO: Inference done 680/1093. Dataloading: 0.0054 s/iter. Inference: 0.2408 s/iter. Eval: 0.1164 s/iter. Total: 0.3628 s/iter. ETA=0:02:29
[02/18 08:34:31] mask2former INFO: Inference done 693/1093. Dataloading: 0.0054 s/iter. Inference: 0.2410 s/iter. Eval: 0.1168 s/iter. Total: 0.3634 s/iter. ETA=0:02:25
[02/18 08:34:36] mask2former INFO: Inference done 708/1093. Dataloading: 0.0054 s/iter. Inference: 0.2407 s/iter. Eval: 0.1170 s/iter. Total: 0.3632 s/iter. ETA=0:02:19
[02/18 08:34:41] mask2former INFO: Inference done 721/1093. Dataloading: 0.0054 s/iter. Inference: 0.2411 s/iter. Eval: 0.1171 s/iter. Total: 0.3637 s/iter. ETA=0:02:15
[02/18 08:34:46] mask2former INFO: Inference done 736/1093. Dataloading: 0.0054 s/iter. Inference: 0.2410 s/iter. Eval: 0.1169 s/iter. Total: 0.3634 s/iter. ETA=0:02:09
[02/18 08:34:52] mask2former INFO: Inference done 751/1093. Dataloading: 0.0054 s/iter. Inference: 0.2409 s/iter. Eval: 0.1169 s/iter. Total: 0.3633 s/iter. ETA=0:02:04
[02/18 08:34:57] mask2former INFO: Inference done 765/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1168 s/iter. Total: 0.3634 s/iter. ETA=0:01:59
[02/18 08:35:02] mask2former INFO: Inference done 780/1093. Dataloading: 0.0053 s/iter. Inference: 0.2410 s/iter. Eval: 0.1168 s/iter. Total: 0.3632 s/iter. ETA=0:01:53
[02/18 08:35:07] mask2former INFO: Inference done 794/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1169 s/iter. Total: 0.3632 s/iter. ETA=0:01:48
[02/18 08:35:13] mask2former INFO: Inference done 808/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1171 s/iter. Total: 0.3635 s/iter. ETA=0:01:43
[02/18 08:35:18] mask2former INFO: Inference done 822/1093. Dataloading: 0.0053 s/iter. Inference: 0.2410 s/iter. Eval: 0.1172 s/iter. Total: 0.3637 s/iter. ETA=0:01:38
[02/18 08:35:23] mask2former INFO: Inference done 836/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1173 s/iter. Total: 0.3636 s/iter. ETA=0:01:33
[02/18 08:35:28] mask2former INFO: Inference done 849/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1175 s/iter. Total: 0.3642 s/iter. ETA=0:01:28
[02/18 08:35:33] mask2former INFO: Inference done 863/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1175 s/iter. Total: 0.3641 s/iter. ETA=0:01:23
[02/18 08:35:38] mask2former INFO: Inference done 877/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1175 s/iter. Total: 0.3640 s/iter. ETA=0:01:18
[02/18 08:35:43] mask2former INFO: Inference done 892/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1173 s/iter. Total: 0.3638 s/iter. ETA=0:01:13
[02/18 08:35:49] mask2former INFO: Inference done 907/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1173 s/iter. Total: 0.3636 s/iter. ETA=0:01:07
[02/18 08:35:54] mask2former INFO: Inference done 922/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1172 s/iter. Total: 0.3635 s/iter. ETA=0:01:02
[02/18 08:35:59] mask2former INFO: Inference done 936/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1173 s/iter. Total: 0.3635 s/iter. ETA=0:00:57
[02/18 08:36:04] mask2former INFO: Inference done 950/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1175 s/iter. Total: 0.3637 s/iter. ETA=0:00:52
[02/18 08:36:09] mask2former INFO: Inference done 964/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1174 s/iter. Total: 0.3637 s/iter. ETA=0:00:46
[02/18 08:36:15] mask2former INFO: Inference done 978/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1174 s/iter. Total: 0.3637 s/iter. ETA=0:00:41
[02/18 08:36:20] mask2former INFO: Inference done 993/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1173 s/iter. Total: 0.3635 s/iter. ETA=0:00:36
[02/18 08:36:25] mask2former INFO: Inference done 1006/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1175 s/iter. Total: 0.3638 s/iter. ETA=0:00:31
[02/18 08:36:30] mask2former INFO: Inference done 1021/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1174 s/iter. Total: 0.3636 s/iter. ETA=0:00:26
[02/18 08:36:35] mask2former INFO: Inference done 1035/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1173 s/iter. Total: 0.3636 s/iter. ETA=0:00:21
[02/18 08:36:40] mask2former INFO: Inference done 1049/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1172 s/iter. Total: 0.3635 s/iter. ETA=0:00:15
[02/18 08:36:45] mask2former INFO: Inference done 1064/1093. Dataloading: 0.0053 s/iter. Inference: 0.2407 s/iter. Eval: 0.1172 s/iter. Total: 0.3633 s/iter. ETA=0:00:10
[02/18 08:36:50] mask2former INFO: Inference done 1078/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1171 s/iter. Total: 0.3632 s/iter. ETA=0:00:05
[02/18 08:37:25] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.028623857846836, 'error_1pix': 0.4342742433869409, 'error_3pix': 0.21495246865428422, 'mIoU': 17.127319812758316, 'fwIoU': 39.757536674321095, 'IoU-1': 94.10076207563421, 'IoU-2': 0.07269216127261253, 'IoU-3': 0.026124074097027102, 'IoU-4': 0.0015663896165237236, 'IoU-5': 0.002111391378766722, 'IoU-6': 0.006100629890036146, 'IoU-7': 0.00848356309650053, 'IoU-8': 0.005714991107473837, 'IoU-9': 1.025299613541348, 'IoU-10': 11.845992388734452, 'IoU-11': 8.656232746769595, 'IoU-12': 29.399356680483873, 'IoU-13': 5.524231426875946, 'IoU-14': 4.7946807513061405, 'IoU-15': 5.566677052891103, 'IoU-16': 4.956223973050178, 'IoU-17': 9.752143690632625, 'IoU-18': 17.722305409378514, 'IoU-19': 18.99483175731111, 'IoU-20': 16.10498015635565, 'IoU-21': 15.23060851505074, 'IoU-22': 19.4279069776805, 'IoU-23': 21.541127507027454, 'IoU-24': 23.2063028723063, 'IoU-25': 30.74031371312444, 'IoU-26': 31.881258621675833, 'IoU-27': 20.09123739682485, 'IoU-28': 16.014480536949787, 'IoU-29': 20.92131566823185, 'IoU-30': 30.531280126099457, 'IoU-31': 28.556074127156204, 'IoU-32': 35.42001026451748, 'IoU-33': 17.443722916348438, 'IoU-34': 17.704586799743403, 'IoU-35': 11.818466154451574, 'IoU-36': 31.025799823286558, 'IoU-37': 16.195156778536347, 'IoU-38': 15.809019574407735, 'IoU-39': 18.78459075342724, 'IoU-40': 19.0778526827719, 'IoU-41': 16.680642206019403, 'IoU-42': 15.249607193025255, 'IoU-43': 28.36176097181675, 'IoU-44': 24.783393428177074, 'IoU-45': 17.530330142692023, 'IoU-46': 16.198775974360785, 'IoU-47': 16.222836875558258, 'IoU-48': 17.096381487707927, 'mACC': 29.375487316762904, 'pACC': 48.793640046562025, 'ACC-1': 97.63785916363057, 'ACC-2': 0.07269291427136872, 'ACC-3': 0.02896960200630353, 'ACC-4': 0.001616915422885572, 'ACC-5': 0.0022056325974852847, 'ACC-6': 0.006588070979876737, 'ACC-7': 0.009459670876220206, 'ACC-8': 0.006172199426232341, 'ACC-9': 70.55460126194647, 'ACC-10': 16.94542026758374, 'ACC-11': 10.013061463969954, 'ACC-12': 86.40930362671058, 'ACC-13': 10.978150806571023, 'ACC-14': 9.260710874184369, 'ACC-15': 8.583449446962256, 'ACC-16': 7.040687566963198, 'ACC-17': 14.498766801259727, 'ACC-18': 28.018584265405956, 'ACC-19': 34.69366878768119, 'ACC-20': 28.846970333239096, 'ACC-21': 25.173790798216206, 'ACC-22': 29.46180115516069, 'ACC-23': 33.535954848655805, 'ACC-24': 36.287156463743116, 'ACC-25': 49.15501150693146, 'ACC-26': 60.411489211510684, 'ACC-27': 36.29847861378816, 'ACC-28': 24.90045201488085, 'ACC-29': 29.45692050926507, 'ACC-30': 42.81194809320564, 'ACC-31': 37.45645980269365, 'ACC-32': 68.63069472920816, 'ACC-33': 23.989257256774092, 'ACC-34': 21.63724155942172, 'ACC-35': 16.184037645151353, 'ACC-36': 78.24202354740567, 'ACC-37': 28.547578807762903, 'ACC-38': 24.549646902470602, 'ACC-39': 28.109303367387138, 'ACC-40': 27.95755666229421, 'ACC-41': 24.358129007462065, 'ACC-42': 24.06923151205838, 'ACC-43': 59.66546568272767, 'ACC-44': 46.36653571318771, 'ACC-45': 28.511049256121286, 'ACC-46': 25.768434944942125, 'ACC-47': 26.569032764025234, 'ACC-48': 28.309769156479287})])
[02/18 08:37:25] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 08:37:25] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 08:37:25] d2.evaluation.testing INFO: copypaste: 3.0286,0.4343,0.2150,17.1273,39.7575,29.3755,48.7936
[02/18 08:37:25] d2.utils.events INFO:  eta: 19:58:05  iter: 14999  total_loss: 32.5  loss_ce: 0  loss_mask: 0.8576  loss_dice: 2.261  loss_seg: 0.8027  loss_ce_0: 0  loss_mask_0: 0.8802  loss_dice_0: 2.307  loss_ce_1: 0  loss_mask_1: 0.8497  loss_dice_1: 2.276  loss_ce_2: 0  loss_mask_2: 0.8531  loss_dice_2: 2.254  loss_ce_3: 0  loss_mask_3: 0.859  loss_dice_3: 2.251  loss_ce_4: 0  loss_mask_4: 0.8576  loss_dice_4: 2.257  loss_ce_5: 0  loss_mask_5: 0.8616  loss_dice_5: 2.248  loss_ce_6: 0  loss_mask_6: 0.8582  loss_dice_6: 2.249  loss_ce_7: 0  loss_mask_7: 0.8574  loss_dice_7: 2.261  loss_ce_8: 0  loss_mask_8: 0.8579  loss_dice_8: 2.253  time: 2.0712  data_time: 0.0235  lr: 7.719e-05  max_mem: 6006M
[02/18 08:37:58] d2.utils.events INFO:  eta: 19:56:25  iter: 15019  total_loss: 33.75  loss_ce: 0  loss_mask: 0.8625  loss_dice: 2.379  loss_seg: 1.038  loss_ce_0: 0  loss_mask_0: 0.8672  loss_dice_0: 2.436  loss_ce_1: 0  loss_mask_1: 0.8612  loss_dice_1: 2.401  loss_ce_2: 0  loss_mask_2: 0.8614  loss_dice_2: 2.39  loss_ce_3: 0  loss_mask_3: 0.8675  loss_dice_3: 2.37  loss_ce_4: 0  loss_mask_4: 0.8629  loss_dice_4: 2.373  loss_ce_5: 0  loss_mask_5: 0.8602  loss_dice_5: 2.376  loss_ce_6: 0  loss_mask_6: 0.8649  loss_dice_6: 2.364  loss_ce_7: 0  loss_mask_7: 0.8636  loss_dice_7: 2.375  loss_ce_8: 0  loss_mask_8: 0.8647  loss_dice_8: 2.37  time: 2.0706  data_time: 0.0288  lr: 7.716e-05  max_mem: 6006M
[02/18 08:38:31] d2.utils.events INFO:  eta: 19:55:53  iter: 15039  total_loss: 32.9  loss_ce: 0  loss_mask: 0.846  loss_dice: 2.262  loss_seg: 0.8541  loss_ce_0: 0  loss_mask_0: 0.872  loss_dice_0: 2.305  loss_ce_1: 0  loss_mask_1: 0.8557  loss_dice_1: 2.269  loss_ce_2: 0  loss_mask_2: 0.8607  loss_dice_2: 2.257  loss_ce_3: 0  loss_mask_3: 0.8549  loss_dice_3: 2.254  loss_ce_4: 0  loss_mask_4: 0.8473  loss_dice_4: 2.258  loss_ce_5: 0  loss_mask_5: 0.849  loss_dice_5: 2.253  loss_ce_6: 0  loss_mask_6: 0.8493  loss_dice_6: 2.248  loss_ce_7: 0  loss_mask_7: 0.8449  loss_dice_7: 2.25  loss_ce_8: 0  loss_mask_8: 0.8453  loss_dice_8: 2.252  time: 2.0700  data_time: 0.0341  lr: 7.7129e-05  max_mem: 6006M
[02/18 08:39:05] d2.utils.events INFO:  eta: 19:57:24  iter: 15059  total_loss: 32.93  loss_ce: 0  loss_mask: 0.8798  loss_dice: 2.293  loss_seg: 1.086  loss_ce_0: 0  loss_mask_0: 0.8832  loss_dice_0: 2.331  loss_ce_1: 0  loss_mask_1: 0.8768  loss_dice_1: 2.307  loss_ce_2: 0  loss_mask_2: 0.8788  loss_dice_2: 2.296  loss_ce_3: 0  loss_mask_3: 0.8781  loss_dice_3: 2.283  loss_ce_4: 0  loss_mask_4: 0.8822  loss_dice_4: 2.286  loss_ce_5: 0  loss_mask_5: 0.8829  loss_dice_5: 2.285  loss_ce_6: 0  loss_mask_6: 0.8797  loss_dice_6: 2.277  loss_ce_7: 0  loss_mask_7: 0.8795  loss_dice_7: 2.281  loss_ce_8: 0  loss_mask_8: 0.8818  loss_dice_8: 2.276  time: 2.0696  data_time: 0.0314  lr: 7.7098e-05  max_mem: 6006M
[02/18 08:39:38] d2.utils.events INFO:  eta: 19:56:19  iter: 15079  total_loss: 34.73  loss_ce: 0  loss_mask: 0.8744  loss_dice: 2.442  loss_seg: 1.071  loss_ce_0: 0  loss_mask_0: 0.8862  loss_dice_0: 2.522  loss_ce_1: 0  loss_mask_1: 0.8746  loss_dice_1: 2.451  loss_ce_2: 0  loss_mask_2: 0.8739  loss_dice_2: 2.437  loss_ce_3: 0  loss_mask_3: 0.8756  loss_dice_3: 2.437  loss_ce_4: 0  loss_mask_4: 0.8765  loss_dice_4: 2.437  loss_ce_5: 0  loss_mask_5: 0.8763  loss_dice_5: 2.431  loss_ce_6: 0  loss_mask_6: 0.878  loss_dice_6: 2.434  loss_ce_7: 0  loss_mask_7: 0.8835  loss_dice_7: 2.435  loss_ce_8: 0  loss_mask_8: 0.8772  loss_dice_8: 2.436  time: 2.0690  data_time: 0.0239  lr: 7.7067e-05  max_mem: 6006M
[02/18 08:40:11] d2.utils.events INFO:  eta: 19:54:49  iter: 15099  total_loss: 31.04  loss_ce: 0  loss_mask: 0.8202  loss_dice: 2.186  loss_seg: 0.8146  loss_ce_0: 0  loss_mask_0: 0.8204  loss_dice_0: 2.252  loss_ce_1: 0  loss_mask_1: 0.8285  loss_dice_1: 2.196  loss_ce_2: 0  loss_mask_2: 0.8267  loss_dice_2: 2.177  loss_ce_3: 0  loss_mask_3: 0.8237  loss_dice_3: 2.175  loss_ce_4: 0  loss_mask_4: 0.8199  loss_dice_4: 2.179  loss_ce_5: 0  loss_mask_5: 0.8216  loss_dice_5: 2.169  loss_ce_6: 0  loss_mask_6: 0.8196  loss_dice_6: 2.176  loss_ce_7: 0  loss_mask_7: 0.8215  loss_dice_7: 2.182  loss_ce_8: 0  loss_mask_8: 0.8203  loss_dice_8: 2.184  time: 2.0684  data_time: 0.0314  lr: 7.7036e-05  max_mem: 6006M
[02/18 08:40:46] d2.utils.events INFO:  eta: 19:55:38  iter: 15119  total_loss: 32.27  loss_ce: 0  loss_mask: 0.887  loss_dice: 2.275  loss_seg: 1.2  loss_ce_0: 0  loss_mask_0: 0.8888  loss_dice_0: 2.347  loss_ce_1: 0  loss_mask_1: 0.8885  loss_dice_1: 2.287  loss_ce_2: 0  loss_mask_2: 0.8953  loss_dice_2: 2.268  loss_ce_3: 0  loss_mask_3: 0.8971  loss_dice_3: 2.254  loss_ce_4: 0  loss_mask_4: 0.8956  loss_dice_4: 2.256  loss_ce_5: 0  loss_mask_5: 0.8904  loss_dice_5: 2.259  loss_ce_6: 0  loss_mask_6: 0.899  loss_dice_6: 2.254  loss_ce_7: 0  loss_mask_7: 0.8983  loss_dice_7: 2.255  loss_ce_8: 0  loss_mask_8: 0.8992  loss_dice_8: 2.259  time: 2.0680  data_time: 0.0270  lr: 7.7005e-05  max_mem: 6006M
[02/18 08:41:20] d2.utils.events INFO:  eta: 19:56:05  iter: 15139  total_loss: 29.63  loss_ce: 0  loss_mask: 0.7964  loss_dice: 2.076  loss_seg: 0.6403  loss_ce_0: 0  loss_mask_0: 0.8103  loss_dice_0: 2.162  loss_ce_1: 0  loss_mask_1: 0.8048  loss_dice_1: 2.098  loss_ce_2: 0  loss_mask_2: 0.8028  loss_dice_2: 2.082  loss_ce_3: 0  loss_mask_3: 0.7976  loss_dice_3: 2.061  loss_ce_4: 0  loss_mask_4: 0.798  loss_dice_4: 2.064  loss_ce_5: 0  loss_mask_5: 0.7989  loss_dice_5: 2.069  loss_ce_6: 0  loss_mask_6: 0.7987  loss_dice_6: 2.063  loss_ce_7: 0  loss_mask_7: 0.796  loss_dice_7: 2.064  loss_ce_8: 0  loss_mask_8: 0.7977  loss_dice_8: 2.062  time: 2.0676  data_time: 0.0324  lr: 7.6974e-05  max_mem: 6006M
[02/18 08:41:53] d2.utils.events INFO:  eta: 19:55:07  iter: 15159  total_loss: 32.84  loss_ce: 0  loss_mask: 0.9073  loss_dice: 2.329  loss_seg: 0.8665  loss_ce_0: 0  loss_mask_0: 0.9067  loss_dice_0: 2.381  loss_ce_1: 0  loss_mask_1: 0.9021  loss_dice_1: 2.34  loss_ce_2: 0  loss_mask_2: 0.9076  loss_dice_2: 2.331  loss_ce_3: 0  loss_mask_3: 0.9088  loss_dice_3: 2.31  loss_ce_4: 0  loss_mask_4: 0.9127  loss_dice_4: 2.316  loss_ce_5: 0  loss_mask_5: 0.9071  loss_dice_5: 2.316  loss_ce_6: 0  loss_mask_6: 0.9076  loss_dice_6: 2.314  loss_ce_7: 0  loss_mask_7: 0.9098  loss_dice_7: 2.311  loss_ce_8: 0  loss_mask_8: 0.9086  loss_dice_8: 2.317  time: 2.0670  data_time: 0.0324  lr: 7.6943e-05  max_mem: 6006M
[02/18 08:42:28] d2.utils.events INFO:  eta: 19:56:22  iter: 15179  total_loss: 32.9  loss_ce: 0  loss_mask: 0.8954  loss_dice: 2.325  loss_seg: 0.8452  loss_ce_0: 0  loss_mask_0: 0.8945  loss_dice_0: 2.383  loss_ce_1: 0  loss_mask_1: 0.8972  loss_dice_1: 2.338  loss_ce_2: 0  loss_mask_2: 0.8988  loss_dice_2: 2.325  loss_ce_3: 0  loss_mask_3: 0.9017  loss_dice_3: 2.315  loss_ce_4: 0  loss_mask_4: 0.9024  loss_dice_4: 2.316  loss_ce_5: 0  loss_mask_5: 0.9008  loss_dice_5: 2.315  loss_ce_6: 0  loss_mask_6: 0.8969  loss_dice_6: 2.317  loss_ce_7: 0  loss_mask_7: 0.9004  loss_dice_7: 2.311  loss_ce_8: 0  loss_mask_8: 0.9047  loss_dice_8: 2.311  time: 2.0666  data_time: 0.0292  lr: 7.6913e-05  max_mem: 6006M
[02/18 08:43:01] d2.utils.events INFO:  eta: 19:54:51  iter: 15199  total_loss: 33.24  loss_ce: 0  loss_mask: 0.8758  loss_dice: 2.371  loss_seg: 0.7237  loss_ce_0: 0  loss_mask_0: 0.8888  loss_dice_0: 2.452  loss_ce_1: 0  loss_mask_1: 0.8777  loss_dice_1: 2.412  loss_ce_2: 0  loss_mask_2: 0.8815  loss_dice_2: 2.383  loss_ce_3: 0  loss_mask_3: 0.8851  loss_dice_3: 2.36  loss_ce_4: 0  loss_mask_4: 0.8869  loss_dice_4: 2.365  loss_ce_5: 0  loss_mask_5: 0.8894  loss_dice_5: 2.361  loss_ce_6: 0  loss_mask_6: 0.8875  loss_dice_6: 2.353  loss_ce_7: 0  loss_mask_7: 0.8838  loss_dice_7: 2.357  loss_ce_8: 0  loss_mask_8: 0.8816  loss_dice_8: 2.362  time: 2.0660  data_time: 0.0347  lr: 7.6882e-05  max_mem: 6006M
[02/18 08:43:34] d2.utils.events INFO:  eta: 19:52:35  iter: 15219  total_loss: 32.94  loss_ce: 0  loss_mask: 0.8317  loss_dice: 2.299  loss_seg: 0.9826  loss_ce_0: 0  loss_mask_0: 0.8429  loss_dice_0: 2.362  loss_ce_1: 0  loss_mask_1: 0.8419  loss_dice_1: 2.309  loss_ce_2: 0  loss_mask_2: 0.8426  loss_dice_2: 2.293  loss_ce_3: 0  loss_mask_3: 0.8372  loss_dice_3: 2.293  loss_ce_4: 0  loss_mask_4: 0.8391  loss_dice_4: 2.296  loss_ce_5: 0  loss_mask_5: 0.841  loss_dice_5: 2.291  loss_ce_6: 0  loss_mask_6: 0.8354  loss_dice_6: 2.291  loss_ce_7: 0  loss_mask_7: 0.8394  loss_dice_7: 2.29  loss_ce_8: 0  loss_mask_8: 0.8383  loss_dice_8: 2.282  time: 2.0655  data_time: 0.0350  lr: 7.6851e-05  max_mem: 6006M
[02/18 08:44:06] d2.utils.events INFO:  eta: 19:49:12  iter: 15239  total_loss: 32.52  loss_ce: 0  loss_mask: 0.8259  loss_dice: 2.323  loss_seg: 0.9812  loss_ce_0: 0  loss_mask_0: 0.8355  loss_dice_0: 2.386  loss_ce_1: 0  loss_mask_1: 0.8311  loss_dice_1: 2.324  loss_ce_2: 0  loss_mask_2: 0.8222  loss_dice_2: 2.309  loss_ce_3: 0  loss_mask_3: 0.8237  loss_dice_3: 2.294  loss_ce_4: 0  loss_mask_4: 0.824  loss_dice_4: 2.298  loss_ce_5: 0  loss_mask_5: 0.8252  loss_dice_5: 2.3  loss_ce_6: 0  loss_mask_6: 0.8225  loss_dice_6: 2.299  loss_ce_7: 0  loss_mask_7: 0.8245  loss_dice_7: 2.3  loss_ce_8: 0  loss_mask_8: 0.8232  loss_dice_8: 2.301  time: 2.0648  data_time: 0.0278  lr: 7.682e-05  max_mem: 6006M
[02/18 08:44:38] d2.utils.events INFO:  eta: 19:50:30  iter: 15259  total_loss: 32.06  loss_ce: 0  loss_mask: 0.8441  loss_dice: 2.251  loss_seg: 1.02  loss_ce_0: 0  loss_mask_0: 0.8541  loss_dice_0: 2.339  loss_ce_1: 0  loss_mask_1: 0.8483  loss_dice_1: 2.262  loss_ce_2: 0  loss_mask_2: 0.8508  loss_dice_2: 2.249  loss_ce_3: 0  loss_mask_3: 0.8499  loss_dice_3: 2.236  loss_ce_4: 0  loss_mask_4: 0.8488  loss_dice_4: 2.237  loss_ce_5: 0  loss_mask_5: 0.8462  loss_dice_5: 2.24  loss_ce_6: 0  loss_mask_6: 0.8532  loss_dice_6: 2.235  loss_ce_7: 0  loss_mask_7: 0.8558  loss_dice_7: 2.234  loss_ce_8: 0  loss_mask_8: 0.8515  loss_dice_8: 2.238  time: 2.0642  data_time: 0.0348  lr: 7.6789e-05  max_mem: 6006M
[02/18 08:45:11] d2.utils.events INFO:  eta: 19:49:58  iter: 15279  total_loss: 33.37  loss_ce: 0  loss_mask: 0.8305  loss_dice: 2.351  loss_seg: 1.286  loss_ce_0: 0  loss_mask_0: 0.8278  loss_dice_0: 2.405  loss_ce_1: 0  loss_mask_1: 0.8257  loss_dice_1: 2.364  loss_ce_2: 0  loss_mask_2: 0.8284  loss_dice_2: 2.354  loss_ce_3: 0  loss_mask_3: 0.8334  loss_dice_3: 2.34  loss_ce_4: 0  loss_mask_4: 0.8328  loss_dice_4: 2.344  loss_ce_5: 0  loss_mask_5: 0.8295  loss_dice_5: 2.343  loss_ce_6: 0  loss_mask_6: 0.8381  loss_dice_6: 2.342  loss_ce_7: 0  loss_mask_7: 0.8375  loss_dice_7: 2.339  loss_ce_8: 0  loss_mask_8: 0.8347  loss_dice_8: 2.341  time: 2.0637  data_time: 0.0252  lr: 7.6758e-05  max_mem: 6006M
[02/18 08:45:42] d2.utils.events INFO:  eta: 19:51:01  iter: 15299  total_loss: 33.66  loss_ce: 0  loss_mask: 0.8664  loss_dice: 2.409  loss_seg: 0.7718  loss_ce_0: 0  loss_mask_0: 0.8828  loss_dice_0: 2.453  loss_ce_1: 0  loss_mask_1: 0.8726  loss_dice_1: 2.423  loss_ce_2: 0  loss_mask_2: 0.8671  loss_dice_2: 2.408  loss_ce_3: 0  loss_mask_3: 0.8704  loss_dice_3: 2.391  loss_ce_4: 0  loss_mask_4: 0.8708  loss_dice_4: 2.39  loss_ce_5: 0  loss_mask_5: 0.8685  loss_dice_5: 2.39  loss_ce_6: 0  loss_mask_6: 0.8708  loss_dice_6: 2.39  loss_ce_7: 0  loss_mask_7: 0.8711  loss_dice_7: 2.39  loss_ce_8: 0  loss_mask_8: 0.8708  loss_dice_8: 2.396  time: 2.0630  data_time: 0.0286  lr: 7.6727e-05  max_mem: 6006M
[02/18 08:46:14] d2.utils.events INFO:  eta: 19:50:18  iter: 15319  total_loss: 33.75  loss_ce: 0  loss_mask: 0.8485  loss_dice: 2.404  loss_seg: 0.9453  loss_ce_0: 0  loss_mask_0: 0.8558  loss_dice_0: 2.455  loss_ce_1: 0  loss_mask_1: 0.8534  loss_dice_1: 2.408  loss_ce_2: 0  loss_mask_2: 0.8561  loss_dice_2: 2.395  loss_ce_3: 0  loss_mask_3: 0.849  loss_dice_3: 2.395  loss_ce_4: 0  loss_mask_4: 0.847  loss_dice_4: 2.393  loss_ce_5: 0  loss_mask_5: 0.8478  loss_dice_5: 2.401  loss_ce_6: 0  loss_mask_6: 0.8518  loss_dice_6: 2.395  loss_ce_7: 0  loss_mask_7: 0.8512  loss_dice_7: 2.398  loss_ce_8: 0  loss_mask_8: 0.855  loss_dice_8: 2.389  time: 2.0624  data_time: 0.0438  lr: 7.6696e-05  max_mem: 6006M
[02/18 08:46:47] d2.utils.events INFO:  eta: 19:49:24  iter: 15339  total_loss: 31.88  loss_ce: 0  loss_mask: 0.8298  loss_dice: 2.2  loss_seg: 1.224  loss_ce_0: 0  loss_mask_0: 0.844  loss_dice_0: 2.286  loss_ce_1: 0  loss_mask_1: 0.832  loss_dice_1: 2.213  loss_ce_2: 0  loss_mask_2: 0.8357  loss_dice_2: 2.187  loss_ce_3: 0  loss_mask_3: 0.8366  loss_dice_3: 2.175  loss_ce_4: 0  loss_mask_4: 0.8326  loss_dice_4: 2.172  loss_ce_5: 0  loss_mask_5: 0.8344  loss_dice_5: 2.169  loss_ce_6: 0  loss_mask_6: 0.8411  loss_dice_6: 2.17  loss_ce_7: 0  loss_mask_7: 0.8364  loss_dice_7: 2.17  loss_ce_8: 0  loss_mask_8: 0.8372  loss_dice_8: 2.173  time: 2.0619  data_time: 0.0295  lr: 7.6665e-05  max_mem: 6006M
[02/18 08:47:19] d2.utils.events INFO:  eta: 19:48:52  iter: 15359  total_loss: 32.09  loss_ce: 0  loss_mask: 0.8413  loss_dice: 2.243  loss_seg: 0.8434  loss_ce_0: 0  loss_mask_0: 0.8399  loss_dice_0: 2.296  loss_ce_1: 0  loss_mask_1: 0.8409  loss_dice_1: 2.245  loss_ce_2: 0  loss_mask_2: 0.8464  loss_dice_2: 2.229  loss_ce_3: 0  loss_mask_3: 0.8537  loss_dice_3: 2.22  loss_ce_4: 0  loss_mask_4: 0.8496  loss_dice_4: 2.223  loss_ce_5: 0  loss_mask_5: 0.8497  loss_dice_5: 2.225  loss_ce_6: 0  loss_mask_6: 0.8542  loss_dice_6: 2.22  loss_ce_7: 0  loss_mask_7: 0.8494  loss_dice_7: 2.224  loss_ce_8: 0  loss_mask_8: 0.8488  loss_dice_8: 2.229  time: 2.0612  data_time: 0.0344  lr: 7.6635e-05  max_mem: 6006M
[02/18 08:47:51] d2.utils.events INFO:  eta: 19:49:59  iter: 15379  total_loss: 32.79  loss_ce: 0  loss_mask: 0.8538  loss_dice: 2.282  loss_seg: 0.9174  loss_ce_0: 0  loss_mask_0: 0.8606  loss_dice_0: 2.325  loss_ce_1: 0  loss_mask_1: 0.8573  loss_dice_1: 2.284  loss_ce_2: 0  loss_mask_2: 0.8596  loss_dice_2: 2.279  loss_ce_3: 0  loss_mask_3: 0.8601  loss_dice_3: 2.266  loss_ce_4: 0  loss_mask_4: 0.8587  loss_dice_4: 2.272  loss_ce_5: 0  loss_mask_5: 0.8601  loss_dice_5: 2.274  loss_ce_6: 0  loss_mask_6: 0.8595  loss_dice_6: 2.27  loss_ce_7: 0  loss_mask_7: 0.8583  loss_dice_7: 2.269  loss_ce_8: 0  loss_mask_8: 0.857  loss_dice_8: 2.269  time: 2.0607  data_time: 0.0361  lr: 7.6604e-05  max_mem: 6006M
[02/18 08:48:27] d2.utils.events INFO:  eta: 19:52:31  iter: 15399  total_loss: 30.68  loss_ce: 0  loss_mask: 0.8035  loss_dice: 2.173  loss_seg: 0.9932  loss_ce_0: 0  loss_mask_0: 0.7999  loss_dice_0: 2.239  loss_ce_1: 0  loss_mask_1: 0.8037  loss_dice_1: 2.171  loss_ce_2: 0  loss_mask_2: 0.8029  loss_dice_2: 2.172  loss_ce_3: 0  loss_mask_3: 0.8054  loss_dice_3: 2.174  loss_ce_4: 0  loss_mask_4: 0.8064  loss_dice_4: 2.174  loss_ce_5: 0  loss_mask_5: 0.8067  loss_dice_5: 2.165  loss_ce_6: 0  loss_mask_6: 0.8047  loss_dice_6: 2.175  loss_ce_7: 0  loss_mask_7: 0.8042  loss_dice_7: 2.178  loss_ce_8: 0  loss_mask_8: 0.81  loss_dice_8: 2.168  time: 2.0603  data_time: 0.0248  lr: 7.6573e-05  max_mem: 6006M
[02/18 08:49:01] d2.utils.events INFO:  eta: 19:49:27  iter: 15419  total_loss: 33.99  loss_ce: 0  loss_mask: 0.8832  loss_dice: 2.402  loss_seg: 0.6804  loss_ce_0: 0  loss_mask_0: 0.8961  loss_dice_0: 2.478  loss_ce_1: 0  loss_mask_1: 0.8945  loss_dice_1: 2.404  loss_ce_2: 0  loss_mask_2: 0.891  loss_dice_2: 2.385  loss_ce_3: 0  loss_mask_3: 0.8911  loss_dice_3: 2.385  loss_ce_4: 0  loss_mask_4: 0.8923  loss_dice_4: 2.385  loss_ce_5: 0  loss_mask_5: 0.895  loss_dice_5: 2.385  loss_ce_6: 0  loss_mask_6: 0.8947  loss_dice_6: 2.391  loss_ce_7: 0  loss_mask_7: 0.8905  loss_dice_7: 2.392  loss_ce_8: 0  loss_mask_8: 0.8874  loss_dice_8: 2.39  time: 2.0598  data_time: 0.0353  lr: 7.6542e-05  max_mem: 6006M
[02/18 08:49:35] d2.utils.events INFO:  eta: 19:50:53  iter: 15439  total_loss: 32.6  loss_ce: 0  loss_mask: 0.8687  loss_dice: 2.304  loss_seg: 1.025  loss_ce_0: 0  loss_mask_0: 0.8869  loss_dice_0: 2.348  loss_ce_1: 0  loss_mask_1: 0.8809  loss_dice_1: 2.313  loss_ce_2: 0  loss_mask_2: 0.8786  loss_dice_2: 2.302  loss_ce_3: 0  loss_mask_3: 0.8748  loss_dice_3: 2.303  loss_ce_4: 0  loss_mask_4: 0.8761  loss_dice_4: 2.296  loss_ce_5: 0  loss_mask_5: 0.8712  loss_dice_5: 2.303  loss_ce_6: 0  loss_mask_6: 0.8724  loss_dice_6: 2.298  loss_ce_7: 0  loss_mask_7: 0.8705  loss_dice_7: 2.295  loss_ce_8: 0  loss_mask_8: 0.8668  loss_dice_8: 2.295  time: 2.0593  data_time: 0.0304  lr: 7.6511e-05  max_mem: 6006M
[02/18 08:50:08] d2.utils.events INFO:  eta: 19:51:22  iter: 15459  total_loss: 31.88  loss_ce: 0  loss_mask: 0.8544  loss_dice: 2.265  loss_seg: 0.7478  loss_ce_0: 0  loss_mask_0: 0.8766  loss_dice_0: 2.317  loss_ce_1: 0  loss_mask_1: 0.8625  loss_dice_1: 2.279  loss_ce_2: 0  loss_mask_2: 0.8635  loss_dice_2: 2.255  loss_ce_3: 0  loss_mask_3: 0.8595  loss_dice_3: 2.244  loss_ce_4: 0  loss_mask_4: 0.8616  loss_dice_4: 2.252  loss_ce_5: 0  loss_mask_5: 0.8619  loss_dice_5: 2.257  loss_ce_6: 0  loss_mask_6: 0.8619  loss_dice_6: 2.246  loss_ce_7: 0  loss_mask_7: 0.8632  loss_dice_7: 2.256  loss_ce_8: 0  loss_mask_8: 0.8606  loss_dice_8: 2.258  time: 2.0588  data_time: 0.0272  lr: 7.648e-05  max_mem: 6006M
[02/18 08:50:41] d2.utils.events INFO:  eta: 19:47:51  iter: 15479  total_loss: 31.33  loss_ce: 0  loss_mask: 0.8247  loss_dice: 2.216  loss_seg: 1.039  loss_ce_0: 0  loss_mask_0: 0.8287  loss_dice_0: 2.264  loss_ce_1: 0  loss_mask_1: 0.8244  loss_dice_1: 2.221  loss_ce_2: 0  loss_mask_2: 0.8319  loss_dice_2: 2.211  loss_ce_3: 0  loss_mask_3: 0.8273  loss_dice_3: 2.195  loss_ce_4: 0  loss_mask_4: 0.828  loss_dice_4: 2.195  loss_ce_5: 0  loss_mask_5: 0.8265  loss_dice_5: 2.193  loss_ce_6: 0  loss_mask_6: 0.8259  loss_dice_6: 2.192  loss_ce_7: 0  loss_mask_7: 0.8275  loss_dice_7: 2.2  loss_ce_8: 0  loss_mask_8: 0.8278  loss_dice_8: 2.2  time: 2.0583  data_time: 0.0360  lr: 7.6449e-05  max_mem: 6006M
[02/18 08:51:15] d2.utils.events INFO:  eta: 19:49:17  iter: 15499  total_loss: 32.73  loss_ce: 0  loss_mask: 0.864  loss_dice: 2.356  loss_seg: 0.8681  loss_ce_0: 0  loss_mask_0: 0.8882  loss_dice_0: 2.423  loss_ce_1: 0  loss_mask_1: 0.8744  loss_dice_1: 2.364  loss_ce_2: 0  loss_mask_2: 0.8764  loss_dice_2: 2.347  loss_ce_3: 0  loss_mask_3: 0.8762  loss_dice_3: 2.335  loss_ce_4: 0  loss_mask_4: 0.875  loss_dice_4: 2.337  loss_ce_5: 0  loss_mask_5: 0.8709  loss_dice_5: 2.341  loss_ce_6: 0  loss_mask_6: 0.867  loss_dice_6: 2.341  loss_ce_7: 0  loss_mask_7: 0.8685  loss_dice_7: 2.338  loss_ce_8: 0  loss_mask_8: 0.8685  loss_dice_8: 2.341  time: 2.0578  data_time: 0.0307  lr: 7.6418e-05  max_mem: 6006M
[02/18 08:51:48] d2.utils.events INFO:  eta: 19:47:27  iter: 15519  total_loss: 31.37  loss_ce: 0  loss_mask: 0.8212  loss_dice: 2.202  loss_seg: 1.074  loss_ce_0: 0  loss_mask_0: 0.8198  loss_dice_0: 2.274  loss_ce_1: 0  loss_mask_1: 0.8239  loss_dice_1: 2.19  loss_ce_2: 0  loss_mask_2: 0.823  loss_dice_2: 2.183  loss_ce_3: 0  loss_mask_3: 0.8287  loss_dice_3: 2.18  loss_ce_4: 0  loss_mask_4: 0.8312  loss_dice_4: 2.182  loss_ce_5: 0  loss_mask_5: 0.8316  loss_dice_5: 2.184  loss_ce_6: 0  loss_mask_6: 0.8301  loss_dice_6: 2.186  loss_ce_7: 0  loss_mask_7: 0.83  loss_dice_7: 2.187  loss_ce_8: 0  loss_mask_8: 0.8326  loss_dice_8: 2.191  time: 2.0573  data_time: 0.0285  lr: 7.6387e-05  max_mem: 6006M
[02/18 08:52:20] d2.utils.events INFO:  eta: 19:48:13  iter: 15539  total_loss: 32.11  loss_ce: 0  loss_mask: 0.8835  loss_dice: 2.239  loss_seg: 0.8043  loss_ce_0: 0  loss_mask_0: 0.8899  loss_dice_0: 2.304  loss_ce_1: 0  loss_mask_1: 0.878  loss_dice_1: 2.25  loss_ce_2: 0  loss_mask_2: 0.8834  loss_dice_2: 2.236  loss_ce_3: 0  loss_mask_3: 0.8864  loss_dice_3: 2.227  loss_ce_4: 0  loss_mask_4: 0.8822  loss_dice_4: 2.23  loss_ce_5: 0  loss_mask_5: 0.8833  loss_dice_5: 2.232  loss_ce_6: 0  loss_mask_6: 0.8878  loss_dice_6: 2.223  loss_ce_7: 0  loss_mask_7: 0.8879  loss_dice_7: 2.222  loss_ce_8: 0  loss_mask_8: 0.8883  loss_dice_8: 2.227  time: 2.0567  data_time: 0.0274  lr: 7.6356e-05  max_mem: 6006M
[02/18 08:52:54] d2.utils.events INFO:  eta: 19:48:27  iter: 15559  total_loss: 32.86  loss_ce: 0  loss_mask: 0.8492  loss_dice: 2.28  loss_seg: 0.9631  loss_ce_0: 0  loss_mask_0: 0.8492  loss_dice_0: 2.364  loss_ce_1: 0  loss_mask_1: 0.8573  loss_dice_1: 2.289  loss_ce_2: 0  loss_mask_2: 0.8562  loss_dice_2: 2.272  loss_ce_3: 0  loss_mask_3: 0.8506  loss_dice_3: 2.26  loss_ce_4: 0  loss_mask_4: 0.8524  loss_dice_4: 2.267  loss_ce_5: 0  loss_mask_5: 0.8534  loss_dice_5: 2.266  loss_ce_6: 0  loss_mask_6: 0.8565  loss_dice_6: 2.272  loss_ce_7: 0  loss_mask_7: 0.8536  loss_dice_7: 2.27  loss_ce_8: 0  loss_mask_8: 0.8522  loss_dice_8: 2.267  time: 2.0562  data_time: 0.0335  lr: 7.6325e-05  max_mem: 6006M
[02/18 08:53:26] d2.utils.events INFO:  eta: 19:48:10  iter: 15579  total_loss: 33.03  loss_ce: 0  loss_mask: 0.8374  loss_dice: 2.317  loss_seg: 1.024  loss_ce_0: 0  loss_mask_0: 0.8397  loss_dice_0: 2.377  loss_ce_1: 0  loss_mask_1: 0.8395  loss_dice_1: 2.332  loss_ce_2: 0  loss_mask_2: 0.8388  loss_dice_2: 2.316  loss_ce_3: 0  loss_mask_3: 0.8426  loss_dice_3: 2.308  loss_ce_4: 0  loss_mask_4: 0.8375  loss_dice_4: 2.312  loss_ce_5: 0  loss_mask_5: 0.8426  loss_dice_5: 2.312  loss_ce_6: 0  loss_mask_6: 0.8464  loss_dice_6: 2.309  loss_ce_7: 0  loss_mask_7: 0.8424  loss_dice_7: 2.31  loss_ce_8: 0  loss_mask_8: 0.8425  loss_dice_8: 2.315  time: 2.0557  data_time: 0.0255  lr: 7.6295e-05  max_mem: 6006M
[02/18 08:53:58] d2.utils.events INFO:  eta: 19:47:22  iter: 15599  total_loss: 32.59  loss_ce: 0  loss_mask: 0.8341  loss_dice: 2.327  loss_seg: 0.8207  loss_ce_0: 0  loss_mask_0: 0.8358  loss_dice_0: 2.377  loss_ce_1: 0  loss_mask_1: 0.836  loss_dice_1: 2.342  loss_ce_2: 0  loss_mask_2: 0.8377  loss_dice_2: 2.319  loss_ce_3: 0  loss_mask_3: 0.8406  loss_dice_3: 2.306  loss_ce_4: 0  loss_mask_4: 0.842  loss_dice_4: 2.305  loss_ce_5: 0  loss_mask_5: 0.842  loss_dice_5: 2.306  loss_ce_6: 0  loss_mask_6: 0.8408  loss_dice_6: 2.308  loss_ce_7: 0  loss_mask_7: 0.8372  loss_dice_7: 2.31  loss_ce_8: 0  loss_mask_8: 0.8409  loss_dice_8: 2.312  time: 2.0551  data_time: 0.0289  lr: 7.6264e-05  max_mem: 6006M
[02/18 08:54:31] d2.utils.events INFO:  eta: 19:47:45  iter: 15619  total_loss: 30.63  loss_ce: 0  loss_mask: 0.8052  loss_dice: 2.186  loss_seg: 0.8455  loss_ce_0: 0  loss_mask_0: 0.8163  loss_dice_0: 2.285  loss_ce_1: 0  loss_mask_1: 0.8067  loss_dice_1: 2.197  loss_ce_2: 0  loss_mask_2: 0.8076  loss_dice_2: 2.184  loss_ce_3: 0  loss_mask_3: 0.8065  loss_dice_3: 2.172  loss_ce_4: 0  loss_mask_4: 0.8101  loss_dice_4: 2.177  loss_ce_5: 0  loss_mask_5: 0.8078  loss_dice_5: 2.182  loss_ce_6: 0  loss_mask_6: 0.8057  loss_dice_6: 2.185  loss_ce_7: 0  loss_mask_7: 0.8082  loss_dice_7: 2.183  loss_ce_8: 0  loss_mask_8: 0.8093  loss_dice_8: 2.181  time: 2.0545  data_time: 0.0295  lr: 7.6233e-05  max_mem: 6006M
[02/18 08:55:04] d2.utils.events INFO:  eta: 19:47:42  iter: 15639  total_loss: 32.9  loss_ce: 0  loss_mask: 0.8531  loss_dice: 2.296  loss_seg: 0.7408  loss_ce_0: 0  loss_mask_0: 0.8652  loss_dice_0: 2.375  loss_ce_1: 0  loss_mask_1: 0.8526  loss_dice_1: 2.311  loss_ce_2: 0  loss_mask_2: 0.8542  loss_dice_2: 2.302  loss_ce_3: 0  loss_mask_3: 0.8493  loss_dice_3: 2.293  loss_ce_4: 0  loss_mask_4: 0.8509  loss_dice_4: 2.293  loss_ce_5: 0  loss_mask_5: 0.851  loss_dice_5: 2.289  loss_ce_6: 0  loss_mask_6: 0.854  loss_dice_6: 2.285  loss_ce_7: 0  loss_mask_7: 0.85  loss_dice_7: 2.288  loss_ce_8: 0  loss_mask_8: 0.8523  loss_dice_8: 2.287  time: 2.0540  data_time: 0.0299  lr: 7.6202e-05  max_mem: 6006M
[02/18 08:55:38] d2.utils.events INFO:  eta: 19:48:18  iter: 15659  total_loss: 32.78  loss_ce: 0  loss_mask: 0.8539  loss_dice: 2.323  loss_seg: 0.9483  loss_ce_0: 0  loss_mask_0: 0.874  loss_dice_0: 2.39  loss_ce_1: 0  loss_mask_1: 0.8561  loss_dice_1: 2.34  loss_ce_2: 0  loss_mask_2: 0.8567  loss_dice_2: 2.321  loss_ce_3: 0  loss_mask_3: 0.8549  loss_dice_3: 2.309  loss_ce_4: 0  loss_mask_4: 0.8543  loss_dice_4: 2.31  loss_ce_5: 0  loss_mask_5: 0.8546  loss_dice_5: 2.31  loss_ce_6: 0  loss_mask_6: 0.8532  loss_dice_6: 2.306  loss_ce_7: 0  loss_mask_7: 0.8547  loss_dice_7: 2.302  loss_ce_8: 0  loss_mask_8: 0.8542  loss_dice_8: 2.306  time: 2.0535  data_time: 0.0291  lr: 7.6171e-05  max_mem: 6006M
[02/18 08:56:12] d2.utils.events INFO:  eta: 19:50:58  iter: 15679  total_loss: 31.08  loss_ce: 0  loss_mask: 0.8325  loss_dice: 2.16  loss_seg: 0.8959  loss_ce_0: 0  loss_mask_0: 0.8586  loss_dice_0: 2.22  loss_ce_1: 0  loss_mask_1: 0.8432  loss_dice_1: 2.189  loss_ce_2: 0  loss_mask_2: 0.8484  loss_dice_2: 2.163  loss_ce_3: 0  loss_mask_3: 0.8425  loss_dice_3: 2.147  loss_ce_4: 0  loss_mask_4: 0.8389  loss_dice_4: 2.145  loss_ce_5: 0  loss_mask_5: 0.8438  loss_dice_5: 2.142  loss_ce_6: 0  loss_mask_6: 0.8394  loss_dice_6: 2.147  loss_ce_7: 0  loss_mask_7: 0.8433  loss_dice_7: 2.152  loss_ce_8: 0  loss_mask_8: 0.8374  loss_dice_8: 2.145  time: 2.0531  data_time: 0.0295  lr: 7.614e-05  max_mem: 6006M
[02/18 08:56:46] d2.utils.events INFO:  eta: 19:51:08  iter: 15699  total_loss: 33.08  loss_ce: 0  loss_mask: 0.8818  loss_dice: 2.273  loss_seg: 0.9466  loss_ce_0: 0  loss_mask_0: 0.882  loss_dice_0: 2.34  loss_ce_1: 0  loss_mask_1: 0.8741  loss_dice_1: 2.29  loss_ce_2: 0  loss_mask_2: 0.8811  loss_dice_2: 2.272  loss_ce_3: 0  loss_mask_3: 0.8825  loss_dice_3: 2.258  loss_ce_4: 0  loss_mask_4: 0.88  loss_dice_4: 2.262  loss_ce_5: 0  loss_mask_5: 0.883  loss_dice_5: 2.261  loss_ce_6: 0  loss_mask_6: 0.8824  loss_dice_6: 2.262  loss_ce_7: 0  loss_mask_7: 0.879  loss_dice_7: 2.26  loss_ce_8: 0  loss_mask_8: 0.8828  loss_dice_8: 2.263  time: 2.0527  data_time: 0.0320  lr: 7.6109e-05  max_mem: 6006M
[02/18 08:57:17] d2.utils.events INFO:  eta: 19:50:25  iter: 15719  total_loss: 32.61  loss_ce: 0  loss_mask: 0.8314  loss_dice: 2.328  loss_seg: 0.8961  loss_ce_0: 0  loss_mask_0: 0.8459  loss_dice_0: 2.364  loss_ce_1: 0  loss_mask_1: 0.8377  loss_dice_1: 2.321  loss_ce_2: 0  loss_mask_2: 0.8361  loss_dice_2: 2.32  loss_ce_3: 0  loss_mask_3: 0.8324  loss_dice_3: 2.308  loss_ce_4: 0  loss_mask_4: 0.8354  loss_dice_4: 2.309  loss_ce_5: 0  loss_mask_5: 0.8351  loss_dice_5: 2.312  loss_ce_6: 0  loss_mask_6: 0.8328  loss_dice_6: 2.313  loss_ce_7: 0  loss_mask_7: 0.8291  loss_dice_7: 2.304  loss_ce_8: 0  loss_mask_8: 0.8353  loss_dice_8: 2.312  time: 2.0520  data_time: 0.0267  lr: 7.6078e-05  max_mem: 6006M
[02/18 08:57:50] d2.utils.events INFO:  eta: 19:49:21  iter: 15739  total_loss: 32.24  loss_ce: 0  loss_mask: 0.8644  loss_dice: 2.306  loss_seg: 0.9208  loss_ce_0: 0  loss_mask_0: 0.8831  loss_dice_0: 2.359  loss_ce_1: 0  loss_mask_1: 0.8675  loss_dice_1: 2.312  loss_ce_2: 0  loss_mask_2: 0.8607  loss_dice_2: 2.301  loss_ce_3: 0  loss_mask_3: 0.8562  loss_dice_3: 2.3  loss_ce_4: 0  loss_mask_4: 0.8581  loss_dice_4: 2.294  loss_ce_5: 0  loss_mask_5: 0.8555  loss_dice_5: 2.292  loss_ce_6: 0  loss_mask_6: 0.8626  loss_dice_6: 2.293  loss_ce_7: 0  loss_mask_7: 0.8621  loss_dice_7: 2.293  loss_ce_8: 0  loss_mask_8: 0.8592  loss_dice_8: 2.292  time: 2.0515  data_time: 0.0297  lr: 7.6047e-05  max_mem: 6006M
[02/18 08:58:22] d2.utils.events INFO:  eta: 19:48:48  iter: 15759  total_loss: 33.17  loss_ce: 0  loss_mask: 0.877  loss_dice: 2.351  loss_seg: 0.8031  loss_ce_0: 0  loss_mask_0: 0.8778  loss_dice_0: 2.41  loss_ce_1: 0  loss_mask_1: 0.8722  loss_dice_1: 2.374  loss_ce_2: 0  loss_mask_2: 0.8724  loss_dice_2: 2.352  loss_ce_3: 0  loss_mask_3: 0.8706  loss_dice_3: 2.34  loss_ce_4: 0  loss_mask_4: 0.8772  loss_dice_4: 2.338  loss_ce_5: 0  loss_mask_5: 0.8745  loss_dice_5: 2.339  loss_ce_6: 0  loss_mask_6: 0.8734  loss_dice_6: 2.335  loss_ce_7: 0  loss_mask_7: 0.8781  loss_dice_7: 2.335  loss_ce_8: 0  loss_mask_8: 0.8752  loss_dice_8: 2.343  time: 2.0509  data_time: 0.0261  lr: 7.6016e-05  max_mem: 6006M
[02/18 08:58:55] d2.utils.events INFO:  eta: 19:48:16  iter: 15779  total_loss: 32.33  loss_ce: 0  loss_mask: 0.7952  loss_dice: 2.283  loss_seg: 0.8318  loss_ce_0: 0  loss_mask_0: 0.799  loss_dice_0: 2.369  loss_ce_1: 0  loss_mask_1: 0.8031  loss_dice_1: 2.291  loss_ce_2: 0  loss_mask_2: 0.8029  loss_dice_2: 2.278  loss_ce_3: 0  loss_mask_3: 0.8008  loss_dice_3: 2.264  loss_ce_4: 0  loss_mask_4: 0.8003  loss_dice_4: 2.266  loss_ce_5: 0  loss_mask_5: 0.8011  loss_dice_5: 2.265  loss_ce_6: 0  loss_mask_6: 0.8034  loss_dice_6: 2.26  loss_ce_7: 0  loss_mask_7: 0.8021  loss_dice_7: 2.263  loss_ce_8: 0  loss_mask_8: 0.7985  loss_dice_8: 2.264  time: 2.0504  data_time: 0.0324  lr: 7.5985e-05  max_mem: 6006M
[02/18 08:59:27] d2.utils.events INFO:  eta: 19:48:26  iter: 15799  total_loss: 31.2  loss_ce: 0  loss_mask: 0.8146  loss_dice: 2.177  loss_seg: 0.8331  loss_ce_0: 0  loss_mask_0: 0.8259  loss_dice_0: 2.269  loss_ce_1: 0  loss_mask_1: 0.8199  loss_dice_1: 2.191  loss_ce_2: 0  loss_mask_2: 0.8255  loss_dice_2: 2.166  loss_ce_3: 0  loss_mask_3: 0.8238  loss_dice_3: 2.156  loss_ce_4: 0  loss_mask_4: 0.8214  loss_dice_4: 2.156  loss_ce_5: 0  loss_mask_5: 0.827  loss_dice_5: 2.164  loss_ce_6: 0  loss_mask_6: 0.8235  loss_dice_6: 2.16  loss_ce_7: 0  loss_mask_7: 0.8199  loss_dice_7: 2.163  loss_ce_8: 0  loss_mask_8: 0.8205  loss_dice_8: 2.163  time: 2.0498  data_time: 0.0377  lr: 7.5954e-05  max_mem: 6006M
[02/18 09:00:00] d2.utils.events INFO:  eta: 19:47:34  iter: 15819  total_loss: 32.22  loss_ce: 0  loss_mask: 0.8528  loss_dice: 2.241  loss_seg: 0.7582  loss_ce_0: 0  loss_mask_0: 0.8517  loss_dice_0: 2.31  loss_ce_1: 0  loss_mask_1: 0.8442  loss_dice_1: 2.252  loss_ce_2: 0  loss_mask_2: 0.8516  loss_dice_2: 2.239  loss_ce_3: 0  loss_mask_3: 0.8517  loss_dice_3: 2.232  loss_ce_4: 0  loss_mask_4: 0.8529  loss_dice_4: 2.234  loss_ce_5: 0  loss_mask_5: 0.856  loss_dice_5: 2.236  loss_ce_6: 0  loss_mask_6: 0.8534  loss_dice_6: 2.238  loss_ce_7: 0  loss_mask_7: 0.856  loss_dice_7: 2.237  loss_ce_8: 0  loss_mask_8: 0.8564  loss_dice_8: 2.228  time: 2.0493  data_time: 0.0341  lr: 7.5923e-05  max_mem: 6006M
[02/18 09:00:31] d2.utils.events INFO:  eta: 19:46:10  iter: 15839  total_loss: 33.54  loss_ce: 0  loss_mask: 0.8601  loss_dice: 2.406  loss_seg: 1.161  loss_ce_0: 0  loss_mask_0: 0.8639  loss_dice_0: 2.468  loss_ce_1: 0  loss_mask_1: 0.8594  loss_dice_1: 2.397  loss_ce_2: 0  loss_mask_2: 0.8647  loss_dice_2: 2.394  loss_ce_3: 0  loss_mask_3: 0.8637  loss_dice_3: 2.388  loss_ce_4: 0  loss_mask_4: 0.8674  loss_dice_4: 2.386  loss_ce_5: 0  loss_mask_5: 0.867  loss_dice_5: 2.39  loss_ce_6: 0  loss_mask_6: 0.8684  loss_dice_6: 2.387  loss_ce_7: 0  loss_mask_7: 0.8617  loss_dice_7: 2.391  loss_ce_8: 0  loss_mask_8: 0.8611  loss_dice_8: 2.393  time: 2.0487  data_time: 0.0343  lr: 7.5893e-05  max_mem: 6006M
[02/18 09:01:03] d2.utils.events INFO:  eta: 19:46:07  iter: 15859  total_loss: 32.97  loss_ce: 0  loss_mask: 0.8635  loss_dice: 2.259  loss_seg: 0.9053  loss_ce_0: 0  loss_mask_0: 0.8814  loss_dice_0: 2.319  loss_ce_1: 0  loss_mask_1: 0.8638  loss_dice_1: 2.256  loss_ce_2: 0  loss_mask_2: 0.8675  loss_dice_2: 2.249  loss_ce_3: 0  loss_mask_3: 0.8711  loss_dice_3: 2.253  loss_ce_4: 0  loss_mask_4: 0.8736  loss_dice_4: 2.247  loss_ce_5: 0  loss_mask_5: 0.8764  loss_dice_5: 2.247  loss_ce_6: 0  loss_mask_6: 0.8718  loss_dice_6: 2.249  loss_ce_7: 0  loss_mask_7: 0.8739  loss_dice_7: 2.255  loss_ce_8: 0  loss_mask_8: 0.8726  loss_dice_8: 2.245  time: 2.0481  data_time: 0.0295  lr: 7.5862e-05  max_mem: 6006M
[02/18 09:01:36] d2.utils.events INFO:  eta: 19:45:35  iter: 15879  total_loss: 32.37  loss_ce: 0  loss_mask: 0.8484  loss_dice: 2.289  loss_seg: 1.181  loss_ce_0: 0  loss_mask_0: 0.855  loss_dice_0: 2.351  loss_ce_1: 0  loss_mask_1: 0.8508  loss_dice_1: 2.297  loss_ce_2: 0  loss_mask_2: 0.8487  loss_dice_2: 2.281  loss_ce_3: 0  loss_mask_3: 0.8478  loss_dice_3: 2.281  loss_ce_4: 0  loss_mask_4: 0.8427  loss_dice_4: 2.281  loss_ce_5: 0  loss_mask_5: 0.845  loss_dice_5: 2.281  loss_ce_6: 0  loss_mask_6: 0.8482  loss_dice_6: 2.278  loss_ce_7: 0  loss_mask_7: 0.8479  loss_dice_7: 2.28  loss_ce_8: 0  loss_mask_8: 0.8498  loss_dice_8: 2.272  time: 2.0476  data_time: 0.0311  lr: 7.5831e-05  max_mem: 6006M
[02/18 09:02:11] d2.utils.events INFO:  eta: 19:46:23  iter: 15899  total_loss: 32.64  loss_ce: 0  loss_mask: 0.8455  loss_dice: 2.339  loss_seg: 0.855  loss_ce_0: 0  loss_mask_0: 0.8533  loss_dice_0: 2.412  loss_ce_1: 0  loss_mask_1: 0.8516  loss_dice_1: 2.356  loss_ce_2: 0  loss_mask_2: 0.8553  loss_dice_2: 2.338  loss_ce_3: 0  loss_mask_3: 0.8586  loss_dice_3: 2.32  loss_ce_4: 0  loss_mask_4: 0.8581  loss_dice_4: 2.318  loss_ce_5: 0  loss_mask_5: 0.8564  loss_dice_5: 2.321  loss_ce_6: 0  loss_mask_6: 0.8552  loss_dice_6: 2.318  loss_ce_7: 0  loss_mask_7: 0.8587  loss_dice_7: 2.315  loss_ce_8: 0  loss_mask_8: 0.8543  loss_dice_8: 2.321  time: 2.0472  data_time: 0.0275  lr: 7.58e-05  max_mem: 6006M
[02/18 09:02:46] d2.utils.events INFO:  eta: 19:48:07  iter: 15919  total_loss: 31.84  loss_ce: 0  loss_mask: 0.8451  loss_dice: 2.261  loss_seg: 0.9107  loss_ce_0: 0  loss_mask_0: 0.8526  loss_dice_0: 2.298  loss_ce_1: 0  loss_mask_1: 0.8556  loss_dice_1: 2.26  loss_ce_2: 0  loss_mask_2: 0.8545  loss_dice_2: 2.25  loss_ce_3: 0  loss_mask_3: 0.8497  loss_dice_3: 2.24  loss_ce_4: 0  loss_mask_4: 0.8506  loss_dice_4: 2.241  loss_ce_5: 0  loss_mask_5: 0.8513  loss_dice_5: 2.243  loss_ce_6: 0  loss_mask_6: 0.8513  loss_dice_6: 2.249  loss_ce_7: 0  loss_mask_7: 0.8474  loss_dice_7: 2.246  loss_ce_8: 0  loss_mask_8: 0.8516  loss_dice_8: 2.245  time: 2.0469  data_time: 0.0265  lr: 7.5769e-05  max_mem: 6006M
[02/18 09:03:20] d2.utils.events INFO:  eta: 19:47:35  iter: 15939  total_loss: 31.72  loss_ce: 0  loss_mask: 0.8599  loss_dice: 2.238  loss_seg: 0.9777  loss_ce_0: 0  loss_mask_0: 0.8615  loss_dice_0: 2.294  loss_ce_1: 0  loss_mask_1: 0.8642  loss_dice_1: 2.239  loss_ce_2: 0  loss_mask_2: 0.862  loss_dice_2: 2.221  loss_ce_3: 0  loss_mask_3: 0.8616  loss_dice_3: 2.215  loss_ce_4: 0  loss_mask_4: 0.8624  loss_dice_4: 2.215  loss_ce_5: 0  loss_mask_5: 0.8635  loss_dice_5: 2.215  loss_ce_6: 0  loss_mask_6: 0.8624  loss_dice_6: 2.219  loss_ce_7: 0  loss_mask_7: 0.8649  loss_dice_7: 2.218  loss_ce_8: 0  loss_mask_8: 0.8653  loss_dice_8: 2.219  time: 2.0464  data_time: 0.0351  lr: 7.5738e-05  max_mem: 6006M
[02/18 09:03:54] d2.utils.events INFO:  eta: 19:47:21  iter: 15959  total_loss: 31.31  loss_ce: 0  loss_mask: 0.8292  loss_dice: 2.215  loss_seg: 0.9128  loss_ce_0: 0  loss_mask_0: 0.8336  loss_dice_0: 2.268  loss_ce_1: 0  loss_mask_1: 0.836  loss_dice_1: 2.22  loss_ce_2: 0  loss_mask_2: 0.8294  loss_dice_2: 2.205  loss_ce_3: 0  loss_mask_3: 0.8348  loss_dice_3: 2.198  loss_ce_4: 0  loss_mask_4: 0.8357  loss_dice_4: 2.195  loss_ce_5: 0  loss_mask_5: 0.8347  loss_dice_5: 2.202  loss_ce_6: 0  loss_mask_6: 0.8342  loss_dice_6: 2.196  loss_ce_7: 0  loss_mask_7: 0.8396  loss_dice_7: 2.207  loss_ce_8: 0  loss_mask_8: 0.834  loss_dice_8: 2.205  time: 2.0459  data_time: 0.0303  lr: 7.5707e-05  max_mem: 6006M
[02/18 09:04:26] d2.utils.events INFO:  eta: 19:47:32  iter: 15979  total_loss: 32  loss_ce: 0  loss_mask: 0.8274  loss_dice: 2.232  loss_seg: 0.8149  loss_ce_0: 0  loss_mask_0: 0.843  loss_dice_0: 2.321  loss_ce_1: 0  loss_mask_1: 0.8305  loss_dice_1: 2.236  loss_ce_2: 0  loss_mask_2: 0.8333  loss_dice_2: 2.221  loss_ce_3: 0  loss_mask_3: 0.834  loss_dice_3: 2.216  loss_ce_4: 0  loss_mask_4: 0.8304  loss_dice_4: 2.221  loss_ce_5: 0  loss_mask_5: 0.8326  loss_dice_5: 2.216  loss_ce_6: 0  loss_mask_6: 0.837  loss_dice_6: 2.218  loss_ce_7: 0  loss_mask_7: 0.8403  loss_dice_7: 2.219  loss_ce_8: 0  loss_mask_8: 0.8386  loss_dice_8: 2.214  time: 2.0454  data_time: 0.0482  lr: 7.5676e-05  max_mem: 6006M
[02/18 09:04:58] d2.utils.events INFO:  eta: 19:47:35  iter: 15999  total_loss: 32.33  loss_ce: 0  loss_mask: 0.8391  loss_dice: 2.258  loss_seg: 0.702  loss_ce_0: 0  loss_mask_0: 0.8567  loss_dice_0: 2.311  loss_ce_1: 0  loss_mask_1: 0.8449  loss_dice_1: 2.279  loss_ce_2: 0  loss_mask_2: 0.8441  loss_dice_2: 2.26  loss_ce_3: 0  loss_mask_3: 0.8407  loss_dice_3: 2.247  loss_ce_4: 0  loss_mask_4: 0.8435  loss_dice_4: 2.256  loss_ce_5: 0  loss_mask_5: 0.844  loss_dice_5: 2.253  loss_ce_6: 0  loss_mask_6: 0.8389  loss_dice_6: 2.25  loss_ce_7: 0  loss_mask_7: 0.8429  loss_dice_7: 2.248  loss_ce_8: 0  loss_mask_8: 0.8428  loss_dice_8: 2.25  time: 2.0449  data_time: 0.0346  lr: 7.5645e-05  max_mem: 6006M
[02/18 09:05:29] d2.utils.events INFO:  eta: 19:45:44  iter: 16019  total_loss: 32.54  loss_ce: 0  loss_mask: 0.83  loss_dice: 2.269  loss_seg: 0.8496  loss_ce_0: 0  loss_mask_0: 0.8358  loss_dice_0: 2.362  loss_ce_1: 0  loss_mask_1: 0.8309  loss_dice_1: 2.289  loss_ce_2: 0  loss_mask_2: 0.8315  loss_dice_2: 2.267  loss_ce_3: 0  loss_mask_3: 0.8328  loss_dice_3: 2.257  loss_ce_4: 0  loss_mask_4: 0.8316  loss_dice_4: 2.26  loss_ce_5: 0  loss_mask_5: 0.8331  loss_dice_5: 2.265  loss_ce_6: 0  loss_mask_6: 0.8326  loss_dice_6: 2.255  loss_ce_7: 0  loss_mask_7: 0.8307  loss_dice_7: 2.256  loss_ce_8: 0  loss_mask_8: 0.8337  loss_dice_8: 2.256  time: 2.0442  data_time: 0.0346  lr: 7.5614e-05  max_mem: 6006M
[02/18 09:06:02] d2.utils.events INFO:  eta: 19:44:53  iter: 16039  total_loss: 31.39  loss_ce: 0  loss_mask: 0.8657  loss_dice: 2.184  loss_seg: 0.7249  loss_ce_0: 0  loss_mask_0: 0.8743  loss_dice_0: 2.276  loss_ce_1: 0  loss_mask_1: 0.864  loss_dice_1: 2.216  loss_ce_2: 0  loss_mask_2: 0.8675  loss_dice_2: 2.199  loss_ce_3: 0  loss_mask_3: 0.8622  loss_dice_3: 2.181  loss_ce_4: 0  loss_mask_4: 0.8612  loss_dice_4: 2.177  loss_ce_5: 0  loss_mask_5: 0.8624  loss_dice_5: 2.177  loss_ce_6: 0  loss_mask_6: 0.8635  loss_dice_6: 2.17  loss_ce_7: 0  loss_mask_7: 0.8681  loss_dice_7: 2.173  loss_ce_8: 0  loss_mask_8: 0.8748  loss_dice_8: 2.167  time: 2.0437  data_time: 0.0316  lr: 7.5583e-05  max_mem: 6006M
[02/18 09:06:36] d2.utils.events INFO:  eta: 19:44:40  iter: 16059  total_loss: 31.49  loss_ce: 0  loss_mask: 0.8417  loss_dice: 2.256  loss_seg: 0.8109  loss_ce_0: 0  loss_mask_0: 0.866  loss_dice_0: 2.323  loss_ce_1: 0  loss_mask_1: 0.8511  loss_dice_1: 2.272  loss_ce_2: 0  loss_mask_2: 0.8533  loss_dice_2: 2.253  loss_ce_3: 0  loss_mask_3: 0.8535  loss_dice_3: 2.247  loss_ce_4: 0  loss_mask_4: 0.853  loss_dice_4: 2.25  loss_ce_5: 0  loss_mask_5: 0.8501  loss_dice_5: 2.251  loss_ce_6: 0  loss_mask_6: 0.8512  loss_dice_6: 2.246  loss_ce_7: 0  loss_mask_7: 0.8493  loss_dice_7: 2.248  loss_ce_8: 0  loss_mask_8: 0.8456  loss_dice_8: 2.246  time: 2.0433  data_time: 0.0328  lr: 7.5552e-05  max_mem: 6006M
[02/18 09:07:09] d2.utils.events INFO:  eta: 19:46:28  iter: 16079  total_loss: 30.79  loss_ce: 0  loss_mask: 0.7925  loss_dice: 2.167  loss_seg: 0.9567  loss_ce_0: 0  loss_mask_0: 0.8  loss_dice_0: 2.237  loss_ce_1: 0  loss_mask_1: 0.7972  loss_dice_1: 2.18  loss_ce_2: 0  loss_mask_2: 0.7946  loss_dice_2: 2.164  loss_ce_3: 0  loss_mask_3: 0.7959  loss_dice_3: 2.157  loss_ce_4: 0  loss_mask_4: 0.7945  loss_dice_4: 2.158  loss_ce_5: 0  loss_mask_5: 0.7967  loss_dice_5: 2.158  loss_ce_6: 0  loss_mask_6: 0.7989  loss_dice_6: 2.149  loss_ce_7: 0  loss_mask_7: 0.793  loss_dice_7: 2.151  loss_ce_8: 0  loss_mask_8: 0.7932  loss_dice_8: 2.156  time: 2.0428  data_time: 0.0280  lr: 7.5521e-05  max_mem: 6006M
[02/18 09:07:42] d2.utils.events INFO:  eta: 19:45:29  iter: 16099  total_loss: 32.94  loss_ce: 0  loss_mask: 0.8456  loss_dice: 2.337  loss_seg: 0.8519  loss_ce_0: 0  loss_mask_0: 0.8521  loss_dice_0: 2.38  loss_ce_1: 0  loss_mask_1: 0.8551  loss_dice_1: 2.334  loss_ce_2: 0  loss_mask_2: 0.8534  loss_dice_2: 2.331  loss_ce_3: 0  loss_mask_3: 0.8623  loss_dice_3: 2.322  loss_ce_4: 0  loss_mask_4: 0.8646  loss_dice_4: 2.325  loss_ce_5: 0  loss_mask_5: 0.859  loss_dice_5: 2.329  loss_ce_6: 0  loss_mask_6: 0.8587  loss_dice_6: 2.326  loss_ce_7: 0  loss_mask_7: 0.8548  loss_dice_7: 2.331  loss_ce_8: 0  loss_mask_8: 0.854  loss_dice_8: 2.333  time: 2.0423  data_time: 0.0311  lr: 7.549e-05  max_mem: 6006M
[02/18 09:08:14] d2.utils.events INFO:  eta: 19:44:56  iter: 16119  total_loss: 31.17  loss_ce: 0  loss_mask: 0.8448  loss_dice: 2.202  loss_seg: 0.7122  loss_ce_0: 0  loss_mask_0: 0.8423  loss_dice_0: 2.275  loss_ce_1: 0  loss_mask_1: 0.8548  loss_dice_1: 2.224  loss_ce_2: 0  loss_mask_2: 0.857  loss_dice_2: 2.205  loss_ce_3: 0  loss_mask_3: 0.8555  loss_dice_3: 2.188  loss_ce_4: 0  loss_mask_4: 0.8607  loss_dice_4: 2.185  loss_ce_5: 0  loss_mask_5: 0.8577  loss_dice_5: 2.187  loss_ce_6: 0  loss_mask_6: 0.8608  loss_dice_6: 2.189  loss_ce_7: 0  loss_mask_7: 0.8612  loss_dice_7: 2.184  loss_ce_8: 0  loss_mask_8: 0.8584  loss_dice_8: 2.188  time: 2.0418  data_time: 0.0345  lr: 7.5459e-05  max_mem: 6006M
[02/18 09:08:45] d2.utils.events INFO:  eta: 19:42:53  iter: 16139  total_loss: 31.65  loss_ce: 0  loss_mask: 0.8297  loss_dice: 2.247  loss_seg: 0.7415  loss_ce_0: 0  loss_mask_0: 0.8071  loss_dice_0: 2.299  loss_ce_1: 0  loss_mask_1: 0.8387  loss_dice_1: 2.251  loss_ce_2: 0  loss_mask_2: 0.8385  loss_dice_2: 2.241  loss_ce_3: 0  loss_mask_3: 0.8389  loss_dice_3: 2.239  loss_ce_4: 0  loss_mask_4: 0.8398  loss_dice_4: 2.245  loss_ce_5: 0  loss_mask_5: 0.8385  loss_dice_5: 2.249  loss_ce_6: 0  loss_mask_6: 0.8423  loss_dice_6: 2.239  loss_ce_7: 0  loss_mask_7: 0.8431  loss_dice_7: 2.242  loss_ce_8: 0  loss_mask_8: 0.8433  loss_dice_8: 2.237  time: 2.0412  data_time: 0.0317  lr: 7.5428e-05  max_mem: 6006M
[02/18 09:09:19] d2.utils.events INFO:  eta: 19:42:40  iter: 16159  total_loss: 31.98  loss_ce: 0  loss_mask: 0.8541  loss_dice: 2.312  loss_seg: 1.135  loss_ce_0: 0  loss_mask_0: 0.859  loss_dice_0: 2.371  loss_ce_1: 0  loss_mask_1: 0.8509  loss_dice_1: 2.319  loss_ce_2: 0  loss_mask_2: 0.8584  loss_dice_2: 2.307  loss_ce_3: 0  loss_mask_3: 0.8626  loss_dice_3: 2.301  loss_ce_4: 0  loss_mask_4: 0.8603  loss_dice_4: 2.303  loss_ce_5: 0  loss_mask_5: 0.8592  loss_dice_5: 2.3  loss_ce_6: 0  loss_mask_6: 0.8572  loss_dice_6: 2.298  loss_ce_7: 0  loss_mask_7: 0.8587  loss_dice_7: 2.302  loss_ce_8: 0  loss_mask_8: 0.8585  loss_dice_8: 2.303  time: 2.0407  data_time: 0.0361  lr: 7.5397e-05  max_mem: 6006M
[02/18 09:09:50] d2.utils.events INFO:  eta: 19:40:22  iter: 16179  total_loss: 33.47  loss_ce: 0  loss_mask: 0.878  loss_dice: 2.344  loss_seg: 0.8777  loss_ce_0: 0  loss_mask_0: 0.8681  loss_dice_0: 2.406  loss_ce_1: 0  loss_mask_1: 0.8739  loss_dice_1: 2.356  loss_ce_2: 0  loss_mask_2: 0.8779  loss_dice_2: 2.338  loss_ce_3: 0  loss_mask_3: 0.8804  loss_dice_3: 2.335  loss_ce_4: 0  loss_mask_4: 0.8847  loss_dice_4: 2.336  loss_ce_5: 0  loss_mask_5: 0.8831  loss_dice_5: 2.334  loss_ce_6: 0  loss_mask_6: 0.8808  loss_dice_6: 2.334  loss_ce_7: 0  loss_mask_7: 0.8788  loss_dice_7: 2.335  loss_ce_8: 0  loss_mask_8: 0.8858  loss_dice_8: 2.334  time: 2.0401  data_time: 0.0312  lr: 7.5366e-05  max_mem: 6006M
[02/18 09:10:22] d2.utils.events INFO:  eta: 19:39:50  iter: 16199  total_loss: 31.58  loss_ce: 0  loss_mask: 0.8402  loss_dice: 2.242  loss_seg: 0.749  loss_ce_0: 0  loss_mask_0: 0.85  loss_dice_0: 2.298  loss_ce_1: 0  loss_mask_1: 0.8461  loss_dice_1: 2.246  loss_ce_2: 0  loss_mask_2: 0.8467  loss_dice_2: 2.23  loss_ce_3: 0  loss_mask_3: 0.8467  loss_dice_3: 2.223  loss_ce_4: 0  loss_mask_4: 0.8493  loss_dice_4: 2.221  loss_ce_5: 0  loss_mask_5: 0.8474  loss_dice_5: 2.225  loss_ce_6: 0  loss_mask_6: 0.8493  loss_dice_6: 2.223  loss_ce_7: 0  loss_mask_7: 0.8509  loss_dice_7: 2.228  loss_ce_8: 0  loss_mask_8: 0.8523  loss_dice_8: 2.228  time: 2.0395  data_time: 0.0292  lr: 7.5335e-05  max_mem: 6006M
[02/18 09:10:55] d2.utils.events INFO:  eta: 19:39:38  iter: 16219  total_loss: 30.76  loss_ce: 0  loss_mask: 0.8246  loss_dice: 2.156  loss_seg: 0.6646  loss_ce_0: 0  loss_mask_0: 0.8391  loss_dice_0: 2.205  loss_ce_1: 0  loss_mask_1: 0.8317  loss_dice_1: 2.157  loss_ce_2: 0  loss_mask_2: 0.8338  loss_dice_2: 2.148  loss_ce_3: 0  loss_mask_3: 0.8326  loss_dice_3: 2.134  loss_ce_4: 0  loss_mask_4: 0.8368  loss_dice_4: 2.135  loss_ce_5: 0  loss_mask_5: 0.837  loss_dice_5: 2.141  loss_ce_6: 0  loss_mask_6: 0.8381  loss_dice_6: 2.136  loss_ce_7: 0  loss_mask_7: 0.8337  loss_dice_7: 2.14  loss_ce_8: 0  loss_mask_8: 0.8355  loss_dice_8: 2.141  time: 2.0390  data_time: 0.0322  lr: 7.5305e-05  max_mem: 6006M
[02/18 09:11:28] d2.utils.events INFO:  eta: 19:39:06  iter: 16239  total_loss: 32.23  loss_ce: 0  loss_mask: 0.8065  loss_dice: 2.287  loss_seg: 0.8391  loss_ce_0: 0  loss_mask_0: 0.814  loss_dice_0: 2.349  loss_ce_1: 0  loss_mask_1: 0.8064  loss_dice_1: 2.293  loss_ce_2: 0  loss_mask_2: 0.8124  loss_dice_2: 2.278  loss_ce_3: 0  loss_mask_3: 0.8154  loss_dice_3: 2.253  loss_ce_4: 0  loss_mask_4: 0.8137  loss_dice_4: 2.262  loss_ce_5: 0  loss_mask_5: 0.8161  loss_dice_5: 2.264  loss_ce_6: 0  loss_mask_6: 0.8135  loss_dice_6: 2.262  loss_ce_7: 0  loss_mask_7: 0.8174  loss_dice_7: 2.263  loss_ce_8: 0  loss_mask_8: 0.8166  loss_dice_8: 2.263  time: 2.0386  data_time: 0.0280  lr: 7.5274e-05  max_mem: 6006M
[02/18 09:11:59] d2.utils.events INFO:  eta: 19:38:22  iter: 16259  total_loss: 32.29  loss_ce: 0  loss_mask: 0.8528  loss_dice: 2.302  loss_seg: 0.7913  loss_ce_0: 0  loss_mask_0: 0.8713  loss_dice_0: 2.326  loss_ce_1: 0  loss_mask_1: 0.8523  loss_dice_1: 2.31  loss_ce_2: 0  loss_mask_2: 0.8523  loss_dice_2: 2.291  loss_ce_3: 0  loss_mask_3: 0.8557  loss_dice_3: 2.282  loss_ce_4: 0  loss_mask_4: 0.8541  loss_dice_4: 2.286  loss_ce_5: 0  loss_mask_5: 0.8528  loss_dice_5: 2.288  loss_ce_6: 0  loss_mask_6: 0.856  loss_dice_6: 2.278  loss_ce_7: 0  loss_mask_7: 0.8568  loss_dice_7: 2.289  loss_ce_8: 0  loss_mask_8: 0.8608  loss_dice_8: 2.284  time: 2.0380  data_time: 0.0290  lr: 7.5243e-05  max_mem: 6006M
[02/18 09:12:31] d2.utils.events INFO:  eta: 19:38:01  iter: 16279  total_loss: 30.15  loss_ce: 0  loss_mask: 0.8272  loss_dice: 2.152  loss_seg: 0.6583  loss_ce_0: 0  loss_mask_0: 0.8477  loss_dice_0: 2.233  loss_ce_1: 0  loss_mask_1: 0.8317  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.8321  loss_dice_2: 2.145  loss_ce_3: 0  loss_mask_3: 0.8294  loss_dice_3: 2.138  loss_ce_4: 0  loss_mask_4: 0.8275  loss_dice_4: 2.15  loss_ce_5: 0  loss_mask_5: 0.8303  loss_dice_5: 2.15  loss_ce_6: 0  loss_mask_6: 0.8318  loss_dice_6: 2.143  loss_ce_7: 0  loss_mask_7: 0.8315  loss_dice_7: 2.147  loss_ce_8: 0  loss_mask_8: 0.8313  loss_dice_8: 2.142  time: 2.0374  data_time: 0.0328  lr: 7.5212e-05  max_mem: 6006M
[02/18 09:13:06] d2.utils.events INFO:  eta: 19:37:53  iter: 16299  total_loss: 31.81  loss_ce: 0  loss_mask: 0.8423  loss_dice: 2.239  loss_seg: 0.9438  loss_ce_0: 0  loss_mask_0: 0.8403  loss_dice_0: 2.338  loss_ce_1: 0  loss_mask_1: 0.8592  loss_dice_1: 2.261  loss_ce_2: 0  loss_mask_2: 0.8557  loss_dice_2: 2.239  loss_ce_3: 0  loss_mask_3: 0.8499  loss_dice_3: 2.223  loss_ce_4: 0  loss_mask_4: 0.8485  loss_dice_4: 2.228  loss_ce_5: 0  loss_mask_5: 0.8462  loss_dice_5: 2.227  loss_ce_6: 0  loss_mask_6: 0.8477  loss_dice_6: 2.222  loss_ce_7: 0  loss_mask_7: 0.8466  loss_dice_7: 2.221  loss_ce_8: 0  loss_mask_8: 0.8454  loss_dice_8: 2.222  time: 2.0371  data_time: 0.0302  lr: 7.5181e-05  max_mem: 6006M
[02/18 09:13:39] d2.utils.events INFO:  eta: 19:36:56  iter: 16319  total_loss: 32.24  loss_ce: 0  loss_mask: 0.8383  loss_dice: 2.258  loss_seg: 1.014  loss_ce_0: 0  loss_mask_0: 0.8421  loss_dice_0: 2.328  loss_ce_1: 0  loss_mask_1: 0.8354  loss_dice_1: 2.269  loss_ce_2: 0  loss_mask_2: 0.8352  loss_dice_2: 2.255  loss_ce_3: 0  loss_mask_3: 0.8392  loss_dice_3: 2.245  loss_ce_4: 0  loss_mask_4: 0.8443  loss_dice_4: 2.244  loss_ce_5: 0  loss_mask_5: 0.8418  loss_dice_5: 2.246  loss_ce_6: 0  loss_mask_6: 0.8445  loss_dice_6: 2.249  loss_ce_7: 0  loss_mask_7: 0.8452  loss_dice_7: 2.245  loss_ce_8: 0  loss_mask_8: 0.8441  loss_dice_8: 2.245  time: 2.0366  data_time: 0.0311  lr: 7.515e-05  max_mem: 6006M
[02/18 09:14:12] d2.utils.events INFO:  eta: 19:36:24  iter: 16339  total_loss: 32.3  loss_ce: 0  loss_mask: 0.8519  loss_dice: 2.308  loss_seg: 0.7863  loss_ce_0: 0  loss_mask_0: 0.8608  loss_dice_0: 2.35  loss_ce_1: 0  loss_mask_1: 0.8611  loss_dice_1: 2.309  loss_ce_2: 0  loss_mask_2: 0.8616  loss_dice_2: 2.301  loss_ce_3: 0  loss_mask_3: 0.8616  loss_dice_3: 2.292  loss_ce_4: 0  loss_mask_4: 0.8582  loss_dice_4: 2.291  loss_ce_5: 0  loss_mask_5: 0.8537  loss_dice_5: 2.298  loss_ce_6: 0  loss_mask_6: 0.8593  loss_dice_6: 2.296  loss_ce_7: 0  loss_mask_7: 0.8574  loss_dice_7: 2.3  loss_ce_8: 0  loss_mask_8: 0.8626  loss_dice_8: 2.3  time: 2.0361  data_time: 0.0300  lr: 7.5119e-05  max_mem: 6006M
[02/18 09:14:47] d2.utils.events INFO:  eta: 19:36:16  iter: 16359  total_loss: 31.89  loss_ce: 0  loss_mask: 0.8507  loss_dice: 2.177  loss_seg: 0.7542  loss_ce_0: 0  loss_mask_0: 0.866  loss_dice_0: 2.25  loss_ce_1: 0  loss_mask_1: 0.8485  loss_dice_1: 2.184  loss_ce_2: 0  loss_mask_2: 0.8542  loss_dice_2: 2.174  loss_ce_3: 0  loss_mask_3: 0.8507  loss_dice_3: 2.17  loss_ce_4: 0  loss_mask_4: 0.8548  loss_dice_4: 2.167  loss_ce_5: 0  loss_mask_5: 0.8559  loss_dice_5: 2.164  loss_ce_6: 0  loss_mask_6: 0.861  loss_dice_6: 2.16  loss_ce_7: 0  loss_mask_7: 0.8611  loss_dice_7: 2.164  loss_ce_8: 0  loss_mask_8: 0.858  loss_dice_8: 2.165  time: 2.0357  data_time: 0.0303  lr: 7.5088e-05  max_mem: 6006M
[02/18 09:15:19] d2.utils.events INFO:  eta: 19:35:44  iter: 16379  total_loss: 30.78  loss_ce: 0  loss_mask: 0.7985  loss_dice: 2.198  loss_seg: 1.009  loss_ce_0: 0  loss_mask_0: 0.7927  loss_dice_0: 2.265  loss_ce_1: 0  loss_mask_1: 0.8002  loss_dice_1: 2.209  loss_ce_2: 0  loss_mask_2: 0.8017  loss_dice_2: 2.2  loss_ce_3: 0  loss_mask_3: 0.7947  loss_dice_3: 2.192  loss_ce_4: 0  loss_mask_4: 0.8018  loss_dice_4: 2.19  loss_ce_5: 0  loss_mask_5: 0.8  loss_dice_5: 2.189  loss_ce_6: 0  loss_mask_6: 0.7975  loss_dice_6: 2.19  loss_ce_7: 0  loss_mask_7: 0.802  loss_dice_7: 2.193  loss_ce_8: 0  loss_mask_8: 0.8043  loss_dice_8: 2.188  time: 2.0352  data_time: 0.0228  lr: 7.5057e-05  max_mem: 6006M
[02/18 09:15:50] d2.utils.events INFO:  eta: 19:33:45  iter: 16399  total_loss: 29.77  loss_ce: 0  loss_mask: 0.8081  loss_dice: 2.085  loss_seg: 0.7065  loss_ce_0: 0  loss_mask_0: 0.8232  loss_dice_0: 2.146  loss_ce_1: 0  loss_mask_1: 0.8134  loss_dice_1: 2.093  loss_ce_2: 0  loss_mask_2: 0.8144  loss_dice_2: 2.079  loss_ce_3: 0  loss_mask_3: 0.8141  loss_dice_3: 2.07  loss_ce_4: 0  loss_mask_4: 0.8144  loss_dice_4: 2.074  loss_ce_5: 0  loss_mask_5: 0.815  loss_dice_5: 2.065  loss_ce_6: 0  loss_mask_6: 0.8134  loss_dice_6: 2.067  loss_ce_7: 0  loss_mask_7: 0.8131  loss_dice_7: 2.068  loss_ce_8: 0  loss_mask_8: 0.8137  loss_dice_8: 2.073  time: 2.0347  data_time: 0.0328  lr: 7.5026e-05  max_mem: 6006M
[02/18 09:16:23] d2.utils.events INFO:  eta: 19:34:03  iter: 16419  total_loss: 31.87  loss_ce: 0  loss_mask: 0.8188  loss_dice: 2.248  loss_seg: 1.01  loss_ce_0: 0  loss_mask_0: 0.8365  loss_dice_0: 2.318  loss_ce_1: 0  loss_mask_1: 0.8163  loss_dice_1: 2.256  loss_ce_2: 0  loss_mask_2: 0.8225  loss_dice_2: 2.239  loss_ce_3: 0  loss_mask_3: 0.8164  loss_dice_3: 2.23  loss_ce_4: 0  loss_mask_4: 0.8191  loss_dice_4: 2.229  loss_ce_5: 0  loss_mask_5: 0.8156  loss_dice_5: 2.229  loss_ce_6: 0  loss_mask_6: 0.8194  loss_dice_6: 2.23  loss_ce_7: 0  loss_mask_7: 0.8207  loss_dice_7: 2.233  loss_ce_8: 0  loss_mask_8: 0.816  loss_dice_8: 2.235  time: 2.0342  data_time: 0.0322  lr: 7.4995e-05  max_mem: 6006M
[02/18 09:16:56] d2.utils.events INFO:  eta: 19:33:22  iter: 16439  total_loss: 33.28  loss_ce: 0  loss_mask: 0.8417  loss_dice: 2.349  loss_seg: 0.8747  loss_ce_0: 0  loss_mask_0: 0.8335  loss_dice_0: 2.411  loss_ce_1: 0  loss_mask_1: 0.8494  loss_dice_1: 2.37  loss_ce_2: 0  loss_mask_2: 0.8441  loss_dice_2: 2.361  loss_ce_3: 0  loss_mask_3: 0.8471  loss_dice_3: 2.341  loss_ce_4: 0  loss_mask_4: 0.8457  loss_dice_4: 2.337  loss_ce_5: 0  loss_mask_5: 0.8483  loss_dice_5: 2.344  loss_ce_6: 0  loss_mask_6: 0.8436  loss_dice_6: 2.339  loss_ce_7: 0  loss_mask_7: 0.8472  loss_dice_7: 2.337  loss_ce_8: 0  loss_mask_8: 0.8482  loss_dice_8: 2.335  time: 2.0337  data_time: 0.0277  lr: 7.4964e-05  max_mem: 6006M
[02/18 09:17:29] d2.utils.events INFO:  eta: 19:32:27  iter: 16459  total_loss: 31.64  loss_ce: 0  loss_mask: 0.8168  loss_dice: 2.283  loss_seg: 0.6105  loss_ce_0: 0  loss_mask_0: 0.8346  loss_dice_0: 2.343  loss_ce_1: 0  loss_mask_1: 0.8345  loss_dice_1: 2.295  loss_ce_2: 0  loss_mask_2: 0.8333  loss_dice_2: 2.277  loss_ce_3: 0  loss_mask_3: 0.8263  loss_dice_3: 2.265  loss_ce_4: 0  loss_mask_4: 0.8276  loss_dice_4: 2.259  loss_ce_5: 0  loss_mask_5: 0.8267  loss_dice_5: 2.261  loss_ce_6: 0  loss_mask_6: 0.8268  loss_dice_6: 2.259  loss_ce_7: 0  loss_mask_7: 0.8279  loss_dice_7: 2.257  loss_ce_8: 0  loss_mask_8: 0.8288  loss_dice_8: 2.265  time: 2.0332  data_time: 0.0321  lr: 7.4933e-05  max_mem: 6006M
[02/18 09:18:02] d2.utils.events INFO:  eta: 19:31:18  iter: 16479  total_loss: 32.14  loss_ce: 0  loss_mask: 0.8455  loss_dice: 2.263  loss_seg: 0.906  loss_ce_0: 0  loss_mask_0: 0.8586  loss_dice_0: 2.295  loss_ce_1: 0  loss_mask_1: 0.8486  loss_dice_1: 2.277  loss_ce_2: 0  loss_mask_2: 0.8458  loss_dice_2: 2.27  loss_ce_3: 0  loss_mask_3: 0.8455  loss_dice_3: 2.259  loss_ce_4: 0  loss_mask_4: 0.8438  loss_dice_4: 2.254  loss_ce_5: 0  loss_mask_5: 0.8429  loss_dice_5: 2.252  loss_ce_6: 0  loss_mask_6: 0.8432  loss_dice_6: 2.249  loss_ce_7: 0  loss_mask_7: 0.8442  loss_dice_7: 2.254  loss_ce_8: 0  loss_mask_8: 0.8465  loss_dice_8: 2.258  time: 2.0327  data_time: 0.0308  lr: 7.4902e-05  max_mem: 6006M
[02/18 09:18:35] d2.utils.events INFO:  eta: 19:30:28  iter: 16499  total_loss: 31.77  loss_ce: 0  loss_mask: 0.8369  loss_dice: 2.275  loss_seg: 0.9087  loss_ce_0: 0  loss_mask_0: 0.8388  loss_dice_0: 2.329  loss_ce_1: 0  loss_mask_1: 0.8394  loss_dice_1: 2.278  loss_ce_2: 0  loss_mask_2: 0.8422  loss_dice_2: 2.264  loss_ce_3: 0  loss_mask_3: 0.8471  loss_dice_3: 2.255  loss_ce_4: 0  loss_mask_4: 0.8438  loss_dice_4: 2.261  loss_ce_5: 0  loss_mask_5: 0.844  loss_dice_5: 2.263  loss_ce_6: 0  loss_mask_6: 0.8447  loss_dice_6: 2.26  loss_ce_7: 0  loss_mask_7: 0.8448  loss_dice_7: 2.257  loss_ce_8: 0  loss_mask_8: 0.8455  loss_dice_8: 2.263  time: 2.0323  data_time: 0.0327  lr: 7.4871e-05  max_mem: 6006M
[02/18 09:19:08] d2.utils.events INFO:  eta: 19:29:36  iter: 16519  total_loss: 32.37  loss_ce: 0  loss_mask: 0.8413  loss_dice: 2.224  loss_seg: 0.7974  loss_ce_0: 0  loss_mask_0: 0.8541  loss_dice_0: 2.286  loss_ce_1: 0  loss_mask_1: 0.853  loss_dice_1: 2.241  loss_ce_2: 0  loss_mask_2: 0.8529  loss_dice_2: 2.22  loss_ce_3: 0  loss_mask_3: 0.8507  loss_dice_3: 2.212  loss_ce_4: 0  loss_mask_4: 0.8451  loss_dice_4: 2.214  loss_ce_5: 0  loss_mask_5: 0.8476  loss_dice_5: 2.217  loss_ce_6: 0  loss_mask_6: 0.8475  loss_dice_6: 2.211  loss_ce_7: 0  loss_mask_7: 0.849  loss_dice_7: 2.212  loss_ce_8: 0  loss_mask_8: 0.8437  loss_dice_8: 2.212  time: 2.0318  data_time: 0.0243  lr: 7.484e-05  max_mem: 6006M
[02/18 09:19:40] d2.utils.events INFO:  eta: 19:29:25  iter: 16539  total_loss: 31.23  loss_ce: 0  loss_mask: 0.8329  loss_dice: 2.195  loss_seg: 0.9445  loss_ce_0: 0  loss_mask_0: 0.8472  loss_dice_0: 2.233  loss_ce_1: 0  loss_mask_1: 0.8422  loss_dice_1: 2.207  loss_ce_2: 0  loss_mask_2: 0.8338  loss_dice_2: 2.196  loss_ce_3: 0  loss_mask_3: 0.8306  loss_dice_3: 2.182  loss_ce_4: 0  loss_mask_4: 0.8318  loss_dice_4: 2.186  loss_ce_5: 0  loss_mask_5: 0.8346  loss_dice_5: 2.197  loss_ce_6: 0  loss_mask_6: 0.8326  loss_dice_6: 2.192  loss_ce_7: 0  loss_mask_7: 0.8333  loss_dice_7: 2.193  loss_ce_8: 0  loss_mask_8: 0.8333  loss_dice_8: 2.188  time: 2.0313  data_time: 0.0311  lr: 7.4809e-05  max_mem: 6006M
[02/18 09:20:16] d2.utils.events INFO:  eta: 19:29:09  iter: 16559  total_loss: 32.45  loss_ce: 0  loss_mask: 0.8538  loss_dice: 2.271  loss_seg: 0.7696  loss_ce_0: 0  loss_mask_0: 0.8604  loss_dice_0: 2.326  loss_ce_1: 0  loss_mask_1: 0.8574  loss_dice_1: 2.268  loss_ce_2: 0  loss_mask_2: 0.8523  loss_dice_2: 2.269  loss_ce_3: 0  loss_mask_3: 0.8545  loss_dice_3: 2.267  loss_ce_4: 0  loss_mask_4: 0.8591  loss_dice_4: 2.261  loss_ce_5: 0  loss_mask_5: 0.8579  loss_dice_5: 2.27  loss_ce_6: 0  loss_mask_6: 0.8547  loss_dice_6: 2.266  loss_ce_7: 0  loss_mask_7: 0.8613  loss_dice_7: 2.269  loss_ce_8: 0  loss_mask_8: 0.86  loss_dice_8: 2.272  time: 2.0310  data_time: 0.0286  lr: 7.4778e-05  max_mem: 6006M
[02/18 09:20:51] d2.utils.events INFO:  eta: 19:28:54  iter: 16579  total_loss: 31.04  loss_ce: 0  loss_mask: 0.796  loss_dice: 2.183  loss_seg: 1.028  loss_ce_0: 0  loss_mask_0: 0.8123  loss_dice_0: 2.258  loss_ce_1: 0  loss_mask_1: 0.8015  loss_dice_1: 2.193  loss_ce_2: 0  loss_mask_2: 0.8013  loss_dice_2: 2.179  loss_ce_3: 0  loss_mask_3: 0.806  loss_dice_3: 2.156  loss_ce_4: 0  loss_mask_4: 0.8102  loss_dice_4: 2.164  loss_ce_5: 0  loss_mask_5: 0.8104  loss_dice_5: 2.166  loss_ce_6: 0  loss_mask_6: 0.8084  loss_dice_6: 2.161  loss_ce_7: 0  loss_mask_7: 0.8047  loss_dice_7: 2.169  loss_ce_8: 0  loss_mask_8: 0.804  loss_dice_8: 2.163  time: 2.0306  data_time: 0.0330  lr: 7.4747e-05  max_mem: 6006M
[02/18 09:21:24] d2.utils.events INFO:  eta: 19:28:41  iter: 16599  total_loss: 31.29  loss_ce: 0  loss_mask: 0.8728  loss_dice: 2.157  loss_seg: 1.013  loss_ce_0: 0  loss_mask_0: 0.8957  loss_dice_0: 2.252  loss_ce_1: 0  loss_mask_1: 0.8688  loss_dice_1: 2.17  loss_ce_2: 0  loss_mask_2: 0.8708  loss_dice_2: 2.147  loss_ce_3: 0  loss_mask_3: 0.8752  loss_dice_3: 2.135  loss_ce_4: 0  loss_mask_4: 0.8772  loss_dice_4: 2.133  loss_ce_5: 0  loss_mask_5: 0.8732  loss_dice_5: 2.14  loss_ce_6: 0  loss_mask_6: 0.8783  loss_dice_6: 2.136  loss_ce_7: 0  loss_mask_7: 0.8735  loss_dice_7: 2.136  loss_ce_8: 0  loss_mask_8: 0.8746  loss_dice_8: 2.139  time: 2.0302  data_time: 0.0368  lr: 7.4716e-05  max_mem: 6006M
[02/18 09:21:58] d2.utils.events INFO:  eta: 19:28:27  iter: 16619  total_loss: 31.16  loss_ce: 0  loss_mask: 0.8245  loss_dice: 2.195  loss_seg: 1.191  loss_ce_0: 0  loss_mask_0: 0.8352  loss_dice_0: 2.278  loss_ce_1: 0  loss_mask_1: 0.8317  loss_dice_1: 2.216  loss_ce_2: 0  loss_mask_2: 0.8314  loss_dice_2: 2.193  loss_ce_3: 0  loss_mask_3: 0.8269  loss_dice_3: 2.177  loss_ce_4: 0  loss_mask_4: 0.8309  loss_dice_4: 2.175  loss_ce_5: 0  loss_mask_5: 0.8288  loss_dice_5: 2.178  loss_ce_6: 0  loss_mask_6: 0.8319  loss_dice_6: 2.182  loss_ce_7: 0  loss_mask_7: 0.8239  loss_dice_7: 2.189  loss_ce_8: 0  loss_mask_8: 0.8238  loss_dice_8: 2.185  time: 2.0298  data_time: 0.0429  lr: 7.4685e-05  max_mem: 6006M
[02/18 09:22:32] d2.utils.events INFO:  eta: 19:28:14  iter: 16639  total_loss: 33.33  loss_ce: 0  loss_mask: 0.8387  loss_dice: 2.347  loss_seg: 0.8948  loss_ce_0: 0  loss_mask_0: 0.8542  loss_dice_0: 2.413  loss_ce_1: 0  loss_mask_1: 0.8405  loss_dice_1: 2.366  loss_ce_2: 0  loss_mask_2: 0.8466  loss_dice_2: 2.343  loss_ce_3: 0  loss_mask_3: 0.8442  loss_dice_3: 2.338  loss_ce_4: 0  loss_mask_4: 0.8451  loss_dice_4: 2.336  loss_ce_5: 0  loss_mask_5: 0.8415  loss_dice_5: 2.336  loss_ce_6: 0  loss_mask_6: 0.8463  loss_dice_6: 2.334  loss_ce_7: 0  loss_mask_7: 0.8467  loss_dice_7: 2.337  loss_ce_8: 0  loss_mask_8: 0.8444  loss_dice_8: 2.337  time: 2.0294  data_time: 0.0394  lr: 7.4654e-05  max_mem: 6006M
[02/18 09:23:06] d2.utils.events INFO:  eta: 19:27:42  iter: 16659  total_loss: 34.01  loss_ce: 0  loss_mask: 0.8564  loss_dice: 2.355  loss_seg: 1.059  loss_ce_0: 0  loss_mask_0: 0.8677  loss_dice_0: 2.411  loss_ce_1: 0  loss_mask_1: 0.8549  loss_dice_1: 2.365  loss_ce_2: 0  loss_mask_2: 0.8575  loss_dice_2: 2.35  loss_ce_3: 0  loss_mask_3: 0.8622  loss_dice_3: 2.343  loss_ce_4: 0  loss_mask_4: 0.8579  loss_dice_4: 2.349  loss_ce_5: 0  loss_mask_5: 0.8577  loss_dice_5: 2.347  loss_ce_6: 0  loss_mask_6: 0.857  loss_dice_6: 2.348  loss_ce_7: 0  loss_mask_7: 0.8597  loss_dice_7: 2.349  loss_ce_8: 0  loss_mask_8: 0.8622  loss_dice_8: 2.343  time: 2.0290  data_time: 0.0499  lr: 7.4623e-05  max_mem: 6006M
[02/18 09:23:40] d2.utils.events INFO:  eta: 19:26:54  iter: 16679  total_loss: 31.56  loss_ce: 0  loss_mask: 0.8326  loss_dice: 2.259  loss_seg: 0.8151  loss_ce_0: 0  loss_mask_0: 0.8257  loss_dice_0: 2.292  loss_ce_1: 0  loss_mask_1: 0.836  loss_dice_1: 2.26  loss_ce_2: 0  loss_mask_2: 0.8374  loss_dice_2: 2.25  loss_ce_3: 0  loss_mask_3: 0.8393  loss_dice_3: 2.248  loss_ce_4: 0  loss_mask_4: 0.8383  loss_dice_4: 2.24  loss_ce_5: 0  loss_mask_5: 0.8397  loss_dice_5: 2.242  loss_ce_6: 0  loss_mask_6: 0.8402  loss_dice_6: 2.248  loss_ce_7: 0  loss_mask_7: 0.8407  loss_dice_7: 2.246  loss_ce_8: 0  loss_mask_8: 0.8405  loss_dice_8: 2.246  time: 2.0286  data_time: 0.0395  lr: 7.4592e-05  max_mem: 6006M
[02/18 09:24:13] d2.utils.events INFO:  eta: 19:25:36  iter: 16699  total_loss: 33.67  loss_ce: 0  loss_mask: 0.8615  loss_dice: 2.37  loss_seg: 1.07  loss_ce_0: 0  loss_mask_0: 0.8781  loss_dice_0: 2.438  loss_ce_1: 0  loss_mask_1: 0.8709  loss_dice_1: 2.382  loss_ce_2: 0  loss_mask_2: 0.8657  loss_dice_2: 2.369  loss_ce_3: 0  loss_mask_3: 0.8619  loss_dice_3: 2.359  loss_ce_4: 0  loss_mask_4: 0.8652  loss_dice_4: 2.362  loss_ce_5: 0  loss_mask_5: 0.8633  loss_dice_5: 2.353  loss_ce_6: 0  loss_mask_6: 0.8648  loss_dice_6: 2.35  loss_ce_7: 0  loss_mask_7: 0.8671  loss_dice_7: 2.349  loss_ce_8: 0  loss_mask_8: 0.8677  loss_dice_8: 2.353  time: 2.0281  data_time: 0.0355  lr: 7.4561e-05  max_mem: 6006M
[02/18 09:24:44] d2.utils.events INFO:  eta: 19:24:32  iter: 16719  total_loss: 32.66  loss_ce: 0  loss_mask: 0.8726  loss_dice: 2.252  loss_seg: 0.7018  loss_ce_0: 0  loss_mask_0: 0.8829  loss_dice_0: 2.306  loss_ce_1: 0  loss_mask_1: 0.8846  loss_dice_1: 2.261  loss_ce_2: 0  loss_mask_2: 0.8812  loss_dice_2: 2.249  loss_ce_3: 0  loss_mask_3: 0.8812  loss_dice_3: 2.244  loss_ce_4: 0  loss_mask_4: 0.8829  loss_dice_4: 2.248  loss_ce_5: 0  loss_mask_5: 0.8853  loss_dice_5: 2.249  loss_ce_6: 0  loss_mask_6: 0.8821  loss_dice_6: 2.252  loss_ce_7: 0  loss_mask_7: 0.8823  loss_dice_7: 2.251  loss_ce_8: 0  loss_mask_8: 0.879  loss_dice_8: 2.247  time: 2.0275  data_time: 0.0422  lr: 7.453e-05  max_mem: 6006M
[02/18 09:25:17] d2.utils.events INFO:  eta: 19:24:31  iter: 16739  total_loss: 31.95  loss_ce: 0  loss_mask: 0.8451  loss_dice: 2.292  loss_seg: 0.8089  loss_ce_0: 0  loss_mask_0: 0.8542  loss_dice_0: 2.34  loss_ce_1: 0  loss_mask_1: 0.8452  loss_dice_1: 2.31  loss_ce_2: 0  loss_mask_2: 0.8476  loss_dice_2: 2.287  loss_ce_3: 0  loss_mask_3: 0.8466  loss_dice_3: 2.278  loss_ce_4: 0  loss_mask_4: 0.8452  loss_dice_4: 2.28  loss_ce_5: 0  loss_mask_5: 0.8472  loss_dice_5: 2.274  loss_ce_6: 0  loss_mask_6: 0.8477  loss_dice_6: 2.271  loss_ce_7: 0  loss_mask_7: 0.8456  loss_dice_7: 2.279  loss_ce_8: 0  loss_mask_8: 0.846  loss_dice_8: 2.276  time: 2.0271  data_time: 0.0350  lr: 7.4499e-05  max_mem: 6006M
[02/18 09:25:50] d2.utils.events INFO:  eta: 19:24:41  iter: 16759  total_loss: 31.12  loss_ce: 0  loss_mask: 0.8245  loss_dice: 2.181  loss_seg: 0.8219  loss_ce_0: 0  loss_mask_0: 0.8584  loss_dice_0: 2.236  loss_ce_1: 0  loss_mask_1: 0.8281  loss_dice_1: 2.189  loss_ce_2: 0  loss_mask_2: 0.8271  loss_dice_2: 2.169  loss_ce_3: 0  loss_mask_3: 0.83  loss_dice_3: 2.166  loss_ce_4: 0  loss_mask_4: 0.8296  loss_dice_4: 2.165  loss_ce_5: 0  loss_mask_5: 0.8305  loss_dice_5: 2.158  loss_ce_6: 0  loss_mask_6: 0.8321  loss_dice_6: 2.159  loss_ce_7: 0  loss_mask_7: 0.8296  loss_dice_7: 2.163  loss_ce_8: 0  loss_mask_8: 0.8312  loss_dice_8: 2.166  time: 2.0266  data_time: 0.0270  lr: 7.4468e-05  max_mem: 6006M
[02/18 09:26:23] d2.utils.events INFO:  eta: 19:25:20  iter: 16779  total_loss: 32.67  loss_ce: 0  loss_mask: 0.8376  loss_dice: 2.291  loss_seg: 0.7205  loss_ce_0: 0  loss_mask_0: 0.8301  loss_dice_0: 2.357  loss_ce_1: 0  loss_mask_1: 0.8465  loss_dice_1: 2.302  loss_ce_2: 0  loss_mask_2: 0.8455  loss_dice_2: 2.29  loss_ce_3: 0  loss_mask_3: 0.8437  loss_dice_3: 2.279  loss_ce_4: 0  loss_mask_4: 0.8454  loss_dice_4: 2.282  loss_ce_5: 0  loss_mask_5: 0.8396  loss_dice_5: 2.277  loss_ce_6: 0  loss_mask_6: 0.8414  loss_dice_6: 2.275  loss_ce_7: 0  loss_mask_7: 0.8426  loss_dice_7: 2.277  loss_ce_8: 0  loss_mask_8: 0.8443  loss_dice_8: 2.275  time: 2.0262  data_time: 0.0350  lr: 7.4437e-05  max_mem: 6006M
[02/18 09:26:58] d2.utils.events INFO:  eta: 19:27:55  iter: 16799  total_loss: 31.88  loss_ce: 0  loss_mask: 0.8417  loss_dice: 2.256  loss_seg: 0.7339  loss_ce_0: 0  loss_mask_0: 0.8544  loss_dice_0: 2.325  loss_ce_1: 0  loss_mask_1: 0.8426  loss_dice_1: 2.266  loss_ce_2: 0  loss_mask_2: 0.8361  loss_dice_2: 2.253  loss_ce_3: 0  loss_mask_3: 0.844  loss_dice_3: 2.24  loss_ce_4: 0  loss_mask_4: 0.845  loss_dice_4: 2.238  loss_ce_5: 0  loss_mask_5: 0.8455  loss_dice_5: 2.24  loss_ce_6: 0  loss_mask_6: 0.8471  loss_dice_6: 2.24  loss_ce_7: 0  loss_mask_7: 0.8504  loss_dice_7: 2.238  loss_ce_8: 0  loss_mask_8: 0.851  loss_dice_8: 2.243  time: 2.0259  data_time: 0.0364  lr: 7.4406e-05  max_mem: 6006M
[02/18 09:27:31] d2.utils.events INFO:  eta: 19:27:22  iter: 16819  total_loss: 31.28  loss_ce: 0  loss_mask: 0.7982  loss_dice: 2.223  loss_seg: 0.8627  loss_ce_0: 0  loss_mask_0: 0.8146  loss_dice_0: 2.29  loss_ce_1: 0  loss_mask_1: 0.7994  loss_dice_1: 2.232  loss_ce_2: 0  loss_mask_2: 0.8074  loss_dice_2: 2.22  loss_ce_3: 0  loss_mask_3: 0.8066  loss_dice_3: 2.2  loss_ce_4: 0  loss_mask_4: 0.8025  loss_dice_4: 2.207  loss_ce_5: 0  loss_mask_5: 0.8023  loss_dice_5: 2.208  loss_ce_6: 0  loss_mask_6: 0.8033  loss_dice_6: 2.204  loss_ce_7: 0  loss_mask_7: 0.8022  loss_dice_7: 2.206  loss_ce_8: 0  loss_mask_8: 0.8015  loss_dice_8: 2.209  time: 2.0254  data_time: 0.0291  lr: 7.4375e-05  max_mem: 6006M
[02/18 09:28:03] d2.utils.events INFO:  eta: 19:27:33  iter: 16839  total_loss: 33.5  loss_ce: 0  loss_mask: 0.8693  loss_dice: 2.358  loss_seg: 0.709  loss_ce_0: 0  loss_mask_0: 0.8657  loss_dice_0: 2.397  loss_ce_1: 0  loss_mask_1: 0.8761  loss_dice_1: 2.344  loss_ce_2: 0  loss_mask_2: 0.8745  loss_dice_2: 2.344  loss_ce_3: 0  loss_mask_3: 0.8732  loss_dice_3: 2.344  loss_ce_4: 0  loss_mask_4: 0.8707  loss_dice_4: 2.349  loss_ce_5: 0  loss_mask_5: 0.8763  loss_dice_5: 2.35  loss_ce_6: 0  loss_mask_6: 0.8759  loss_dice_6: 2.346  loss_ce_7: 0  loss_mask_7: 0.876  loss_dice_7: 2.35  loss_ce_8: 0  loss_mask_8: 0.8744  loss_dice_8: 2.35  time: 2.0249  data_time: 0.0335  lr: 7.4344e-05  max_mem: 6006M
[02/18 09:28:36] d2.utils.events INFO:  eta: 19:25:32  iter: 16859  total_loss: 32.21  loss_ce: 0  loss_mask: 0.826  loss_dice: 2.309  loss_seg: 0.8149  loss_ce_0: 0  loss_mask_0: 0.8235  loss_dice_0: 2.371  loss_ce_1: 0  loss_mask_1: 0.8235  loss_dice_1: 2.324  loss_ce_2: 0  loss_mask_2: 0.822  loss_dice_2: 2.313  loss_ce_3: 0  loss_mask_3: 0.8278  loss_dice_3: 2.296  loss_ce_4: 0  loss_mask_4: 0.8275  loss_dice_4: 2.297  loss_ce_5: 0  loss_mask_5: 0.8259  loss_dice_5: 2.302  loss_ce_6: 0  loss_mask_6: 0.8308  loss_dice_6: 2.296  loss_ce_7: 0  loss_mask_7: 0.8309  loss_dice_7: 2.298  loss_ce_8: 0  loss_mask_8: 0.8318  loss_dice_8: 2.3  time: 2.0244  data_time: 0.0314  lr: 7.4313e-05  max_mem: 6006M
[02/18 09:29:08] d2.utils.events INFO:  eta: 19:24:00  iter: 16879  total_loss: 32.31  loss_ce: 0  loss_mask: 0.8721  loss_dice: 2.265  loss_seg: 0.7964  loss_ce_0: 0  loss_mask_0: 0.8816  loss_dice_0: 2.333  loss_ce_1: 0  loss_mask_1: 0.8799  loss_dice_1: 2.28  loss_ce_2: 0  loss_mask_2: 0.8774  loss_dice_2: 2.263  loss_ce_3: 0  loss_mask_3: 0.8783  loss_dice_3: 2.255  loss_ce_4: 0  loss_mask_4: 0.8748  loss_dice_4: 2.256  loss_ce_5: 0  loss_mask_5: 0.875  loss_dice_5: 2.262  loss_ce_6: 0  loss_mask_6: 0.8775  loss_dice_6: 2.264  loss_ce_7: 0  loss_mask_7: 0.8745  loss_dice_7: 2.259  loss_ce_8: 0  loss_mask_8: 0.8782  loss_dice_8: 2.265  time: 2.0239  data_time: 0.0298  lr: 7.4282e-05  max_mem: 6006M
[02/18 09:29:41] d2.utils.events INFO:  eta: 19:22:06  iter: 16899  total_loss: 32.58  loss_ce: 0  loss_mask: 0.8364  loss_dice: 2.328  loss_seg: 0.9369  loss_ce_0: 0  loss_mask_0: 0.8284  loss_dice_0: 2.379  loss_ce_1: 0  loss_mask_1: 0.8496  loss_dice_1: 2.328  loss_ce_2: 0  loss_mask_2: 0.8429  loss_dice_2: 2.316  loss_ce_3: 0  loss_mask_3: 0.8377  loss_dice_3: 2.315  loss_ce_4: 0  loss_mask_4: 0.8405  loss_dice_4: 2.314  loss_ce_5: 0  loss_mask_5: 0.8449  loss_dice_5: 2.319  loss_ce_6: 0  loss_mask_6: 0.8381  loss_dice_6: 2.306  loss_ce_7: 0  loss_mask_7: 0.8377  loss_dice_7: 2.314  loss_ce_8: 0  loss_mask_8: 0.8369  loss_dice_8: 2.31  time: 2.0235  data_time: 0.0342  lr: 7.4251e-05  max_mem: 6006M
[02/18 09:30:13] d2.utils.events INFO:  eta: 19:19:24  iter: 16919  total_loss: 33.66  loss_ce: 0  loss_mask: 0.8539  loss_dice: 2.357  loss_seg: 1.231  loss_ce_0: 0  loss_mask_0: 0.868  loss_dice_0: 2.43  loss_ce_1: 0  loss_mask_1: 0.8588  loss_dice_1: 2.362  loss_ce_2: 0  loss_mask_2: 0.8635  loss_dice_2: 2.348  loss_ce_3: 0  loss_mask_3: 0.8593  loss_dice_3: 2.333  loss_ce_4: 0  loss_mask_4: 0.86  loss_dice_4: 2.329  loss_ce_5: 0  loss_mask_5: 0.8601  loss_dice_5: 2.329  loss_ce_6: 0  loss_mask_6: 0.861  loss_dice_6: 2.34  loss_ce_7: 0  loss_mask_7: 0.8635  loss_dice_7: 2.334  loss_ce_8: 0  loss_mask_8: 0.8616  loss_dice_8: 2.335  time: 2.0230  data_time: 0.0288  lr: 7.422e-05  max_mem: 6006M
[02/18 09:30:45] d2.utils.events INFO:  eta: 19:18:37  iter: 16939  total_loss: 32.43  loss_ce: 0  loss_mask: 0.8405  loss_dice: 2.327  loss_seg: 0.8631  loss_ce_0: 0  loss_mask_0: 0.8456  loss_dice_0: 2.385  loss_ce_1: 0  loss_mask_1: 0.8423  loss_dice_1: 2.333  loss_ce_2: 0  loss_mask_2: 0.8456  loss_dice_2: 2.311  loss_ce_3: 0  loss_mask_3: 0.8467  loss_dice_3: 2.306  loss_ce_4: 0  loss_mask_4: 0.8491  loss_dice_4: 2.301  loss_ce_5: 0  loss_mask_5: 0.8459  loss_dice_5: 2.309  loss_ce_6: 0  loss_mask_6: 0.8475  loss_dice_6: 2.297  loss_ce_7: 0  loss_mask_7: 0.8436  loss_dice_7: 2.302  loss_ce_8: 0  loss_mask_8: 0.8454  loss_dice_8: 2.303  time: 2.0225  data_time: 0.0358  lr: 7.4189e-05  max_mem: 6006M
[02/18 09:31:19] d2.utils.events INFO:  eta: 19:17:45  iter: 16959  total_loss: 33.12  loss_ce: 0  loss_mask: 0.8765  loss_dice: 2.287  loss_seg: 0.9254  loss_ce_0: 0  loss_mask_0: 0.8982  loss_dice_0: 2.348  loss_ce_1: 0  loss_mask_1: 0.8845  loss_dice_1: 2.301  loss_ce_2: 0  loss_mask_2: 0.8787  loss_dice_2: 2.294  loss_ce_3: 0  loss_mask_3: 0.883  loss_dice_3: 2.28  loss_ce_4: 0  loss_mask_4: 0.8828  loss_dice_4: 2.284  loss_ce_5: 0  loss_mask_5: 0.8834  loss_dice_5: 2.286  loss_ce_6: 0  loss_mask_6: 0.8812  loss_dice_6: 2.284  loss_ce_7: 0  loss_mask_7: 0.8825  loss_dice_7: 2.283  loss_ce_8: 0  loss_mask_8: 0.8806  loss_dice_8: 2.29  time: 2.0221  data_time: 0.0228  lr: 7.4158e-05  max_mem: 6006M
[02/18 09:31:53] d2.utils.events INFO:  eta: 19:17:48  iter: 16979  total_loss: 31.88  loss_ce: 0  loss_mask: 0.818  loss_dice: 2.192  loss_seg: 0.9009  loss_ce_0: 0  loss_mask_0: 0.8372  loss_dice_0: 2.275  loss_ce_1: 0  loss_mask_1: 0.8226  loss_dice_1: 2.211  loss_ce_2: 0  loss_mask_2: 0.8247  loss_dice_2: 2.193  loss_ce_3: 0  loss_mask_3: 0.8238  loss_dice_3: 2.189  loss_ce_4: 0  loss_mask_4: 0.8227  loss_dice_4: 2.193  loss_ce_5: 0  loss_mask_5: 0.8264  loss_dice_5: 2.189  loss_ce_6: 0  loss_mask_6: 0.8262  loss_dice_6: 2.187  loss_ce_7: 0  loss_mask_7: 0.8272  loss_dice_7: 2.186  loss_ce_8: 0  loss_mask_8: 0.8244  loss_dice_8: 2.181  time: 2.0217  data_time: 0.0243  lr: 7.4127e-05  max_mem: 6006M
[02/18 09:32:25] d2.utils.events INFO:  eta: 19:17:31  iter: 16999  total_loss: 31.37  loss_ce: 0  loss_mask: 0.8156  loss_dice: 2.231  loss_seg: 0.87  loss_ce_0: 0  loss_mask_0: 0.8242  loss_dice_0: 2.315  loss_ce_1: 0  loss_mask_1: 0.8098  loss_dice_1: 2.235  loss_ce_2: 0  loss_mask_2: 0.8223  loss_dice_2: 2.223  loss_ce_3: 0  loss_mask_3: 0.8227  loss_dice_3: 2.215  loss_ce_4: 0  loss_mask_4: 0.8215  loss_dice_4: 2.222  loss_ce_5: 0  loss_mask_5: 0.8159  loss_dice_5: 2.221  loss_ce_6: 0  loss_mask_6: 0.8159  loss_dice_6: 2.221  loss_ce_7: 0  loss_mask_7: 0.817  loss_dice_7: 2.218  loss_ce_8: 0  loss_mask_8: 0.8128  loss_dice_8: 2.218  time: 2.0212  data_time: 0.0301  lr: 7.4096e-05  max_mem: 6006M
[02/18 09:32:56] d2.utils.events INFO:  eta: 19:17:21  iter: 17019  total_loss: 32.89  loss_ce: 0  loss_mask: 0.8405  loss_dice: 2.326  loss_seg: 0.7606  loss_ce_0: 0  loss_mask_0: 0.8512  loss_dice_0: 2.395  loss_ce_1: 0  loss_mask_1: 0.8503  loss_dice_1: 2.344  loss_ce_2: 0  loss_mask_2: 0.8497  loss_dice_2: 2.329  loss_ce_3: 0  loss_mask_3: 0.8496  loss_dice_3: 2.306  loss_ce_4: 0  loss_mask_4: 0.8473  loss_dice_4: 2.306  loss_ce_5: 0  loss_mask_5: 0.8466  loss_dice_5: 2.308  loss_ce_6: 0  loss_mask_6: 0.8515  loss_dice_6: 2.301  loss_ce_7: 0  loss_mask_7: 0.848  loss_dice_7: 2.305  loss_ce_8: 0  loss_mask_8: 0.8458  loss_dice_8: 2.305  time: 2.0206  data_time: 0.0330  lr: 7.4065e-05  max_mem: 6006M
[02/18 09:33:28] d2.utils.events INFO:  eta: 19:18:05  iter: 17039  total_loss: 32.8  loss_ce: 0  loss_mask: 0.8336  loss_dice: 2.378  loss_seg: 0.7163  loss_ce_0: 0  loss_mask_0: 0.8381  loss_dice_0: 2.466  loss_ce_1: 0  loss_mask_1: 0.8376  loss_dice_1: 2.391  loss_ce_2: 0  loss_mask_2: 0.8352  loss_dice_2: 2.375  loss_ce_3: 0  loss_mask_3: 0.8337  loss_dice_3: 2.365  loss_ce_4: 0  loss_mask_4: 0.8392  loss_dice_4: 2.365  loss_ce_5: 0  loss_mask_5: 0.8371  loss_dice_5: 2.365  loss_ce_6: 0  loss_mask_6: 0.8361  loss_dice_6: 2.365  loss_ce_7: 0  loss_mask_7: 0.8371  loss_dice_7: 2.36  loss_ce_8: 0  loss_mask_8: 0.8398  loss_dice_8: 2.362  time: 2.0202  data_time: 0.0235  lr: 7.4034e-05  max_mem: 6006M
[02/18 09:33:59] d2.utils.events INFO:  eta: 19:15:03  iter: 17059  total_loss: 31.73  loss_ce: 0  loss_mask: 0.8336  loss_dice: 2.233  loss_seg: 0.9487  loss_ce_0: 0  loss_mask_0: 0.8303  loss_dice_0: 2.292  loss_ce_1: 0  loss_mask_1: 0.8398  loss_dice_1: 2.238  loss_ce_2: 0  loss_mask_2: 0.8412  loss_dice_2: 2.229  loss_ce_3: 0  loss_mask_3: 0.8406  loss_dice_3: 2.222  loss_ce_4: 0  loss_mask_4: 0.8467  loss_dice_4: 2.217  loss_ce_5: 0  loss_mask_5: 0.845  loss_dice_5: 2.215  loss_ce_6: 0  loss_mask_6: 0.8402  loss_dice_6: 2.218  loss_ce_7: 0  loss_mask_7: 0.8397  loss_dice_7: 2.221  loss_ce_8: 0  loss_mask_8: 0.841  loss_dice_8: 2.222  time: 2.0196  data_time: 0.0322  lr: 7.4003e-05  max_mem: 6006M
[02/18 09:34:32] d2.utils.events INFO:  eta: 19:11:52  iter: 17079  total_loss: 32.97  loss_ce: 0  loss_mask: 0.8214  loss_dice: 2.317  loss_seg: 0.9601  loss_ce_0: 0  loss_mask_0: 0.813  loss_dice_0: 2.407  loss_ce_1: 0  loss_mask_1: 0.8197  loss_dice_1: 2.332  loss_ce_2: 0  loss_mask_2: 0.8164  loss_dice_2: 2.314  loss_ce_3: 0  loss_mask_3: 0.8192  loss_dice_3: 2.305  loss_ce_4: 0  loss_mask_4: 0.828  loss_dice_4: 2.309  loss_ce_5: 0  loss_mask_5: 0.8264  loss_dice_5: 2.302  loss_ce_6: 0  loss_mask_6: 0.8294  loss_dice_6: 2.298  loss_ce_7: 0  loss_mask_7: 0.825  loss_dice_7: 2.3  loss_ce_8: 0  loss_mask_8: 0.8268  loss_dice_8: 2.304  time: 2.0191  data_time: 0.0306  lr: 7.3972e-05  max_mem: 6006M
[02/18 09:35:04] d2.utils.events INFO:  eta: 19:11:20  iter: 17099  total_loss: 32.32  loss_ce: 0  loss_mask: 0.8586  loss_dice: 2.239  loss_seg: 1.164  loss_ce_0: 0  loss_mask_0: 0.864  loss_dice_0: 2.321  loss_ce_1: 0  loss_mask_1: 0.8632  loss_dice_1: 2.254  loss_ce_2: 0  loss_mask_2: 0.8613  loss_dice_2: 2.239  loss_ce_3: 0  loss_mask_3: 0.8568  loss_dice_3: 2.233  loss_ce_4: 0  loss_mask_4: 0.8574  loss_dice_4: 2.227  loss_ce_5: 0  loss_mask_5: 0.8569  loss_dice_5: 2.238  loss_ce_6: 0  loss_mask_6: 0.8625  loss_dice_6: 2.233  loss_ce_7: 0  loss_mask_7: 0.8649  loss_dice_7: 2.233  loss_ce_8: 0  loss_mask_8: 0.8626  loss_dice_8: 2.238  time: 2.0187  data_time: 0.0357  lr: 7.3941e-05  max_mem: 6006M
[02/18 09:35:38] d2.utils.events INFO:  eta: 19:10:48  iter: 17119  total_loss: 31.71  loss_ce: 0  loss_mask: 0.8243  loss_dice: 2.269  loss_seg: 1.031  loss_ce_0: 0  loss_mask_0: 0.8348  loss_dice_0: 2.327  loss_ce_1: 0  loss_mask_1: 0.8301  loss_dice_1: 2.263  loss_ce_2: 0  loss_mask_2: 0.8334  loss_dice_2: 2.251  loss_ce_3: 0  loss_mask_3: 0.8336  loss_dice_3: 2.236  loss_ce_4: 0  loss_mask_4: 0.8348  loss_dice_4: 2.247  loss_ce_5: 0  loss_mask_5: 0.8345  loss_dice_5: 2.242  loss_ce_6: 0  loss_mask_6: 0.837  loss_dice_6: 2.244  loss_ce_7: 0  loss_mask_7: 0.834  loss_dice_7: 2.251  loss_ce_8: 0  loss_mask_8: 0.836  loss_dice_8: 2.249  time: 2.0183  data_time: 0.0292  lr: 7.391e-05  max_mem: 6006M
[02/18 09:36:10] d2.utils.events INFO:  eta: 19:10:41  iter: 17139  total_loss: 33.13  loss_ce: 0  loss_mask: 0.8678  loss_dice: 2.347  loss_seg: 0.7731  loss_ce_0: 0  loss_mask_0: 0.891  loss_dice_0: 2.423  loss_ce_1: 0  loss_mask_1: 0.8759  loss_dice_1: 2.374  loss_ce_2: 0  loss_mask_2: 0.874  loss_dice_2: 2.346  loss_ce_3: 0  loss_mask_3: 0.8746  loss_dice_3: 2.332  loss_ce_4: 0  loss_mask_4: 0.8726  loss_dice_4: 2.339  loss_ce_5: 0  loss_mask_5: 0.8728  loss_dice_5: 2.333  loss_ce_6: 0  loss_mask_6: 0.8764  loss_dice_6: 2.328  loss_ce_7: 0  loss_mask_7: 0.8765  loss_dice_7: 2.322  loss_ce_8: 0  loss_mask_8: 0.8774  loss_dice_8: 2.323  time: 2.0178  data_time: 0.0267  lr: 7.3879e-05  max_mem: 6006M
[02/18 09:36:44] d2.utils.events INFO:  eta: 19:09:31  iter: 17159  total_loss: 32.14  loss_ce: 0  loss_mask: 0.8592  loss_dice: 2.258  loss_seg: 0.895  loss_ce_0: 0  loss_mask_0: 0.8758  loss_dice_0: 2.329  loss_ce_1: 0  loss_mask_1: 0.8679  loss_dice_1: 2.27  loss_ce_2: 0  loss_mask_2: 0.8617  loss_dice_2: 2.254  loss_ce_3: 0  loss_mask_3: 0.8571  loss_dice_3: 2.251  loss_ce_4: 0  loss_mask_4: 0.8543  loss_dice_4: 2.247  loss_ce_5: 0  loss_mask_5: 0.8588  loss_dice_5: 2.254  loss_ce_6: 0  loss_mask_6: 0.8587  loss_dice_6: 2.248  loss_ce_7: 0  loss_mask_7: 0.8534  loss_dice_7: 2.248  loss_ce_8: 0  loss_mask_8: 0.8554  loss_dice_8: 2.246  time: 2.0174  data_time: 0.0270  lr: 7.3848e-05  max_mem: 6006M
[02/18 09:37:14] d2.utils.events INFO:  eta: 19:06:58  iter: 17179  total_loss: 32.62  loss_ce: 0  loss_mask: 0.8484  loss_dice: 2.327  loss_seg: 0.9759  loss_ce_0: 0  loss_mask_0: 0.843  loss_dice_0: 2.394  loss_ce_1: 0  loss_mask_1: 0.8452  loss_dice_1: 2.34  loss_ce_2: 0  loss_mask_2: 0.8478  loss_dice_2: 2.327  loss_ce_3: 0  loss_mask_3: 0.8481  loss_dice_3: 2.31  loss_ce_4: 0  loss_mask_4: 0.8498  loss_dice_4: 2.313  loss_ce_5: 0  loss_mask_5: 0.8494  loss_dice_5: 2.315  loss_ce_6: 0  loss_mask_6: 0.8528  loss_dice_6: 2.308  loss_ce_7: 0  loss_mask_7: 0.8501  loss_dice_7: 2.304  loss_ce_8: 0  loss_mask_8: 0.8488  loss_dice_8: 2.316  time: 2.0168  data_time: 0.0306  lr: 7.3817e-05  max_mem: 6006M
[02/18 09:37:48] d2.utils.events INFO:  eta: 19:09:04  iter: 17199  total_loss: 30.6  loss_ce: 0  loss_mask: 0.7683  loss_dice: 2.192  loss_seg: 0.8068  loss_ce_0: 0  loss_mask_0: 0.7644  loss_dice_0: 2.272  loss_ce_1: 0  loss_mask_1: 0.7637  loss_dice_1: 2.192  loss_ce_2: 0  loss_mask_2: 0.7662  loss_dice_2: 2.182  loss_ce_3: 0  loss_mask_3: 0.7697  loss_dice_3: 2.175  loss_ce_4: 0  loss_mask_4: 0.7712  loss_dice_4: 2.175  loss_ce_5: 0  loss_mask_5: 0.7722  loss_dice_5: 2.176  loss_ce_6: 0  loss_mask_6: 0.7713  loss_dice_6: 2.176  loss_ce_7: 0  loss_mask_7: 0.7696  loss_dice_7: 2.174  loss_ce_8: 0  loss_mask_8: 0.7697  loss_dice_8: 2.181  time: 2.0164  data_time: 0.0252  lr: 7.3786e-05  max_mem: 6006M
[02/18 09:38:20] d2.utils.events INFO:  eta: 19:07:07  iter: 17219  total_loss: 32.51  loss_ce: 0  loss_mask: 0.8243  loss_dice: 2.3  loss_seg: 0.924  loss_ce_0: 0  loss_mask_0: 0.819  loss_dice_0: 2.355  loss_ce_1: 0  loss_mask_1: 0.8302  loss_dice_1: 2.311  loss_ce_2: 0  loss_mask_2: 0.8335  loss_dice_2: 2.291  loss_ce_3: 0  loss_mask_3: 0.8348  loss_dice_3: 2.278  loss_ce_4: 0  loss_mask_4: 0.8343  loss_dice_4: 2.286  loss_ce_5: 0  loss_mask_5: 0.8363  loss_dice_5: 2.288  loss_ce_6: 0  loss_mask_6: 0.8312  loss_dice_6: 2.292  loss_ce_7: 0  loss_mask_7: 0.8329  loss_dice_7: 2.292  loss_ce_8: 0  loss_mask_8: 0.8354  loss_dice_8: 2.292  time: 2.0160  data_time: 0.0317  lr: 7.3755e-05  max_mem: 6006M
[02/18 09:38:53] d2.utils.events INFO:  eta: 19:07:34  iter: 17239  total_loss: 29.84  loss_ce: 0  loss_mask: 0.8403  loss_dice: 2.13  loss_seg: 0.7518  loss_ce_0: 0  loss_mask_0: 0.8579  loss_dice_0: 2.178  loss_ce_1: 0  loss_mask_1: 0.8418  loss_dice_1: 2.125  loss_ce_2: 0  loss_mask_2: 0.8464  loss_dice_2: 2.113  loss_ce_3: 0  loss_mask_3: 0.8418  loss_dice_3: 2.113  loss_ce_4: 0  loss_mask_4: 0.8434  loss_dice_4: 2.106  loss_ce_5: 0  loss_mask_5: 0.8433  loss_dice_5: 2.113  loss_ce_6: 0  loss_mask_6: 0.8435  loss_dice_6: 2.11  loss_ce_7: 0  loss_mask_7: 0.8418  loss_dice_7: 2.111  loss_ce_8: 0  loss_mask_8: 0.8395  loss_dice_8: 2.121  time: 2.0155  data_time: 0.0335  lr: 7.3724e-05  max_mem: 6006M
[02/18 09:39:26] d2.utils.events INFO:  eta: 19:09:24  iter: 17259  total_loss: 31.86  loss_ce: 0  loss_mask: 0.7946  loss_dice: 2.236  loss_seg: 0.8074  loss_ce_0: 0  loss_mask_0: 0.7977  loss_dice_0: 2.28  loss_ce_1: 0  loss_mask_1: 0.7989  loss_dice_1: 2.243  loss_ce_2: 0  loss_mask_2: 0.803  loss_dice_2: 2.219  loss_ce_3: 0  loss_mask_3: 0.8003  loss_dice_3: 2.218  loss_ce_4: 0  loss_mask_4: 0.7972  loss_dice_4: 2.219  loss_ce_5: 0  loss_mask_5: 0.7995  loss_dice_5: 2.215  loss_ce_6: 0  loss_mask_6: 0.7991  loss_dice_6: 2.213  loss_ce_7: 0  loss_mask_7: 0.7976  loss_dice_7: 2.217  loss_ce_8: 0  loss_mask_8: 0.8008  loss_dice_8: 2.217  time: 2.0151  data_time: 0.0328  lr: 7.3693e-05  max_mem: 6006M
[02/18 09:39:57] d2.utils.events INFO:  eta: 19:08:51  iter: 17279  total_loss: 31.59  loss_ce: 0  loss_mask: 0.8176  loss_dice: 2.231  loss_seg: 0.8144  loss_ce_0: 0  loss_mask_0: 0.8272  loss_dice_0: 2.302  loss_ce_1: 0  loss_mask_1: 0.8238  loss_dice_1: 2.245  loss_ce_2: 0  loss_mask_2: 0.8243  loss_dice_2: 2.224  loss_ce_3: 0  loss_mask_3: 0.8245  loss_dice_3: 2.215  loss_ce_4: 0  loss_mask_4: 0.8262  loss_dice_4: 2.223  loss_ce_5: 0  loss_mask_5: 0.8276  loss_dice_5: 2.221  loss_ce_6: 0  loss_mask_6: 0.8252  loss_dice_6: 2.226  loss_ce_7: 0  loss_mask_7: 0.8205  loss_dice_7: 2.227  loss_ce_8: 0  loss_mask_8: 0.8218  loss_dice_8: 2.224  time: 2.0146  data_time: 0.0277  lr: 7.3662e-05  max_mem: 6006M
[02/18 09:40:30] d2.utils.events INFO:  eta: 19:07:30  iter: 17299  total_loss: 31.75  loss_ce: 0  loss_mask: 0.8347  loss_dice: 2.173  loss_seg: 0.8218  loss_ce_0: 0  loss_mask_0: 0.8393  loss_dice_0: 2.252  loss_ce_1: 0  loss_mask_1: 0.8345  loss_dice_1: 2.173  loss_ce_2: 0  loss_mask_2: 0.8395  loss_dice_2: 2.161  loss_ce_3: 0  loss_mask_3: 0.8351  loss_dice_3: 2.158  loss_ce_4: 0  loss_mask_4: 0.8355  loss_dice_4: 2.156  loss_ce_5: 0  loss_mask_5: 0.8379  loss_dice_5: 2.153  loss_ce_6: 0  loss_mask_6: 0.8405  loss_dice_6: 2.153  loss_ce_7: 0  loss_mask_7: 0.838  loss_dice_7: 2.159  loss_ce_8: 0  loss_mask_8: 0.8365  loss_dice_8: 2.158  time: 2.0141  data_time: 0.0400  lr: 7.3631e-05  max_mem: 6006M
[02/18 09:41:03] d2.utils.events INFO:  eta: 19:08:39  iter: 17319  total_loss: 32.92  loss_ce: 0  loss_mask: 0.8204  loss_dice: 2.344  loss_seg: 1.04  loss_ce_0: 0  loss_mask_0: 0.8207  loss_dice_0: 2.4  loss_ce_1: 0  loss_mask_1: 0.8255  loss_dice_1: 2.344  loss_ce_2: 0  loss_mask_2: 0.8285  loss_dice_2: 2.335  loss_ce_3: 0  loss_mask_3: 0.8322  loss_dice_3: 2.326  loss_ce_4: 0  loss_mask_4: 0.8289  loss_dice_4: 2.328  loss_ce_5: 0  loss_mask_5: 0.8291  loss_dice_5: 2.338  loss_ce_6: 0  loss_mask_6: 0.832  loss_dice_6: 2.325  loss_ce_7: 0  loss_mask_7: 0.8336  loss_dice_7: 2.334  loss_ce_8: 0  loss_mask_8: 0.8341  loss_dice_8: 2.338  time: 2.0137  data_time: 0.0304  lr: 7.36e-05  max_mem: 6006M
[02/18 09:41:34] d2.utils.events INFO:  eta: 19:07:33  iter: 17339  total_loss: 32.77  loss_ce: 0  loss_mask: 0.8506  loss_dice: 2.244  loss_seg: 0.909  loss_ce_0: 0  loss_mask_0: 0.8481  loss_dice_0: 2.308  loss_ce_1: 0  loss_mask_1: 0.8445  loss_dice_1: 2.263  loss_ce_2: 0  loss_mask_2: 0.8507  loss_dice_2: 2.233  loss_ce_3: 0  loss_mask_3: 0.8489  loss_dice_3: 2.235  loss_ce_4: 0  loss_mask_4: 0.8495  loss_dice_4: 2.235  loss_ce_5: 0  loss_mask_5: 0.8531  loss_dice_5: 2.237  loss_ce_6: 0  loss_mask_6: 0.8539  loss_dice_6: 2.235  loss_ce_7: 0  loss_mask_7: 0.8551  loss_dice_7: 2.228  loss_ce_8: 0  loss_mask_8: 0.8553  loss_dice_8: 2.229  time: 2.0132  data_time: 0.0300  lr: 7.3568e-05  max_mem: 6006M
[02/18 09:42:08] d2.utils.events INFO:  eta: 19:07:34  iter: 17359  total_loss: 31.97  loss_ce: 0  loss_mask: 0.8394  loss_dice: 2.232  loss_seg: 0.7899  loss_ce_0: 0  loss_mask_0: 0.8397  loss_dice_0: 2.291  loss_ce_1: 0  loss_mask_1: 0.8399  loss_dice_1: 2.244  loss_ce_2: 0  loss_mask_2: 0.8424  loss_dice_2: 2.237  loss_ce_3: 0  loss_mask_3: 0.8387  loss_dice_3: 2.221  loss_ce_4: 0  loss_mask_4: 0.8432  loss_dice_4: 2.222  loss_ce_5: 0  loss_mask_5: 0.8443  loss_dice_5: 2.226  loss_ce_6: 0  loss_mask_6: 0.8468  loss_dice_6: 2.23  loss_ce_7: 0  loss_mask_7: 0.8481  loss_dice_7: 2.221  loss_ce_8: 0  loss_mask_8: 0.8423  loss_dice_8: 2.223  time: 2.0128  data_time: 0.0341  lr: 7.3537e-05  max_mem: 6006M
[02/18 09:42:41] d2.utils.events INFO:  eta: 19:07:36  iter: 17379  total_loss: 31.72  loss_ce: 0  loss_mask: 0.7991  loss_dice: 2.247  loss_seg: 1.17  loss_ce_0: 0  loss_mask_0: 0.793  loss_dice_0: 2.331  loss_ce_1: 0  loss_mask_1: 0.7926  loss_dice_1: 2.25  loss_ce_2: 0  loss_mask_2: 0.7912  loss_dice_2: 2.241  loss_ce_3: 0  loss_mask_3: 0.7971  loss_dice_3: 2.24  loss_ce_4: 0  loss_mask_4: 0.7973  loss_dice_4: 2.241  loss_ce_5: 0  loss_mask_5: 0.7941  loss_dice_5: 2.239  loss_ce_6: 0  loss_mask_6: 0.7944  loss_dice_6: 2.237  loss_ce_7: 0  loss_mask_7: 0.7956  loss_dice_7: 2.23  loss_ce_8: 0  loss_mask_8: 0.7978  loss_dice_8: 2.233  time: 2.0124  data_time: 0.0317  lr: 7.3506e-05  max_mem: 6006M
[02/18 09:43:15] d2.utils.events INFO:  eta: 19:10:37  iter: 17399  total_loss: 32.84  loss_ce: 0  loss_mask: 0.8302  loss_dice: 2.35  loss_seg: 0.9263  loss_ce_0: 0  loss_mask_0: 0.8411  loss_dice_0: 2.408  loss_ce_1: 0  loss_mask_1: 0.8239  loss_dice_1: 2.347  loss_ce_2: 0  loss_mask_2: 0.8236  loss_dice_2: 2.334  loss_ce_3: 0  loss_mask_3: 0.8262  loss_dice_3: 2.324  loss_ce_4: 0  loss_mask_4: 0.8286  loss_dice_4: 2.32  loss_ce_5: 0  loss_mask_5: 0.829  loss_dice_5: 2.328  loss_ce_6: 0  loss_mask_6: 0.826  loss_dice_6: 2.334  loss_ce_7: 0  loss_mask_7: 0.8302  loss_dice_7: 2.34  loss_ce_8: 0  loss_mask_8: 0.828  loss_dice_8: 2.336  time: 2.0120  data_time: 0.0323  lr: 7.3475e-05  max_mem: 6006M
[02/18 09:43:47] d2.utils.events INFO:  eta: 19:08:52  iter: 17419  total_loss: 31.53  loss_ce: 0  loss_mask: 0.8359  loss_dice: 2.237  loss_seg: 0.8821  loss_ce_0: 0  loss_mask_0: 0.8326  loss_dice_0: 2.281  loss_ce_1: 0  loss_mask_1: 0.8418  loss_dice_1: 2.23  loss_ce_2: 0  loss_mask_2: 0.8411  loss_dice_2: 2.222  loss_ce_3: 0  loss_mask_3: 0.8375  loss_dice_3: 2.223  loss_ce_4: 0  loss_mask_4: 0.8383  loss_dice_4: 2.223  loss_ce_5: 0  loss_mask_5: 0.8352  loss_dice_5: 2.221  loss_ce_6: 0  loss_mask_6: 0.831  loss_dice_6: 2.219  loss_ce_7: 0  loss_mask_7: 0.8353  loss_dice_7: 2.218  loss_ce_8: 0  loss_mask_8: 0.8403  loss_dice_8: 2.221  time: 2.0115  data_time: 0.0324  lr: 7.3444e-05  max_mem: 6006M
[02/18 09:44:20] d2.utils.events INFO:  eta: 19:08:20  iter: 17439  total_loss: 32.76  loss_ce: 0  loss_mask: 0.8435  loss_dice: 2.274  loss_seg: 1.148  loss_ce_0: 0  loss_mask_0: 0.8499  loss_dice_0: 2.35  loss_ce_1: 0  loss_mask_1: 0.846  loss_dice_1: 2.294  loss_ce_2: 0  loss_mask_2: 0.8477  loss_dice_2: 2.277  loss_ce_3: 0  loss_mask_3: 0.8416  loss_dice_3: 2.262  loss_ce_4: 0  loss_mask_4: 0.8462  loss_dice_4: 2.273  loss_ce_5: 0  loss_mask_5: 0.8458  loss_dice_5: 2.267  loss_ce_6: 0  loss_mask_6: 0.8472  loss_dice_6: 2.267  loss_ce_7: 0  loss_mask_7: 0.8441  loss_dice_7: 2.272  loss_ce_8: 0  loss_mask_8: 0.8438  loss_dice_8: 2.269  time: 2.0111  data_time: 0.0259  lr: 7.3413e-05  max_mem: 6006M
[02/18 09:44:53] d2.utils.events INFO:  eta: 19:04:51  iter: 17459  total_loss: 32.98  loss_ce: 0  loss_mask: 0.8536  loss_dice: 2.267  loss_seg: 1.075  loss_ce_0: 0  loss_mask_0: 0.8853  loss_dice_0: 2.332  loss_ce_1: 0  loss_mask_1: 0.856  loss_dice_1: 2.287  loss_ce_2: 0  loss_mask_2: 0.8529  loss_dice_2: 2.279  loss_ce_3: 0  loss_mask_3: 0.8554  loss_dice_3: 2.258  loss_ce_4: 0  loss_mask_4: 0.8533  loss_dice_4: 2.256  loss_ce_5: 0  loss_mask_5: 0.8518  loss_dice_5: 2.258  loss_ce_6: 0  loss_mask_6: 0.8566  loss_dice_6: 2.258  loss_ce_7: 0  loss_mask_7: 0.8557  loss_dice_7: 2.253  loss_ce_8: 0  loss_mask_8: 0.8525  loss_dice_8: 2.258  time: 2.0107  data_time: 0.0309  lr: 7.3382e-05  max_mem: 6006M
[02/18 09:45:25] d2.utils.events INFO:  eta: 19:04:19  iter: 17479  total_loss: 31.18  loss_ce: 0  loss_mask: 0.8213  loss_dice: 2.191  loss_seg: 1.129  loss_ce_0: 0  loss_mask_0: 0.8252  loss_dice_0: 2.272  loss_ce_1: 0  loss_mask_1: 0.8213  loss_dice_1: 2.204  loss_ce_2: 0  loss_mask_2: 0.8245  loss_dice_2: 2.184  loss_ce_3: 0  loss_mask_3: 0.829  loss_dice_3: 2.181  loss_ce_4: 0  loss_mask_4: 0.8264  loss_dice_4: 2.177  loss_ce_5: 0  loss_mask_5: 0.8264  loss_dice_5: 2.182  loss_ce_6: 0  loss_mask_6: 0.8282  loss_dice_6: 2.176  loss_ce_7: 0  loss_mask_7: 0.8269  loss_dice_7: 2.181  loss_ce_8: 0  loss_mask_8: 0.8254  loss_dice_8: 2.178  time: 2.0102  data_time: 0.0301  lr: 7.3351e-05  max_mem: 6006M
[02/18 09:45:59] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 09:45:59] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 09:45:59] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 09:46:14] mask2former INFO: Inference done 11/1093. Dataloading: 0.0038 s/iter. Inference: 0.2410 s/iter. Eval: 0.1013 s/iter. Total: 0.3461 s/iter. ETA=0:06:14
[02/18 09:46:19] mask2former INFO: Inference done 26/1093. Dataloading: 0.0048 s/iter. Inference: 0.2382 s/iter. Eval: 0.1090 s/iter. Total: 0.3522 s/iter. ETA=0:06:15
[02/18 09:46:24] mask2former INFO: Inference done 40/1093. Dataloading: 0.0051 s/iter. Inference: 0.2408 s/iter. Eval: 0.1086 s/iter. Total: 0.3545 s/iter. ETA=0:06:13
[02/18 09:46:29] mask2former INFO: Inference done 55/1093. Dataloading: 0.0050 s/iter. Inference: 0.2373 s/iter. Eval: 0.1103 s/iter. Total: 0.3527 s/iter. ETA=0:06:06
[02/18 09:46:35] mask2former INFO: Inference done 70/1093. Dataloading: 0.0053 s/iter. Inference: 0.2372 s/iter. Eval: 0.1100 s/iter. Total: 0.3526 s/iter. ETA=0:06:00
[02/18 09:46:40] mask2former INFO: Inference done 84/1093. Dataloading: 0.0055 s/iter. Inference: 0.2388 s/iter. Eval: 0.1122 s/iter. Total: 0.3565 s/iter. ETA=0:05:59
[02/18 09:46:45] mask2former INFO: Inference done 98/1093. Dataloading: 0.0056 s/iter. Inference: 0.2387 s/iter. Eval: 0.1139 s/iter. Total: 0.3583 s/iter. ETA=0:05:56
[02/18 09:46:50] mask2former INFO: Inference done 113/1093. Dataloading: 0.0055 s/iter. Inference: 0.2393 s/iter. Eval: 0.1121 s/iter. Total: 0.3571 s/iter. ETA=0:05:49
[02/18 09:46:56] mask2former INFO: Inference done 128/1093. Dataloading: 0.0055 s/iter. Inference: 0.2385 s/iter. Eval: 0.1118 s/iter. Total: 0.3558 s/iter. ETA=0:05:43
[02/18 09:47:01] mask2former INFO: Inference done 142/1093. Dataloading: 0.0054 s/iter. Inference: 0.2382 s/iter. Eval: 0.1123 s/iter. Total: 0.3560 s/iter. ETA=0:05:38
[02/18 09:47:06] mask2former INFO: Inference done 156/1093. Dataloading: 0.0054 s/iter. Inference: 0.2378 s/iter. Eval: 0.1137 s/iter. Total: 0.3570 s/iter. ETA=0:05:34
[02/18 09:47:11] mask2former INFO: Inference done 171/1093. Dataloading: 0.0054 s/iter. Inference: 0.2373 s/iter. Eval: 0.1140 s/iter. Total: 0.3568 s/iter. ETA=0:05:28
[02/18 09:47:16] mask2former INFO: Inference done 185/1093. Dataloading: 0.0054 s/iter. Inference: 0.2378 s/iter. Eval: 0.1142 s/iter. Total: 0.3575 s/iter. ETA=0:05:24
[02/18 09:47:21] mask2former INFO: Inference done 199/1093. Dataloading: 0.0054 s/iter. Inference: 0.2380 s/iter. Eval: 0.1149 s/iter. Total: 0.3584 s/iter. ETA=0:05:20
[02/18 09:47:26] mask2former INFO: Inference done 213/1093. Dataloading: 0.0054 s/iter. Inference: 0.2376 s/iter. Eval: 0.1159 s/iter. Total: 0.3590 s/iter. ETA=0:05:15
[02/18 09:47:32] mask2former INFO: Inference done 228/1093. Dataloading: 0.0054 s/iter. Inference: 0.2372 s/iter. Eval: 0.1155 s/iter. Total: 0.3581 s/iter. ETA=0:05:09
[02/18 09:47:37] mask2former INFO: Inference done 242/1093. Dataloading: 0.0053 s/iter. Inference: 0.2379 s/iter. Eval: 0.1154 s/iter. Total: 0.3587 s/iter. ETA=0:05:05
[02/18 09:47:42] mask2former INFO: Inference done 256/1093. Dataloading: 0.0053 s/iter. Inference: 0.2376 s/iter. Eval: 0.1158 s/iter. Total: 0.3589 s/iter. ETA=0:05:00
[02/18 09:47:47] mask2former INFO: Inference done 270/1093. Dataloading: 0.0054 s/iter. Inference: 0.2380 s/iter. Eval: 0.1158 s/iter. Total: 0.3593 s/iter. ETA=0:04:55
[02/18 09:47:52] mask2former INFO: Inference done 285/1093. Dataloading: 0.0054 s/iter. Inference: 0.2378 s/iter. Eval: 0.1156 s/iter. Total: 0.3589 s/iter. ETA=0:04:50
[02/18 09:47:58] mask2former INFO: Inference done 300/1093. Dataloading: 0.0054 s/iter. Inference: 0.2379 s/iter. Eval: 0.1153 s/iter. Total: 0.3587 s/iter. ETA=0:04:44
[02/18 09:48:03] mask2former INFO: Inference done 315/1093. Dataloading: 0.0054 s/iter. Inference: 0.2373 s/iter. Eval: 0.1152 s/iter. Total: 0.3580 s/iter. ETA=0:04:38
[02/18 09:48:08] mask2former INFO: Inference done 330/1093. Dataloading: 0.0054 s/iter. Inference: 0.2374 s/iter. Eval: 0.1152 s/iter. Total: 0.3580 s/iter. ETA=0:04:33
[02/18 09:48:13] mask2former INFO: Inference done 344/1093. Dataloading: 0.0054 s/iter. Inference: 0.2381 s/iter. Eval: 0.1150 s/iter. Total: 0.3585 s/iter. ETA=0:04:28
[02/18 09:48:19] mask2former INFO: Inference done 358/1093. Dataloading: 0.0054 s/iter. Inference: 0.2383 s/iter. Eval: 0.1154 s/iter. Total: 0.3592 s/iter. ETA=0:04:24
[02/18 09:48:24] mask2former INFO: Inference done 372/1093. Dataloading: 0.0054 s/iter. Inference: 0.2386 s/iter. Eval: 0.1155 s/iter. Total: 0.3595 s/iter. ETA=0:04:19
[02/18 09:48:29] mask2former INFO: Inference done 387/1093. Dataloading: 0.0054 s/iter. Inference: 0.2382 s/iter. Eval: 0.1155 s/iter. Total: 0.3592 s/iter. ETA=0:04:13
[02/18 09:48:34] mask2former INFO: Inference done 401/1093. Dataloading: 0.0053 s/iter. Inference: 0.2382 s/iter. Eval: 0.1159 s/iter. Total: 0.3595 s/iter. ETA=0:04:08
[02/18 09:48:39] mask2former INFO: Inference done 416/1093. Dataloading: 0.0053 s/iter. Inference: 0.2379 s/iter. Eval: 0.1158 s/iter. Total: 0.3591 s/iter. ETA=0:04:03
[02/18 09:48:45] mask2former INFO: Inference done 430/1093. Dataloading: 0.0053 s/iter. Inference: 0.2382 s/iter. Eval: 0.1161 s/iter. Total: 0.3597 s/iter. ETA=0:03:58
[02/18 09:48:50] mask2former INFO: Inference done 445/1093. Dataloading: 0.0053 s/iter. Inference: 0.2379 s/iter. Eval: 0.1161 s/iter. Total: 0.3594 s/iter. ETA=0:03:52
[02/18 09:48:55] mask2former INFO: Inference done 458/1093. Dataloading: 0.0053 s/iter. Inference: 0.2387 s/iter. Eval: 0.1164 s/iter. Total: 0.3606 s/iter. ETA=0:03:48
[02/18 09:49:00] mask2former INFO: Inference done 472/1093. Dataloading: 0.0053 s/iter. Inference: 0.2386 s/iter. Eval: 0.1165 s/iter. Total: 0.3606 s/iter. ETA=0:03:43
[02/18 09:49:05] mask2former INFO: Inference done 485/1093. Dataloading: 0.0053 s/iter. Inference: 0.2392 s/iter. Eval: 0.1167 s/iter. Total: 0.3613 s/iter. ETA=0:03:39
[02/18 09:49:10] mask2former INFO: Inference done 499/1093. Dataloading: 0.0053 s/iter. Inference: 0.2394 s/iter. Eval: 0.1167 s/iter. Total: 0.3615 s/iter. ETA=0:03:34
[02/18 09:49:16] mask2former INFO: Inference done 514/1093. Dataloading: 0.0054 s/iter. Inference: 0.2391 s/iter. Eval: 0.1166 s/iter. Total: 0.3611 s/iter. ETA=0:03:29
[02/18 09:49:21] mask2former INFO: Inference done 527/1093. Dataloading: 0.0054 s/iter. Inference: 0.2395 s/iter. Eval: 0.1173 s/iter. Total: 0.3624 s/iter. ETA=0:03:25
[02/18 09:49:26] mask2former INFO: Inference done 541/1093. Dataloading: 0.0054 s/iter. Inference: 0.2398 s/iter. Eval: 0.1175 s/iter. Total: 0.3628 s/iter. ETA=0:03:20
[02/18 09:49:32] mask2former INFO: Inference done 555/1093. Dataloading: 0.0054 s/iter. Inference: 0.2403 s/iter. Eval: 0.1174 s/iter. Total: 0.3633 s/iter. ETA=0:03:15
[02/18 09:49:37] mask2former INFO: Inference done 568/1093. Dataloading: 0.0054 s/iter. Inference: 0.2410 s/iter. Eval: 0.1178 s/iter. Total: 0.3644 s/iter. ETA=0:03:11
[02/18 09:49:42] mask2former INFO: Inference done 583/1093. Dataloading: 0.0054 s/iter. Inference: 0.2410 s/iter. Eval: 0.1176 s/iter. Total: 0.3641 s/iter. ETA=0:03:05
[02/18 09:49:48] mask2former INFO: Inference done 597/1093. Dataloading: 0.0054 s/iter. Inference: 0.2414 s/iter. Eval: 0.1176 s/iter. Total: 0.3645 s/iter. ETA=0:03:00
[02/18 09:49:53] mask2former INFO: Inference done 612/1093. Dataloading: 0.0054 s/iter. Inference: 0.2412 s/iter. Eval: 0.1175 s/iter. Total: 0.3642 s/iter. ETA=0:02:55
[02/18 09:49:58] mask2former INFO: Inference done 626/1093. Dataloading: 0.0054 s/iter. Inference: 0.2415 s/iter. Eval: 0.1173 s/iter. Total: 0.3643 s/iter. ETA=0:02:50
[02/18 09:50:03] mask2former INFO: Inference done 641/1093. Dataloading: 0.0054 s/iter. Inference: 0.2413 s/iter. Eval: 0.1173 s/iter. Total: 0.3641 s/iter. ETA=0:02:44
[02/18 09:50:09] mask2former INFO: Inference done 655/1093. Dataloading: 0.0054 s/iter. Inference: 0.2417 s/iter. Eval: 0.1171 s/iter. Total: 0.3643 s/iter. ETA=0:02:39
[02/18 09:50:14] mask2former INFO: Inference done 670/1093. Dataloading: 0.0054 s/iter. Inference: 0.2417 s/iter. Eval: 0.1169 s/iter. Total: 0.3641 s/iter. ETA=0:02:34
[02/18 09:50:19] mask2former INFO: Inference done 684/1093. Dataloading: 0.0054 s/iter. Inference: 0.2416 s/iter. Eval: 0.1169 s/iter. Total: 0.3640 s/iter. ETA=0:02:28
[02/18 09:50:24] mask2former INFO: Inference done 698/1093. Dataloading: 0.0054 s/iter. Inference: 0.2413 s/iter. Eval: 0.1171 s/iter. Total: 0.3639 s/iter. ETA=0:02:23
[02/18 09:50:29] mask2former INFO: Inference done 711/1093. Dataloading: 0.0054 s/iter. Inference: 0.2415 s/iter. Eval: 0.1176 s/iter. Total: 0.3645 s/iter. ETA=0:02:19
[02/18 09:50:34] mask2former INFO: Inference done 725/1093. Dataloading: 0.0054 s/iter. Inference: 0.2413 s/iter. Eval: 0.1176 s/iter. Total: 0.3644 s/iter. ETA=0:02:14
[02/18 09:50:39] mask2former INFO: Inference done 739/1093. Dataloading: 0.0054 s/iter. Inference: 0.2416 s/iter. Eval: 0.1176 s/iter. Total: 0.3647 s/iter. ETA=0:02:09
[02/18 09:50:45] mask2former INFO: Inference done 753/1093. Dataloading: 0.0054 s/iter. Inference: 0.2417 s/iter. Eval: 0.1178 s/iter. Total: 0.3650 s/iter. ETA=0:02:04
[02/18 09:50:50] mask2former INFO: Inference done 767/1093. Dataloading: 0.0054 s/iter. Inference: 0.2416 s/iter. Eval: 0.1179 s/iter. Total: 0.3650 s/iter. ETA=0:01:58
[02/18 09:50:55] mask2former INFO: Inference done 782/1093. Dataloading: 0.0054 s/iter. Inference: 0.2417 s/iter. Eval: 0.1177 s/iter. Total: 0.3649 s/iter. ETA=0:01:53
[02/18 09:51:00] mask2former INFO: Inference done 796/1093. Dataloading: 0.0054 s/iter. Inference: 0.2414 s/iter. Eval: 0.1179 s/iter. Total: 0.3649 s/iter. ETA=0:01:48
[02/18 09:51:05] mask2former INFO: Inference done 811/1093. Dataloading: 0.0054 s/iter. Inference: 0.2412 s/iter. Eval: 0.1178 s/iter. Total: 0.3645 s/iter. ETA=0:01:42
[02/18 09:51:11] mask2former INFO: Inference done 826/1093. Dataloading: 0.0054 s/iter. Inference: 0.2410 s/iter. Eval: 0.1180 s/iter. Total: 0.3645 s/iter. ETA=0:01:37
[02/18 09:51:16] mask2former INFO: Inference done 840/1093. Dataloading: 0.0054 s/iter. Inference: 0.2409 s/iter. Eval: 0.1181 s/iter. Total: 0.3644 s/iter. ETA=0:01:32
[02/18 09:51:21] mask2former INFO: Inference done 855/1093. Dataloading: 0.0054 s/iter. Inference: 0.2408 s/iter. Eval: 0.1180 s/iter. Total: 0.3642 s/iter. ETA=0:01:26
[02/18 09:51:27] mask2former INFO: Inference done 869/1093. Dataloading: 0.0054 s/iter. Inference: 0.2408 s/iter. Eval: 0.1181 s/iter. Total: 0.3643 s/iter. ETA=0:01:21
[02/18 09:51:32] mask2former INFO: Inference done 882/1093. Dataloading: 0.0054 s/iter. Inference: 0.2411 s/iter. Eval: 0.1181 s/iter. Total: 0.3647 s/iter. ETA=0:01:16
[02/18 09:51:37] mask2former INFO: Inference done 896/1093. Dataloading: 0.0054 s/iter. Inference: 0.2413 s/iter. Eval: 0.1181 s/iter. Total: 0.3649 s/iter. ETA=0:01:11
[02/18 09:51:42] mask2former INFO: Inference done 909/1093. Dataloading: 0.0054 s/iter. Inference: 0.2414 s/iter. Eval: 0.1183 s/iter. Total: 0.3653 s/iter. ETA=0:01:07
[02/18 09:51:47] mask2former INFO: Inference done 923/1093. Dataloading: 0.0054 s/iter. Inference: 0.2415 s/iter. Eval: 0.1182 s/iter. Total: 0.3653 s/iter. ETA=0:01:02
[02/18 09:51:52] mask2former INFO: Inference done 937/1093. Dataloading: 0.0054 s/iter. Inference: 0.2416 s/iter. Eval: 0.1182 s/iter. Total: 0.3653 s/iter. ETA=0:00:56
[02/18 09:51:57] mask2former INFO: Inference done 951/1093. Dataloading: 0.0054 s/iter. Inference: 0.2417 s/iter. Eval: 0.1182 s/iter. Total: 0.3654 s/iter. ETA=0:00:51
[02/18 09:52:03] mask2former INFO: Inference done 965/1093. Dataloading: 0.0054 s/iter. Inference: 0.2416 s/iter. Eval: 0.1183 s/iter. Total: 0.3654 s/iter. ETA=0:00:46
[02/18 09:52:08] mask2former INFO: Inference done 978/1093. Dataloading: 0.0054 s/iter. Inference: 0.2418 s/iter. Eval: 0.1184 s/iter. Total: 0.3657 s/iter. ETA=0:00:42
[02/18 09:52:13] mask2former INFO: Inference done 993/1093. Dataloading: 0.0054 s/iter. Inference: 0.2415 s/iter. Eval: 0.1186 s/iter. Total: 0.3656 s/iter. ETA=0:00:36
[02/18 09:52:18] mask2former INFO: Inference done 1008/1093. Dataloading: 0.0054 s/iter. Inference: 0.2413 s/iter. Eval: 0.1185 s/iter. Total: 0.3653 s/iter. ETA=0:00:31
[02/18 09:52:23] mask2former INFO: Inference done 1022/1093. Dataloading: 0.0054 s/iter. Inference: 0.2413 s/iter. Eval: 0.1186 s/iter. Total: 0.3654 s/iter. ETA=0:00:25
[02/18 09:52:29] mask2former INFO: Inference done 1037/1093. Dataloading: 0.0054 s/iter. Inference: 0.2411 s/iter. Eval: 0.1185 s/iter. Total: 0.3652 s/iter. ETA=0:00:20
[02/18 09:52:34] mask2former INFO: Inference done 1051/1093. Dataloading: 0.0054 s/iter. Inference: 0.2413 s/iter. Eval: 0.1184 s/iter. Total: 0.3652 s/iter. ETA=0:00:15
[02/18 09:52:39] mask2former INFO: Inference done 1065/1093. Dataloading: 0.0054 s/iter. Inference: 0.2414 s/iter. Eval: 0.1186 s/iter. Total: 0.3655 s/iter. ETA=0:00:10
[02/18 09:52:44] mask2former INFO: Inference done 1080/1093. Dataloading: 0.0054 s/iter. Inference: 0.2413 s/iter. Eval: 0.1184 s/iter. Total: 0.3652 s/iter. ETA=0:00:04
[02/18 09:53:17] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.9488675693364677, 'error_1pix': 0.40775968061354645, 'error_3pix': 0.21162268008997334, 'mIoU': 18.120922655132162, 'fwIoU': 40.498871214949446, 'IoU-1': 94.32556066145571, 'IoU-2': 0.031065315175536422, 'IoU-3': 0.052640125825409945, 'IoU-4': 0.013922860274657917, 'IoU-5': 0.0032707947889128587, 'IoU-6': 0.005422050842889698, 'IoU-7': 0.010966515572452113, 'IoU-8': 0.008068085146773893, 'IoU-9': 1.0443825660040686, 'IoU-10': 12.357198087570787, 'IoU-11': 9.60373142666729, 'IoU-12': 32.89238200894769, 'IoU-13': 12.797596392379498, 'IoU-14': 12.231054279145589, 'IoU-15': 9.657056498997521, 'IoU-16': 5.939606564380022, 'IoU-17': 8.54612273976051, 'IoU-18': 14.246875111945434, 'IoU-19': 16.049071020676646, 'IoU-20': 14.494010263273486, 'IoU-21': 19.15352521938965, 'IoU-22': 23.570245164373986, 'IoU-23': 20.508153063797547, 'IoU-24': 19.840797466733523, 'IoU-25': 26.55353875827322, 'IoU-26': 36.0715972354445, 'IoU-27': 27.875745981606066, 'IoU-28': 21.625934475882882, 'IoU-29': 25.73271546589805, 'IoU-30': 33.076633692512374, 'IoU-31': 28.043524349913252, 'IoU-32': 31.343495936091248, 'IoU-33': 28.793817360975243, 'IoU-34': 17.10050223181646, 'IoU-35': 12.259410114404474, 'IoU-36': 29.35560509759027, 'IoU-37': 11.001284393244957, 'IoU-38': 10.143041586569508, 'IoU-39': 14.051379026825773, 'IoU-40': 16.15910766109709, 'IoU-41': 18.785847885460942, 'IoU-42': 18.272468182447057, 'IoU-43': 30.78304487789259, 'IoU-44': 27.402675279486516, 'IoU-45': 19.83530517041744, 'IoU-46': 19.18131936407049, 'IoU-47': 19.058574987412566, 'IoU-48': 19.914994047885244, 'mACC': 30.59543071651069, 'pACC': 49.57341603411591, 'ACC-1': 97.42179905014898, 'ACC-2': 0.031065435369042514, 'ACC-3': 0.06100520077266206, 'ACC-4': 0.014677328875405647, 'ACC-5': 0.0033822285945369654, 'ACC-6': 0.005599814217928299, 'ACC-7': 0.011461547418059033, 'ACC-8': 0.00839467826778283, 'ACC-9': 72.64464297821162, 'ACC-10': 17.96148244152556, 'ACC-11': 11.193975505295839, 'ACC-12': 81.95177403762426, 'ACC-13': 23.441105581086937, 'ACC-14': 23.571413470366632, 'ACC-15': 16.32441605233438, 'ACC-16': 9.071853939999452, 'ACC-17': 13.90917565336753, 'ACC-18': 23.913271715951538, 'ACC-19': 26.966314148727527, 'ACC-20': 22.101635223916634, 'ACC-21': 26.83251488862822, 'ACC-22': 31.412826582915553, 'ACC-23': 30.872456843162237, 'ACC-24': 33.24444592548208, 'ACC-25': 45.68291068208275, 'ACC-26': 68.23891778217569, 'ACC-27': 49.136551486902775, 'ACC-28': 32.5734161674341, 'ACC-29': 35.3871950161024, 'ACC-30': 47.849405984217, 'ACC-31': 37.458540031095694, 'ACC-32': 46.03972807227045, 'ACC-33': 44.87885066284532, 'ACC-34': 24.68098436249911, 'ACC-35': 19.55085855543829, 'ACC-36': 82.07939107158776, 'ACC-37': 21.730875966744993, 'ACC-38': 17.556042087390054, 'ACC-39': 21.554610396446293, 'ACC-40': 22.548054846030062, 'ACC-41': 24.80885653240505, 'ACC-42': 26.352089739909733, 'ACC-43': 59.93078694505283, 'ACC-44': 49.62172840104671, 'ACC-45': 31.30318098917815, 'ACC-46': 30.48402408074873, 'ACC-47': 31.867879587387087, 'ACC-48': 34.295104673261754})])
[02/18 09:53:17] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 09:53:17] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 09:53:17] d2.evaluation.testing INFO: copypaste: 2.9489,0.4078,0.2116,18.1209,40.4989,30.5954,49.5734
[02/18 09:53:18] d2.utils.events INFO:  eta: 19:03:15  iter: 17499  total_loss: 30.94  loss_ce: 0  loss_mask: 0.8128  loss_dice: 2.244  loss_seg: 0.8085  loss_ce_0: 0  loss_mask_0: 0.8162  loss_dice_0: 2.285  loss_ce_1: 0  loss_mask_1: 0.8092  loss_dice_1: 2.243  loss_ce_2: 0  loss_mask_2: 0.8149  loss_dice_2: 2.232  loss_ce_3: 0  loss_mask_3: 0.8145  loss_dice_3: 2.233  loss_ce_4: 0  loss_mask_4: 0.8149  loss_dice_4: 2.231  loss_ce_5: 0  loss_mask_5: 0.8138  loss_dice_5: 2.234  loss_ce_6: 0  loss_mask_6: 0.8167  loss_dice_6: 2.226  loss_ce_7: 0  loss_mask_7: 0.8168  loss_dice_7: 2.226  loss_ce_8: 0  loss_mask_8: 0.8144  loss_dice_8: 2.226  time: 2.0098  data_time: 0.0352  lr: 7.332e-05  max_mem: 6006M
[02/18 09:53:51] d2.utils.events INFO:  eta: 19:06:10  iter: 17519  total_loss: 31.99  loss_ce: 0  loss_mask: 0.7869  loss_dice: 2.255  loss_seg: 0.8898  loss_ce_0: 0  loss_mask_0: 0.7979  loss_dice_0: 2.306  loss_ce_1: 0  loss_mask_1: 0.795  loss_dice_1: 2.271  loss_ce_2: 0  loss_mask_2: 0.7905  loss_dice_2: 2.25  loss_ce_3: 0  loss_mask_3: 0.7947  loss_dice_3: 2.243  loss_ce_4: 0  loss_mask_4: 0.7921  loss_dice_4: 2.241  loss_ce_5: 0  loss_mask_5: 0.7929  loss_dice_5: 2.243  loss_ce_6: 0  loss_mask_6: 0.7957  loss_dice_6: 2.235  loss_ce_7: 0  loss_mask_7: 0.7906  loss_dice_7: 2.24  loss_ce_8: 0  loss_mask_8: 0.7928  loss_dice_8: 2.238  time: 2.0094  data_time: 0.0328  lr: 7.3289e-05  max_mem: 6006M
[02/18 09:54:23] d2.utils.events INFO:  eta: 19:03:26  iter: 17539  total_loss: 31.97  loss_ce: 0  loss_mask: 0.8068  loss_dice: 2.214  loss_seg: 0.877  loss_ce_0: 0  loss_mask_0: 0.8222  loss_dice_0: 2.294  loss_ce_1: 0  loss_mask_1: 0.8154  loss_dice_1: 2.224  loss_ce_2: 0  loss_mask_2: 0.8124  loss_dice_2: 2.212  loss_ce_3: 0  loss_mask_3: 0.8198  loss_dice_3: 2.209  loss_ce_4: 0  loss_mask_4: 0.8185  loss_dice_4: 2.211  loss_ce_5: 0  loss_mask_5: 0.8148  loss_dice_5: 2.211  loss_ce_6: 0  loss_mask_6: 0.8168  loss_dice_6: 2.21  loss_ce_7: 0  loss_mask_7: 0.8199  loss_dice_7: 2.205  loss_ce_8: 0  loss_mask_8: 0.8155  loss_dice_8: 2.213  time: 2.0090  data_time: 0.0325  lr: 7.3258e-05  max_mem: 6006M
[02/18 09:54:56] d2.utils.events INFO:  eta: 19:02:54  iter: 17559  total_loss: 32.33  loss_ce: 0  loss_mask: 0.8261  loss_dice: 2.243  loss_seg: 0.8365  loss_ce_0: 0  loss_mask_0: 0.8318  loss_dice_0: 2.311  loss_ce_1: 0  loss_mask_1: 0.8267  loss_dice_1: 2.25  loss_ce_2: 0  loss_mask_2: 0.8309  loss_dice_2: 2.227  loss_ce_3: 0  loss_mask_3: 0.8366  loss_dice_3: 2.214  loss_ce_4: 0  loss_mask_4: 0.833  loss_dice_4: 2.225  loss_ce_5: 0  loss_mask_5: 0.8305  loss_dice_5: 2.22  loss_ce_6: 0  loss_mask_6: 0.8342  loss_dice_6: 2.22  loss_ce_7: 0  loss_mask_7: 0.8349  loss_dice_7: 2.223  loss_ce_8: 0  loss_mask_8: 0.8321  loss_dice_8: 2.229  time: 2.0086  data_time: 0.0358  lr: 7.3227e-05  max_mem: 6006M
[02/18 09:55:29] d2.utils.events INFO:  eta: 18:59:09  iter: 17579  total_loss: 31.5  loss_ce: 0  loss_mask: 0.8206  loss_dice: 2.222  loss_seg: 0.7589  loss_ce_0: 0  loss_mask_0: 0.8228  loss_dice_0: 2.284  loss_ce_1: 0  loss_mask_1: 0.8189  loss_dice_1: 2.231  loss_ce_2: 0  loss_mask_2: 0.8251  loss_dice_2: 2.222  loss_ce_3: 0  loss_mask_3: 0.8214  loss_dice_3: 2.208  loss_ce_4: 0  loss_mask_4: 0.8195  loss_dice_4: 2.21  loss_ce_5: 0  loss_mask_5: 0.8184  loss_dice_5: 2.207  loss_ce_6: 0  loss_mask_6: 0.8216  loss_dice_6: 2.214  loss_ce_7: 0  loss_mask_7: 0.8213  loss_dice_7: 2.22  loss_ce_8: 0  loss_mask_8: 0.8214  loss_dice_8: 2.214  time: 2.0082  data_time: 0.0324  lr: 7.3196e-05  max_mem: 6006M
[02/18 09:56:03] d2.utils.events INFO:  eta: 19:01:18  iter: 17599  total_loss: 30.37  loss_ce: 0  loss_mask: 0.7939  loss_dice: 2.173  loss_seg: 0.8785  loss_ce_0: 0  loss_mask_0: 0.7949  loss_dice_0: 2.257  loss_ce_1: 0  loss_mask_1: 0.8007  loss_dice_1: 2.202  loss_ce_2: 0  loss_mask_2: 0.8015  loss_dice_2: 2.179  loss_ce_3: 0  loss_mask_3: 0.805  loss_dice_3: 2.162  loss_ce_4: 0  loss_mask_4: 0.8041  loss_dice_4: 2.164  loss_ce_5: 0  loss_mask_5: 0.8014  loss_dice_5: 2.166  loss_ce_6: 0  loss_mask_6: 0.7993  loss_dice_6: 2.159  loss_ce_7: 0  loss_mask_7: 0.7995  loss_dice_7: 2.159  loss_ce_8: 0  loss_mask_8: 0.8002  loss_dice_8: 2.16  time: 2.0078  data_time: 0.0335  lr: 7.3165e-05  max_mem: 6006M
[02/18 09:56:36] d2.utils.events INFO:  eta: 18:59:47  iter: 17619  total_loss: 30.92  loss_ce: 0  loss_mask: 0.831  loss_dice: 2.206  loss_seg: 0.7168  loss_ce_0: 0  loss_mask_0: 0.8391  loss_dice_0: 2.269  loss_ce_1: 0  loss_mask_1: 0.8282  loss_dice_1: 2.229  loss_ce_2: 0  loss_mask_2: 0.8318  loss_dice_2: 2.208  loss_ce_3: 0  loss_mask_3: 0.8346  loss_dice_3: 2.197  loss_ce_4: 0  loss_mask_4: 0.8347  loss_dice_4: 2.19  loss_ce_5: 0  loss_mask_5: 0.8343  loss_dice_5: 2.199  loss_ce_6: 0  loss_mask_6: 0.8399  loss_dice_6: 2.191  loss_ce_7: 0  loss_mask_7: 0.8398  loss_dice_7: 2.201  loss_ce_8: 0  loss_mask_8: 0.8392  loss_dice_8: 2.197  time: 2.0074  data_time: 0.0335  lr: 7.3134e-05  max_mem: 6006M
[02/18 09:57:10] d2.utils.events INFO:  eta: 18:58:24  iter: 17639  total_loss: 31.84  loss_ce: 0  loss_mask: 0.8076  loss_dice: 2.231  loss_seg: 1.045  loss_ce_0: 0  loss_mask_0: 0.8281  loss_dice_0: 2.305  loss_ce_1: 0  loss_mask_1: 0.8132  loss_dice_1: 2.241  loss_ce_2: 0  loss_mask_2: 0.8128  loss_dice_2: 2.222  loss_ce_3: 0  loss_mask_3: 0.8096  loss_dice_3: 2.215  loss_ce_4: 0  loss_mask_4: 0.8066  loss_dice_4: 2.213  loss_ce_5: 0  loss_mask_5: 0.8103  loss_dice_5: 2.211  loss_ce_6: 0  loss_mask_6: 0.8132  loss_dice_6: 2.216  loss_ce_7: 0  loss_mask_7: 0.8153  loss_dice_7: 2.214  loss_ce_8: 0  loss_mask_8: 0.8143  loss_dice_8: 2.211  time: 2.0070  data_time: 0.0270  lr: 7.3103e-05  max_mem: 6006M
[02/18 09:57:41] d2.utils.events INFO:  eta: 18:56:16  iter: 17659  total_loss: 30.8  loss_ce: 0  loss_mask: 0.7986  loss_dice: 2.2  loss_seg: 1.017  loss_ce_0: 0  loss_mask_0: 0.8081  loss_dice_0: 2.271  loss_ce_1: 0  loss_mask_1: 0.7994  loss_dice_1: 2.212  loss_ce_2: 0  loss_mask_2: 0.8022  loss_dice_2: 2.19  loss_ce_3: 0  loss_mask_3: 0.7982  loss_dice_3: 2.188  loss_ce_4: 0  loss_mask_4: 0.7985  loss_dice_4: 2.188  loss_ce_5: 0  loss_mask_5: 0.8027  loss_dice_5: 2.19  loss_ce_6: 0  loss_mask_6: 0.7976  loss_dice_6: 2.186  loss_ce_7: 0  loss_mask_7: 0.8002  loss_dice_7: 2.189  loss_ce_8: 0  loss_mask_8: 0.8007  loss_dice_8: 2.194  time: 2.0065  data_time: 0.0309  lr: 7.3072e-05  max_mem: 6006M
[02/18 09:58:14] d2.utils.events INFO:  eta: 18:54:03  iter: 17679  total_loss: 33.24  loss_ce: 0  loss_mask: 0.8618  loss_dice: 2.351  loss_seg: 1.099  loss_ce_0: 0  loss_mask_0: 0.869  loss_dice_0: 2.423  loss_ce_1: 0  loss_mask_1: 0.8722  loss_dice_1: 2.366  loss_ce_2: 0  loss_mask_2: 0.8708  loss_dice_2: 2.351  loss_ce_3: 0  loss_mask_3: 0.8685  loss_dice_3: 2.344  loss_ce_4: 0  loss_mask_4: 0.8648  loss_dice_4: 2.343  loss_ce_5: 0  loss_mask_5: 0.8637  loss_dice_5: 2.343  loss_ce_6: 0  loss_mask_6: 0.8656  loss_dice_6: 2.338  loss_ce_7: 0  loss_mask_7: 0.8647  loss_dice_7: 2.338  loss_ce_8: 0  loss_mask_8: 0.8649  loss_dice_8: 2.342  time: 2.0061  data_time: 0.0270  lr: 7.3041e-05  max_mem: 6006M
[02/18 09:58:45] d2.utils.events INFO:  eta: 18:55:12  iter: 17699  total_loss: 31.14  loss_ce: 0  loss_mask: 0.8139  loss_dice: 2.138  loss_seg: 0.7459  loss_ce_0: 0  loss_mask_0: 0.8227  loss_dice_0: 2.213  loss_ce_1: 0  loss_mask_1: 0.8142  loss_dice_1: 2.156  loss_ce_2: 0  loss_mask_2: 0.8121  loss_dice_2: 2.144  loss_ce_3: 0  loss_mask_3: 0.8188  loss_dice_3: 2.137  loss_ce_4: 0  loss_mask_4: 0.8199  loss_dice_4: 2.14  loss_ce_5: 0  loss_mask_5: 0.8216  loss_dice_5: 2.136  loss_ce_6: 0  loss_mask_6: 0.8195  loss_dice_6: 2.136  loss_ce_7: 0  loss_mask_7: 0.8215  loss_dice_7: 2.135  loss_ce_8: 0  loss_mask_8: 0.8238  loss_dice_8: 2.134  time: 2.0056  data_time: 0.0396  lr: 7.301e-05  max_mem: 6006M
[02/18 09:59:15] d2.utils.events INFO:  eta: 18:55:23  iter: 17719  total_loss: 31.61  loss_ce: 0  loss_mask: 0.8277  loss_dice: 2.3  loss_seg: 0.9913  loss_ce_0: 0  loss_mask_0: 0.8391  loss_dice_0: 2.354  loss_ce_1: 0  loss_mask_1: 0.8407  loss_dice_1: 2.31  loss_ce_2: 0  loss_mask_2: 0.8385  loss_dice_2: 2.291  loss_ce_3: 0  loss_mask_3: 0.838  loss_dice_3: 2.284  loss_ce_4: 0  loss_mask_4: 0.8397  loss_dice_4: 2.29  loss_ce_5: 0  loss_mask_5: 0.8341  loss_dice_5: 2.287  loss_ce_6: 0  loss_mask_6: 0.8363  loss_dice_6: 2.289  loss_ce_7: 0  loss_mask_7: 0.8373  loss_dice_7: 2.286  loss_ce_8: 0  loss_mask_8: 0.8361  loss_dice_8: 2.287  time: 2.0050  data_time: 0.0236  lr: 7.2978e-05  max_mem: 6006M
[02/18 09:59:49] d2.utils.events INFO:  eta: 18:54:52  iter: 17739  total_loss: 31.8  loss_ce: 0  loss_mask: 0.8338  loss_dice: 2.265  loss_seg: 0.7089  loss_ce_0: 0  loss_mask_0: 0.8379  loss_dice_0: 2.33  loss_ce_1: 0  loss_mask_1: 0.8398  loss_dice_1: 2.274  loss_ce_2: 0  loss_mask_2: 0.8409  loss_dice_2: 2.26  loss_ce_3: 0  loss_mask_3: 0.8408  loss_dice_3: 2.251  loss_ce_4: 0  loss_mask_4: 0.8418  loss_dice_4: 2.25  loss_ce_5: 0  loss_mask_5: 0.8441  loss_dice_5: 2.251  loss_ce_6: 0  loss_mask_6: 0.8381  loss_dice_6: 2.253  loss_ce_7: 0  loss_mask_7: 0.8413  loss_dice_7: 2.25  loss_ce_8: 0  loss_mask_8: 0.8409  loss_dice_8: 2.247  time: 2.0046  data_time: 0.0299  lr: 7.2947e-05  max_mem: 6006M
[02/18 10:00:20] d2.utils.events INFO:  eta: 18:54:19  iter: 17759  total_loss: 32.08  loss_ce: 0  loss_mask: 0.8358  loss_dice: 2.222  loss_seg: 0.9989  loss_ce_0: 0  loss_mask_0: 0.8373  loss_dice_0: 2.273  loss_ce_1: 0  loss_mask_1: 0.8383  loss_dice_1: 2.231  loss_ce_2: 0  loss_mask_2: 0.8379  loss_dice_2: 2.215  loss_ce_3: 0  loss_mask_3: 0.8361  loss_dice_3: 2.212  loss_ce_4: 0  loss_mask_4: 0.8379  loss_dice_4: 2.214  loss_ce_5: 0  loss_mask_5: 0.8378  loss_dice_5: 2.216  loss_ce_6: 0  loss_mask_6: 0.8364  loss_dice_6: 2.215  loss_ce_7: 0  loss_mask_7: 0.8372  loss_dice_7: 2.213  loss_ce_8: 0  loss_mask_8: 0.8406  loss_dice_8: 2.213  time: 2.0042  data_time: 0.0287  lr: 7.2916e-05  max_mem: 6006M
[02/18 10:00:54] d2.utils.events INFO:  eta: 18:53:46  iter: 17779  total_loss: 31.01  loss_ce: 0  loss_mask: 0.7969  loss_dice: 2.215  loss_seg: 0.8743  loss_ce_0: 0  loss_mask_0: 0.8207  loss_dice_0: 2.288  loss_ce_1: 0  loss_mask_1: 0.8069  loss_dice_1: 2.218  loss_ce_2: 0  loss_mask_2: 0.8025  loss_dice_2: 2.205  loss_ce_3: 0  loss_mask_3: 0.7978  loss_dice_3: 2.206  loss_ce_4: 0  loss_mask_4: 0.7974  loss_dice_4: 2.207  loss_ce_5: 0  loss_mask_5: 0.8019  loss_dice_5: 2.212  loss_ce_6: 0  loss_mask_6: 0.8082  loss_dice_6: 2.212  loss_ce_7: 0  loss_mask_7: 0.8085  loss_dice_7: 2.205  loss_ce_8: 0  loss_mask_8: 0.8046  loss_dice_8: 2.216  time: 2.0038  data_time: 0.0316  lr: 7.2885e-05  max_mem: 6006M
[02/18 10:01:27] d2.utils.events INFO:  eta: 18:50:37  iter: 17799  total_loss: 30.28  loss_ce: 0  loss_mask: 0.797  loss_dice: 2.155  loss_seg: 0.8316  loss_ce_0: 0  loss_mask_0: 0.8015  loss_dice_0: 2.21  loss_ce_1: 0  loss_mask_1: 0.8001  loss_dice_1: 2.143  loss_ce_2: 0  loss_mask_2: 0.7977  loss_dice_2: 2.143  loss_ce_3: 0  loss_mask_3: 0.8002  loss_dice_3: 2.137  loss_ce_4: 0  loss_mask_4: 0.803  loss_dice_4: 2.145  loss_ce_5: 0  loss_mask_5: 0.7986  loss_dice_5: 2.145  loss_ce_6: 0  loss_mask_6: 0.8033  loss_dice_6: 2.137  loss_ce_7: 0  loss_mask_7: 0.8022  loss_dice_7: 2.139  loss_ce_8: 0  loss_mask_8: 0.8009  loss_dice_8: 2.146  time: 2.0034  data_time: 0.0298  lr: 7.2854e-05  max_mem: 6006M
[02/18 10:02:00] d2.utils.events INFO:  eta: 18:49:10  iter: 17819  total_loss: 32.34  loss_ce: 0  loss_mask: 0.8088  loss_dice: 2.268  loss_seg: 1.072  loss_ce_0: 0  loss_mask_0: 0.8199  loss_dice_0: 2.329  loss_ce_1: 0  loss_mask_1: 0.8139  loss_dice_1: 2.282  loss_ce_2: 0  loss_mask_2: 0.8162  loss_dice_2: 2.266  loss_ce_3: 0  loss_mask_3: 0.8131  loss_dice_3: 2.251  loss_ce_4: 0  loss_mask_4: 0.8113  loss_dice_4: 2.255  loss_ce_5: 0  loss_mask_5: 0.8119  loss_dice_5: 2.259  loss_ce_6: 0  loss_mask_6: 0.8144  loss_dice_6: 2.246  loss_ce_7: 0  loss_mask_7: 0.8145  loss_dice_7: 2.25  loss_ce_8: 0  loss_mask_8: 0.8125  loss_dice_8: 2.248  time: 2.0030  data_time: 0.0303  lr: 7.2823e-05  max_mem: 6006M
[02/18 10:02:32] d2.utils.events INFO:  eta: 18:48:38  iter: 17839  total_loss: 31.55  loss_ce: 0  loss_mask: 0.8263  loss_dice: 2.231  loss_seg: 0.9747  loss_ce_0: 0  loss_mask_0: 0.8151  loss_dice_0: 2.306  loss_ce_1: 0  loss_mask_1: 0.8271  loss_dice_1: 2.24  loss_ce_2: 0  loss_mask_2: 0.831  loss_dice_2: 2.229  loss_ce_3: 0  loss_mask_3: 0.8332  loss_dice_3: 2.221  loss_ce_4: 0  loss_mask_4: 0.832  loss_dice_4: 2.223  loss_ce_5: 0  loss_mask_5: 0.8317  loss_dice_5: 2.224  loss_ce_6: 0  loss_mask_6: 0.8383  loss_dice_6: 2.22  loss_ce_7: 0  loss_mask_7: 0.8387  loss_dice_7: 2.22  loss_ce_8: 0  loss_mask_8: 0.8408  loss_dice_8: 2.223  time: 2.0025  data_time: 0.0382  lr: 7.2792e-05  max_mem: 6006M
[02/18 10:03:05] d2.utils.events INFO:  eta: 18:47:33  iter: 17859  total_loss: 31.15  loss_ce: 0  loss_mask: 0.8365  loss_dice: 2.141  loss_seg: 0.6496  loss_ce_0: 0  loss_mask_0: 0.8361  loss_dice_0: 2.164  loss_ce_1: 0  loss_mask_1: 0.8386  loss_dice_1: 2.149  loss_ce_2: 0  loss_mask_2: 0.8377  loss_dice_2: 2.141  loss_ce_3: 0  loss_mask_3: 0.8394  loss_dice_3: 2.125  loss_ce_4: 0  loss_mask_4: 0.8409  loss_dice_4: 2.126  loss_ce_5: 0  loss_mask_5: 0.8418  loss_dice_5: 2.127  loss_ce_6: 0  loss_mask_6: 0.8387  loss_dice_6: 2.129  loss_ce_7: 0  loss_mask_7: 0.8404  loss_dice_7: 2.131  loss_ce_8: 0  loss_mask_8: 0.8409  loss_dice_8: 2.134  time: 2.0021  data_time: 0.0271  lr: 7.2761e-05  max_mem: 6006M
[02/18 10:03:37] d2.utils.events INFO:  eta: 18:48:30  iter: 17879  total_loss: 33.63  loss_ce: 0  loss_mask: 0.8331  loss_dice: 2.377  loss_seg: 1.021  loss_ce_0: 0  loss_mask_0: 0.8445  loss_dice_0: 2.453  loss_ce_1: 0  loss_mask_1: 0.8311  loss_dice_1: 2.379  loss_ce_2: 0  loss_mask_2: 0.8328  loss_dice_2: 2.369  loss_ce_3: 0  loss_mask_3: 0.8355  loss_dice_3: 2.358  loss_ce_4: 0  loss_mask_4: 0.8367  loss_dice_4: 2.359  loss_ce_5: 0  loss_mask_5: 0.8369  loss_dice_5: 2.363  loss_ce_6: 0  loss_mask_6: 0.8362  loss_dice_6: 2.364  loss_ce_7: 0  loss_mask_7: 0.8383  loss_dice_7: 2.368  loss_ce_8: 0  loss_mask_8: 0.8335  loss_dice_8: 2.367  time: 2.0017  data_time: 0.0390  lr: 7.273e-05  max_mem: 6006M
[02/18 10:04:12] d2.utils.events INFO:  eta: 18:48:35  iter: 17899  total_loss: 32.12  loss_ce: 0  loss_mask: 0.8444  loss_dice: 2.216  loss_seg: 0.9421  loss_ce_0: 0  loss_mask_0: 0.859  loss_dice_0: 2.277  loss_ce_1: 0  loss_mask_1: 0.8495  loss_dice_1: 2.23  loss_ce_2: 0  loss_mask_2: 0.8484  loss_dice_2: 2.21  loss_ce_3: 0  loss_mask_3: 0.8521  loss_dice_3: 2.206  loss_ce_4: 0  loss_mask_4: 0.8513  loss_dice_4: 2.205  loss_ce_5: 0  loss_mask_5: 0.8511  loss_dice_5: 2.212  loss_ce_6: 0  loss_mask_6: 0.8491  loss_dice_6: 2.209  loss_ce_7: 0  loss_mask_7: 0.8484  loss_dice_7: 2.199  loss_ce_8: 0  loss_mask_8: 0.8501  loss_dice_8: 2.2  time: 2.0014  data_time: 0.0256  lr: 7.2699e-05  max_mem: 6006M
[02/18 10:04:43] d2.utils.events INFO:  eta: 18:48:56  iter: 17919  total_loss: 31.57  loss_ce: 0  loss_mask: 0.8247  loss_dice: 2.219  loss_seg: 0.9489  loss_ce_0: 0  loss_mask_0: 0.8246  loss_dice_0: 2.29  loss_ce_1: 0  loss_mask_1: 0.832  loss_dice_1: 2.23  loss_ce_2: 0  loss_mask_2: 0.8287  loss_dice_2: 2.216  loss_ce_3: 0  loss_mask_3: 0.8289  loss_dice_3: 2.208  loss_ce_4: 0  loss_mask_4: 0.8317  loss_dice_4: 2.209  loss_ce_5: 0  loss_mask_5: 0.83  loss_dice_5: 2.203  loss_ce_6: 0  loss_mask_6: 0.8344  loss_dice_6: 2.205  loss_ce_7: 0  loss_mask_7: 0.8325  loss_dice_7: 2.205  loss_ce_8: 0  loss_mask_8: 0.8359  loss_dice_8: 2.205  time: 2.0009  data_time: 0.0252  lr: 7.2668e-05  max_mem: 6006M
[02/18 10:05:15] d2.utils.events INFO:  eta: 18:49:03  iter: 17939  total_loss: 31.92  loss_ce: 0  loss_mask: 0.8164  loss_dice: 2.242  loss_seg: 0.9712  loss_ce_0: 0  loss_mask_0: 0.8286  loss_dice_0: 2.319  loss_ce_1: 0  loss_mask_1: 0.8246  loss_dice_1: 2.251  loss_ce_2: 0  loss_mask_2: 0.8272  loss_dice_2: 2.241  loss_ce_3: 0  loss_mask_3: 0.8245  loss_dice_3: 2.233  loss_ce_4: 0  loss_mask_4: 0.8196  loss_dice_4: 2.235  loss_ce_5: 0  loss_mask_5: 0.8223  loss_dice_5: 2.229  loss_ce_6: 0  loss_mask_6: 0.8228  loss_dice_6: 2.232  loss_ce_7: 0  loss_mask_7: 0.8205  loss_dice_7: 2.237  loss_ce_8: 0  loss_mask_8: 0.8192  loss_dice_8: 2.232  time: 2.0004  data_time: 0.0297  lr: 7.2637e-05  max_mem: 6006M
[02/18 10:05:46] d2.utils.events INFO:  eta: 18:46:21  iter: 17959  total_loss: 32.29  loss_ce: 0  loss_mask: 0.8253  loss_dice: 2.205  loss_seg: 1.118  loss_ce_0: 0  loss_mask_0: 0.8286  loss_dice_0: 2.267  loss_ce_1: 0  loss_mask_1: 0.8246  loss_dice_1: 2.223  loss_ce_2: 0  loss_mask_2: 0.826  loss_dice_2: 2.207  loss_ce_3: 0  loss_mask_3: 0.8285  loss_dice_3: 2.205  loss_ce_4: 0  loss_mask_4: 0.8292  loss_dice_4: 2.198  loss_ce_5: 0  loss_mask_5: 0.8302  loss_dice_5: 2.195  loss_ce_6: 0  loss_mask_6: 0.8358  loss_dice_6: 2.192  loss_ce_7: 0  loss_mask_7: 0.8313  loss_dice_7: 2.195  loss_ce_8: 0  loss_mask_8: 0.8321  loss_dice_8: 2.194  time: 1.9999  data_time: 0.0273  lr: 7.2606e-05  max_mem: 6006M
[02/18 10:06:19] d2.utils.events INFO:  eta: 18:45:28  iter: 17979  total_loss: 31.49  loss_ce: 0  loss_mask: 0.8217  loss_dice: 2.236  loss_seg: 1.079  loss_ce_0: 0  loss_mask_0: 0.8224  loss_dice_0: 2.302  loss_ce_1: 0  loss_mask_1: 0.8305  loss_dice_1: 2.247  loss_ce_2: 0  loss_mask_2: 0.8258  loss_dice_2: 2.235  loss_ce_3: 0  loss_mask_3: 0.8262  loss_dice_3: 2.228  loss_ce_4: 0  loss_mask_4: 0.8271  loss_dice_4: 2.224  loss_ce_5: 0  loss_mask_5: 0.8273  loss_dice_5: 2.226  loss_ce_6: 0  loss_mask_6: 0.8218  loss_dice_6: 2.224  loss_ce_7: 0  loss_mask_7: 0.8242  loss_dice_7: 2.226  loss_ce_8: 0  loss_mask_8: 0.824  loss_dice_8: 2.227  time: 1.9995  data_time: 0.0336  lr: 7.2574e-05  max_mem: 6006M
[02/18 10:06:53] d2.utils.events INFO:  eta: 18:45:54  iter: 17999  total_loss: 30.98  loss_ce: 0  loss_mask: 0.8002  loss_dice: 2.176  loss_seg: 0.8126  loss_ce_0: 0  loss_mask_0: 0.8156  loss_dice_0: 2.254  loss_ce_1: 0  loss_mask_1: 0.8002  loss_dice_1: 2.194  loss_ce_2: 0  loss_mask_2: 0.8026  loss_dice_2: 2.177  loss_ce_3: 0  loss_mask_3: 0.8074  loss_dice_3: 2.17  loss_ce_4: 0  loss_mask_4: 0.8078  loss_dice_4: 2.17  loss_ce_5: 0  loss_mask_5: 0.8053  loss_dice_5: 2.173  loss_ce_6: 0  loss_mask_6: 0.8106  loss_dice_6: 2.164  loss_ce_7: 0  loss_mask_7: 0.8082  loss_dice_7: 2.165  loss_ce_8: 0  loss_mask_8: 0.8061  loss_dice_8: 2.172  time: 1.9992  data_time: 0.0312  lr: 7.2543e-05  max_mem: 6006M
[02/18 10:07:28] d2.utils.events INFO:  eta: 18:47:44  iter: 18019  total_loss: 32.71  loss_ce: 0  loss_mask: 0.8402  loss_dice: 2.315  loss_seg: 0.7828  loss_ce_0: 0  loss_mask_0: 0.8549  loss_dice_0: 2.386  loss_ce_1: 0  loss_mask_1: 0.8479  loss_dice_1: 2.333  loss_ce_2: 0  loss_mask_2: 0.8415  loss_dice_2: 2.314  loss_ce_3: 0  loss_mask_3: 0.8478  loss_dice_3: 2.303  loss_ce_4: 0  loss_mask_4: 0.847  loss_dice_4: 2.297  loss_ce_5: 0  loss_mask_5: 0.8455  loss_dice_5: 2.307  loss_ce_6: 0  loss_mask_6: 0.849  loss_dice_6: 2.302  loss_ce_7: 0  loss_mask_7: 0.8467  loss_dice_7: 2.305  loss_ce_8: 0  loss_mask_8: 0.8485  loss_dice_8: 2.306  time: 1.9989  data_time: 0.0250  lr: 7.2512e-05  max_mem: 6006M
[02/18 10:08:00] d2.utils.events INFO:  eta: 18:46:49  iter: 18039  total_loss: 30.97  loss_ce: 0  loss_mask: 0.8178  loss_dice: 2.171  loss_seg: 0.9095  loss_ce_0: 0  loss_mask_0: 0.8402  loss_dice_0: 2.217  loss_ce_1: 0  loss_mask_1: 0.8263  loss_dice_1: 2.185  loss_ce_2: 0  loss_mask_2: 0.8281  loss_dice_2: 2.17  loss_ce_3: 0  loss_mask_3: 0.8204  loss_dice_3: 2.158  loss_ce_4: 0  loss_mask_4: 0.8177  loss_dice_4: 2.155  loss_ce_5: 0  loss_mask_5: 0.8179  loss_dice_5: 2.159  loss_ce_6: 0  loss_mask_6: 0.8191  loss_dice_6: 2.153  loss_ce_7: 0  loss_mask_7: 0.8207  loss_dice_7: 2.165  loss_ce_8: 0  loss_mask_8: 0.8222  loss_dice_8: 2.156  time: 1.9985  data_time: 0.0302  lr: 7.2481e-05  max_mem: 6006M
[02/18 10:08:33] d2.utils.events INFO:  eta: 18:47:28  iter: 18059  total_loss: 32.23  loss_ce: 0  loss_mask: 0.8467  loss_dice: 2.246  loss_seg: 0.8433  loss_ce_0: 0  loss_mask_0: 0.8581  loss_dice_0: 2.293  loss_ce_1: 0  loss_mask_1: 0.8559  loss_dice_1: 2.25  loss_ce_2: 0  loss_mask_2: 0.8527  loss_dice_2: 2.248  loss_ce_3: 0  loss_mask_3: 0.8497  loss_dice_3: 2.228  loss_ce_4: 0  loss_mask_4: 0.85  loss_dice_4: 2.232  loss_ce_5: 0  loss_mask_5: 0.8485  loss_dice_5: 2.231  loss_ce_6: 0  loss_mask_6: 0.8454  loss_dice_6: 2.23  loss_ce_7: 0  loss_mask_7: 0.8442  loss_dice_7: 2.232  loss_ce_8: 0  loss_mask_8: 0.8447  loss_dice_8: 2.236  time: 1.9981  data_time: 0.0304  lr: 7.245e-05  max_mem: 6006M
[02/18 10:09:07] d2.utils.events INFO:  eta: 18:49:43  iter: 18079  total_loss: 31.59  loss_ce: 0  loss_mask: 0.8181  loss_dice: 2.155  loss_seg: 0.9647  loss_ce_0: 0  loss_mask_0: 0.8264  loss_dice_0: 2.218  loss_ce_1: 0  loss_mask_1: 0.8189  loss_dice_1: 2.158  loss_ce_2: 0  loss_mask_2: 0.8171  loss_dice_2: 2.154  loss_ce_3: 0  loss_mask_3: 0.8283  loss_dice_3: 2.139  loss_ce_4: 0  loss_mask_4: 0.8258  loss_dice_4: 2.154  loss_ce_5: 0  loss_mask_5: 0.8234  loss_dice_5: 2.151  loss_ce_6: 0  loss_mask_6: 0.8332  loss_dice_6: 2.144  loss_ce_7: 0  loss_mask_7: 0.8328  loss_dice_7: 2.148  loss_ce_8: 0  loss_mask_8: 0.8297  loss_dice_8: 2.144  time: 1.9977  data_time: 0.0298  lr: 7.2419e-05  max_mem: 6006M
[02/18 10:09:40] d2.utils.events INFO:  eta: 18:51:24  iter: 18099  total_loss: 30.97  loss_ce: 0  loss_mask: 0.7982  loss_dice: 2.162  loss_seg: 1.013  loss_ce_0: 0  loss_mask_0: 0.8221  loss_dice_0: 2.245  loss_ce_1: 0  loss_mask_1: 0.8059  loss_dice_1: 2.179  loss_ce_2: 0  loss_mask_2: 0.8077  loss_dice_2: 2.152  loss_ce_3: 0  loss_mask_3: 0.8054  loss_dice_3: 2.151  loss_ce_4: 0  loss_mask_4: 0.8083  loss_dice_4: 2.147  loss_ce_5: 0  loss_mask_5: 0.8055  loss_dice_5: 2.148  loss_ce_6: 0  loss_mask_6: 0.8047  loss_dice_6: 2.147  loss_ce_7: 0  loss_mask_7: 0.8031  loss_dice_7: 2.15  loss_ce_8: 0  loss_mask_8: 0.8038  loss_dice_8: 2.153  time: 1.9973  data_time: 0.0252  lr: 7.2388e-05  max_mem: 6006M
[02/18 10:10:13] d2.utils.events INFO:  eta: 18:50:16  iter: 18119  total_loss: 32.3  loss_ce: 0  loss_mask: 0.79  loss_dice: 2.274  loss_seg: 1.015  loss_ce_0: 0  loss_mask_0: 0.8044  loss_dice_0: 2.334  loss_ce_1: 0  loss_mask_1: 0.797  loss_dice_1: 2.29  loss_ce_2: 0  loss_mask_2: 0.8039  loss_dice_2: 2.272  loss_ce_3: 0  loss_mask_3: 0.8008  loss_dice_3: 2.26  loss_ce_4: 0  loss_mask_4: 0.7987  loss_dice_4: 2.265  loss_ce_5: 0  loss_mask_5: 0.7994  loss_dice_5: 2.267  loss_ce_6: 0  loss_mask_6: 0.7986  loss_dice_6: 2.269  loss_ce_7: 0  loss_mask_7: 0.7993  loss_dice_7: 2.266  loss_ce_8: 0  loss_mask_8: 0.7955  loss_dice_8: 2.267  time: 1.9970  data_time: 0.0262  lr: 7.2357e-05  max_mem: 6006M
[02/18 10:10:45] d2.utils.events INFO:  eta: 18:49:44  iter: 18139  total_loss: 31.39  loss_ce: 0  loss_mask: 0.7783  loss_dice: 2.214  loss_seg: 0.7796  loss_ce_0: 0  loss_mask_0: 0.7878  loss_dice_0: 2.298  loss_ce_1: 0  loss_mask_1: 0.7827  loss_dice_1: 2.24  loss_ce_2: 0  loss_mask_2: 0.7801  loss_dice_2: 2.213  loss_ce_3: 0  loss_mask_3: 0.7815  loss_dice_3: 2.188  loss_ce_4: 0  loss_mask_4: 0.7807  loss_dice_4: 2.195  loss_ce_5: 0  loss_mask_5: 0.7824  loss_dice_5: 2.197  loss_ce_6: 0  loss_mask_6: 0.7781  loss_dice_6: 2.19  loss_ce_7: 0  loss_mask_7: 0.7767  loss_dice_7: 2.195  loss_ce_8: 0  loss_mask_8: 0.7794  loss_dice_8: 2.198  time: 1.9965  data_time: 0.0259  lr: 7.2326e-05  max_mem: 6006M
[02/18 10:11:18] d2.utils.events INFO:  eta: 18:49:52  iter: 18159  total_loss: 30.89  loss_ce: 0  loss_mask: 0.8167  loss_dice: 2.15  loss_seg: 0.7163  loss_ce_0: 0  loss_mask_0: 0.8339  loss_dice_0: 2.221  loss_ce_1: 0  loss_mask_1: 0.8165  loss_dice_1: 2.164  loss_ce_2: 0  loss_mask_2: 0.8131  loss_dice_2: 2.154  loss_ce_3: 0  loss_mask_3: 0.8202  loss_dice_3: 2.147  loss_ce_4: 0  loss_mask_4: 0.8256  loss_dice_4: 2.138  loss_ce_5: 0  loss_mask_5: 0.8214  loss_dice_5: 2.14  loss_ce_6: 0  loss_mask_6: 0.8218  loss_dice_6: 2.14  loss_ce_7: 0  loss_mask_7: 0.8233  loss_dice_7: 2.139  loss_ce_8: 0  loss_mask_8: 0.8238  loss_dice_8: 2.144  time: 1.9962  data_time: 0.0277  lr: 7.2295e-05  max_mem: 6006M
[02/18 10:11:51] d2.utils.events INFO:  eta: 18:49:25  iter: 18179  total_loss: 31.36  loss_ce: 0  loss_mask: 0.7873  loss_dice: 2.198  loss_seg: 0.9129  loss_ce_0: 0  loss_mask_0: 0.7928  loss_dice_0: 2.25  loss_ce_1: 0  loss_mask_1: 0.7941  loss_dice_1: 2.199  loss_ce_2: 0  loss_mask_2: 0.7934  loss_dice_2: 2.194  loss_ce_3: 0  loss_mask_3: 0.7905  loss_dice_3: 2.192  loss_ce_4: 0  loss_mask_4: 0.7918  loss_dice_4: 2.184  loss_ce_5: 0  loss_mask_5: 0.7903  loss_dice_5: 2.191  loss_ce_6: 0  loss_mask_6: 0.7901  loss_dice_6: 2.185  loss_ce_7: 0  loss_mask_7: 0.7914  loss_dice_7: 2.186  loss_ce_8: 0  loss_mask_8: 0.7912  loss_dice_8: 2.182  time: 1.9957  data_time: 0.0272  lr: 7.2263e-05  max_mem: 6006M
[02/18 10:12:24] d2.utils.events INFO:  eta: 18:48:47  iter: 18199  total_loss: 31.39  loss_ce: 0  loss_mask: 0.7992  loss_dice: 2.179  loss_seg: 0.8894  loss_ce_0: 0  loss_mask_0: 0.7954  loss_dice_0: 2.262  loss_ce_1: 0  loss_mask_1: 0.8048  loss_dice_1: 2.187  loss_ce_2: 0  loss_mask_2: 0.8048  loss_dice_2: 2.178  loss_ce_3: 0  loss_mask_3: 0.8074  loss_dice_3: 2.172  loss_ce_4: 0  loss_mask_4: 0.805  loss_dice_4: 2.167  loss_ce_5: 0  loss_mask_5: 0.8053  loss_dice_5: 2.167  loss_ce_6: 0  loss_mask_6: 0.8073  loss_dice_6: 2.166  loss_ce_7: 0  loss_mask_7: 0.8081  loss_dice_7: 2.163  loss_ce_8: 0  loss_mask_8: 0.808  loss_dice_8: 2.162  time: 1.9954  data_time: 0.0290  lr: 7.2232e-05  max_mem: 6006M
[02/18 10:12:57] d2.utils.events INFO:  eta: 18:48:38  iter: 18219  total_loss: 31.96  loss_ce: 0  loss_mask: 0.8303  loss_dice: 2.288  loss_seg: 1.074  loss_ce_0: 0  loss_mask_0: 0.8534  loss_dice_0: 2.336  loss_ce_1: 0  loss_mask_1: 0.8306  loss_dice_1: 2.291  loss_ce_2: 0  loss_mask_2: 0.8339  loss_dice_2: 2.282  loss_ce_3: 0  loss_mask_3: 0.8441  loss_dice_3: 2.269  loss_ce_4: 0  loss_mask_4: 0.8431  loss_dice_4: 2.27  loss_ce_5: 0  loss_mask_5: 0.8429  loss_dice_5: 2.276  loss_ce_6: 0  loss_mask_6: 0.8416  loss_dice_6: 2.272  loss_ce_7: 0  loss_mask_7: 0.8425  loss_dice_7: 2.266  loss_ce_8: 0  loss_mask_8: 0.8449  loss_dice_8: 2.27  time: 1.9950  data_time: 0.0317  lr: 7.2201e-05  max_mem: 6006M
[02/18 10:13:30] d2.utils.events INFO:  eta: 18:48:06  iter: 18239  total_loss: 31.1  loss_ce: 0  loss_mask: 0.833  loss_dice: 2.199  loss_seg: 0.8832  loss_ce_0: 0  loss_mask_0: 0.8406  loss_dice_0: 2.249  loss_ce_1: 0  loss_mask_1: 0.8426  loss_dice_1: 2.209  loss_ce_2: 0  loss_mask_2: 0.8394  loss_dice_2: 2.203  loss_ce_3: 0  loss_mask_3: 0.8335  loss_dice_3: 2.198  loss_ce_4: 0  loss_mask_4: 0.8349  loss_dice_4: 2.2  loss_ce_5: 0  loss_mask_5: 0.8373  loss_dice_5: 2.192  loss_ce_6: 0  loss_mask_6: 0.8349  loss_dice_6: 2.192  loss_ce_7: 0  loss_mask_7: 0.8401  loss_dice_7: 2.19  loss_ce_8: 0  loss_mask_8: 0.8368  loss_dice_8: 2.192  time: 1.9946  data_time: 0.0317  lr: 7.217e-05  max_mem: 6006M
[02/18 10:14:03] d2.utils.events INFO:  eta: 18:47:51  iter: 18259  total_loss: 30.79  loss_ce: 0  loss_mask: 0.7793  loss_dice: 2.154  loss_seg: 0.8873  loss_ce_0: 0  loss_mask_0: 0.7788  loss_dice_0: 2.226  loss_ce_1: 0  loss_mask_1: 0.7873  loss_dice_1: 2.172  loss_ce_2: 0  loss_mask_2: 0.7883  loss_dice_2: 2.149  loss_ce_3: 0  loss_mask_3: 0.7882  loss_dice_3: 2.143  loss_ce_4: 0  loss_mask_4: 0.7906  loss_dice_4: 2.14  loss_ce_5: 0  loss_mask_5: 0.7933  loss_dice_5: 2.14  loss_ce_6: 0  loss_mask_6: 0.7938  loss_dice_6: 2.138  loss_ce_7: 0  loss_mask_7: 0.7907  loss_dice_7: 2.136  loss_ce_8: 0  loss_mask_8: 0.7888  loss_dice_8: 2.137  time: 1.9942  data_time: 0.0351  lr: 7.2139e-05  max_mem: 6006M
[02/18 10:14:37] d2.utils.events INFO:  eta: 18:47:18  iter: 18279  total_loss: 31.91  loss_ce: 0  loss_mask: 0.8176  loss_dice: 2.26  loss_seg: 0.9106  loss_ce_0: 0  loss_mask_0: 0.8077  loss_dice_0: 2.32  loss_ce_1: 0  loss_mask_1: 0.8215  loss_dice_1: 2.262  loss_ce_2: 0  loss_mask_2: 0.8213  loss_dice_2: 2.253  loss_ce_3: 0  loss_mask_3: 0.8208  loss_dice_3: 2.243  loss_ce_4: 0  loss_mask_4: 0.8212  loss_dice_4: 2.24  loss_ce_5: 0  loss_mask_5: 0.8217  loss_dice_5: 2.251  loss_ce_6: 0  loss_mask_6: 0.8226  loss_dice_6: 2.24  loss_ce_7: 0  loss_mask_7: 0.8251  loss_dice_7: 2.242  loss_ce_8: 0  loss_mask_8: 0.8254  loss_dice_8: 2.246  time: 1.9939  data_time: 0.0295  lr: 7.2108e-05  max_mem: 6006M
[02/18 10:15:08] d2.utils.events INFO:  eta: 18:46:16  iter: 18299  total_loss: 31.4  loss_ce: 0  loss_mask: 0.8085  loss_dice: 2.249  loss_seg: 0.9587  loss_ce_0: 0  loss_mask_0: 0.8161  loss_dice_0: 2.298  loss_ce_1: 0  loss_mask_1: 0.8045  loss_dice_1: 2.258  loss_ce_2: 0  loss_mask_2: 0.8061  loss_dice_2: 2.241  loss_ce_3: 0  loss_mask_3: 0.8044  loss_dice_3: 2.234  loss_ce_4: 0  loss_mask_4: 0.8098  loss_dice_4: 2.23  loss_ce_5: 0  loss_mask_5: 0.8071  loss_dice_5: 2.236  loss_ce_6: 0  loss_mask_6: 0.8117  loss_dice_6: 2.239  loss_ce_7: 0  loss_mask_7: 0.812  loss_dice_7: 2.237  loss_ce_8: 0  loss_mask_8: 0.8134  loss_dice_8: 2.236  time: 1.9934  data_time: 0.0237  lr: 7.2077e-05  max_mem: 6006M
[02/18 10:15:42] d2.utils.events INFO:  eta: 18:45:27  iter: 18319  total_loss: 31.94  loss_ce: 0  loss_mask: 0.8235  loss_dice: 2.265  loss_seg: 0.7996  loss_ce_0: 0  loss_mask_0: 0.8416  loss_dice_0: 2.312  loss_ce_1: 0  loss_mask_1: 0.8232  loss_dice_1: 2.278  loss_ce_2: 0  loss_mask_2: 0.823  loss_dice_2: 2.263  loss_ce_3: 0  loss_mask_3: 0.8241  loss_dice_3: 2.244  loss_ce_4: 0  loss_mask_4: 0.8292  loss_dice_4: 2.25  loss_ce_5: 0  loss_mask_5: 0.8289  loss_dice_5: 2.247  loss_ce_6: 0  loss_mask_6: 0.8269  loss_dice_6: 2.247  loss_ce_7: 0  loss_mask_7: 0.8245  loss_dice_7: 2.242  loss_ce_8: 0  loss_mask_8: 0.827  loss_dice_8: 2.251  time: 1.9931  data_time: 0.0324  lr: 7.2046e-05  max_mem: 6006M
[02/18 10:16:16] d2.utils.events INFO:  eta: 18:45:29  iter: 18339  total_loss: 32.89  loss_ce: 0  loss_mask: 0.8262  loss_dice: 2.328  loss_seg: 0.7726  loss_ce_0: 0  loss_mask_0: 0.8347  loss_dice_0: 2.398  loss_ce_1: 0  loss_mask_1: 0.8321  loss_dice_1: 2.349  loss_ce_2: 0  loss_mask_2: 0.83  loss_dice_2: 2.32  loss_ce_3: 0  loss_mask_3: 0.8271  loss_dice_3: 2.309  loss_ce_4: 0  loss_mask_4: 0.8258  loss_dice_4: 2.317  loss_ce_5: 0  loss_mask_5: 0.8232  loss_dice_5: 2.318  loss_ce_6: 0  loss_mask_6: 0.8239  loss_dice_6: 2.317  loss_ce_7: 0  loss_mask_7: 0.8274  loss_dice_7: 2.321  loss_ce_8: 0  loss_mask_8: 0.8268  loss_dice_8: 2.316  time: 1.9928  data_time: 0.0281  lr: 7.2015e-05  max_mem: 6006M
[02/18 10:16:47] d2.utils.events INFO:  eta: 18:43:21  iter: 18359  total_loss: 30.79  loss_ce: 0  loss_mask: 0.8169  loss_dice: 2.194  loss_seg: 0.9529  loss_ce_0: 0  loss_mask_0: 0.8219  loss_dice_0: 2.286  loss_ce_1: 0  loss_mask_1: 0.8152  loss_dice_1: 2.22  loss_ce_2: 0  loss_mask_2: 0.8138  loss_dice_2: 2.201  loss_ce_3: 0  loss_mask_3: 0.8133  loss_dice_3: 2.18  loss_ce_4: 0  loss_mask_4: 0.8167  loss_dice_4: 2.182  loss_ce_5: 0  loss_mask_5: 0.8154  loss_dice_5: 2.173  loss_ce_6: 0  loss_mask_6: 0.8168  loss_dice_6: 2.17  loss_ce_7: 0  loss_mask_7: 0.8167  loss_dice_7: 2.172  loss_ce_8: 0  loss_mask_8: 0.8189  loss_dice_8: 2.178  time: 1.9923  data_time: 0.0412  lr: 7.1983e-05  max_mem: 6006M
[02/18 10:17:18] d2.utils.events INFO:  eta: 18:42:44  iter: 18379  total_loss: 31.2  loss_ce: 0  loss_mask: 0.7854  loss_dice: 2.19  loss_seg: 0.9138  loss_ce_0: 0  loss_mask_0: 0.796  loss_dice_0: 2.263  loss_ce_1: 0  loss_mask_1: 0.7814  loss_dice_1: 2.205  loss_ce_2: 0  loss_mask_2: 0.7847  loss_dice_2: 2.193  loss_ce_3: 0  loss_mask_3: 0.7893  loss_dice_3: 2.179  loss_ce_4: 0  loss_mask_4: 0.791  loss_dice_4: 2.18  loss_ce_5: 0  loss_mask_5: 0.7943  loss_dice_5: 2.183  loss_ce_6: 0  loss_mask_6: 0.7925  loss_dice_6: 2.177  loss_ce_7: 0  loss_mask_7: 0.7906  loss_dice_7: 2.174  loss_ce_8: 0  loss_mask_8: 0.7892  loss_dice_8: 2.182  time: 1.9918  data_time: 0.0338  lr: 7.1952e-05  max_mem: 6006M
[02/18 10:17:51] d2.utils.events INFO:  eta: 18:42:12  iter: 18399  total_loss: 30.81  loss_ce: 0  loss_mask: 0.8156  loss_dice: 2.117  loss_seg: 0.7587  loss_ce_0: 0  loss_mask_0: 0.8159  loss_dice_0: 2.169  loss_ce_1: 0  loss_mask_1: 0.822  loss_dice_1: 2.128  loss_ce_2: 0  loss_mask_2: 0.819  loss_dice_2: 2.111  loss_ce_3: 0  loss_mask_3: 0.8192  loss_dice_3: 2.103  loss_ce_4: 0  loss_mask_4: 0.8199  loss_dice_4: 2.107  loss_ce_5: 0  loss_mask_5: 0.8173  loss_dice_5: 2.11  loss_ce_6: 0  loss_mask_6: 0.8172  loss_dice_6: 2.106  loss_ce_7: 0  loss_mask_7: 0.8172  loss_dice_7: 2.108  loss_ce_8: 0  loss_mask_8: 0.8145  loss_dice_8: 2.114  time: 1.9914  data_time: 0.0320  lr: 7.1921e-05  max_mem: 6006M
[02/18 10:18:25] d2.utils.events INFO:  eta: 18:42:14  iter: 18419  total_loss: 31.98  loss_ce: 0  loss_mask: 0.8125  loss_dice: 2.265  loss_seg: 1.467  loss_ce_0: 0  loss_mask_0: 0.8219  loss_dice_0: 2.316  loss_ce_1: 0  loss_mask_1: 0.8185  loss_dice_1: 2.271  loss_ce_2: 0  loss_mask_2: 0.8237  loss_dice_2: 2.262  loss_ce_3: 0  loss_mask_3: 0.8266  loss_dice_3: 2.253  loss_ce_4: 0  loss_mask_4: 0.8271  loss_dice_4: 2.25  loss_ce_5: 0  loss_mask_5: 0.8254  loss_dice_5: 2.249  loss_ce_6: 0  loss_mask_6: 0.8251  loss_dice_6: 2.247  loss_ce_7: 0  loss_mask_7: 0.8219  loss_dice_7: 2.251  loss_ce_8: 0  loss_mask_8: 0.8212  loss_dice_8: 2.26  time: 1.9911  data_time: 0.0372  lr: 7.189e-05  max_mem: 6006M
[02/18 10:18:57] d2.utils.events INFO:  eta: 18:41:11  iter: 18439  total_loss: 33.27  loss_ce: 0  loss_mask: 0.8387  loss_dice: 2.36  loss_seg: 1.063  loss_ce_0: 0  loss_mask_0: 0.837  loss_dice_0: 2.437  loss_ce_1: 0  loss_mask_1: 0.8321  loss_dice_1: 2.384  loss_ce_2: 0  loss_mask_2: 0.8412  loss_dice_2: 2.368  loss_ce_3: 0  loss_mask_3: 0.8434  loss_dice_3: 2.347  loss_ce_4: 0  loss_mask_4: 0.8419  loss_dice_4: 2.356  loss_ce_5: 0  loss_mask_5: 0.8436  loss_dice_5: 2.353  loss_ce_6: 0  loss_mask_6: 0.842  loss_dice_6: 2.347  loss_ce_7: 0  loss_mask_7: 0.8466  loss_dice_7: 2.352  loss_ce_8: 0  loss_mask_8: 0.8486  loss_dice_8: 2.349  time: 1.9906  data_time: 0.0325  lr: 7.1859e-05  max_mem: 6006M
[02/18 10:19:29] d2.utils.events INFO:  eta: 18:40:39  iter: 18459  total_loss: 32.16  loss_ce: 0  loss_mask: 0.8256  loss_dice: 2.234  loss_seg: 0.73  loss_ce_0: 0  loss_mask_0: 0.8382  loss_dice_0: 2.316  loss_ce_1: 0  loss_mask_1: 0.8265  loss_dice_1: 2.258  loss_ce_2: 0  loss_mask_2: 0.8276  loss_dice_2: 2.245  loss_ce_3: 0  loss_mask_3: 0.8284  loss_dice_3: 2.227  loss_ce_4: 0  loss_mask_4: 0.8273  loss_dice_4: 2.232  loss_ce_5: 0  loss_mask_5: 0.8304  loss_dice_5: 2.231  loss_ce_6: 0  loss_mask_6: 0.8288  loss_dice_6: 2.226  loss_ce_7: 0  loss_mask_7: 0.8276  loss_dice_7: 2.226  loss_ce_8: 0  loss_mask_8: 0.8303  loss_dice_8: 2.23  time: 1.9902  data_time: 0.0264  lr: 7.1828e-05  max_mem: 6006M
[02/18 10:20:03] d2.utils.events INFO:  eta: 18:41:19  iter: 18479  total_loss: 30.86  loss_ce: 0  loss_mask: 0.7739  loss_dice: 2.153  loss_seg: 1.057  loss_ce_0: 0  loss_mask_0: 0.7849  loss_dice_0: 2.233  loss_ce_1: 0  loss_mask_1: 0.7716  loss_dice_1: 2.176  loss_ce_2: 0  loss_mask_2: 0.7721  loss_dice_2: 2.164  loss_ce_3: 0  loss_mask_3: 0.7718  loss_dice_3: 2.147  loss_ce_4: 0  loss_mask_4: 0.7738  loss_dice_4: 2.142  loss_ce_5: 0  loss_mask_5: 0.7749  loss_dice_5: 2.142  loss_ce_6: 0  loss_mask_6: 0.7759  loss_dice_6: 2.142  loss_ce_7: 0  loss_mask_7: 0.7731  loss_dice_7: 2.148  loss_ce_8: 0  loss_mask_8: 0.772  loss_dice_8: 2.146  time: 1.9899  data_time: 0.0374  lr: 7.1797e-05  max_mem: 6006M
[02/18 10:20:36] d2.utils.events INFO:  eta: 18:40:41  iter: 18499  total_loss: 31.45  loss_ce: 0  loss_mask: 0.7854  loss_dice: 2.271  loss_seg: 0.9788  loss_ce_0: 0  loss_mask_0: 0.7966  loss_dice_0: 2.321  loss_ce_1: 0  loss_mask_1: 0.7856  loss_dice_1: 2.28  loss_ce_2: 0  loss_mask_2: 0.7873  loss_dice_2: 2.266  loss_ce_3: 0  loss_mask_3: 0.7908  loss_dice_3: 2.272  loss_ce_4: 0  loss_mask_4: 0.789  loss_dice_4: 2.266  loss_ce_5: 0  loss_mask_5: 0.7915  loss_dice_5: 2.266  loss_ce_6: 0  loss_mask_6: 0.7893  loss_dice_6: 2.266  loss_ce_7: 0  loss_mask_7: 0.7868  loss_dice_7: 2.266  loss_ce_8: 0  loss_mask_8: 0.7857  loss_dice_8: 2.264  time: 1.9895  data_time: 0.0299  lr: 7.1766e-05  max_mem: 6006M
[02/18 10:21:09] d2.utils.events INFO:  eta: 18:40:08  iter: 18519  total_loss: 32.99  loss_ce: 0  loss_mask: 0.8281  loss_dice: 2.312  loss_seg: 0.7687  loss_ce_0: 0  loss_mask_0: 0.848  loss_dice_0: 2.355  loss_ce_1: 0  loss_mask_1: 0.8331  loss_dice_1: 2.328  loss_ce_2: 0  loss_mask_2: 0.8302  loss_dice_2: 2.319  loss_ce_3: 0  loss_mask_3: 0.8251  loss_dice_3: 2.308  loss_ce_4: 0  loss_mask_4: 0.8244  loss_dice_4: 2.307  loss_ce_5: 0  loss_mask_5: 0.8289  loss_dice_5: 2.302  loss_ce_6: 0  loss_mask_6: 0.8326  loss_dice_6: 2.298  loss_ce_7: 0  loss_mask_7: 0.8347  loss_dice_7: 2.297  loss_ce_8: 0  loss_mask_8: 0.8331  loss_dice_8: 2.298  time: 1.9892  data_time: 0.0278  lr: 7.1735e-05  max_mem: 6006M
[02/18 10:21:42] d2.utils.events INFO:  eta: 18:39:36  iter: 18539  total_loss: 30.97  loss_ce: 0  loss_mask: 0.836  loss_dice: 2.158  loss_seg: 0.9803  loss_ce_0: 0  loss_mask_0: 0.8546  loss_dice_0: 2.209  loss_ce_1: 0  loss_mask_1: 0.8363  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.8355  loss_dice_2: 2.15  loss_ce_3: 0  loss_mask_3: 0.8391  loss_dice_3: 2.144  loss_ce_4: 0  loss_mask_4: 0.8393  loss_dice_4: 2.145  loss_ce_5: 0  loss_mask_5: 0.8397  loss_dice_5: 2.147  loss_ce_6: 0  loss_mask_6: 0.8446  loss_dice_6: 2.149  loss_ce_7: 0  loss_mask_7: 0.8408  loss_dice_7: 2.147  loss_ce_8: 0  loss_mask_8: 0.8427  loss_dice_8: 2.148  time: 1.9888  data_time: 0.0347  lr: 7.1703e-05  max_mem: 6006M
[02/18 10:22:16] d2.utils.events INFO:  eta: 18:39:04  iter: 18559  total_loss: 31  loss_ce: 0  loss_mask: 0.7946  loss_dice: 2.187  loss_seg: 0.8861  loss_ce_0: 0  loss_mask_0: 0.7887  loss_dice_0: 2.283  loss_ce_1: 0  loss_mask_1: 0.8013  loss_dice_1: 2.208  loss_ce_2: 0  loss_mask_2: 0.8201  loss_dice_2: 2.182  loss_ce_3: 0  loss_mask_3: 0.8123  loss_dice_3: 2.17  loss_ce_4: 0  loss_mask_4: 0.8123  loss_dice_4: 2.173  loss_ce_5: 0  loss_mask_5: 0.8108  loss_dice_5: 2.17  loss_ce_6: 0  loss_mask_6: 0.8042  loss_dice_6: 2.17  loss_ce_7: 0  loss_mask_7: 0.809  loss_dice_7: 2.173  loss_ce_8: 0  loss_mask_8: 0.8093  loss_dice_8: 2.167  time: 1.9885  data_time: 0.0261  lr: 7.1672e-05  max_mem: 6006M
[02/18 10:22:49] d2.utils.events INFO:  eta: 18:38:59  iter: 18579  total_loss: 32.02  loss_ce: 0  loss_mask: 0.8484  loss_dice: 2.265  loss_seg: 0.7634  loss_ce_0: 0  loss_mask_0: 0.8663  loss_dice_0: 2.335  loss_ce_1: 0  loss_mask_1: 0.8609  loss_dice_1: 2.283  loss_ce_2: 0  loss_mask_2: 0.8545  loss_dice_2: 2.269  loss_ce_3: 0  loss_mask_3: 0.8519  loss_dice_3: 2.253  loss_ce_4: 0  loss_mask_4: 0.8533  loss_dice_4: 2.255  loss_ce_5: 0  loss_mask_5: 0.8517  loss_dice_5: 2.251  loss_ce_6: 0  loss_mask_6: 0.8549  loss_dice_6: 2.247  loss_ce_7: 0  loss_mask_7: 0.8518  loss_dice_7: 2.245  loss_ce_8: 0  loss_mask_8: 0.8511  loss_dice_8: 2.243  time: 1.9881  data_time: 0.0276  lr: 7.1641e-05  max_mem: 6006M
[02/18 10:23:23] d2.utils.events INFO:  eta: 18:37:59  iter: 18599  total_loss: 30.37  loss_ce: 0  loss_mask: 0.8167  loss_dice: 2.154  loss_seg: 0.8692  loss_ce_0: 0  loss_mask_0: 0.8281  loss_dice_0: 2.241  loss_ce_1: 0  loss_mask_1: 0.8195  loss_dice_1: 2.167  loss_ce_2: 0  loss_mask_2: 0.8195  loss_dice_2: 2.15  loss_ce_3: 0  loss_mask_3: 0.823  loss_dice_3: 2.13  loss_ce_4: 0  loss_mask_4: 0.8258  loss_dice_4: 2.13  loss_ce_5: 0  loss_mask_5: 0.82  loss_dice_5: 2.13  loss_ce_6: 0  loss_mask_6: 0.8193  loss_dice_6: 2.137  loss_ce_7: 0  loss_mask_7: 0.8231  loss_dice_7: 2.135  loss_ce_8: 0  loss_mask_8: 0.8187  loss_dice_8: 2.141  time: 1.9878  data_time: 0.0266  lr: 7.161e-05  max_mem: 6006M
[02/18 10:23:55] d2.utils.events INFO:  eta: 18:37:26  iter: 18619  total_loss: 31.51  loss_ce: 0  loss_mask: 0.8268  loss_dice: 2.238  loss_seg: 0.6641  loss_ce_0: 0  loss_mask_0: 0.8451  loss_dice_0: 2.289  loss_ce_1: 0  loss_mask_1: 0.8289  loss_dice_1: 2.245  loss_ce_2: 0  loss_mask_2: 0.8292  loss_dice_2: 2.229  loss_ce_3: 0  loss_mask_3: 0.8258  loss_dice_3: 2.221  loss_ce_4: 0  loss_mask_4: 0.8264  loss_dice_4: 2.227  loss_ce_5: 0  loss_mask_5: 0.8237  loss_dice_5: 2.224  loss_ce_6: 0  loss_mask_6: 0.8276  loss_dice_6: 2.226  loss_ce_7: 0  loss_mask_7: 0.8254  loss_dice_7: 2.23  loss_ce_8: 0  loss_mask_8: 0.8248  loss_dice_8: 2.232  time: 1.9874  data_time: 0.0321  lr: 7.1579e-05  max_mem: 6006M
[02/18 10:24:28] d2.utils.events INFO:  eta: 18:36:54  iter: 18639  total_loss: 30.02  loss_ce: 0  loss_mask: 0.789  loss_dice: 2.137  loss_seg: 0.8075  loss_ce_0: 0  loss_mask_0: 0.7957  loss_dice_0: 2.183  loss_ce_1: 0  loss_mask_1: 0.7926  loss_dice_1: 2.135  loss_ce_2: 0  loss_mask_2: 0.7981  loss_dice_2: 2.135  loss_ce_3: 0  loss_mask_3: 0.8003  loss_dice_3: 2.121  loss_ce_4: 0  loss_mask_4: 0.7979  loss_dice_4: 2.118  loss_ce_5: 0  loss_mask_5: 0.7964  loss_dice_5: 2.127  loss_ce_6: 0  loss_mask_6: 0.7977  loss_dice_6: 2.116  loss_ce_7: 0  loss_mask_7: 0.8014  loss_dice_7: 2.123  loss_ce_8: 0  loss_mask_8: 0.7972  loss_dice_8: 2.122  time: 1.9870  data_time: 0.0269  lr: 7.1548e-05  max_mem: 6006M
[02/18 10:25:01] d2.utils.events INFO:  eta: 18:37:37  iter: 18659  total_loss: 31.6  loss_ce: 0  loss_mask: 0.8114  loss_dice: 2.178  loss_seg: 0.9525  loss_ce_0: 0  loss_mask_0: 0.8173  loss_dice_0: 2.239  loss_ce_1: 0  loss_mask_1: 0.8181  loss_dice_1: 2.195  loss_ce_2: 0  loss_mask_2: 0.8158  loss_dice_2: 2.184  loss_ce_3: 0  loss_mask_3: 0.813  loss_dice_3: 2.175  loss_ce_4: 0  loss_mask_4: 0.8107  loss_dice_4: 2.171  loss_ce_5: 0  loss_mask_5: 0.8143  loss_dice_5: 2.173  loss_ce_6: 0  loss_mask_6: 0.8127  loss_dice_6: 2.168  loss_ce_7: 0  loss_mask_7: 0.8126  loss_dice_7: 2.172  loss_ce_8: 0  loss_mask_8: 0.8128  loss_dice_8: 2.167  time: 1.9867  data_time: 0.0354  lr: 7.1517e-05  max_mem: 6006M
[02/18 10:25:32] d2.utils.events INFO:  eta: 18:35:55  iter: 18679  total_loss: 32.33  loss_ce: 0  loss_mask: 0.8269  loss_dice: 2.287  loss_seg: 0.9255  loss_ce_0: 0  loss_mask_0: 0.8504  loss_dice_0: 2.348  loss_ce_1: 0  loss_mask_1: 0.8314  loss_dice_1: 2.296  loss_ce_2: 0  loss_mask_2: 0.8268  loss_dice_2: 2.287  loss_ce_3: 0  loss_mask_3: 0.8266  loss_dice_3: 2.284  loss_ce_4: 0  loss_mask_4: 0.8295  loss_dice_4: 2.283  loss_ce_5: 0  loss_mask_5: 0.8295  loss_dice_5: 2.277  loss_ce_6: 0  loss_mask_6: 0.8246  loss_dice_6: 2.281  loss_ce_7: 0  loss_mask_7: 0.8251  loss_dice_7: 2.281  loss_ce_8: 0  loss_mask_8: 0.8255  loss_dice_8: 2.278  time: 1.9862  data_time: 0.0290  lr: 7.1485e-05  max_mem: 6006M
[02/18 10:26:05] d2.utils.events INFO:  eta: 18:34:14  iter: 18699  total_loss: 30.79  loss_ce: 0  loss_mask: 0.8099  loss_dice: 2.166  loss_seg: 0.768  loss_ce_0: 0  loss_mask_0: 0.8217  loss_dice_0: 2.232  loss_ce_1: 0  loss_mask_1: 0.8112  loss_dice_1: 2.181  loss_ce_2: 0  loss_mask_2: 0.8093  loss_dice_2: 2.168  loss_ce_3: 0  loss_mask_3: 0.8086  loss_dice_3: 2.156  loss_ce_4: 0  loss_mask_4: 0.8137  loss_dice_4: 2.153  loss_ce_5: 0  loss_mask_5: 0.8112  loss_dice_5: 2.162  loss_ce_6: 0  loss_mask_6: 0.8131  loss_dice_6: 2.157  loss_ce_7: 0  loss_mask_7: 0.8121  loss_dice_7: 2.158  loss_ce_8: 0  loss_mask_8: 0.8122  loss_dice_8: 2.164  time: 1.9858  data_time: 0.0300  lr: 7.1454e-05  max_mem: 6006M
[02/18 10:26:38] d2.utils.events INFO:  eta: 18:34:50  iter: 18719  total_loss: 31.91  loss_ce: 0  loss_mask: 0.8022  loss_dice: 2.2  loss_seg: 0.8446  loss_ce_0: 0  loss_mask_0: 0.8196  loss_dice_0: 2.246  loss_ce_1: 0  loss_mask_1: 0.8008  loss_dice_1: 2.202  loss_ce_2: 0  loss_mask_2: 0.8018  loss_dice_2: 2.19  loss_ce_3: 0  loss_mask_3: 0.8058  loss_dice_3: 2.188  loss_ce_4: 0  loss_mask_4: 0.8037  loss_dice_4: 2.19  loss_ce_5: 0  loss_mask_5: 0.8068  loss_dice_5: 2.193  loss_ce_6: 0  loss_mask_6: 0.8057  loss_dice_6: 2.188  loss_ce_7: 0  loss_mask_7: 0.8043  loss_dice_7: 2.19  loss_ce_8: 0  loss_mask_8: 0.8025  loss_dice_8: 2.188  time: 1.9855  data_time: 0.0341  lr: 7.1423e-05  max_mem: 6006M
[02/18 10:27:14] d2.utils.events INFO:  eta: 18:34:23  iter: 18739  total_loss: 30.27  loss_ce: 0  loss_mask: 0.8069  loss_dice: 2.133  loss_seg: 0.8204  loss_ce_0: 0  loss_mask_0: 0.8102  loss_dice_0: 2.212  loss_ce_1: 0  loss_mask_1: 0.8146  loss_dice_1: 2.144  loss_ce_2: 0  loss_mask_2: 0.8186  loss_dice_2: 2.129  loss_ce_3: 0  loss_mask_3: 0.8192  loss_dice_3: 2.123  loss_ce_4: 0  loss_mask_4: 0.8167  loss_dice_4: 2.12  loss_ce_5: 0  loss_mask_5: 0.821  loss_dice_5: 2.124  loss_ce_6: 0  loss_mask_6: 0.8177  loss_dice_6: 2.127  loss_ce_7: 0  loss_mask_7: 0.8174  loss_dice_7: 2.127  loss_ce_8: 0  loss_mask_8: 0.8171  loss_dice_8: 2.121  time: 1.9852  data_time: 0.0291  lr: 7.1392e-05  max_mem: 6006M
[02/18 10:27:46] d2.utils.events INFO:  eta: 18:33:41  iter: 18759  total_loss: 31.28  loss_ce: 0  loss_mask: 0.8316  loss_dice: 2.197  loss_seg: 1.046  loss_ce_0: 0  loss_mask_0: 0.8422  loss_dice_0: 2.252  loss_ce_1: 0  loss_mask_1: 0.8344  loss_dice_1: 2.203  loss_ce_2: 0  loss_mask_2: 0.8355  loss_dice_2: 2.198  loss_ce_3: 0  loss_mask_3: 0.8367  loss_dice_3: 2.186  loss_ce_4: 0  loss_mask_4: 0.8347  loss_dice_4: 2.184  loss_ce_5: 0  loss_mask_5: 0.8375  loss_dice_5: 2.177  loss_ce_6: 0  loss_mask_6: 0.8388  loss_dice_6: 2.178  loss_ce_7: 0  loss_mask_7: 0.8374  loss_dice_7: 2.184  loss_ce_8: 0  loss_mask_8: 0.8389  loss_dice_8: 2.182  time: 1.9848  data_time: 0.0271  lr: 7.1361e-05  max_mem: 6006M
[02/18 10:28:19] d2.utils.events INFO:  eta: 18:33:03  iter: 18779  total_loss: 32.41  loss_ce: 0  loss_mask: 0.8453  loss_dice: 2.209  loss_seg: 0.9482  loss_ce_0: 0  loss_mask_0: 0.8596  loss_dice_0: 2.271  loss_ce_1: 0  loss_mask_1: 0.8395  loss_dice_1: 2.216  loss_ce_2: 0  loss_mask_2: 0.841  loss_dice_2: 2.202  loss_ce_3: 0  loss_mask_3: 0.8497  loss_dice_3: 2.203  loss_ce_4: 0  loss_mask_4: 0.8476  loss_dice_4: 2.201  loss_ce_5: 0  loss_mask_5: 0.8472  loss_dice_5: 2.194  loss_ce_6: 0  loss_mask_6: 0.8477  loss_dice_6: 2.194  loss_ce_7: 0  loss_mask_7: 0.844  loss_dice_7: 2.197  loss_ce_8: 0  loss_mask_8: 0.8443  loss_dice_8: 2.197  time: 1.9845  data_time: 0.0301  lr: 7.133e-05  max_mem: 6006M
[02/18 10:28:51] d2.utils.events INFO:  eta: 18:32:36  iter: 18799  total_loss: 32.08  loss_ce: 0  loss_mask: 0.8288  loss_dice: 2.246  loss_seg: 0.8014  loss_ce_0: 0  loss_mask_0: 0.8318  loss_dice_0: 2.302  loss_ce_1: 0  loss_mask_1: 0.8358  loss_dice_1: 2.263  loss_ce_2: 0  loss_mask_2: 0.8337  loss_dice_2: 2.255  loss_ce_3: 0  loss_mask_3: 0.8346  loss_dice_3: 2.235  loss_ce_4: 0  loss_mask_4: 0.8336  loss_dice_4: 2.233  loss_ce_5: 0  loss_mask_5: 0.8339  loss_dice_5: 2.241  loss_ce_6: 0  loss_mask_6: 0.8334  loss_dice_6: 2.235  loss_ce_7: 0  loss_mask_7: 0.8338  loss_dice_7: 2.237  loss_ce_8: 0  loss_mask_8: 0.8345  loss_dice_8: 2.235  time: 1.9841  data_time: 0.0298  lr: 7.1299e-05  max_mem: 6006M
[02/18 10:29:27] d2.utils.events INFO:  eta: 18:36:56  iter: 18819  total_loss: 32.92  loss_ce: 0  loss_mask: 0.8537  loss_dice: 2.308  loss_seg: 0.8285  loss_ce_0: 0  loss_mask_0: 0.8695  loss_dice_0: 2.376  loss_ce_1: 0  loss_mask_1: 0.8634  loss_dice_1: 2.313  loss_ce_2: 0  loss_mask_2: 0.869  loss_dice_2: 2.29  loss_ce_3: 0  loss_mask_3: 0.8693  loss_dice_3: 2.285  loss_ce_4: 0  loss_mask_4: 0.8684  loss_dice_4: 2.289  loss_ce_5: 0  loss_mask_5: 0.8685  loss_dice_5: 2.292  loss_ce_6: 0  loss_mask_6: 0.8688  loss_dice_6: 2.291  loss_ce_7: 0  loss_mask_7: 0.8655  loss_dice_7: 2.297  loss_ce_8: 0  loss_mask_8: 0.8666  loss_dice_8: 2.3  time: 1.9839  data_time: 0.0301  lr: 7.1267e-05  max_mem: 6006M
[02/18 10:29:58] d2.utils.events INFO:  eta: 18:37:07  iter: 18839  total_loss: 31.14  loss_ce: 0  loss_mask: 0.7873  loss_dice: 2.234  loss_seg: 1.076  loss_ce_0: 0  loss_mask_0: 0.8034  loss_dice_0: 2.29  loss_ce_1: 0  loss_mask_1: 0.7928  loss_dice_1: 2.235  loss_ce_2: 0  loss_mask_2: 0.793  loss_dice_2: 2.225  loss_ce_3: 0  loss_mask_3: 0.7866  loss_dice_3: 2.221  loss_ce_4: 0  loss_mask_4: 0.7878  loss_dice_4: 2.227  loss_ce_5: 0  loss_mask_5: 0.7913  loss_dice_5: 2.218  loss_ce_6: 0  loss_mask_6: 0.7899  loss_dice_6: 2.227  loss_ce_7: 0  loss_mask_7: 0.7914  loss_dice_7: 2.227  loss_ce_8: 0  loss_mask_8: 0.7913  loss_dice_8: 2.234  time: 1.9834  data_time: 0.0366  lr: 7.1236e-05  max_mem: 6006M
[02/18 10:30:31] d2.utils.events INFO:  eta: 18:36:34  iter: 18859  total_loss: 30.31  loss_ce: 0  loss_mask: 0.8297  loss_dice: 2.112  loss_seg: 0.6345  loss_ce_0: 0  loss_mask_0: 0.845  loss_dice_0: 2.204  loss_ce_1: 0  loss_mask_1: 0.8273  loss_dice_1: 2.124  loss_ce_2: 0  loss_mask_2: 0.8323  loss_dice_2: 2.115  loss_ce_3: 0  loss_mask_3: 0.8308  loss_dice_3: 2.101  loss_ce_4: 0  loss_mask_4: 0.8366  loss_dice_4: 2.098  loss_ce_5: 0  loss_mask_5: 0.8384  loss_dice_5: 2.099  loss_ce_6: 0  loss_mask_6: 0.835  loss_dice_6: 2.097  loss_ce_7: 0  loss_mask_7: 0.8346  loss_dice_7: 2.102  loss_ce_8: 0  loss_mask_8: 0.8347  loss_dice_8: 2.1  time: 1.9830  data_time: 0.0299  lr: 7.1205e-05  max_mem: 6006M
[02/18 10:31:04] d2.utils.events INFO:  eta: 18:36:57  iter: 18879  total_loss: 30.02  loss_ce: 0  loss_mask: 0.781  loss_dice: 2.115  loss_seg: 1.05  loss_ce_0: 0  loss_mask_0: 0.7796  loss_dice_0: 2.202  loss_ce_1: 0  loss_mask_1: 0.7843  loss_dice_1: 2.127  loss_ce_2: 0  loss_mask_2: 0.7812  loss_dice_2: 2.107  loss_ce_3: 0  loss_mask_3: 0.7799  loss_dice_3: 2.101  loss_ce_4: 0  loss_mask_4: 0.7846  loss_dice_4: 2.1  loss_ce_5: 0  loss_mask_5: 0.782  loss_dice_5: 2.099  loss_ce_6: 0  loss_mask_6: 0.785  loss_dice_6: 2.097  loss_ce_7: 0  loss_mask_7: 0.7862  loss_dice_7: 2.104  loss_ce_8: 0  loss_mask_8: 0.7868  loss_dice_8: 2.101  time: 1.9827  data_time: 0.0280  lr: 7.1174e-05  max_mem: 6006M
[02/18 10:31:39] d2.utils.events INFO:  eta: 18:36:57  iter: 18899  total_loss: 32.15  loss_ce: 0  loss_mask: 0.8072  loss_dice: 2.249  loss_seg: 1.197  loss_ce_0: 0  loss_mask_0: 0.8228  loss_dice_0: 2.308  loss_ce_1: 0  loss_mask_1: 0.8138  loss_dice_1: 2.254  loss_ce_2: 0  loss_mask_2: 0.8126  loss_dice_2: 2.248  loss_ce_3: 0  loss_mask_3: 0.8159  loss_dice_3: 2.24  loss_ce_4: 0  loss_mask_4: 0.8118  loss_dice_4: 2.233  loss_ce_5: 0  loss_mask_5: 0.8098  loss_dice_5: 2.237  loss_ce_6: 0  loss_mask_6: 0.8134  loss_dice_6: 2.23  loss_ce_7: 0  loss_mask_7: 0.8133  loss_dice_7: 2.232  loss_ce_8: 0  loss_mask_8: 0.8123  loss_dice_8: 2.237  time: 1.9824  data_time: 0.0310  lr: 7.1143e-05  max_mem: 6006M
[02/18 10:32:12] d2.utils.events INFO:  eta: 18:37:21  iter: 18919  total_loss: 30.83  loss_ce: 0  loss_mask: 0.8141  loss_dice: 2.147  loss_seg: 0.8053  loss_ce_0: 0  loss_mask_0: 0.8163  loss_dice_0: 2.202  loss_ce_1: 0  loss_mask_1: 0.8179  loss_dice_1: 2.153  loss_ce_2: 0  loss_mask_2: 0.819  loss_dice_2: 2.136  loss_ce_3: 0  loss_mask_3: 0.8168  loss_dice_3: 2.132  loss_ce_4: 0  loss_mask_4: 0.8182  loss_dice_4: 2.137  loss_ce_5: 0  loss_mask_5: 0.8172  loss_dice_5: 2.136  loss_ce_6: 0  loss_mask_6: 0.8194  loss_dice_6: 2.133  loss_ce_7: 0  loss_mask_7: 0.8163  loss_dice_7: 2.139  loss_ce_8: 0  loss_mask_8: 0.8139  loss_dice_8: 2.141  time: 1.9821  data_time: 0.0346  lr: 7.1112e-05  max_mem: 6006M
[02/18 10:32:47] d2.utils.events INFO:  eta: 18:39:30  iter: 18939  total_loss: 32.22  loss_ce: 0  loss_mask: 0.8587  loss_dice: 2.257  loss_seg: 0.7343  loss_ce_0: 0  loss_mask_0: 0.8931  loss_dice_0: 2.327  loss_ce_1: 0  loss_mask_1: 0.8611  loss_dice_1: 2.275  loss_ce_2: 0  loss_mask_2: 0.8628  loss_dice_2: 2.26  loss_ce_3: 0  loss_mask_3: 0.8587  loss_dice_3: 2.238  loss_ce_4: 0  loss_mask_4: 0.8602  loss_dice_4: 2.24  loss_ce_5: 0  loss_mask_5: 0.8612  loss_dice_5: 2.248  loss_ce_6: 0  loss_mask_6: 0.8625  loss_dice_6: 2.243  loss_ce_7: 0  loss_mask_7: 0.8657  loss_dice_7: 2.239  loss_ce_8: 0  loss_mask_8: 0.8622  loss_dice_8: 2.245  time: 1.9819  data_time: 0.0340  lr: 7.108e-05  max_mem: 6006M
[02/18 10:33:21] d2.utils.events INFO:  eta: 18:44:25  iter: 18959  total_loss: 31.1  loss_ce: 0  loss_mask: 0.7831  loss_dice: 2.117  loss_seg: 1.195  loss_ce_0: 0  loss_mask_0: 0.799  loss_dice_0: 2.184  loss_ce_1: 0  loss_mask_1: 0.7886  loss_dice_1: 2.143  loss_ce_2: 0  loss_mask_2: 0.7853  loss_dice_2: 2.121  loss_ce_3: 0  loss_mask_3: 0.7955  loss_dice_3: 2.105  loss_ce_4: 0  loss_mask_4: 0.7891  loss_dice_4: 2.114  loss_ce_5: 0  loss_mask_5: 0.7889  loss_dice_5: 2.11  loss_ce_6: 0  loss_mask_6: 0.7858  loss_dice_6: 2.111  loss_ce_7: 0  loss_mask_7: 0.7905  loss_dice_7: 2.104  loss_ce_8: 0  loss_mask_8: 0.7906  loss_dice_8: 2.099  time: 1.9815  data_time: 0.0261  lr: 7.1049e-05  max_mem: 6006M
[02/18 10:33:55] d2.utils.events INFO:  eta: 18:43:52  iter: 18979  total_loss: 31.01  loss_ce: 0  loss_mask: 0.7966  loss_dice: 2.218  loss_seg: 0.9479  loss_ce_0: 0  loss_mask_0: 0.8034  loss_dice_0: 2.279  loss_ce_1: 0  loss_mask_1: 0.7934  loss_dice_1: 2.23  loss_ce_2: 0  loss_mask_2: 0.8002  loss_dice_2: 2.214  loss_ce_3: 0  loss_mask_3: 0.7977  loss_dice_3: 2.201  loss_ce_4: 0  loss_mask_4: 0.7964  loss_dice_4: 2.202  loss_ce_5: 0  loss_mask_5: 0.8008  loss_dice_5: 2.205  loss_ce_6: 0  loss_mask_6: 0.7967  loss_dice_6: 2.203  loss_ce_7: 0  loss_mask_7: 0.798  loss_dice_7: 2.208  loss_ce_8: 0  loss_mask_8: 0.7973  loss_dice_8: 2.207  time: 1.9812  data_time: 0.0273  lr: 7.1018e-05  max_mem: 6006M
[02/18 10:34:28] d2.utils.events INFO:  eta: 18:37:52  iter: 18999  total_loss: 30.33  loss_ce: 0  loss_mask: 0.752  loss_dice: 2.198  loss_seg: 0.712  loss_ce_0: 0  loss_mask_0: 0.7597  loss_dice_0: 2.238  loss_ce_1: 0  loss_mask_1: 0.7654  loss_dice_1: 2.207  loss_ce_2: 0  loss_mask_2: 0.7626  loss_dice_2: 2.188  loss_ce_3: 0  loss_mask_3: 0.7597  loss_dice_3: 2.192  loss_ce_4: 0  loss_mask_4: 0.7596  loss_dice_4: 2.188  loss_ce_5: 0  loss_mask_5: 0.7595  loss_dice_5: 2.189  loss_ce_6: 0  loss_mask_6: 0.7544  loss_dice_6: 2.186  loss_ce_7: 0  loss_mask_7: 0.7545  loss_dice_7: 2.184  loss_ce_8: 0  loss_mask_8: 0.7572  loss_dice_8: 2.185  time: 1.9809  data_time: 0.0326  lr: 7.0987e-05  max_mem: 6006M
[02/18 10:35:01] d2.utils.events INFO:  eta: 18:34:37  iter: 19019  total_loss: 29.25  loss_ce: 0  loss_mask: 0.7882  loss_dice: 2.1  loss_seg: 0.7495  loss_ce_0: 0  loss_mask_0: 0.8121  loss_dice_0: 2.149  loss_ce_1: 0  loss_mask_1: 0.792  loss_dice_1: 2.105  loss_ce_2: 0  loss_mask_2: 0.7871  loss_dice_2: 2.1  loss_ce_3: 0  loss_mask_3: 0.7891  loss_dice_3: 2.097  loss_ce_4: 0  loss_mask_4: 0.7891  loss_dice_4: 2.097  loss_ce_5: 0  loss_mask_5: 0.7908  loss_dice_5: 2.096  loss_ce_6: 0  loss_mask_6: 0.7899  loss_dice_6: 2.082  loss_ce_7: 0  loss_mask_7: 0.7877  loss_dice_7: 2.092  loss_ce_8: 0  loss_mask_8: 0.7864  loss_dice_8: 2.097  time: 1.9805  data_time: 0.0328  lr: 7.0956e-05  max_mem: 6006M
[02/18 10:35:32] d2.utils.events INFO:  eta: 18:34:23  iter: 19039  total_loss: 32.1  loss_ce: 0  loss_mask: 0.8666  loss_dice: 2.215  loss_seg: 1.07  loss_ce_0: 0  loss_mask_0: 0.8872  loss_dice_0: 2.27  loss_ce_1: 0  loss_mask_1: 0.8682  loss_dice_1: 2.224  loss_ce_2: 0  loss_mask_2: 0.8648  loss_dice_2: 2.207  loss_ce_3: 0  loss_mask_3: 0.8689  loss_dice_3: 2.197  loss_ce_4: 0  loss_mask_4: 0.8707  loss_dice_4: 2.202  loss_ce_5: 0  loss_mask_5: 0.8684  loss_dice_5: 2.203  loss_ce_6: 0  loss_mask_6: 0.8702  loss_dice_6: 2.201  loss_ce_7: 0  loss_mask_7: 0.8724  loss_dice_7: 2.201  loss_ce_8: 0  loss_mask_8: 0.8746  loss_dice_8: 2.203  time: 1.9801  data_time: 0.0334  lr: 7.0925e-05  max_mem: 6006M
[02/18 10:36:06] d2.utils.events INFO:  eta: 18:33:50  iter: 19059  total_loss: 32.47  loss_ce: 0  loss_mask: 0.8676  loss_dice: 2.304  loss_seg: 0.916  loss_ce_0: 0  loss_mask_0: 0.8548  loss_dice_0: 2.355  loss_ce_1: 0  loss_mask_1: 0.8599  loss_dice_1: 2.313  loss_ce_2: 0  loss_mask_2: 0.8696  loss_dice_2: 2.298  loss_ce_3: 0  loss_mask_3: 0.8751  loss_dice_3: 2.283  loss_ce_4: 0  loss_mask_4: 0.8801  loss_dice_4: 2.28  loss_ce_5: 0  loss_mask_5: 0.8776  loss_dice_5: 2.283  loss_ce_6: 0  loss_mask_6: 0.8795  loss_dice_6: 2.285  loss_ce_7: 0  loss_mask_7: 0.8767  loss_dice_7: 2.286  loss_ce_8: 0  loss_mask_8: 0.8762  loss_dice_8: 2.294  time: 1.9798  data_time: 0.0244  lr: 7.0894e-05  max_mem: 6006M
[02/18 10:36:41] d2.utils.events INFO:  eta: 18:32:28  iter: 19079  total_loss: 30.99  loss_ce: 0  loss_mask: 0.8333  loss_dice: 2.176  loss_seg: 0.9204  loss_ce_0: 0  loss_mask_0: 0.8415  loss_dice_0: 2.235  loss_ce_1: 0  loss_mask_1: 0.8325  loss_dice_1: 2.184  loss_ce_2: 0  loss_mask_2: 0.8306  loss_dice_2: 2.169  loss_ce_3: 0  loss_mask_3: 0.8343  loss_dice_3: 2.16  loss_ce_4: 0  loss_mask_4: 0.8339  loss_dice_4: 2.161  loss_ce_5: 0  loss_mask_5: 0.8337  loss_dice_5: 2.167  loss_ce_6: 0  loss_mask_6: 0.8348  loss_dice_6: 2.163  loss_ce_7: 0  loss_mask_7: 0.8391  loss_dice_7: 2.16  loss_ce_8: 0  loss_mask_8: 0.8402  loss_dice_8: 2.161  time: 1.9795  data_time: 0.0261  lr: 7.0862e-05  max_mem: 6006M
[02/18 10:37:15] d2.utils.events INFO:  eta: 18:30:58  iter: 19099  total_loss: 31.11  loss_ce: 0  loss_mask: 0.8177  loss_dice: 2.204  loss_seg: 0.8201  loss_ce_0: 0  loss_mask_0: 0.8321  loss_dice_0: 2.276  loss_ce_1: 0  loss_mask_1: 0.8189  loss_dice_1: 2.228  loss_ce_2: 0  loss_mask_2: 0.8198  loss_dice_2: 2.201  loss_ce_3: 0  loss_mask_3: 0.8189  loss_dice_3: 2.181  loss_ce_4: 0  loss_mask_4: 0.8225  loss_dice_4: 2.185  loss_ce_5: 0  loss_mask_5: 0.8212  loss_dice_5: 2.192  loss_ce_6: 0  loss_mask_6: 0.8195  loss_dice_6: 2.185  loss_ce_7: 0  loss_mask_7: 0.8225  loss_dice_7: 2.189  loss_ce_8: 0  loss_mask_8: 0.821  loss_dice_8: 2.197  time: 1.9792  data_time: 0.0310  lr: 7.0831e-05  max_mem: 6006M
[02/18 10:37:47] d2.utils.events INFO:  eta: 18:29:31  iter: 19119  total_loss: 32.96  loss_ce: 0  loss_mask: 0.8318  loss_dice: 2.286  loss_seg: 0.9204  loss_ce_0: 0  loss_mask_0: 0.8461  loss_dice_0: 2.364  loss_ce_1: 0  loss_mask_1: 0.8381  loss_dice_1: 2.299  loss_ce_2: 0  loss_mask_2: 0.8369  loss_dice_2: 2.289  loss_ce_3: 0  loss_mask_3: 0.8284  loss_dice_3: 2.276  loss_ce_4: 0  loss_mask_4: 0.8287  loss_dice_4: 2.283  loss_ce_5: 0  loss_mask_5: 0.8326  loss_dice_5: 2.284  loss_ce_6: 0  loss_mask_6: 0.8287  loss_dice_6: 2.279  loss_ce_7: 0  loss_mask_7: 0.8328  loss_dice_7: 2.277  loss_ce_8: 0  loss_mask_8: 0.8338  loss_dice_8: 2.28  time: 1.9788  data_time: 0.0319  lr: 7.08e-05  max_mem: 6006M
[02/18 10:38:22] d2.utils.events INFO:  eta: 18:32:16  iter: 19139  total_loss: 28.91  loss_ce: 0  loss_mask: 0.792  loss_dice: 2.043  loss_seg: 0.6679  loss_ce_0: 0  loss_mask_0: 0.7945  loss_dice_0: 2.102  loss_ce_1: 0  loss_mask_1: 0.7897  loss_dice_1: 2.046  loss_ce_2: 0  loss_mask_2: 0.7913  loss_dice_2: 2.032  loss_ce_3: 0  loss_mask_3: 0.7914  loss_dice_3: 2.028  loss_ce_4: 0  loss_mask_4: 0.7929  loss_dice_4: 2.026  loss_ce_5: 0  loss_mask_5: 0.7885  loss_dice_5: 2.03  loss_ce_6: 0  loss_mask_6: 0.79  loss_dice_6: 2.028  loss_ce_7: 0  loss_mask_7: 0.7905  loss_dice_7: 2.025  loss_ce_8: 0  loss_mask_8: 0.7952  loss_dice_8: 2.034  time: 1.9786  data_time: 0.0331  lr: 7.0769e-05  max_mem: 6006M
[02/18 10:38:54] d2.utils.events INFO:  eta: 18:32:18  iter: 19159  total_loss: 31.14  loss_ce: 0  loss_mask: 0.7319  loss_dice: 2.2  loss_seg: 1.064  loss_ce_0: 0  loss_mask_0: 0.7345  loss_dice_0: 2.267  loss_ce_1: 0  loss_mask_1: 0.7417  loss_dice_1: 2.203  loss_ce_2: 0  loss_mask_2: 0.7408  loss_dice_2: 2.196  loss_ce_3: 0  loss_mask_3: 0.7346  loss_dice_3: 2.189  loss_ce_4: 0  loss_mask_4: 0.7371  loss_dice_4: 2.189  loss_ce_5: 0  loss_mask_5: 0.7368  loss_dice_5: 2.185  loss_ce_6: 0  loss_mask_6: 0.7366  loss_dice_6: 2.189  loss_ce_7: 0  loss_mask_7: 0.7379  loss_dice_7: 2.19  loss_ce_8: 0  loss_mask_8: 0.7365  loss_dice_8: 2.193  time: 1.9782  data_time: 0.0317  lr: 7.0738e-05  max_mem: 6006M
[02/18 10:39:26] d2.utils.events INFO:  eta: 18:32:45  iter: 19179  total_loss: 33.25  loss_ce: 0  loss_mask: 0.8751  loss_dice: 2.362  loss_seg: 0.887  loss_ce_0: 0  loss_mask_0: 0.8854  loss_dice_0: 2.412  loss_ce_1: 0  loss_mask_1: 0.8889  loss_dice_1: 2.361  loss_ce_2: 0  loss_mask_2: 0.886  loss_dice_2: 2.347  loss_ce_3: 0  loss_mask_3: 0.8815  loss_dice_3: 2.346  loss_ce_4: 0  loss_mask_4: 0.878  loss_dice_4: 2.347  loss_ce_5: 0  loss_mask_5: 0.8744  loss_dice_5: 2.346  loss_ce_6: 0  loss_mask_6: 0.8783  loss_dice_6: 2.342  loss_ce_7: 0  loss_mask_7: 0.8808  loss_dice_7: 2.347  loss_ce_8: 0  loss_mask_8: 0.8802  loss_dice_8: 2.348  time: 1.9778  data_time: 0.0272  lr: 7.0706e-05  max_mem: 6006M
[02/18 10:39:58] d2.utils.events INFO:  eta: 18:31:23  iter: 19199  total_loss: 31.23  loss_ce: 0  loss_mask: 0.8192  loss_dice: 2.203  loss_seg: 0.7839  loss_ce_0: 0  loss_mask_0: 0.8309  loss_dice_0: 2.259  loss_ce_1: 0  loss_mask_1: 0.8174  loss_dice_1: 2.208  loss_ce_2: 0  loss_mask_2: 0.8183  loss_dice_2: 2.193  loss_ce_3: 0  loss_mask_3: 0.8215  loss_dice_3: 2.187  loss_ce_4: 0  loss_mask_4: 0.8232  loss_dice_4: 2.178  loss_ce_5: 0  loss_mask_5: 0.827  loss_dice_5: 2.182  loss_ce_6: 0  loss_mask_6: 0.8234  loss_dice_6: 2.181  loss_ce_7: 0  loss_mask_7: 0.8269  loss_dice_7: 2.183  loss_ce_8: 0  loss_mask_8: 0.8272  loss_dice_8: 2.185  time: 1.9774  data_time: 0.0307  lr: 7.0675e-05  max_mem: 6006M
[02/18 10:40:28] d2.utils.events INFO:  eta: 18:29:11  iter: 19219  total_loss: 32.12  loss_ce: 0  loss_mask: 0.8337  loss_dice: 2.288  loss_seg: 0.8689  loss_ce_0: 0  loss_mask_0: 0.8452  loss_dice_0: 2.363  loss_ce_1: 0  loss_mask_1: 0.8317  loss_dice_1: 2.308  loss_ce_2: 0  loss_mask_2: 0.8342  loss_dice_2: 2.28  loss_ce_3: 0  loss_mask_3: 0.8338  loss_dice_3: 2.273  loss_ce_4: 0  loss_mask_4: 0.8395  loss_dice_4: 2.273  loss_ce_5: 0  loss_mask_5: 0.8399  loss_dice_5: 2.282  loss_ce_6: 0  loss_mask_6: 0.8388  loss_dice_6: 2.282  loss_ce_7: 0  loss_mask_7: 0.837  loss_dice_7: 2.282  loss_ce_8: 0  loss_mask_8: 0.8394  loss_dice_8: 2.282  time: 1.9769  data_time: 0.0315  lr: 7.0644e-05  max_mem: 6006M
[02/18 10:41:02] d2.utils.events INFO:  eta: 18:28:01  iter: 19239  total_loss: 29.94  loss_ce: 0  loss_mask: 0.8258  loss_dice: 2.086  loss_seg: 0.8126  loss_ce_0: 0  loss_mask_0: 0.7963  loss_dice_0: 2.176  loss_ce_1: 0  loss_mask_1: 0.826  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.827  loss_dice_2: 2.082  loss_ce_3: 0  loss_mask_3: 0.8332  loss_dice_3: 2.076  loss_ce_4: 0  loss_mask_4: 0.8385  loss_dice_4: 2.074  loss_ce_5: 0  loss_mask_5: 0.8328  loss_dice_5: 2.072  loss_ce_6: 0  loss_mask_6: 0.8336  loss_dice_6: 2.068  loss_ce_7: 0  loss_mask_7: 0.8347  loss_dice_7: 2.076  loss_ce_8: 0  loss_mask_8: 0.8355  loss_dice_8: 2.08  time: 1.9766  data_time: 0.0305  lr: 7.0613e-05  max_mem: 6006M
[02/18 10:41:35] d2.utils.events INFO:  eta: 18:26:49  iter: 19259  total_loss: 30.79  loss_ce: 0  loss_mask: 0.7628  loss_dice: 2.19  loss_seg: 0.8175  loss_ce_0: 0  loss_mask_0: 0.7703  loss_dice_0: 2.26  loss_ce_1: 0  loss_mask_1: 0.7616  loss_dice_1: 2.196  loss_ce_2: 0  loss_mask_2: 0.7612  loss_dice_2: 2.186  loss_ce_3: 0  loss_mask_3: 0.7614  loss_dice_3: 2.182  loss_ce_4: 0  loss_mask_4: 0.7607  loss_dice_4: 2.172  loss_ce_5: 0  loss_mask_5: 0.7618  loss_dice_5: 2.184  loss_ce_6: 0  loss_mask_6: 0.7668  loss_dice_6: 2.172  loss_ce_7: 0  loss_mask_7: 0.7644  loss_dice_7: 2.176  loss_ce_8: 0  loss_mask_8: 0.7679  loss_dice_8: 2.175  time: 1.9763  data_time: 0.0271  lr: 7.0582e-05  max_mem: 6006M
[02/18 10:42:07] d2.utils.events INFO:  eta: 18:24:14  iter: 19279  total_loss: 31.99  loss_ce: 0  loss_mask: 0.8348  loss_dice: 2.221  loss_seg: 1.137  loss_ce_0: 0  loss_mask_0: 0.8282  loss_dice_0: 2.291  loss_ce_1: 0  loss_mask_1: 0.8417  loss_dice_1: 2.238  loss_ce_2: 0  loss_mask_2: 0.8441  loss_dice_2: 2.227  loss_ce_3: 0  loss_mask_3: 0.8485  loss_dice_3: 2.209  loss_ce_4: 0  loss_mask_4: 0.846  loss_dice_4: 2.203  loss_ce_5: 0  loss_mask_5: 0.8448  loss_dice_5: 2.211  loss_ce_6: 0  loss_mask_6: 0.843  loss_dice_6: 2.21  loss_ce_7: 0  loss_mask_7: 0.8428  loss_dice_7: 2.217  loss_ce_8: 0  loss_mask_8: 0.8432  loss_dice_8: 2.215  time: 1.9759  data_time: 0.0402  lr: 7.0551e-05  max_mem: 6006M
[02/18 10:42:41] d2.utils.events INFO:  eta: 18:25:44  iter: 19299  total_loss: 33.48  loss_ce: 0  loss_mask: 0.857  loss_dice: 2.359  loss_seg: 0.9267  loss_ce_0: 0  loss_mask_0: 0.8778  loss_dice_0: 2.401  loss_ce_1: 0  loss_mask_1: 0.8563  loss_dice_1: 2.352  loss_ce_2: 0  loss_mask_2: 0.8585  loss_dice_2: 2.342  loss_ce_3: 0  loss_mask_3: 0.8611  loss_dice_3: 2.34  loss_ce_4: 0  loss_mask_4: 0.8595  loss_dice_4: 2.341  loss_ce_5: 0  loss_mask_5: 0.8606  loss_dice_5: 2.345  loss_ce_6: 0  loss_mask_6: 0.8619  loss_dice_6: 2.344  loss_ce_7: 0  loss_mask_7: 0.8636  loss_dice_7: 2.341  loss_ce_8: 0  loss_mask_8: 0.8645  loss_dice_8: 2.347  time: 1.9756  data_time: 0.0349  lr: 7.0519e-05  max_mem: 6006M
[02/18 10:43:15] d2.utils.events INFO:  eta: 18:25:52  iter: 19319  total_loss: 31.67  loss_ce: 0  loss_mask: 0.8312  loss_dice: 2.204  loss_seg: 1.217  loss_ce_0: 0  loss_mask_0: 0.8261  loss_dice_0: 2.277  loss_ce_1: 0  loss_mask_1: 0.8322  loss_dice_1: 2.205  loss_ce_2: 0  loss_mask_2: 0.8374  loss_dice_2: 2.187  loss_ce_3: 0  loss_mask_3: 0.8314  loss_dice_3: 2.183  loss_ce_4: 0  loss_mask_4: 0.8303  loss_dice_4: 2.194  loss_ce_5: 0  loss_mask_5: 0.834  loss_dice_5: 2.192  loss_ce_6: 0  loss_mask_6: 0.8292  loss_dice_6: 2.19  loss_ce_7: 0  loss_mask_7: 0.8346  loss_dice_7: 2.19  loss_ce_8: 0  loss_mask_8: 0.8343  loss_dice_8: 2.189  time: 1.9753  data_time: 0.0319  lr: 7.0488e-05  max_mem: 6006M
[02/18 10:43:46] d2.utils.events INFO:  eta: 18:22:52  iter: 19339  total_loss: 32.43  loss_ce: 0  loss_mask: 0.8127  loss_dice: 2.267  loss_seg: 0.8666  loss_ce_0: 0  loss_mask_0: 0.8311  loss_dice_0: 2.317  loss_ce_1: 0  loss_mask_1: 0.818  loss_dice_1: 2.279  loss_ce_2: 0  loss_mask_2: 0.8199  loss_dice_2: 2.263  loss_ce_3: 0  loss_mask_3: 0.8236  loss_dice_3: 2.249  loss_ce_4: 0  loss_mask_4: 0.8197  loss_dice_4: 2.249  loss_ce_5: 0  loss_mask_5: 0.8212  loss_dice_5: 2.251  loss_ce_6: 0  loss_mask_6: 0.8198  loss_dice_6: 2.254  loss_ce_7: 0  loss_mask_7: 0.8154  loss_dice_7: 2.254  loss_ce_8: 0  loss_mask_8: 0.8141  loss_dice_8: 2.26  time: 1.9748  data_time: 0.0263  lr: 7.0457e-05  max_mem: 6006M
[02/18 10:44:16] d2.utils.events INFO:  eta: 18:21:04  iter: 19359  total_loss: 31.3  loss_ce: 0  loss_mask: 0.8003  loss_dice: 2.263  loss_seg: 0.8946  loss_ce_0: 0  loss_mask_0: 0.8127  loss_dice_0: 2.325  loss_ce_1: 0  loss_mask_1: 0.8015  loss_dice_1: 2.266  loss_ce_2: 0  loss_mask_2: 0.8054  loss_dice_2: 2.246  loss_ce_3: 0  loss_mask_3: 0.8068  loss_dice_3: 2.247  loss_ce_4: 0  loss_mask_4: 0.8097  loss_dice_4: 2.247  loss_ce_5: 0  loss_mask_5: 0.8073  loss_dice_5: 2.247  loss_ce_6: 0  loss_mask_6: 0.8099  loss_dice_6: 2.25  loss_ce_7: 0  loss_mask_7: 0.8096  loss_dice_7: 2.251  loss_ce_8: 0  loss_mask_8: 0.8078  loss_dice_8: 2.243  time: 1.9744  data_time: 0.0276  lr: 7.0426e-05  max_mem: 6006M
[02/18 10:44:49] d2.utils.events INFO:  eta: 18:20:32  iter: 19379  total_loss: 31.41  loss_ce: 0  loss_mask: 0.839  loss_dice: 2.186  loss_seg: 0.9716  loss_ce_0: 0  loss_mask_0: 0.8551  loss_dice_0: 2.245  loss_ce_1: 0  loss_mask_1: 0.8452  loss_dice_1: 2.193  loss_ce_2: 0  loss_mask_2: 0.8438  loss_dice_2: 2.179  loss_ce_3: 0  loss_mask_3: 0.8439  loss_dice_3: 2.183  loss_ce_4: 0  loss_mask_4: 0.8422  loss_dice_4: 2.182  loss_ce_5: 0  loss_mask_5: 0.8416  loss_dice_5: 2.182  loss_ce_6: 0  loss_mask_6: 0.8406  loss_dice_6: 2.185  loss_ce_7: 0  loss_mask_7: 0.8423  loss_dice_7: 2.181  loss_ce_8: 0  loss_mask_8: 0.8429  loss_dice_8: 2.175  time: 1.9740  data_time: 0.0337  lr: 7.0395e-05  max_mem: 6006M
[02/18 10:45:24] d2.utils.events INFO:  eta: 18:20:30  iter: 19399  total_loss: 31.12  loss_ce: 0  loss_mask: 0.8154  loss_dice: 2.181  loss_seg: 0.7107  loss_ce_0: 0  loss_mask_0: 0.8374  loss_dice_0: 2.239  loss_ce_1: 0  loss_mask_1: 0.825  loss_dice_1: 2.207  loss_ce_2: 0  loss_mask_2: 0.8264  loss_dice_2: 2.182  loss_ce_3: 0  loss_mask_3: 0.8268  loss_dice_3: 2.165  loss_ce_4: 0  loss_mask_4: 0.8315  loss_dice_4: 2.175  loss_ce_5: 0  loss_mask_5: 0.8252  loss_dice_5: 2.161  loss_ce_6: 0  loss_mask_6: 0.8247  loss_dice_6: 2.165  loss_ce_7: 0  loss_mask_7: 0.8282  loss_dice_7: 2.175  loss_ce_8: 0  loss_mask_8: 0.8245  loss_dice_8: 2.172  time: 1.9738  data_time: 0.0335  lr: 7.0363e-05  max_mem: 6006M
[02/18 10:45:57] d2.utils.events INFO:  eta: 18:20:42  iter: 19419  total_loss: 30.47  loss_ce: 0  loss_mask: 0.799  loss_dice: 2.129  loss_seg: 1.013  loss_ce_0: 0  loss_mask_0: 0.7975  loss_dice_0: 2.213  loss_ce_1: 0  loss_mask_1: 0.7983  loss_dice_1: 2.149  loss_ce_2: 0  loss_mask_2: 0.7998  loss_dice_2: 2.134  loss_ce_3: 0  loss_mask_3: 0.8033  loss_dice_3: 2.128  loss_ce_4: 0  loss_mask_4: 0.8042  loss_dice_4: 2.123  loss_ce_5: 0  loss_mask_5: 0.8059  loss_dice_5: 2.119  loss_ce_6: 0  loss_mask_6: 0.8035  loss_dice_6: 2.12  loss_ce_7: 0  loss_mask_7: 0.8073  loss_dice_7: 2.116  loss_ce_8: 0  loss_mask_8: 0.809  loss_dice_8: 2.121  time: 1.9735  data_time: 0.0350  lr: 7.0332e-05  max_mem: 6006M
[02/18 10:46:31] d2.utils.events INFO:  eta: 18:21:56  iter: 19439  total_loss: 30.89  loss_ce: 0  loss_mask: 0.7816  loss_dice: 2.183  loss_seg: 0.7364  loss_ce_0: 0  loss_mask_0: 0.8052  loss_dice_0: 2.245  loss_ce_1: 0  loss_mask_1: 0.7828  loss_dice_1: 2.189  loss_ce_2: 0  loss_mask_2: 0.7749  loss_dice_2: 2.178  loss_ce_3: 0  loss_mask_3: 0.7796  loss_dice_3: 2.172  loss_ce_4: 0  loss_mask_4: 0.7858  loss_dice_4: 2.176  loss_ce_5: 0  loss_mask_5: 0.7864  loss_dice_5: 2.169  loss_ce_6: 0  loss_mask_6: 0.7903  loss_dice_6: 2.173  loss_ce_7: 0  loss_mask_7: 0.7918  loss_dice_7: 2.173  loss_ce_8: 0  loss_mask_8: 0.7914  loss_dice_8: 2.173  time: 1.9732  data_time: 0.0288  lr: 7.0301e-05  max_mem: 6006M
[02/18 10:47:04] d2.utils.events INFO:  eta: 18:21:23  iter: 19459  total_loss: 33.04  loss_ce: 0  loss_mask: 0.8009  loss_dice: 2.294  loss_seg: 0.9755  loss_ce_0: 0  loss_mask_0: 0.7975  loss_dice_0: 2.347  loss_ce_1: 0  loss_mask_1: 0.7988  loss_dice_1: 2.311  loss_ce_2: 0  loss_mask_2: 0.7969  loss_dice_2: 2.293  loss_ce_3: 0  loss_mask_3: 0.8021  loss_dice_3: 2.285  loss_ce_4: 0  loss_mask_4: 0.8083  loss_dice_4: 2.285  loss_ce_5: 0  loss_mask_5: 0.8062  loss_dice_5: 2.289  loss_ce_6: 0  loss_mask_6: 0.8043  loss_dice_6: 2.28  loss_ce_7: 0  loss_mask_7: 0.8055  loss_dice_7: 2.284  loss_ce_8: 0  loss_mask_8: 0.8095  loss_dice_8: 2.281  time: 1.9728  data_time: 0.0308  lr: 7.027e-05  max_mem: 6006M
[02/18 10:47:36] d2.utils.events INFO:  eta: 18:17:37  iter: 19479  total_loss: 31.21  loss_ce: 0  loss_mask: 0.8299  loss_dice: 2.142  loss_seg: 0.9423  loss_ce_0: 0  loss_mask_0: 0.8361  loss_dice_0: 2.196  loss_ce_1: 0  loss_mask_1: 0.8387  loss_dice_1: 2.161  loss_ce_2: 0  loss_mask_2: 0.8382  loss_dice_2: 2.143  loss_ce_3: 0  loss_mask_3: 0.8362  loss_dice_3: 2.127  loss_ce_4: 0  loss_mask_4: 0.8378  loss_dice_4: 2.129  loss_ce_5: 0  loss_mask_5: 0.8395  loss_dice_5: 2.128  loss_ce_6: 0  loss_mask_6: 0.8372  loss_dice_6: 2.122  loss_ce_7: 0  loss_mask_7: 0.838  loss_dice_7: 2.128  loss_ce_8: 0  loss_mask_8: 0.8361  loss_dice_8: 2.125  time: 1.9724  data_time: 0.0296  lr: 7.0239e-05  max_mem: 6006M
[02/18 10:48:09] d2.utils.events INFO:  eta: 18:17:17  iter: 19499  total_loss: 29.71  loss_ce: 0  loss_mask: 0.7644  loss_dice: 2.052  loss_seg: 0.8133  loss_ce_0: 0  loss_mask_0: 0.7616  loss_dice_0: 2.119  loss_ce_1: 0  loss_mask_1: 0.7638  loss_dice_1: 2.053  loss_ce_2: 0  loss_mask_2: 0.7636  loss_dice_2: 2.046  loss_ce_3: 0  loss_mask_3: 0.7686  loss_dice_3: 2.04  loss_ce_4: 0  loss_mask_4: 0.7641  loss_dice_4: 2.037  loss_ce_5: 0  loss_mask_5: 0.7653  loss_dice_5: 2.04  loss_ce_6: 0  loss_mask_6: 0.7632  loss_dice_6: 2.038  loss_ce_7: 0  loss_mask_7: 0.7626  loss_dice_7: 2.044  loss_ce_8: 0  loss_mask_8: 0.7659  loss_dice_8: 2.041  time: 1.9721  data_time: 0.0294  lr: 7.0207e-05  max_mem: 6006M
[02/18 10:48:43] d2.utils.events INFO:  eta: 18:16:32  iter: 19519  total_loss: 31.97  loss_ce: 0  loss_mask: 0.8023  loss_dice: 2.204  loss_seg: 0.8779  loss_ce_0: 0  loss_mask_0: 0.8104  loss_dice_0: 2.27  loss_ce_1: 0  loss_mask_1: 0.8065  loss_dice_1: 2.21  loss_ce_2: 0  loss_mask_2: 0.8051  loss_dice_2: 2.212  loss_ce_3: 0  loss_mask_3: 0.8064  loss_dice_3: 2.204  loss_ce_4: 0  loss_mask_4: 0.8085  loss_dice_4: 2.2  loss_ce_5: 0  loss_mask_5: 0.8048  loss_dice_5: 2.199  loss_ce_6: 0  loss_mask_6: 0.8084  loss_dice_6: 2.198  loss_ce_7: 0  loss_mask_7: 0.8062  loss_dice_7: 2.193  loss_ce_8: 0  loss_mask_8: 0.808  loss_dice_8: 2.199  time: 1.9718  data_time: 0.0320  lr: 7.0176e-05  max_mem: 6006M
[02/18 10:49:15] d2.utils.events INFO:  eta: 18:16:12  iter: 19539  total_loss: 28.96  loss_ce: 0  loss_mask: 0.7569  loss_dice: 2.031  loss_seg: 0.7097  loss_ce_0: 0  loss_mask_0: 0.759  loss_dice_0: 2.081  loss_ce_1: 0  loss_mask_1: 0.7613  loss_dice_1: 2.046  loss_ce_2: 0  loss_mask_2: 0.7577  loss_dice_2: 2.032  loss_ce_3: 0  loss_mask_3: 0.7564  loss_dice_3: 2.019  loss_ce_4: 0  loss_mask_4: 0.764  loss_dice_4: 2.025  loss_ce_5: 0  loss_mask_5: 0.7627  loss_dice_5: 2.02  loss_ce_6: 0  loss_mask_6: 0.7644  loss_dice_6: 2.018  loss_ce_7: 0  loss_mask_7: 0.7624  loss_dice_7: 2.019  loss_ce_8: 0  loss_mask_8: 0.7601  loss_dice_8: 2.026  time: 1.9714  data_time: 0.0290  lr: 7.0145e-05  max_mem: 6006M
[02/18 10:49:48] d2.utils.events INFO:  eta: 18:15:27  iter: 19559  total_loss: 30.9  loss_ce: 0  loss_mask: 0.8128  loss_dice: 2.154  loss_seg: 0.882  loss_ce_0: 0  loss_mask_0: 0.8188  loss_dice_0: 2.204  loss_ce_1: 0  loss_mask_1: 0.8095  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.8134  loss_dice_2: 2.141  loss_ce_3: 0  loss_mask_3: 0.8102  loss_dice_3: 2.135  loss_ce_4: 0  loss_mask_4: 0.813  loss_dice_4: 2.141  loss_ce_5: 0  loss_mask_5: 0.8166  loss_dice_5: 2.138  loss_ce_6: 0  loss_mask_6: 0.8137  loss_dice_6: 2.133  loss_ce_7: 0  loss_mask_7: 0.817  loss_dice_7: 2.14  loss_ce_8: 0  loss_mask_8: 0.8186  loss_dice_8: 2.141  time: 1.9711  data_time: 0.0274  lr: 7.0114e-05  max_mem: 6006M
[02/18 10:50:22] d2.utils.events INFO:  eta: 18:14:12  iter: 19579  total_loss: 29.61  loss_ce: 0  loss_mask: 0.787  loss_dice: 2.086  loss_seg: 0.7847  loss_ce_0: 0  loss_mask_0: 0.7879  loss_dice_0: 2.172  loss_ce_1: 0  loss_mask_1: 0.7858  loss_dice_1: 2.099  loss_ce_2: 0  loss_mask_2: 0.7886  loss_dice_2: 2.084  loss_ce_3: 0  loss_mask_3: 0.7878  loss_dice_3: 2.078  loss_ce_4: 0  loss_mask_4: 0.7879  loss_dice_4: 2.079  loss_ce_5: 0  loss_mask_5: 0.789  loss_dice_5: 2.08  loss_ce_6: 0  loss_mask_6: 0.7851  loss_dice_6: 2.076  loss_ce_7: 0  loss_mask_7: 0.7885  loss_dice_7: 2.076  loss_ce_8: 0  loss_mask_8: 0.7907  loss_dice_8: 2.076  time: 1.9708  data_time: 0.0333  lr: 7.0083e-05  max_mem: 6006M
[02/18 10:50:57] d2.utils.events INFO:  eta: 18:16:20  iter: 19599  total_loss: 32.03  loss_ce: 0  loss_mask: 0.8486  loss_dice: 2.231  loss_seg: 1.175  loss_ce_0: 0  loss_mask_0: 0.8546  loss_dice_0: 2.27  loss_ce_1: 0  loss_mask_1: 0.8428  loss_dice_1: 2.245  loss_ce_2: 0  loss_mask_2: 0.8456  loss_dice_2: 2.23  loss_ce_3: 0  loss_mask_3: 0.8508  loss_dice_3: 2.225  loss_ce_4: 0  loss_mask_4: 0.8496  loss_dice_4: 2.219  loss_ce_5: 0  loss_mask_5: 0.8484  loss_dice_5: 2.221  loss_ce_6: 0  loss_mask_6: 0.8505  loss_dice_6: 2.222  loss_ce_7: 0  loss_mask_7: 0.8501  loss_dice_7: 2.229  loss_ce_8: 0  loss_mask_8: 0.8486  loss_dice_8: 2.219  time: 1.9706  data_time: 0.0299  lr: 7.0051e-05  max_mem: 6006M
[02/18 10:51:28] d2.utils.events INFO:  eta: 18:13:49  iter: 19619  total_loss: 30.51  loss_ce: 0  loss_mask: 0.8031  loss_dice: 2.2  loss_seg: 0.8048  loss_ce_0: 0  loss_mask_0: 0.8167  loss_dice_0: 2.283  loss_ce_1: 0  loss_mask_1: 0.8066  loss_dice_1: 2.206  loss_ce_2: 0  loss_mask_2: 0.8087  loss_dice_2: 2.198  loss_ce_3: 0  loss_mask_3: 0.8094  loss_dice_3: 2.197  loss_ce_4: 0  loss_mask_4: 0.8095  loss_dice_4: 2.198  loss_ce_5: 0  loss_mask_5: 0.8056  loss_dice_5: 2.189  loss_ce_6: 0  loss_mask_6: 0.8038  loss_dice_6: 2.195  loss_ce_7: 0  loss_mask_7: 0.8047  loss_dice_7: 2.191  loss_ce_8: 0  loss_mask_8: 0.8049  loss_dice_8: 2.191  time: 1.9702  data_time: 0.0364  lr: 7.002e-05  max_mem: 6006M
[02/18 10:52:02] d2.utils.events INFO:  eta: 18:14:02  iter: 19639  total_loss: 30.83  loss_ce: 0  loss_mask: 0.82  loss_dice: 2.153  loss_seg: 0.8891  loss_ce_0: 0  loss_mask_0: 0.8252  loss_dice_0: 2.218  loss_ce_1: 0  loss_mask_1: 0.8176  loss_dice_1: 2.171  loss_ce_2: 0  loss_mask_2: 0.8165  loss_dice_2: 2.156  loss_ce_3: 0  loss_mask_3: 0.8189  loss_dice_3: 2.146  loss_ce_4: 0  loss_mask_4: 0.8197  loss_dice_4: 2.141  loss_ce_5: 0  loss_mask_5: 0.8218  loss_dice_5: 2.146  loss_ce_6: 0  loss_mask_6: 0.8182  loss_dice_6: 2.144  loss_ce_7: 0  loss_mask_7: 0.8226  loss_dice_7: 2.145  loss_ce_8: 0  loss_mask_8: 0.8209  loss_dice_8: 2.151  time: 1.9699  data_time: 0.0391  lr: 6.9989e-05  max_mem: 6006M
[02/18 10:52:34] d2.utils.events INFO:  eta: 18:12:44  iter: 19659  total_loss: 30.46  loss_ce: 0  loss_mask: 0.8227  loss_dice: 2.143  loss_seg: 1.009  loss_ce_0: 0  loss_mask_0: 0.8449  loss_dice_0: 2.183  loss_ce_1: 0  loss_mask_1: 0.8283  loss_dice_1: 2.162  loss_ce_2: 0  loss_mask_2: 0.8251  loss_dice_2: 2.154  loss_ce_3: 0  loss_mask_3: 0.8232  loss_dice_3: 2.128  loss_ce_4: 0  loss_mask_4: 0.8237  loss_dice_4: 2.133  loss_ce_5: 0  loss_mask_5: 0.8238  loss_dice_5: 2.132  loss_ce_6: 0  loss_mask_6: 0.8256  loss_dice_6: 2.123  loss_ce_7: 0  loss_mask_7: 0.8277  loss_dice_7: 2.13  loss_ce_8: 0  loss_mask_8: 0.8277  loss_dice_8: 2.131  time: 1.9695  data_time: 0.0301  lr: 6.9958e-05  max_mem: 6006M
[02/18 10:53:06] d2.utils.events INFO:  eta: 18:13:25  iter: 19679  total_loss: 31.85  loss_ce: 0  loss_mask: 0.8129  loss_dice: 2.264  loss_seg: 0.8562  loss_ce_0: 0  loss_mask_0: 0.8206  loss_dice_0: 2.337  loss_ce_1: 0  loss_mask_1: 0.8188  loss_dice_1: 2.274  loss_ce_2: 0  loss_mask_2: 0.8239  loss_dice_2: 2.255  loss_ce_3: 0  loss_mask_3: 0.8219  loss_dice_3: 2.252  loss_ce_4: 0  loss_mask_4: 0.8224  loss_dice_4: 2.257  loss_ce_5: 0  loss_mask_5: 0.8212  loss_dice_5: 2.259  loss_ce_6: 0  loss_mask_6: 0.8186  loss_dice_6: 2.259  loss_ce_7: 0  loss_mask_7: 0.8132  loss_dice_7: 2.262  loss_ce_8: 0  loss_mask_8: 0.8193  loss_dice_8: 2.25  time: 1.9691  data_time: 0.0310  lr: 6.9927e-05  max_mem: 6006M
[02/18 10:53:38] d2.utils.events INFO:  eta: 18:14:23  iter: 19699  total_loss: 30.55  loss_ce: 0  loss_mask: 0.8103  loss_dice: 2.128  loss_seg: 0.7736  loss_ce_0: 0  loss_mask_0: 0.8198  loss_dice_0: 2.168  loss_ce_1: 0  loss_mask_1: 0.8129  loss_dice_1: 2.137  loss_ce_2: 0  loss_mask_2: 0.8219  loss_dice_2: 2.119  loss_ce_3: 0  loss_mask_3: 0.8177  loss_dice_3: 2.116  loss_ce_4: 0  loss_mask_4: 0.8183  loss_dice_4: 2.121  loss_ce_5: 0  loss_mask_5: 0.8201  loss_dice_5: 2.115  loss_ce_6: 0  loss_mask_6: 0.8142  loss_dice_6: 2.115  loss_ce_7: 0  loss_mask_7: 0.8167  loss_dice_7: 2.116  loss_ce_8: 0  loss_mask_8: 0.8168  loss_dice_8: 2.118  time: 1.9687  data_time: 0.0442  lr: 6.9895e-05  max_mem: 6006M
[02/18 10:54:10] d2.utils.events INFO:  eta: 18:11:19  iter: 19719  total_loss: 31.5  loss_ce: 0  loss_mask: 0.8177  loss_dice: 2.173  loss_seg: 0.8995  loss_ce_0: 0  loss_mask_0: 0.8185  loss_dice_0: 2.221  loss_ce_1: 0  loss_mask_1: 0.8189  loss_dice_1: 2.178  loss_ce_2: 0  loss_mask_2: 0.8197  loss_dice_2: 2.164  loss_ce_3: 0  loss_mask_3: 0.8188  loss_dice_3: 2.157  loss_ce_4: 0  loss_mask_4: 0.8201  loss_dice_4: 2.164  loss_ce_5: 0  loss_mask_5: 0.8162  loss_dice_5: 2.158  loss_ce_6: 0  loss_mask_6: 0.8151  loss_dice_6: 2.16  loss_ce_7: 0  loss_mask_7: 0.8194  loss_dice_7: 2.157  loss_ce_8: 0  loss_mask_8: 0.8185  loss_dice_8: 2.16  time: 1.9684  data_time: 0.0220  lr: 6.9864e-05  max_mem: 6006M
[02/18 10:54:44] d2.utils.events INFO:  eta: 18:10:47  iter: 19739  total_loss: 30.95  loss_ce: 0  loss_mask: 0.8064  loss_dice: 2.187  loss_seg: 0.8542  loss_ce_0: 0  loss_mask_0: 0.8228  loss_dice_0: 2.251  loss_ce_1: 0  loss_mask_1: 0.8016  loss_dice_1: 2.199  loss_ce_2: 0  loss_mask_2: 0.8031  loss_dice_2: 2.184  loss_ce_3: 0  loss_mask_3: 0.8055  loss_dice_3: 2.174  loss_ce_4: 0  loss_mask_4: 0.8113  loss_dice_4: 2.169  loss_ce_5: 0  loss_mask_5: 0.8091  loss_dice_5: 2.176  loss_ce_6: 0  loss_mask_6: 0.8087  loss_dice_6: 2.172  loss_ce_7: 0  loss_mask_7: 0.8094  loss_dice_7: 2.171  loss_ce_8: 0  loss_mask_8: 0.807  loss_dice_8: 2.174  time: 1.9681  data_time: 0.0341  lr: 6.9833e-05  max_mem: 6006M
[02/18 10:55:16] d2.utils.events INFO:  eta: 18:11:14  iter: 19759  total_loss: 30.79  loss_ce: 0  loss_mask: 0.8225  loss_dice: 2.15  loss_seg: 0.9021  loss_ce_0: 0  loss_mask_0: 0.8266  loss_dice_0: 2.235  loss_ce_1: 0  loss_mask_1: 0.8247  loss_dice_1: 2.161  loss_ce_2: 0  loss_mask_2: 0.8332  loss_dice_2: 2.148  loss_ce_3: 0  loss_mask_3: 0.8341  loss_dice_3: 2.145  loss_ce_4: 0  loss_mask_4: 0.8322  loss_dice_4: 2.15  loss_ce_5: 0  loss_mask_5: 0.8268  loss_dice_5: 2.147  loss_ce_6: 0  loss_mask_6: 0.8284  loss_dice_6: 2.143  loss_ce_7: 0  loss_mask_7: 0.8318  loss_dice_7: 2.14  loss_ce_8: 0  loss_mask_8: 0.8343  loss_dice_8: 2.143  time: 1.9677  data_time: 0.0321  lr: 6.9802e-05  max_mem: 6006M
[02/18 10:55:49] d2.utils.events INFO:  eta: 18:10:13  iter: 19779  total_loss: 31.4  loss_ce: 0  loss_mask: 0.8049  loss_dice: 2.175  loss_seg: 0.9747  loss_ce_0: 0  loss_mask_0: 0.8162  loss_dice_0: 2.265  loss_ce_1: 0  loss_mask_1: 0.812  loss_dice_1: 2.187  loss_ce_2: 0  loss_mask_2: 0.8089  loss_dice_2: 2.179  loss_ce_3: 0  loss_mask_3: 0.8122  loss_dice_3: 2.168  loss_ce_4: 0  loss_mask_4: 0.8094  loss_dice_4: 2.166  loss_ce_5: 0  loss_mask_5: 0.811  loss_dice_5: 2.167  loss_ce_6: 0  loss_mask_6: 0.8093  loss_dice_6: 2.168  loss_ce_7: 0  loss_mask_7: 0.8059  loss_dice_7: 2.165  loss_ce_8: 0  loss_mask_8: 0.8081  loss_dice_8: 2.169  time: 1.9674  data_time: 0.0291  lr: 6.977e-05  max_mem: 6006M
[02/18 10:56:22] d2.utils.events INFO:  eta: 18:11:47  iter: 19799  total_loss: 28.02  loss_ce: 0  loss_mask: 0.757  loss_dice: 1.981  loss_seg: 0.8274  loss_ce_0: 0  loss_mask_0: 0.7629  loss_dice_0: 2.056  loss_ce_1: 0  loss_mask_1: 0.7615  loss_dice_1: 1.995  loss_ce_2: 0  loss_mask_2: 0.7632  loss_dice_2: 1.979  loss_ce_3: 0  loss_mask_3: 0.7637  loss_dice_3: 1.963  loss_ce_4: 0  loss_mask_4: 0.7644  loss_dice_4: 1.961  loss_ce_5: 0  loss_mask_5: 0.7635  loss_dice_5: 1.968  loss_ce_6: 0  loss_mask_6: 0.7639  loss_dice_6: 1.964  loss_ce_7: 0  loss_mask_7: 0.7622  loss_dice_7: 1.963  loss_ce_8: 0  loss_mask_8: 0.7627  loss_dice_8: 1.971  time: 1.9671  data_time: 0.0321  lr: 6.9739e-05  max_mem: 6006M
[02/18 10:56:54] d2.utils.events INFO:  eta: 18:08:24  iter: 19819  total_loss: 31.35  loss_ce: 0  loss_mask: 0.7887  loss_dice: 2.216  loss_seg: 0.7938  loss_ce_0: 0  loss_mask_0: 0.8107  loss_dice_0: 2.297  loss_ce_1: 0  loss_mask_1: 0.7939  loss_dice_1: 2.245  loss_ce_2: 0  loss_mask_2: 0.7914  loss_dice_2: 2.219  loss_ce_3: 0  loss_mask_3: 0.7949  loss_dice_3: 2.209  loss_ce_4: 0  loss_mask_4: 0.7914  loss_dice_4: 2.214  loss_ce_5: 0  loss_mask_5: 0.7925  loss_dice_5: 2.211  loss_ce_6: 0  loss_mask_6: 0.7962  loss_dice_6: 2.209  loss_ce_7: 0  loss_mask_7: 0.7967  loss_dice_7: 2.208  loss_ce_8: 0  loss_mask_8: 0.7959  loss_dice_8: 2.216  time: 1.9667  data_time: 0.0312  lr: 6.9708e-05  max_mem: 6006M
[02/18 10:57:29] d2.utils.events INFO:  eta: 18:09:04  iter: 19839  total_loss: 30.16  loss_ce: 0  loss_mask: 0.7782  loss_dice: 2.137  loss_seg: 0.9014  loss_ce_0: 0  loss_mask_0: 0.7786  loss_dice_0: 2.207  loss_ce_1: 0  loss_mask_1: 0.7791  loss_dice_1: 2.158  loss_ce_2: 0  loss_mask_2: 0.776  loss_dice_2: 2.145  loss_ce_3: 0  loss_mask_3: 0.7793  loss_dice_3: 2.132  loss_ce_4: 0  loss_mask_4: 0.7792  loss_dice_4: 2.134  loss_ce_5: 0  loss_mask_5: 0.7816  loss_dice_5: 2.137  loss_ce_6: 0  loss_mask_6: 0.7804  loss_dice_6: 2.131  loss_ce_7: 0  loss_mask_7: 0.7796  loss_dice_7: 2.13  loss_ce_8: 0  loss_mask_8: 0.7851  loss_dice_8: 2.131  time: 1.9665  data_time: 0.0336  lr: 6.9677e-05  max_mem: 6006M
[02/18 10:58:04] d2.utils.events INFO:  eta: 18:10:36  iter: 19859  total_loss: 30.35  loss_ce: 0  loss_mask: 0.8099  loss_dice: 2.085  loss_seg: 0.8984  loss_ce_0: 0  loss_mask_0: 0.8238  loss_dice_0: 2.146  loss_ce_1: 0  loss_mask_1: 0.8118  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.8124  loss_dice_2: 2.085  loss_ce_3: 0  loss_mask_3: 0.8121  loss_dice_3: 2.076  loss_ce_4: 0  loss_mask_4: 0.8153  loss_dice_4: 2.076  loss_ce_5: 0  loss_mask_5: 0.8157  loss_dice_5: 2.078  loss_ce_6: 0  loss_mask_6: 0.8201  loss_dice_6: 2.078  loss_ce_7: 0  loss_mask_7: 0.8186  loss_dice_7: 2.08  loss_ce_8: 0  loss_mask_8: 0.8145  loss_dice_8: 2.086  time: 1.9662  data_time: 0.0259  lr: 6.9646e-05  max_mem: 6006M
[02/18 10:58:37] d2.utils.events INFO:  eta: 18:09:47  iter: 19879  total_loss: 32.78  loss_ce: 0  loss_mask: 0.8441  loss_dice: 2.321  loss_seg: 0.9755  loss_ce_0: 0  loss_mask_0: 0.8439  loss_dice_0: 2.355  loss_ce_1: 0  loss_mask_1: 0.8411  loss_dice_1: 2.334  loss_ce_2: 0  loss_mask_2: 0.8428  loss_dice_2: 2.324  loss_ce_3: 0  loss_mask_3: 0.8408  loss_dice_3: 2.312  loss_ce_4: 0  loss_mask_4: 0.8402  loss_dice_4: 2.313  loss_ce_5: 0  loss_mask_5: 0.8391  loss_dice_5: 2.309  loss_ce_6: 0  loss_mask_6: 0.8399  loss_dice_6: 2.304  loss_ce_7: 0  loss_mask_7: 0.8379  loss_dice_7: 2.304  loss_ce_8: 0  loss_mask_8: 0.839  loss_dice_8: 2.301  time: 1.9659  data_time: 0.0330  lr: 6.9614e-05  max_mem: 6006M
[02/18 10:59:09] d2.utils.events INFO:  eta: 18:05:16  iter: 19899  total_loss: 31.75  loss_ce: 0  loss_mask: 0.8195  loss_dice: 2.268  loss_seg: 0.9654  loss_ce_0: 0  loss_mask_0: 0.8249  loss_dice_0: 2.329  loss_ce_1: 0  loss_mask_1: 0.8214  loss_dice_1: 2.276  loss_ce_2: 0  loss_mask_2: 0.8219  loss_dice_2: 2.264  loss_ce_3: 0  loss_mask_3: 0.824  loss_dice_3: 2.254  loss_ce_4: 0  loss_mask_4: 0.8216  loss_dice_4: 2.257  loss_ce_5: 0  loss_mask_5: 0.8214  loss_dice_5: 2.254  loss_ce_6: 0  loss_mask_6: 0.8264  loss_dice_6: 2.253  loss_ce_7: 0  loss_mask_7: 0.8247  loss_dice_7: 2.255  loss_ce_8: 0  loss_mask_8: 0.8213  loss_dice_8: 2.259  time: 1.9656  data_time: 0.0269  lr: 6.9583e-05  max_mem: 6006M
[02/18 10:59:42] d2.utils.events INFO:  eta: 18:04:09  iter: 19919  total_loss: 31.58  loss_ce: 0  loss_mask: 0.8328  loss_dice: 2.234  loss_seg: 0.7943  loss_ce_0: 0  loss_mask_0: 0.8447  loss_dice_0: 2.298  loss_ce_1: 0  loss_mask_1: 0.8451  loss_dice_1: 2.239  loss_ce_2: 0  loss_mask_2: 0.843  loss_dice_2: 2.223  loss_ce_3: 0  loss_mask_3: 0.8418  loss_dice_3: 2.212  loss_ce_4: 0  loss_mask_4: 0.8407  loss_dice_4: 2.21  loss_ce_5: 0  loss_mask_5: 0.8392  loss_dice_5: 2.213  loss_ce_6: 0  loss_mask_6: 0.8338  loss_dice_6: 2.22  loss_ce_7: 0  loss_mask_7: 0.838  loss_dice_7: 2.222  loss_ce_8: 0  loss_mask_8: 0.8372  loss_dice_8: 2.224  time: 1.9652  data_time: 0.0333  lr: 6.9552e-05  max_mem: 6006M
[02/18 11:00:15] d2.utils.events INFO:  eta: 18:03:14  iter: 19939  total_loss: 31.63  loss_ce: 0  loss_mask: 0.8355  loss_dice: 2.186  loss_seg: 0.9201  loss_ce_0: 0  loss_mask_0: 0.8398  loss_dice_0: 2.251  loss_ce_1: 0  loss_mask_1: 0.8369  loss_dice_1: 2.191  loss_ce_2: 0  loss_mask_2: 0.8391  loss_dice_2: 2.178  loss_ce_3: 0  loss_mask_3: 0.8399  loss_dice_3: 2.17  loss_ce_4: 0  loss_mask_4: 0.8416  loss_dice_4: 2.168  loss_ce_5: 0  loss_mask_5: 0.844  loss_dice_5: 2.172  loss_ce_6: 0  loss_mask_6: 0.8444  loss_dice_6: 2.174  loss_ce_7: 0  loss_mask_7: 0.8419  loss_dice_7: 2.164  loss_ce_8: 0  loss_mask_8: 0.8419  loss_dice_8: 2.17  time: 1.9649  data_time: 0.0291  lr: 6.9521e-05  max_mem: 6006M
[02/18 11:00:50] d2.utils.events INFO:  eta: 18:02:41  iter: 19959  total_loss: 30.86  loss_ce: 0  loss_mask: 0.8003  loss_dice: 2.176  loss_seg: 0.788  loss_ce_0: 0  loss_mask_0: 0.8074  loss_dice_0: 2.229  loss_ce_1: 0  loss_mask_1: 0.8046  loss_dice_1: 2.187  loss_ce_2: 0  loss_mask_2: 0.8044  loss_dice_2: 2.169  loss_ce_3: 0  loss_mask_3: 0.8032  loss_dice_3: 2.16  loss_ce_4: 0  loss_mask_4: 0.8037  loss_dice_4: 2.161  loss_ce_5: 0  loss_mask_5: 0.8029  loss_dice_5: 2.163  loss_ce_6: 0  loss_mask_6: 0.8055  loss_dice_6: 2.16  loss_ce_7: 0  loss_mask_7: 0.8048  loss_dice_7: 2.161  loss_ce_8: 0  loss_mask_8: 0.8084  loss_dice_8: 2.156  time: 1.9647  data_time: 0.0264  lr: 6.9489e-05  max_mem: 6006M
[02/18 11:01:22] d2.utils.events INFO:  eta: 18:02:09  iter: 19979  total_loss: 31  loss_ce: 0  loss_mask: 0.7682  loss_dice: 2.13  loss_seg: 1.018  loss_ce_0: 0  loss_mask_0: 0.782  loss_dice_0: 2.23  loss_ce_1: 0  loss_mask_1: 0.7902  loss_dice_1: 2.147  loss_ce_2: 0  loss_mask_2: 0.7842  loss_dice_2: 2.126  loss_ce_3: 0  loss_mask_3: 0.7797  loss_dice_3: 2.114  loss_ce_4: 0  loss_mask_4: 0.7819  loss_dice_4: 2.115  loss_ce_5: 0  loss_mask_5: 0.7777  loss_dice_5: 2.117  loss_ce_6: 0  loss_mask_6: 0.7756  loss_dice_6: 2.115  loss_ce_7: 0  loss_mask_7: 0.7742  loss_dice_7: 2.113  loss_ce_8: 0  loss_mask_8: 0.7755  loss_dice_8: 2.118  time: 1.9643  data_time: 0.0318  lr: 6.9458e-05  max_mem: 6006M
[02/18 11:01:55] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0019999.pth
[02/18 11:01:56] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 11:01:56] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 11:01:56] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 11:02:11] mask2former INFO: Inference done 11/1093. Dataloading: 0.0044 s/iter. Inference: 0.2504 s/iter. Eval: 0.1080 s/iter. Total: 0.3628 s/iter. ETA=0:06:32
[02/18 11:02:16] mask2former INFO: Inference done 26/1093. Dataloading: 0.0050 s/iter. Inference: 0.2453 s/iter. Eval: 0.1062 s/iter. Total: 0.3566 s/iter. ETA=0:06:20
[02/18 11:02:21] mask2former INFO: Inference done 40/1093. Dataloading: 0.0054 s/iter. Inference: 0.2404 s/iter. Eval: 0.1141 s/iter. Total: 0.3600 s/iter. ETA=0:06:19
[02/18 11:02:27] mask2former INFO: Inference done 54/1093. Dataloading: 0.0053 s/iter. Inference: 0.2397 s/iter. Eval: 0.1177 s/iter. Total: 0.3628 s/iter. ETA=0:06:16
[02/18 11:02:32] mask2former INFO: Inference done 68/1093. Dataloading: 0.0055 s/iter. Inference: 0.2434 s/iter. Eval: 0.1165 s/iter. Total: 0.3654 s/iter. ETA=0:06:14
[02/18 11:02:37] mask2former INFO: Inference done 83/1093. Dataloading: 0.0054 s/iter. Inference: 0.2410 s/iter. Eval: 0.1144 s/iter. Total: 0.3608 s/iter. ETA=0:06:04
[02/18 11:02:42] mask2former INFO: Inference done 98/1093. Dataloading: 0.0055 s/iter. Inference: 0.2392 s/iter. Eval: 0.1150 s/iter. Total: 0.3598 s/iter. ETA=0:05:57
[02/18 11:02:47] mask2former INFO: Inference done 112/1093. Dataloading: 0.0054 s/iter. Inference: 0.2389 s/iter. Eval: 0.1159 s/iter. Total: 0.3603 s/iter. ETA=0:05:53
[02/18 11:02:53] mask2former INFO: Inference done 126/1093. Dataloading: 0.0055 s/iter. Inference: 0.2407 s/iter. Eval: 0.1152 s/iter. Total: 0.3616 s/iter. ETA=0:05:49
[02/18 11:02:58] mask2former INFO: Inference done 141/1093. Dataloading: 0.0056 s/iter. Inference: 0.2408 s/iter. Eval: 0.1144 s/iter. Total: 0.3609 s/iter. ETA=0:05:43
[02/18 11:03:03] mask2former INFO: Inference done 157/1093. Dataloading: 0.0055 s/iter. Inference: 0.2395 s/iter. Eval: 0.1138 s/iter. Total: 0.3588 s/iter. ETA=0:05:35
[02/18 11:03:09] mask2former INFO: Inference done 172/1093. Dataloading: 0.0054 s/iter. Inference: 0.2388 s/iter. Eval: 0.1140 s/iter. Total: 0.3583 s/iter. ETA=0:05:29
[02/18 11:03:14] mask2former INFO: Inference done 187/1093. Dataloading: 0.0054 s/iter. Inference: 0.2376 s/iter. Eval: 0.1143 s/iter. Total: 0.3574 s/iter. ETA=0:05:23
[02/18 11:03:19] mask2former INFO: Inference done 201/1093. Dataloading: 0.0054 s/iter. Inference: 0.2373 s/iter. Eval: 0.1150 s/iter. Total: 0.3577 s/iter. ETA=0:05:19
[02/18 11:03:24] mask2former INFO: Inference done 215/1093. Dataloading: 0.0053 s/iter. Inference: 0.2376 s/iter. Eval: 0.1155 s/iter. Total: 0.3585 s/iter. ETA=0:05:14
[02/18 11:03:29] mask2former INFO: Inference done 229/1093. Dataloading: 0.0053 s/iter. Inference: 0.2377 s/iter. Eval: 0.1160 s/iter. Total: 0.3590 s/iter. ETA=0:05:10
[02/18 11:03:35] mask2former INFO: Inference done 243/1093. Dataloading: 0.0052 s/iter. Inference: 0.2390 s/iter. Eval: 0.1156 s/iter. Total: 0.3600 s/iter. ETA=0:05:05
[02/18 11:03:40] mask2former INFO: Inference done 257/1093. Dataloading: 0.0054 s/iter. Inference: 0.2394 s/iter. Eval: 0.1150 s/iter. Total: 0.3599 s/iter. ETA=0:05:00
[02/18 11:03:45] mask2former INFO: Inference done 272/1093. Dataloading: 0.0053 s/iter. Inference: 0.2391 s/iter. Eval: 0.1153 s/iter. Total: 0.3599 s/iter. ETA=0:04:55
[02/18 11:03:50] mask2former INFO: Inference done 287/1093. Dataloading: 0.0054 s/iter. Inference: 0.2388 s/iter. Eval: 0.1149 s/iter. Total: 0.3592 s/iter. ETA=0:04:49
[02/18 11:03:55] mask2former INFO: Inference done 301/1093. Dataloading: 0.0053 s/iter. Inference: 0.2385 s/iter. Eval: 0.1153 s/iter. Total: 0.3592 s/iter. ETA=0:04:44
[02/18 11:04:00] mask2former INFO: Inference done 316/1093. Dataloading: 0.0053 s/iter. Inference: 0.2383 s/iter. Eval: 0.1149 s/iter. Total: 0.3586 s/iter. ETA=0:04:38
[02/18 11:04:06] mask2former INFO: Inference done 330/1093. Dataloading: 0.0053 s/iter. Inference: 0.2390 s/iter. Eval: 0.1150 s/iter. Total: 0.3594 s/iter. ETA=0:04:34
[02/18 11:04:11] mask2former INFO: Inference done 345/1093. Dataloading: 0.0053 s/iter. Inference: 0.2391 s/iter. Eval: 0.1151 s/iter. Total: 0.3595 s/iter. ETA=0:04:28
[02/18 11:04:16] mask2former INFO: Inference done 359/1093. Dataloading: 0.0054 s/iter. Inference: 0.2392 s/iter. Eval: 0.1155 s/iter. Total: 0.3601 s/iter. ETA=0:04:24
[02/18 11:04:22] mask2former INFO: Inference done 372/1093. Dataloading: 0.0054 s/iter. Inference: 0.2398 s/iter. Eval: 0.1164 s/iter. Total: 0.3617 s/iter. ETA=0:04:20
[02/18 11:04:27] mask2former INFO: Inference done 386/1093. Dataloading: 0.0054 s/iter. Inference: 0.2402 s/iter. Eval: 0.1160 s/iter. Total: 0.3617 s/iter. ETA=0:04:15
[02/18 11:04:32] mask2former INFO: Inference done 400/1093. Dataloading: 0.0053 s/iter. Inference: 0.2403 s/iter. Eval: 0.1158 s/iter. Total: 0.3616 s/iter. ETA=0:04:10
[02/18 11:04:37] mask2former INFO: Inference done 414/1093. Dataloading: 0.0053 s/iter. Inference: 0.2407 s/iter. Eval: 0.1160 s/iter. Total: 0.3621 s/iter. ETA=0:04:05
[02/18 11:04:42] mask2former INFO: Inference done 428/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1160 s/iter. Total: 0.3623 s/iter. ETA=0:04:00
[02/18 11:04:47] mask2former INFO: Inference done 442/1093. Dataloading: 0.0053 s/iter. Inference: 0.2413 s/iter. Eval: 0.1158 s/iter. Total: 0.3625 s/iter. ETA=0:03:56
[02/18 11:04:53] mask2former INFO: Inference done 456/1093. Dataloading: 0.0053 s/iter. Inference: 0.2414 s/iter. Eval: 0.1161 s/iter. Total: 0.3629 s/iter. ETA=0:03:51
[02/18 11:04:58] mask2former INFO: Inference done 471/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1161 s/iter. Total: 0.3626 s/iter. ETA=0:03:45
[02/18 11:05:03] mask2former INFO: Inference done 485/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1159 s/iter. Total: 0.3625 s/iter. ETA=0:03:40
[02/18 11:05:08] mask2former INFO: Inference done 499/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1163 s/iter. Total: 0.3628 s/iter. ETA=0:03:35
[02/18 11:05:13] mask2former INFO: Inference done 513/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1165 s/iter. Total: 0.3632 s/iter. ETA=0:03:30
[02/18 11:05:19] mask2former INFO: Inference done 528/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1164 s/iter. Total: 0.3627 s/iter. ETA=0:03:24
[02/18 11:05:24] mask2former INFO: Inference done 542/1093. Dataloading: 0.0053 s/iter. Inference: 0.2410 s/iter. Eval: 0.1163 s/iter. Total: 0.3626 s/iter. ETA=0:03:19
[02/18 11:05:29] mask2former INFO: Inference done 557/1093. Dataloading: 0.0053 s/iter. Inference: 0.2410 s/iter. Eval: 0.1160 s/iter. Total: 0.3624 s/iter. ETA=0:03:14
[02/18 11:05:34] mask2former INFO: Inference done 571/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1162 s/iter. Total: 0.3623 s/iter. ETA=0:03:09
[02/18 11:05:39] mask2former INFO: Inference done 585/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1161 s/iter. Total: 0.3624 s/iter. ETA=0:03:04
[02/18 11:05:44] mask2former INFO: Inference done 600/1093. Dataloading: 0.0053 s/iter. Inference: 0.2406 s/iter. Eval: 0.1161 s/iter. Total: 0.3621 s/iter. ETA=0:02:58
[02/18 11:05:50] mask2former INFO: Inference done 614/1093. Dataloading: 0.0053 s/iter. Inference: 0.2406 s/iter. Eval: 0.1164 s/iter. Total: 0.3623 s/iter. ETA=0:02:53
[02/18 11:05:55] mask2former INFO: Inference done 629/1093. Dataloading: 0.0053 s/iter. Inference: 0.2407 s/iter. Eval: 0.1162 s/iter. Total: 0.3623 s/iter. ETA=0:02:48
[02/18 11:06:00] mask2former INFO: Inference done 643/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1163 s/iter. Total: 0.3624 s/iter. ETA=0:02:43
[02/18 11:06:05] mask2former INFO: Inference done 657/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1163 s/iter. Total: 0.3627 s/iter. ETA=0:02:38
[02/18 11:06:11] mask2former INFO: Inference done 672/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1163 s/iter. Total: 0.3625 s/iter. ETA=0:02:32
[02/18 11:06:16] mask2former INFO: Inference done 686/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1162 s/iter. Total: 0.3627 s/iter. ETA=0:02:27
[02/18 11:06:21] mask2former INFO: Inference done 700/1093. Dataloading: 0.0052 s/iter. Inference: 0.2410 s/iter. Eval: 0.1163 s/iter. Total: 0.3626 s/iter. ETA=0:02:22
[02/18 11:06:26] mask2former INFO: Inference done 715/1093. Dataloading: 0.0052 s/iter. Inference: 0.2409 s/iter. Eval: 0.1163 s/iter. Total: 0.3625 s/iter. ETA=0:02:17
[02/18 11:06:32] mask2former INFO: Inference done 729/1093. Dataloading: 0.0052 s/iter. Inference: 0.2413 s/iter. Eval: 0.1162 s/iter. Total: 0.3628 s/iter. ETA=0:02:12
[02/18 11:06:37] mask2former INFO: Inference done 743/1093. Dataloading: 0.0052 s/iter. Inference: 0.2410 s/iter. Eval: 0.1164 s/iter. Total: 0.3628 s/iter. ETA=0:02:06
[02/18 11:06:42] mask2former INFO: Inference done 758/1093. Dataloading: 0.0052 s/iter. Inference: 0.2410 s/iter. Eval: 0.1160 s/iter. Total: 0.3624 s/iter. ETA=0:02:01
[02/18 11:06:47] mask2former INFO: Inference done 773/1093. Dataloading: 0.0052 s/iter. Inference: 0.2409 s/iter. Eval: 0.1160 s/iter. Total: 0.3622 s/iter. ETA=0:01:55
[02/18 11:06:52] mask2former INFO: Inference done 786/1093. Dataloading: 0.0052 s/iter. Inference: 0.2409 s/iter. Eval: 0.1163 s/iter. Total: 0.3626 s/iter. ETA=0:01:51
[02/18 11:06:57] mask2former INFO: Inference done 800/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1162 s/iter. Total: 0.3625 s/iter. ETA=0:01:46
[02/18 11:07:02] mask2former INFO: Inference done 814/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1161 s/iter. Total: 0.3625 s/iter. ETA=0:01:41
[02/18 11:07:07] mask2former INFO: Inference done 828/1093. Dataloading: 0.0052 s/iter. Inference: 0.2410 s/iter. Eval: 0.1163 s/iter. Total: 0.3628 s/iter. ETA=0:01:36
[02/18 11:07:13] mask2former INFO: Inference done 842/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1165 s/iter. Total: 0.3631 s/iter. ETA=0:01:31
[02/18 11:07:18] mask2former INFO: Inference done 856/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1165 s/iter. Total: 0.3630 s/iter. ETA=0:01:26
[02/18 11:07:23] mask2former INFO: Inference done 870/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1168 s/iter. Total: 0.3632 s/iter. ETA=0:01:21
[02/18 11:07:28] mask2former INFO: Inference done 884/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1167 s/iter. Total: 0.3633 s/iter. ETA=0:01:15
[02/18 11:07:33] mask2former INFO: Inference done 899/1093. Dataloading: 0.0053 s/iter. Inference: 0.2410 s/iter. Eval: 0.1166 s/iter. Total: 0.3631 s/iter. ETA=0:01:10
[02/18 11:07:39] mask2former INFO: Inference done 914/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1165 s/iter. Total: 0.3628 s/iter. ETA=0:01:04
[02/18 11:07:44] mask2former INFO: Inference done 929/1093. Dataloading: 0.0053 s/iter. Inference: 0.2409 s/iter. Eval: 0.1164 s/iter. Total: 0.3626 s/iter. ETA=0:00:59
[02/18 11:07:49] mask2former INFO: Inference done 943/1093. Dataloading: 0.0053 s/iter. Inference: 0.2408 s/iter. Eval: 0.1165 s/iter. Total: 0.3628 s/iter. ETA=0:00:54
[02/18 11:07:54] mask2former INFO: Inference done 956/1093. Dataloading: 0.0053 s/iter. Inference: 0.2410 s/iter. Eval: 0.1168 s/iter. Total: 0.3632 s/iter. ETA=0:00:49
[02/18 11:07:59] mask2former INFO: Inference done 969/1093. Dataloading: 0.0053 s/iter. Inference: 0.2414 s/iter. Eval: 0.1168 s/iter. Total: 0.3636 s/iter. ETA=0:00:45
[02/18 11:08:05] mask2former INFO: Inference done 983/1093. Dataloading: 0.0053 s/iter. Inference: 0.2414 s/iter. Eval: 0.1169 s/iter. Total: 0.3637 s/iter. ETA=0:00:40
[02/18 11:08:10] mask2former INFO: Inference done 997/1093. Dataloading: 0.0053 s/iter. Inference: 0.2413 s/iter. Eval: 0.1169 s/iter. Total: 0.3637 s/iter. ETA=0:00:34
[02/18 11:08:15] mask2former INFO: Inference done 1011/1093. Dataloading: 0.0053 s/iter. Inference: 0.2415 s/iter. Eval: 0.1170 s/iter. Total: 0.3640 s/iter. ETA=0:00:29
[02/18 11:08:20] mask2former INFO: Inference done 1025/1093. Dataloading: 0.0053 s/iter. Inference: 0.2415 s/iter. Eval: 0.1169 s/iter. Total: 0.3639 s/iter. ETA=0:00:24
[02/18 11:08:25] mask2former INFO: Inference done 1040/1093. Dataloading: 0.0053 s/iter. Inference: 0.2413 s/iter. Eval: 0.1167 s/iter. Total: 0.3635 s/iter. ETA=0:00:19
[02/18 11:08:30] mask2former INFO: Inference done 1053/1093. Dataloading: 0.0053 s/iter. Inference: 0.2416 s/iter. Eval: 0.1169 s/iter. Total: 0.3640 s/iter. ETA=0:00:14
[02/18 11:08:36] mask2former INFO: Inference done 1068/1093. Dataloading: 0.0053 s/iter. Inference: 0.2415 s/iter. Eval: 0.1168 s/iter. Total: 0.3638 s/iter. ETA=0:00:09
[02/18 11:08:41] mask2former INFO: Inference done 1083/1093. Dataloading: 0.0053 s/iter. Inference: 0.2413 s/iter. Eval: 0.1167 s/iter. Total: 0.3634 s/iter. ETA=0:00:03
[02/18 11:09:14] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.6365863285100346, 'error_1pix': 0.3444519385547274, 'error_3pix': 0.20300801807525873, 'mIoU': 20.74117393463286, 'fwIoU': 42.93416097863051, 'IoU-1': 94.72226196640172, 'IoU-2': 0.040268478608759, 'IoU-3': 0.05158620714931687, 'IoU-4': 0.015197768441055994, 'IoU-5': 0.008497743057055862, 'IoU-6': 0.00825536598789213, 'IoU-7': 0.006778125206242297, 'IoU-8': 0.006071166210317339, 'IoU-9': 1.1227798478998174, 'IoU-10': 9.796590805375661, 'IoU-11': 12.181840374275051, 'IoU-12': 37.76304883399491, 'IoU-13': 25.957137580104945, 'IoU-14': 22.199378311494318, 'IoU-15': 24.18163619141886, 'IoU-16': 23.018816760467814, 'IoU-17': 20.729992297644053, 'IoU-18': 22.713597112283818, 'IoU-19': 21.21092437386056, 'IoU-20': 22.38652796252227, 'IoU-21': 21.47566088084648, 'IoU-22': 25.69425334503294, 'IoU-23': 25.846950895764138, 'IoU-24': 27.41407756090596, 'IoU-25': 34.85885378899239, 'IoU-26': 34.04684536497065, 'IoU-27': 16.847212870761375, 'IoU-28': 11.568519261664408, 'IoU-29': 19.619843027212873, 'IoU-30': 30.713501047404634, 'IoU-31': 26.34432274543944, 'IoU-32': 37.43469731013139, 'IoU-33': 28.538841445972622, 'IoU-34': 24.039274265148062, 'IoU-35': 18.47016455612652, 'IoU-36': 29.678658085342967, 'IoU-37': 29.265141536170287, 'IoU-38': 20.72163153883972, 'IoU-39': 16.467419678855315, 'IoU-40': 17.57401001298852, 'IoU-41': 14.812034101109772, 'IoU-42': 11.812940398087948, 'IoU-43': 23.918009588717073, 'IoU-44': 29.124091001302205, 'IoU-45': 21.89448231159699, 'IoU-46': 19.455524341043233, 'IoU-47': 19.068543456625477, 'IoU-48': 20.749657172919623, 'mACC': 34.29048141698794, 'pACC': 52.5203535626263, 'ACC-1': 97.37480003695369, 'ACC-2': 0.04026854564971276, 'ACC-3': 0.05952487939075282, 'ACC-4': 0.015796255665507446, 'ACC-5': 0.00867539892130972, 'ACC-6': 0.008399472315503944, 'ACC-7': 0.00691312566061283, 'ACC-8': 0.006172069902394887, 'ACC-9': 78.66120669200109, 'ACC-10': 14.95006936046098, 'ACC-11': 13.898833785922966, 'ACC-12': 73.42349886328567, 'ACC-13': 35.41608223899002, 'ACC-14': 29.964157268791876, 'ACC-15': 41.351882142927444, 'ACC-16': 40.53718113168349, 'ACC-17': 34.3869886385397, 'ACC-18': 35.26480792072431, 'ACC-19': 35.89450211035081, 'ACC-20': 38.48270321342612, 'ACC-21': 35.420225942726915, 'ACC-22': 39.55094442101358, 'ACC-23': 41.9486753213362, 'ACC-24': 44.67010959962028, 'ACC-25': 55.47973573167035, 'ACC-26': 68.41792385458794, 'ACC-27': 32.45368095295761, 'ACC-28': 18.325310895962375, 'ACC-29': 28.21158369837051, 'ACC-30': 42.864496995467576, 'ACC-31': 33.319301466911135, 'ACC-32': 63.933821998877086, 'ACC-33': 41.55111724609631, 'ACC-34': 31.00973849862077, 'ACC-35': 25.829084597622774, 'ACC-36': 54.075814994691385, 'ACC-37': 47.975276174208894, 'ACC-38': 30.576228077145405, 'ACC-39': 25.521998876135477, 'ACC-40': 29.44064665751831, 'ACC-41': 25.50905371256857, 'ACC-42': 20.03049607540949, 'ACC-43': 49.116714260427344, 'ACC-44': 55.538310969263016, 'ACC-45': 34.54511542282043, 'ACC-46': 31.344685957755587, 'ACC-47': 33.52967977194982, 'ACC-48': 36.0008726921221})])
[02/18 11:09:14] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 11:09:14] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 11:09:14] d2.evaluation.testing INFO: copypaste: 2.6366,0.3445,0.2030,20.7412,42.9342,34.2905,52.5204
[02/18 11:09:14] d2.utils.events INFO:  eta: 18:00:44  iter: 19999  total_loss: 31.96  loss_ce: 0  loss_mask: 0.8107  loss_dice: 2.175  loss_seg: 1.08  loss_ce_0: 0  loss_mask_0: 0.8227  loss_dice_0: 2.261  loss_ce_1: 0  loss_mask_1: 0.8137  loss_dice_1: 2.2  loss_ce_2: 0  loss_mask_2: 0.8112  loss_dice_2: 2.183  loss_ce_3: 0  loss_mask_3: 0.8105  loss_dice_3: 2.177  loss_ce_4: 0  loss_mask_4: 0.8124  loss_dice_4: 2.169  loss_ce_5: 0  loss_mask_5: 0.8111  loss_dice_5: 2.17  loss_ce_6: 0  loss_mask_6: 0.813  loss_dice_6: 2.17  loss_ce_7: 0  loss_mask_7: 0.815  loss_dice_7: 2.17  loss_ce_8: 0  loss_mask_8: 0.8109  loss_dice_8: 2.171  time: 1.9640  data_time: 0.0244  lr: 6.9427e-05  max_mem: 6006M
[02/18 11:09:46] d2.utils.events INFO:  eta: 17:57:10  iter: 20019  total_loss: 30.66  loss_ce: 0  loss_mask: 0.7544  loss_dice: 2.142  loss_seg: 0.9605  loss_ce_0: 0  loss_mask_0: 0.7528  loss_dice_0: 2.203  loss_ce_1: 0  loss_mask_1: 0.7575  loss_dice_1: 2.142  loss_ce_2: 0  loss_mask_2: 0.7666  loss_dice_2: 2.131  loss_ce_3: 0  loss_mask_3: 0.7647  loss_dice_3: 2.132  loss_ce_4: 0  loss_mask_4: 0.7636  loss_dice_4: 2.129  loss_ce_5: 0  loss_mask_5: 0.7618  loss_dice_5: 2.132  loss_ce_6: 0  loss_mask_6: 0.7631  loss_dice_6: 2.129  loss_ce_7: 0  loss_mask_7: 0.7608  loss_dice_7: 2.135  loss_ce_8: 0  loss_mask_8: 0.7618  loss_dice_8: 2.134  time: 1.9636  data_time: 0.0312  lr: 6.9396e-05  max_mem: 6006M
[02/18 11:10:17] d2.utils.events INFO:  eta: 17:56:13  iter: 20039  total_loss: 29.67  loss_ce: 0  loss_mask: 0.7589  loss_dice: 2.138  loss_seg: 0.6807  loss_ce_0: 0  loss_mask_0: 0.7624  loss_dice_0: 2.199  loss_ce_1: 0  loss_mask_1: 0.7694  loss_dice_1: 2.153  loss_ce_2: 0  loss_mask_2: 0.77  loss_dice_2: 2.136  loss_ce_3: 0  loss_mask_3: 0.769  loss_dice_3: 2.129  loss_ce_4: 0  loss_mask_4: 0.7669  loss_dice_4: 2.122  loss_ce_5: 0  loss_mask_5: 0.7677  loss_dice_5: 2.123  loss_ce_6: 0  loss_mask_6: 0.7691  loss_dice_6: 2.123  loss_ce_7: 0  loss_mask_7: 0.7693  loss_dice_7: 2.13  loss_ce_8: 0  loss_mask_8: 0.7682  loss_dice_8: 2.128  time: 1.9632  data_time: 0.0277  lr: 6.9364e-05  max_mem: 6006M
[02/18 11:10:48] d2.utils.events INFO:  eta: 17:55:41  iter: 20059  total_loss: 31.7  loss_ce: 0  loss_mask: 0.773  loss_dice: 2.189  loss_seg: 0.8166  loss_ce_0: 0  loss_mask_0: 0.7878  loss_dice_0: 2.248  loss_ce_1: 0  loss_mask_1: 0.7746  loss_dice_1: 2.198  loss_ce_2: 0  loss_mask_2: 0.7771  loss_dice_2: 2.179  loss_ce_3: 0  loss_mask_3: 0.7802  loss_dice_3: 2.168  loss_ce_4: 0  loss_mask_4: 0.7753  loss_dice_4: 2.164  loss_ce_5: 0  loss_mask_5: 0.7729  loss_dice_5: 2.166  loss_ce_6: 0  loss_mask_6: 0.7705  loss_dice_6: 2.166  loss_ce_7: 0  loss_mask_7: 0.7757  loss_dice_7: 2.168  loss_ce_8: 0  loss_mask_8: 0.7762  loss_dice_8: 2.167  time: 1.9628  data_time: 0.0290  lr: 6.9333e-05  max_mem: 6006M
[02/18 11:11:22] d2.utils.events INFO:  eta: 17:54:38  iter: 20079  total_loss: 30.49  loss_ce: 0  loss_mask: 0.8249  loss_dice: 2.189  loss_seg: 0.7306  loss_ce_0: 0  loss_mask_0: 0.8384  loss_dice_0: 2.26  loss_ce_1: 0  loss_mask_1: 0.832  loss_dice_1: 2.209  loss_ce_2: 0  loss_mask_2: 0.8376  loss_dice_2: 2.191  loss_ce_3: 0  loss_mask_3: 0.8371  loss_dice_3: 2.184  loss_ce_4: 0  loss_mask_4: 0.838  loss_dice_4: 2.184  loss_ce_5: 0  loss_mask_5: 0.8394  loss_dice_5: 2.182  loss_ce_6: 0  loss_mask_6: 0.8398  loss_dice_6: 2.185  loss_ce_7: 0  loss_mask_7: 0.8341  loss_dice_7: 2.182  loss_ce_8: 0  loss_mask_8: 0.8362  loss_dice_8: 2.19  time: 1.9625  data_time: 0.0411  lr: 6.9302e-05  max_mem: 6006M
[02/18 11:11:53] d2.utils.events INFO:  eta: 17:52:55  iter: 20099  total_loss: 29.55  loss_ce: 0  loss_mask: 0.7852  loss_dice: 2.031  loss_seg: 0.7748  loss_ce_0: 0  loss_mask_0: 0.793  loss_dice_0: 2.105  loss_ce_1: 0  loss_mask_1: 0.7943  loss_dice_1: 2.043  loss_ce_2: 0  loss_mask_2: 0.7941  loss_dice_2: 2.025  loss_ce_3: 0  loss_mask_3: 0.7877  loss_dice_3: 2.015  loss_ce_4: 0  loss_mask_4: 0.7888  loss_dice_4: 2.017  loss_ce_5: 0  loss_mask_5: 0.7862  loss_dice_5: 2.024  loss_ce_6: 0  loss_mask_6: 0.7845  loss_dice_6: 2.023  loss_ce_7: 0  loss_mask_7: 0.7869  loss_dice_7: 2.027  loss_ce_8: 0  loss_mask_8: 0.7872  loss_dice_8: 2.021  time: 1.9621  data_time: 0.0406  lr: 6.9271e-05  max_mem: 6006M
[02/18 11:12:23] d2.utils.events INFO:  eta: 17:51:08  iter: 20119  total_loss: 30.79  loss_ce: 0  loss_mask: 0.7739  loss_dice: 2.128  loss_seg: 1.105  loss_ce_0: 0  loss_mask_0: 0.7758  loss_dice_0: 2.209  loss_ce_1: 0  loss_mask_1: 0.7687  loss_dice_1: 2.148  loss_ce_2: 0  loss_mask_2: 0.7761  loss_dice_2: 2.128  loss_ce_3: 0  loss_mask_3: 0.7713  loss_dice_3: 2.113  loss_ce_4: 0  loss_mask_4: 0.7735  loss_dice_4: 2.115  loss_ce_5: 0  loss_mask_5: 0.7764  loss_dice_5: 2.116  loss_ce_6: 0  loss_mask_6: 0.7764  loss_dice_6: 2.11  loss_ce_7: 0  loss_mask_7: 0.7794  loss_dice_7: 2.114  loss_ce_8: 0  loss_mask_8: 0.7785  loss_dice_8: 2.114  time: 1.9616  data_time: 0.0360  lr: 6.9239e-05  max_mem: 6006M
[02/18 11:12:34] d2.utils.events INFO:  eta: 17:40:57  iter: 20139  total_loss: 29.97  loss_ce: 0  loss_mask: 0.7507  loss_dice: 2.061  loss_seg: 0.925  loss_ce_0: 0  loss_mask_0: 0.7408  loss_dice_0: 2.133  loss_ce_1: 0  loss_mask_1: 0.7505  loss_dice_1: 2.08  loss_ce_2: 0  loss_mask_2: 0.7508  loss_dice_2: 2.056  loss_ce_3: 0  loss_mask_3: 0.7546  loss_dice_3: 2.047  loss_ce_4: 0  loss_mask_4: 0.7532  loss_dice_4: 2.044  loss_ce_5: 0  loss_mask_5: 0.7523  loss_dice_5: 2.049  loss_ce_6: 0  loss_mask_6: 0.7529  loss_dice_6: 2.052  loss_ce_7: 0  loss_mask_7: 0.7494  loss_dice_7: 2.046  loss_ce_8: 0  loss_mask_8: 0.7487  loss_dice_8: 2.048  time: 1.9602  data_time: 0.0235  lr: 6.9208e-05  max_mem: 6006M
[02/18 11:12:46] d2.utils.events INFO:  eta: 17:35:18  iter: 20159  total_loss: 29.78  loss_ce: 0  loss_mask: 0.7991  loss_dice: 2.133  loss_seg: 0.6572  loss_ce_0: 0  loss_mask_0: 0.805  loss_dice_0: 2.21  loss_ce_1: 0  loss_mask_1: 0.8079  loss_dice_1: 2.139  loss_ce_2: 0  loss_mask_2: 0.8048  loss_dice_2: 2.114  loss_ce_3: 0  loss_mask_3: 0.8084  loss_dice_3: 2.111  loss_ce_4: 0  loss_mask_4: 0.8104  loss_dice_4: 2.115  loss_ce_5: 0  loss_mask_5: 0.8092  loss_dice_5: 2.113  loss_ce_6: 0  loss_mask_6: 0.8074  loss_dice_6: 2.117  loss_ce_7: 0  loss_mask_7: 0.8096  loss_dice_7: 2.126  loss_ce_8: 0  loss_mask_8: 0.8086  loss_dice_8: 2.125  time: 1.9589  data_time: 0.0269  lr: 6.9177e-05  max_mem: 6006M
[02/18 11:12:58] d2.utils.events INFO:  eta: 17:28:32  iter: 20179  total_loss: 29.98  loss_ce: 0  loss_mask: 0.7822  loss_dice: 2.139  loss_seg: 0.7043  loss_ce_0: 0  loss_mask_0: 0.7854  loss_dice_0: 2.218  loss_ce_1: 0  loss_mask_1: 0.7796  loss_dice_1: 2.158  loss_ce_2: 0  loss_mask_2: 0.7775  loss_dice_2: 2.149  loss_ce_3: 0  loss_mask_3: 0.7767  loss_dice_3: 2.132  loss_ce_4: 0  loss_mask_4: 0.7804  loss_dice_4: 2.134  loss_ce_5: 0  loss_mask_5: 0.7812  loss_dice_5: 2.135  loss_ce_6: 0  loss_mask_6: 0.784  loss_dice_6: 2.124  loss_ce_7: 0  loss_mask_7: 0.785  loss_dice_7: 2.127  loss_ce_8: 0  loss_mask_8: 0.7821  loss_dice_8: 2.133  time: 1.9575  data_time: 0.0222  lr: 6.9146e-05  max_mem: 6006M
[02/18 11:13:10] d2.utils.events INFO:  eta: 17:23:00  iter: 20199  total_loss: 30.88  loss_ce: 0  loss_mask: 0.7922  loss_dice: 2.143  loss_seg: 0.8144  loss_ce_0: 0  loss_mask_0: 0.7875  loss_dice_0: 2.242  loss_ce_1: 0  loss_mask_1: 0.7899  loss_dice_1: 2.164  loss_ce_2: 0  loss_mask_2: 0.7882  loss_dice_2: 2.149  loss_ce_3: 0  loss_mask_3: 0.792  loss_dice_3: 2.138  loss_ce_4: 0  loss_mask_4: 0.7914  loss_dice_4: 2.14  loss_ce_5: 0  loss_mask_5: 0.789  loss_dice_5: 2.141  loss_ce_6: 0  loss_mask_6: 0.7937  loss_dice_6: 2.139  loss_ce_7: 0  loss_mask_7: 0.7926  loss_dice_7: 2.136  loss_ce_8: 0  loss_mask_8: 0.7935  loss_dice_8: 2.137  time: 1.9562  data_time: 0.0233  lr: 6.9114e-05  max_mem: 6006M
[02/18 11:13:23] d2.utils.events INFO:  eta: 17:19:16  iter: 20219  total_loss: 30.84  loss_ce: 0  loss_mask: 0.8049  loss_dice: 2.176  loss_seg: 0.8348  loss_ce_0: 0  loss_mask_0: 0.813  loss_dice_0: 2.252  loss_ce_1: 0  loss_mask_1: 0.8091  loss_dice_1: 2.19  loss_ce_2: 0  loss_mask_2: 0.8062  loss_dice_2: 2.174  loss_ce_3: 0  loss_mask_3: 0.8079  loss_dice_3: 2.167  loss_ce_4: 0  loss_mask_4: 0.8083  loss_dice_4: 2.167  loss_ce_5: 0  loss_mask_5: 0.8051  loss_dice_5: 2.169  loss_ce_6: 0  loss_mask_6: 0.8068  loss_dice_6: 2.169  loss_ce_7: 0  loss_mask_7: 0.806  loss_dice_7: 2.164  loss_ce_8: 0  loss_mask_8: 0.8078  loss_dice_8: 2.165  time: 1.9548  data_time: 0.0217  lr: 6.9083e-05  max_mem: 6006M
[02/18 11:13:35] d2.utils.events INFO:  eta: 17:12:54  iter: 20239  total_loss: 29.94  loss_ce: 0  loss_mask: 0.7823  loss_dice: 2.081  loss_seg: 0.7633  loss_ce_0: 0  loss_mask_0: 0.7792  loss_dice_0: 2.153  loss_ce_1: 0  loss_mask_1: 0.7712  loss_dice_1: 2.079  loss_ce_2: 0  loss_mask_2: 0.7745  loss_dice_2: 2.073  loss_ce_3: 0  loss_mask_3: 0.7808  loss_dice_3: 2.07  loss_ce_4: 0  loss_mask_4: 0.7818  loss_dice_4: 2.061  loss_ce_5: 0  loss_mask_5: 0.7839  loss_dice_5: 2.062  loss_ce_6: 0  loss_mask_6: 0.7867  loss_dice_6: 2.059  loss_ce_7: 0  loss_mask_7: 0.7832  loss_dice_7: 2.055  loss_ce_8: 0  loss_mask_8: 0.7813  loss_dice_8: 2.066  time: 1.9535  data_time: 0.0299  lr: 6.9052e-05  max_mem: 6006M
[02/18 11:13:48] d2.utils.events INFO:  eta: 17:02:20  iter: 20259  total_loss: 32.62  loss_ce: 0  loss_mask: 0.8504  loss_dice: 2.296  loss_seg: 0.9014  loss_ce_0: 0  loss_mask_0: 0.8452  loss_dice_0: 2.329  loss_ce_1: 0  loss_mask_1: 0.8487  loss_dice_1: 2.31  loss_ce_2: 0  loss_mask_2: 0.8515  loss_dice_2: 2.295  loss_ce_3: 0  loss_mask_3: 0.8525  loss_dice_3: 2.289  loss_ce_4: 0  loss_mask_4: 0.8539  loss_dice_4: 2.291  loss_ce_5: 0  loss_mask_5: 0.855  loss_dice_5: 2.289  loss_ce_6: 0  loss_mask_6: 0.8544  loss_dice_6: 2.284  loss_ce_7: 0  loss_mask_7: 0.852  loss_dice_7: 2.286  loss_ce_8: 0  loss_mask_8: 0.855  loss_dice_8: 2.285  time: 1.9522  data_time: 0.0182  lr: 6.9021e-05  max_mem: 6006M
[02/18 11:14:02] d2.utils.events INFO:  eta: 16:55:46  iter: 20279  total_loss: 31.82  loss_ce: 0  loss_mask: 0.8201  loss_dice: 2.208  loss_seg: 0.8329  loss_ce_0: 0  loss_mask_0: 0.8328  loss_dice_0: 2.269  loss_ce_1: 0  loss_mask_1: 0.8239  loss_dice_1: 2.214  loss_ce_2: 0  loss_mask_2: 0.8217  loss_dice_2: 2.206  loss_ce_3: 0  loss_mask_3: 0.8193  loss_dice_3: 2.193  loss_ce_4: 0  loss_mask_4: 0.8228  loss_dice_4: 2.201  loss_ce_5: 0  loss_mask_5: 0.824  loss_dice_5: 2.202  loss_ce_6: 0  loss_mask_6: 0.8204  loss_dice_6: 2.198  loss_ce_7: 0  loss_mask_7: 0.8184  loss_dice_7: 2.206  loss_ce_8: 0  loss_mask_8: 0.8196  loss_dice_8: 2.203  time: 1.9510  data_time: 0.0398  lr: 6.8989e-05  max_mem: 6006M
[02/18 11:14:15] d2.utils.events INFO:  eta: 16:49:16  iter: 20299  total_loss: 31.7  loss_ce: 0  loss_mask: 0.8204  loss_dice: 2.25  loss_seg: 0.5973  loss_ce_0: 0  loss_mask_0: 0.8098  loss_dice_0: 2.325  loss_ce_1: 0  loss_mask_1: 0.8147  loss_dice_1: 2.25  loss_ce_2: 0  loss_mask_2: 0.8191  loss_dice_2: 2.234  loss_ce_3: 0  loss_mask_3: 0.8206  loss_dice_3: 2.232  loss_ce_4: 0  loss_mask_4: 0.8178  loss_dice_4: 2.234  loss_ce_5: 0  loss_mask_5: 0.8177  loss_dice_5: 2.229  loss_ce_6: 0  loss_mask_6: 0.8216  loss_dice_6: 2.233  loss_ce_7: 0  loss_mask_7: 0.8208  loss_dice_7: 2.231  loss_ce_8: 0  loss_mask_8: 0.8231  loss_dice_8: 2.227  time: 1.9497  data_time: 0.0308  lr: 6.8958e-05  max_mem: 6006M
[02/18 11:14:29] d2.utils.events INFO:  eta: 16:46:05  iter: 20319  total_loss: 31.01  loss_ce: 0  loss_mask: 0.8269  loss_dice: 2.151  loss_seg: 0.6514  loss_ce_0: 0  loss_mask_0: 0.8399  loss_dice_0: 2.204  loss_ce_1: 0  loss_mask_1: 0.831  loss_dice_1: 2.168  loss_ce_2: 0  loss_mask_2: 0.8313  loss_dice_2: 2.153  loss_ce_3: 0  loss_mask_3: 0.8336  loss_dice_3: 2.142  loss_ce_4: 0  loss_mask_4: 0.8321  loss_dice_4: 2.144  loss_ce_5: 0  loss_mask_5: 0.833  loss_dice_5: 2.141  loss_ce_6: 0  loss_mask_6: 0.8315  loss_dice_6: 2.146  loss_ce_7: 0  loss_mask_7: 0.8336  loss_dice_7: 2.146  loss_ce_8: 0  loss_mask_8: 0.8337  loss_dice_8: 2.149  time: 1.9485  data_time: 0.0296  lr: 6.8927e-05  max_mem: 6006M
[02/18 11:14:42] d2.utils.events INFO:  eta: 16:39:20  iter: 20339  total_loss: 30.38  loss_ce: 0  loss_mask: 0.7799  loss_dice: 2.192  loss_seg: 0.7189  loss_ce_0: 0  loss_mask_0: 0.7953  loss_dice_0: 2.244  loss_ce_1: 0  loss_mask_1: 0.7771  loss_dice_1: 2.19  loss_ce_2: 0  loss_mask_2: 0.7798  loss_dice_2: 2.182  loss_ce_3: 0  loss_mask_3: 0.7847  loss_dice_3: 2.173  loss_ce_4: 0  loss_mask_4: 0.7821  loss_dice_4: 2.177  loss_ce_5: 0  loss_mask_5: 0.7813  loss_dice_5: 2.174  loss_ce_6: 0  loss_mask_6: 0.783  loss_dice_6: 2.175  loss_ce_7: 0  loss_mask_7: 0.7796  loss_dice_7: 2.177  loss_ce_8: 0  loss_mask_8: 0.7785  loss_dice_8: 2.174  time: 1.9472  data_time: 0.0327  lr: 6.8896e-05  max_mem: 6006M
[02/18 11:14:56] d2.utils.events INFO:  eta: 16:36:13  iter: 20359  total_loss: 28.68  loss_ce: 0  loss_mask: 0.7784  loss_dice: 2.07  loss_seg: 0.8986  loss_ce_0: 0  loss_mask_0: 0.7795  loss_dice_0: 2.144  loss_ce_1: 0  loss_mask_1: 0.7797  loss_dice_1: 2.067  loss_ce_2: 0  loss_mask_2: 0.7819  loss_dice_2: 2.061  loss_ce_3: 0  loss_mask_3: 0.78  loss_dice_3: 2.053  loss_ce_4: 0  loss_mask_4: 0.7782  loss_dice_4: 2.049  loss_ce_5: 0  loss_mask_5: 0.7807  loss_dice_5: 2.049  loss_ce_6: 0  loss_mask_6: 0.7822  loss_dice_6: 2.051  loss_ce_7: 0  loss_mask_7: 0.7831  loss_dice_7: 2.048  loss_ce_8: 0  loss_mask_8: 0.786  loss_dice_8: 2.044  time: 1.9460  data_time: 0.0360  lr: 6.8864e-05  max_mem: 6006M
[02/18 11:15:10] d2.utils.events INFO:  eta: 16:24:46  iter: 20379  total_loss: 30.29  loss_ce: 0  loss_mask: 0.7597  loss_dice: 2.105  loss_seg: 0.6793  loss_ce_0: 0  loss_mask_0: 0.7681  loss_dice_0: 2.19  loss_ce_1: 0  loss_mask_1: 0.7677  loss_dice_1: 2.114  loss_ce_2: 0  loss_mask_2: 0.765  loss_dice_2: 2.098  loss_ce_3: 0  loss_mask_3: 0.7637  loss_dice_3: 2.084  loss_ce_4: 0  loss_mask_4: 0.7639  loss_dice_4: 2.082  loss_ce_5: 0  loss_mask_5: 0.7647  loss_dice_5: 2.084  loss_ce_6: 0  loss_mask_6: 0.7639  loss_dice_6: 2.084  loss_ce_7: 0  loss_mask_7: 0.7625  loss_dice_7: 2.079  loss_ce_8: 0  loss_mask_8: 0.7618  loss_dice_8: 2.079  time: 1.9447  data_time: 0.0331  lr: 6.8833e-05  max_mem: 6006M
[02/18 11:15:26] d2.utils.events INFO:  eta: 16:14:33  iter: 20399  total_loss: 31.21  loss_ce: 0  loss_mask: 0.7829  loss_dice: 2.197  loss_seg: 0.7357  loss_ce_0: 0  loss_mask_0: 0.8129  loss_dice_0: 2.272  loss_ce_1: 0  loss_mask_1: 0.7873  loss_dice_1: 2.198  loss_ce_2: 0  loss_mask_2: 0.7797  loss_dice_2: 2.185  loss_ce_3: 0  loss_mask_3: 0.7877  loss_dice_3: 2.172  loss_ce_4: 0  loss_mask_4: 0.7841  loss_dice_4: 2.175  loss_ce_5: 0  loss_mask_5: 0.7816  loss_dice_5: 2.177  loss_ce_6: 0  loss_mask_6: 0.7852  loss_dice_6: 2.172  loss_ce_7: 0  loss_mask_7: 0.784  loss_dice_7: 2.179  loss_ce_8: 0  loss_mask_8: 0.7816  loss_dice_8: 2.18  time: 1.9436  data_time: 0.0346  lr: 6.8802e-05  max_mem: 6006M
[02/18 11:15:54] d2.utils.events INFO:  eta: 16:07:13  iter: 20419  total_loss: 30.61  loss_ce: 0  loss_mask: 0.8158  loss_dice: 2.189  loss_seg: 0.8073  loss_ce_0: 0  loss_mask_0: 0.8093  loss_dice_0: 2.246  loss_ce_1: 0  loss_mask_1: 0.8222  loss_dice_1: 2.184  loss_ce_2: 0  loss_mask_2: 0.8242  loss_dice_2: 2.177  loss_ce_3: 0  loss_mask_3: 0.8218  loss_dice_3: 2.163  loss_ce_4: 0  loss_mask_4: 0.822  loss_dice_4: 2.164  loss_ce_5: 0  loss_mask_5: 0.8254  loss_dice_5: 2.167  loss_ce_6: 0  loss_mask_6: 0.8305  loss_dice_6: 2.163  loss_ce_7: 0  loss_mask_7: 0.8252  loss_dice_7: 2.162  loss_ce_8: 0  loss_mask_8: 0.8264  loss_dice_8: 2.163  time: 1.9431  data_time: 0.0556  lr: 6.877e-05  max_mem: 6006M
[02/18 11:16:17] d2.utils.events INFO:  eta: 15:58:53  iter: 20439  total_loss: 30.49  loss_ce: 0  loss_mask: 0.8102  loss_dice: 2.148  loss_seg: 0.499  loss_ce_0: 0  loss_mask_0: 0.8057  loss_dice_0: 2.191  loss_ce_1: 0  loss_mask_1: 0.8045  loss_dice_1: 2.153  loss_ce_2: 0  loss_mask_2: 0.8127  loss_dice_2: 2.147  loss_ce_3: 0  loss_mask_3: 0.8149  loss_dice_3: 2.132  loss_ce_4: 0  loss_mask_4: 0.8223  loss_dice_4: 2.13  loss_ce_5: 0  loss_mask_5: 0.8189  loss_dice_5: 2.129  loss_ce_6: 0  loss_mask_6: 0.8159  loss_dice_6: 2.134  loss_ce_7: 0  loss_mask_7: 0.8188  loss_dice_7: 2.134  loss_ce_8: 0  loss_mask_8: 0.8176  loss_dice_8: 2.136  time: 1.9423  data_time: 0.0428  lr: 6.8739e-05  max_mem: 6006M
[02/18 11:16:51] d2.utils.events INFO:  eta: 15:59:47  iter: 20459  total_loss: 32.17  loss_ce: 0  loss_mask: 0.8222  loss_dice: 2.197  loss_seg: 0.7574  loss_ce_0: 0  loss_mask_0: 0.8339  loss_dice_0: 2.25  loss_ce_1: 0  loss_mask_1: 0.8231  loss_dice_1: 2.213  loss_ce_2: 0  loss_mask_2: 0.8249  loss_dice_2: 2.199  loss_ce_3: 0  loss_mask_3: 0.8242  loss_dice_3: 2.182  loss_ce_4: 0  loss_mask_4: 0.8234  loss_dice_4: 2.184  loss_ce_5: 0  loss_mask_5: 0.823  loss_dice_5: 2.188  loss_ce_6: 0  loss_mask_6: 0.8234  loss_dice_6: 2.184  loss_ce_7: 0  loss_mask_7: 0.8208  loss_dice_7: 2.176  loss_ce_8: 0  loss_mask_8: 0.8232  loss_dice_8: 2.187  time: 1.9420  data_time: 0.0401  lr: 6.8708e-05  max_mem: 6006M
[02/18 11:17:23] d2.utils.events INFO:  eta: 15:59:18  iter: 20479  total_loss: 31.12  loss_ce: 0  loss_mask: 0.786  loss_dice: 2.227  loss_seg: 0.9139  loss_ce_0: 0  loss_mask_0: 0.797  loss_dice_0: 2.308  loss_ce_1: 0  loss_mask_1: 0.7803  loss_dice_1: 2.249  loss_ce_2: 0  loss_mask_2: 0.784  loss_dice_2: 2.232  loss_ce_3: 0  loss_mask_3: 0.7886  loss_dice_3: 2.218  loss_ce_4: 0  loss_mask_4: 0.7896  loss_dice_4: 2.212  loss_ce_5: 0  loss_mask_5: 0.7902  loss_dice_5: 2.217  loss_ce_6: 0  loss_mask_6: 0.7978  loss_dice_6: 2.215  loss_ce_7: 0  loss_mask_7: 0.8012  loss_dice_7: 2.206  loss_ce_8: 0  loss_mask_8: 0.795  loss_dice_8: 2.204  time: 1.9417  data_time: 0.0470  lr: 6.8677e-05  max_mem: 6006M
[02/18 11:17:56] d2.utils.events INFO:  eta: 15:58:49  iter: 20499  total_loss: 29.48  loss_ce: 0  loss_mask: 0.8047  loss_dice: 2.062  loss_seg: 0.7031  loss_ce_0: 0  loss_mask_0: 0.8279  loss_dice_0: 2.13  loss_ce_1: 0  loss_mask_1: 0.8232  loss_dice_1: 2.05  loss_ce_2: 0  loss_mask_2: 0.8218  loss_dice_2: 2.039  loss_ce_3: 0  loss_mask_3: 0.818  loss_dice_3: 2.039  loss_ce_4: 0  loss_mask_4: 0.8213  loss_dice_4: 2.039  loss_ce_5: 0  loss_mask_5: 0.8172  loss_dice_5: 2.038  loss_ce_6: 0  loss_mask_6: 0.8201  loss_dice_6: 2.037  loss_ce_7: 0  loss_mask_7: 0.8204  loss_dice_7: 2.044  loss_ce_8: 0  loss_mask_8: 0.821  loss_dice_8: 2.043  time: 1.9415  data_time: 0.0309  lr: 6.8645e-05  max_mem: 6006M
[02/18 11:18:28] d2.utils.events INFO:  eta: 15:55:22  iter: 20519  total_loss: 32.85  loss_ce: 0  loss_mask: 0.8221  loss_dice: 2.294  loss_seg: 0.8729  loss_ce_0: 0  loss_mask_0: 0.8498  loss_dice_0: 2.368  loss_ce_1: 0  loss_mask_1: 0.8183  loss_dice_1: 2.307  loss_ce_2: 0  loss_mask_2: 0.8264  loss_dice_2: 2.292  loss_ce_3: 0  loss_mask_3: 0.8245  loss_dice_3: 2.268  loss_ce_4: 0  loss_mask_4: 0.8256  loss_dice_4: 2.265  loss_ce_5: 0  loss_mask_5: 0.8286  loss_dice_5: 2.265  loss_ce_6: 0  loss_mask_6: 0.8312  loss_dice_6: 2.259  loss_ce_7: 0  loss_mask_7: 0.8317  loss_dice_7: 2.26  loss_ce_8: 0  loss_mask_8: 0.8276  loss_dice_8: 2.259  time: 1.9411  data_time: 0.0378  lr: 6.8614e-05  max_mem: 6006M
[02/18 11:19:01] d2.utils.events INFO:  eta: 15:55:48  iter: 20539  total_loss: 31.05  loss_ce: 0  loss_mask: 0.7968  loss_dice: 2.222  loss_seg: 0.5406  loss_ce_0: 0  loss_mask_0: 0.8166  loss_dice_0: 2.286  loss_ce_1: 0  loss_mask_1: 0.8092  loss_dice_1: 2.23  loss_ce_2: 0  loss_mask_2: 0.8093  loss_dice_2: 2.22  loss_ce_3: 0  loss_mask_3: 0.8047  loss_dice_3: 2.217  loss_ce_4: 0  loss_mask_4: 0.8055  loss_dice_4: 2.218  loss_ce_5: 0  loss_mask_5: 0.8021  loss_dice_5: 2.22  loss_ce_6: 0  loss_mask_6: 0.8007  loss_dice_6: 2.217  loss_ce_7: 0  loss_mask_7: 0.8031  loss_dice_7: 2.22  loss_ce_8: 0  loss_mask_8: 0.8055  loss_dice_8: 2.213  time: 1.9408  data_time: 0.0396  lr: 6.8583e-05  max_mem: 6006M
[02/18 11:19:34] d2.utils.events INFO:  eta: 15:55:59  iter: 20559  total_loss: 29.39  loss_ce: 0  loss_mask: 0.79  loss_dice: 2.096  loss_seg: 0.9082  loss_ce_0: 0  loss_mask_0: 0.8119  loss_dice_0: 2.168  loss_ce_1: 0  loss_mask_1: 0.7918  loss_dice_1: 2.106  loss_ce_2: 0  loss_mask_2: 0.793  loss_dice_2: 2.082  loss_ce_3: 0  loss_mask_3: 0.7899  loss_dice_3: 2.08  loss_ce_4: 0  loss_mask_4: 0.7928  loss_dice_4: 2.076  loss_ce_5: 0  loss_mask_5: 0.7919  loss_dice_5: 2.075  loss_ce_6: 0  loss_mask_6: 0.7906  loss_dice_6: 2.078  loss_ce_7: 0  loss_mask_7: 0.7928  loss_dice_7: 2.081  loss_ce_8: 0  loss_mask_8: 0.7903  loss_dice_8: 2.083  time: 1.9405  data_time: 0.0385  lr: 6.8552e-05  max_mem: 6006M
[02/18 11:20:07] d2.utils.events INFO:  eta: 15:56:10  iter: 20579  total_loss: 32.12  loss_ce: 0  loss_mask: 0.8321  loss_dice: 2.246  loss_seg: 1.051  loss_ce_0: 0  loss_mask_0: 0.8466  loss_dice_0: 2.314  loss_ce_1: 0  loss_mask_1: 0.8346  loss_dice_1: 2.251  loss_ce_2: 0  loss_mask_2: 0.8323  loss_dice_2: 2.244  loss_ce_3: 0  loss_mask_3: 0.8293  loss_dice_3: 2.232  loss_ce_4: 0  loss_mask_4: 0.832  loss_dice_4: 2.236  loss_ce_5: 0  loss_mask_5: 0.8336  loss_dice_5: 2.234  loss_ce_6: 0  loss_mask_6: 0.8324  loss_dice_6: 2.235  loss_ce_7: 0  loss_mask_7: 0.8351  loss_dice_7: 2.229  loss_ce_8: 0  loss_mask_8: 0.8364  loss_dice_8: 2.23  time: 1.9402  data_time: 0.0450  lr: 6.852e-05  max_mem: 6006M
[02/18 11:20:37] d2.utils.events INFO:  eta: 15:50:22  iter: 20599  total_loss: 32.74  loss_ce: 0  loss_mask: 0.8406  loss_dice: 2.307  loss_seg: 0.8012  loss_ce_0: 0  loss_mask_0: 0.8571  loss_dice_0: 2.361  loss_ce_1: 0  loss_mask_1: 0.8305  loss_dice_1: 2.329  loss_ce_2: 0  loss_mask_2: 0.8413  loss_dice_2: 2.311  loss_ce_3: 0  loss_mask_3: 0.8439  loss_dice_3: 2.296  loss_ce_4: 0  loss_mask_4: 0.8441  loss_dice_4: 2.303  loss_ce_5: 0  loss_mask_5: 0.8424  loss_dice_5: 2.298  loss_ce_6: 0  loss_mask_6: 0.8421  loss_dice_6: 2.291  loss_ce_7: 0  loss_mask_7: 0.8433  loss_dice_7: 2.294  loss_ce_8: 0  loss_mask_8: 0.8437  loss_dice_8: 2.301  time: 1.9398  data_time: 0.0312  lr: 6.8489e-05  max_mem: 6006M
[02/18 11:21:09] d2.utils.events INFO:  eta: 15:49:53  iter: 20619  total_loss: 30.92  loss_ce: 0  loss_mask: 0.8055  loss_dice: 2.21  loss_seg: 0.672  loss_ce_0: 0  loss_mask_0: 0.8203  loss_dice_0: 2.269  loss_ce_1: 0  loss_mask_1: 0.8091  loss_dice_1: 2.223  loss_ce_2: 0  loss_mask_2: 0.8108  loss_dice_2: 2.207  loss_ce_3: 0  loss_mask_3: 0.8106  loss_dice_3: 2.196  loss_ce_4: 0  loss_mask_4: 0.8114  loss_dice_4: 2.194  loss_ce_5: 0  loss_mask_5: 0.812  loss_dice_5: 2.196  loss_ce_6: 0  loss_mask_6: 0.8107  loss_dice_6: 2.196  loss_ce_7: 0  loss_mask_7: 0.8113  loss_dice_7: 2.196  loss_ce_8: 0  loss_mask_8: 0.811  loss_dice_8: 2.192  time: 1.9395  data_time: 0.0286  lr: 6.8458e-05  max_mem: 6006M
[02/18 11:21:41] d2.utils.events INFO:  eta: 15:46:54  iter: 20639  total_loss: 29.48  loss_ce: 0  loss_mask: 0.8017  loss_dice: 2.077  loss_seg: 0.7822  loss_ce_0: 0  loss_mask_0: 0.8123  loss_dice_0: 2.136  loss_ce_1: 0  loss_mask_1: 0.8067  loss_dice_1: 2.072  loss_ce_2: 0  loss_mask_2: 0.8065  loss_dice_2: 2.048  loss_ce_3: 0  loss_mask_3: 0.7998  loss_dice_3: 2.047  loss_ce_4: 0  loss_mask_4: 0.8051  loss_dice_4: 2.055  loss_ce_5: 0  loss_mask_5: 0.8043  loss_dice_5: 2.053  loss_ce_6: 0  loss_mask_6: 0.8027  loss_dice_6: 2.053  loss_ce_7: 0  loss_mask_7: 0.8034  loss_dice_7: 2.049  loss_ce_8: 0  loss_mask_8: 0.8053  loss_dice_8: 2.047  time: 1.9391  data_time: 0.0283  lr: 6.8426e-05  max_mem: 6006M
[02/18 11:22:13] d2.utils.events INFO:  eta: 15:45:46  iter: 20659  total_loss: 31.2  loss_ce: 0  loss_mask: 0.7764  loss_dice: 2.215  loss_seg: 0.7806  loss_ce_0: 0  loss_mask_0: 0.8001  loss_dice_0: 2.262  loss_ce_1: 0  loss_mask_1: 0.7791  loss_dice_1: 2.223  loss_ce_2: 0  loss_mask_2: 0.7752  loss_dice_2: 2.214  loss_ce_3: 0  loss_mask_3: 0.7741  loss_dice_3: 2.209  loss_ce_4: 0  loss_mask_4: 0.7789  loss_dice_4: 2.208  loss_ce_5: 0  loss_mask_5: 0.7759  loss_dice_5: 2.213  loss_ce_6: 0  loss_mask_6: 0.7763  loss_dice_6: 2.205  loss_ce_7: 0  loss_mask_7: 0.778  loss_dice_7: 2.204  loss_ce_8: 0  loss_mask_8: 0.7769  loss_dice_8: 2.208  time: 1.9388  data_time: 0.0309  lr: 6.8395e-05  max_mem: 6006M
[02/18 11:22:45] d2.utils.events INFO:  eta: 15:43:35  iter: 20679  total_loss: 30.76  loss_ce: 0  loss_mask: 0.8137  loss_dice: 2.14  loss_seg: 1.074  loss_ce_0: 0  loss_mask_0: 0.8243  loss_dice_0: 2.206  loss_ce_1: 0  loss_mask_1: 0.8221  loss_dice_1: 2.138  loss_ce_2: 0  loss_mask_2: 0.8178  loss_dice_2: 2.13  loss_ce_3: 0  loss_mask_3: 0.8204  loss_dice_3: 2.122  loss_ce_4: 0  loss_mask_4: 0.8163  loss_dice_4: 2.12  loss_ce_5: 0  loss_mask_5: 0.8114  loss_dice_5: 2.123  loss_ce_6: 0  loss_mask_6: 0.8169  loss_dice_6: 2.127  loss_ce_7: 0  loss_mask_7: 0.817  loss_dice_7: 2.122  loss_ce_8: 0  loss_mask_8: 0.817  loss_dice_8: 2.128  time: 1.9385  data_time: 0.0390  lr: 6.8364e-05  max_mem: 6006M
[02/18 11:23:16] d2.utils.events INFO:  eta: 15:43:06  iter: 20699  total_loss: 28.81  loss_ce: 0  loss_mask: 0.727  loss_dice: 2.063  loss_seg: 0.7408  loss_ce_0: 0  loss_mask_0: 0.7424  loss_dice_0: 2.134  loss_ce_1: 0  loss_mask_1: 0.7394  loss_dice_1: 2.062  loss_ce_2: 0  loss_mask_2: 0.741  loss_dice_2: 2.043  loss_ce_3: 0  loss_mask_3: 0.7367  loss_dice_3: 2.038  loss_ce_4: 0  loss_mask_4: 0.7336  loss_dice_4: 2.039  loss_ce_5: 0  loss_mask_5: 0.733  loss_dice_5: 2.037  loss_ce_6: 0  loss_mask_6: 0.7327  loss_dice_6: 2.038  loss_ce_7: 0  loss_mask_7: 0.7335  loss_dice_7: 2.036  loss_ce_8: 0  loss_mask_8: 0.7335  loss_dice_8: 2.035  time: 1.9381  data_time: 0.0344  lr: 6.8332e-05  max_mem: 6006M
[02/18 11:23:50] d2.utils.events INFO:  eta: 15:45:50  iter: 20719  total_loss: 29.91  loss_ce: 0  loss_mask: 0.7622  loss_dice: 2.126  loss_seg: 0.7352  loss_ce_0: 0  loss_mask_0: 0.7739  loss_dice_0: 2.21  loss_ce_1: 0  loss_mask_1: 0.7621  loss_dice_1: 2.131  loss_ce_2: 0  loss_mask_2: 0.7628  loss_dice_2: 2.123  loss_ce_3: 0  loss_mask_3: 0.7681  loss_dice_3: 2.113  loss_ce_4: 0  loss_mask_4: 0.7688  loss_dice_4: 2.108  loss_ce_5: 0  loss_mask_5: 0.7715  loss_dice_5: 2.112  loss_ce_6: 0  loss_mask_6: 0.7693  loss_dice_6: 2.11  loss_ce_7: 0  loss_mask_7: 0.7689  loss_dice_7: 2.111  loss_ce_8: 0  loss_mask_8: 0.7668  loss_dice_8: 2.111  time: 1.9379  data_time: 0.0298  lr: 6.8301e-05  max_mem: 6006M
[02/18 11:24:22] d2.utils.events INFO:  eta: 15:44:30  iter: 20739  total_loss: 28.96  loss_ce: 0  loss_mask: 0.7338  loss_dice: 2.074  loss_seg: 0.7555  loss_ce_0: 0  loss_mask_0: 0.7385  loss_dice_0: 2.145  loss_ce_1: 0  loss_mask_1: 0.7463  loss_dice_1: 2.079  loss_ce_2: 0  loss_mask_2: 0.7411  loss_dice_2: 2.068  loss_ce_3: 0  loss_mask_3: 0.7417  loss_dice_3: 2.059  loss_ce_4: 0  loss_mask_4: 0.7411  loss_dice_4: 2.061  loss_ce_5: 0  loss_mask_5: 0.7408  loss_dice_5: 2.059  loss_ce_6: 0  loss_mask_6: 0.7445  loss_dice_6: 2.053  loss_ce_7: 0  loss_mask_7: 0.7448  loss_dice_7: 2.057  loss_ce_8: 0  loss_mask_8: 0.7445  loss_dice_8: 2.058  time: 1.9375  data_time: 0.0324  lr: 6.827e-05  max_mem: 6006M
[02/18 11:24:53] d2.utils.events INFO:  eta: 15:43:04  iter: 20759  total_loss: 31.55  loss_ce: 0  loss_mask: 0.8445  loss_dice: 2.216  loss_seg: 0.6676  loss_ce_0: 0  loss_mask_0: 0.879  loss_dice_0: 2.267  loss_ce_1: 0  loss_mask_1: 0.8432  loss_dice_1: 2.215  loss_ce_2: 0  loss_mask_2: 0.8464  loss_dice_2: 2.202  loss_ce_3: 0  loss_mask_3: 0.8473  loss_dice_3: 2.202  loss_ce_4: 0  loss_mask_4: 0.8465  loss_dice_4: 2.201  loss_ce_5: 0  loss_mask_5: 0.8454  loss_dice_5: 2.21  loss_ce_6: 0  loss_mask_6: 0.8528  loss_dice_6: 2.201  loss_ce_7: 0  loss_mask_7: 0.8496  loss_dice_7: 2.204  loss_ce_8: 0  loss_mask_8: 0.846  loss_dice_8: 2.206  time: 1.9371  data_time: 0.0283  lr: 6.8239e-05  max_mem: 6006M
[02/18 11:25:26] d2.utils.events INFO:  eta: 15:43:32  iter: 20779  total_loss: 31.24  loss_ce: 0  loss_mask: 0.8571  loss_dice: 2.232  loss_seg: 0.5691  loss_ce_0: 0  loss_mask_0: 0.8586  loss_dice_0: 2.27  loss_ce_1: 0  loss_mask_1: 0.8668  loss_dice_1: 2.243  loss_ce_2: 0  loss_mask_2: 0.8653  loss_dice_2: 2.229  loss_ce_3: 0  loss_mask_3: 0.8672  loss_dice_3: 2.212  loss_ce_4: 0  loss_mask_4: 0.8678  loss_dice_4: 2.22  loss_ce_5: 0  loss_mask_5: 0.8678  loss_dice_5: 2.228  loss_ce_6: 0  loss_mask_6: 0.8711  loss_dice_6: 2.215  loss_ce_7: 0  loss_mask_7: 0.8724  loss_dice_7: 2.218  loss_ce_8: 0  loss_mask_8: 0.8711  loss_dice_8: 2.222  time: 1.9369  data_time: 0.0324  lr: 6.8207e-05  max_mem: 6006M
[02/18 11:25:58] d2.utils.events INFO:  eta: 15:42:24  iter: 20799  total_loss: 29.03  loss_ce: 0  loss_mask: 0.777  loss_dice: 2.047  loss_seg: 0.5788  loss_ce_0: 0  loss_mask_0: 0.7845  loss_dice_0: 2.124  loss_ce_1: 0  loss_mask_1: 0.7748  loss_dice_1: 2.069  loss_ce_2: 0  loss_mask_2: 0.7777  loss_dice_2: 2.053  loss_ce_3: 0  loss_mask_3: 0.7817  loss_dice_3: 2.032  loss_ce_4: 0  loss_mask_4: 0.7837  loss_dice_4: 2.036  loss_ce_5: 0  loss_mask_5: 0.7792  loss_dice_5: 2.04  loss_ce_6: 0  loss_mask_6: 0.7817  loss_dice_6: 2.033  loss_ce_7: 0  loss_mask_7: 0.7807  loss_dice_7: 2.031  loss_ce_8: 0  loss_mask_8: 0.7822  loss_dice_8: 2.034  time: 1.9366  data_time: 0.0324  lr: 6.8176e-05  max_mem: 6006M
[02/18 11:26:30] d2.utils.events INFO:  eta: 15:41:38  iter: 20819  total_loss: 29.57  loss_ce: 0  loss_mask: 0.7733  loss_dice: 2.079  loss_seg: 0.9014  loss_ce_0: 0  loss_mask_0: 0.7738  loss_dice_0: 2.157  loss_ce_1: 0  loss_mask_1: 0.7791  loss_dice_1: 2.081  loss_ce_2: 0  loss_mask_2: 0.7785  loss_dice_2: 2.072  loss_ce_3: 0  loss_mask_3: 0.7806  loss_dice_3: 2.062  loss_ce_4: 0  loss_mask_4: 0.7837  loss_dice_4: 2.063  loss_ce_5: 0  loss_mask_5: 0.7842  loss_dice_5: 2.07  loss_ce_6: 0  loss_mask_6: 0.781  loss_dice_6: 2.064  loss_ce_7: 0  loss_mask_7: 0.7785  loss_dice_7: 2.063  loss_ce_8: 0  loss_mask_8: 0.781  loss_dice_8: 2.065  time: 1.9362  data_time: 0.0406  lr: 6.8145e-05  max_mem: 6006M
[02/18 11:27:02] d2.utils.events INFO:  eta: 15:41:57  iter: 20839  total_loss: 33.69  loss_ce: 0  loss_mask: 0.8351  loss_dice: 2.383  loss_seg: 0.7481  loss_ce_0: 0  loss_mask_0: 0.8589  loss_dice_0: 2.438  loss_ce_1: 0  loss_mask_1: 0.8393  loss_dice_1: 2.4  loss_ce_2: 0  loss_mask_2: 0.8418  loss_dice_2: 2.39  loss_ce_3: 0  loss_mask_3: 0.8415  loss_dice_3: 2.383  loss_ce_4: 0  loss_mask_4: 0.8421  loss_dice_4: 2.377  loss_ce_5: 0  loss_mask_5: 0.8394  loss_dice_5: 2.377  loss_ce_6: 0  loss_mask_6: 0.8417  loss_dice_6: 2.378  loss_ce_7: 0  loss_mask_7: 0.8436  loss_dice_7: 2.375  loss_ce_8: 0  loss_mask_8: 0.8435  loss_dice_8: 2.376  time: 1.9359  data_time: 0.0271  lr: 6.8113e-05  max_mem: 6006M
[02/18 11:27:35] d2.utils.events INFO:  eta: 15:40:58  iter: 20859  total_loss: 29.52  loss_ce: 0  loss_mask: 0.7916  loss_dice: 2.117  loss_seg: 0.5049  loss_ce_0: 0  loss_mask_0: 0.8042  loss_dice_0: 2.18  loss_ce_1: 0  loss_mask_1: 0.7955  loss_dice_1: 2.132  loss_ce_2: 0  loss_mask_2: 0.7979  loss_dice_2: 2.119  loss_ce_3: 0  loss_mask_3: 0.7971  loss_dice_3: 2.111  loss_ce_4: 0  loss_mask_4: 0.8017  loss_dice_4: 2.111  loss_ce_5: 0  loss_mask_5: 0.8051  loss_dice_5: 2.107  loss_ce_6: 0  loss_mask_6: 0.7993  loss_dice_6: 2.105  loss_ce_7: 0  loss_mask_7: 0.7994  loss_dice_7: 2.101  loss_ce_8: 0  loss_mask_8: 0.8003  loss_dice_8: 2.102  time: 1.9356  data_time: 0.0301  lr: 6.8082e-05  max_mem: 6006M
[02/18 11:28:06] d2.utils.events INFO:  eta: 15:35:57  iter: 20879  total_loss: 31.05  loss_ce: 0  loss_mask: 0.8377  loss_dice: 2.221  loss_seg: 0.7742  loss_ce_0: 0  loss_mask_0: 0.8325  loss_dice_0: 2.273  loss_ce_1: 0  loss_mask_1: 0.8391  loss_dice_1: 2.225  loss_ce_2: 0  loss_mask_2: 0.8434  loss_dice_2: 2.21  loss_ce_3: 0  loss_mask_3: 0.8375  loss_dice_3: 2.2  loss_ce_4: 0  loss_mask_4: 0.8377  loss_dice_4: 2.204  loss_ce_5: 0  loss_mask_5: 0.8372  loss_dice_5: 2.207  loss_ce_6: 0  loss_mask_6: 0.8351  loss_dice_6: 2.202  loss_ce_7: 0  loss_mask_7: 0.8373  loss_dice_7: 2.206  loss_ce_8: 0  loss_mask_8: 0.8342  loss_dice_8: 2.205  time: 1.9353  data_time: 0.0294  lr: 6.8051e-05  max_mem: 6006M
[02/18 11:28:40] d2.utils.events INFO:  eta: 15:31:41  iter: 20899  total_loss: 28.54  loss_ce: 0  loss_mask: 0.7932  loss_dice: 2.033  loss_seg: 0.6824  loss_ce_0: 0  loss_mask_0: 0.7996  loss_dice_0: 2.111  loss_ce_1: 0  loss_mask_1: 0.7967  loss_dice_1: 2.049  loss_ce_2: 0  loss_mask_2: 0.7948  loss_dice_2: 2.021  loss_ce_3: 0  loss_mask_3: 0.7956  loss_dice_3: 2.006  loss_ce_4: 0  loss_mask_4: 0.7975  loss_dice_4: 2.013  loss_ce_5: 0  loss_mask_5: 0.7959  loss_dice_5: 2.013  loss_ce_6: 0  loss_mask_6: 0.7933  loss_dice_6: 2.007  loss_ce_7: 0  loss_mask_7: 0.7923  loss_dice_7: 2.01  loss_ce_8: 0  loss_mask_8: 0.7909  loss_dice_8: 2.018  time: 1.9350  data_time: 0.0340  lr: 6.8019e-05  max_mem: 6006M
[02/18 11:29:13] d2.utils.events INFO:  eta: 15:35:00  iter: 20919  total_loss: 31.96  loss_ce: 0  loss_mask: 0.8025  loss_dice: 2.303  loss_seg: 0.8917  loss_ce_0: 0  loss_mask_0: 0.8027  loss_dice_0: 2.379  loss_ce_1: 0  loss_mask_1: 0.8057  loss_dice_1: 2.311  loss_ce_2: 0  loss_mask_2: 0.8021  loss_dice_2: 2.3  loss_ce_3: 0  loss_mask_3: 0.8085  loss_dice_3: 2.289  loss_ce_4: 0  loss_mask_4: 0.8083  loss_dice_4: 2.288  loss_ce_5: 0  loss_mask_5: 0.8059  loss_dice_5: 2.294  loss_ce_6: 0  loss_mask_6: 0.8086  loss_dice_6: 2.283  loss_ce_7: 0  loss_mask_7: 0.8123  loss_dice_7: 2.289  loss_ce_8: 0  loss_mask_8: 0.8101  loss_dice_8: 2.291  time: 1.9347  data_time: 0.0342  lr: 6.7988e-05  max_mem: 6006M
[02/18 11:29:44] d2.utils.events INFO:  eta: 15:24:54  iter: 20939  total_loss: 30.08  loss_ce: 0  loss_mask: 0.7906  loss_dice: 2.068  loss_seg: 0.7225  loss_ce_0: 0  loss_mask_0: 0.7968  loss_dice_0: 2.116  loss_ce_1: 0  loss_mask_1: 0.7897  loss_dice_1: 2.076  loss_ce_2: 0  loss_mask_2: 0.794  loss_dice_2: 2.059  loss_ce_3: 0  loss_mask_3: 0.7882  loss_dice_3: 2.059  loss_ce_4: 0  loss_mask_4: 0.7925  loss_dice_4: 2.066  loss_ce_5: 0  loss_mask_5: 0.7926  loss_dice_5: 2.071  loss_ce_6: 0  loss_mask_6: 0.7911  loss_dice_6: 2.064  loss_ce_7: 0  loss_mask_7: 0.7892  loss_dice_7: 2.07  loss_ce_8: 0  loss_mask_8: 0.7914  loss_dice_8: 2.067  time: 1.9343  data_time: 0.0265  lr: 6.7957e-05  max_mem: 6006M
[02/18 11:30:15] d2.utils.events INFO:  eta: 15:22:12  iter: 20959  total_loss: 30.8  loss_ce: 0  loss_mask: 0.7893  loss_dice: 2.173  loss_seg: 0.7809  loss_ce_0: 0  loss_mask_0: 0.7997  loss_dice_0: 2.226  loss_ce_1: 0  loss_mask_1: 0.7933  loss_dice_1: 2.191  loss_ce_2: 0  loss_mask_2: 0.7957  loss_dice_2: 2.178  loss_ce_3: 0  loss_mask_3: 0.7981  loss_dice_3: 2.164  loss_ce_4: 0  loss_mask_4: 0.7997  loss_dice_4: 2.168  loss_ce_5: 0  loss_mask_5: 0.7973  loss_dice_5: 2.163  loss_ce_6: 0  loss_mask_6: 0.8025  loss_dice_6: 2.161  loss_ce_7: 0  loss_mask_7: 0.8008  loss_dice_7: 2.164  loss_ce_8: 0  loss_mask_8: 0.7989  loss_dice_8: 2.165  time: 1.9340  data_time: 0.0313  lr: 6.7925e-05  max_mem: 6006M
[02/18 11:30:48] d2.utils.events INFO:  eta: 15:20:33  iter: 20979  total_loss: 30.43  loss_ce: 0  loss_mask: 0.7863  loss_dice: 2.164  loss_seg: 0.8903  loss_ce_0: 0  loss_mask_0: 0.7958  loss_dice_0: 2.224  loss_ce_1: 0  loss_mask_1: 0.8015  loss_dice_1: 2.166  loss_ce_2: 0  loss_mask_2: 0.806  loss_dice_2: 2.154  loss_ce_3: 0  loss_mask_3: 0.7975  loss_dice_3: 2.154  loss_ce_4: 0  loss_mask_4: 0.7946  loss_dice_4: 2.155  loss_ce_5: 0  loss_mask_5: 0.7967  loss_dice_5: 2.15  loss_ce_6: 0  loss_mask_6: 0.7985  loss_dice_6: 2.15  loss_ce_7: 0  loss_mask_7: 0.8021  loss_dice_7: 2.151  loss_ce_8: 0  loss_mask_8: 0.7939  loss_dice_8: 2.15  time: 1.9337  data_time: 0.0334  lr: 6.7894e-05  max_mem: 6006M
[02/18 11:31:22] d2.utils.events INFO:  eta: 15:22:32  iter: 20999  total_loss: 29.93  loss_ce: 0  loss_mask: 0.7744  loss_dice: 2.097  loss_seg: 0.9003  loss_ce_0: 0  loss_mask_0: 0.7779  loss_dice_0: 2.181  loss_ce_1: 0  loss_mask_1: 0.7855  loss_dice_1: 2.105  loss_ce_2: 0  loss_mask_2: 0.7839  loss_dice_2: 2.091  loss_ce_3: 0  loss_mask_3: 0.783  loss_dice_3: 2.081  loss_ce_4: 0  loss_mask_4: 0.7836  loss_dice_4: 2.086  loss_ce_5: 0  loss_mask_5: 0.7858  loss_dice_5: 2.084  loss_ce_6: 0  loss_mask_6: 0.7874  loss_dice_6: 2.077  loss_ce_7: 0  loss_mask_7: 0.7826  loss_dice_7: 2.083  loss_ce_8: 0  loss_mask_8: 0.783  loss_dice_8: 2.08  time: 1.9335  data_time: 0.0333  lr: 6.7863e-05  max_mem: 6006M
[02/18 11:31:55] d2.utils.events INFO:  eta: 15:24:18  iter: 21019  total_loss: 30.31  loss_ce: 0  loss_mask: 0.779  loss_dice: 2.177  loss_seg: 0.5774  loss_ce_0: 0  loss_mask_0: 0.7887  loss_dice_0: 2.243  loss_ce_1: 0  loss_mask_1: 0.7812  loss_dice_1: 2.19  loss_ce_2: 0  loss_mask_2: 0.7834  loss_dice_2: 2.168  loss_ce_3: 0  loss_mask_3: 0.7819  loss_dice_3: 2.142  loss_ce_4: 0  loss_mask_4: 0.7804  loss_dice_4: 2.148  loss_ce_5: 0  loss_mask_5: 0.7788  loss_dice_5: 2.148  loss_ce_6: 0  loss_mask_6: 0.7819  loss_dice_6: 2.151  loss_ce_7: 0  loss_mask_7: 0.7824  loss_dice_7: 2.155  loss_ce_8: 0  loss_mask_8: 0.7821  loss_dice_8: 2.156  time: 1.9332  data_time: 0.0294  lr: 6.7832e-05  max_mem: 6006M
[02/18 11:32:28] d2.utils.events INFO:  eta: 15:25:41  iter: 21039  total_loss: 29.21  loss_ce: 0  loss_mask: 0.7495  loss_dice: 2.077  loss_seg: 0.7255  loss_ce_0: 0  loss_mask_0: 0.751  loss_dice_0: 2.142  loss_ce_1: 0  loss_mask_1: 0.7488  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7542  loss_dice_2: 2.073  loss_ce_3: 0  loss_mask_3: 0.7499  loss_dice_3: 2.063  loss_ce_4: 0  loss_mask_4: 0.751  loss_dice_4: 2.057  loss_ce_5: 0  loss_mask_5: 0.7535  loss_dice_5: 2.064  loss_ce_6: 0  loss_mask_6: 0.7559  loss_dice_6: 2.064  loss_ce_7: 0  loss_mask_7: 0.7542  loss_dice_7: 2.062  loss_ce_8: 0  loss_mask_8: 0.7556  loss_dice_8: 2.061  time: 1.9329  data_time: 0.0328  lr: 6.78e-05  max_mem: 6006M
[02/18 11:32:59] d2.utils.events INFO:  eta: 15:24:19  iter: 21059  total_loss: 30.44  loss_ce: 0  loss_mask: 0.767  loss_dice: 2.206  loss_seg: 0.7177  loss_ce_0: 0  loss_mask_0: 0.7774  loss_dice_0: 2.279  loss_ce_1: 0  loss_mask_1: 0.7699  loss_dice_1: 2.213  loss_ce_2: 0  loss_mask_2: 0.7729  loss_dice_2: 2.212  loss_ce_3: 0  loss_mask_3: 0.774  loss_dice_3: 2.2  loss_ce_4: 0  loss_mask_4: 0.7691  loss_dice_4: 2.199  loss_ce_5: 0  loss_mask_5: 0.7715  loss_dice_5: 2.2  loss_ce_6: 0  loss_mask_6: 0.7699  loss_dice_6: 2.194  loss_ce_7: 0  loss_mask_7: 0.7719  loss_dice_7: 2.191  loss_ce_8: 0  loss_mask_8: 0.7716  loss_dice_8: 2.195  time: 1.9326  data_time: 0.0335  lr: 6.7769e-05  max_mem: 6006M
[02/18 11:33:31] d2.utils.events INFO:  eta: 15:25:46  iter: 21079  total_loss: 30.1  loss_ce: 0  loss_mask: 0.7609  loss_dice: 2.17  loss_seg: 0.8007  loss_ce_0: 0  loss_mask_0: 0.7802  loss_dice_0: 2.237  loss_ce_1: 0  loss_mask_1: 0.7722  loss_dice_1: 2.178  loss_ce_2: 0  loss_mask_2: 0.7661  loss_dice_2: 2.157  loss_ce_3: 0  loss_mask_3: 0.7637  loss_dice_3: 2.148  loss_ce_4: 0  loss_mask_4: 0.765  loss_dice_4: 2.152  loss_ce_5: 0  loss_mask_5: 0.7635  loss_dice_5: 2.154  loss_ce_6: 0  loss_mask_6: 0.7653  loss_dice_6: 2.148  loss_ce_7: 0  loss_mask_7: 0.7632  loss_dice_7: 2.149  loss_ce_8: 0  loss_mask_8: 0.7622  loss_dice_8: 2.155  time: 1.9322  data_time: 0.0325  lr: 6.7738e-05  max_mem: 6006M
[02/18 11:34:01] d2.utils.events INFO:  eta: 15:28:46  iter: 21099  total_loss: 30.61  loss_ce: 0  loss_mask: 0.7789  loss_dice: 2.196  loss_seg: 0.7189  loss_ce_0: 0  loss_mask_0: 0.789  loss_dice_0: 2.259  loss_ce_1: 0  loss_mask_1: 0.7788  loss_dice_1: 2.204  loss_ce_2: 0  loss_mask_2: 0.7816  loss_dice_2: 2.188  loss_ce_3: 0  loss_mask_3: 0.7855  loss_dice_3: 2.174  loss_ce_4: 0  loss_mask_4: 0.7839  loss_dice_4: 2.178  loss_ce_5: 0  loss_mask_5: 0.784  loss_dice_5: 2.176  loss_ce_6: 0  loss_mask_6: 0.787  loss_dice_6: 2.179  loss_ce_7: 0  loss_mask_7: 0.7834  loss_dice_7: 2.176  loss_ce_8: 0  loss_mask_8: 0.7835  loss_dice_8: 2.184  time: 1.9318  data_time: 0.0361  lr: 6.7706e-05  max_mem: 6006M
[02/18 11:34:31] d2.utils.events INFO:  eta: 15:30:37  iter: 21119  total_loss: 30.91  loss_ce: 0  loss_mask: 0.7774  loss_dice: 2.179  loss_seg: 0.6587  loss_ce_0: 0  loss_mask_0: 0.7889  loss_dice_0: 2.259  loss_ce_1: 0  loss_mask_1: 0.7776  loss_dice_1: 2.214  loss_ce_2: 0  loss_mask_2: 0.7821  loss_dice_2: 2.188  loss_ce_3: 0  loss_mask_3: 0.782  loss_dice_3: 2.164  loss_ce_4: 0  loss_mask_4: 0.7825  loss_dice_4: 2.174  loss_ce_5: 0  loss_mask_5: 0.7844  loss_dice_5: 2.17  loss_ce_6: 0  loss_mask_6: 0.7802  loss_dice_6: 2.166  loss_ce_7: 0  loss_mask_7: 0.7814  loss_dice_7: 2.17  loss_ce_8: 0  loss_mask_8: 0.7813  loss_dice_8: 2.167  time: 1.9314  data_time: 0.0426  lr: 6.7675e-05  max_mem: 6006M
[02/18 11:35:02] d2.utils.events INFO:  eta: 15:39:06  iter: 21139  total_loss: 29.58  loss_ce: 0  loss_mask: 0.7756  loss_dice: 2.152  loss_seg: 0.5044  loss_ce_0: 0  loss_mask_0: 0.7781  loss_dice_0: 2.216  loss_ce_1: 0  loss_mask_1: 0.7772  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.7757  loss_dice_2: 2.147  loss_ce_3: 0  loss_mask_3: 0.7767  loss_dice_3: 2.145  loss_ce_4: 0  loss_mask_4: 0.775  loss_dice_4: 2.142  loss_ce_5: 0  loss_mask_5: 0.7772  loss_dice_5: 2.142  loss_ce_6: 0  loss_mask_6: 0.7792  loss_dice_6: 2.138  loss_ce_7: 0  loss_mask_7: 0.7772  loss_dice_7: 2.141  loss_ce_8: 0  loss_mask_8: 0.7795  loss_dice_8: 2.141  time: 1.9311  data_time: 0.0313  lr: 6.7644e-05  max_mem: 6006M
[02/18 11:35:34] d2.utils.events INFO:  eta: 15:52:18  iter: 21159  total_loss: 30.72  loss_ce: 0  loss_mask: 0.8325  loss_dice: 2.189  loss_seg: 0.791  loss_ce_0: 0  loss_mask_0: 0.855  loss_dice_0: 2.233  loss_ce_1: 0  loss_mask_1: 0.834  loss_dice_1: 2.189  loss_ce_2: 0  loss_mask_2: 0.8322  loss_dice_2: 2.173  loss_ce_3: 0  loss_mask_3: 0.833  loss_dice_3: 2.173  loss_ce_4: 0  loss_mask_4: 0.8342  loss_dice_4: 2.175  loss_ce_5: 0  loss_mask_5: 0.8383  loss_dice_5: 2.176  loss_ce_6: 0  loss_mask_6: 0.8362  loss_dice_6: 2.177  loss_ce_7: 0  loss_mask_7: 0.8365  loss_dice_7: 2.179  loss_ce_8: 0  loss_mask_8: 0.8378  loss_dice_8: 2.178  time: 1.9308  data_time: 0.0349  lr: 6.7612e-05  max_mem: 6006M
[02/18 11:36:07] d2.utils.events INFO:  eta: 15:58:51  iter: 21179  total_loss: 29.83  loss_ce: 0  loss_mask: 0.8019  loss_dice: 2.141  loss_seg: 0.6279  loss_ce_0: 0  loss_mask_0: 0.797  loss_dice_0: 2.231  loss_ce_1: 0  loss_mask_1: 0.8032  loss_dice_1: 2.156  loss_ce_2: 0  loss_mask_2: 0.8053  loss_dice_2: 2.143  loss_ce_3: 0  loss_mask_3: 0.8085  loss_dice_3: 2.131  loss_ce_4: 0  loss_mask_4: 0.8079  loss_dice_4: 2.136  loss_ce_5: 0  loss_mask_5: 0.8075  loss_dice_5: 2.133  loss_ce_6: 0  loss_mask_6: 0.8079  loss_dice_6: 2.131  loss_ce_7: 0  loss_mask_7: 0.8082  loss_dice_7: 2.129  loss_ce_8: 0  loss_mask_8: 0.8066  loss_dice_8: 2.128  time: 1.9305  data_time: 0.0255  lr: 6.7581e-05  max_mem: 6006M
[02/18 11:36:39] d2.utils.events INFO:  eta: 16:07:51  iter: 21199  total_loss: 31.67  loss_ce: 0  loss_mask: 0.7948  loss_dice: 2.275  loss_seg: 0.6808  loss_ce_0: 0  loss_mask_0: 0.814  loss_dice_0: 2.334  loss_ce_1: 0  loss_mask_1: 0.8041  loss_dice_1: 2.294  loss_ce_2: 0  loss_mask_2: 0.8002  loss_dice_2: 2.273  loss_ce_3: 0  loss_mask_3: 0.8019  loss_dice_3: 2.267  loss_ce_4: 0  loss_mask_4: 0.798  loss_dice_4: 2.27  loss_ce_5: 0  loss_mask_5: 0.8006  loss_dice_5: 2.267  loss_ce_6: 0  loss_mask_6: 0.8  loss_dice_6: 2.261  loss_ce_7: 0  loss_mask_7: 0.7982  loss_dice_7: 2.269  loss_ce_8: 0  loss_mask_8: 0.7976  loss_dice_8: 2.263  time: 1.9302  data_time: 0.0281  lr: 6.755e-05  max_mem: 6006M
[02/18 11:37:13] d2.utils.events INFO:  eta: 16:13:45  iter: 21219  total_loss: 32.22  loss_ce: 0  loss_mask: 0.7748  loss_dice: 2.29  loss_seg: 1.236  loss_ce_0: 0  loss_mask_0: 0.7853  loss_dice_0: 2.334  loss_ce_1: 0  loss_mask_1: 0.7863  loss_dice_1: 2.301  loss_ce_2: 0  loss_mask_2: 0.7823  loss_dice_2: 2.28  loss_ce_3: 0  loss_mask_3: 0.7803  loss_dice_3: 2.27  loss_ce_4: 0  loss_mask_4: 0.7796  loss_dice_4: 2.279  loss_ce_5: 0  loss_mask_5: 0.7765  loss_dice_5: 2.272  loss_ce_6: 0  loss_mask_6: 0.7798  loss_dice_6: 2.262  loss_ce_7: 0  loss_mask_7: 0.7795  loss_dice_7: 2.266  loss_ce_8: 0  loss_mask_8: 0.78  loss_dice_8: 2.272  time: 1.9299  data_time: 0.0365  lr: 6.7518e-05  max_mem: 6006M
[02/18 11:37:44] d2.utils.events INFO:  eta: 16:20:00  iter: 21239  total_loss: 30.27  loss_ce: 0  loss_mask: 0.8085  loss_dice: 2.116  loss_seg: 0.7957  loss_ce_0: 0  loss_mask_0: 0.8103  loss_dice_0: 2.198  loss_ce_1: 0  loss_mask_1: 0.8099  loss_dice_1: 2.138  loss_ce_2: 0  loss_mask_2: 0.8186  loss_dice_2: 2.116  loss_ce_3: 0  loss_mask_3: 0.8141  loss_dice_3: 2.106  loss_ce_4: 0  loss_mask_4: 0.8174  loss_dice_4: 2.108  loss_ce_5: 0  loss_mask_5: 0.8162  loss_dice_5: 2.105  loss_ce_6: 0  loss_mask_6: 0.8127  loss_dice_6: 2.101  loss_ce_7: 0  loss_mask_7: 0.8145  loss_dice_7: 2.096  loss_ce_8: 0  loss_mask_8: 0.8136  loss_dice_8: 2.101  time: 1.9296  data_time: 0.0325  lr: 6.7487e-05  max_mem: 6006M
[02/18 11:38:16] d2.utils.events INFO:  eta: 16:25:11  iter: 21259  total_loss: 29.81  loss_ce: 0  loss_mask: 0.8157  loss_dice: 2.085  loss_seg: 0.5666  loss_ce_0: 0  loss_mask_0: 0.811  loss_dice_0: 2.184  loss_ce_1: 0  loss_mask_1: 0.8177  loss_dice_1: 2.11  loss_ce_2: 0  loss_mask_2: 0.8167  loss_dice_2: 2.091  loss_ce_3: 0  loss_mask_3: 0.8137  loss_dice_3: 2.071  loss_ce_4: 0  loss_mask_4: 0.8134  loss_dice_4: 2.072  loss_ce_5: 0  loss_mask_5: 0.8116  loss_dice_5: 2.078  loss_ce_6: 0  loss_mask_6: 0.8158  loss_dice_6: 2.073  loss_ce_7: 0  loss_mask_7: 0.814  loss_dice_7: 2.07  loss_ce_8: 0  loss_mask_8: 0.8162  loss_dice_8: 2.072  time: 1.9293  data_time: 0.0365  lr: 6.7456e-05  max_mem: 6006M
[02/18 11:38:47] d2.utils.events INFO:  eta: 16:28:07  iter: 21279  total_loss: 30.19  loss_ce: 0  loss_mask: 0.8041  loss_dice: 2.187  loss_seg: 0.6351  loss_ce_0: 0  loss_mask_0: 0.8017  loss_dice_0: 2.234  loss_ce_1: 0  loss_mask_1: 0.8073  loss_dice_1: 2.2  loss_ce_2: 0  loss_mask_2: 0.8088  loss_dice_2: 2.186  loss_ce_3: 0  loss_mask_3: 0.8136  loss_dice_3: 2.177  loss_ce_4: 0  loss_mask_4: 0.814  loss_dice_4: 2.174  loss_ce_5: 0  loss_mask_5: 0.8171  loss_dice_5: 2.174  loss_ce_6: 0  loss_mask_6: 0.8149  loss_dice_6: 2.176  loss_ce_7: 0  loss_mask_7: 0.822  loss_dice_7: 2.171  loss_ce_8: 0  loss_mask_8: 0.8163  loss_dice_8: 2.175  time: 1.9289  data_time: 0.0274  lr: 6.7424e-05  max_mem: 6006M
[02/18 11:39:21] d2.utils.events INFO:  eta: 16:34:57  iter: 21299  total_loss: 28.75  loss_ce: 0  loss_mask: 0.7681  loss_dice: 2.088  loss_seg: 0.5328  loss_ce_0: 0  loss_mask_0: 0.7795  loss_dice_0: 2.162  loss_ce_1: 0  loss_mask_1: 0.7695  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7719  loss_dice_2: 2.084  loss_ce_3: 0  loss_mask_3: 0.7729  loss_dice_3: 2.067  loss_ce_4: 0  loss_mask_4: 0.7726  loss_dice_4: 2.068  loss_ce_5: 0  loss_mask_5: 0.7717  loss_dice_5: 2.079  loss_ce_6: 0  loss_mask_6: 0.7712  loss_dice_6: 2.073  loss_ce_7: 0  loss_mask_7: 0.7733  loss_dice_7: 2.077  loss_ce_8: 0  loss_mask_8: 0.7764  loss_dice_8: 2.071  time: 1.9287  data_time: 0.0289  lr: 6.7393e-05  max_mem: 6006M
[02/18 11:39:53] d2.utils.events INFO:  eta: 16:39:05  iter: 21319  total_loss: 31.79  loss_ce: 0  loss_mask: 0.8326  loss_dice: 2.32  loss_seg: 0.643  loss_ce_0: 0  loss_mask_0: 0.8464  loss_dice_0: 2.378  loss_ce_1: 0  loss_mask_1: 0.8369  loss_dice_1: 2.329  loss_ce_2: 0  loss_mask_2: 0.8377  loss_dice_2: 2.313  loss_ce_3: 0  loss_mask_3: 0.8376  loss_dice_3: 2.311  loss_ce_4: 0  loss_mask_4: 0.8357  loss_dice_4: 2.31  loss_ce_5: 0  loss_mask_5: 0.8378  loss_dice_5: 2.315  loss_ce_6: 0  loss_mask_6: 0.8341  loss_dice_6: 2.312  loss_ce_7: 0  loss_mask_7: 0.8376  loss_dice_7: 2.312  loss_ce_8: 0  loss_mask_8: 0.8382  loss_dice_8: 2.311  time: 1.9284  data_time: 0.0317  lr: 6.7362e-05  max_mem: 6006M
[02/18 11:40:24] d2.utils.events INFO:  eta: 16:42:07  iter: 21339  total_loss: 30.18  loss_ce: 0  loss_mask: 0.8038  loss_dice: 2.15  loss_seg: 0.7419  loss_ce_0: 0  loss_mask_0: 0.814  loss_dice_0: 2.213  loss_ce_1: 0  loss_mask_1: 0.8075  loss_dice_1: 2.151  loss_ce_2: 0  loss_mask_2: 0.8054  loss_dice_2: 2.139  loss_ce_3: 0  loss_mask_3: 0.8002  loss_dice_3: 2.136  loss_ce_4: 0  loss_mask_4: 0.8077  loss_dice_4: 2.134  loss_ce_5: 0  loss_mask_5: 0.8075  loss_dice_5: 2.136  loss_ce_6: 0  loss_mask_6: 0.8106  loss_dice_6: 2.14  loss_ce_7: 0  loss_mask_7: 0.8066  loss_dice_7: 2.139  loss_ce_8: 0  loss_mask_8: 0.8096  loss_dice_8: 2.142  time: 1.9280  data_time: 0.0330  lr: 6.733e-05  max_mem: 6006M
[02/18 11:40:55] d2.utils.events INFO:  eta: 16:43:30  iter: 21359  total_loss: 30.24  loss_ce: 0  loss_mask: 0.7649  loss_dice: 2.155  loss_seg: 0.8751  loss_ce_0: 0  loss_mask_0: 0.7813  loss_dice_0: 2.229  loss_ce_1: 0  loss_mask_1: 0.7748  loss_dice_1: 2.166  loss_ce_2: 0  loss_mask_2: 0.7659  loss_dice_2: 2.161  loss_ce_3: 0  loss_mask_3: 0.7644  loss_dice_3: 2.146  loss_ce_4: 0  loss_mask_4: 0.7662  loss_dice_4: 2.151  loss_ce_5: 0  loss_mask_5: 0.764  loss_dice_5: 2.149  loss_ce_6: 0  loss_mask_6: 0.7658  loss_dice_6: 2.148  loss_ce_7: 0  loss_mask_7: 0.77  loss_dice_7: 2.142  loss_ce_8: 0  loss_mask_8: 0.7685  loss_dice_8: 2.149  time: 1.9277  data_time: 0.0305  lr: 6.7299e-05  max_mem: 6006M
[02/18 11:41:29] d2.utils.events INFO:  eta: 16:50:43  iter: 21379  total_loss: 32.09  loss_ce: 0  loss_mask: 0.8227  loss_dice: 2.233  loss_seg: 0.5551  loss_ce_0: 0  loss_mask_0: 0.8466  loss_dice_0: 2.281  loss_ce_1: 0  loss_mask_1: 0.8267  loss_dice_1: 2.253  loss_ce_2: 0  loss_mask_2: 0.8272  loss_dice_2: 2.247  loss_ce_3: 0  loss_mask_3: 0.8368  loss_dice_3: 2.231  loss_ce_4: 0  loss_mask_4: 0.8329  loss_dice_4: 2.229  loss_ce_5: 0  loss_mask_5: 0.8262  loss_dice_5: 2.231  loss_ce_6: 0  loss_mask_6: 0.824  loss_dice_6: 2.231  loss_ce_7: 0  loss_mask_7: 0.8265  loss_dice_7: 2.232  loss_ce_8: 0  loss_mask_8: 0.8269  loss_dice_8: 2.238  time: 1.9274  data_time: 0.0305  lr: 6.7267e-05  max_mem: 6006M
[02/18 11:42:03] d2.utils.events INFO:  eta: 16:55:18  iter: 21399  total_loss: 30.85  loss_ce: 0  loss_mask: 0.8185  loss_dice: 2.199  loss_seg: 0.6437  loss_ce_0: 0  loss_mask_0: 0.8215  loss_dice_0: 2.272  loss_ce_1: 0  loss_mask_1: 0.8161  loss_dice_1: 2.229  loss_ce_2: 0  loss_mask_2: 0.824  loss_dice_2: 2.202  loss_ce_3: 0  loss_mask_3: 0.8226  loss_dice_3: 2.191  loss_ce_4: 0  loss_mask_4: 0.8224  loss_dice_4: 2.19  loss_ce_5: 0  loss_mask_5: 0.8269  loss_dice_5: 2.183  loss_ce_6: 0  loss_mask_6: 0.822  loss_dice_6: 2.19  loss_ce_7: 0  loss_mask_7: 0.8255  loss_dice_7: 2.188  loss_ce_8: 0  loss_mask_8: 0.8249  loss_dice_8: 2.19  time: 1.9272  data_time: 0.0333  lr: 6.7236e-05  max_mem: 6006M
[02/18 11:42:33] d2.utils.events INFO:  eta: 16:54:46  iter: 21419  total_loss: 29.75  loss_ce: 0  loss_mask: 0.7905  loss_dice: 2.127  loss_seg: 0.7464  loss_ce_0: 0  loss_mask_0: 0.7973  loss_dice_0: 2.21  loss_ce_1: 0  loss_mask_1: 0.7891  loss_dice_1: 2.145  loss_ce_2: 0  loss_mask_2: 0.795  loss_dice_2: 2.135  loss_ce_3: 0  loss_mask_3: 0.7899  loss_dice_3: 2.127  loss_ce_4: 0  loss_mask_4: 0.7906  loss_dice_4: 2.126  loss_ce_5: 0  loss_mask_5: 0.7891  loss_dice_5: 2.128  loss_ce_6: 0  loss_mask_6: 0.7895  loss_dice_6: 2.125  loss_ce_7: 0  loss_mask_7: 0.7894  loss_dice_7: 2.122  loss_ce_8: 0  loss_mask_8: 0.7892  loss_dice_8: 2.12  time: 1.9269  data_time: 0.0314  lr: 6.7205e-05  max_mem: 6006M
[02/18 11:43:07] d2.utils.events INFO:  eta: 16:56:55  iter: 21439  total_loss: 28.89  loss_ce: 0  loss_mask: 0.761  loss_dice: 2.046  loss_seg: 0.769  loss_ce_0: 0  loss_mask_0: 0.7664  loss_dice_0: 2.132  loss_ce_1: 0  loss_mask_1: 0.7644  loss_dice_1: 2.08  loss_ce_2: 0  loss_mask_2: 0.7652  loss_dice_2: 2.06  loss_ce_3: 0  loss_mask_3: 0.7644  loss_dice_3: 2.04  loss_ce_4: 0  loss_mask_4: 0.7654  loss_dice_4: 2.041  loss_ce_5: 0  loss_mask_5: 0.7655  loss_dice_5: 2.04  loss_ce_6: 0  loss_mask_6: 0.7649  loss_dice_6: 2.028  loss_ce_7: 0  loss_mask_7: 0.7628  loss_dice_7: 2.032  loss_ce_8: 0  loss_mask_8: 0.7624  loss_dice_8: 2.037  time: 1.9266  data_time: 0.0358  lr: 6.7173e-05  max_mem: 6006M
[02/18 11:43:38] d2.utils.events INFO:  eta: 16:54:08  iter: 21459  total_loss: 28.94  loss_ce: 0  loss_mask: 0.7399  loss_dice: 2.062  loss_seg: 0.7418  loss_ce_0: 0  loss_mask_0: 0.7382  loss_dice_0: 2.105  loss_ce_1: 0  loss_mask_1: 0.7402  loss_dice_1: 2.066  loss_ce_2: 0  loss_mask_2: 0.7447  loss_dice_2: 2.053  loss_ce_3: 0  loss_mask_3: 0.7488  loss_dice_3: 2.049  loss_ce_4: 0  loss_mask_4: 0.7478  loss_dice_4: 2.049  loss_ce_5: 0  loss_mask_5: 0.7447  loss_dice_5: 2.048  loss_ce_6: 0  loss_mask_6: 0.7512  loss_dice_6: 2.047  loss_ce_7: 0  loss_mask_7: 0.7491  loss_dice_7: 2.046  loss_ce_8: 0  loss_mask_8: 0.7447  loss_dice_8: 2.051  time: 1.9263  data_time: 0.0276  lr: 6.7142e-05  max_mem: 6006M
[02/18 11:44:12] d2.utils.events INFO:  eta: 16:54:24  iter: 21479  total_loss: 31.26  loss_ce: 0  loss_mask: 0.8311  loss_dice: 2.249  loss_seg: 0.727  loss_ce_0: 0  loss_mask_0: 0.8479  loss_dice_0: 2.311  loss_ce_1: 0  loss_mask_1: 0.831  loss_dice_1: 2.264  loss_ce_2: 0  loss_mask_2: 0.8282  loss_dice_2: 2.25  loss_ce_3: 0  loss_mask_3: 0.8269  loss_dice_3: 2.227  loss_ce_4: 0  loss_mask_4: 0.8279  loss_dice_4: 2.232  loss_ce_5: 0  loss_mask_5: 0.8293  loss_dice_5: 2.232  loss_ce_6: 0  loss_mask_6: 0.8341  loss_dice_6: 2.222  loss_ce_7: 0  loss_mask_7: 0.8349  loss_dice_7: 2.226  loss_ce_8: 0  loss_mask_8: 0.8348  loss_dice_8: 2.232  time: 1.9261  data_time: 0.0351  lr: 6.7111e-05  max_mem: 6006M
[02/18 11:44:43] d2.utils.events INFO:  eta: 16:54:17  iter: 21499  total_loss: 28.84  loss_ce: 0  loss_mask: 0.7583  loss_dice: 2.105  loss_seg: 0.6451  loss_ce_0: 0  loss_mask_0: 0.7557  loss_dice_0: 2.173  loss_ce_1: 0  loss_mask_1: 0.7566  loss_dice_1: 2.108  loss_ce_2: 0  loss_mask_2: 0.7599  loss_dice_2: 2.102  loss_ce_3: 0  loss_mask_3: 0.757  loss_dice_3: 2.089  loss_ce_4: 0  loss_mask_4: 0.762  loss_dice_4: 2.078  loss_ce_5: 0  loss_mask_5: 0.761  loss_dice_5: 2.081  loss_ce_6: 0  loss_mask_6: 0.7601  loss_dice_6: 2.074  loss_ce_7: 0  loss_mask_7: 0.7599  loss_dice_7: 2.078  loss_ce_8: 0  loss_mask_8: 0.7638  loss_dice_8: 2.077  time: 1.9257  data_time: 0.0265  lr: 6.7079e-05  max_mem: 6006M
[02/18 11:45:14] d2.utils.events INFO:  eta: 16:53:12  iter: 21519  total_loss: 29.37  loss_ce: 0  loss_mask: 0.763  loss_dice: 2.091  loss_seg: 0.6566  loss_ce_0: 0  loss_mask_0: 0.7841  loss_dice_0: 2.157  loss_ce_1: 0  loss_mask_1: 0.7739  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7719  loss_dice_2: 2.078  loss_ce_3: 0  loss_mask_3: 0.7692  loss_dice_3: 2.077  loss_ce_4: 0  loss_mask_4: 0.7687  loss_dice_4: 2.077  loss_ce_5: 0  loss_mask_5: 0.7701  loss_dice_5: 2.077  loss_ce_6: 0  loss_mask_6: 0.7665  loss_dice_6: 2.075  loss_ce_7: 0  loss_mask_7: 0.7675  loss_dice_7: 2.073  loss_ce_8: 0  loss_mask_8: 0.7634  loss_dice_8: 2.076  time: 1.9254  data_time: 0.0275  lr: 6.7048e-05  max_mem: 6006M
[02/18 11:45:45] d2.utils.events INFO:  eta: 16:50:31  iter: 21539  total_loss: 31.08  loss_ce: 0  loss_mask: 0.8203  loss_dice: 2.155  loss_seg: 0.7421  loss_ce_0: 0  loss_mask_0: 0.8174  loss_dice_0: 2.197  loss_ce_1: 0  loss_mask_1: 0.8115  loss_dice_1: 2.159  loss_ce_2: 0  loss_mask_2: 0.8202  loss_dice_2: 2.15  loss_ce_3: 0  loss_mask_3: 0.8258  loss_dice_3: 2.135  loss_ce_4: 0  loss_mask_4: 0.8238  loss_dice_4: 2.145  loss_ce_5: 0  loss_mask_5: 0.8217  loss_dice_5: 2.141  loss_ce_6: 0  loss_mask_6: 0.824  loss_dice_6: 2.135  loss_ce_7: 0  loss_mask_7: 0.8286  loss_dice_7: 2.138  loss_ce_8: 0  loss_mask_8: 0.8286  loss_dice_8: 2.142  time: 1.9250  data_time: 0.0261  lr: 6.7017e-05  max_mem: 6006M
[02/18 11:46:17] d2.utils.events INFO:  eta: 16:49:35  iter: 21559  total_loss: 31.2  loss_ce: 0  loss_mask: 0.7901  loss_dice: 2.252  loss_seg: 0.9917  loss_ce_0: 0  loss_mask_0: 0.8059  loss_dice_0: 2.295  loss_ce_1: 0  loss_mask_1: 0.79  loss_dice_1: 2.255  loss_ce_2: 0  loss_mask_2: 0.7858  loss_dice_2: 2.244  loss_ce_3: 0  loss_mask_3: 0.7891  loss_dice_3: 2.24  loss_ce_4: 0  loss_mask_4: 0.7882  loss_dice_4: 2.237  loss_ce_5: 0  loss_mask_5: 0.7883  loss_dice_5: 2.237  loss_ce_6: 0  loss_mask_6: 0.7908  loss_dice_6: 2.24  loss_ce_7: 0  loss_mask_7: 0.7894  loss_dice_7: 2.241  loss_ce_8: 0  loss_mask_8: 0.7917  loss_dice_8: 2.242  time: 1.9247  data_time: 0.0359  lr: 6.6985e-05  max_mem: 6006M
[02/18 11:46:48] d2.utils.events INFO:  eta: 16:48:13  iter: 21579  total_loss: 29.11  loss_ce: 0  loss_mask: 0.7721  loss_dice: 2.05  loss_seg: 0.5834  loss_ce_0: 0  loss_mask_0: 0.7821  loss_dice_0: 2.119  loss_ce_1: 0  loss_mask_1: 0.7725  loss_dice_1: 2.056  loss_ce_2: 0  loss_mask_2: 0.7722  loss_dice_2: 2.045  loss_ce_3: 0  loss_mask_3: 0.7743  loss_dice_3: 2.035  loss_ce_4: 0  loss_mask_4: 0.7778  loss_dice_4: 2.036  loss_ce_5: 0  loss_mask_5: 0.7742  loss_dice_5: 2.04  loss_ce_6: 0  loss_mask_6: 0.7767  loss_dice_6: 2.037  loss_ce_7: 0  loss_mask_7: 0.7748  loss_dice_7: 2.04  loss_ce_8: 0  loss_mask_8: 0.7766  loss_dice_8: 2.043  time: 1.9244  data_time: 0.0294  lr: 6.6954e-05  max_mem: 6006M
[02/18 11:47:22] d2.utils.events INFO:  eta: 16:48:00  iter: 21599  total_loss: 29.28  loss_ce: 0  loss_mask: 0.7516  loss_dice: 2.046  loss_seg: 0.7103  loss_ce_0: 0  loss_mask_0: 0.7534  loss_dice_0: 2.146  loss_ce_1: 0  loss_mask_1: 0.7575  loss_dice_1: 2.061  loss_ce_2: 0  loss_mask_2: 0.7553  loss_dice_2: 2.053  loss_ce_3: 0  loss_mask_3: 0.7554  loss_dice_3: 2.031  loss_ce_4: 0  loss_mask_4: 0.7561  loss_dice_4: 2.034  loss_ce_5: 0  loss_mask_5: 0.7558  loss_dice_5: 2.03  loss_ce_6: 0  loss_mask_6: 0.7589  loss_dice_6: 2.026  loss_ce_7: 0  loss_mask_7: 0.7573  loss_dice_7: 2.026  loss_ce_8: 0  loss_mask_8: 0.7582  loss_dice_8: 2.031  time: 1.9241  data_time: 0.0339  lr: 6.6922e-05  max_mem: 6006M
[02/18 11:47:55] d2.utils.events INFO:  eta: 16:48:00  iter: 21619  total_loss: 29.33  loss_ce: 0  loss_mask: 0.7684  loss_dice: 2.086  loss_seg: 0.6291  loss_ce_0: 0  loss_mask_0: 0.7749  loss_dice_0: 2.159  loss_ce_1: 0  loss_mask_1: 0.7607  loss_dice_1: 2.102  loss_ce_2: 0  loss_mask_2: 0.7663  loss_dice_2: 2.086  loss_ce_3: 0  loss_mask_3: 0.7653  loss_dice_3: 2.07  loss_ce_4: 0  loss_mask_4: 0.768  loss_dice_4: 2.072  loss_ce_5: 0  loss_mask_5: 0.7685  loss_dice_5: 2.072  loss_ce_6: 0  loss_mask_6: 0.7674  loss_dice_6: 2.067  loss_ce_7: 0  loss_mask_7: 0.7709  loss_dice_7: 2.069  loss_ce_8: 0  loss_mask_8: 0.7742  loss_dice_8: 2.066  time: 1.9239  data_time: 0.0324  lr: 6.6891e-05  max_mem: 6006M
[02/18 11:48:29] d2.utils.events INFO:  eta: 16:47:29  iter: 21639  total_loss: 31.66  loss_ce: 0  loss_mask: 0.7858  loss_dice: 2.233  loss_seg: 0.6287  loss_ce_0: 0  loss_mask_0: 0.8111  loss_dice_0: 2.294  loss_ce_1: 0  loss_mask_1: 0.7967  loss_dice_1: 2.253  loss_ce_2: 0  loss_mask_2: 0.7915  loss_dice_2: 2.241  loss_ce_3: 0  loss_mask_3: 0.7919  loss_dice_3: 2.228  loss_ce_4: 0  loss_mask_4: 0.7923  loss_dice_4: 2.226  loss_ce_5: 0  loss_mask_5: 0.7916  loss_dice_5: 2.228  loss_ce_6: 0  loss_mask_6: 0.7927  loss_dice_6: 2.229  loss_ce_7: 0  loss_mask_7: 0.7893  loss_dice_7: 2.227  loss_ce_8: 0  loss_mask_8: 0.7866  loss_dice_8: 2.228  time: 1.9237  data_time: 0.0330  lr: 6.686e-05  max_mem: 6006M
[02/18 11:49:02] d2.utils.events INFO:  eta: 16:49:18  iter: 21659  total_loss: 30.18  loss_ce: 0  loss_mask: 0.771  loss_dice: 2.197  loss_seg: 0.727  loss_ce_0: 0  loss_mask_0: 0.7813  loss_dice_0: 2.269  loss_ce_1: 0  loss_mask_1: 0.7821  loss_dice_1: 2.206  loss_ce_2: 0  loss_mask_2: 0.7784  loss_dice_2: 2.191  loss_ce_3: 0  loss_mask_3: 0.7725  loss_dice_3: 2.184  loss_ce_4: 0  loss_mask_4: 0.7773  loss_dice_4: 2.182  loss_ce_5: 0  loss_mask_5: 0.7741  loss_dice_5: 2.183  loss_ce_6: 0  loss_mask_6: 0.771  loss_dice_6: 2.176  loss_ce_7: 0  loss_mask_7: 0.7705  loss_dice_7: 2.177  loss_ce_8: 0  loss_mask_8: 0.7751  loss_dice_8: 2.182  time: 1.9234  data_time: 0.0288  lr: 6.6828e-05  max_mem: 6006M
[02/18 11:49:32] d2.utils.events INFO:  eta: 16:46:50  iter: 21679  total_loss: 29.98  loss_ce: 0  loss_mask: 0.7828  loss_dice: 2.096  loss_seg: 0.6048  loss_ce_0: 0  loss_mask_0: 0.7999  loss_dice_0: 2.179  loss_ce_1: 0  loss_mask_1: 0.7973  loss_dice_1: 2.099  loss_ce_2: 0  loss_mask_2: 0.7873  loss_dice_2: 2.076  loss_ce_3: 0  loss_mask_3: 0.7882  loss_dice_3: 2.078  loss_ce_4: 0  loss_mask_4: 0.7889  loss_dice_4: 2.077  loss_ce_5: 0  loss_mask_5: 0.7854  loss_dice_5: 2.075  loss_ce_6: 0  loss_mask_6: 0.793  loss_dice_6: 2.076  loss_ce_7: 0  loss_mask_7: 0.7921  loss_dice_7: 2.076  loss_ce_8: 0  loss_mask_8: 0.7931  loss_dice_8: 2.079  time: 1.9230  data_time: 0.0350  lr: 6.6797e-05  max_mem: 6006M
[02/18 11:50:05] d2.utils.events INFO:  eta: 16:47:05  iter: 21699  total_loss: 30.35  loss_ce: 0  loss_mask: 0.7449  loss_dice: 2.202  loss_seg: 0.891  loss_ce_0: 0  loss_mask_0: 0.7548  loss_dice_0: 2.295  loss_ce_1: 0  loss_mask_1: 0.7444  loss_dice_1: 2.221  loss_ce_2: 0  loss_mask_2: 0.7502  loss_dice_2: 2.204  loss_ce_3: 0  loss_mask_3: 0.754  loss_dice_3: 2.189  loss_ce_4: 0  loss_mask_4: 0.7518  loss_dice_4: 2.191  loss_ce_5: 0  loss_mask_5: 0.7492  loss_dice_5: 2.189  loss_ce_6: 0  loss_mask_6: 0.7516  loss_dice_6: 2.188  loss_ce_7: 0  loss_mask_7: 0.7505  loss_dice_7: 2.194  loss_ce_8: 0  loss_mask_8: 0.7499  loss_dice_8: 2.196  time: 1.9228  data_time: 0.0264  lr: 6.6766e-05  max_mem: 6006M
[02/18 11:50:39] d2.utils.events INFO:  eta: 16:45:38  iter: 21719  total_loss: 30.35  loss_ce: 0  loss_mask: 0.7916  loss_dice: 2.145  loss_seg: 0.5475  loss_ce_0: 0  loss_mask_0: 0.7897  loss_dice_0: 2.219  loss_ce_1: 0  loss_mask_1: 0.7903  loss_dice_1: 2.155  loss_ce_2: 0  loss_mask_2: 0.7994  loss_dice_2: 2.143  loss_ce_3: 0  loss_mask_3: 0.7972  loss_dice_3: 2.134  loss_ce_4: 0  loss_mask_4: 0.7928  loss_dice_4: 2.128  loss_ce_5: 0  loss_mask_5: 0.7968  loss_dice_5: 2.133  loss_ce_6: 0  loss_mask_6: 0.8025  loss_dice_6: 2.134  loss_ce_7: 0  loss_mask_7: 0.8021  loss_dice_7: 2.133  loss_ce_8: 0  loss_mask_8: 0.8031  loss_dice_8: 2.13  time: 1.9226  data_time: 0.0288  lr: 6.6734e-05  max_mem: 6006M
[02/18 11:51:08] d2.utils.events INFO:  eta: 16:43:11  iter: 21739  total_loss: 28.28  loss_ce: 0  loss_mask: 0.7651  loss_dice: 1.966  loss_seg: 0.9125  loss_ce_0: 0  loss_mask_0: 0.7617  loss_dice_0: 2.033  loss_ce_1: 0  loss_mask_1: 0.7632  loss_dice_1: 1.99  loss_ce_2: 0  loss_mask_2: 0.768  loss_dice_2: 1.97  loss_ce_3: 0  loss_mask_3: 0.7704  loss_dice_3: 1.946  loss_ce_4: 0  loss_mask_4: 0.7703  loss_dice_4: 1.952  loss_ce_5: 0  loss_mask_5: 0.7693  loss_dice_5: 1.942  loss_ce_6: 0  loss_mask_6: 0.772  loss_dice_6: 1.948  loss_ce_7: 0  loss_mask_7: 0.7689  loss_dice_7: 1.947  loss_ce_8: 0  loss_mask_8: 0.767  loss_dice_8: 1.949  time: 1.9221  data_time: 0.0325  lr: 6.6703e-05  max_mem: 6006M
[02/18 11:51:39] d2.utils.events INFO:  eta: 16:42:50  iter: 21759  total_loss: 29.46  loss_ce: 0  loss_mask: 0.7751  loss_dice: 2.094  loss_seg: 0.81  loss_ce_0: 0  loss_mask_0: 0.7782  loss_dice_0: 2.152  loss_ce_1: 0  loss_mask_1: 0.776  loss_dice_1: 2.088  loss_ce_2: 0  loss_mask_2: 0.7755  loss_dice_2: 2.08  loss_ce_3: 0  loss_mask_3: 0.7743  loss_dice_3: 2.081  loss_ce_4: 0  loss_mask_4: 0.7722  loss_dice_4: 2.084  loss_ce_5: 0  loss_mask_5: 0.7724  loss_dice_5: 2.084  loss_ce_6: 0  loss_mask_6: 0.7741  loss_dice_6: 2.085  loss_ce_7: 0  loss_mask_7: 0.773  loss_dice_7: 2.086  loss_ce_8: 0  loss_mask_8: 0.7765  loss_dice_8: 2.085  time: 1.9217  data_time: 0.0288  lr: 6.6671e-05  max_mem: 6006M
[02/18 11:52:11] d2.utils.events INFO:  eta: 16:41:28  iter: 21779  total_loss: 30.03  loss_ce: 0  loss_mask: 0.7769  loss_dice: 2.126  loss_seg: 0.7352  loss_ce_0: 0  loss_mask_0: 0.7754  loss_dice_0: 2.198  loss_ce_1: 0  loss_mask_1: 0.7753  loss_dice_1: 2.143  loss_ce_2: 0  loss_mask_2: 0.7772  loss_dice_2: 2.125  loss_ce_3: 0  loss_mask_3: 0.7785  loss_dice_3: 2.115  loss_ce_4: 0  loss_mask_4: 0.7783  loss_dice_4: 2.119  loss_ce_5: 0  loss_mask_5: 0.7757  loss_dice_5: 2.12  loss_ce_6: 0  loss_mask_6: 0.7762  loss_dice_6: 2.11  loss_ce_7: 0  loss_mask_7: 0.7751  loss_dice_7: 2.123  loss_ce_8: 0  loss_mask_8: 0.7759  loss_dice_8: 2.117  time: 1.9215  data_time: 0.0261  lr: 6.664e-05  max_mem: 6006M
[02/18 11:52:40] d2.utils.events INFO:  eta: 16:40:11  iter: 21799  total_loss: 31  loss_ce: 0  loss_mask: 0.8093  loss_dice: 2.212  loss_seg: 0.7747  loss_ce_0: 0  loss_mask_0: 0.8167  loss_dice_0: 2.266  loss_ce_1: 0  loss_mask_1: 0.8173  loss_dice_1: 2.218  loss_ce_2: 0  loss_mask_2: 0.8148  loss_dice_2: 2.206  loss_ce_3: 0  loss_mask_3: 0.8151  loss_dice_3: 2.199  loss_ce_4: 0  loss_mask_4: 0.8154  loss_dice_4: 2.196  loss_ce_5: 0  loss_mask_5: 0.8116  loss_dice_5: 2.203  loss_ce_6: 0  loss_mask_6: 0.8127  loss_dice_6: 2.204  loss_ce_7: 0  loss_mask_7: 0.8171  loss_dice_7: 2.202  loss_ce_8: 0  loss_mask_8: 0.8156  loss_dice_8: 2.207  time: 1.9211  data_time: 0.0411  lr: 6.6609e-05  max_mem: 6006M
[02/18 11:53:08] d2.utils.events INFO:  eta: 16:37:26  iter: 21819  total_loss: 30.69  loss_ce: 0  loss_mask: 0.788  loss_dice: 2.218  loss_seg: 0.8269  loss_ce_0: 0  loss_mask_0: 0.795  loss_dice_0: 2.275  loss_ce_1: 0  loss_mask_1: 0.7952  loss_dice_1: 2.239  loss_ce_2: 0  loss_mask_2: 0.7871  loss_dice_2: 2.222  loss_ce_3: 0  loss_mask_3: 0.7894  loss_dice_3: 2.211  loss_ce_4: 0  loss_mask_4: 0.7933  loss_dice_4: 2.207  loss_ce_5: 0  loss_mask_5: 0.7856  loss_dice_5: 2.209  loss_ce_6: 0  loss_mask_6: 0.7866  loss_dice_6: 2.205  loss_ce_7: 0  loss_mask_7: 0.7905  loss_dice_7: 2.197  loss_ce_8: 0  loss_mask_8: 0.793  loss_dice_8: 2.2  time: 1.9206  data_time: 0.0432  lr: 6.6577e-05  max_mem: 6006M
[02/18 11:53:40] d2.utils.events INFO:  eta: 16:36:49  iter: 21839  total_loss: 29.49  loss_ce: 0  loss_mask: 0.7749  loss_dice: 2.09  loss_seg: 0.7499  loss_ce_0: 0  loss_mask_0: 0.7846  loss_dice_0: 2.169  loss_ce_1: 0  loss_mask_1: 0.7808  loss_dice_1: 2.095  loss_ce_2: 0  loss_mask_2: 0.7819  loss_dice_2: 2.082  loss_ce_3: 0  loss_mask_3: 0.7856  loss_dice_3: 2.08  loss_ce_4: 0  loss_mask_4: 0.7848  loss_dice_4: 2.077  loss_ce_5: 0  loss_mask_5: 0.7827  loss_dice_5: 2.073  loss_ce_6: 0  loss_mask_6: 0.7823  loss_dice_6: 2.078  loss_ce_7: 0  loss_mask_7: 0.7801  loss_dice_7: 2.079  loss_ce_8: 0  loss_mask_8: 0.7777  loss_dice_8: 2.084  time: 1.9202  data_time: 0.0274  lr: 6.6546e-05  max_mem: 6006M
[02/18 11:54:12] d2.utils.events INFO:  eta: 16:33:18  iter: 21859  total_loss: 30.41  loss_ce: 0  loss_mask: 0.7764  loss_dice: 2.171  loss_seg: 0.6265  loss_ce_0: 0  loss_mask_0: 0.785  loss_dice_0: 2.191  loss_ce_1: 0  loss_mask_1: 0.7882  loss_dice_1: 2.17  loss_ce_2: 0  loss_mask_2: 0.7821  loss_dice_2: 2.161  loss_ce_3: 0  loss_mask_3: 0.7847  loss_dice_3: 2.156  loss_ce_4: 0  loss_mask_4: 0.7828  loss_dice_4: 2.156  loss_ce_5: 0  loss_mask_5: 0.7817  loss_dice_5: 2.163  loss_ce_6: 0  loss_mask_6: 0.785  loss_dice_6: 2.156  loss_ce_7: 0  loss_mask_7: 0.7866  loss_dice_7: 2.162  loss_ce_8: 0  loss_mask_8: 0.7867  loss_dice_8: 2.161  time: 1.9200  data_time: 0.0361  lr: 6.6515e-05  max_mem: 6006M
[02/18 11:54:47] d2.utils.events INFO:  eta: 16:35:52  iter: 21879  total_loss: 31.16  loss_ce: 0  loss_mask: 0.8236  loss_dice: 2.194  loss_seg: 0.6384  loss_ce_0: 0  loss_mask_0: 0.8394  loss_dice_0: 2.246  loss_ce_1: 0  loss_mask_1: 0.8344  loss_dice_1: 2.21  loss_ce_2: 0  loss_mask_2: 0.8307  loss_dice_2: 2.199  loss_ce_3: 0  loss_mask_3: 0.8295  loss_dice_3: 2.189  loss_ce_4: 0  loss_mask_4: 0.8325  loss_dice_4: 2.187  loss_ce_5: 0  loss_mask_5: 0.8284  loss_dice_5: 2.193  loss_ce_6: 0  loss_mask_6: 0.8274  loss_dice_6: 2.189  loss_ce_7: 0  loss_mask_7: 0.831  loss_dice_7: 2.189  loss_ce_8: 0  loss_mask_8: 0.8314  loss_dice_8: 2.188  time: 1.9198  data_time: 0.0362  lr: 6.6483e-05  max_mem: 6006M
[02/18 11:55:22] d2.utils.events INFO:  eta: 16:36:12  iter: 21899  total_loss: 31.53  loss_ce: 0  loss_mask: 0.7689  loss_dice: 2.264  loss_seg: 0.8266  loss_ce_0: 0  loss_mask_0: 0.7879  loss_dice_0: 2.327  loss_ce_1: 0  loss_mask_1: 0.7724  loss_dice_1: 2.288  loss_ce_2: 0  loss_mask_2: 0.7728  loss_dice_2: 2.27  loss_ce_3: 0  loss_mask_3: 0.772  loss_dice_3: 2.257  loss_ce_4: 0  loss_mask_4: 0.7717  loss_dice_4: 2.262  loss_ce_5: 0  loss_mask_5: 0.7685  loss_dice_5: 2.264  loss_ce_6: 0  loss_mask_6: 0.7756  loss_dice_6: 2.263  loss_ce_7: 0  loss_mask_7: 0.7772  loss_dice_7: 2.254  loss_ce_8: 0  loss_mask_8: 0.7727  loss_dice_8: 2.254  time: 1.9196  data_time: 0.0258  lr: 6.6452e-05  max_mem: 6006M
[02/18 11:55:55] d2.utils.events INFO:  eta: 16:34:50  iter: 21919  total_loss: 30.53  loss_ce: 0  loss_mask: 0.7772  loss_dice: 2.189  loss_seg: 0.7059  loss_ce_0: 0  loss_mask_0: 0.7813  loss_dice_0: 2.246  loss_ce_1: 0  loss_mask_1: 0.7734  loss_dice_1: 2.211  loss_ce_2: 0  loss_mask_2: 0.7796  loss_dice_2: 2.192  loss_ce_3: 0  loss_mask_3: 0.7774  loss_dice_3: 2.182  loss_ce_4: 0  loss_mask_4: 0.7814  loss_dice_4: 2.18  loss_ce_5: 0  loss_mask_5: 0.7807  loss_dice_5: 2.183  loss_ce_6: 0  loss_mask_6: 0.7795  loss_dice_6: 2.178  loss_ce_7: 0  loss_mask_7: 0.7797  loss_dice_7: 2.178  loss_ce_8: 0  loss_mask_8: 0.7803  loss_dice_8: 2.182  time: 1.9194  data_time: 0.0364  lr: 6.642e-05  max_mem: 6006M
[02/18 11:56:29] d2.utils.events INFO:  eta: 16:37:20  iter: 21939  total_loss: 30.65  loss_ce: 0  loss_mask: 0.7772  loss_dice: 2.182  loss_seg: 0.9018  loss_ce_0: 0  loss_mask_0: 0.7838  loss_dice_0: 2.248  loss_ce_1: 0  loss_mask_1: 0.7822  loss_dice_1: 2.196  loss_ce_2: 0  loss_mask_2: 0.7854  loss_dice_2: 2.186  loss_ce_3: 0  loss_mask_3: 0.7825  loss_dice_3: 2.179  loss_ce_4: 0  loss_mask_4: 0.7876  loss_dice_4: 2.175  loss_ce_5: 0  loss_mask_5: 0.786  loss_dice_5: 2.174  loss_ce_6: 0  loss_mask_6: 0.7855  loss_dice_6: 2.173  loss_ce_7: 0  loss_mask_7: 0.7827  loss_dice_7: 2.172  loss_ce_8: 0  loss_mask_8: 0.7837  loss_dice_8: 2.17  time: 1.9192  data_time: 0.0339  lr: 6.6389e-05  max_mem: 6006M
[02/18 11:57:00] d2.utils.events INFO:  eta: 16:34:29  iter: 21959  total_loss: 30.09  loss_ce: 0  loss_mask: 0.7962  loss_dice: 2.149  loss_seg: 0.6104  loss_ce_0: 0  loss_mask_0: 0.8043  loss_dice_0: 2.223  loss_ce_1: 0  loss_mask_1: 0.7942  loss_dice_1: 2.162  loss_ce_2: 0  loss_mask_2: 0.7956  loss_dice_2: 2.15  loss_ce_3: 0  loss_mask_3: 0.7978  loss_dice_3: 2.141  loss_ce_4: 0  loss_mask_4: 0.7967  loss_dice_4: 2.142  loss_ce_5: 0  loss_mask_5: 0.7968  loss_dice_5: 2.136  loss_ce_6: 0  loss_mask_6: 0.7985  loss_dice_6: 2.138  loss_ce_7: 0  loss_mask_7: 0.7987  loss_dice_7: 2.138  loss_ce_8: 0  loss_mask_8: 0.7967  loss_dice_8: 2.139  time: 1.9188  data_time: 0.0328  lr: 6.6358e-05  max_mem: 6006M
[02/18 11:57:30] d2.utils.events INFO:  eta: 16:31:00  iter: 21979  total_loss: 29.79  loss_ce: 0  loss_mask: 0.7481  loss_dice: 2.168  loss_seg: 0.6522  loss_ce_0: 0  loss_mask_0: 0.7657  loss_dice_0: 2.228  loss_ce_1: 0  loss_mask_1: 0.7553  loss_dice_1: 2.184  loss_ce_2: 0  loss_mask_2: 0.7488  loss_dice_2: 2.177  loss_ce_3: 0  loss_mask_3: 0.7521  loss_dice_3: 2.154  loss_ce_4: 0  loss_mask_4: 0.7539  loss_dice_4: 2.155  loss_ce_5: 0  loss_mask_5: 0.7524  loss_dice_5: 2.152  loss_ce_6: 0  loss_mask_6: 0.7542  loss_dice_6: 2.157  loss_ce_7: 0  loss_mask_7: 0.7527  loss_dice_7: 2.154  loss_ce_8: 0  loss_mask_8: 0.7561  loss_dice_8: 2.15  time: 1.9185  data_time: 0.0275  lr: 6.6326e-05  max_mem: 6006M
[02/18 11:58:00] d2.utils.events INFO:  eta: 16:29:09  iter: 21999  total_loss: 29.42  loss_ce: 0  loss_mask: 0.7275  loss_dice: 2.097  loss_seg: 0.7467  loss_ce_0: 0  loss_mask_0: 0.7366  loss_dice_0: 2.173  loss_ce_1: 0  loss_mask_1: 0.7366  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7352  loss_dice_2: 2.086  loss_ce_3: 0  loss_mask_3: 0.7345  loss_dice_3: 2.081  loss_ce_4: 0  loss_mask_4: 0.7361  loss_dice_4: 2.078  loss_ce_5: 0  loss_mask_5: 0.7338  loss_dice_5: 2.078  loss_ce_6: 0  loss_mask_6: 0.7332  loss_dice_6: 2.084  loss_ce_7: 0  loss_mask_7: 0.7347  loss_dice_7: 2.077  loss_ce_8: 0  loss_mask_8: 0.7341  loss_dice_8: 2.079  time: 1.9181  data_time: 0.0351  lr: 6.6295e-05  max_mem: 6006M
[02/18 11:58:32] d2.utils.events INFO:  eta: 16:27:26  iter: 22019  total_loss: 30.28  loss_ce: 0  loss_mask: 0.7705  loss_dice: 2.158  loss_seg: 0.8538  loss_ce_0: 0  loss_mask_0: 0.7999  loss_dice_0: 2.245  loss_ce_1: 0  loss_mask_1: 0.7775  loss_dice_1: 2.18  loss_ce_2: 0  loss_mask_2: 0.778  loss_dice_2: 2.155  loss_ce_3: 0  loss_mask_3: 0.7704  loss_dice_3: 2.152  loss_ce_4: 0  loss_mask_4: 0.7694  loss_dice_4: 2.149  loss_ce_5: 0  loss_mask_5: 0.7732  loss_dice_5: 2.15  loss_ce_6: 0  loss_mask_6: 0.7753  loss_dice_6: 2.146  loss_ce_7: 0  loss_mask_7: 0.7772  loss_dice_7: 2.146  loss_ce_8: 0  loss_mask_8: 0.7753  loss_dice_8: 2.145  time: 1.9178  data_time: 0.0320  lr: 6.6263e-05  max_mem: 6006M
[02/18 11:59:03] d2.utils.events INFO:  eta: 16:26:55  iter: 22039  total_loss: 30.95  loss_ce: 0  loss_mask: 0.7934  loss_dice: 2.195  loss_seg: 0.5157  loss_ce_0: 0  loss_mask_0: 0.818  loss_dice_0: 2.237  loss_ce_1: 0  loss_mask_1: 0.792  loss_dice_1: 2.211  loss_ce_2: 0  loss_mask_2: 0.7937  loss_dice_2: 2.183  loss_ce_3: 0  loss_mask_3: 0.7927  loss_dice_3: 2.171  loss_ce_4: 0  loss_mask_4: 0.7914  loss_dice_4: 2.174  loss_ce_5: 0  loss_mask_5: 0.7956  loss_dice_5: 2.179  loss_ce_6: 0  loss_mask_6: 0.796  loss_dice_6: 2.178  loss_ce_7: 0  loss_mask_7: 0.7946  loss_dice_7: 2.178  loss_ce_8: 0  loss_mask_8: 0.7937  loss_dice_8: 2.185  time: 1.9175  data_time: 0.0277  lr: 6.6232e-05  max_mem: 6006M
[02/18 11:59:36] d2.utils.events INFO:  eta: 16:28:05  iter: 22059  total_loss: 30.47  loss_ce: 0  loss_mask: 0.8068  loss_dice: 2.207  loss_seg: 0.6789  loss_ce_0: 0  loss_mask_0: 0.8233  loss_dice_0: 2.259  loss_ce_1: 0  loss_mask_1: 0.8049  loss_dice_1: 2.205  loss_ce_2: 0  loss_mask_2: 0.809  loss_dice_2: 2.189  loss_ce_3: 0  loss_mask_3: 0.8105  loss_dice_3: 2.189  loss_ce_4: 0  loss_mask_4: 0.8091  loss_dice_4: 2.185  loss_ce_5: 0  loss_mask_5: 0.8087  loss_dice_5: 2.192  loss_ce_6: 0  loss_mask_6: 0.8124  loss_dice_6: 2.197  loss_ce_7: 0  loss_mask_7: 0.8112  loss_dice_7: 2.19  loss_ce_8: 0  loss_mask_8: 0.8076  loss_dice_8: 2.191  time: 1.9172  data_time: 0.0339  lr: 6.6201e-05  max_mem: 6006M
[02/18 12:00:11] d2.utils.events INFO:  eta: 16:31:20  iter: 22079  total_loss: 30.99  loss_ce: 0  loss_mask: 0.8039  loss_dice: 2.157  loss_seg: 1.025  loss_ce_0: 0  loss_mask_0: 0.8098  loss_dice_0: 2.224  loss_ce_1: 0  loss_mask_1: 0.8041  loss_dice_1: 2.173  loss_ce_2: 0  loss_mask_2: 0.8026  loss_dice_2: 2.154  loss_ce_3: 0  loss_mask_3: 0.8072  loss_dice_3: 2.147  loss_ce_4: 0  loss_mask_4: 0.809  loss_dice_4: 2.14  loss_ce_5: 0  loss_mask_5: 0.8118  loss_dice_5: 2.143  loss_ce_6: 0  loss_mask_6: 0.8109  loss_dice_6: 2.14  loss_ce_7: 0  loss_mask_7: 0.8107  loss_dice_7: 2.146  loss_ce_8: 0  loss_mask_8: 0.8112  loss_dice_8: 2.14  time: 1.9170  data_time: 0.0335  lr: 6.6169e-05  max_mem: 6006M
[02/18 12:00:45] d2.utils.events INFO:  eta: 16:30:49  iter: 22099  total_loss: 31.51  loss_ce: 0  loss_mask: 0.7712  loss_dice: 2.234  loss_seg: 0.7871  loss_ce_0: 0  loss_mask_0: 0.7911  loss_dice_0: 2.283  loss_ce_1: 0  loss_mask_1: 0.7798  loss_dice_1: 2.232  loss_ce_2: 0  loss_mask_2: 0.7799  loss_dice_2: 2.222  loss_ce_3: 0  loss_mask_3: 0.781  loss_dice_3: 2.207  loss_ce_4: 0  loss_mask_4: 0.7808  loss_dice_4: 2.212  loss_ce_5: 0  loss_mask_5: 0.7814  loss_dice_5: 2.22  loss_ce_6: 0  loss_mask_6: 0.7827  loss_dice_6: 2.212  loss_ce_7: 0  loss_mask_7: 0.784  loss_dice_7: 2.227  loss_ce_8: 0  loss_mask_8: 0.7801  loss_dice_8: 2.223  time: 1.9168  data_time: 0.0329  lr: 6.6138e-05  max_mem: 6006M
[02/18 12:01:15] d2.utils.events INFO:  eta: 16:31:07  iter: 22119  total_loss: 29.98  loss_ce: 0  loss_mask: 0.7697  loss_dice: 2.118  loss_seg: 0.8059  loss_ce_0: 0  loss_mask_0: 0.7756  loss_dice_0: 2.201  loss_ce_1: 0  loss_mask_1: 0.7718  loss_dice_1: 2.122  loss_ce_2: 0  loss_mask_2: 0.7678  loss_dice_2: 2.107  loss_ce_3: 0  loss_mask_3: 0.7696  loss_dice_3: 2.107  loss_ce_4: 0  loss_mask_4: 0.7688  loss_dice_4: 2.103  loss_ce_5: 0  loss_mask_5: 0.7708  loss_dice_5: 2.11  loss_ce_6: 0  loss_mask_6: 0.7703  loss_dice_6: 2.109  loss_ce_7: 0  loss_mask_7: 0.7661  loss_dice_7: 2.111  loss_ce_8: 0  loss_mask_8: 0.7694  loss_dice_8: 2.11  time: 1.9165  data_time: 0.0344  lr: 6.6106e-05  max_mem: 6006M
[02/18 12:01:48] d2.utils.events INFO:  eta: 16:31:46  iter: 22139  total_loss: 30.42  loss_ce: 0  loss_mask: 0.7642  loss_dice: 2.149  loss_seg: 0.7482  loss_ce_0: 0  loss_mask_0: 0.7814  loss_dice_0: 2.23  loss_ce_1: 0  loss_mask_1: 0.7732  loss_dice_1: 2.173  loss_ce_2: 0  loss_mask_2: 0.7719  loss_dice_2: 2.152  loss_ce_3: 0  loss_mask_3: 0.7793  loss_dice_3: 2.136  loss_ce_4: 0  loss_mask_4: 0.7765  loss_dice_4: 2.133  loss_ce_5: 0  loss_mask_5: 0.7703  loss_dice_5: 2.135  loss_ce_6: 0  loss_mask_6: 0.7705  loss_dice_6: 2.129  loss_ce_7: 0  loss_mask_7: 0.7714  loss_dice_7: 2.135  loss_ce_8: 0  loss_mask_8: 0.7699  loss_dice_8: 2.14  time: 1.9162  data_time: 0.0323  lr: 6.6075e-05  max_mem: 6006M
[02/18 12:02:20] d2.utils.events INFO:  eta: 16:31:05  iter: 22159  total_loss: 28.77  loss_ce: 0  loss_mask: 0.7167  loss_dice: 2.023  loss_seg: 0.6997  loss_ce_0: 0  loss_mask_0: 0.7251  loss_dice_0: 2.124  loss_ce_1: 0  loss_mask_1: 0.7191  loss_dice_1: 2.033  loss_ce_2: 0  loss_mask_2: 0.7171  loss_dice_2: 2.024  loss_ce_3: 0  loss_mask_3: 0.7174  loss_dice_3: 2.006  loss_ce_4: 0  loss_mask_4: 0.7193  loss_dice_4: 2.011  loss_ce_5: 0  loss_mask_5: 0.7174  loss_dice_5: 2.009  loss_ce_6: 0  loss_mask_6: 0.7192  loss_dice_6: 2.005  loss_ce_7: 0  loss_mask_7: 0.7183  loss_dice_7: 2.003  loss_ce_8: 0  loss_mask_8: 0.7192  loss_dice_8: 2.009  time: 1.9159  data_time: 0.0305  lr: 6.6044e-05  max_mem: 6006M
[02/18 12:02:51] d2.utils.events INFO:  eta: 16:30:01  iter: 22179  total_loss: 30.23  loss_ce: 0  loss_mask: 0.7773  loss_dice: 2.129  loss_seg: 0.8669  loss_ce_0: 0  loss_mask_0: 0.7852  loss_dice_0: 2.192  loss_ce_1: 0  loss_mask_1: 0.7853  loss_dice_1: 2.154  loss_ce_2: 0  loss_mask_2: 0.7883  loss_dice_2: 2.126  loss_ce_3: 0  loss_mask_3: 0.7833  loss_dice_3: 2.119  loss_ce_4: 0  loss_mask_4: 0.786  loss_dice_4: 2.115  loss_ce_5: 0  loss_mask_5: 0.7842  loss_dice_5: 2.118  loss_ce_6: 0  loss_mask_6: 0.7826  loss_dice_6: 2.115  loss_ce_7: 0  loss_mask_7: 0.7818  loss_dice_7: 2.113  loss_ce_8: 0  loss_mask_8: 0.7833  loss_dice_8: 2.12  time: 1.9156  data_time: 0.0291  lr: 6.6012e-05  max_mem: 6006M
[02/18 12:03:24] d2.utils.events INFO:  eta: 16:29:47  iter: 22199  total_loss: 28.13  loss_ce: 0  loss_mask: 0.7471  loss_dice: 2.011  loss_seg: 0.6829  loss_ce_0: 0  loss_mask_0: 0.7559  loss_dice_0: 2.052  loss_ce_1: 0  loss_mask_1: 0.7485  loss_dice_1: 2.02  loss_ce_2: 0  loss_mask_2: 0.7527  loss_dice_2: 2.006  loss_ce_3: 0  loss_mask_3: 0.7467  loss_dice_3: 2  loss_ce_4: 0  loss_mask_4: 0.748  loss_dice_4: 1.996  loss_ce_5: 0  loss_mask_5: 0.7489  loss_dice_5: 2.002  loss_ce_6: 0  loss_mask_6: 0.7496  loss_dice_6: 1.996  loss_ce_7: 0  loss_mask_7: 0.7489  loss_dice_7: 2.001  loss_ce_8: 0  loss_mask_8: 0.7472  loss_dice_8: 2.003  time: 1.9154  data_time: 0.0296  lr: 6.5981e-05  max_mem: 6006M
[02/18 12:03:55] d2.utils.events INFO:  eta: 16:28:58  iter: 22219  total_loss: 29.55  loss_ce: 0  loss_mask: 0.7542  loss_dice: 2.076  loss_seg: 0.768  loss_ce_0: 0  loss_mask_0: 0.7481  loss_dice_0: 2.122  loss_ce_1: 0  loss_mask_1: 0.7581  loss_dice_1: 2.083  loss_ce_2: 0  loss_mask_2: 0.7566  loss_dice_2: 2.076  loss_ce_3: 0  loss_mask_3: 0.7546  loss_dice_3: 2.057  loss_ce_4: 0  loss_mask_4: 0.7539  loss_dice_4: 2.066  loss_ce_5: 0  loss_mask_5: 0.7538  loss_dice_5: 2.061  loss_ce_6: 0  loss_mask_6: 0.7549  loss_dice_6: 2.052  loss_ce_7: 0  loss_mask_7: 0.7528  loss_dice_7: 2.06  loss_ce_8: 0  loss_mask_8: 0.7573  loss_dice_8: 2.063  time: 1.9151  data_time: 0.0288  lr: 6.5949e-05  max_mem: 6006M
[02/18 12:04:30] d2.utils.events INFO:  eta: 16:28:59  iter: 22239  total_loss: 28.78  loss_ce: 0  loss_mask: 0.7576  loss_dice: 2.037  loss_seg: 0.8098  loss_ce_0: 0  loss_mask_0: 0.764  loss_dice_0: 2.116  loss_ce_1: 0  loss_mask_1: 0.7695  loss_dice_1: 2.047  loss_ce_2: 0  loss_mask_2: 0.7665  loss_dice_2: 2.034  loss_ce_3: 0  loss_mask_3: 0.7629  loss_dice_3: 2.027  loss_ce_4: 0  loss_mask_4: 0.7632  loss_dice_4: 2.026  loss_ce_5: 0  loss_mask_5: 0.7639  loss_dice_5: 2.027  loss_ce_6: 0  loss_mask_6: 0.7647  loss_dice_6: 2.027  loss_ce_7: 0  loss_mask_7: 0.7611  loss_dice_7: 2.024  loss_ce_8: 0  loss_mask_8: 0.7629  loss_dice_8: 2.023  time: 1.9149  data_time: 0.0281  lr: 6.5918e-05  max_mem: 6006M
[02/18 12:05:04] d2.utils.events INFO:  eta: 16:29:53  iter: 22259  total_loss: 29.19  loss_ce: 0  loss_mask: 0.7714  loss_dice: 2.099  loss_seg: 0.6032  loss_ce_0: 0  loss_mask_0: 0.7809  loss_dice_0: 2.16  loss_ce_1: 0  loss_mask_1: 0.7844  loss_dice_1: 2.121  loss_ce_2: 0  loss_mask_2: 0.7825  loss_dice_2: 2.105  loss_ce_3: 0  loss_mask_3: 0.7876  loss_dice_3: 2.088  loss_ce_4: 0  loss_mask_4: 0.7858  loss_dice_4: 2.092  loss_ce_5: 0  loss_mask_5: 0.7835  loss_dice_5: 2.089  loss_ce_6: 0  loss_mask_6: 0.7851  loss_dice_6: 2.083  loss_ce_7: 0  loss_mask_7: 0.791  loss_dice_7: 2.087  loss_ce_8: 0  loss_mask_8: 0.784  loss_dice_8: 2.085  time: 1.9147  data_time: 0.0265  lr: 6.5886e-05  max_mem: 6006M
[02/18 12:05:36] d2.utils.events INFO:  eta: 16:31:07  iter: 22279  total_loss: 30.62  loss_ce: 0  loss_mask: 0.801  loss_dice: 2.112  loss_seg: 0.6766  loss_ce_0: 0  loss_mask_0: 0.8118  loss_dice_0: 2.205  loss_ce_1: 0  loss_mask_1: 0.8132  loss_dice_1: 2.135  loss_ce_2: 0  loss_mask_2: 0.8089  loss_dice_2: 2.111  loss_ce_3: 0  loss_mask_3: 0.8057  loss_dice_3: 2.1  loss_ce_4: 0  loss_mask_4: 0.8096  loss_dice_4: 2.102  loss_ce_5: 0  loss_mask_5: 0.8088  loss_dice_5: 2.105  loss_ce_6: 0  loss_mask_6: 0.8096  loss_dice_6: 2.108  loss_ce_7: 0  loss_mask_7: 0.8048  loss_dice_7: 2.107  loss_ce_8: 0  loss_mask_8: 0.806  loss_dice_8: 2.102  time: 1.9144  data_time: 0.0348  lr: 6.5855e-05  max_mem: 6006M
[02/18 12:06:08] d2.utils.events INFO:  eta: 16:30:35  iter: 22299  total_loss: 29.47  loss_ce: 0  loss_mask: 0.7719  loss_dice: 2.124  loss_seg: 0.7819  loss_ce_0: 0  loss_mask_0: 0.7768  loss_dice_0: 2.2  loss_ce_1: 0  loss_mask_1: 0.7746  loss_dice_1: 2.15  loss_ce_2: 0  loss_mask_2: 0.7713  loss_dice_2: 2.133  loss_ce_3: 0  loss_mask_3: 0.7719  loss_dice_3: 2.121  loss_ce_4: 0  loss_mask_4: 0.7737  loss_dice_4: 2.118  loss_ce_5: 0  loss_mask_5: 0.7714  loss_dice_5: 2.116  loss_ce_6: 0  loss_mask_6: 0.7741  loss_dice_6: 2.116  loss_ce_7: 0  loss_mask_7: 0.7736  loss_dice_7: 2.119  loss_ce_8: 0  loss_mask_8: 0.7725  loss_dice_8: 2.115  time: 1.9141  data_time: 0.0326  lr: 6.5824e-05  max_mem: 6006M
[02/18 12:06:41] d2.utils.events INFO:  eta: 16:31:25  iter: 22319  total_loss: 30.28  loss_ce: 0  loss_mask: 0.793  loss_dice: 2.149  loss_seg: 0.6122  loss_ce_0: 0  loss_mask_0: 0.8091  loss_dice_0: 2.224  loss_ce_1: 0  loss_mask_1: 0.8018  loss_dice_1: 2.163  loss_ce_2: 0  loss_mask_2: 0.7998  loss_dice_2: 2.152  loss_ce_3: 0  loss_mask_3: 0.8043  loss_dice_3: 2.138  loss_ce_4: 0  loss_mask_4: 0.8047  loss_dice_4: 2.143  loss_ce_5: 0  loss_mask_5: 0.8026  loss_dice_5: 2.141  loss_ce_6: 0  loss_mask_6: 0.8018  loss_dice_6: 2.142  loss_ce_7: 0  loss_mask_7: 0.8029  loss_dice_7: 2.146  loss_ce_8: 0  loss_mask_8: 0.7969  loss_dice_8: 2.142  time: 1.9139  data_time: 0.0265  lr: 6.5792e-05  max_mem: 6006M
[02/18 12:07:13] d2.utils.events INFO:  eta: 16:34:29  iter: 22339  total_loss: 29.12  loss_ce: 0  loss_mask: 0.7705  loss_dice: 2.079  loss_seg: 0.8068  loss_ce_0: 0  loss_mask_0: 0.7799  loss_dice_0: 2.149  loss_ce_1: 0  loss_mask_1: 0.7683  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7684  loss_dice_2: 2.075  loss_ce_3: 0  loss_mask_3: 0.7706  loss_dice_3: 2.068  loss_ce_4: 0  loss_mask_4: 0.7717  loss_dice_4: 2.068  loss_ce_5: 0  loss_mask_5: 0.7773  loss_dice_5: 2.073  loss_ce_6: 0  loss_mask_6: 0.7693  loss_dice_6: 2.067  loss_ce_7: 0  loss_mask_7: 0.7685  loss_dice_7: 2.072  loss_ce_8: 0  loss_mask_8: 0.7702  loss_dice_8: 2.073  time: 1.9136  data_time: 0.0315  lr: 6.5761e-05  max_mem: 6006M
[02/18 12:07:48] d2.utils.events INFO:  eta: 16:36:07  iter: 22359  total_loss: 31.1  loss_ce: 0  loss_mask: 0.7679  loss_dice: 2.23  loss_seg: 0.7139  loss_ce_0: 0  loss_mask_0: 0.7794  loss_dice_0: 2.278  loss_ce_1: 0  loss_mask_1: 0.768  loss_dice_1: 2.244  loss_ce_2: 0  loss_mask_2: 0.7703  loss_dice_2: 2.226  loss_ce_3: 0  loss_mask_3: 0.7718  loss_dice_3: 2.221  loss_ce_4: 0  loss_mask_4: 0.7705  loss_dice_4: 2.219  loss_ce_5: 0  loss_mask_5: 0.7703  loss_dice_5: 2.226  loss_ce_6: 0  loss_mask_6: 0.7705  loss_dice_6: 2.221  loss_ce_7: 0  loss_mask_7: 0.7703  loss_dice_7: 2.219  loss_ce_8: 0  loss_mask_8: 0.7672  loss_dice_8: 2.218  time: 1.9134  data_time: 0.0283  lr: 6.5729e-05  max_mem: 6006M
[02/18 12:08:22] d2.utils.events INFO:  eta: 16:36:16  iter: 22379  total_loss: 31.3  loss_ce: 0  loss_mask: 0.7925  loss_dice: 2.238  loss_seg: 0.6118  loss_ce_0: 0  loss_mask_0: 0.8045  loss_dice_0: 2.261  loss_ce_1: 0  loss_mask_1: 0.8091  loss_dice_1: 2.251  loss_ce_2: 0  loss_mask_2: 0.8131  loss_dice_2: 2.236  loss_ce_3: 0  loss_mask_3: 0.8076  loss_dice_3: 2.229  loss_ce_4: 0  loss_mask_4: 0.8095  loss_dice_4: 2.231  loss_ce_5: 0  loss_mask_5: 0.8046  loss_dice_5: 2.234  loss_ce_6: 0  loss_mask_6: 0.806  loss_dice_6: 2.23  loss_ce_7: 0  loss_mask_7: 0.8045  loss_dice_7: 2.235  loss_ce_8: 0  loss_mask_8: 0.8065  loss_dice_8: 2.233  time: 1.9133  data_time: 0.0277  lr: 6.5698e-05  max_mem: 6006M
[02/18 12:08:55] d2.utils.events INFO:  eta: 16:36:31  iter: 22399  total_loss: 30.56  loss_ce: 0  loss_mask: 0.7896  loss_dice: 2.126  loss_seg: 0.6017  loss_ce_0: 0  loss_mask_0: 0.7988  loss_dice_0: 2.165  loss_ce_1: 0  loss_mask_1: 0.7876  loss_dice_1: 2.127  loss_ce_2: 0  loss_mask_2: 0.7904  loss_dice_2: 2.118  loss_ce_3: 0  loss_mask_3: 0.7925  loss_dice_3: 2.113  loss_ce_4: 0  loss_mask_4: 0.7913  loss_dice_4: 2.116  loss_ce_5: 0  loss_mask_5: 0.7891  loss_dice_5: 2.115  loss_ce_6: 0  loss_mask_6: 0.7961  loss_dice_6: 2.114  loss_ce_7: 0  loss_mask_7: 0.7967  loss_dice_7: 2.116  loss_ce_8: 0  loss_mask_8: 0.7949  loss_dice_8: 2.114  time: 1.9130  data_time: 0.0295  lr: 6.5666e-05  max_mem: 6006M
[02/18 12:09:28] d2.utils.events INFO:  eta: 16:36:43  iter: 22419  total_loss: 29.86  loss_ce: 0  loss_mask: 0.7545  loss_dice: 2.12  loss_seg: 0.6825  loss_ce_0: 0  loss_mask_0: 0.7571  loss_dice_0: 2.189  loss_ce_1: 0  loss_mask_1: 0.761  loss_dice_1: 2.135  loss_ce_2: 0  loss_mask_2: 0.7671  loss_dice_2: 2.119  loss_ce_3: 0  loss_mask_3: 0.7624  loss_dice_3: 2.103  loss_ce_4: 0  loss_mask_4: 0.7656  loss_dice_4: 2.11  loss_ce_5: 0  loss_mask_5: 0.7608  loss_dice_5: 2.11  loss_ce_6: 0  loss_mask_6: 0.757  loss_dice_6: 2.109  loss_ce_7: 0  loss_mask_7: 0.7611  loss_dice_7: 2.106  loss_ce_8: 0  loss_mask_8: 0.7587  loss_dice_8: 2.107  time: 1.9128  data_time: 0.0334  lr: 6.5635e-05  max_mem: 6006M
[02/18 12:10:01] d2.utils.events INFO:  eta: 16:36:11  iter: 22439  total_loss: 30.31  loss_ce: 0  loss_mask: 0.7979  loss_dice: 2.171  loss_seg: 0.5967  loss_ce_0: 0  loss_mask_0: 0.807  loss_dice_0: 2.214  loss_ce_1: 0  loss_mask_1: 0.7939  loss_dice_1: 2.187  loss_ce_2: 0  loss_mask_2: 0.7935  loss_dice_2: 2.174  loss_ce_3: 0  loss_mask_3: 0.7977  loss_dice_3: 2.168  loss_ce_4: 0  loss_mask_4: 0.7978  loss_dice_4: 2.167  loss_ce_5: 0  loss_mask_5: 0.7979  loss_dice_5: 2.165  loss_ce_6: 0  loss_mask_6: 0.7983  loss_dice_6: 2.16  loss_ce_7: 0  loss_mask_7: 0.8003  loss_dice_7: 2.164  loss_ce_8: 0  loss_mask_8: 0.8009  loss_dice_8: 2.164  time: 1.9125  data_time: 0.0379  lr: 6.5604e-05  max_mem: 6006M
[02/18 12:10:34] d2.utils.events INFO:  eta: 16:37:04  iter: 22459  total_loss: 31.3  loss_ce: 0  loss_mask: 0.7625  loss_dice: 2.256  loss_seg: 0.8826  loss_ce_0: 0  loss_mask_0: 0.7675  loss_dice_0: 2.312  loss_ce_1: 0  loss_mask_1: 0.7544  loss_dice_1: 2.265  loss_ce_2: 0  loss_mask_2: 0.7569  loss_dice_2: 2.258  loss_ce_3: 0  loss_mask_3: 0.7658  loss_dice_3: 2.246  loss_ce_4: 0  loss_mask_4: 0.7637  loss_dice_4: 2.239  loss_ce_5: 0  loss_mask_5: 0.7668  loss_dice_5: 2.243  loss_ce_6: 0  loss_mask_6: 0.7648  loss_dice_6: 2.241  loss_ce_7: 0  loss_mask_7: 0.7643  loss_dice_7: 2.24  loss_ce_8: 0  loss_mask_8: 0.7626  loss_dice_8: 2.243  time: 1.9123  data_time: 0.0320  lr: 6.5572e-05  max_mem: 6006M
[02/18 12:11:04] d2.utils.events INFO:  eta: 16:35:12  iter: 22479  total_loss: 28.34  loss_ce: 0  loss_mask: 0.7321  loss_dice: 2.057  loss_seg: 0.6323  loss_ce_0: 0  loss_mask_0: 0.7373  loss_dice_0: 2.122  loss_ce_1: 0  loss_mask_1: 0.7281  loss_dice_1: 2.067  loss_ce_2: 0  loss_mask_2: 0.725  loss_dice_2: 2.062  loss_ce_3: 0  loss_mask_3: 0.7306  loss_dice_3: 2.051  loss_ce_4: 0  loss_mask_4: 0.7322  loss_dice_4: 2.055  loss_ce_5: 0  loss_mask_5: 0.7325  loss_dice_5: 2.056  loss_ce_6: 0  loss_mask_6: 0.7307  loss_dice_6: 2.057  loss_ce_7: 0  loss_mask_7: 0.7344  loss_dice_7: 2.051  loss_ce_8: 0  loss_mask_8: 0.7295  loss_dice_8: 2.054  time: 1.9119  data_time: 0.0406  lr: 6.5541e-05  max_mem: 6006M
[02/18 12:11:35] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 12:11:35] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 12:11:35] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 12:11:49] mask2former INFO: Inference done 11/1093. Dataloading: 0.0036 s/iter. Inference: 0.2297 s/iter. Eval: 0.1064 s/iter. Total: 0.3397 s/iter. ETA=0:06:07
[02/18 12:11:54] mask2former INFO: Inference done 25/1093. Dataloading: 0.0050 s/iter. Inference: 0.2396 s/iter. Eval: 0.1072 s/iter. Total: 0.3519 s/iter. ETA=0:06:15
[02/18 12:11:59] mask2former INFO: Inference done 39/1093. Dataloading: 0.0050 s/iter. Inference: 0.2388 s/iter. Eval: 0.1107 s/iter. Total: 0.3546 s/iter. ETA=0:06:13
[02/18 12:12:04] mask2former INFO: Inference done 53/1093. Dataloading: 0.0052 s/iter. Inference: 0.2426 s/iter. Eval: 0.1098 s/iter. Total: 0.3577 s/iter. ETA=0:06:11
[02/18 12:12:09] mask2former INFO: Inference done 68/1093. Dataloading: 0.0051 s/iter. Inference: 0.2436 s/iter. Eval: 0.1095 s/iter. Total: 0.3582 s/iter. ETA=0:06:07
[02/18 12:12:15] mask2former INFO: Inference done 83/1093. Dataloading: 0.0054 s/iter. Inference: 0.2427 s/iter. Eval: 0.1092 s/iter. Total: 0.3575 s/iter. ETA=0:06:01
[02/18 12:12:20] mask2former INFO: Inference done 97/1093. Dataloading: 0.0053 s/iter. Inference: 0.2404 s/iter. Eval: 0.1117 s/iter. Total: 0.3575 s/iter. ETA=0:05:56
[02/18 12:12:25] mask2former INFO: Inference done 111/1093. Dataloading: 0.0053 s/iter. Inference: 0.2413 s/iter. Eval: 0.1135 s/iter. Total: 0.3601 s/iter. ETA=0:05:53
[02/18 12:12:30] mask2former INFO: Inference done 126/1093. Dataloading: 0.0053 s/iter. Inference: 0.2404 s/iter. Eval: 0.1130 s/iter. Total: 0.3588 s/iter. ETA=0:05:46
[02/18 12:12:35] mask2former INFO: Inference done 140/1093. Dataloading: 0.0053 s/iter. Inference: 0.2415 s/iter. Eval: 0.1135 s/iter. Total: 0.3605 s/iter. ETA=0:05:43
[02/18 12:12:41] mask2former INFO: Inference done 155/1093. Dataloading: 0.0054 s/iter. Inference: 0.2407 s/iter. Eval: 0.1133 s/iter. Total: 0.3594 s/iter. ETA=0:05:37
[02/18 12:12:46] mask2former INFO: Inference done 170/1093. Dataloading: 0.0053 s/iter. Inference: 0.2402 s/iter. Eval: 0.1133 s/iter. Total: 0.3588 s/iter. ETA=0:05:31
[02/18 12:12:51] mask2former INFO: Inference done 185/1093. Dataloading: 0.0053 s/iter. Inference: 0.2396 s/iter. Eval: 0.1125 s/iter. Total: 0.3574 s/iter. ETA=0:05:24
[02/18 12:12:56] mask2former INFO: Inference done 199/1093. Dataloading: 0.0053 s/iter. Inference: 0.2399 s/iter. Eval: 0.1128 s/iter. Total: 0.3581 s/iter. ETA=0:05:20
[02/18 12:13:01] mask2former INFO: Inference done 214/1093. Dataloading: 0.0053 s/iter. Inference: 0.2392 s/iter. Eval: 0.1128 s/iter. Total: 0.3574 s/iter. ETA=0:05:14
[02/18 12:13:07] mask2former INFO: Inference done 228/1093. Dataloading: 0.0053 s/iter. Inference: 0.2396 s/iter. Eval: 0.1130 s/iter. Total: 0.3580 s/iter. ETA=0:05:09
[02/18 12:13:12] mask2former INFO: Inference done 243/1093. Dataloading: 0.0054 s/iter. Inference: 0.2396 s/iter. Eval: 0.1126 s/iter. Total: 0.3577 s/iter. ETA=0:05:04
[02/18 12:13:17] mask2former INFO: Inference done 257/1093. Dataloading: 0.0054 s/iter. Inference: 0.2399 s/iter. Eval: 0.1125 s/iter. Total: 0.3579 s/iter. ETA=0:04:59
[02/18 12:13:22] mask2former INFO: Inference done 271/1093. Dataloading: 0.0054 s/iter. Inference: 0.2398 s/iter. Eval: 0.1127 s/iter. Total: 0.3580 s/iter. ETA=0:04:54
[02/18 12:13:27] mask2former INFO: Inference done 286/1093. Dataloading: 0.0054 s/iter. Inference: 0.2401 s/iter. Eval: 0.1121 s/iter. Total: 0.3576 s/iter. ETA=0:04:48
[02/18 12:13:33] mask2former INFO: Inference done 301/1093. Dataloading: 0.0054 s/iter. Inference: 0.2397 s/iter. Eval: 0.1123 s/iter. Total: 0.3575 s/iter. ETA=0:04:43
[02/18 12:13:38] mask2former INFO: Inference done 316/1093. Dataloading: 0.0054 s/iter. Inference: 0.2393 s/iter. Eval: 0.1120 s/iter. Total: 0.3567 s/iter. ETA=0:04:37
[02/18 12:13:43] mask2former INFO: Inference done 329/1093. Dataloading: 0.0059 s/iter. Inference: 0.2391 s/iter. Eval: 0.1128 s/iter. Total: 0.3579 s/iter. ETA=0:04:33
[02/18 12:13:48] mask2former INFO: Inference done 344/1093. Dataloading: 0.0059 s/iter. Inference: 0.2388 s/iter. Eval: 0.1126 s/iter. Total: 0.3574 s/iter. ETA=0:04:27
[02/18 12:13:53] mask2former INFO: Inference done 358/1093. Dataloading: 0.0059 s/iter. Inference: 0.2389 s/iter. Eval: 0.1125 s/iter. Total: 0.3574 s/iter. ETA=0:04:22
[02/18 12:13:58] mask2former INFO: Inference done 371/1093. Dataloading: 0.0059 s/iter. Inference: 0.2394 s/iter. Eval: 0.1136 s/iter. Total: 0.3590 s/iter. ETA=0:04:19
[02/18 12:14:03] mask2former INFO: Inference done 385/1093. Dataloading: 0.0059 s/iter. Inference: 0.2396 s/iter. Eval: 0.1139 s/iter. Total: 0.3595 s/iter. ETA=0:04:14
[02/18 12:14:08] mask2former INFO: Inference done 398/1093. Dataloading: 0.0059 s/iter. Inference: 0.2401 s/iter. Eval: 0.1146 s/iter. Total: 0.3607 s/iter. ETA=0:04:10
[02/18 12:14:14] mask2former INFO: Inference done 412/1093. Dataloading: 0.0058 s/iter. Inference: 0.2406 s/iter. Eval: 0.1145 s/iter. Total: 0.3611 s/iter. ETA=0:04:05
[02/18 12:14:19] mask2former INFO: Inference done 425/1093. Dataloading: 0.0059 s/iter. Inference: 0.2408 s/iter. Eval: 0.1154 s/iter. Total: 0.3622 s/iter. ETA=0:04:01
[02/18 12:14:24] mask2former INFO: Inference done 438/1093. Dataloading: 0.0059 s/iter. Inference: 0.2415 s/iter. Eval: 0.1156 s/iter. Total: 0.3630 s/iter. ETA=0:03:57
[02/18 12:14:29] mask2former INFO: Inference done 450/1093. Dataloading: 0.0059 s/iter. Inference: 0.2422 s/iter. Eval: 0.1165 s/iter. Total: 0.3648 s/iter. ETA=0:03:54
[02/18 12:14:34] mask2former INFO: Inference done 464/1093. Dataloading: 0.0059 s/iter. Inference: 0.2423 s/iter. Eval: 0.1167 s/iter. Total: 0.3650 s/iter. ETA=0:03:49
[02/18 12:14:39] mask2former INFO: Inference done 478/1093. Dataloading: 0.0059 s/iter. Inference: 0.2426 s/iter. Eval: 0.1164 s/iter. Total: 0.3649 s/iter. ETA=0:03:44
[02/18 12:14:44] mask2former INFO: Inference done 492/1093. Dataloading: 0.0058 s/iter. Inference: 0.2427 s/iter. Eval: 0.1161 s/iter. Total: 0.3647 s/iter. ETA=0:03:39
[02/18 12:14:50] mask2former INFO: Inference done 507/1093. Dataloading: 0.0058 s/iter. Inference: 0.2429 s/iter. Eval: 0.1157 s/iter. Total: 0.3645 s/iter. ETA=0:03:33
[02/18 12:14:55] mask2former INFO: Inference done 521/1093. Dataloading: 0.0058 s/iter. Inference: 0.2429 s/iter. Eval: 0.1159 s/iter. Total: 0.3647 s/iter. ETA=0:03:28
[02/18 12:15:00] mask2former INFO: Inference done 535/1093. Dataloading: 0.0058 s/iter. Inference: 0.2431 s/iter. Eval: 0.1160 s/iter. Total: 0.3650 s/iter. ETA=0:03:23
[02/18 12:15:05] mask2former INFO: Inference done 550/1093. Dataloading: 0.0058 s/iter. Inference: 0.2428 s/iter. Eval: 0.1159 s/iter. Total: 0.3645 s/iter. ETA=0:03:17
[02/18 12:15:11] mask2former INFO: Inference done 565/1093. Dataloading: 0.0057 s/iter. Inference: 0.2425 s/iter. Eval: 0.1157 s/iter. Total: 0.3640 s/iter. ETA=0:03:12
[02/18 12:15:16] mask2former INFO: Inference done 579/1093. Dataloading: 0.0058 s/iter. Inference: 0.2425 s/iter. Eval: 0.1158 s/iter. Total: 0.3642 s/iter. ETA=0:03:07
[02/18 12:15:21] mask2former INFO: Inference done 593/1093. Dataloading: 0.0058 s/iter. Inference: 0.2426 s/iter. Eval: 0.1157 s/iter. Total: 0.3641 s/iter. ETA=0:03:02
[02/18 12:15:26] mask2former INFO: Inference done 608/1093. Dataloading: 0.0057 s/iter. Inference: 0.2423 s/iter. Eval: 0.1155 s/iter. Total: 0.3637 s/iter. ETA=0:02:56
[02/18 12:15:31] mask2former INFO: Inference done 623/1093. Dataloading: 0.0057 s/iter. Inference: 0.2423 s/iter. Eval: 0.1151 s/iter. Total: 0.3632 s/iter. ETA=0:02:50
[02/18 12:15:36] mask2former INFO: Inference done 637/1093. Dataloading: 0.0057 s/iter. Inference: 0.2427 s/iter. Eval: 0.1149 s/iter. Total: 0.3634 s/iter. ETA=0:02:45
[02/18 12:15:41] mask2former INFO: Inference done 651/1093. Dataloading: 0.0057 s/iter. Inference: 0.2428 s/iter. Eval: 0.1148 s/iter. Total: 0.3635 s/iter. ETA=0:02:40
[02/18 12:15:47] mask2former INFO: Inference done 664/1093. Dataloading: 0.0057 s/iter. Inference: 0.2428 s/iter. Eval: 0.1152 s/iter. Total: 0.3639 s/iter. ETA=0:02:36
[02/18 12:15:52] mask2former INFO: Inference done 678/1093. Dataloading: 0.0057 s/iter. Inference: 0.2431 s/iter. Eval: 0.1150 s/iter. Total: 0.3639 s/iter. ETA=0:02:31
[02/18 12:15:57] mask2former INFO: Inference done 692/1093. Dataloading: 0.0057 s/iter. Inference: 0.2432 s/iter. Eval: 0.1150 s/iter. Total: 0.3640 s/iter. ETA=0:02:25
[02/18 12:16:02] mask2former INFO: Inference done 706/1093. Dataloading: 0.0057 s/iter. Inference: 0.2432 s/iter. Eval: 0.1150 s/iter. Total: 0.3640 s/iter. ETA=0:02:20
[02/18 12:16:07] mask2former INFO: Inference done 722/1093. Dataloading: 0.0057 s/iter. Inference: 0.2426 s/iter. Eval: 0.1150 s/iter. Total: 0.3634 s/iter. ETA=0:02:14
[02/18 12:16:12] mask2former INFO: Inference done 736/1093. Dataloading: 0.0057 s/iter. Inference: 0.2425 s/iter. Eval: 0.1152 s/iter. Total: 0.3634 s/iter. ETA=0:02:09
[02/18 12:16:18] mask2former INFO: Inference done 751/1093. Dataloading: 0.0056 s/iter. Inference: 0.2423 s/iter. Eval: 0.1150 s/iter. Total: 0.3630 s/iter. ETA=0:02:04
[02/18 12:16:23] mask2former INFO: Inference done 766/1093. Dataloading: 0.0056 s/iter. Inference: 0.2421 s/iter. Eval: 0.1148 s/iter. Total: 0.3626 s/iter. ETA=0:01:58
[02/18 12:16:28] mask2former INFO: Inference done 780/1093. Dataloading: 0.0056 s/iter. Inference: 0.2420 s/iter. Eval: 0.1148 s/iter. Total: 0.3626 s/iter. ETA=0:01:53
[02/18 12:16:33] mask2former INFO: Inference done 795/1093. Dataloading: 0.0056 s/iter. Inference: 0.2418 s/iter. Eval: 0.1148 s/iter. Total: 0.3624 s/iter. ETA=0:01:47
[02/18 12:16:38] mask2former INFO: Inference done 810/1093. Dataloading: 0.0056 s/iter. Inference: 0.2418 s/iter. Eval: 0.1148 s/iter. Total: 0.3622 s/iter. ETA=0:01:42
[02/18 12:16:44] mask2former INFO: Inference done 824/1093. Dataloading: 0.0056 s/iter. Inference: 0.2422 s/iter. Eval: 0.1147 s/iter. Total: 0.3626 s/iter. ETA=0:01:37
[02/18 12:16:49] mask2former INFO: Inference done 839/1093. Dataloading: 0.0056 s/iter. Inference: 0.2420 s/iter. Eval: 0.1148 s/iter. Total: 0.3624 s/iter. ETA=0:01:32
[02/18 12:16:54] mask2former INFO: Inference done 854/1093. Dataloading: 0.0055 s/iter. Inference: 0.2420 s/iter. Eval: 0.1146 s/iter. Total: 0.3622 s/iter. ETA=0:01:26
[02/18 12:16:59] mask2former INFO: Inference done 868/1093. Dataloading: 0.0056 s/iter. Inference: 0.2420 s/iter. Eval: 0.1146 s/iter. Total: 0.3622 s/iter. ETA=0:01:21
[02/18 12:17:05] mask2former INFO: Inference done 883/1093. Dataloading: 0.0055 s/iter. Inference: 0.2419 s/iter. Eval: 0.1144 s/iter. Total: 0.3620 s/iter. ETA=0:01:16
[02/18 12:17:10] mask2former INFO: Inference done 898/1093. Dataloading: 0.0055 s/iter. Inference: 0.2420 s/iter. Eval: 0.1142 s/iter. Total: 0.3618 s/iter. ETA=0:01:10
[02/18 12:17:15] mask2former INFO: Inference done 911/1093. Dataloading: 0.0055 s/iter. Inference: 0.2423 s/iter. Eval: 0.1143 s/iter. Total: 0.3622 s/iter. ETA=0:01:05
[02/18 12:17:20] mask2former INFO: Inference done 925/1093. Dataloading: 0.0055 s/iter. Inference: 0.2424 s/iter. Eval: 0.1142 s/iter. Total: 0.3623 s/iter. ETA=0:01:00
[02/18 12:17:25] mask2former INFO: Inference done 940/1093. Dataloading: 0.0055 s/iter. Inference: 0.2425 s/iter. Eval: 0.1141 s/iter. Total: 0.3622 s/iter. ETA=0:00:55
[02/18 12:17:31] mask2former INFO: Inference done 954/1093. Dataloading: 0.0055 s/iter. Inference: 0.2425 s/iter. Eval: 0.1142 s/iter. Total: 0.3623 s/iter. ETA=0:00:50
[02/18 12:17:36] mask2former INFO: Inference done 968/1093. Dataloading: 0.0055 s/iter. Inference: 0.2422 s/iter. Eval: 0.1145 s/iter. Total: 0.3623 s/iter. ETA=0:00:45
[02/18 12:17:41] mask2former INFO: Inference done 983/1093. Dataloading: 0.0055 s/iter. Inference: 0.2420 s/iter. Eval: 0.1145 s/iter. Total: 0.3621 s/iter. ETA=0:00:39
[02/18 12:17:46] mask2former INFO: Inference done 996/1093. Dataloading: 0.0055 s/iter. Inference: 0.2422 s/iter. Eval: 0.1146 s/iter. Total: 0.3624 s/iter. ETA=0:00:35
[02/18 12:17:51] mask2former INFO: Inference done 1011/1093. Dataloading: 0.0055 s/iter. Inference: 0.2419 s/iter. Eval: 0.1147 s/iter. Total: 0.3621 s/iter. ETA=0:00:29
[02/18 12:17:56] mask2former INFO: Inference done 1025/1093. Dataloading: 0.0055 s/iter. Inference: 0.2419 s/iter. Eval: 0.1148 s/iter. Total: 0.3622 s/iter. ETA=0:00:24
[02/18 12:18:01] mask2former INFO: Inference done 1040/1093. Dataloading: 0.0055 s/iter. Inference: 0.2418 s/iter. Eval: 0.1146 s/iter. Total: 0.3619 s/iter. ETA=0:00:19
[02/18 12:18:06] mask2former INFO: Inference done 1053/1093. Dataloading: 0.0055 s/iter. Inference: 0.2420 s/iter. Eval: 0.1147 s/iter. Total: 0.3623 s/iter. ETA=0:00:14
[02/18 12:18:12] mask2former INFO: Inference done 1068/1093. Dataloading: 0.0055 s/iter. Inference: 0.2419 s/iter. Eval: 0.1147 s/iter. Total: 0.3621 s/iter. ETA=0:00:09
[02/18 12:18:17] mask2former INFO: Inference done 1083/1093. Dataloading: 0.0054 s/iter. Inference: 0.2419 s/iter. Eval: 0.1146 s/iter. Total: 0.3620 s/iter. ETA=0:00:03
[02/18 12:18:50] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.3997450425272717, 'error_1pix': 0.3229761208281318, 'error_3pix': 0.19444782060724655, 'mIoU': 18.038393450567273, 'fwIoU': 40.61148305142205, 'IoU-1': 93.7880092529635, 'IoU-2': 0.02051718659133202, 'IoU-3': 0.05501550353421799, 'IoU-4': 0.013929500340628957, 'IoU-5': 0.0085486281588962, 'IoU-6': 0.014527540180754884, 'IoU-7': 0.013258607344551787, 'IoU-8': 0.008678942684751464, 'IoU-9': 1.009743258036638, 'IoU-10': 11.413864009815253, 'IoU-11': 8.64359711911333, 'IoU-12': 38.70232877101223, 'IoU-13': 26.754157059588646, 'IoU-14': 23.058057629970282, 'IoU-15': 19.285085042826257, 'IoU-16': 21.708411131881768, 'IoU-17': 16.344318111764927, 'IoU-18': 6.632536719248774, 'IoU-19': 6.270066982333851, 'IoU-20': 29.646587342642594, 'IoU-21': 31.212737069530803, 'IoU-22': 20.87523727495028, 'IoU-23': 13.008699276622353, 'IoU-24': 10.416475916774141, 'IoU-25': 9.985379281079256, 'IoU-26': 23.507549273812526, 'IoU-27': 28.183046635300514, 'IoU-28': 26.24181895585557, 'IoU-29': 21.297343811213594, 'IoU-30': 26.398251889021612, 'IoU-31': 29.961151884257013, 'IoU-32': 35.91680451970402, 'IoU-33': 18.501839580016906, 'IoU-34': 21.13257073484896, 'IoU-35': 28.7238613858789, 'IoU-36': 34.45781749516447, 'IoU-37': 31.67977246365336, 'IoU-38': 18.87652066377213, 'IoU-39': 10.758521798656679, 'IoU-40': 9.22013291498099, 'IoU-41': 9.235633111288523, 'IoU-42': 9.562155290486125, 'IoU-43': 29.315119022966446, 'IoU-44': 19.46011563857198, 'IoU-45': 11.621198877600072, 'IoU-46': 12.317480998027662, 'IoU-47': 11.032494486585843, 'IoU-48': 9.551917036575201, 'mACC': 30.59066485358739, 'pACC': 49.54415640226702, 'ACC-1': 95.89403470511499, 'ACC-2': 0.02051720942151242, 'ACC-3': 0.06333055270973355, 'ACC-4': 0.014801694607456572, 'ACC-5': 0.008823218004070444, 'ACC-6': 0.014823892161125826, 'ACC-7': 0.013462133202350415, 'ACC-8': 0.008763571192290032, 'ACC-9': 69.82505694137915, 'ACC-10': 15.943298386153609, 'ACC-11': 9.711594372868548, 'ACC-12': 79.81430480121067, 'ACC-13': 35.608761550052996, 'ACC-14': 28.64856648657863, 'ACC-15': 28.554923842687842, 'ACC-16': 37.08232532433865, 'ACC-17': 27.199689289736323, 'ACC-18': 10.333617315410136, 'ACC-19': 11.370011516697684, 'ACC-20': 74.21105394016764, 'ACC-21': 44.292866195049314, 'ACC-22': 27.794308919851403, 'ACC-23': 20.203284710496035, 'ACC-24': 18.86154579189989, 'ACC-25': 19.14396640664026, 'ACC-26': 47.11529970763631, 'ACC-27': 46.42991250789667, 'ACC-28': 41.26485832704066, 'ACC-29': 32.91293260847865, 'ACC-30': 45.49434957374655, 'ACC-31': 47.688564685370345, 'ACC-32': 70.11562897640633, 'ACC-33': 29.675095169697368, 'ACC-34': 29.499563698974672, 'ACC-35': 38.70850164807666, 'ACC-36': 51.05609077412823, 'ACC-37': 46.53193423590365, 'ACC-38': 26.301827349007272, 'ACC-39': 15.919305823350548, 'ACC-40': 15.191093439344696, 'ACC-41': 18.1485214802433, 'ACC-42': 19.91378468321534, 'ACC-43': 74.23348984990005, 'ACC-44': 39.150123093259666, 'ACC-45': 21.429411331699868, 'ACC-46': 22.422747759233367, 'ACC-47': 18.360520855536823, 'ACC-48': 16.15062262641536})])
[02/18 12:18:50] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 12:18:50] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 12:18:50] d2.evaluation.testing INFO: copypaste: 2.3997,0.3230,0.1944,18.0384,40.6115,30.5907,49.5442
[02/18 12:18:50] d2.utils.events INFO:  eta: 16:34:40  iter: 22499  total_loss: 29.06  loss_ce: 0  loss_mask: 0.7399  loss_dice: 2.03  loss_seg: 0.7417  loss_ce_0: 0  loss_mask_0: 0.7431  loss_dice_0: 2.108  loss_ce_1: 0  loss_mask_1: 0.7369  loss_dice_1: 2.031  loss_ce_2: 0  loss_mask_2: 0.7417  loss_dice_2: 2.023  loss_ce_3: 0  loss_mask_3: 0.7442  loss_dice_3: 2.017  loss_ce_4: 0  loss_mask_4: 0.7447  loss_dice_4: 2.017  loss_ce_5: 0  loss_mask_5: 0.7472  loss_dice_5: 2.018  loss_ce_6: 0  loss_mask_6: 0.7499  loss_dice_6: 2.026  loss_ce_7: 0  loss_mask_7: 0.7463  loss_dice_7: 2.021  loss_ce_8: 0  loss_mask_8: 0.7431  loss_dice_8: 2.021  time: 1.9116  data_time: 0.0394  lr: 6.5509e-05  max_mem: 6006M
[02/18 12:19:22] d2.utils.events INFO:  eta: 16:35:28  iter: 22519  total_loss: 29.41  loss_ce: 0  loss_mask: 0.755  loss_dice: 2.068  loss_seg: 0.6905  loss_ce_0: 0  loss_mask_0: 0.7682  loss_dice_0: 2.138  loss_ce_1: 0  loss_mask_1: 0.7607  loss_dice_1: 2.079  loss_ce_2: 0  loss_mask_2: 0.7633  loss_dice_2: 2.065  loss_ce_3: 0  loss_mask_3: 0.7638  loss_dice_3: 2.058  loss_ce_4: 0  loss_mask_4: 0.7613  loss_dice_4: 2.059  loss_ce_5: 0  loss_mask_5: 0.7589  loss_dice_5: 2.06  loss_ce_6: 0  loss_mask_6: 0.7588  loss_dice_6: 2.05  loss_ce_7: 0  loss_mask_7: 0.761  loss_dice_7: 2.054  loss_ce_8: 0  loss_mask_8: 0.7599  loss_dice_8: 2.057  time: 1.9113  data_time: 0.0325  lr: 6.5478e-05  max_mem: 6006M
[02/18 12:19:55] d2.utils.events INFO:  eta: 16:35:56  iter: 22539  total_loss: 31.07  loss_ce: 0  loss_mask: 0.7611  loss_dice: 2.252  loss_seg: 0.9255  loss_ce_0: 0  loss_mask_0: 0.7754  loss_dice_0: 2.322  loss_ce_1: 0  loss_mask_1: 0.7589  loss_dice_1: 2.274  loss_ce_2: 0  loss_mask_2: 0.7622  loss_dice_2: 2.253  loss_ce_3: 0  loss_mask_3: 0.765  loss_dice_3: 2.246  loss_ce_4: 0  loss_mask_4: 0.7646  loss_dice_4: 2.248  loss_ce_5: 0  loss_mask_5: 0.7643  loss_dice_5: 2.255  loss_ce_6: 0  loss_mask_6: 0.7654  loss_dice_6: 2.246  loss_ce_7: 0  loss_mask_7: 0.765  loss_dice_7: 2.247  loss_ce_8: 0  loss_mask_8: 0.7662  loss_dice_8: 2.244  time: 1.9111  data_time: 0.0366  lr: 6.5446e-05  max_mem: 6006M
[02/18 12:20:26] d2.utils.events INFO:  eta: 16:33:46  iter: 22559  total_loss: 28.26  loss_ce: 0  loss_mask: 0.7529  loss_dice: 1.986  loss_seg: 0.7597  loss_ce_0: 0  loss_mask_0: 0.7618  loss_dice_0: 2.061  loss_ce_1: 0  loss_mask_1: 0.7528  loss_dice_1: 2.008  loss_ce_2: 0  loss_mask_2: 0.7571  loss_dice_2: 1.986  loss_ce_3: 0  loss_mask_3: 0.7568  loss_dice_3: 1.971  loss_ce_4: 0  loss_mask_4: 0.7585  loss_dice_4: 1.971  loss_ce_5: 0  loss_mask_5: 0.7571  loss_dice_5: 1.975  loss_ce_6: 0  loss_mask_6: 0.7547  loss_dice_6: 1.974  loss_ce_7: 0  loss_mask_7: 0.7583  loss_dice_7: 1.98  loss_ce_8: 0  loss_mask_8: 0.7571  loss_dice_8: 1.98  time: 1.9107  data_time: 0.0352  lr: 6.5415e-05  max_mem: 6006M
[02/18 12:20:58] d2.utils.events INFO:  eta: 16:34:00  iter: 22579  total_loss: 30.06  loss_ce: 0  loss_mask: 0.7533  loss_dice: 2.163  loss_seg: 0.8529  loss_ce_0: 0  loss_mask_0: 0.7587  loss_dice_0: 2.226  loss_ce_1: 0  loss_mask_1: 0.7639  loss_dice_1: 2.171  loss_ce_2: 0  loss_mask_2: 0.765  loss_dice_2: 2.153  loss_ce_3: 0  loss_mask_3: 0.7589  loss_dice_3: 2.142  loss_ce_4: 0  loss_mask_4: 0.7611  loss_dice_4: 2.148  loss_ce_5: 0  loss_mask_5: 0.761  loss_dice_5: 2.145  loss_ce_6: 0  loss_mask_6: 0.7589  loss_dice_6: 2.138  loss_ce_7: 0  loss_mask_7: 0.7625  loss_dice_7: 2.144  loss_ce_8: 0  loss_mask_8: 0.763  loss_dice_8: 2.151  time: 1.9105  data_time: 0.0311  lr: 6.5383e-05  max_mem: 6006M
[02/18 12:21:29] d2.utils.events INFO:  eta: 16:33:21  iter: 22599  total_loss: 28.67  loss_ce: 0  loss_mask: 0.7483  loss_dice: 2.047  loss_seg: 0.7752  loss_ce_0: 0  loss_mask_0: 0.7495  loss_dice_0: 2.151  loss_ce_1: 0  loss_mask_1: 0.7445  loss_dice_1: 2.072  loss_ce_2: 0  loss_mask_2: 0.7506  loss_dice_2: 2.052  loss_ce_3: 0  loss_mask_3: 0.7493  loss_dice_3: 2.032  loss_ce_4: 0  loss_mask_4: 0.7503  loss_dice_4: 2.029  loss_ce_5: 0  loss_mask_5: 0.7503  loss_dice_5: 2.035  loss_ce_6: 0  loss_mask_6: 0.7485  loss_dice_6: 2.031  loss_ce_7: 0  loss_mask_7: 0.7489  loss_dice_7: 2.031  loss_ce_8: 0  loss_mask_8: 0.7494  loss_dice_8: 2.038  time: 1.9102  data_time: 0.0335  lr: 6.5352e-05  max_mem: 6006M
[02/18 12:21:59] d2.utils.events INFO:  eta: 16:29:55  iter: 22619  total_loss: 30.65  loss_ce: 0  loss_mask: 0.7781  loss_dice: 2.118  loss_seg: 0.6698  loss_ce_0: 0  loss_mask_0: 0.7995  loss_dice_0: 2.199  loss_ce_1: 0  loss_mask_1: 0.7856  loss_dice_1: 2.134  loss_ce_2: 0  loss_mask_2: 0.7824  loss_dice_2: 2.12  loss_ce_3: 0  loss_mask_3: 0.7796  loss_dice_3: 2.109  loss_ce_4: 0  loss_mask_4: 0.7762  loss_dice_4: 2.111  loss_ce_5: 0  loss_mask_5: 0.7788  loss_dice_5: 2.112  loss_ce_6: 0  loss_mask_6: 0.7838  loss_dice_6: 2.107  loss_ce_7: 0  loss_mask_7: 0.787  loss_dice_7: 2.106  loss_ce_8: 0  loss_mask_8: 0.7853  loss_dice_8: 2.102  time: 1.9098  data_time: 0.0292  lr: 6.5321e-05  max_mem: 6006M
[02/18 12:22:32] d2.utils.events INFO:  eta: 16:28:22  iter: 22639  total_loss: 30.69  loss_ce: 0  loss_mask: 0.7891  loss_dice: 2.208  loss_seg: 0.6386  loss_ce_0: 0  loss_mask_0: 0.7831  loss_dice_0: 2.265  loss_ce_1: 0  loss_mask_1: 0.7883  loss_dice_1: 2.216  loss_ce_2: 0  loss_mask_2: 0.7842  loss_dice_2: 2.208  loss_ce_3: 0  loss_mask_3: 0.7899  loss_dice_3: 2.197  loss_ce_4: 0  loss_mask_4: 0.792  loss_dice_4: 2.198  loss_ce_5: 0  loss_mask_5: 0.7908  loss_dice_5: 2.2  loss_ce_6: 0  loss_mask_6: 0.791  loss_dice_6: 2.195  loss_ce_7: 0  loss_mask_7: 0.7879  loss_dice_7: 2.195  loss_ce_8: 0  loss_mask_8: 0.7914  loss_dice_8: 2.195  time: 1.9096  data_time: 0.0289  lr: 6.5289e-05  max_mem: 6006M
[02/18 12:23:03] d2.utils.events INFO:  eta: 16:26:09  iter: 22659  total_loss: 30.89  loss_ce: 0  loss_mask: 0.8044  loss_dice: 2.253  loss_seg: 0.6171  loss_ce_0: 0  loss_mask_0: 0.8244  loss_dice_0: 2.278  loss_ce_1: 0  loss_mask_1: 0.8157  loss_dice_1: 2.249  loss_ce_2: 0  loss_mask_2: 0.8071  loss_dice_2: 2.244  loss_ce_3: 0  loss_mask_3: 0.8068  loss_dice_3: 2.234  loss_ce_4: 0  loss_mask_4: 0.8043  loss_dice_4: 2.236  loss_ce_5: 0  loss_mask_5: 0.8042  loss_dice_5: 2.234  loss_ce_6: 0  loss_mask_6: 0.8057  loss_dice_6: 2.241  loss_ce_7: 0  loss_mask_7: 0.8085  loss_dice_7: 2.237  loss_ce_8: 0  loss_mask_8: 0.8077  loss_dice_8: 2.236  time: 1.9092  data_time: 0.0336  lr: 6.5258e-05  max_mem: 6006M
[02/18 12:23:35] d2.utils.events INFO:  eta: 16:26:39  iter: 22679  total_loss: 30.03  loss_ce: 0  loss_mask: 0.7894  loss_dice: 2.129  loss_seg: 0.8967  loss_ce_0: 0  loss_mask_0: 0.7993  loss_dice_0: 2.196  loss_ce_1: 0  loss_mask_1: 0.7953  loss_dice_1: 2.142  loss_ce_2: 0  loss_mask_2: 0.7929  loss_dice_2: 2.13  loss_ce_3: 0  loss_mask_3: 0.7895  loss_dice_3: 2.121  loss_ce_4: 0  loss_mask_4: 0.7922  loss_dice_4: 2.121  loss_ce_5: 0  loss_mask_5: 0.7943  loss_dice_5: 2.122  loss_ce_6: 0  loss_mask_6: 0.7923  loss_dice_6: 2.118  loss_ce_7: 0  loss_mask_7: 0.7931  loss_dice_7: 2.115  loss_ce_8: 0  loss_mask_8: 0.7943  loss_dice_8: 2.118  time: 1.9090  data_time: 0.0298  lr: 6.5226e-05  max_mem: 6006M
[02/18 12:24:07] d2.utils.events INFO:  eta: 16:24:50  iter: 22699  total_loss: 29.56  loss_ce: 0  loss_mask: 0.7545  loss_dice: 2.039  loss_seg: 1.117  loss_ce_0: 0  loss_mask_0: 0.7481  loss_dice_0: 2.108  loss_ce_1: 0  loss_mask_1: 0.7549  loss_dice_1: 2.055  loss_ce_2: 0  loss_mask_2: 0.7589  loss_dice_2: 2.036  loss_ce_3: 0  loss_mask_3: 0.7603  loss_dice_3: 2.027  loss_ce_4: 0  loss_mask_4: 0.7601  loss_dice_4: 2.035  loss_ce_5: 0  loss_mask_5: 0.7561  loss_dice_5: 2.034  loss_ce_6: 0  loss_mask_6: 0.7611  loss_dice_6: 2.026  loss_ce_7: 0  loss_mask_7: 0.7636  loss_dice_7: 2.029  loss_ce_8: 0  loss_mask_8: 0.763  loss_dice_8: 2.027  time: 1.9087  data_time: 0.0313  lr: 6.5195e-05  max_mem: 6006M
[02/18 12:24:39] d2.utils.events INFO:  eta: 16:24:18  iter: 22719  total_loss: 30.28  loss_ce: 0  loss_mask: 0.7601  loss_dice: 2.139  loss_seg: 0.7436  loss_ce_0: 0  loss_mask_0: 0.7842  loss_dice_0: 2.205  loss_ce_1: 0  loss_mask_1: 0.7632  loss_dice_1: 2.153  loss_ce_2: 0  loss_mask_2: 0.7638  loss_dice_2: 2.14  loss_ce_3: 0  loss_mask_3: 0.7611  loss_dice_3: 2.124  loss_ce_4: 0  loss_mask_4: 0.7621  loss_dice_4: 2.124  loss_ce_5: 0  loss_mask_5: 0.7619  loss_dice_5: 2.128  loss_ce_6: 0  loss_mask_6: 0.7595  loss_dice_6: 2.132  loss_ce_7: 0  loss_mask_7: 0.7589  loss_dice_7: 2.126  loss_ce_8: 0  loss_mask_8: 0.757  loss_dice_8: 2.128  time: 1.9084  data_time: 0.0289  lr: 6.5163e-05  max_mem: 6006M
[02/18 12:25:13] d2.utils.events INFO:  eta: 16:25:09  iter: 22739  total_loss: 30.22  loss_ce: 0  loss_mask: 0.7799  loss_dice: 2.139  loss_seg: 0.7003  loss_ce_0: 0  loss_mask_0: 0.7893  loss_dice_0: 2.241  loss_ce_1: 0  loss_mask_1: 0.786  loss_dice_1: 2.169  loss_ce_2: 0  loss_mask_2: 0.7859  loss_dice_2: 2.135  loss_ce_3: 0  loss_mask_3: 0.787  loss_dice_3: 2.112  loss_ce_4: 0  loss_mask_4: 0.7865  loss_dice_4: 2.118  loss_ce_5: 0  loss_mask_5: 0.7859  loss_dice_5: 2.118  loss_ce_6: 0  loss_mask_6: 0.7876  loss_dice_6: 2.115  loss_ce_7: 0  loss_mask_7: 0.7855  loss_dice_7: 2.116  loss_ce_8: 0  loss_mask_8: 0.7855  loss_dice_8: 2.121  time: 1.9082  data_time: 0.0299  lr: 6.5132e-05  max_mem: 6006M
[02/18 12:25:44] d2.utils.events INFO:  eta: 16:25:11  iter: 22759  total_loss: 28.05  loss_ce: 0  loss_mask: 0.7738  loss_dice: 1.955  loss_seg: 0.766  loss_ce_0: 0  loss_mask_0: 0.7997  loss_dice_0: 2.003  loss_ce_1: 0  loss_mask_1: 0.7843  loss_dice_1: 1.96  loss_ce_2: 0  loss_mask_2: 0.778  loss_dice_2: 1.952  loss_ce_3: 0  loss_mask_3: 0.7798  loss_dice_3: 1.943  loss_ce_4: 0  loss_mask_4: 0.7812  loss_dice_4: 1.944  loss_ce_5: 0  loss_mask_5: 0.7811  loss_dice_5: 1.942  loss_ce_6: 0  loss_mask_6: 0.783  loss_dice_6: 1.943  loss_ce_7: 0  loss_mask_7: 0.7812  loss_dice_7: 1.945  loss_ce_8: 0  loss_mask_8: 0.7807  loss_dice_8: 1.943  time: 1.9079  data_time: 0.0302  lr: 6.51e-05  max_mem: 6006M
[02/18 12:26:15] d2.utils.events INFO:  eta: 16:24:00  iter: 22779  total_loss: 30.74  loss_ce: 0  loss_mask: 0.79  loss_dice: 2.169  loss_seg: 0.9269  loss_ce_0: 0  loss_mask_0: 0.8048  loss_dice_0: 2.215  loss_ce_1: 0  loss_mask_1: 0.7873  loss_dice_1: 2.179  loss_ce_2: 0  loss_mask_2: 0.7862  loss_dice_2: 2.162  loss_ce_3: 0  loss_mask_3: 0.7852  loss_dice_3: 2.149  loss_ce_4: 0  loss_mask_4: 0.7907  loss_dice_4: 2.146  loss_ce_5: 0  loss_mask_5: 0.7859  loss_dice_5: 2.152  loss_ce_6: 0  loss_mask_6: 0.793  loss_dice_6: 2.151  loss_ce_7: 0  loss_mask_7: 0.7909  loss_dice_7: 2.148  loss_ce_8: 0  loss_mask_8: 0.7954  loss_dice_8: 2.154  time: 1.9076  data_time: 0.0343  lr: 6.5069e-05  max_mem: 6006M
[02/18 12:26:47] d2.utils.events INFO:  eta: 16:23:00  iter: 22799  total_loss: 29.2  loss_ce: 0  loss_mask: 0.7446  loss_dice: 2.075  loss_seg: 0.6036  loss_ce_0: 0  loss_mask_0: 0.7735  loss_dice_0: 2.161  loss_ce_1: 0  loss_mask_1: 0.763  loss_dice_1: 2.102  loss_ce_2: 0  loss_mask_2: 0.758  loss_dice_2: 2.079  loss_ce_3: 0  loss_mask_3: 0.7498  loss_dice_3: 2.062  loss_ce_4: 0  loss_mask_4: 0.7498  loss_dice_4: 2.061  loss_ce_5: 0  loss_mask_5: 0.7476  loss_dice_5: 2.063  loss_ce_6: 0  loss_mask_6: 0.7441  loss_dice_6: 2.065  loss_ce_7: 0  loss_mask_7: 0.7449  loss_dice_7: 2.064  loss_ce_8: 0  loss_mask_8: 0.7459  loss_dice_8: 2.06  time: 1.9073  data_time: 0.0295  lr: 6.5037e-05  max_mem: 6006M
[02/18 12:27:18] d2.utils.events INFO:  eta: 16:22:28  iter: 22819  total_loss: 28.52  loss_ce: 0  loss_mask: 0.7506  loss_dice: 1.999  loss_seg: 0.8001  loss_ce_0: 0  loss_mask_0: 0.7515  loss_dice_0: 2.072  loss_ce_1: 0  loss_mask_1: 0.7506  loss_dice_1: 2.003  loss_ce_2: 0  loss_mask_2: 0.7527  loss_dice_2: 1.992  loss_ce_3: 0  loss_mask_3: 0.7553  loss_dice_3: 1.987  loss_ce_4: 0  loss_mask_4: 0.7552  loss_dice_4: 1.988  loss_ce_5: 0  loss_mask_5: 0.7555  loss_dice_5: 1.989  loss_ce_6: 0  loss_mask_6: 0.7588  loss_dice_6: 1.98  loss_ce_7: 0  loss_mask_7: 0.7575  loss_dice_7: 1.985  loss_ce_8: 0  loss_mask_8: 0.7571  loss_dice_8: 1.987  time: 1.9070  data_time: 0.0298  lr: 6.5006e-05  max_mem: 6006M
[02/18 12:27:49] d2.utils.events INFO:  eta: 16:21:56  iter: 22839  total_loss: 31.47  loss_ce: 0  loss_mask: 0.8269  loss_dice: 2.196  loss_seg: 0.913  loss_ce_0: 0  loss_mask_0: 0.8306  loss_dice_0: 2.242  loss_ce_1: 0  loss_mask_1: 0.826  loss_dice_1: 2.196  loss_ce_2: 0  loss_mask_2: 0.8325  loss_dice_2: 2.188  loss_ce_3: 0  loss_mask_3: 0.8335  loss_dice_3: 2.184  loss_ce_4: 0  loss_mask_4: 0.828  loss_dice_4: 2.18  loss_ce_5: 0  loss_mask_5: 0.8306  loss_dice_5: 2.181  loss_ce_6: 0  loss_mask_6: 0.8301  loss_dice_6: 2.183  loss_ce_7: 0  loss_mask_7: 0.8264  loss_dice_7: 2.18  loss_ce_8: 0  loss_mask_8: 0.8258  loss_dice_8: 2.185  time: 1.9067  data_time: 0.0329  lr: 6.4974e-05  max_mem: 6006M
[02/18 12:28:21] d2.utils.events INFO:  eta: 16:20:29  iter: 22859  total_loss: 29.96  loss_ce: 0  loss_mask: 0.7727  loss_dice: 2.096  loss_seg: 0.6515  loss_ce_0: 0  loss_mask_0: 0.7594  loss_dice_0: 2.135  loss_ce_1: 0  loss_mask_1: 0.7676  loss_dice_1: 2.109  loss_ce_2: 0  loss_mask_2: 0.7713  loss_dice_2: 2.093  loss_ce_3: 0  loss_mask_3: 0.7733  loss_dice_3: 2.082  loss_ce_4: 0  loss_mask_4: 0.7747  loss_dice_4: 2.087  loss_ce_5: 0  loss_mask_5: 0.7739  loss_dice_5: 2.083  loss_ce_6: 0  loss_mask_6: 0.7809  loss_dice_6: 2.083  loss_ce_7: 0  loss_mask_7: 0.7812  loss_dice_7: 2.092  loss_ce_8: 0  loss_mask_8: 0.7808  loss_dice_8: 2.095  time: 1.9064  data_time: 0.0314  lr: 6.4943e-05  max_mem: 6006M
[02/18 12:28:54] d2.utils.events INFO:  eta: 16:20:04  iter: 22879  total_loss: 29.35  loss_ce: 0  loss_mask: 0.7656  loss_dice: 2.055  loss_seg: 0.7707  loss_ce_0: 0  loss_mask_0: 0.7702  loss_dice_0: 2.122  loss_ce_1: 0  loss_mask_1: 0.7788  loss_dice_1: 2.078  loss_ce_2: 0  loss_mask_2: 0.7743  loss_dice_2: 2.059  loss_ce_3: 0  loss_mask_3: 0.7716  loss_dice_3: 2.046  loss_ce_4: 0  loss_mask_4: 0.7728  loss_dice_4: 2.051  loss_ce_5: 0  loss_mask_5: 0.7755  loss_dice_5: 2.049  loss_ce_6: 0  loss_mask_6: 0.7731  loss_dice_6: 2.049  loss_ce_7: 0  loss_mask_7: 0.7744  loss_dice_7: 2.051  loss_ce_8: 0  loss_mask_8: 0.7755  loss_dice_8: 2.048  time: 1.9062  data_time: 0.0296  lr: 6.4911e-05  max_mem: 6006M
[02/18 12:29:23] d2.utils.events INFO:  eta: 16:17:12  iter: 22899  total_loss: 30.44  loss_ce: 0  loss_mask: 0.7671  loss_dice: 2.225  loss_seg: 0.7054  loss_ce_0: 0  loss_mask_0: 0.7823  loss_dice_0: 2.299  loss_ce_1: 0  loss_mask_1: 0.7744  loss_dice_1: 2.234  loss_ce_2: 0  loss_mask_2: 0.7732  loss_dice_2: 2.221  loss_ce_3: 0  loss_mask_3: 0.7789  loss_dice_3: 2.209  loss_ce_4: 0  loss_mask_4: 0.7781  loss_dice_4: 2.212  loss_ce_5: 0  loss_mask_5: 0.7726  loss_dice_5: 2.212  loss_ce_6: 0  loss_mask_6: 0.7756  loss_dice_6: 2.207  loss_ce_7: 0  loss_mask_7: 0.7731  loss_dice_7: 2.211  loss_ce_8: 0  loss_mask_8: 0.7696  loss_dice_8: 2.213  time: 1.9058  data_time: 0.0496  lr: 6.488e-05  max_mem: 6006M
[02/18 12:29:55] d2.utils.events INFO:  eta: 16:16:13  iter: 22919  total_loss: 29  loss_ce: 0  loss_mask: 0.7552  loss_dice: 2.092  loss_seg: 0.7598  loss_ce_0: 0  loss_mask_0: 0.7587  loss_dice_0: 2.148  loss_ce_1: 0  loss_mask_1: 0.7625  loss_dice_1: 2.076  loss_ce_2: 0  loss_mask_2: 0.7585  loss_dice_2: 2.068  loss_ce_3: 0  loss_mask_3: 0.7651  loss_dice_3: 2.063  loss_ce_4: 0  loss_mask_4: 0.7667  loss_dice_4: 2.068  loss_ce_5: 0  loss_mask_5: 0.7634  loss_dice_5: 2.069  loss_ce_6: 0  loss_mask_6: 0.7656  loss_dice_6: 2.068  loss_ce_7: 0  loss_mask_7: 0.7632  loss_dice_7: 2.068  loss_ce_8: 0  loss_mask_8: 0.7647  loss_dice_8: 2.075  time: 1.9055  data_time: 0.0342  lr: 6.4849e-05  max_mem: 6006M
[02/18 12:30:29] d2.utils.events INFO:  eta: 16:15:41  iter: 22939  total_loss: 30.35  loss_ce: 0  loss_mask: 0.7551  loss_dice: 2.165  loss_seg: 0.6921  loss_ce_0: 0  loss_mask_0: 0.7797  loss_dice_0: 2.212  loss_ce_1: 0  loss_mask_1: 0.7592  loss_dice_1: 2.167  loss_ce_2: 0  loss_mask_2: 0.7566  loss_dice_2: 2.16  loss_ce_3: 0  loss_mask_3: 0.7561  loss_dice_3: 2.148  loss_ce_4: 0  loss_mask_4: 0.758  loss_dice_4: 2.158  loss_ce_5: 0  loss_mask_5: 0.76  loss_dice_5: 2.155  loss_ce_6: 0  loss_mask_6: 0.7615  loss_dice_6: 2.15  loss_ce_7: 0  loss_mask_7: 0.7631  loss_dice_7: 2.149  loss_ce_8: 0  loss_mask_8: 0.7618  loss_dice_8: 2.156  time: 1.9053  data_time: 0.0334  lr: 6.4817e-05  max_mem: 6006M
[02/18 12:31:03] d2.utils.events INFO:  eta: 16:16:57  iter: 22959  total_loss: 31.03  loss_ce: 0  loss_mask: 0.759  loss_dice: 2.151  loss_seg: 0.9419  loss_ce_0: 0  loss_mask_0: 0.7665  loss_dice_0: 2.23  loss_ce_1: 0  loss_mask_1: 0.76  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.7672  loss_dice_2: 2.138  loss_ce_3: 0  loss_mask_3: 0.7697  loss_dice_3: 2.135  loss_ce_4: 0  loss_mask_4: 0.7667  loss_dice_4: 2.139  loss_ce_5: 0  loss_mask_5: 0.7648  loss_dice_5: 2.133  loss_ce_6: 0  loss_mask_6: 0.7649  loss_dice_6: 2.136  loss_ce_7: 0  loss_mask_7: 0.7632  loss_dice_7: 2.137  loss_ce_8: 0  loss_mask_8: 0.7634  loss_dice_8: 2.137  time: 1.9051  data_time: 0.0338  lr: 6.4786e-05  max_mem: 6006M
[02/18 12:31:36] d2.utils.events INFO:  eta: 16:19:05  iter: 22979  total_loss: 30.38  loss_ce: 0  loss_mask: 0.7676  loss_dice: 2.132  loss_seg: 0.7892  loss_ce_0: 0  loss_mask_0: 0.7752  loss_dice_0: 2.197  loss_ce_1: 0  loss_mask_1: 0.7744  loss_dice_1: 2.138  loss_ce_2: 0  loss_mask_2: 0.7716  loss_dice_2: 2.128  loss_ce_3: 0  loss_mask_3: 0.7676  loss_dice_3: 2.11  loss_ce_4: 0  loss_mask_4: 0.767  loss_dice_4: 2.107  loss_ce_5: 0  loss_mask_5: 0.7673  loss_dice_5: 2.113  loss_ce_6: 0  loss_mask_6: 0.7687  loss_dice_6: 2.11  loss_ce_7: 0  loss_mask_7: 0.7683  loss_dice_7: 2.107  loss_ce_8: 0  loss_mask_8: 0.7699  loss_dice_8: 2.108  time: 1.9049  data_time: 0.0352  lr: 6.4754e-05  max_mem: 6006M
[02/18 12:32:08] d2.utils.events INFO:  eta: 16:18:17  iter: 22999  total_loss: 29.53  loss_ce: 0  loss_mask: 0.7771  loss_dice: 2.091  loss_seg: 0.6066  loss_ce_0: 0  loss_mask_0: 0.7865  loss_dice_0: 2.17  loss_ce_1: 0  loss_mask_1: 0.7815  loss_dice_1: 2.11  loss_ce_2: 0  loss_mask_2: 0.7814  loss_dice_2: 2.093  loss_ce_3: 0  loss_mask_3: 0.7785  loss_dice_3: 2.077  loss_ce_4: 0  loss_mask_4: 0.7769  loss_dice_4: 2.077  loss_ce_5: 0  loss_mask_5: 0.7739  loss_dice_5: 2.071  loss_ce_6: 0  loss_mask_6: 0.7739  loss_dice_6: 2.075  loss_ce_7: 0  loss_mask_7: 0.7735  loss_dice_7: 2.076  loss_ce_8: 0  loss_mask_8: 0.7767  loss_dice_8: 2.073  time: 1.9047  data_time: 0.0314  lr: 6.4723e-05  max_mem: 6006M
[02/18 12:32:44] d2.utils.events INFO:  eta: 16:21:48  iter: 23019  total_loss: 29.76  loss_ce: 0  loss_mask: 0.7724  loss_dice: 2.156  loss_seg: 0.7725  loss_ce_0: 0  loss_mask_0: 0.7892  loss_dice_0: 2.204  loss_ce_1: 0  loss_mask_1: 0.777  loss_dice_1: 2.168  loss_ce_2: 0  loss_mask_2: 0.7759  loss_dice_2: 2.164  loss_ce_3: 0  loss_mask_3: 0.7795  loss_dice_3: 2.149  loss_ce_4: 0  loss_mask_4: 0.7753  loss_dice_4: 2.145  loss_ce_5: 0  loss_mask_5: 0.7773  loss_dice_5: 2.145  loss_ce_6: 0  loss_mask_6: 0.7762  loss_dice_6: 2.144  loss_ce_7: 0  loss_mask_7: 0.7743  loss_dice_7: 2.144  loss_ce_8: 0  loss_mask_8: 0.776  loss_dice_8: 2.143  time: 1.9045  data_time: 0.0320  lr: 6.4691e-05  max_mem: 6006M
[02/18 12:33:17] d2.utils.events INFO:  eta: 16:23:30  iter: 23039  total_loss: 29.91  loss_ce: 0  loss_mask: 0.7522  loss_dice: 2.158  loss_seg: 0.7793  loss_ce_0: 0  loss_mask_0: 0.7479  loss_dice_0: 2.219  loss_ce_1: 0  loss_mask_1: 0.7588  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.7608  loss_dice_2: 2.148  loss_ce_3: 0  loss_mask_3: 0.7559  loss_dice_3: 2.149  loss_ce_4: 0  loss_mask_4: 0.7593  loss_dice_4: 2.147  loss_ce_5: 0  loss_mask_5: 0.7633  loss_dice_5: 2.146  loss_ce_6: 0  loss_mask_6: 0.7626  loss_dice_6: 2.139  loss_ce_7: 0  loss_mask_7: 0.7611  loss_dice_7: 2.15  loss_ce_8: 0  loss_mask_8: 0.7607  loss_dice_8: 2.147  time: 1.9043  data_time: 0.0311  lr: 6.466e-05  max_mem: 6006M
[02/18 12:33:50] d2.utils.events INFO:  eta: 16:20:59  iter: 23059  total_loss: 30.43  loss_ce: 0  loss_mask: 0.7446  loss_dice: 2.146  loss_seg: 0.9815  loss_ce_0: 0  loss_mask_0: 0.7654  loss_dice_0: 2.236  loss_ce_1: 0  loss_mask_1: 0.7485  loss_dice_1: 2.167  loss_ce_2: 0  loss_mask_2: 0.7521  loss_dice_2: 2.149  loss_ce_3: 0  loss_mask_3: 0.7481  loss_dice_3: 2.138  loss_ce_4: 0  loss_mask_4: 0.7504  loss_dice_4: 2.135  loss_ce_5: 0  loss_mask_5: 0.7489  loss_dice_5: 2.144  loss_ce_6: 0  loss_mask_6: 0.7484  loss_dice_6: 2.133  loss_ce_7: 0  loss_mask_7: 0.753  loss_dice_7: 2.13  loss_ce_8: 0  loss_mask_8: 0.7497  loss_dice_8: 2.14  time: 1.9041  data_time: 0.0366  lr: 6.4628e-05  max_mem: 6006M
[02/18 12:34:22] d2.utils.events INFO:  eta: 16:17:34  iter: 23079  total_loss: 29.68  loss_ce: 0  loss_mask: 0.7722  loss_dice: 2.076  loss_seg: 0.6907  loss_ce_0: 0  loss_mask_0: 0.7871  loss_dice_0: 2.167  loss_ce_1: 0  loss_mask_1: 0.7823  loss_dice_1: 2.088  loss_ce_2: 0  loss_mask_2: 0.7779  loss_dice_2: 2.074  loss_ce_3: 0  loss_mask_3: 0.7775  loss_dice_3: 2.056  loss_ce_4: 0  loss_mask_4: 0.7777  loss_dice_4: 2.06  loss_ce_5: 0  loss_mask_5: 0.7765  loss_dice_5: 2.067  loss_ce_6: 0  loss_mask_6: 0.7764  loss_dice_6: 2.067  loss_ce_7: 0  loss_mask_7: 0.776  loss_dice_7: 2.071  loss_ce_8: 0  loss_mask_8: 0.775  loss_dice_8: 2.076  time: 1.9038  data_time: 0.0303  lr: 6.4597e-05  max_mem: 6006M
[02/18 12:34:56] d2.utils.events INFO:  eta: 16:17:50  iter: 23099  total_loss: 28.54  loss_ce: 0  loss_mask: 0.7382  loss_dice: 2.077  loss_seg: 0.5869  loss_ce_0: 0  loss_mask_0: 0.7406  loss_dice_0: 2.147  loss_ce_1: 0  loss_mask_1: 0.7452  loss_dice_1: 2.101  loss_ce_2: 0  loss_mask_2: 0.7484  loss_dice_2: 2.078  loss_ce_3: 0  loss_mask_3: 0.7479  loss_dice_3: 2.06  loss_ce_4: 0  loss_mask_4: 0.7474  loss_dice_4: 2.07  loss_ce_5: 0  loss_mask_5: 0.7502  loss_dice_5: 2.067  loss_ce_6: 0  loss_mask_6: 0.7464  loss_dice_6: 2.068  loss_ce_7: 0  loss_mask_7: 0.7448  loss_dice_7: 2.07  loss_ce_8: 0  loss_mask_8: 0.7455  loss_dice_8: 2.07  time: 1.9037  data_time: 0.0342  lr: 6.4565e-05  max_mem: 6006M
[02/18 12:35:28] d2.utils.events INFO:  eta: 16:19:23  iter: 23119  total_loss: 30  loss_ce: 0  loss_mask: 0.7652  loss_dice: 2.146  loss_seg: 0.6601  loss_ce_0: 0  loss_mask_0: 0.7693  loss_dice_0: 2.21  loss_ce_1: 0  loss_mask_1: 0.7707  loss_dice_1: 2.171  loss_ce_2: 0  loss_mask_2: 0.7649  loss_dice_2: 2.145  loss_ce_3: 0  loss_mask_3: 0.7664  loss_dice_3: 2.149  loss_ce_4: 0  loss_mask_4: 0.7675  loss_dice_4: 2.151  loss_ce_5: 0  loss_mask_5: 0.7661  loss_dice_5: 2.138  loss_ce_6: 0  loss_mask_6: 0.768  loss_dice_6: 2.146  loss_ce_7: 0  loss_mask_7: 0.7674  loss_dice_7: 2.147  loss_ce_8: 0  loss_mask_8: 0.7664  loss_dice_8: 2.147  time: 1.9034  data_time: 0.0346  lr: 6.4534e-05  max_mem: 6006M
[02/18 12:36:01] d2.utils.events INFO:  eta: 16:18:36  iter: 23139  total_loss: 30.84  loss_ce: 0  loss_mask: 0.7989  loss_dice: 2.141  loss_seg: 0.7135  loss_ce_0: 0  loss_mask_0: 0.8042  loss_dice_0: 2.22  loss_ce_1: 0  loss_mask_1: 0.8045  loss_dice_1: 2.153  loss_ce_2: 0  loss_mask_2: 0.7997  loss_dice_2: 2.141  loss_ce_3: 0  loss_mask_3: 0.8043  loss_dice_3: 2.131  loss_ce_4: 0  loss_mask_4: 0.8048  loss_dice_4: 2.13  loss_ce_5: 0  loss_mask_5: 0.8035  loss_dice_5: 2.129  loss_ce_6: 0  loss_mask_6: 0.8041  loss_dice_6: 2.128  loss_ce_7: 0  loss_mask_7: 0.8046  loss_dice_7: 2.126  loss_ce_8: 0  loss_mask_8: 0.8041  loss_dice_8: 2.132  time: 1.9032  data_time: 0.0436  lr: 6.4502e-05  max_mem: 6006M
[02/18 12:36:33] d2.utils.events INFO:  eta: 16:18:05  iter: 23159  total_loss: 30.66  loss_ce: 0  loss_mask: 0.7687  loss_dice: 2.151  loss_seg: 0.8749  loss_ce_0: 0  loss_mask_0: 0.791  loss_dice_0: 2.21  loss_ce_1: 0  loss_mask_1: 0.7795  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.7759  loss_dice_2: 2.153  loss_ce_3: 0  loss_mask_3: 0.7726  loss_dice_3: 2.136  loss_ce_4: 0  loss_mask_4: 0.7765  loss_dice_4: 2.133  loss_ce_5: 0  loss_mask_5: 0.7766  loss_dice_5: 2.135  loss_ce_6: 0  loss_mask_6: 0.7769  loss_dice_6: 2.134  loss_ce_7: 0  loss_mask_7: 0.7752  loss_dice_7: 2.139  loss_ce_8: 0  loss_mask_8: 0.7707  loss_dice_8: 2.143  time: 1.9029  data_time: 0.0297  lr: 6.4471e-05  max_mem: 6006M
[02/18 12:37:05] d2.utils.events INFO:  eta: 16:17:33  iter: 23179  total_loss: 29.88  loss_ce: 0  loss_mask: 0.7719  loss_dice: 2.143  loss_seg: 0.7959  loss_ce_0: 0  loss_mask_0: 0.7658  loss_dice_0: 2.219  loss_ce_1: 0  loss_mask_1: 0.7747  loss_dice_1: 2.164  loss_ce_2: 0  loss_mask_2: 0.772  loss_dice_2: 2.151  loss_ce_3: 0  loss_mask_3: 0.7726  loss_dice_3: 2.14  loss_ce_4: 0  loss_mask_4: 0.7737  loss_dice_4: 2.141  loss_ce_5: 0  loss_mask_5: 0.7747  loss_dice_5: 2.147  loss_ce_6: 0  loss_mask_6: 0.7737  loss_dice_6: 2.139  loss_ce_7: 0  loss_mask_7: 0.7759  loss_dice_7: 2.139  loss_ce_8: 0  loss_mask_8: 0.7822  loss_dice_8: 2.136  time: 1.9026  data_time: 0.0325  lr: 6.4439e-05  max_mem: 6006M
[02/18 12:37:39] d2.utils.events INFO:  eta: 16:15:57  iter: 23199  total_loss: 28.89  loss_ce: 0  loss_mask: 0.7353  loss_dice: 2.011  loss_seg: 0.7054  loss_ce_0: 0  loss_mask_0: 0.7552  loss_dice_0: 2.071  loss_ce_1: 0  loss_mask_1: 0.742  loss_dice_1: 2.015  loss_ce_2: 0  loss_mask_2: 0.74  loss_dice_2: 1.994  loss_ce_3: 0  loss_mask_3: 0.735  loss_dice_3: 1.988  loss_ce_4: 0  loss_mask_4: 0.7393  loss_dice_4: 1.994  loss_ce_5: 0  loss_mask_5: 0.7393  loss_dice_5: 1.994  loss_ce_6: 0  loss_mask_6: 0.7384  loss_dice_6: 1.992  loss_ce_7: 0  loss_mask_7: 0.7398  loss_dice_7: 1.99  loss_ce_8: 0  loss_mask_8: 0.7421  loss_dice_8: 1.993  time: 1.9025  data_time: 0.0333  lr: 6.4408e-05  max_mem: 6006M
[02/18 12:38:12] d2.utils.events INFO:  eta: 16:15:25  iter: 23219  total_loss: 29.32  loss_ce: 0  loss_mask: 0.7238  loss_dice: 2.095  loss_seg: 0.6089  loss_ce_0: 0  loss_mask_0: 0.7531  loss_dice_0: 2.157  loss_ce_1: 0  loss_mask_1: 0.7515  loss_dice_1: 2.104  loss_ce_2: 0  loss_mask_2: 0.7339  loss_dice_2: 2.088  loss_ce_3: 0  loss_mask_3: 0.7257  loss_dice_3: 2.075  loss_ce_4: 0  loss_mask_4: 0.7246  loss_dice_4: 2.077  loss_ce_5: 0  loss_mask_5: 0.7259  loss_dice_5: 2.079  loss_ce_6: 0  loss_mask_6: 0.7251  loss_dice_6: 2.08  loss_ce_7: 0  loss_mask_7: 0.7243  loss_dice_7: 2.081  loss_ce_8: 0  loss_mask_8: 0.7229  loss_dice_8: 2.08  time: 1.9023  data_time: 0.0330  lr: 6.4376e-05  max_mem: 6006M
[02/18 12:38:45] d2.utils.events INFO:  eta: 16:14:28  iter: 23239  total_loss: 30.91  loss_ce: 0  loss_mask: 0.7453  loss_dice: 2.165  loss_seg: 0.9627  loss_ce_0: 0  loss_mask_0: 0.7627  loss_dice_0: 2.23  loss_ce_1: 0  loss_mask_1: 0.7496  loss_dice_1: 2.184  loss_ce_2: 0  loss_mask_2: 0.7442  loss_dice_2: 2.172  loss_ce_3: 0  loss_mask_3: 0.748  loss_dice_3: 2.157  loss_ce_4: 0  loss_mask_4: 0.75  loss_dice_4: 2.162  loss_ce_5: 0  loss_mask_5: 0.7523  loss_dice_5: 2.161  loss_ce_6: 0  loss_mask_6: 0.7537  loss_dice_6: 2.16  loss_ce_7: 0  loss_mask_7: 0.7508  loss_dice_7: 2.163  loss_ce_8: 0  loss_mask_8: 0.7496  loss_dice_8: 2.158  time: 1.9020  data_time: 0.0354  lr: 6.4345e-05  max_mem: 6006M
[02/18 12:39:15] d2.utils.events INFO:  eta: 16:11:00  iter: 23259  total_loss: 28.78  loss_ce: 0  loss_mask: 0.7413  loss_dice: 2.024  loss_seg: 0.7622  loss_ce_0: 0  loss_mask_0: 0.766  loss_dice_0: 2.104  loss_ce_1: 0  loss_mask_1: 0.7467  loss_dice_1: 2.039  loss_ce_2: 0  loss_mask_2: 0.7467  loss_dice_2: 2.025  loss_ce_3: 0  loss_mask_3: 0.7468  loss_dice_3: 2.008  loss_ce_4: 0  loss_mask_4: 0.7445  loss_dice_4: 2.006  loss_ce_5: 0  loss_mask_5: 0.7469  loss_dice_5: 2.003  loss_ce_6: 0  loss_mask_6: 0.7461  loss_dice_6: 1.999  loss_ce_7: 0  loss_mask_7: 0.7451  loss_dice_7: 2.003  loss_ce_8: 0  loss_mask_8: 0.7473  loss_dice_8: 2.007  time: 1.9017  data_time: 0.0306  lr: 6.4313e-05  max_mem: 6006M
[02/18 12:39:49] d2.utils.events INFO:  eta: 16:09:56  iter: 23279  total_loss: 29.48  loss_ce: 0  loss_mask: 0.7715  loss_dice: 2.062  loss_seg: 0.753  loss_ce_0: 0  loss_mask_0: 0.7818  loss_dice_0: 2.149  loss_ce_1: 0  loss_mask_1: 0.7723  loss_dice_1: 2.089  loss_ce_2: 0  loss_mask_2: 0.7716  loss_dice_2: 2.074  loss_ce_3: 0  loss_mask_3: 0.7712  loss_dice_3: 2.063  loss_ce_4: 0  loss_mask_4: 0.7718  loss_dice_4: 2.064  loss_ce_5: 0  loss_mask_5: 0.7733  loss_dice_5: 2.063  loss_ce_6: 0  loss_mask_6: 0.7729  loss_dice_6: 2.06  loss_ce_7: 0  loss_mask_7: 0.777  loss_dice_7: 2.061  loss_ce_8: 0  loss_mask_8: 0.7782  loss_dice_8: 2.059  time: 1.9015  data_time: 0.0250  lr: 6.4282e-05  max_mem: 6006M
[02/18 12:40:22] d2.utils.events INFO:  eta: 16:10:14  iter: 23299  total_loss: 29.56  loss_ce: 0  loss_mask: 0.7872  loss_dice: 2.095  loss_seg: 0.749  loss_ce_0: 0  loss_mask_0: 0.8178  loss_dice_0: 2.164  loss_ce_1: 0  loss_mask_1: 0.7903  loss_dice_1: 2.104  loss_ce_2: 0  loss_mask_2: 0.7863  loss_dice_2: 2.103  loss_ce_3: 0  loss_mask_3: 0.7918  loss_dice_3: 2.079  loss_ce_4: 0  loss_mask_4: 0.7908  loss_dice_4: 2.081  loss_ce_5: 0  loss_mask_5: 0.7892  loss_dice_5: 2.086  loss_ce_6: 0  loss_mask_6: 0.788  loss_dice_6: 2.081  loss_ce_7: 0  loss_mask_7: 0.7873  loss_dice_7: 2.088  loss_ce_8: 0  loss_mask_8: 0.7883  loss_dice_8: 2.091  time: 1.9013  data_time: 0.0295  lr: 6.425e-05  max_mem: 6006M
[02/18 12:40:56] d2.utils.events INFO:  eta: 16:10:05  iter: 23319  total_loss: 29.67  loss_ce: 0  loss_mask: 0.739  loss_dice: 2.088  loss_seg: 0.5839  loss_ce_0: 0  loss_mask_0: 0.7469  loss_dice_0: 2.166  loss_ce_1: 0  loss_mask_1: 0.7449  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7434  loss_dice_2: 2.091  loss_ce_3: 0  loss_mask_3: 0.7504  loss_dice_3: 2.072  loss_ce_4: 0  loss_mask_4: 0.7478  loss_dice_4: 2.078  loss_ce_5: 0  loss_mask_5: 0.7488  loss_dice_5: 2.075  loss_ce_6: 0  loss_mask_6: 0.7495  loss_dice_6: 2.073  loss_ce_7: 0  loss_mask_7: 0.7463  loss_dice_7: 2.076  loss_ce_8: 0  loss_mask_8: 0.7469  loss_dice_8: 2.073  time: 1.9011  data_time: 0.0272  lr: 6.4219e-05  max_mem: 6006M
[02/18 12:41:30] d2.utils.events INFO:  eta: 16:10:05  iter: 23339  total_loss: 31.02  loss_ce: 0  loss_mask: 0.7729  loss_dice: 2.222  loss_seg: 0.7445  loss_ce_0: 0  loss_mask_0: 0.7929  loss_dice_0: 2.286  loss_ce_1: 0  loss_mask_1: 0.7741  loss_dice_1: 2.238  loss_ce_2: 0  loss_mask_2: 0.7706  loss_dice_2: 2.228  loss_ce_3: 0  loss_mask_3: 0.77  loss_dice_3: 2.218  loss_ce_4: 0  loss_mask_4: 0.7736  loss_dice_4: 2.214  loss_ce_5: 0  loss_mask_5: 0.7703  loss_dice_5: 2.215  loss_ce_6: 0  loss_mask_6: 0.7746  loss_dice_6: 2.214  loss_ce_7: 0  loss_mask_7: 0.773  loss_dice_7: 2.213  loss_ce_8: 0  loss_mask_8: 0.7711  loss_dice_8: 2.21  time: 1.9009  data_time: 0.0345  lr: 6.4187e-05  max_mem: 6006M
[02/18 12:42:02] d2.utils.events INFO:  eta: 16:09:18  iter: 23359  total_loss: 30.18  loss_ce: 0  loss_mask: 0.789  loss_dice: 2.115  loss_seg: 0.7307  loss_ce_0: 0  loss_mask_0: 0.8096  loss_dice_0: 2.178  loss_ce_1: 0  loss_mask_1: 0.8009  loss_dice_1: 2.14  loss_ce_2: 0  loss_mask_2: 0.7968  loss_dice_2: 2.126  loss_ce_3: 0  loss_mask_3: 0.7944  loss_dice_3: 2.111  loss_ce_4: 0  loss_mask_4: 0.7953  loss_dice_4: 2.115  loss_ce_5: 0  loss_mask_5: 0.7966  loss_dice_5: 2.116  loss_ce_6: 0  loss_mask_6: 0.7938  loss_dice_6: 2.108  loss_ce_7: 0  loss_mask_7: 0.7934  loss_dice_7: 2.111  loss_ce_8: 0  loss_mask_8: 0.794  loss_dice_8: 2.105  time: 1.9007  data_time: 0.0349  lr: 6.4156e-05  max_mem: 6006M
[02/18 12:42:36] d2.utils.events INFO:  eta: 16:08:11  iter: 23379  total_loss: 31.43  loss_ce: 0  loss_mask: 0.8009  loss_dice: 2.235  loss_seg: 0.7423  loss_ce_0: 0  loss_mask_0: 0.8082  loss_dice_0: 2.304  loss_ce_1: 0  loss_mask_1: 0.8022  loss_dice_1: 2.256  loss_ce_2: 0  loss_mask_2: 0.7981  loss_dice_2: 2.234  loss_ce_3: 0  loss_mask_3: 0.8002  loss_dice_3: 2.222  loss_ce_4: 0  loss_mask_4: 0.8032  loss_dice_4: 2.222  loss_ce_5: 0  loss_mask_5: 0.8003  loss_dice_5: 2.224  loss_ce_6: 0  loss_mask_6: 0.8033  loss_dice_6: 2.22  loss_ce_7: 0  loss_mask_7: 0.8039  loss_dice_7: 2.227  loss_ce_8: 0  loss_mask_8: 0.8072  loss_dice_8: 2.22  time: 1.9005  data_time: 0.0350  lr: 6.4124e-05  max_mem: 6006M
[02/18 12:43:09] d2.utils.events INFO:  eta: 16:07:35  iter: 23399  total_loss: 30.06  loss_ce: 0  loss_mask: 0.7804  loss_dice: 2.161  loss_seg: 0.5321  loss_ce_0: 0  loss_mask_0: 0.7799  loss_dice_0: 2.212  loss_ce_1: 0  loss_mask_1: 0.778  loss_dice_1: 2.168  loss_ce_2: 0  loss_mask_2: 0.7796  loss_dice_2: 2.16  loss_ce_3: 0  loss_mask_3: 0.7772  loss_dice_3: 2.15  loss_ce_4: 0  loss_mask_4: 0.7777  loss_dice_4: 2.151  loss_ce_5: 0  loss_mask_5: 0.7789  loss_dice_5: 2.148  loss_ce_6: 0  loss_mask_6: 0.7801  loss_dice_6: 2.149  loss_ce_7: 0  loss_mask_7: 0.777  loss_dice_7: 2.149  loss_ce_8: 0  loss_mask_8: 0.7822  loss_dice_8: 2.154  time: 1.9003  data_time: 0.0274  lr: 6.4093e-05  max_mem: 6006M
[02/18 12:43:43] d2.utils.events INFO:  eta: 16:07:58  iter: 23419  total_loss: 29.98  loss_ce: 0  loss_mask: 0.7919  loss_dice: 2.124  loss_seg: 0.6553  loss_ce_0: 0  loss_mask_0: 0.802  loss_dice_0: 2.173  loss_ce_1: 0  loss_mask_1: 0.7918  loss_dice_1: 2.143  loss_ce_2: 0  loss_mask_2: 0.7975  loss_dice_2: 2.132  loss_ce_3: 0  loss_mask_3: 0.7982  loss_dice_3: 2.13  loss_ce_4: 0  loss_mask_4: 0.7963  loss_dice_4: 2.124  loss_ce_5: 0  loss_mask_5: 0.797  loss_dice_5: 2.125  loss_ce_6: 0  loss_mask_6: 0.7986  loss_dice_6: 2.119  loss_ce_7: 0  loss_mask_7: 0.7983  loss_dice_7: 2.128  loss_ce_8: 0  loss_mask_8: 0.7957  loss_dice_8: 2.125  time: 1.9001  data_time: 0.0377  lr: 6.4061e-05  max_mem: 6006M
[02/18 12:44:16] d2.utils.events INFO:  eta: 16:07:11  iter: 23439  total_loss: 29.61  loss_ce: 0  loss_mask: 0.7646  loss_dice: 2.176  loss_seg: 0.7985  loss_ce_0: 0  loss_mask_0: 0.7658  loss_dice_0: 2.238  loss_ce_1: 0  loss_mask_1: 0.7662  loss_dice_1: 2.19  loss_ce_2: 0  loss_mask_2: 0.7666  loss_dice_2: 2.178  loss_ce_3: 0  loss_mask_3: 0.7688  loss_dice_3: 2.153  loss_ce_4: 0  loss_mask_4: 0.77  loss_dice_4: 2.159  loss_ce_5: 0  loss_mask_5: 0.7693  loss_dice_5: 2.156  loss_ce_6: 0  loss_mask_6: 0.7726  loss_dice_6: 2.155  loss_ce_7: 0  loss_mask_7: 0.7725  loss_dice_7: 2.157  loss_ce_8: 0  loss_mask_8: 0.7723  loss_dice_8: 2.162  time: 1.8999  data_time: 0.0268  lr: 6.403e-05  max_mem: 6006M
[02/18 12:44:49] d2.utils.events INFO:  eta: 16:06:39  iter: 23459  total_loss: 29.91  loss_ce: 0  loss_mask: 0.7972  loss_dice: 2.107  loss_seg: 0.6317  loss_ce_0: 0  loss_mask_0: 0.7923  loss_dice_0: 2.162  loss_ce_1: 0  loss_mask_1: 0.802  loss_dice_1: 2.108  loss_ce_2: 0  loss_mask_2: 0.7989  loss_dice_2: 2.104  loss_ce_3: 0  loss_mask_3: 0.7968  loss_dice_3: 2.095  loss_ce_4: 0  loss_mask_4: 0.7987  loss_dice_4: 2.091  loss_ce_5: 0  loss_mask_5: 0.7948  loss_dice_5: 2.098  loss_ce_6: 0  loss_mask_6: 0.7972  loss_dice_6: 2.094  loss_ce_7: 0  loss_mask_7: 0.7964  loss_dice_7: 2.104  loss_ce_8: 0  loss_mask_8: 0.8005  loss_dice_8: 2.102  time: 1.8996  data_time: 0.0356  lr: 6.3998e-05  max_mem: 6006M
[02/18 12:45:22] d2.utils.events INFO:  eta: 16:06:49  iter: 23479  total_loss: 29.02  loss_ce: 0  loss_mask: 0.7611  loss_dice: 2.039  loss_seg: 0.7468  loss_ce_0: 0  loss_mask_0: 0.7697  loss_dice_0: 2.098  loss_ce_1: 0  loss_mask_1: 0.765  loss_dice_1: 2.059  loss_ce_2: 0  loss_mask_2: 0.7669  loss_dice_2: 2.042  loss_ce_3: 0  loss_mask_3: 0.7626  loss_dice_3: 2.036  loss_ce_4: 0  loss_mask_4: 0.767  loss_dice_4: 2.031  loss_ce_5: 0  loss_mask_5: 0.7693  loss_dice_5: 2.034  loss_ce_6: 0  loss_mask_6: 0.7689  loss_dice_6: 2.031  loss_ce_7: 0  loss_mask_7: 0.7676  loss_dice_7: 2.036  loss_ce_8: 0  loss_mask_8: 0.7692  loss_dice_8: 2.032  time: 1.8994  data_time: 0.0372  lr: 6.3966e-05  max_mem: 6006M
[02/18 12:45:54] d2.utils.events INFO:  eta: 16:06:17  iter: 23499  total_loss: 29.19  loss_ce: 0  loss_mask: 0.7733  loss_dice: 2.076  loss_seg: 0.7512  loss_ce_0: 0  loss_mask_0: 0.7844  loss_dice_0: 2.116  loss_ce_1: 0  loss_mask_1: 0.7714  loss_dice_1: 2.086  loss_ce_2: 0  loss_mask_2: 0.7735  loss_dice_2: 2.067  loss_ce_3: 0  loss_mask_3: 0.7803  loss_dice_3: 2.064  loss_ce_4: 0  loss_mask_4: 0.7763  loss_dice_4: 2.063  loss_ce_5: 0  loss_mask_5: 0.7744  loss_dice_5: 2.063  loss_ce_6: 0  loss_mask_6: 0.7788  loss_dice_6: 2.065  loss_ce_7: 0  loss_mask_7: 0.7764  loss_dice_7: 2.067  loss_ce_8: 0  loss_mask_8: 0.779  loss_dice_8: 2.065  time: 1.8992  data_time: 0.0248  lr: 6.3935e-05  max_mem: 6006M
[02/18 12:46:26] d2.utils.events INFO:  eta: 16:05:04  iter: 23519  total_loss: 29.28  loss_ce: 0  loss_mask: 0.7543  loss_dice: 2.074  loss_seg: 0.7722  loss_ce_0: 0  loss_mask_0: 0.7712  loss_dice_0: 2.144  loss_ce_1: 0  loss_mask_1: 0.7671  loss_dice_1: 2.083  loss_ce_2: 0  loss_mask_2: 0.7606  loss_dice_2: 2.069  loss_ce_3: 0  loss_mask_3: 0.7635  loss_dice_3: 2.063  loss_ce_4: 0  loss_mask_4: 0.7628  loss_dice_4: 2.068  loss_ce_5: 0  loss_mask_5: 0.7613  loss_dice_5: 2.065  loss_ce_6: 0  loss_mask_6: 0.763  loss_dice_6: 2.064  loss_ce_7: 0  loss_mask_7: 0.7659  loss_dice_7: 2.068  loss_ce_8: 0  loss_mask_8: 0.7627  loss_dice_8: 2.061  time: 1.8989  data_time: 0.0327  lr: 6.3903e-05  max_mem: 6006M
[02/18 12:46:58] d2.utils.events INFO:  eta: 16:04:32  iter: 23539  total_loss: 30.08  loss_ce: 0  loss_mask: 0.7787  loss_dice: 2.132  loss_seg: 0.6665  loss_ce_0: 0  loss_mask_0: 0.8048  loss_dice_0: 2.204  loss_ce_1: 0  loss_mask_1: 0.7938  loss_dice_1: 2.147  loss_ce_2: 0  loss_mask_2: 0.7864  loss_dice_2: 2.135  loss_ce_3: 0  loss_mask_3: 0.7789  loss_dice_3: 2.122  loss_ce_4: 0  loss_mask_4: 0.7776  loss_dice_4: 2.116  loss_ce_5: 0  loss_mask_5: 0.7816  loss_dice_5: 2.126  loss_ce_6: 0  loss_mask_6: 0.7807  loss_dice_6: 2.117  loss_ce_7: 0  loss_mask_7: 0.7827  loss_dice_7: 2.121  loss_ce_8: 0  loss_mask_8: 0.7826  loss_dice_8: 2.117  time: 1.8987  data_time: 0.0306  lr: 6.3872e-05  max_mem: 6006M
[02/18 12:47:28] d2.utils.events INFO:  eta: 16:05:02  iter: 23559  total_loss: 28.36  loss_ce: 0  loss_mask: 0.7795  loss_dice: 2.018  loss_seg: 0.8296  loss_ce_0: 0  loss_mask_0: 0.7672  loss_dice_0: 2.083  loss_ce_1: 0  loss_mask_1: 0.7792  loss_dice_1: 2.033  loss_ce_2: 0  loss_mask_2: 0.7806  loss_dice_2: 2.02  loss_ce_3: 0  loss_mask_3: 0.7829  loss_dice_3: 2.009  loss_ce_4: 0  loss_mask_4: 0.7864  loss_dice_4: 1.997  loss_ce_5: 0  loss_mask_5: 0.7866  loss_dice_5: 2.005  loss_ce_6: 0  loss_mask_6: 0.7868  loss_dice_6: 2.01  loss_ce_7: 0  loss_mask_7: 0.7874  loss_dice_7: 1.999  loss_ce_8: 0  loss_mask_8: 0.7841  loss_dice_8: 2.007  time: 1.8983  data_time: 0.0294  lr: 6.384e-05  max_mem: 6006M
[02/18 12:47:58] d2.utils.events INFO:  eta: 16:04:42  iter: 23579  total_loss: 28.76  loss_ce: 0  loss_mask: 0.7419  loss_dice: 2.035  loss_seg: 0.6284  loss_ce_0: 0  loss_mask_0: 0.7494  loss_dice_0: 2.106  loss_ce_1: 0  loss_mask_1: 0.7411  loss_dice_1: 2.042  loss_ce_2: 0  loss_mask_2: 0.7385  loss_dice_2: 2.032  loss_ce_3: 0  loss_mask_3: 0.7408  loss_dice_3: 2.014  loss_ce_4: 0  loss_mask_4: 0.7436  loss_dice_4: 2.021  loss_ce_5: 0  loss_mask_5: 0.7433  loss_dice_5: 2.022  loss_ce_6: 0  loss_mask_6: 0.7415  loss_dice_6: 2.028  loss_ce_7: 0  loss_mask_7: 0.744  loss_dice_7: 2.031  loss_ce_8: 0  loss_mask_8: 0.7417  loss_dice_8: 2.027  time: 1.8980  data_time: 0.0370  lr: 6.3809e-05  max_mem: 6006M
[02/18 12:48:31] d2.utils.events INFO:  eta: 16:04:31  iter: 23599  total_loss: 29.1  loss_ce: 0  loss_mask: 0.7406  loss_dice: 2.019  loss_seg: 1.088  loss_ce_0: 0  loss_mask_0: 0.7512  loss_dice_0: 2.095  loss_ce_1: 0  loss_mask_1: 0.7448  loss_dice_1: 2.039  loss_ce_2: 0  loss_mask_2: 0.7514  loss_dice_2: 2.008  loss_ce_3: 0  loss_mask_3: 0.7494  loss_dice_3: 2  loss_ce_4: 0  loss_mask_4: 0.7526  loss_dice_4: 1.998  loss_ce_5: 0  loss_mask_5: 0.7497  loss_dice_5: 1.997  loss_ce_6: 0  loss_mask_6: 0.7502  loss_dice_6: 2  loss_ce_7: 0  loss_mask_7: 0.7485  loss_dice_7: 1.998  loss_ce_8: 0  loss_mask_8: 0.7503  loss_dice_8: 2.003  time: 1.8978  data_time: 0.0255  lr: 6.3777e-05  max_mem: 6006M
[02/18 12:49:04] d2.utils.events INFO:  eta: 16:07:13  iter: 23619  total_loss: 28.76  loss_ce: 0  loss_mask: 0.7174  loss_dice: 2.113  loss_seg: 0.7464  loss_ce_0: 0  loss_mask_0: 0.73  loss_dice_0: 2.187  loss_ce_1: 0  loss_mask_1: 0.7244  loss_dice_1: 2.123  loss_ce_2: 0  loss_mask_2: 0.7223  loss_dice_2: 2.098  loss_ce_3: 0  loss_mask_3: 0.7205  loss_dice_3: 2.102  loss_ce_4: 0  loss_mask_4: 0.72  loss_dice_4: 2.101  loss_ce_5: 0  loss_mask_5: 0.7187  loss_dice_5: 2.1  loss_ce_6: 0  loss_mask_6: 0.721  loss_dice_6: 2.101  loss_ce_7: 0  loss_mask_7: 0.7219  loss_dice_7: 2.101  loss_ce_8: 0  loss_mask_8: 0.7227  loss_dice_8: 2.105  time: 1.8976  data_time: 0.0292  lr: 6.3746e-05  max_mem: 6006M
[02/18 12:49:36] d2.utils.events INFO:  eta: 16:05:20  iter: 23639  total_loss: 28.91  loss_ce: 0  loss_mask: 0.7398  loss_dice: 2.032  loss_seg: 0.8768  loss_ce_0: 0  loss_mask_0: 0.7465  loss_dice_0: 2.101  loss_ce_1: 0  loss_mask_1: 0.7381  loss_dice_1: 2.049  loss_ce_2: 0  loss_mask_2: 0.741  loss_dice_2: 2.034  loss_ce_3: 0  loss_mask_3: 0.7447  loss_dice_3: 2.024  loss_ce_4: 0  loss_mask_4: 0.7441  loss_dice_4: 2.018  loss_ce_5: 0  loss_mask_5: 0.7431  loss_dice_5: 2.018  loss_ce_6: 0  loss_mask_6: 0.744  loss_dice_6: 2.023  loss_ce_7: 0  loss_mask_7: 0.7439  loss_dice_7: 2.022  loss_ce_8: 0  loss_mask_8: 0.748  loss_dice_8: 2.024  time: 1.8973  data_time: 0.0305  lr: 6.3714e-05  max_mem: 6006M
[02/18 12:50:09] d2.utils.events INFO:  eta: 16:07:09  iter: 23659  total_loss: 29.4  loss_ce: 0  loss_mask: 0.7447  loss_dice: 2.042  loss_seg: 0.9653  loss_ce_0: 0  loss_mask_0: 0.7442  loss_dice_0: 2.117  loss_ce_1: 0  loss_mask_1: 0.7396  loss_dice_1: 2.053  loss_ce_2: 0  loss_mask_2: 0.7468  loss_dice_2: 2.042  loss_ce_3: 0  loss_mask_3: 0.7486  loss_dice_3: 2.035  loss_ce_4: 0  loss_mask_4: 0.7471  loss_dice_4: 2.036  loss_ce_5: 0  loss_mask_5: 0.7476  loss_dice_5: 2.033  loss_ce_6: 0  loss_mask_6: 0.7494  loss_dice_6: 2.03  loss_ce_7: 0  loss_mask_7: 0.7493  loss_dice_7: 2.032  loss_ce_8: 0  loss_mask_8: 0.7486  loss_dice_8: 2.041  time: 1.8971  data_time: 0.0302  lr: 6.3683e-05  max_mem: 6006M
[02/18 12:50:42] d2.utils.events INFO:  eta: 16:07:06  iter: 23679  total_loss: 29.86  loss_ce: 0  loss_mask: 0.7971  loss_dice: 2.147  loss_seg: 0.5613  loss_ce_0: 0  loss_mask_0: 0.8068  loss_dice_0: 2.193  loss_ce_1: 0  loss_mask_1: 0.7936  loss_dice_1: 2.16  loss_ce_2: 0  loss_mask_2: 0.8062  loss_dice_2: 2.14  loss_ce_3: 0  loss_mask_3: 0.8061  loss_dice_3: 2.126  loss_ce_4: 0  loss_mask_4: 0.8046  loss_dice_4: 2.13  loss_ce_5: 0  loss_mask_5: 0.8079  loss_dice_5: 2.132  loss_ce_6: 0  loss_mask_6: 0.8078  loss_dice_6: 2.13  loss_ce_7: 0  loss_mask_7: 0.8077  loss_dice_7: 2.127  loss_ce_8: 0  loss_mask_8: 0.8113  loss_dice_8: 2.139  time: 1.8969  data_time: 0.0352  lr: 6.3651e-05  max_mem: 6006M
[02/18 12:51:14] d2.utils.events INFO:  eta: 16:06:49  iter: 23699  total_loss: 30.1  loss_ce: 0  loss_mask: 0.7846  loss_dice: 2.148  loss_seg: 0.8044  loss_ce_0: 0  loss_mask_0: 0.8012  loss_dice_0: 2.18  loss_ce_1: 0  loss_mask_1: 0.7862  loss_dice_1: 2.151  loss_ce_2: 0  loss_mask_2: 0.7857  loss_dice_2: 2.138  loss_ce_3: 0  loss_mask_3: 0.7865  loss_dice_3: 2.129  loss_ce_4: 0  loss_mask_4: 0.7868  loss_dice_4: 2.129  loss_ce_5: 0  loss_mask_5: 0.7872  loss_dice_5: 2.136  loss_ce_6: 0  loss_mask_6: 0.7841  loss_dice_6: 2.136  loss_ce_7: 0  loss_mask_7: 0.7852  loss_dice_7: 2.136  loss_ce_8: 0  loss_mask_8: 0.7858  loss_dice_8: 2.137  time: 1.8966  data_time: 0.0292  lr: 6.362e-05  max_mem: 6006M
[02/18 12:51:48] d2.utils.events INFO:  eta: 16:06:02  iter: 23719  total_loss: 30.08  loss_ce: 0  loss_mask: 0.7807  loss_dice: 2.149  loss_seg: 0.5962  loss_ce_0: 0  loss_mask_0: 0.798  loss_dice_0: 2.246  loss_ce_1: 0  loss_mask_1: 0.7726  loss_dice_1: 2.163  loss_ce_2: 0  loss_mask_2: 0.781  loss_dice_2: 2.14  loss_ce_3: 0  loss_mask_3: 0.7896  loss_dice_3: 2.133  loss_ce_4: 0  loss_mask_4: 0.7919  loss_dice_4: 2.13  loss_ce_5: 0  loss_mask_5: 0.7943  loss_dice_5: 2.129  loss_ce_6: 0  loss_mask_6: 0.7872  loss_dice_6: 2.129  loss_ce_7: 0  loss_mask_7: 0.783  loss_dice_7: 2.129  loss_ce_8: 0  loss_mask_8: 0.7856  loss_dice_8: 2.132  time: 1.8965  data_time: 0.0333  lr: 6.3588e-05  max_mem: 6006M
[02/18 12:52:21] d2.utils.events INFO:  eta: 16:05:45  iter: 23739  total_loss: 28.73  loss_ce: 0  loss_mask: 0.7562  loss_dice: 1.999  loss_seg: 0.6516  loss_ce_0: 0  loss_mask_0: 0.7617  loss_dice_0: 2.065  loss_ce_1: 0  loss_mask_1: 0.7614  loss_dice_1: 2.012  loss_ce_2: 0  loss_mask_2: 0.7638  loss_dice_2: 1.994  loss_ce_3: 0  loss_mask_3: 0.7616  loss_dice_3: 1.987  loss_ce_4: 0  loss_mask_4: 0.7608  loss_dice_4: 1.987  loss_ce_5: 0  loss_mask_5: 0.7608  loss_dice_5: 1.988  loss_ce_6: 0  loss_mask_6: 0.761  loss_dice_6: 1.986  loss_ce_7: 0  loss_mask_7: 0.7612  loss_dice_7: 1.987  loss_ce_8: 0  loss_mask_8: 0.7636  loss_dice_8: 1.988  time: 1.8962  data_time: 0.0348  lr: 6.3556e-05  max_mem: 6006M
[02/18 12:52:52] d2.utils.events INFO:  eta: 16:05:13  iter: 23759  total_loss: 28.26  loss_ce: 0  loss_mask: 0.7574  loss_dice: 2  loss_seg: 0.6554  loss_ce_0: 0  loss_mask_0: 0.7823  loss_dice_0: 2.084  loss_ce_1: 0  loss_mask_1: 0.7631  loss_dice_1: 2.013  loss_ce_2: 0  loss_mask_2: 0.7602  loss_dice_2: 2  loss_ce_3: 0  loss_mask_3: 0.7605  loss_dice_3: 1.986  loss_ce_4: 0  loss_mask_4: 0.7628  loss_dice_4: 1.986  loss_ce_5: 0  loss_mask_5: 0.7546  loss_dice_5: 1.989  loss_ce_6: 0  loss_mask_6: 0.7567  loss_dice_6: 1.991  loss_ce_7: 0  loss_mask_7: 0.759  loss_dice_7: 1.987  loss_ce_8: 0  loss_mask_8: 0.7601  loss_dice_8: 1.989  time: 1.8960  data_time: 0.0347  lr: 6.3525e-05  max_mem: 6006M
[02/18 12:53:24] d2.utils.events INFO:  eta: 16:05:09  iter: 23779  total_loss: 31.41  loss_ce: 0  loss_mask: 0.7803  loss_dice: 2.25  loss_seg: 0.6334  loss_ce_0: 0  loss_mask_0: 0.7867  loss_dice_0: 2.287  loss_ce_1: 0  loss_mask_1: 0.7827  loss_dice_1: 2.255  loss_ce_2: 0  loss_mask_2: 0.7844  loss_dice_2: 2.246  loss_ce_3: 0  loss_mask_3: 0.7857  loss_dice_3: 2.229  loss_ce_4: 0  loss_mask_4: 0.7884  loss_dice_4: 2.228  loss_ce_5: 0  loss_mask_5: 0.7893  loss_dice_5: 2.235  loss_ce_6: 0  loss_mask_6: 0.7882  loss_dice_6: 2.235  loss_ce_7: 0  loss_mask_7: 0.7895  loss_dice_7: 2.237  loss_ce_8: 0  loss_mask_8: 0.786  loss_dice_8: 2.239  time: 1.8957  data_time: 0.0261  lr: 6.3493e-05  max_mem: 6006M
[02/18 12:53:57] d2.utils.events INFO:  eta: 16:04:37  iter: 23799  total_loss: 28.96  loss_ce: 0  loss_mask: 0.7718  loss_dice: 2.018  loss_seg: 0.7886  loss_ce_0: 0  loss_mask_0: 0.7845  loss_dice_0: 2.079  loss_ce_1: 0  loss_mask_1: 0.7894  loss_dice_1: 2.045  loss_ce_2: 0  loss_mask_2: 0.7863  loss_dice_2: 2.028  loss_ce_3: 0  loss_mask_3: 0.7781  loss_dice_3: 2.005  loss_ce_4: 0  loss_mask_4: 0.7785  loss_dice_4: 2.006  loss_ce_5: 0  loss_mask_5: 0.7749  loss_dice_5: 2.012  loss_ce_6: 0  loss_mask_6: 0.772  loss_dice_6: 2.007  loss_ce_7: 0  loss_mask_7: 0.7717  loss_dice_7: 2.007  loss_ce_8: 0  loss_mask_8: 0.7711  loss_dice_8: 2.007  time: 1.8955  data_time: 0.0268  lr: 6.3462e-05  max_mem: 6006M
[02/18 12:54:28] d2.utils.events INFO:  eta: 16:04:50  iter: 23819  total_loss: 29.22  loss_ce: 0  loss_mask: 0.7593  loss_dice: 2.04  loss_seg: 0.7908  loss_ce_0: 0  loss_mask_0: 0.7797  loss_dice_0: 2.12  loss_ce_1: 0  loss_mask_1: 0.7697  loss_dice_1: 2.058  loss_ce_2: 0  loss_mask_2: 0.7683  loss_dice_2: 2.043  loss_ce_3: 0  loss_mask_3: 0.7687  loss_dice_3: 2.04  loss_ce_4: 0  loss_mask_4: 0.7657  loss_dice_4: 2.033  loss_ce_5: 0  loss_mask_5: 0.767  loss_dice_5: 2.03  loss_ce_6: 0  loss_mask_6: 0.7628  loss_dice_6: 2.03  loss_ce_7: 0  loss_mask_7: 0.7643  loss_dice_7: 2.026  loss_ce_8: 0  loss_mask_8: 0.7634  loss_dice_8: 2.028  time: 1.8952  data_time: 0.0316  lr: 6.343e-05  max_mem: 6006M
[02/18 12:55:02] d2.utils.events INFO:  eta: 16:07:12  iter: 23839  total_loss: 29.45  loss_ce: 0  loss_mask: 0.725  loss_dice: 2.128  loss_seg: 0.8952  loss_ce_0: 0  loss_mask_0: 0.7267  loss_dice_0: 2.201  loss_ce_1: 0  loss_mask_1: 0.723  loss_dice_1: 2.14  loss_ce_2: 0  loss_mask_2: 0.7273  loss_dice_2: 2.125  loss_ce_3: 0  loss_mask_3: 0.7227  loss_dice_3: 2.125  loss_ce_4: 0  loss_mask_4: 0.7233  loss_dice_4: 2.12  loss_ce_5: 0  loss_mask_5: 0.7222  loss_dice_5: 2.121  loss_ce_6: 0  loss_mask_6: 0.7208  loss_dice_6: 2.117  loss_ce_7: 0  loss_mask_7: 0.7226  loss_dice_7: 2.114  loss_ce_8: 0  loss_mask_8: 0.7203  loss_dice_8: 2.119  time: 1.8950  data_time: 0.0328  lr: 6.3399e-05  max_mem: 6006M
[02/18 12:55:34] d2.utils.events INFO:  eta: 16:07:35  iter: 23859  total_loss: 30.31  loss_ce: 0  loss_mask: 0.7859  loss_dice: 2.136  loss_seg: 0.792  loss_ce_0: 0  loss_mask_0: 0.7926  loss_dice_0: 2.2  loss_ce_1: 0  loss_mask_1: 0.7884  loss_dice_1: 2.151  loss_ce_2: 0  loss_mask_2: 0.7866  loss_dice_2: 2.138  loss_ce_3: 0  loss_mask_3: 0.7896  loss_dice_3: 2.127  loss_ce_4: 0  loss_mask_4: 0.7912  loss_dice_4: 2.126  loss_ce_5: 0  loss_mask_5: 0.7857  loss_dice_5: 2.132  loss_ce_6: 0  loss_mask_6: 0.7884  loss_dice_6: 2.131  loss_ce_7: 0  loss_mask_7: 0.7888  loss_dice_7: 2.129  loss_ce_8: 0  loss_mask_8: 0.7878  loss_dice_8: 2.123  time: 1.8948  data_time: 0.0336  lr: 6.3367e-05  max_mem: 6006M
[02/18 12:56:06] d2.utils.events INFO:  eta: 16:06:32  iter: 23879  total_loss: 28.6  loss_ce: 0  loss_mask: 0.7376  loss_dice: 2.064  loss_seg: 0.6421  loss_ce_0: 0  loss_mask_0: 0.748  loss_dice_0: 2.125  loss_ce_1: 0  loss_mask_1: 0.7436  loss_dice_1: 2.074  loss_ce_2: 0  loss_mask_2: 0.7374  loss_dice_2: 2.06  loss_ce_3: 0  loss_mask_3: 0.7356  loss_dice_3: 2.058  loss_ce_4: 0  loss_mask_4: 0.7366  loss_dice_4: 2.056  loss_ce_5: 0  loss_mask_5: 0.7347  loss_dice_5: 2.053  loss_ce_6: 0  loss_mask_6: 0.7326  loss_dice_6: 2.055  loss_ce_7: 0  loss_mask_7: 0.7345  loss_dice_7: 2.053  loss_ce_8: 0  loss_mask_8: 0.733  loss_dice_8: 2.054  time: 1.8945  data_time: 0.0303  lr: 6.3336e-05  max_mem: 6006M
[02/18 12:56:38] d2.utils.events INFO:  eta: 16:06:15  iter: 23899  total_loss: 30.99  loss_ce: 0  loss_mask: 0.7992  loss_dice: 2.219  loss_seg: 0.7665  loss_ce_0: 0  loss_mask_0: 0.8173  loss_dice_0: 2.255  loss_ce_1: 0  loss_mask_1: 0.7999  loss_dice_1: 2.233  loss_ce_2: 0  loss_mask_2: 0.7983  loss_dice_2: 2.219  loss_ce_3: 0  loss_mask_3: 0.8016  loss_dice_3: 2.211  loss_ce_4: 0  loss_mask_4: 0.8017  loss_dice_4: 2.202  loss_ce_5: 0  loss_mask_5: 0.8006  loss_dice_5: 2.202  loss_ce_6: 0  loss_mask_6: 0.8058  loss_dice_6: 2.207  loss_ce_7: 0  loss_mask_7: 0.8029  loss_dice_7: 2.207  loss_ce_8: 0  loss_mask_8: 0.8037  loss_dice_8: 2.201  time: 1.8943  data_time: 0.0282  lr: 6.3304e-05  max_mem: 6006M
[02/18 12:57:09] d2.utils.events INFO:  eta: 16:05:34  iter: 23919  total_loss: 30.85  loss_ce: 0  loss_mask: 0.7965  loss_dice: 2.157  loss_seg: 0.7617  loss_ce_0: 0  loss_mask_0: 0.8266  loss_dice_0: 2.225  loss_ce_1: 0  loss_mask_1: 0.7949  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.7957  loss_dice_2: 2.151  loss_ce_3: 0  loss_mask_3: 0.7973  loss_dice_3: 2.138  loss_ce_4: 0  loss_mask_4: 0.7957  loss_dice_4: 2.145  loss_ce_5: 0  loss_mask_5: 0.7945  loss_dice_5: 2.147  loss_ce_6: 0  loss_mask_6: 0.7915  loss_dice_6: 2.143  loss_ce_7: 0  loss_mask_7: 0.7934  loss_dice_7: 2.142  loss_ce_8: 0  loss_mask_8: 0.7967  loss_dice_8: 2.142  time: 1.8940  data_time: 0.0277  lr: 6.3272e-05  max_mem: 6006M
[02/18 12:57:41] d2.utils.events INFO:  eta: 16:04:10  iter: 23939  total_loss: 30.59  loss_ce: 0  loss_mask: 0.8193  loss_dice: 2.17  loss_seg: 0.7091  loss_ce_0: 0  loss_mask_0: 0.8291  loss_dice_0: 2.219  loss_ce_1: 0  loss_mask_1: 0.821  loss_dice_1: 2.172  loss_ce_2: 0  loss_mask_2: 0.8264  loss_dice_2: 2.161  loss_ce_3: 0  loss_mask_3: 0.8279  loss_dice_3: 2.144  loss_ce_4: 0  loss_mask_4: 0.825  loss_dice_4: 2.158  loss_ce_5: 0  loss_mask_5: 0.8225  loss_dice_5: 2.15  loss_ce_6: 0  loss_mask_6: 0.8232  loss_dice_6: 2.143  loss_ce_7: 0  loss_mask_7: 0.8217  loss_dice_7: 2.141  loss_ce_8: 0  loss_mask_8: 0.8246  loss_dice_8: 2.149  time: 1.8937  data_time: 0.0275  lr: 6.3241e-05  max_mem: 6006M
[02/18 12:58:16] d2.utils.events INFO:  eta: 16:02:39  iter: 23959  total_loss: 30.22  loss_ce: 0  loss_mask: 0.7445  loss_dice: 2.145  loss_seg: 0.8647  loss_ce_0: 0  loss_mask_0: 0.7648  loss_dice_0: 2.216  loss_ce_1: 0  loss_mask_1: 0.7465  loss_dice_1: 2.16  loss_ce_2: 0  loss_mask_2: 0.7494  loss_dice_2: 2.154  loss_ce_3: 0  loss_mask_3: 0.7504  loss_dice_3: 2.14  loss_ce_4: 0  loss_mask_4: 0.7485  loss_dice_4: 2.14  loss_ce_5: 0  loss_mask_5: 0.7529  loss_dice_5: 2.138  loss_ce_6: 0  loss_mask_6: 0.7503  loss_dice_6: 2.135  loss_ce_7: 0  loss_mask_7: 0.7492  loss_dice_7: 2.133  loss_ce_8: 0  loss_mask_8: 0.7527  loss_dice_8: 2.139  time: 1.8936  data_time: 0.0355  lr: 6.3209e-05  max_mem: 6006M
[02/18 12:58:48] d2.utils.events INFO:  eta: 16:00:48  iter: 23979  total_loss: 28.97  loss_ce: 0  loss_mask: 0.7665  loss_dice: 2.047  loss_seg: 0.6592  loss_ce_0: 0  loss_mask_0: 0.781  loss_dice_0: 2.104  loss_ce_1: 0  loss_mask_1: 0.7762  loss_dice_1: 2.058  loss_ce_2: 0  loss_mask_2: 0.7797  loss_dice_2: 2.045  loss_ce_3: 0  loss_mask_3: 0.7783  loss_dice_3: 2.034  loss_ce_4: 0  loss_mask_4: 0.7781  loss_dice_4: 2.035  loss_ce_5: 0  loss_mask_5: 0.7718  loss_dice_5: 2.038  loss_ce_6: 0  loss_mask_6: 0.7754  loss_dice_6: 2.04  loss_ce_7: 0  loss_mask_7: 0.7722  loss_dice_7: 2.039  loss_ce_8: 0  loss_mask_8: 0.7717  loss_dice_8: 2.041  time: 1.8934  data_time: 0.0340  lr: 6.3178e-05  max_mem: 6006M
[02/18 12:59:20] d2.utils.events INFO:  eta: 15:59:52  iter: 23999  total_loss: 30.94  loss_ce: 0  loss_mask: 0.7822  loss_dice: 2.222  loss_seg: 0.7601  loss_ce_0: 0  loss_mask_0: 0.7952  loss_dice_0: 2.277  loss_ce_1: 0  loss_mask_1: 0.7864  loss_dice_1: 2.231  loss_ce_2: 0  loss_mask_2: 0.7894  loss_dice_2: 2.219  loss_ce_3: 0  loss_mask_3: 0.785  loss_dice_3: 2.205  loss_ce_4: 0  loss_mask_4: 0.7865  loss_dice_4: 2.208  loss_ce_5: 0  loss_mask_5: 0.7895  loss_dice_5: 2.211  loss_ce_6: 0  loss_mask_6: 0.7868  loss_dice_6: 2.199  loss_ce_7: 0  loss_mask_7: 0.7859  loss_dice_7: 2.208  loss_ce_8: 0  loss_mask_8: 0.7859  loss_dice_8: 2.207  time: 1.8931  data_time: 0.0326  lr: 6.3146e-05  max_mem: 6006M
[02/18 12:59:53] d2.utils.events INFO:  eta: 15:58:46  iter: 24019  total_loss: 29.23  loss_ce: 0  loss_mask: 0.7862  loss_dice: 1.986  loss_seg: 0.5992  loss_ce_0: 0  loss_mask_0: 0.7833  loss_dice_0: 2.07  loss_ce_1: 0  loss_mask_1: 0.7873  loss_dice_1: 2.017  loss_ce_2: 0  loss_mask_2: 0.7828  loss_dice_2: 2.006  loss_ce_3: 0  loss_mask_3: 0.7921  loss_dice_3: 1.981  loss_ce_4: 0  loss_mask_4: 0.7943  loss_dice_4: 1.982  loss_ce_5: 0  loss_mask_5: 0.7952  loss_dice_5: 1.983  loss_ce_6: 0  loss_mask_6: 0.7977  loss_dice_6: 1.983  loss_ce_7: 0  loss_mask_7: 0.798  loss_dice_7: 1.983  loss_ce_8: 0  loss_mask_8: 0.7971  loss_dice_8: 1.984  time: 1.8929  data_time: 0.0318  lr: 6.3115e-05  max_mem: 6006M
[02/18 13:00:25] d2.utils.events INFO:  eta: 15:57:04  iter: 24039  total_loss: 29.38  loss_ce: 0  loss_mask: 0.7877  loss_dice: 2.088  loss_seg: 0.6775  loss_ce_0: 0  loss_mask_0: 0.8117  loss_dice_0: 2.149  loss_ce_1: 0  loss_mask_1: 0.7899  loss_dice_1: 2.108  loss_ce_2: 0  loss_mask_2: 0.7843  loss_dice_2: 2.089  loss_ce_3: 0  loss_mask_3: 0.7881  loss_dice_3: 2.086  loss_ce_4: 0  loss_mask_4: 0.7883  loss_dice_4: 2.082  loss_ce_5: 0  loss_mask_5: 0.7861  loss_dice_5: 2.083  loss_ce_6: 0  loss_mask_6: 0.7862  loss_dice_6: 2.08  loss_ce_7: 0  loss_mask_7: 0.7858  loss_dice_7: 2.083  loss_ce_8: 0  loss_mask_8: 0.786  loss_dice_8: 2.084  time: 1.8927  data_time: 0.0359  lr: 6.3083e-05  max_mem: 6006M
[02/18 13:00:57] d2.utils.events INFO:  eta: 15:56:07  iter: 24059  total_loss: 31.21  loss_ce: 0  loss_mask: 0.8095  loss_dice: 2.209  loss_seg: 0.6546  loss_ce_0: 0  loss_mask_0: 0.8224  loss_dice_0: 2.267  loss_ce_1: 0  loss_mask_1: 0.8154  loss_dice_1: 2.221  loss_ce_2: 0  loss_mask_2: 0.813  loss_dice_2: 2.202  loss_ce_3: 0  loss_mask_3: 0.8119  loss_dice_3: 2.193  loss_ce_4: 0  loss_mask_4: 0.8085  loss_dice_4: 2.204  loss_ce_5: 0  loss_mask_5: 0.8111  loss_dice_5: 2.201  loss_ce_6: 0  loss_mask_6: 0.8103  loss_dice_6: 2.195  loss_ce_7: 0  loss_mask_7: 0.8097  loss_dice_7: 2.199  loss_ce_8: 0  loss_mask_8: 0.8069  loss_dice_8: 2.204  time: 1.8924  data_time: 0.0344  lr: 6.3051e-05  max_mem: 6006M
[02/18 13:01:29] d2.utils.events INFO:  eta: 15:56:00  iter: 24079  total_loss: 29.58  loss_ce: 0  loss_mask: 0.7734  loss_dice: 2.149  loss_seg: 0.7036  loss_ce_0: 0  loss_mask_0: 0.7768  loss_dice_0: 2.21  loss_ce_1: 0  loss_mask_1: 0.7749  loss_dice_1: 2.15  loss_ce_2: 0  loss_mask_2: 0.7741  loss_dice_2: 2.135  loss_ce_3: 0  loss_mask_3: 0.7779  loss_dice_3: 2.128  loss_ce_4: 0  loss_mask_4: 0.7782  loss_dice_4: 2.128  loss_ce_5: 0  loss_mask_5: 0.7736  loss_dice_5: 2.125  loss_ce_6: 0  loss_mask_6: 0.7759  loss_dice_6: 2.126  loss_ce_7: 0  loss_mask_7: 0.7765  loss_dice_7: 2.122  loss_ce_8: 0  loss_mask_8: 0.7778  loss_dice_8: 2.13  time: 1.8922  data_time: 0.0366  lr: 6.302e-05  max_mem: 6006M
[02/18 13:02:01] d2.utils.events INFO:  eta: 15:53:45  iter: 24099  total_loss: 28.68  loss_ce: 0  loss_mask: 0.7618  loss_dice: 2.037  loss_seg: 0.7975  loss_ce_0: 0  loss_mask_0: 0.7601  loss_dice_0: 2.129  loss_ce_1: 0  loss_mask_1: 0.7685  loss_dice_1: 2.046  loss_ce_2: 0  loss_mask_2: 0.7694  loss_dice_2: 2.035  loss_ce_3: 0  loss_mask_3: 0.7654  loss_dice_3: 2.03  loss_ce_4: 0  loss_mask_4: 0.7635  loss_dice_4: 2.036  loss_ce_5: 0  loss_mask_5: 0.7658  loss_dice_5: 2.032  loss_ce_6: 0  loss_mask_6: 0.7704  loss_dice_6: 2.028  loss_ce_7: 0  loss_mask_7: 0.7708  loss_dice_7: 2.028  loss_ce_8: 0  loss_mask_8: 0.7669  loss_dice_8: 2.033  time: 1.8919  data_time: 0.0361  lr: 6.2988e-05  max_mem: 6006M
[02/18 13:02:35] d2.utils.events INFO:  eta: 15:53:52  iter: 24119  total_loss: 28.7  loss_ce: 0  loss_mask: 0.7097  loss_dice: 1.978  loss_seg: 0.5814  loss_ce_0: 0  loss_mask_0: 0.71  loss_dice_0: 2.066  loss_ce_1: 0  loss_mask_1: 0.7165  loss_dice_1: 1.991  loss_ce_2: 0  loss_mask_2: 0.7179  loss_dice_2: 1.969  loss_ce_3: 0  loss_mask_3: 0.7155  loss_dice_3: 1.965  loss_ce_4: 0  loss_mask_4: 0.715  loss_dice_4: 1.967  loss_ce_5: 0  loss_mask_5: 0.7141  loss_dice_5: 1.966  loss_ce_6: 0  loss_mask_6: 0.7142  loss_dice_6: 1.965  loss_ce_7: 0  loss_mask_7: 0.7168  loss_dice_7: 1.968  loss_ce_8: 0  loss_mask_8: 0.7167  loss_dice_8: 1.967  time: 1.8918  data_time: 0.0325  lr: 6.2957e-05  max_mem: 6006M
[02/18 13:03:08] d2.utils.events INFO:  eta: 15:53:34  iter: 24139  total_loss: 28.18  loss_ce: 0  loss_mask: 0.7268  loss_dice: 2.014  loss_seg: 0.7028  loss_ce_0: 0  loss_mask_0: 0.7157  loss_dice_0: 2.1  loss_ce_1: 0  loss_mask_1: 0.7212  loss_dice_1: 2.023  loss_ce_2: 0  loss_mask_2: 0.7305  loss_dice_2: 2.011  loss_ce_3: 0  loss_mask_3: 0.7336  loss_dice_3: 2.005  loss_ce_4: 0  loss_mask_4: 0.7362  loss_dice_4: 2  loss_ce_5: 0  loss_mask_5: 0.7334  loss_dice_5: 2.007  loss_ce_6: 0  loss_mask_6: 0.7373  loss_dice_6: 1.997  loss_ce_7: 0  loss_mask_7: 0.739  loss_dice_7: 2.001  loss_ce_8: 0  loss_mask_8: 0.7381  loss_dice_8: 2.001  time: 1.8916  data_time: 0.0358  lr: 6.2925e-05  max_mem: 6006M
[02/18 13:03:40] d2.utils.events INFO:  eta: 15:53:02  iter: 24159  total_loss: 29.51  loss_ce: 0  loss_mask: 0.7584  loss_dice: 2.058  loss_seg: 0.725  loss_ce_0: 0  loss_mask_0: 0.7695  loss_dice_0: 2.137  loss_ce_1: 0  loss_mask_1: 0.7607  loss_dice_1: 2.085  loss_ce_2: 0  loss_mask_2: 0.7602  loss_dice_2: 2.06  loss_ce_3: 0  loss_mask_3: 0.7645  loss_dice_3: 2.051  loss_ce_4: 0  loss_mask_4: 0.7646  loss_dice_4: 2.049  loss_ce_5: 0  loss_mask_5: 0.7655  loss_dice_5: 2.053  loss_ce_6: 0  loss_mask_6: 0.7664  loss_dice_6: 2.046  loss_ce_7: 0  loss_mask_7: 0.7668  loss_dice_7: 2.048  loss_ce_8: 0  loss_mask_8: 0.7642  loss_dice_8: 2.055  time: 1.8913  data_time: 0.0298  lr: 6.2894e-05  max_mem: 6006M
[02/18 13:04:13] d2.utils.events INFO:  eta: 15:52:50  iter: 24179  total_loss: 28.92  loss_ce: 0  loss_mask: 0.7577  loss_dice: 2.062  loss_seg: 0.6772  loss_ce_0: 0  loss_mask_0: 0.7642  loss_dice_0: 2.132  loss_ce_1: 0  loss_mask_1: 0.7623  loss_dice_1: 2.079  loss_ce_2: 0  loss_mask_2: 0.7625  loss_dice_2: 2.052  loss_ce_3: 0  loss_mask_3: 0.7645  loss_dice_3: 2.045  loss_ce_4: 0  loss_mask_4: 0.7653  loss_dice_4: 2.052  loss_ce_5: 0  loss_mask_5: 0.7632  loss_dice_5: 2.054  loss_ce_6: 0  loss_mask_6: 0.7598  loss_dice_6: 2.05  loss_ce_7: 0  loss_mask_7: 0.7637  loss_dice_7: 2.042  loss_ce_8: 0  loss_mask_8: 0.7636  loss_dice_8: 2.052  time: 1.8911  data_time: 0.0291  lr: 6.2862e-05  max_mem: 6006M
[02/18 13:04:45] d2.utils.events INFO:  eta: 15:52:42  iter: 24199  total_loss: 27.98  loss_ce: 0  loss_mask: 0.7327  loss_dice: 1.976  loss_seg: 0.6141  loss_ce_0: 0  loss_mask_0: 0.7311  loss_dice_0: 2.068  loss_ce_1: 0  loss_mask_1: 0.7505  loss_dice_1: 2  loss_ce_2: 0  loss_mask_2: 0.747  loss_dice_2: 1.975  loss_ce_3: 0  loss_mask_3: 0.7389  loss_dice_3: 1.97  loss_ce_4: 0  loss_mask_4: 0.7387  loss_dice_4: 1.971  loss_ce_5: 0  loss_mask_5: 0.7366  loss_dice_5: 1.967  loss_ce_6: 0  loss_mask_6: 0.7381  loss_dice_6: 1.971  loss_ce_7: 0  loss_mask_7: 0.7406  loss_dice_7: 1.965  loss_ce_8: 0  loss_mask_8: 0.7377  loss_dice_8: 1.963  time: 1.8909  data_time: 0.0317  lr: 6.283e-05  max_mem: 6006M
[02/18 13:05:17] d2.utils.events INFO:  eta: 15:51:26  iter: 24219  total_loss: 30.56  loss_ce: 0  loss_mask: 0.7535  loss_dice: 2.093  loss_seg: 0.7659  loss_ce_0: 0  loss_mask_0: 0.765  loss_dice_0: 2.202  loss_ce_1: 0  loss_mask_1: 0.7539  loss_dice_1: 2.124  loss_ce_2: 0  loss_mask_2: 0.7549  loss_dice_2: 2.104  loss_ce_3: 0  loss_mask_3: 0.7552  loss_dice_3: 2.089  loss_ce_4: 0  loss_mask_4: 0.753  loss_dice_4: 2.091  loss_ce_5: 0  loss_mask_5: 0.7579  loss_dice_5: 2.092  loss_ce_6: 0  loss_mask_6: 0.7569  loss_dice_6: 2.084  loss_ce_7: 0  loss_mask_7: 0.7589  loss_dice_7: 2.084  loss_ce_8: 0  loss_mask_8: 0.7604  loss_dice_8: 2.09  time: 1.8906  data_time: 0.0285  lr: 6.2799e-05  max_mem: 6006M
[02/18 13:05:47] d2.utils.events INFO:  eta: 15:50:53  iter: 24239  total_loss: 30.44  loss_ce: 0  loss_mask: 0.7834  loss_dice: 2.154  loss_seg: 0.7741  loss_ce_0: 0  loss_mask_0: 0.7951  loss_dice_0: 2.218  loss_ce_1: 0  loss_mask_1: 0.7795  loss_dice_1: 2.168  loss_ce_2: 0  loss_mask_2: 0.7798  loss_dice_2: 2.152  loss_ce_3: 0  loss_mask_3: 0.7794  loss_dice_3: 2.141  loss_ce_4: 0  loss_mask_4: 0.7799  loss_dice_4: 2.148  loss_ce_5: 0  loss_mask_5: 0.7778  loss_dice_5: 2.145  loss_ce_6: 0  loss_mask_6: 0.7833  loss_dice_6: 2.141  loss_ce_7: 0  loss_mask_7: 0.7851  loss_dice_7: 2.14  loss_ce_8: 0  loss_mask_8: 0.7824  loss_dice_8: 2.142  time: 1.8903  data_time: 0.0305  lr: 6.2767e-05  max_mem: 6006M
[02/18 13:06:19] d2.utils.events INFO:  eta: 15:51:32  iter: 24259  total_loss: 29.19  loss_ce: 0  loss_mask: 0.7838  loss_dice: 2.058  loss_seg: 0.8666  loss_ce_0: 0  loss_mask_0: 0.8046  loss_dice_0: 2.122  loss_ce_1: 0  loss_mask_1: 0.7858  loss_dice_1: 2.086  loss_ce_2: 0  loss_mask_2: 0.7792  loss_dice_2: 2.07  loss_ce_3: 0  loss_mask_3: 0.7911  loss_dice_3: 2.054  loss_ce_4: 0  loss_mask_4: 0.7882  loss_dice_4: 2.052  loss_ce_5: 0  loss_mask_5: 0.7841  loss_dice_5: 2.058  loss_ce_6: 0  loss_mask_6: 0.7856  loss_dice_6: 2.053  loss_ce_7: 0  loss_mask_7: 0.7853  loss_dice_7: 2.05  loss_ce_8: 0  loss_mask_8: 0.784  loss_dice_8: 2.049  time: 1.8901  data_time: 0.0398  lr: 6.2736e-05  max_mem: 6006M
[02/18 13:06:52] d2.utils.events INFO:  eta: 15:51:30  iter: 24279  total_loss: 29.76  loss_ce: 0  loss_mask: 0.7519  loss_dice: 2.128  loss_seg: 0.9652  loss_ce_0: 0  loss_mask_0: 0.7552  loss_dice_0: 2.219  loss_ce_1: 0  loss_mask_1: 0.7507  loss_dice_1: 2.155  loss_ce_2: 0  loss_mask_2: 0.7548  loss_dice_2: 2.14  loss_ce_3: 0  loss_mask_3: 0.757  loss_dice_3: 2.13  loss_ce_4: 0  loss_mask_4: 0.7578  loss_dice_4: 2.123  loss_ce_5: 0  loss_mask_5: 0.7546  loss_dice_5: 2.128  loss_ce_6: 0  loss_mask_6: 0.7538  loss_dice_6: 2.13  loss_ce_7: 0  loss_mask_7: 0.7572  loss_dice_7: 2.125  loss_ce_8: 0  loss_mask_8: 0.7582  loss_dice_8: 2.123  time: 1.8899  data_time: 0.0330  lr: 6.2704e-05  max_mem: 6006M
[02/18 13:07:26] d2.utils.events INFO:  eta: 15:51:18  iter: 24299  total_loss: 31.81  loss_ce: 0  loss_mask: 0.7825  loss_dice: 2.234  loss_seg: 0.9971  loss_ce_0: 0  loss_mask_0: 0.7948  loss_dice_0: 2.31  loss_ce_1: 0  loss_mask_1: 0.7822  loss_dice_1: 2.247  loss_ce_2: 0  loss_mask_2: 0.7867  loss_dice_2: 2.23  loss_ce_3: 0  loss_mask_3: 0.789  loss_dice_3: 2.226  loss_ce_4: 0  loss_mask_4: 0.7917  loss_dice_4: 2.231  loss_ce_5: 0  loss_mask_5: 0.791  loss_dice_5: 2.219  loss_ce_6: 0  loss_mask_6: 0.7906  loss_dice_6: 2.223  loss_ce_7: 0  loss_mask_7: 0.7916  loss_dice_7: 2.22  loss_ce_8: 0  loss_mask_8: 0.7902  loss_dice_8: 2.221  time: 1.8897  data_time: 0.0355  lr: 6.2672e-05  max_mem: 6006M
[02/18 13:07:58] d2.utils.events INFO:  eta: 15:50:11  iter: 24319  total_loss: 28.41  loss_ce: 0  loss_mask: 0.7418  loss_dice: 2.006  loss_seg: 0.5591  loss_ce_0: 0  loss_mask_0: 0.7362  loss_dice_0: 2.048  loss_ce_1: 0  loss_mask_1: 0.7443  loss_dice_1: 2.007  loss_ce_2: 0  loss_mask_2: 0.7419  loss_dice_2: 1.994  loss_ce_3: 0  loss_mask_3: 0.7382  loss_dice_3: 1.987  loss_ce_4: 0  loss_mask_4: 0.7425  loss_dice_4: 1.986  loss_ce_5: 0  loss_mask_5: 0.7429  loss_dice_5: 1.988  loss_ce_6: 0  loss_mask_6: 0.7424  loss_dice_6: 1.986  loss_ce_7: 0  loss_mask_7: 0.7425  loss_dice_7: 1.989  loss_ce_8: 0  loss_mask_8: 0.7442  loss_dice_8: 1.99  time: 1.8895  data_time: 0.0414  lr: 6.2641e-05  max_mem: 6006M
[02/18 13:08:29] d2.utils.events INFO:  eta: 15:49:09  iter: 24339  total_loss: 28.3  loss_ce: 0  loss_mask: 0.7313  loss_dice: 2.033  loss_seg: 0.714  loss_ce_0: 0  loss_mask_0: 0.745  loss_dice_0: 2.097  loss_ce_1: 0  loss_mask_1: 0.7323  loss_dice_1: 2.033  loss_ce_2: 0  loss_mask_2: 0.7341  loss_dice_2: 2.024  loss_ce_3: 0  loss_mask_3: 0.7377  loss_dice_3: 2.014  loss_ce_4: 0  loss_mask_4: 0.7361  loss_dice_4: 2.012  loss_ce_5: 0  loss_mask_5: 0.7337  loss_dice_5: 2.017  loss_ce_6: 0  loss_mask_6: 0.734  loss_dice_6: 2.019  loss_ce_7: 0  loss_mask_7: 0.7343  loss_dice_7: 2.019  loss_ce_8: 0  loss_mask_8: 0.7363  loss_dice_8: 2.018  time: 1.8892  data_time: 0.0435  lr: 6.2609e-05  max_mem: 6006M
[02/18 13:09:01] d2.utils.events INFO:  eta: 15:47:43  iter: 24359  total_loss: 29.27  loss_ce: 0  loss_mask: 0.7672  loss_dice: 2.113  loss_seg: 0.4414  loss_ce_0: 0  loss_mask_0: 0.7822  loss_dice_0: 2.192  loss_ce_1: 0  loss_mask_1: 0.7696  loss_dice_1: 2.132  loss_ce_2: 0  loss_mask_2: 0.7686  loss_dice_2: 2.107  loss_ce_3: 0  loss_mask_3: 0.7734  loss_dice_3: 2.101  loss_ce_4: 0  loss_mask_4: 0.7737  loss_dice_4: 2.098  loss_ce_5: 0  loss_mask_5: 0.7732  loss_dice_5: 2.099  loss_ce_6: 0  loss_mask_6: 0.7734  loss_dice_6: 2.095  loss_ce_7: 0  loss_mask_7: 0.7711  loss_dice_7: 2.098  loss_ce_8: 0  loss_mask_8: 0.7739  loss_dice_8: 2.097  time: 1.8890  data_time: 0.0427  lr: 6.2578e-05  max_mem: 6006M
[02/18 13:09:33] d2.utils.events INFO:  eta: 15:46:58  iter: 24379  total_loss: 28.58  loss_ce: 0  loss_mask: 0.7203  loss_dice: 2.012  loss_seg: 0.7584  loss_ce_0: 0  loss_mask_0: 0.7389  loss_dice_0: 2.085  loss_ce_1: 0  loss_mask_1: 0.7268  loss_dice_1: 2.029  loss_ce_2: 0  loss_mask_2: 0.7195  loss_dice_2: 2.023  loss_ce_3: 0  loss_mask_3: 0.7207  loss_dice_3: 2.008  loss_ce_4: 0  loss_mask_4: 0.7225  loss_dice_4: 2.008  loss_ce_5: 0  loss_mask_5: 0.722  loss_dice_5: 2.006  loss_ce_6: 0  loss_mask_6: 0.7218  loss_dice_6: 2.001  loss_ce_7: 0  loss_mask_7: 0.7233  loss_dice_7: 2.002  loss_ce_8: 0  loss_mask_8: 0.7249  loss_dice_8: 2  time: 1.8887  data_time: 0.0367  lr: 6.2546e-05  max_mem: 6006M
[02/18 13:10:04] d2.utils.events INFO:  eta: 15:45:04  iter: 24399  total_loss: 28.42  loss_ce: 0  loss_mask: 0.752  loss_dice: 1.995  loss_seg: 0.6973  loss_ce_0: 0  loss_mask_0: 0.7781  loss_dice_0: 2.076  loss_ce_1: 0  loss_mask_1: 0.7593  loss_dice_1: 1.997  loss_ce_2: 0  loss_mask_2: 0.7622  loss_dice_2: 1.984  loss_ce_3: 0  loss_mask_3: 0.7577  loss_dice_3: 1.981  loss_ce_4: 0  loss_mask_4: 0.755  loss_dice_4: 1.981  loss_ce_5: 0  loss_mask_5: 0.7524  loss_dice_5: 1.986  loss_ce_6: 0  loss_mask_6: 0.7536  loss_dice_6: 1.978  loss_ce_7: 0  loss_mask_7: 0.7572  loss_dice_7: 1.976  loss_ce_8: 0  loss_mask_8: 0.7562  loss_dice_8: 1.976  time: 1.8884  data_time: 0.0358  lr: 6.2514e-05  max_mem: 6006M
[02/18 13:10:39] d2.utils.events INFO:  eta: 15:42:34  iter: 24419  total_loss: 28.5  loss_ce: 0  loss_mask: 0.7587  loss_dice: 2.029  loss_seg: 0.5284  loss_ce_0: 0  loss_mask_0: 0.7576  loss_dice_0: 2.111  loss_ce_1: 0  loss_mask_1: 0.7513  loss_dice_1: 2.066  loss_ce_2: 0  loss_mask_2: 0.7524  loss_dice_2: 2.043  loss_ce_3: 0  loss_mask_3: 0.7593  loss_dice_3: 2.025  loss_ce_4: 0  loss_mask_4: 0.7599  loss_dice_4: 2.021  loss_ce_5: 0  loss_mask_5: 0.7612  loss_dice_5: 2.03  loss_ce_6: 0  loss_mask_6: 0.7648  loss_dice_6: 2.019  loss_ce_7: 0  loss_mask_7: 0.7631  loss_dice_7: 2.014  loss_ce_8: 0  loss_mask_8: 0.7656  loss_dice_8: 2.021  time: 1.8883  data_time: 0.0388  lr: 6.2483e-05  max_mem: 6006M
[02/18 13:11:10] d2.utils.events INFO:  eta: 15:41:27  iter: 24439  total_loss: 30.07  loss_ce: 0  loss_mask: 0.7846  loss_dice: 2.085  loss_seg: 0.5996  loss_ce_0: 0  loss_mask_0: 0.7954  loss_dice_0: 2.152  loss_ce_1: 0  loss_mask_1: 0.7833  loss_dice_1: 2.101  loss_ce_2: 0  loss_mask_2: 0.7832  loss_dice_2: 2.081  loss_ce_3: 0  loss_mask_3: 0.7813  loss_dice_3: 2.076  loss_ce_4: 0  loss_mask_4: 0.781  loss_dice_4: 2.076  loss_ce_5: 0  loss_mask_5: 0.7848  loss_dice_5: 2.077  loss_ce_6: 0  loss_mask_6: 0.78  loss_dice_6: 2.064  loss_ce_7: 0  loss_mask_7: 0.7814  loss_dice_7: 2.081  loss_ce_8: 0  loss_mask_8: 0.7871  loss_dice_8: 2.077  time: 1.8880  data_time: 0.0373  lr: 6.2451e-05  max_mem: 6006M
[02/18 13:11:45] d2.utils.events INFO:  eta: 15:41:13  iter: 24459  total_loss: 31.38  loss_ce: 0  loss_mask: 0.7947  loss_dice: 2.208  loss_seg: 0.7527  loss_ce_0: 0  loss_mask_0: 0.8224  loss_dice_0: 2.245  loss_ce_1: 0  loss_mask_1: 0.804  loss_dice_1: 2.197  loss_ce_2: 0  loss_mask_2: 0.7962  loss_dice_2: 2.201  loss_ce_3: 0  loss_mask_3: 0.7967  loss_dice_3: 2.193  loss_ce_4: 0  loss_mask_4: 0.8  loss_dice_4: 2.195  loss_ce_5: 0  loss_mask_5: 0.7975  loss_dice_5: 2.197  loss_ce_6: 0  loss_mask_6: 0.7956  loss_dice_6: 2.198  loss_ce_7: 0  loss_mask_7: 0.7965  loss_dice_7: 2.192  loss_ce_8: 0  loss_mask_8: 0.7963  loss_dice_8: 2.195  time: 1.8879  data_time: 0.0437  lr: 6.242e-05  max_mem: 6006M
[02/18 13:12:17] d2.utils.events INFO:  eta: 15:40:58  iter: 24479  total_loss: 29.98  loss_ce: 0  loss_mask: 0.796  loss_dice: 2.058  loss_seg: 0.6408  loss_ce_0: 0  loss_mask_0: 0.8066  loss_dice_0: 2.116  loss_ce_1: 0  loss_mask_1: 0.7906  loss_dice_1: 2.077  loss_ce_2: 0  loss_mask_2: 0.7923  loss_dice_2: 2.072  loss_ce_3: 0  loss_mask_3: 0.7984  loss_dice_3: 2.061  loss_ce_4: 0  loss_mask_4: 0.794  loss_dice_4: 2.055  loss_ce_5: 0  loss_mask_5: 0.7948  loss_dice_5: 2.057  loss_ce_6: 0  loss_mask_6: 0.7992  loss_dice_6: 2.05  loss_ce_7: 0  loss_mask_7: 0.7982  loss_dice_7: 2.05  loss_ce_8: 0  loss_mask_8: 0.7976  loss_dice_8: 2.049  time: 1.8877  data_time: 0.0379  lr: 6.2388e-05  max_mem: 6006M
[02/18 13:12:48] d2.utils.events INFO:  eta: 15:39:22  iter: 24499  total_loss: 27.61  loss_ce: 0  loss_mask: 0.7228  loss_dice: 1.972  loss_seg: 0.5769  loss_ce_0: 0  loss_mask_0: 0.7404  loss_dice_0: 2.015  loss_ce_1: 0  loss_mask_1: 0.7268  loss_dice_1: 1.975  loss_ce_2: 0  loss_mask_2: 0.7256  loss_dice_2: 1.966  loss_ce_3: 0  loss_mask_3: 0.7285  loss_dice_3: 1.955  loss_ce_4: 0  loss_mask_4: 0.7319  loss_dice_4: 1.957  loss_ce_5: 0  loss_mask_5: 0.731  loss_dice_5: 1.961  loss_ce_6: 0  loss_mask_6: 0.7283  loss_dice_6: 1.961  loss_ce_7: 0  loss_mask_7: 0.729  loss_dice_7: 1.959  loss_ce_8: 0  loss_mask_8: 0.7279  loss_dice_8: 1.962  time: 1.8874  data_time: 0.0376  lr: 6.2356e-05  max_mem: 6006M
[02/18 13:13:20] d2.utils.events INFO:  eta: 15:39:05  iter: 24519  total_loss: 29.46  loss_ce: 0  loss_mask: 0.7507  loss_dice: 2.114  loss_seg: 0.9452  loss_ce_0: 0  loss_mask_0: 0.7266  loss_dice_0: 2.194  loss_ce_1: 0  loss_mask_1: 0.745  loss_dice_1: 2.123  loss_ce_2: 0  loss_mask_2: 0.7503  loss_dice_2: 2.11  loss_ce_3: 0  loss_mask_3: 0.7535  loss_dice_3: 2.105  loss_ce_4: 0  loss_mask_4: 0.7568  loss_dice_4: 2.109  loss_ce_5: 0  loss_mask_5: 0.7557  loss_dice_5: 2.109  loss_ce_6: 0  loss_mask_6: 0.7526  loss_dice_6: 2.108  loss_ce_7: 0  loss_mask_7: 0.7537  loss_dice_7: 2.107  loss_ce_8: 0  loss_mask_8: 0.7512  loss_dice_8: 2.103  time: 1.8871  data_time: 0.0330  lr: 6.2325e-05  max_mem: 6006M
[02/18 13:13:54] d2.utils.events INFO:  eta: 15:40:15  iter: 24539  total_loss: 29.83  loss_ce: 0  loss_mask: 0.7549  loss_dice: 2.121  loss_seg: 0.6991  loss_ce_0: 0  loss_mask_0: 0.757  loss_dice_0: 2.166  loss_ce_1: 0  loss_mask_1: 0.7607  loss_dice_1: 2.134  loss_ce_2: 0  loss_mask_2: 0.7571  loss_dice_2: 2.126  loss_ce_3: 0  loss_mask_3: 0.7613  loss_dice_3: 2.113  loss_ce_4: 0  loss_mask_4: 0.7609  loss_dice_4: 2.115  loss_ce_5: 0  loss_mask_5: 0.761  loss_dice_5: 2.113  loss_ce_6: 0  loss_mask_6: 0.7615  loss_dice_6: 2.109  loss_ce_7: 0  loss_mask_7: 0.7626  loss_dice_7: 2.106  loss_ce_8: 0  loss_mask_8: 0.7599  loss_dice_8: 2.112  time: 1.8870  data_time: 0.0372  lr: 6.2293e-05  max_mem: 6006M
[02/18 13:14:28] d2.utils.events INFO:  eta: 15:42:01  iter: 24559  total_loss: 28.62  loss_ce: 0  loss_mask: 0.767  loss_dice: 2.095  loss_seg: 0.5537  loss_ce_0: 0  loss_mask_0: 0.7887  loss_dice_0: 2.177  loss_ce_1: 0  loss_mask_1: 0.7681  loss_dice_1: 2.12  loss_ce_2: 0  loss_mask_2: 0.766  loss_dice_2: 2.107  loss_ce_3: 0  loss_mask_3: 0.7672  loss_dice_3: 2.096  loss_ce_4: 0  loss_mask_4: 0.7676  loss_dice_4: 2.089  loss_ce_5: 0  loss_mask_5: 0.7695  loss_dice_5: 2.096  loss_ce_6: 0  loss_mask_6: 0.7676  loss_dice_6: 2.089  loss_ce_7: 0  loss_mask_7: 0.7705  loss_dice_7: 2.088  loss_ce_8: 0  loss_mask_8: 0.769  loss_dice_8: 2.084  time: 1.8868  data_time: 0.0285  lr: 6.2261e-05  max_mem: 6006M
[02/18 13:14:59] d2.utils.events INFO:  eta: 15:40:42  iter: 24579  total_loss: 28.63  loss_ce: 0  loss_mask: 0.7544  loss_dice: 2.018  loss_seg: 0.5715  loss_ce_0: 0  loss_mask_0: 0.7806  loss_dice_0: 2.085  loss_ce_1: 0  loss_mask_1: 0.7571  loss_dice_1: 2.035  loss_ce_2: 0  loss_mask_2: 0.7621  loss_dice_2: 2.017  loss_ce_3: 0  loss_mask_3: 0.7571  loss_dice_3: 2.01  loss_ce_4: 0  loss_mask_4: 0.7596  loss_dice_4: 2.011  loss_ce_5: 0  loss_mask_5: 0.7606  loss_dice_5: 2.011  loss_ce_6: 0  loss_mask_6: 0.7589  loss_dice_6: 2.014  loss_ce_7: 0  loss_mask_7: 0.7584  loss_dice_7: 2.017  loss_ce_8: 0  loss_mask_8: 0.7564  loss_dice_8: 2.014  time: 1.8865  data_time: 0.0273  lr: 6.223e-05  max_mem: 6006M
[02/18 13:15:34] d2.utils.events INFO:  eta: 15:41:18  iter: 24599  total_loss: 27.55  loss_ce: 0  loss_mask: 0.7361  loss_dice: 1.973  loss_seg: 0.547  loss_ce_0: 0  loss_mask_0: 0.7495  loss_dice_0: 2.026  loss_ce_1: 0  loss_mask_1: 0.7405  loss_dice_1: 1.975  loss_ce_2: 0  loss_mask_2: 0.742  loss_dice_2: 1.97  loss_ce_3: 0  loss_mask_3: 0.739  loss_dice_3: 1.965  loss_ce_4: 0  loss_mask_4: 0.742  loss_dice_4: 1.966  loss_ce_5: 0  loss_mask_5: 0.7405  loss_dice_5: 1.966  loss_ce_6: 0  loss_mask_6: 0.7453  loss_dice_6: 1.96  loss_ce_7: 0  loss_mask_7: 0.7418  loss_dice_7: 1.965  loss_ce_8: 0  loss_mask_8: 0.7419  loss_dice_8: 1.971  time: 1.8864  data_time: 0.0346  lr: 6.2198e-05  max_mem: 6006M
[02/18 13:16:08] d2.utils.events INFO:  eta: 15:41:08  iter: 24619  total_loss: 29.66  loss_ce: 0  loss_mask: 0.7604  loss_dice: 2.071  loss_seg: 0.753  loss_ce_0: 0  loss_mask_0: 0.7648  loss_dice_0: 2.133  loss_ce_1: 0  loss_mask_1: 0.7642  loss_dice_1: 2.085  loss_ce_2: 0  loss_mask_2: 0.7687  loss_dice_2: 2.069  loss_ce_3: 0  loss_mask_3: 0.7721  loss_dice_3: 2.059  loss_ce_4: 0  loss_mask_4: 0.7699  loss_dice_4: 2.057  loss_ce_5: 0  loss_mask_5: 0.766  loss_dice_5: 2.06  loss_ce_6: 0  loss_mask_6: 0.7664  loss_dice_6: 2.056  loss_ce_7: 0  loss_mask_7: 0.7657  loss_dice_7: 2.063  loss_ce_8: 0  loss_mask_8: 0.7656  loss_dice_8: 2.062  time: 1.8863  data_time: 0.0328  lr: 6.2167e-05  max_mem: 6006M
[02/18 13:16:39] d2.utils.events INFO:  eta: 15:40:36  iter: 24639  total_loss: 28.92  loss_ce: 0  loss_mask: 0.7709  loss_dice: 2.036  loss_seg: 0.6065  loss_ce_0: 0  loss_mask_0: 0.7771  loss_dice_0: 2.095  loss_ce_1: 0  loss_mask_1: 0.7713  loss_dice_1: 2.054  loss_ce_2: 0  loss_mask_2: 0.7746  loss_dice_2: 2.029  loss_ce_3: 0  loss_mask_3: 0.7732  loss_dice_3: 2.022  loss_ce_4: 0  loss_mask_4: 0.774  loss_dice_4: 2.024  loss_ce_5: 0  loss_mask_5: 0.776  loss_dice_5: 2.023  loss_ce_6: 0  loss_mask_6: 0.7761  loss_dice_6: 2.02  loss_ce_7: 0  loss_mask_7: 0.7769  loss_dice_7: 2.023  loss_ce_8: 0  loss_mask_8: 0.7763  loss_dice_8: 2.025  time: 1.8860  data_time: 0.0283  lr: 6.2135e-05  max_mem: 6006M
[02/18 13:17:13] d2.utils.events INFO:  eta: 15:40:29  iter: 24659  total_loss: 29.28  loss_ce: 0  loss_mask: 0.7402  loss_dice: 2.059  loss_seg: 0.5431  loss_ce_0: 0  loss_mask_0: 0.739  loss_dice_0: 2.131  loss_ce_1: 0  loss_mask_1: 0.7466  loss_dice_1: 2.061  loss_ce_2: 0  loss_mask_2: 0.7441  loss_dice_2: 2.052  loss_ce_3: 0  loss_mask_3: 0.7421  loss_dice_3: 2.049  loss_ce_4: 0  loss_mask_4: 0.7416  loss_dice_4: 2.054  loss_ce_5: 0  loss_mask_5: 0.7445  loss_dice_5: 2.053  loss_ce_6: 0  loss_mask_6: 0.7405  loss_dice_6: 2.051  loss_ce_7: 0  loss_mask_7: 0.7387  loss_dice_7: 2.051  loss_ce_8: 0  loss_mask_8: 0.739  loss_dice_8: 2.051  time: 1.8859  data_time: 0.0291  lr: 6.2103e-05  max_mem: 6006M
[02/18 13:17:43] d2.utils.events INFO:  eta: 15:38:49  iter: 24679  total_loss: 29.04  loss_ce: 0  loss_mask: 0.7488  loss_dice: 2.111  loss_seg: 0.9784  loss_ce_0: 0  loss_mask_0: 0.7641  loss_dice_0: 2.188  loss_ce_1: 0  loss_mask_1: 0.7484  loss_dice_1: 2.124  loss_ce_2: 0  loss_mask_2: 0.7484  loss_dice_2: 2.105  loss_ce_3: 0  loss_mask_3: 0.7483  loss_dice_3: 2.1  loss_ce_4: 0  loss_mask_4: 0.7529  loss_dice_4: 2.097  loss_ce_5: 0  loss_mask_5: 0.7487  loss_dice_5: 2.1  loss_ce_6: 0  loss_mask_6: 0.7498  loss_dice_6: 2.1  loss_ce_7: 0  loss_mask_7: 0.7534  loss_dice_7: 2.092  loss_ce_8: 0  loss_mask_8: 0.7505  loss_dice_8: 2.103  time: 1.8855  data_time: 0.0295  lr: 6.2072e-05  max_mem: 6006M
[02/18 13:18:15] d2.utils.events INFO:  eta: 15:38:39  iter: 24699  total_loss: 29.88  loss_ce: 0  loss_mask: 0.7638  loss_dice: 2.093  loss_seg: 0.5325  loss_ce_0: 0  loss_mask_0: 0.7857  loss_dice_0: 2.187  loss_ce_1: 0  loss_mask_1: 0.7731  loss_dice_1: 2.12  loss_ce_2: 0  loss_mask_2: 0.7755  loss_dice_2: 2.094  loss_ce_3: 0  loss_mask_3: 0.7744  loss_dice_3: 2.076  loss_ce_4: 0  loss_mask_4: 0.775  loss_dice_4: 2.083  loss_ce_5: 0  loss_mask_5: 0.7737  loss_dice_5: 2.081  loss_ce_6: 0  loss_mask_6: 0.7726  loss_dice_6: 2.077  loss_ce_7: 0  loss_mask_7: 0.7755  loss_dice_7: 2.084  loss_ce_8: 0  loss_mask_8: 0.7746  loss_dice_8: 2.081  time: 1.8853  data_time: 0.0272  lr: 6.204e-05  max_mem: 6006M
[02/18 13:18:48] d2.utils.events INFO:  eta: 15:38:07  iter: 24719  total_loss: 30.85  loss_ce: 0  loss_mask: 0.7804  loss_dice: 2.193  loss_seg: 0.6655  loss_ce_0: 0  loss_mask_0: 0.7798  loss_dice_0: 2.242  loss_ce_1: 0  loss_mask_1: 0.7833  loss_dice_1: 2.211  loss_ce_2: 0  loss_mask_2: 0.7874  loss_dice_2: 2.195  loss_ce_3: 0  loss_mask_3: 0.7862  loss_dice_3: 2.184  loss_ce_4: 0  loss_mask_4: 0.7813  loss_dice_4: 2.188  loss_ce_5: 0  loss_mask_5: 0.7843  loss_dice_5: 2.186  loss_ce_6: 0  loss_mask_6: 0.7876  loss_dice_6: 2.181  loss_ce_7: 0  loss_mask_7: 0.784  loss_dice_7: 2.184  loss_ce_8: 0  loss_mask_8: 0.7837  loss_dice_8: 2.185  time: 1.8851  data_time: 0.0277  lr: 6.2008e-05  max_mem: 6006M
[02/18 13:19:21] d2.utils.events INFO:  eta: 15:37:37  iter: 24739  total_loss: 28.33  loss_ce: 0  loss_mask: 0.736  loss_dice: 1.999  loss_seg: 0.5589  loss_ce_0: 0  loss_mask_0: 0.7309  loss_dice_0: 2.09  loss_ce_1: 0  loss_mask_1: 0.7297  loss_dice_1: 2.021  loss_ce_2: 0  loss_mask_2: 0.7281  loss_dice_2: 1.999  loss_ce_3: 0  loss_mask_3: 0.7308  loss_dice_3: 1.99  loss_ce_4: 0  loss_mask_4: 0.7341  loss_dice_4: 1.99  loss_ce_5: 0  loss_mask_5: 0.7321  loss_dice_5: 1.993  loss_ce_6: 0  loss_mask_6: 0.7356  loss_dice_6: 1.988  loss_ce_7: 0  loss_mask_7: 0.7347  loss_dice_7: 1.99  loss_ce_8: 0  loss_mask_8: 0.7367  loss_dice_8: 1.993  time: 1.8849  data_time: 0.0279  lr: 6.1977e-05  max_mem: 6006M
[02/18 13:19:51] d2.utils.events INFO:  eta: 15:37:03  iter: 24759  total_loss: 27.78  loss_ce: 0  loss_mask: 0.7635  loss_dice: 1.939  loss_seg: 0.5674  loss_ce_0: 0  loss_mask_0: 0.7753  loss_dice_0: 2.006  loss_ce_1: 0  loss_mask_1: 0.7672  loss_dice_1: 1.956  loss_ce_2: 0  loss_mask_2: 0.7677  loss_dice_2: 1.944  loss_ce_3: 0  loss_mask_3: 0.7717  loss_dice_3: 1.928  loss_ce_4: 0  loss_mask_4: 0.7727  loss_dice_4: 1.922  loss_ce_5: 0  loss_mask_5: 0.7678  loss_dice_5: 1.93  loss_ce_6: 0  loss_mask_6: 0.7728  loss_dice_6: 1.926  loss_ce_7: 0  loss_mask_7: 0.7745  loss_dice_7: 1.925  loss_ce_8: 0  loss_mask_8: 0.7715  loss_dice_8: 1.926  time: 1.8846  data_time: 0.0323  lr: 6.1945e-05  max_mem: 6006M
[02/18 13:20:23] d2.utils.events INFO:  eta: 15:36:04  iter: 24779  total_loss: 28.08  loss_ce: 0  loss_mask: 0.7494  loss_dice: 1.979  loss_seg: 0.7022  loss_ce_0: 0  loss_mask_0: 0.7504  loss_dice_0: 2.034  loss_ce_1: 0  loss_mask_1: 0.7439  loss_dice_1: 1.987  loss_ce_2: 0  loss_mask_2: 0.743  loss_dice_2: 1.974  loss_ce_3: 0  loss_mask_3: 0.7477  loss_dice_3: 1.961  loss_ce_4: 0  loss_mask_4: 0.747  loss_dice_4: 1.969  loss_ce_5: 0  loss_mask_5: 0.7495  loss_dice_5: 1.963  loss_ce_6: 0  loss_mask_6: 0.7511  loss_dice_6: 1.962  loss_ce_7: 0  loss_mask_7: 0.751  loss_dice_7: 1.966  loss_ce_8: 0  loss_mask_8: 0.7509  loss_dice_8: 1.966  time: 1.8844  data_time: 0.0307  lr: 6.1914e-05  max_mem: 6006M
[02/18 13:20:54] d2.utils.events INFO:  eta: 15:35:44  iter: 24799  total_loss: 28.02  loss_ce: 0  loss_mask: 0.7379  loss_dice: 1.968  loss_seg: 0.849  loss_ce_0: 0  loss_mask_0: 0.7301  loss_dice_0: 2.057  loss_ce_1: 0  loss_mask_1: 0.7431  loss_dice_1: 1.975  loss_ce_2: 0  loss_mask_2: 0.7447  loss_dice_2: 1.962  loss_ce_3: 0  loss_mask_3: 0.7481  loss_dice_3: 1.956  loss_ce_4: 0  loss_mask_4: 0.7471  loss_dice_4: 1.949  loss_ce_5: 0  loss_mask_5: 0.7422  loss_dice_5: 1.962  loss_ce_6: 0  loss_mask_6: 0.7446  loss_dice_6: 1.949  loss_ce_7: 0  loss_mask_7: 0.7442  loss_dice_7: 1.95  loss_ce_8: 0  loss_mask_8: 0.7419  loss_dice_8: 1.951  time: 1.8841  data_time: 0.0259  lr: 6.1882e-05  max_mem: 6006M
[02/18 13:21:25] d2.utils.events INFO:  eta: 15:35:28  iter: 24819  total_loss: 28.79  loss_ce: 0  loss_mask: 0.7493  loss_dice: 2.09  loss_seg: 0.7715  loss_ce_0: 0  loss_mask_0: 0.7718  loss_dice_0: 2.168  loss_ce_1: 0  loss_mask_1: 0.7473  loss_dice_1: 2.107  loss_ce_2: 0  loss_mask_2: 0.751  loss_dice_2: 2.09  loss_ce_3: 0  loss_mask_3: 0.7496  loss_dice_3: 2.077  loss_ce_4: 0  loss_mask_4: 0.749  loss_dice_4: 2.075  loss_ce_5: 0  loss_mask_5: 0.7474  loss_dice_5: 2.085  loss_ce_6: 0  loss_mask_6: 0.7508  loss_dice_6: 2.085  loss_ce_7: 0  loss_mask_7: 0.748  loss_dice_7: 2.074  loss_ce_8: 0  loss_mask_8: 0.7505  loss_dice_8: 2.075  time: 1.8838  data_time: 0.0298  lr: 6.185e-05  max_mem: 6006M
[02/18 13:21:56] d2.utils.events INFO:  eta: 15:32:58  iter: 24839  total_loss: 30.43  loss_ce: 0  loss_mask: 0.7779  loss_dice: 2.147  loss_seg: 0.615  loss_ce_0: 0  loss_mask_0: 0.7936  loss_dice_0: 2.2  loss_ce_1: 0  loss_mask_1: 0.7812  loss_dice_1: 2.158  loss_ce_2: 0  loss_mask_2: 0.783  loss_dice_2: 2.143  loss_ce_3: 0  loss_mask_3: 0.7893  loss_dice_3: 2.14  loss_ce_4: 0  loss_mask_4: 0.7879  loss_dice_4: 2.131  loss_ce_5: 0  loss_mask_5: 0.7882  loss_dice_5: 2.136  loss_ce_6: 0  loss_mask_6: 0.7873  loss_dice_6: 2.137  loss_ce_7: 0  loss_mask_7: 0.7846  loss_dice_7: 2.14  loss_ce_8: 0  loss_mask_8: 0.7849  loss_dice_8: 2.139  time: 1.8835  data_time: 0.0260  lr: 6.1819e-05  max_mem: 6006M
[02/18 13:22:30] d2.utils.events INFO:  eta: 15:33:56  iter: 24859  total_loss: 30.4  loss_ce: 0  loss_mask: 0.7366  loss_dice: 2.112  loss_seg: 0.8767  loss_ce_0: 0  loss_mask_0: 0.756  loss_dice_0: 2.205  loss_ce_1: 0  loss_mask_1: 0.7464  loss_dice_1: 2.127  loss_ce_2: 0  loss_mask_2: 0.7481  loss_dice_2: 2.106  loss_ce_3: 0  loss_mask_3: 0.7506  loss_dice_3: 2.097  loss_ce_4: 0  loss_mask_4: 0.7479  loss_dice_4: 2.099  loss_ce_5: 0  loss_mask_5: 0.7481  loss_dice_5: 2.1  loss_ce_6: 0  loss_mask_6: 0.7483  loss_dice_6: 2.097  loss_ce_7: 0  loss_mask_7: 0.7463  loss_dice_7: 2.095  loss_ce_8: 0  loss_mask_8: 0.7478  loss_dice_8: 2.097  time: 1.8834  data_time: 0.0380  lr: 6.1787e-05  max_mem: 6006M
[02/18 13:23:01] d2.utils.events INFO:  eta: 15:32:44  iter: 24879  total_loss: 28.88  loss_ce: 0  loss_mask: 0.7755  loss_dice: 2.047  loss_seg: 0.5819  loss_ce_0: 0  loss_mask_0: 0.7787  loss_dice_0: 2.126  loss_ce_1: 0  loss_mask_1: 0.7771  loss_dice_1: 2.067  loss_ce_2: 0  loss_mask_2: 0.7752  loss_dice_2: 2.049  loss_ce_3: 0  loss_mask_3: 0.7752  loss_dice_3: 2.04  loss_ce_4: 0  loss_mask_4: 0.7795  loss_dice_4: 2.037  loss_ce_5: 0  loss_mask_5: 0.7756  loss_dice_5: 2.037  loss_ce_6: 0  loss_mask_6: 0.7773  loss_dice_6: 2.034  loss_ce_7: 0  loss_mask_7: 0.7758  loss_dice_7: 2.04  loss_ce_8: 0  loss_mask_8: 0.7767  loss_dice_8: 2.038  time: 1.8831  data_time: 0.0296  lr: 6.1755e-05  max_mem: 6006M
[02/18 13:23:34] d2.utils.events INFO:  eta: 15:33:14  iter: 24899  total_loss: 27.74  loss_ce: 0  loss_mask: 0.7313  loss_dice: 1.938  loss_seg: 0.6146  loss_ce_0: 0  loss_mask_0: 0.7209  loss_dice_0: 2.017  loss_ce_1: 0  loss_mask_1: 0.728  loss_dice_1: 1.95  loss_ce_2: 0  loss_mask_2: 0.7318  loss_dice_2: 1.943  loss_ce_3: 0  loss_mask_3: 0.7374  loss_dice_3: 1.928  loss_ce_4: 0  loss_mask_4: 0.7391  loss_dice_4: 1.926  loss_ce_5: 0  loss_mask_5: 0.7397  loss_dice_5: 1.928  loss_ce_6: 0  loss_mask_6: 0.7412  loss_dice_6: 1.924  loss_ce_7: 0  loss_mask_7: 0.7401  loss_dice_7: 1.922  loss_ce_8: 0  loss_mask_8: 0.7405  loss_dice_8: 1.926  time: 1.8829  data_time: 0.0311  lr: 6.1724e-05  max_mem: 6006M
[02/18 13:24:06] d2.utils.events INFO:  eta: 15:33:50  iter: 24919  total_loss: 29.33  loss_ce: 0  loss_mask: 0.7652  loss_dice: 2.079  loss_seg: 0.5927  loss_ce_0: 0  loss_mask_0: 0.7708  loss_dice_0: 2.142  loss_ce_1: 0  loss_mask_1: 0.7752  loss_dice_1: 2.093  loss_ce_2: 0  loss_mask_2: 0.7704  loss_dice_2: 2.087  loss_ce_3: 0  loss_mask_3: 0.7673  loss_dice_3: 2.081  loss_ce_4: 0  loss_mask_4: 0.7649  loss_dice_4: 2.084  loss_ce_5: 0  loss_mask_5: 0.7664  loss_dice_5: 2.084  loss_ce_6: 0  loss_mask_6: 0.7671  loss_dice_6: 2.077  loss_ce_7: 0  loss_mask_7: 0.769  loss_dice_7: 2.082  loss_ce_8: 0  loss_mask_8: 0.7693  loss_dice_8: 2.075  time: 1.8827  data_time: 0.0413  lr: 6.1692e-05  max_mem: 6006M
[02/18 13:24:36] d2.utils.events INFO:  eta: 15:33:18  iter: 24939  total_loss: 28.45  loss_ce: 0  loss_mask: 0.7447  loss_dice: 1.977  loss_seg: 0.5818  loss_ce_0: 0  loss_mask_0: 0.7555  loss_dice_0: 2.062  loss_ce_1: 0  loss_mask_1: 0.753  loss_dice_1: 2.008  loss_ce_2: 0  loss_mask_2: 0.755  loss_dice_2: 1.987  loss_ce_3: 0  loss_mask_3: 0.7483  loss_dice_3: 1.974  loss_ce_4: 0  loss_mask_4: 0.7514  loss_dice_4: 1.977  loss_ce_5: 0  loss_mask_5: 0.7495  loss_dice_5: 1.97  loss_ce_6: 0  loss_mask_6: 0.745  loss_dice_6: 1.973  loss_ce_7: 0  loss_mask_7: 0.7469  loss_dice_7: 1.971  loss_ce_8: 0  loss_mask_8: 0.7467  loss_dice_8: 1.973  time: 1.8824  data_time: 0.0381  lr: 6.166e-05  max_mem: 6006M
[02/18 13:25:08] d2.utils.events INFO:  eta: 15:31:48  iter: 24959  total_loss: 29.66  loss_ce: 0  loss_mask: 0.7907  loss_dice: 2.093  loss_seg: 0.6371  loss_ce_0: 0  loss_mask_0: 0.8054  loss_dice_0: 2.174  loss_ce_1: 0  loss_mask_1: 0.7932  loss_dice_1: 2.112  loss_ce_2: 0  loss_mask_2: 0.791  loss_dice_2: 2.085  loss_ce_3: 0  loss_mask_3: 0.7889  loss_dice_3: 2.08  loss_ce_4: 0  loss_mask_4: 0.7921  loss_dice_4: 2.088  loss_ce_5: 0  loss_mask_5: 0.7922  loss_dice_5: 2.086  loss_ce_6: 0  loss_mask_6: 0.7921  loss_dice_6: 2.086  loss_ce_7: 0  loss_mask_7: 0.7935  loss_dice_7: 2.082  loss_ce_8: 0  loss_mask_8: 0.7919  loss_dice_8: 2.086  time: 1.8822  data_time: 0.0242  lr: 6.1629e-05  max_mem: 6006M
[02/18 13:25:42] d2.utils.events INFO:  eta: 15:31:16  iter: 24979  total_loss: 29.18  loss_ce: 0  loss_mask: 0.7427  loss_dice: 2.075  loss_seg: 0.7302  loss_ce_0: 0  loss_mask_0: 0.7545  loss_dice_0: 2.086  loss_ce_1: 0  loss_mask_1: 0.7344  loss_dice_1: 2.061  loss_ce_2: 0  loss_mask_2: 0.7363  loss_dice_2: 2.054  loss_ce_3: 0  loss_mask_3: 0.743  loss_dice_3: 2.058  loss_ce_4: 0  loss_mask_4: 0.7442  loss_dice_4: 2.062  loss_ce_5: 0  loss_mask_5: 0.7432  loss_dice_5: 2.063  loss_ce_6: 0  loss_mask_6: 0.7473  loss_dice_6: 2.047  loss_ce_7: 0  loss_mask_7: 0.7456  loss_dice_7: 2.057  loss_ce_8: 0  loss_mask_8: 0.7459  loss_dice_8: 2.068  time: 1.8820  data_time: 0.0242  lr: 6.1597e-05  max_mem: 6006M
[02/18 13:26:13] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0024999.pth
[02/18 13:26:14] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 13:26:14] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 13:26:14] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 13:26:28] mask2former INFO: Inference done 11/1093. Dataloading: 0.0034 s/iter. Inference: 0.2513 s/iter. Eval: 0.1276 s/iter. Total: 0.3823 s/iter. ETA=0:06:53
[02/18 13:26:33] mask2former INFO: Inference done 25/1093. Dataloading: 0.0051 s/iter. Inference: 0.2395 s/iter. Eval: 0.1214 s/iter. Total: 0.3661 s/iter. ETA=0:06:31
[02/18 13:26:39] mask2former INFO: Inference done 40/1093. Dataloading: 0.0051 s/iter. Inference: 0.2379 s/iter. Eval: 0.1162 s/iter. Total: 0.3592 s/iter. ETA=0:06:18
[02/18 13:26:44] mask2former INFO: Inference done 54/1093. Dataloading: 0.0054 s/iter. Inference: 0.2347 s/iter. Eval: 0.1189 s/iter. Total: 0.3591 s/iter. ETA=0:06:13
[02/18 13:26:49] mask2former INFO: Inference done 68/1093. Dataloading: 0.0054 s/iter. Inference: 0.2372 s/iter. Eval: 0.1189 s/iter. Total: 0.3616 s/iter. ETA=0:06:10
[02/18 13:26:54] mask2former INFO: Inference done 82/1093. Dataloading: 0.0053 s/iter. Inference: 0.2366 s/iter. Eval: 0.1189 s/iter. Total: 0.3609 s/iter. ETA=0:06:04
[02/18 13:26:59] mask2former INFO: Inference done 96/1093. Dataloading: 0.0053 s/iter. Inference: 0.2384 s/iter. Eval: 0.1173 s/iter. Total: 0.3611 s/iter. ETA=0:05:59
[02/18 13:27:04] mask2former INFO: Inference done 110/1093. Dataloading: 0.0052 s/iter. Inference: 0.2396 s/iter. Eval: 0.1168 s/iter. Total: 0.3617 s/iter. ETA=0:05:55
[02/18 13:27:09] mask2former INFO: Inference done 124/1093. Dataloading: 0.0053 s/iter. Inference: 0.2418 s/iter. Eval: 0.1167 s/iter. Total: 0.3639 s/iter. ETA=0:05:52
[02/18 13:27:14] mask2former INFO: Inference done 137/1093. Dataloading: 0.0053 s/iter. Inference: 0.2427 s/iter. Eval: 0.1180 s/iter. Total: 0.3660 s/iter. ETA=0:05:49
[02/18 13:27:20] mask2former INFO: Inference done 151/1093. Dataloading: 0.0053 s/iter. Inference: 0.2428 s/iter. Eval: 0.1184 s/iter. Total: 0.3665 s/iter. ETA=0:05:45
[02/18 13:27:25] mask2former INFO: Inference done 165/1093. Dataloading: 0.0052 s/iter. Inference: 0.2427 s/iter. Eval: 0.1179 s/iter. Total: 0.3659 s/iter. ETA=0:05:39
[02/18 13:27:30] mask2former INFO: Inference done 179/1093. Dataloading: 0.0052 s/iter. Inference: 0.2421 s/iter. Eval: 0.1183 s/iter. Total: 0.3657 s/iter. ETA=0:05:34
[02/18 13:27:35] mask2former INFO: Inference done 193/1093. Dataloading: 0.0052 s/iter. Inference: 0.2416 s/iter. Eval: 0.1185 s/iter. Total: 0.3654 s/iter. ETA=0:05:28
[02/18 13:27:40] mask2former INFO: Inference done 207/1093. Dataloading: 0.0052 s/iter. Inference: 0.2416 s/iter. Eval: 0.1182 s/iter. Total: 0.3651 s/iter. ETA=0:05:23
[02/18 13:27:45] mask2former INFO: Inference done 221/1093. Dataloading: 0.0051 s/iter. Inference: 0.2419 s/iter. Eval: 0.1179 s/iter. Total: 0.3650 s/iter. ETA=0:05:18
[02/18 13:27:50] mask2former INFO: Inference done 235/1093. Dataloading: 0.0051 s/iter. Inference: 0.2419 s/iter. Eval: 0.1179 s/iter. Total: 0.3650 s/iter. ETA=0:05:13
[02/18 13:27:55] mask2former INFO: Inference done 249/1093. Dataloading: 0.0051 s/iter. Inference: 0.2417 s/iter. Eval: 0.1185 s/iter. Total: 0.3654 s/iter. ETA=0:05:08
[02/18 13:28:01] mask2former INFO: Inference done 264/1093. Dataloading: 0.0051 s/iter. Inference: 0.2406 s/iter. Eval: 0.1191 s/iter. Total: 0.3650 s/iter. ETA=0:05:02
[02/18 13:28:06] mask2former INFO: Inference done 279/1093. Dataloading: 0.0051 s/iter. Inference: 0.2397 s/iter. Eval: 0.1186 s/iter. Total: 0.3635 s/iter. ETA=0:04:55
[02/18 13:28:11] mask2former INFO: Inference done 293/1093. Dataloading: 0.0052 s/iter. Inference: 0.2395 s/iter. Eval: 0.1185 s/iter. Total: 0.3632 s/iter. ETA=0:04:50
[02/18 13:28:16] mask2former INFO: Inference done 307/1093. Dataloading: 0.0052 s/iter. Inference: 0.2402 s/iter. Eval: 0.1184 s/iter. Total: 0.3638 s/iter. ETA=0:04:45
[02/18 13:28:21] mask2former INFO: Inference done 322/1093. Dataloading: 0.0052 s/iter. Inference: 0.2398 s/iter. Eval: 0.1180 s/iter. Total: 0.3631 s/iter. ETA=0:04:39
[02/18 13:28:26] mask2former INFO: Inference done 337/1093. Dataloading: 0.0051 s/iter. Inference: 0.2397 s/iter. Eval: 0.1174 s/iter. Total: 0.3624 s/iter. ETA=0:04:33
[02/18 13:28:32] mask2former INFO: Inference done 351/1093. Dataloading: 0.0051 s/iter. Inference: 0.2398 s/iter. Eval: 0.1176 s/iter. Total: 0.3626 s/iter. ETA=0:04:29
[02/18 13:28:37] mask2former INFO: Inference done 365/1093. Dataloading: 0.0051 s/iter. Inference: 0.2401 s/iter. Eval: 0.1179 s/iter. Total: 0.3633 s/iter. ETA=0:04:24
[02/18 13:28:42] mask2former INFO: Inference done 379/1093. Dataloading: 0.0051 s/iter. Inference: 0.2400 s/iter. Eval: 0.1180 s/iter. Total: 0.3632 s/iter. ETA=0:04:19
[02/18 13:28:47] mask2former INFO: Inference done 393/1093. Dataloading: 0.0051 s/iter. Inference: 0.2400 s/iter. Eval: 0.1183 s/iter. Total: 0.3634 s/iter. ETA=0:04:14
[02/18 13:28:52] mask2former INFO: Inference done 408/1093. Dataloading: 0.0051 s/iter. Inference: 0.2396 s/iter. Eval: 0.1181 s/iter. Total: 0.3629 s/iter. ETA=0:04:08
[02/18 13:28:58] mask2former INFO: Inference done 422/1093. Dataloading: 0.0051 s/iter. Inference: 0.2400 s/iter. Eval: 0.1180 s/iter. Total: 0.3632 s/iter. ETA=0:04:03
[02/18 13:29:03] mask2former INFO: Inference done 435/1093. Dataloading: 0.0052 s/iter. Inference: 0.2406 s/iter. Eval: 0.1183 s/iter. Total: 0.3642 s/iter. ETA=0:03:59
[02/18 13:29:08] mask2former INFO: Inference done 449/1093. Dataloading: 0.0052 s/iter. Inference: 0.2408 s/iter. Eval: 0.1180 s/iter. Total: 0.3640 s/iter. ETA=0:03:54
[02/18 13:29:13] mask2former INFO: Inference done 463/1093. Dataloading: 0.0052 s/iter. Inference: 0.2410 s/iter. Eval: 0.1181 s/iter. Total: 0.3644 s/iter. ETA=0:03:49
[02/18 13:29:18] mask2former INFO: Inference done 477/1093. Dataloading: 0.0053 s/iter. Inference: 0.2412 s/iter. Eval: 0.1180 s/iter. Total: 0.3645 s/iter. ETA=0:03:44
[02/18 13:29:23] mask2former INFO: Inference done 491/1093. Dataloading: 0.0053 s/iter. Inference: 0.2416 s/iter. Eval: 0.1177 s/iter. Total: 0.3647 s/iter. ETA=0:03:39
[02/18 13:29:28] mask2former INFO: Inference done 505/1093. Dataloading: 0.0053 s/iter. Inference: 0.2418 s/iter. Eval: 0.1174 s/iter. Total: 0.3646 s/iter. ETA=0:03:34
[02/18 13:29:34] mask2former INFO: Inference done 520/1093. Dataloading: 0.0053 s/iter. Inference: 0.2414 s/iter. Eval: 0.1173 s/iter. Total: 0.3641 s/iter. ETA=0:03:28
[02/18 13:29:39] mask2former INFO: Inference done 535/1093. Dataloading: 0.0052 s/iter. Inference: 0.2412 s/iter. Eval: 0.1173 s/iter. Total: 0.3638 s/iter. ETA=0:03:23
[02/18 13:29:44] mask2former INFO: Inference done 549/1093. Dataloading: 0.0052 s/iter. Inference: 0.2412 s/iter. Eval: 0.1174 s/iter. Total: 0.3640 s/iter. ETA=0:03:18
[02/18 13:29:49] mask2former INFO: Inference done 562/1093. Dataloading: 0.0052 s/iter. Inference: 0.2416 s/iter. Eval: 0.1178 s/iter. Total: 0.3648 s/iter. ETA=0:03:13
[02/18 13:29:55] mask2former INFO: Inference done 577/1093. Dataloading: 0.0052 s/iter. Inference: 0.2415 s/iter. Eval: 0.1176 s/iter. Total: 0.3645 s/iter. ETA=0:03:08
[02/18 13:30:00] mask2former INFO: Inference done 591/1093. Dataloading: 0.0052 s/iter. Inference: 0.2414 s/iter. Eval: 0.1178 s/iter. Total: 0.3645 s/iter. ETA=0:03:02
[02/18 13:30:05] mask2former INFO: Inference done 606/1093. Dataloading: 0.0053 s/iter. Inference: 0.2411 s/iter. Eval: 0.1176 s/iter. Total: 0.3641 s/iter. ETA=0:02:57
[02/18 13:30:10] mask2former INFO: Inference done 621/1093. Dataloading: 0.0053 s/iter. Inference: 0.2406 s/iter. Eval: 0.1177 s/iter. Total: 0.3637 s/iter. ETA=0:02:51
[02/18 13:30:15] mask2former INFO: Inference done 636/1093. Dataloading: 0.0053 s/iter. Inference: 0.2406 s/iter. Eval: 0.1174 s/iter. Total: 0.3634 s/iter. ETA=0:02:46
[02/18 13:30:20] mask2former INFO: Inference done 651/1093. Dataloading: 0.0053 s/iter. Inference: 0.2400 s/iter. Eval: 0.1174 s/iter. Total: 0.3627 s/iter. ETA=0:02:40
[02/18 13:30:26] mask2former INFO: Inference done 665/1093. Dataloading: 0.0052 s/iter. Inference: 0.2403 s/iter. Eval: 0.1173 s/iter. Total: 0.3629 s/iter. ETA=0:02:35
[02/18 13:30:31] mask2former INFO: Inference done 679/1093. Dataloading: 0.0053 s/iter. Inference: 0.2406 s/iter. Eval: 0.1171 s/iter. Total: 0.3631 s/iter. ETA=0:02:30
[02/18 13:30:36] mask2former INFO: Inference done 694/1093. Dataloading: 0.0052 s/iter. Inference: 0.2401 s/iter. Eval: 0.1170 s/iter. Total: 0.3624 s/iter. ETA=0:02:24
[02/18 13:30:41] mask2former INFO: Inference done 708/1093. Dataloading: 0.0052 s/iter. Inference: 0.2402 s/iter. Eval: 0.1170 s/iter. Total: 0.3625 s/iter. ETA=0:02:19
[02/18 13:30:46] mask2former INFO: Inference done 722/1093. Dataloading: 0.0052 s/iter. Inference: 0.2404 s/iter. Eval: 0.1172 s/iter. Total: 0.3629 s/iter. ETA=0:02:14
[02/18 13:30:51] mask2former INFO: Inference done 736/1093. Dataloading: 0.0052 s/iter. Inference: 0.2407 s/iter. Eval: 0.1171 s/iter. Total: 0.3631 s/iter. ETA=0:02:09
[02/18 13:30:57] mask2former INFO: Inference done 750/1093. Dataloading: 0.0055 s/iter. Inference: 0.2406 s/iter. Eval: 0.1171 s/iter. Total: 0.3634 s/iter. ETA=0:02:04
[02/18 13:31:02] mask2former INFO: Inference done 764/1093. Dataloading: 0.0055 s/iter. Inference: 0.2408 s/iter. Eval: 0.1170 s/iter. Total: 0.3634 s/iter. ETA=0:01:59
[02/18 13:31:07] mask2former INFO: Inference done 778/1093. Dataloading: 0.0055 s/iter. Inference: 0.2410 s/iter. Eval: 0.1169 s/iter. Total: 0.3636 s/iter. ETA=0:01:54
[02/18 13:31:12] mask2former INFO: Inference done 792/1093. Dataloading: 0.0056 s/iter. Inference: 0.2410 s/iter. Eval: 0.1171 s/iter. Total: 0.3637 s/iter. ETA=0:01:49
[02/18 13:31:17] mask2former INFO: Inference done 806/1093. Dataloading: 0.0056 s/iter. Inference: 0.2410 s/iter. Eval: 0.1171 s/iter. Total: 0.3637 s/iter. ETA=0:01:44
[02/18 13:31:23] mask2former INFO: Inference done 820/1093. Dataloading: 0.0055 s/iter. Inference: 0.2410 s/iter. Eval: 0.1172 s/iter. Total: 0.3638 s/iter. ETA=0:01:39
[02/18 13:31:28] mask2former INFO: Inference done 835/1093. Dataloading: 0.0055 s/iter. Inference: 0.2407 s/iter. Eval: 0.1171 s/iter. Total: 0.3634 s/iter. ETA=0:01:33
[02/18 13:31:33] mask2former INFO: Inference done 849/1093. Dataloading: 0.0055 s/iter. Inference: 0.2407 s/iter. Eval: 0.1174 s/iter. Total: 0.3637 s/iter. ETA=0:01:28
[02/18 13:31:38] mask2former INFO: Inference done 863/1093. Dataloading: 0.0055 s/iter. Inference: 0.2406 s/iter. Eval: 0.1176 s/iter. Total: 0.3639 s/iter. ETA=0:01:23
[02/18 13:31:43] mask2former INFO: Inference done 877/1093. Dataloading: 0.0055 s/iter. Inference: 0.2408 s/iter. Eval: 0.1176 s/iter. Total: 0.3639 s/iter. ETA=0:01:18
[02/18 13:31:49] mask2former INFO: Inference done 891/1093. Dataloading: 0.0055 s/iter. Inference: 0.2409 s/iter. Eval: 0.1174 s/iter. Total: 0.3639 s/iter. ETA=0:01:13
[02/18 13:31:54] mask2former INFO: Inference done 905/1093. Dataloading: 0.0055 s/iter. Inference: 0.2410 s/iter. Eval: 0.1174 s/iter. Total: 0.3639 s/iter. ETA=0:01:08
[02/18 13:31:59] mask2former INFO: Inference done 920/1093. Dataloading: 0.0055 s/iter. Inference: 0.2408 s/iter. Eval: 0.1171 s/iter. Total: 0.3635 s/iter. ETA=0:01:02
[02/18 13:32:04] mask2former INFO: Inference done 935/1093. Dataloading: 0.0055 s/iter. Inference: 0.2405 s/iter. Eval: 0.1171 s/iter. Total: 0.3632 s/iter. ETA=0:00:57
[02/18 13:32:09] mask2former INFO: Inference done 950/1093. Dataloading: 0.0054 s/iter. Inference: 0.2404 s/iter. Eval: 0.1170 s/iter. Total: 0.3630 s/iter. ETA=0:00:51
[02/18 13:32:14] mask2former INFO: Inference done 965/1093. Dataloading: 0.0054 s/iter. Inference: 0.2403 s/iter. Eval: 0.1168 s/iter. Total: 0.3627 s/iter. ETA=0:00:46
[02/18 13:32:19] mask2former INFO: Inference done 979/1093. Dataloading: 0.0054 s/iter. Inference: 0.2402 s/iter. Eval: 0.1170 s/iter. Total: 0.3627 s/iter. ETA=0:00:41
[02/18 13:32:24] mask2former INFO: Inference done 993/1093. Dataloading: 0.0054 s/iter. Inference: 0.2402 s/iter. Eval: 0.1170 s/iter. Total: 0.3627 s/iter. ETA=0:00:36
[02/18 13:32:30] mask2former INFO: Inference done 1006/1093. Dataloading: 0.0054 s/iter. Inference: 0.2405 s/iter. Eval: 0.1173 s/iter. Total: 0.3633 s/iter. ETA=0:00:31
[02/18 13:32:35] mask2former INFO: Inference done 1020/1093. Dataloading: 0.0054 s/iter. Inference: 0.2404 s/iter. Eval: 0.1173 s/iter. Total: 0.3632 s/iter. ETA=0:00:26
[02/18 13:32:40] mask2former INFO: Inference done 1034/1093. Dataloading: 0.0054 s/iter. Inference: 0.2406 s/iter. Eval: 0.1173 s/iter. Total: 0.3635 s/iter. ETA=0:00:21
[02/18 13:32:45] mask2former INFO: Inference done 1049/1093. Dataloading: 0.0054 s/iter. Inference: 0.2404 s/iter. Eval: 0.1172 s/iter. Total: 0.3631 s/iter. ETA=0:00:15
[02/18 13:32:50] mask2former INFO: Inference done 1063/1093. Dataloading: 0.0055 s/iter. Inference: 0.2405 s/iter. Eval: 0.1170 s/iter. Total: 0.3631 s/iter. ETA=0:00:10
[02/18 13:32:55] mask2former INFO: Inference done 1078/1093. Dataloading: 0.0055 s/iter. Inference: 0.2404 s/iter. Eval: 0.1170 s/iter. Total: 0.3629 s/iter. ETA=0:00:05
[02/18 13:33:30] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.512378388324249, 'error_1pix': 0.36982520491890025, 'error_3pix': 0.19738001527337773, 'mIoU': 21.100375517618367, 'fwIoU': 43.32544519617632, 'IoU-1': 94.94675336509843, 'IoU-2': 0.05025446693702521, 'IoU-3': 0.04207864744509019, 'IoU-4': 0.010982019330741418, 'IoU-5': 0.002861873124578768, 'IoU-6': 0.013311414939256645, 'IoU-7': 0.012664083428167385, 'IoU-8': 0.009940750730285875, 'IoU-9': 0.5844758011225885, 'IoU-10': 6.4764069817486645, 'IoU-11': 1.8465250140444107, 'IoU-12': 37.41751433854852, 'IoU-13': 31.413863777575212, 'IoU-14': 24.68067391285988, 'IoU-15': 21.411952145955354, 'IoU-16': 25.3055638032301, 'IoU-17': 25.134101778978525, 'IoU-18': 25.479073115581812, 'IoU-19': 29.773522323547002, 'IoU-20': 32.27793366277736, 'IoU-21': 11.610699838576762, 'IoU-22': 20.559558501281987, 'IoU-23': 24.67932130300518, 'IoU-24': 25.01430182696705, 'IoU-25': 32.08559394691223, 'IoU-26': 37.21884620920458, 'IoU-27': 26.080393781447974, 'IoU-28': 22.26298012202235, 'IoU-29': 25.786159488626932, 'IoU-30': 32.624850046713874, 'IoU-31': 27.129941245016294, 'IoU-32': 30.152769699306383, 'IoU-33': 23.54518814874969, 'IoU-34': 25.564455087768216, 'IoU-35': 31.862676849912734, 'IoU-36': 34.7126833380763, 'IoU-37': 18.278003379182987, 'IoU-38': 13.65134253907239, 'IoU-39': 12.576958841459748, 'IoU-40': 10.698665736935203, 'IoU-41': 15.076939818826752, 'IoU-42': 24.690218350848735, 'IoU-43': 33.306349569810386, 'IoU-44': 21.711163461247672, 'IoU-45': 16.420862040597008, 'IoU-46': 18.892483712039006, 'IoU-47': 19.19950882520478, 'IoU-48': 20.534655859865424, 'mACC': 34.13279352389095, 'pACC': 52.9497671620518, 'ACC-1': 96.63840785454916, 'ACC-2': 0.05025461164387575, 'ACC-3': 0.04715255649320305, 'ACC-4': 0.011442558357047621, 'ACC-5': 0.0029409256269318203, 'ACC-6': 0.013669909564489859, 'ACC-7': 0.013097529296626295, 'ACC-8': 0.010244434680003356, 'ACC-9': 39.917538176190085, 'ACC-10': 8.240848634901882, 'ACC-11': 2.0443262955708095, 'ACC-12': 77.05234239744367, 'ACC-13': 42.62123333236499, 'ACC-14': 33.7466524921663, 'ACC-15': 35.00296183663686, 'ACC-16': 45.99281344683767, 'ACC-17': 41.006389867131965, 'ACC-18': 36.9722068664403, 'ACC-19': 52.32468747788391, 'ACC-20': 73.00277533247034, 'ACC-21': 20.179346257418203, 'ACC-22': 31.968721362196884, 'ACC-23': 37.963728887577716, 'ACC-24': 36.35993746120788, 'ACC-25': 46.13619907796912, 'ACC-26': 65.79788957963905, 'ACC-27': 44.44672313577178, 'ACC-28': 33.873464309947785, 'ACC-29': 37.06137752982859, 'ACC-30': 55.46094177933202, 'ACC-31': 39.75484556347349, 'ACC-32': 48.865738797234684, 'ACC-33': 35.51871064442565, 'ACC-34': 35.35783548844008, 'ACC-35': 45.569800013621496, 'ACC-36': 65.80502167243513, 'ACC-37': 34.401877258598454, 'ACC-38': 26.028513573060103, 'ACC-39': 21.908517722038194, 'ACC-40': 16.17596569321334, 'ACC-41': 20.731697924487918, 'ACC-42': 34.14042862942475, 'ACC-43': 62.61095846233462, 'ACC-44': 38.999472117176886, 'ACC-45': 25.728774260874676, 'ACC-46': 30.266668595357547, 'ACC-47': 31.427750438732183, 'ACC-48': 31.12119637469727})])
[02/18 13:33:30] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 13:33:30] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 13:33:30] d2.evaluation.testing INFO: copypaste: 2.5124,0.3698,0.1974,21.1004,43.3254,34.1328,52.9498
[02/18 13:33:30] d2.utils.events INFO:  eta: 15:31:29  iter: 24999  total_loss: 30.34  loss_ce: 0  loss_mask: 0.7755  loss_dice: 2.135  loss_seg: 0.7295  loss_ce_0: 0  loss_mask_0: 0.7744  loss_dice_0: 2.21  loss_ce_1: 0  loss_mask_1: 0.7719  loss_dice_1: 2.155  loss_ce_2: 0  loss_mask_2: 0.7728  loss_dice_2: 2.147  loss_ce_3: 0  loss_mask_3: 0.7715  loss_dice_3: 2.132  loss_ce_4: 0  loss_mask_4: 0.7725  loss_dice_4: 2.129  loss_ce_5: 0  loss_mask_5: 0.7732  loss_dice_5: 2.13  loss_ce_6: 0  loss_mask_6: 0.7758  loss_dice_6: 2.128  loss_ce_7: 0  loss_mask_7: 0.7744  loss_dice_7: 2.128  loss_ce_8: 0  loss_mask_8: 0.7756  loss_dice_8: 2.131  time: 1.8817  data_time: 0.0311  lr: 6.1565e-05  max_mem: 6006M
[02/18 13:33:42] d2.utils.events INFO:  eta: 15:26:34  iter: 25019  total_loss: 29.33  loss_ce: 0  loss_mask: 0.7689  loss_dice: 2.107  loss_seg: 0.6496  loss_ce_0: 0  loss_mask_0: 0.7957  loss_dice_0: 2.159  loss_ce_1: 0  loss_mask_1: 0.7682  loss_dice_1: 2.13  loss_ce_2: 0  loss_mask_2: 0.7712  loss_dice_2: 2.115  loss_ce_3: 0  loss_mask_3: 0.7739  loss_dice_3: 2.1  loss_ce_4: 0  loss_mask_4: 0.7758  loss_dice_4: 2.092  loss_ce_5: 0  loss_mask_5: 0.7763  loss_dice_5: 2.096  loss_ce_6: 0  loss_mask_6: 0.7755  loss_dice_6: 2.092  loss_ce_7: 0  loss_mask_7: 0.779  loss_dice_7: 2.096  loss_ce_8: 0  loss_mask_8: 0.7768  loss_dice_8: 2.094  time: 1.8807  data_time: 0.0228  lr: 6.1534e-05  max_mem: 6006M
[02/18 13:33:54] d2.utils.events INFO:  eta: 15:24:00  iter: 25039  total_loss: 28.96  loss_ce: 0  loss_mask: 0.7676  loss_dice: 2.079  loss_seg: 0.503  loss_ce_0: 0  loss_mask_0: 0.7765  loss_dice_0: 2.158  loss_ce_1: 0  loss_mask_1: 0.7708  loss_dice_1: 2.098  loss_ce_2: 0  loss_mask_2: 0.7692  loss_dice_2: 2.067  loss_ce_3: 0  loss_mask_3: 0.7666  loss_dice_3: 2.061  loss_ce_4: 0  loss_mask_4: 0.7668  loss_dice_4: 2.062  loss_ce_5: 0  loss_mask_5: 0.7697  loss_dice_5: 2.07  loss_ce_6: 0  loss_mask_6: 0.7669  loss_dice_6: 2.063  loss_ce_7: 0  loss_mask_7: 0.7716  loss_dice_7: 2.067  loss_ce_8: 0  loss_mask_8: 0.7682  loss_dice_8: 2.063  time: 1.8797  data_time: 0.0235  lr: 6.1502e-05  max_mem: 6006M
[02/18 13:34:06] d2.utils.events INFO:  eta: 15:19:43  iter: 25059  total_loss: 29.35  loss_ce: 0  loss_mask: 0.731  loss_dice: 2.078  loss_seg: 0.8501  loss_ce_0: 0  loss_mask_0: 0.7476  loss_dice_0: 2.179  loss_ce_1: 0  loss_mask_1: 0.7274  loss_dice_1: 2.092  loss_ce_2: 0  loss_mask_2: 0.7303  loss_dice_2: 2.078  loss_ce_3: 0  loss_mask_3: 0.7355  loss_dice_3: 2.066  loss_ce_4: 0  loss_mask_4: 0.7379  loss_dice_4: 2.069  loss_ce_5: 0  loss_mask_5: 0.7384  loss_dice_5: 2.064  loss_ce_6: 0  loss_mask_6: 0.7414  loss_dice_6: 2.062  loss_ce_7: 0  loss_mask_7: 0.742  loss_dice_7: 2.064  loss_ce_8: 0  loss_mask_8: 0.7393  loss_dice_8: 2.059  time: 1.8787  data_time: 0.0193  lr: 6.147e-05  max_mem: 6006M
[02/18 13:34:19] d2.utils.events INFO:  eta: 15:12:29  iter: 25079  total_loss: 28.22  loss_ce: 0  loss_mask: 0.7217  loss_dice: 2.034  loss_seg: 0.7913  loss_ce_0: 0  loss_mask_0: 0.7352  loss_dice_0: 2.099  loss_ce_1: 0  loss_mask_1: 0.7346  loss_dice_1: 2.043  loss_ce_2: 0  loss_mask_2: 0.731  loss_dice_2: 2.026  loss_ce_3: 0  loss_mask_3: 0.7298  loss_dice_3: 2.016  loss_ce_4: 0  loss_mask_4: 0.7287  loss_dice_4: 2.02  loss_ce_5: 0  loss_mask_5: 0.7267  loss_dice_5: 2.027  loss_ce_6: 0  loss_mask_6: 0.7242  loss_dice_6: 2.022  loss_ce_7: 0  loss_mask_7: 0.7239  loss_dice_7: 2.023  loss_ce_8: 0  loss_mask_8: 0.7268  loss_dice_8: 2.027  time: 1.8777  data_time: 0.0257  lr: 6.1439e-05  max_mem: 6006M
[02/18 13:34:32] d2.utils.events INFO:  eta: 15:07:20  iter: 25099  total_loss: 28.26  loss_ce: 0  loss_mask: 0.7571  loss_dice: 1.993  loss_seg: 0.7317  loss_ce_0: 0  loss_mask_0: 0.7566  loss_dice_0: 2.075  loss_ce_1: 0  loss_mask_1: 0.7623  loss_dice_1: 1.994  loss_ce_2: 0  loss_mask_2: 0.7574  loss_dice_2: 1.993  loss_ce_3: 0  loss_mask_3: 0.7567  loss_dice_3: 1.982  loss_ce_4: 0  loss_mask_4: 0.7606  loss_dice_4: 1.981  loss_ce_5: 0  loss_mask_5: 0.7587  loss_dice_5: 1.986  loss_ce_6: 0  loss_mask_6: 0.7572  loss_dice_6: 1.98  loss_ce_7: 0  loss_mask_7: 0.7585  loss_dice_7: 1.987  loss_ce_8: 0  loss_mask_8: 0.7585  loss_dice_8: 1.992  time: 1.8767  data_time: 0.0247  lr: 6.1407e-05  max_mem: 6006M
[02/18 13:34:45] d2.utils.events INFO:  eta: 15:00:34  iter: 25119  total_loss: 29.57  loss_ce: 0  loss_mask: 0.7873  loss_dice: 2.057  loss_seg: 0.7151  loss_ce_0: 0  loss_mask_0: 0.794  loss_dice_0: 2.134  loss_ce_1: 0  loss_mask_1: 0.7869  loss_dice_1: 2.074  loss_ce_2: 0  loss_mask_2: 0.7873  loss_dice_2: 2.067  loss_ce_3: 0  loss_mask_3: 0.7937  loss_dice_3: 2.057  loss_ce_4: 0  loss_mask_4: 0.7894  loss_dice_4: 2.062  loss_ce_5: 0  loss_mask_5: 0.7911  loss_dice_5: 2.057  loss_ce_6: 0  loss_mask_6: 0.7934  loss_dice_6: 2.056  loss_ce_7: 0  loss_mask_7: 0.7915  loss_dice_7: 2.06  loss_ce_8: 0  loss_mask_8: 0.7904  loss_dice_8: 2.06  time: 1.8757  data_time: 0.0256  lr: 6.1375e-05  max_mem: 6006M
[02/18 13:35:06] d2.utils.events INFO:  eta: 14:54:13  iter: 25139  total_loss: 28.39  loss_ce: 0  loss_mask: 0.7224  loss_dice: 2.034  loss_seg: 0.6382  loss_ce_0: 0  loss_mask_0: 0.7404  loss_dice_0: 2.118  loss_ce_1: 0  loss_mask_1: 0.729  loss_dice_1: 2.055  loss_ce_2: 0  loss_mask_2: 0.7275  loss_dice_2: 2.036  loss_ce_3: 0  loss_mask_3: 0.7258  loss_dice_3: 2.022  loss_ce_4: 0  loss_mask_4: 0.7261  loss_dice_4: 2.027  loss_ce_5: 0  loss_mask_5: 0.7267  loss_dice_5: 2.02  loss_ce_6: 0  loss_mask_6: 0.7266  loss_dice_6: 2.016  loss_ce_7: 0  loss_mask_7: 0.7258  loss_dice_7: 2.02  loss_ce_8: 0  loss_mask_8: 0.7265  loss_dice_8: 2.021  time: 1.8750  data_time: 0.0426  lr: 6.1344e-05  max_mem: 6006M
[02/18 13:35:37] d2.utils.events INFO:  eta: 14:53:43  iter: 25159  total_loss: 29.99  loss_ce: 0  loss_mask: 0.7898  loss_dice: 2.131  loss_seg: 0.6938  loss_ce_0: 0  loss_mask_0: 0.8011  loss_dice_0: 2.172  loss_ce_1: 0  loss_mask_1: 0.7912  loss_dice_1: 2.137  loss_ce_2: 0  loss_mask_2: 0.79  loss_dice_2: 2.132  loss_ce_3: 0  loss_mask_3: 0.7923  loss_dice_3: 2.126  loss_ce_4: 0  loss_mask_4: 0.7917  loss_dice_4: 2.127  loss_ce_5: 0  loss_mask_5: 0.7888  loss_dice_5: 2.13  loss_ce_6: 0  loss_mask_6: 0.7894  loss_dice_6: 2.117  loss_ce_7: 0  loss_mask_7: 0.7883  loss_dice_7: 2.125  loss_ce_8: 0  loss_mask_8: 0.7895  loss_dice_8: 2.118  time: 1.8748  data_time: 0.0258  lr: 6.1312e-05  max_mem: 6006M
[02/18 13:36:09] d2.utils.events INFO:  eta: 14:53:07  iter: 25179  total_loss: 27.69  loss_ce: 0  loss_mask: 0.7183  loss_dice: 1.958  loss_seg: 0.8352  loss_ce_0: 0  loss_mask_0: 0.7328  loss_dice_0: 2.041  loss_ce_1: 0  loss_mask_1: 0.719  loss_dice_1: 1.97  loss_ce_2: 0  loss_mask_2: 0.7201  loss_dice_2: 1.953  loss_ce_3: 0  loss_mask_3: 0.7256  loss_dice_3: 1.944  loss_ce_4: 0  loss_mask_4: 0.7273  loss_dice_4: 1.943  loss_ce_5: 0  loss_mask_5: 0.7253  loss_dice_5: 1.943  loss_ce_6: 0  loss_mask_6: 0.7276  loss_dice_6: 1.935  loss_ce_7: 0  loss_mask_7: 0.7255  loss_dice_7: 1.935  loss_ce_8: 0  loss_mask_8: 0.7252  loss_dice_8: 1.946  time: 1.8745  data_time: 0.0369  lr: 6.128e-05  max_mem: 6006M
[02/18 13:36:40] d2.utils.events INFO:  eta: 14:50:18  iter: 25199  total_loss: 29.56  loss_ce: 0  loss_mask: 0.7668  loss_dice: 2.06  loss_seg: 0.6514  loss_ce_0: 0  loss_mask_0: 0.7723  loss_dice_0: 2.113  loss_ce_1: 0  loss_mask_1: 0.7745  loss_dice_1: 2.07  loss_ce_2: 0  loss_mask_2: 0.7734  loss_dice_2: 2.048  loss_ce_3: 0  loss_mask_3: 0.7693  loss_dice_3: 2.042  loss_ce_4: 0  loss_mask_4: 0.7668  loss_dice_4: 2.043  loss_ce_5: 0  loss_mask_5: 0.7649  loss_dice_5: 2.044  loss_ce_6: 0  loss_mask_6: 0.7705  loss_dice_6: 2.051  loss_ce_7: 0  loss_mask_7: 0.7714  loss_dice_7: 2.05  loss_ce_8: 0  loss_mask_8: 0.7704  loss_dice_8: 2.051  time: 1.8743  data_time: 0.0306  lr: 6.1249e-05  max_mem: 6006M
[02/18 13:37:13] d2.utils.events INFO:  eta: 14:50:33  iter: 25219  total_loss: 28.14  loss_ce: 0  loss_mask: 0.745  loss_dice: 1.997  loss_seg: 0.6016  loss_ce_0: 0  loss_mask_0: 0.766  loss_dice_0: 2.062  loss_ce_1: 0  loss_mask_1: 0.7514  loss_dice_1: 2.014  loss_ce_2: 0  loss_mask_2: 0.7475  loss_dice_2: 1.999  loss_ce_3: 0  loss_mask_3: 0.7492  loss_dice_3: 1.979  loss_ce_4: 0  loss_mask_4: 0.7478  loss_dice_4: 1.974  loss_ce_5: 0  loss_mask_5: 0.7473  loss_dice_5: 1.981  loss_ce_6: 0  loss_mask_6: 0.7469  loss_dice_6: 1.985  loss_ce_7: 0  loss_mask_7: 0.7475  loss_dice_7: 1.982  loss_ce_8: 0  loss_mask_8: 0.7475  loss_dice_8: 1.984  time: 1.8741  data_time: 0.0274  lr: 6.1217e-05  max_mem: 6006M
[02/18 13:37:48] d2.utils.events INFO:  eta: 14:51:39  iter: 25239  total_loss: 30.36  loss_ce: 0  loss_mask: 0.7724  loss_dice: 2.153  loss_seg: 0.8376  loss_ce_0: 0  loss_mask_0: 0.7798  loss_dice_0: 2.209  loss_ce_1: 0  loss_mask_1: 0.7674  loss_dice_1: 2.162  loss_ce_2: 0  loss_mask_2: 0.7694  loss_dice_2: 2.143  loss_ce_3: 0  loss_mask_3: 0.7712  loss_dice_3: 2.139  loss_ce_4: 0  loss_mask_4: 0.7708  loss_dice_4: 2.14  loss_ce_5: 0  loss_mask_5: 0.7731  loss_dice_5: 2.143  loss_ce_6: 0  loss_mask_6: 0.7741  loss_dice_6: 2.136  loss_ce_7: 0  loss_mask_7: 0.7735  loss_dice_7: 2.137  loss_ce_8: 0  loss_mask_8: 0.7723  loss_dice_8: 2.145  time: 1.8740  data_time: 0.0212  lr: 6.1185e-05  max_mem: 6006M
[02/18 13:38:22] d2.utils.events INFO:  eta: 14:52:13  iter: 25259  total_loss: 29.06  loss_ce: 0  loss_mask: 0.7382  loss_dice: 2.077  loss_seg: 0.6073  loss_ce_0: 0  loss_mask_0: 0.7608  loss_dice_0: 2.136  loss_ce_1: 0  loss_mask_1: 0.7491  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7483  loss_dice_2: 2.077  loss_ce_3: 0  loss_mask_3: 0.7391  loss_dice_3: 2.075  loss_ce_4: 0  loss_mask_4: 0.7395  loss_dice_4: 2.076  loss_ce_5: 0  loss_mask_5: 0.7387  loss_dice_5: 2.074  loss_ce_6: 0  loss_mask_6: 0.7359  loss_dice_6: 2.075  loss_ce_7: 0  loss_mask_7: 0.7357  loss_dice_7: 2.076  loss_ce_8: 0  loss_mask_8: 0.7406  loss_dice_8: 2.072  time: 1.8739  data_time: 0.0274  lr: 6.1154e-05  max_mem: 6006M
[02/18 13:38:55] d2.utils.events INFO:  eta: 14:50:54  iter: 25279  total_loss: 29.95  loss_ce: 0  loss_mask: 0.7512  loss_dice: 2.166  loss_seg: 0.8415  loss_ce_0: 0  loss_mask_0: 0.7651  loss_dice_0: 2.236  loss_ce_1: 0  loss_mask_1: 0.7583  loss_dice_1: 2.172  loss_ce_2: 0  loss_mask_2: 0.7558  loss_dice_2: 2.164  loss_ce_3: 0  loss_mask_3: 0.7576  loss_dice_3: 2.158  loss_ce_4: 0  loss_mask_4: 0.7587  loss_dice_4: 2.161  loss_ce_5: 0  loss_mask_5: 0.7568  loss_dice_5: 2.156  loss_ce_6: 0  loss_mask_6: 0.7561  loss_dice_6: 2.159  loss_ce_7: 0  loss_mask_7: 0.7535  loss_dice_7: 2.166  loss_ce_8: 0  loss_mask_8: 0.7552  loss_dice_8: 2.162  time: 1.8737  data_time: 0.0267  lr: 6.1122e-05  max_mem: 6006M
[02/18 13:39:29] d2.utils.events INFO:  eta: 14:49:46  iter: 25299  total_loss: 30.73  loss_ce: 0  loss_mask: 0.811  loss_dice: 2.174  loss_seg: 0.9511  loss_ce_0: 0  loss_mask_0: 0.8208  loss_dice_0: 2.241  loss_ce_1: 0  loss_mask_1: 0.8104  loss_dice_1: 2.188  loss_ce_2: 0  loss_mask_2: 0.8133  loss_dice_2: 2.183  loss_ce_3: 0  loss_mask_3: 0.811  loss_dice_3: 2.175  loss_ce_4: 0  loss_mask_4: 0.8104  loss_dice_4: 2.172  loss_ce_5: 0  loss_mask_5: 0.8084  loss_dice_5: 2.171  loss_ce_6: 0  loss_mask_6: 0.8097  loss_dice_6: 2.168  loss_ce_7: 0  loss_mask_7: 0.8091  loss_dice_7: 2.163  loss_ce_8: 0  loss_mask_8: 0.8104  loss_dice_8: 2.164  time: 1.8735  data_time: 0.0288  lr: 6.109e-05  max_mem: 6006M
[02/18 13:40:02] d2.utils.events INFO:  eta: 14:48:39  iter: 25319  total_loss: 30.4  loss_ce: 0  loss_mask: 0.7543  loss_dice: 2.15  loss_seg: 0.9389  loss_ce_0: 0  loss_mask_0: 0.7846  loss_dice_0: 2.219  loss_ce_1: 0  loss_mask_1: 0.756  loss_dice_1: 2.171  loss_ce_2: 0  loss_mask_2: 0.76  loss_dice_2: 2.161  loss_ce_3: 0  loss_mask_3: 0.7586  loss_dice_3: 2.147  loss_ce_4: 0  loss_mask_4: 0.7608  loss_dice_4: 2.148  loss_ce_5: 0  loss_mask_5: 0.7582  loss_dice_5: 2.146  loss_ce_6: 0  loss_mask_6: 0.7593  loss_dice_6: 2.149  loss_ce_7: 0  loss_mask_7: 0.7628  loss_dice_7: 2.148  loss_ce_8: 0  loss_mask_8: 0.763  loss_dice_8: 2.15  time: 1.8734  data_time: 0.0269  lr: 6.1059e-05  max_mem: 6006M
[02/18 13:40:34] d2.utils.events INFO:  eta: 14:48:09  iter: 25339  total_loss: 30.83  loss_ce: 0  loss_mask: 0.7781  loss_dice: 2.197  loss_seg: 0.6922  loss_ce_0: 0  loss_mask_0: 0.7887  loss_dice_0: 2.251  loss_ce_1: 0  loss_mask_1: 0.7725  loss_dice_1: 2.213  loss_ce_2: 0  loss_mask_2: 0.7738  loss_dice_2: 2.197  loss_ce_3: 0  loss_mask_3: 0.7743  loss_dice_3: 2.182  loss_ce_4: 0  loss_mask_4: 0.7805  loss_dice_4: 2.182  loss_ce_5: 0  loss_mask_5: 0.7775  loss_dice_5: 2.188  loss_ce_6: 0  loss_mask_6: 0.7801  loss_dice_6: 2.179  loss_ce_7: 0  loss_mask_7: 0.7818  loss_dice_7: 2.184  loss_ce_8: 0  loss_mask_8: 0.7813  loss_dice_8: 2.186  time: 1.8732  data_time: 0.0317  lr: 6.1027e-05  max_mem: 6006M
[02/18 13:41:08] d2.utils.events INFO:  eta: 14:48:51  iter: 25359  total_loss: 29.22  loss_ce: 0  loss_mask: 0.7634  loss_dice: 2.065  loss_seg: 0.5566  loss_ce_0: 0  loss_mask_0: 0.7759  loss_dice_0: 2.132  loss_ce_1: 0  loss_mask_1: 0.772  loss_dice_1: 2.068  loss_ce_2: 0  loss_mask_2: 0.7677  loss_dice_2: 2.059  loss_ce_3: 0  loss_mask_3: 0.7606  loss_dice_3: 2.061  loss_ce_4: 0  loss_mask_4: 0.7639  loss_dice_4: 2.063  loss_ce_5: 0  loss_mask_5: 0.7637  loss_dice_5: 2.063  loss_ce_6: 0  loss_mask_6: 0.7603  loss_dice_6: 2.063  loss_ce_7: 0  loss_mask_7: 0.7629  loss_dice_7: 2.064  loss_ce_8: 0  loss_mask_8: 0.7628  loss_dice_8: 2.06  time: 1.8730  data_time: 0.0266  lr: 6.0995e-05  max_mem: 6006M
[02/18 13:41:41] d2.utils.events INFO:  eta: 14:49:50  iter: 25379  total_loss: 29.36  loss_ce: 0  loss_mask: 0.7073  loss_dice: 2.076  loss_seg: 0.7077  loss_ce_0: 0  loss_mask_0: 0.7206  loss_dice_0: 2.134  loss_ce_1: 0  loss_mask_1: 0.7078  loss_dice_1: 2.104  loss_ce_2: 0  loss_mask_2: 0.7102  loss_dice_2: 2.078  loss_ce_3: 0  loss_mask_3: 0.7129  loss_dice_3: 2.065  loss_ce_4: 0  loss_mask_4: 0.7106  loss_dice_4: 2.065  loss_ce_5: 0  loss_mask_5: 0.7101  loss_dice_5: 2.067  loss_ce_6: 0  loss_mask_6: 0.7144  loss_dice_6: 2.071  loss_ce_7: 0  loss_mask_7: 0.7143  loss_dice_7: 2.074  loss_ce_8: 0  loss_mask_8: 0.7139  loss_dice_8: 2.074  time: 1.8728  data_time: 0.0279  lr: 6.0963e-05  max_mem: 6006M
[02/18 13:42:16] d2.utils.events INFO:  eta: 14:52:20  iter: 25399  total_loss: 30.01  loss_ce: 0  loss_mask: 0.7736  loss_dice: 2.131  loss_seg: 0.585  loss_ce_0: 0  loss_mask_0: 0.7761  loss_dice_0: 2.199  loss_ce_1: 0  loss_mask_1: 0.7707  loss_dice_1: 2.151  loss_ce_2: 0  loss_mask_2: 0.7724  loss_dice_2: 2.137  loss_ce_3: 0  loss_mask_3: 0.7795  loss_dice_3: 2.116  loss_ce_4: 0  loss_mask_4: 0.7822  loss_dice_4: 2.114  loss_ce_5: 0  loss_mask_5: 0.7813  loss_dice_5: 2.121  loss_ce_6: 0  loss_mask_6: 0.7825  loss_dice_6: 2.118  loss_ce_7: 0  loss_mask_7: 0.7812  loss_dice_7: 2.114  loss_ce_8: 0  loss_mask_8: 0.7813  loss_dice_8: 2.123  time: 1.8727  data_time: 0.0299  lr: 6.0932e-05  max_mem: 6006M
[02/18 13:42:49] d2.utils.events INFO:  eta: 14:53:43  iter: 25419  total_loss: 28.27  loss_ce: 0  loss_mask: 0.7504  loss_dice: 1.981  loss_seg: 0.8376  loss_ce_0: 0  loss_mask_0: 0.7527  loss_dice_0: 2.053  loss_ce_1: 0  loss_mask_1: 0.7524  loss_dice_1: 1.992  loss_ce_2: 0  loss_mask_2: 0.7539  loss_dice_2: 1.987  loss_ce_3: 0  loss_mask_3: 0.7497  loss_dice_3: 1.975  loss_ce_4: 0  loss_mask_4: 0.7488  loss_dice_4: 1.976  loss_ce_5: 0  loss_mask_5: 0.7507  loss_dice_5: 1.978  loss_ce_6: 0  loss_mask_6: 0.7497  loss_dice_6: 1.976  loss_ce_7: 0  loss_mask_7: 0.7512  loss_dice_7: 1.981  loss_ce_8: 0  loss_mask_8: 0.7521  loss_dice_8: 1.979  time: 1.8725  data_time: 0.0276  lr: 6.09e-05  max_mem: 6006M
[02/18 13:43:23] d2.utils.events INFO:  eta: 14:55:14  iter: 25439  total_loss: 30.06  loss_ce: 0  loss_mask: 0.7506  loss_dice: 2.12  loss_seg: 0.8068  loss_ce_0: 0  loss_mask_0: 0.7453  loss_dice_0: 2.189  loss_ce_1: 0  loss_mask_1: 0.75  loss_dice_1: 2.129  loss_ce_2: 0  loss_mask_2: 0.7515  loss_dice_2: 2.121  loss_ce_3: 0  loss_mask_3: 0.7503  loss_dice_3: 2.113  loss_ce_4: 0  loss_mask_4: 0.7524  loss_dice_4: 2.111  loss_ce_5: 0  loss_mask_5: 0.7526  loss_dice_5: 2.118  loss_ce_6: 0  loss_mask_6: 0.7565  loss_dice_6: 2.114  loss_ce_7: 0  loss_mask_7: 0.7557  loss_dice_7: 2.116  loss_ce_8: 0  loss_mask_8: 0.7539  loss_dice_8: 2.119  time: 1.8724  data_time: 0.0275  lr: 6.0868e-05  max_mem: 6006M
[02/18 13:43:57] d2.utils.events INFO:  eta: 14:53:19  iter: 25459  total_loss: 29.31  loss_ce: 0  loss_mask: 0.7518  loss_dice: 2.071  loss_seg: 0.8132  loss_ce_0: 0  loss_mask_0: 0.7688  loss_dice_0: 2.138  loss_ce_1: 0  loss_mask_1: 0.7566  loss_dice_1: 2.074  loss_ce_2: 0  loss_mask_2: 0.7544  loss_dice_2: 2.06  loss_ce_3: 0  loss_mask_3: 0.7536  loss_dice_3: 2.053  loss_ce_4: 0  loss_mask_4: 0.7525  loss_dice_4: 2.055  loss_ce_5: 0  loss_mask_5: 0.7533  loss_dice_5: 2.052  loss_ce_6: 0  loss_mask_6: 0.7556  loss_dice_6: 2.054  loss_ce_7: 0  loss_mask_7: 0.7556  loss_dice_7: 2.055  loss_ce_8: 0  loss_mask_8: 0.7522  loss_dice_8: 2.056  time: 1.8723  data_time: 0.0279  lr: 6.0837e-05  max_mem: 6006M
[02/18 13:44:29] d2.utils.events INFO:  eta: 14:52:10  iter: 25479  total_loss: 29.24  loss_ce: 0  loss_mask: 0.7683  loss_dice: 2.085  loss_seg: 0.6006  loss_ce_0: 0  loss_mask_0: 0.7851  loss_dice_0: 2.144  loss_ce_1: 0  loss_mask_1: 0.7769  loss_dice_1: 2.097  loss_ce_2: 0  loss_mask_2: 0.7753  loss_dice_2: 2.079  loss_ce_3: 0  loss_mask_3: 0.7727  loss_dice_3: 2.073  loss_ce_4: 0  loss_mask_4: 0.7722  loss_dice_4: 2.073  loss_ce_5: 0  loss_mask_5: 0.7737  loss_dice_5: 2.074  loss_ce_6: 0  loss_mask_6: 0.77  loss_dice_6: 2.074  loss_ce_7: 0  loss_mask_7: 0.7695  loss_dice_7: 2.078  loss_ce_8: 0  loss_mask_8: 0.7699  loss_dice_8: 2.077  time: 1.8721  data_time: 0.0295  lr: 6.0805e-05  max_mem: 6006M
[02/18 13:45:00] d2.utils.events INFO:  eta: 14:53:41  iter: 25499  total_loss: 27.65  loss_ce: 0  loss_mask: 0.7186  loss_dice: 1.963  loss_seg: 0.7981  loss_ce_0: 0  loss_mask_0: 0.7301  loss_dice_0: 2.036  loss_ce_1: 0  loss_mask_1: 0.7284  loss_dice_1: 1.982  loss_ce_2: 0  loss_mask_2: 0.7246  loss_dice_2: 1.973  loss_ce_3: 0  loss_mask_3: 0.7226  loss_dice_3: 1.966  loss_ce_4: 0  loss_mask_4: 0.7231  loss_dice_4: 1.965  loss_ce_5: 0  loss_mask_5: 0.7214  loss_dice_5: 1.965  loss_ce_6: 0  loss_mask_6: 0.723  loss_dice_6: 1.957  loss_ce_7: 0  loss_mask_7: 0.7237  loss_dice_7: 1.956  loss_ce_8: 0  loss_mask_8: 0.7233  loss_dice_8: 1.96  time: 1.8718  data_time: 0.0290  lr: 6.0773e-05  max_mem: 6006M
[02/18 13:45:33] d2.utils.events INFO:  eta: 14:54:51  iter: 25519  total_loss: 29.48  loss_ce: 0  loss_mask: 0.7426  loss_dice: 2.125  loss_seg: 0.8731  loss_ce_0: 0  loss_mask_0: 0.7463  loss_dice_0: 2.182  loss_ce_1: 0  loss_mask_1: 0.753  loss_dice_1: 2.126  loss_ce_2: 0  loss_mask_2: 0.748  loss_dice_2: 2.115  loss_ce_3: 0  loss_mask_3: 0.7452  loss_dice_3: 2.109  loss_ce_4: 0  loss_mask_4: 0.7468  loss_dice_4: 2.112  loss_ce_5: 0  loss_mask_5: 0.7438  loss_dice_5: 2.113  loss_ce_6: 0  loss_mask_6: 0.7458  loss_dice_6: 2.109  loss_ce_7: 0  loss_mask_7: 0.7428  loss_dice_7: 2.108  loss_ce_8: 0  loss_mask_8: 0.7409  loss_dice_8: 2.103  time: 1.8716  data_time: 0.0302  lr: 6.0742e-05  max_mem: 6006M
[02/18 13:46:08] d2.utils.events INFO:  eta: 14:55:07  iter: 25539  total_loss: 29.98  loss_ce: 0  loss_mask: 0.7653  loss_dice: 2.073  loss_seg: 0.7243  loss_ce_0: 0  loss_mask_0: 0.779  loss_dice_0: 2.15  loss_ce_1: 0  loss_mask_1: 0.7691  loss_dice_1: 2.086  loss_ce_2: 0  loss_mask_2: 0.7677  loss_dice_2: 2.068  loss_ce_3: 0  loss_mask_3: 0.7687  loss_dice_3: 2.064  loss_ce_4: 0  loss_mask_4: 0.7723  loss_dice_4: 2.069  loss_ce_5: 0  loss_mask_5: 0.7716  loss_dice_5: 2.061  loss_ce_6: 0  loss_mask_6: 0.7695  loss_dice_6: 2.059  loss_ce_7: 0  loss_mask_7: 0.7735  loss_dice_7: 2.054  loss_ce_8: 0  loss_mask_8: 0.7732  loss_dice_8: 2.053  time: 1.8715  data_time: 0.0280  lr: 6.071e-05  max_mem: 6006M
[02/18 13:46:41] d2.utils.events INFO:  eta: 14:54:31  iter: 25559  total_loss: 29.81  loss_ce: 0  loss_mask: 0.7618  loss_dice: 2.172  loss_seg: 0.4353  loss_ce_0: 0  loss_mask_0: 0.7786  loss_dice_0: 2.234  loss_ce_1: 0  loss_mask_1: 0.7747  loss_dice_1: 2.193  loss_ce_2: 0  loss_mask_2: 0.7652  loss_dice_2: 2.179  loss_ce_3: 0  loss_mask_3: 0.7655  loss_dice_3: 2.163  loss_ce_4: 0  loss_mask_4: 0.7672  loss_dice_4: 2.166  loss_ce_5: 0  loss_mask_5: 0.767  loss_dice_5: 2.164  loss_ce_6: 0  loss_mask_6: 0.7673  loss_dice_6: 2.16  loss_ce_7: 0  loss_mask_7: 0.7696  loss_dice_7: 2.161  loss_ce_8: 0  loss_mask_8: 0.7674  loss_dice_8: 2.167  time: 1.8714  data_time: 0.0275  lr: 6.0678e-05  max_mem: 6006M
[02/18 13:47:13] d2.utils.events INFO:  eta: 14:54:30  iter: 25579  total_loss: 28.36  loss_ce: 0  loss_mask: 0.768  loss_dice: 1.975  loss_seg: 0.6597  loss_ce_0: 0  loss_mask_0: 0.7864  loss_dice_0: 2.043  loss_ce_1: 0  loss_mask_1: 0.7737  loss_dice_1: 1.977  loss_ce_2: 0  loss_mask_2: 0.7742  loss_dice_2: 1.975  loss_ce_3: 0  loss_mask_3: 0.7711  loss_dice_3: 1.963  loss_ce_4: 0  loss_mask_4: 0.7703  loss_dice_4: 1.962  loss_ce_5: 0  loss_mask_5: 0.7684  loss_dice_5: 1.963  loss_ce_6: 0  loss_mask_6: 0.769  loss_dice_6: 1.964  loss_ce_7: 0  loss_mask_7: 0.7693  loss_dice_7: 1.966  loss_ce_8: 0  loss_mask_8: 0.7676  loss_dice_8: 1.962  time: 1.8711  data_time: 0.0224  lr: 6.0646e-05  max_mem: 6006M
[02/18 13:47:46] d2.utils.events INFO:  eta: 14:53:34  iter: 25599  total_loss: 28.79  loss_ce: 0  loss_mask: 0.7333  loss_dice: 2.097  loss_seg: 0.7797  loss_ce_0: 0  loss_mask_0: 0.7432  loss_dice_0: 2.189  loss_ce_1: 0  loss_mask_1: 0.7412  loss_dice_1: 2.123  loss_ce_2: 0  loss_mask_2: 0.735  loss_dice_2: 2.095  loss_ce_3: 0  loss_mask_3: 0.7336  loss_dice_3: 2.084  loss_ce_4: 0  loss_mask_4: 0.7349  loss_dice_4: 2.088  loss_ce_5: 0  loss_mask_5: 0.7346  loss_dice_5: 2.083  loss_ce_6: 0  loss_mask_6: 0.7356  loss_dice_6: 2.084  loss_ce_7: 0  loss_mask_7: 0.7381  loss_dice_7: 2.083  loss_ce_8: 0  loss_mask_8: 0.734  loss_dice_8: 2.084  time: 1.8710  data_time: 0.0272  lr: 6.0615e-05  max_mem: 6006M
[02/18 13:48:16] d2.utils.events INFO:  eta: 14:49:11  iter: 25619  total_loss: 28.72  loss_ce: 0  loss_mask: 0.7442  loss_dice: 2.03  loss_seg: 0.7754  loss_ce_0: 0  loss_mask_0: 0.7579  loss_dice_0: 2.076  loss_ce_1: 0  loss_mask_1: 0.7505  loss_dice_1: 2.045  loss_ce_2: 0  loss_mask_2: 0.747  loss_dice_2: 2.03  loss_ce_3: 0  loss_mask_3: 0.7557  loss_dice_3: 2.017  loss_ce_4: 0  loss_mask_4: 0.752  loss_dice_4: 2.025  loss_ce_5: 0  loss_mask_5: 0.7508  loss_dice_5: 2.018  loss_ce_6: 0  loss_mask_6: 0.7541  loss_dice_6: 2.025  loss_ce_7: 0  loss_mask_7: 0.7519  loss_dice_7: 2.021  loss_ce_8: 0  loss_mask_8: 0.7506  loss_dice_8: 2.019  time: 1.8707  data_time: 0.0267  lr: 6.0583e-05  max_mem: 6006M
[02/18 13:48:47] d2.utils.events INFO:  eta: 14:48:02  iter: 25639  total_loss: 28.92  loss_ce: 0  loss_mask: 0.7277  loss_dice: 2.1  loss_seg: 0.6619  loss_ce_0: 0  loss_mask_0: 0.7246  loss_dice_0: 2.177  loss_ce_1: 0  loss_mask_1: 0.7304  loss_dice_1: 2.113  loss_ce_2: 0  loss_mask_2: 0.731  loss_dice_2: 2.103  loss_ce_3: 0  loss_mask_3: 0.7275  loss_dice_3: 2.089  loss_ce_4: 0  loss_mask_4: 0.7262  loss_dice_4: 2.089  loss_ce_5: 0  loss_mask_5: 0.7273  loss_dice_5: 2.088  loss_ce_6: 0  loss_mask_6: 0.7279  loss_dice_6: 2.09  loss_ce_7: 0  loss_mask_7: 0.7285  loss_dice_7: 2.094  loss_ce_8: 0  loss_mask_8: 0.7284  loss_dice_8: 2.09  time: 1.8704  data_time: 0.0349  lr: 6.0551e-05  max_mem: 6006M
[02/18 13:49:17] d2.utils.events INFO:  eta: 14:43:40  iter: 25659  total_loss: 28.65  loss_ce: 0  loss_mask: 0.7091  loss_dice: 2.048  loss_seg: 0.7817  loss_ce_0: 0  loss_mask_0: 0.7064  loss_dice_0: 2.118  loss_ce_1: 0  loss_mask_1: 0.7119  loss_dice_1: 2.056  loss_ce_2: 0  loss_mask_2: 0.7104  loss_dice_2: 2.048  loss_ce_3: 0  loss_mask_3: 0.7095  loss_dice_3: 2.032  loss_ce_4: 0  loss_mask_4: 0.7105  loss_dice_4: 2.033  loss_ce_5: 0  loss_mask_5: 0.7094  loss_dice_5: 2.03  loss_ce_6: 0  loss_mask_6: 0.7102  loss_dice_6: 2.025  loss_ce_7: 0  loss_mask_7: 0.7109  loss_dice_7: 2.029  loss_ce_8: 0  loss_mask_8: 0.7094  loss_dice_8: 2.032  time: 1.8701  data_time: 0.0252  lr: 6.052e-05  max_mem: 6006M
[02/18 13:49:49] d2.utils.events INFO:  eta: 14:46:12  iter: 25679  total_loss: 30.66  loss_ce: 0  loss_mask: 0.7849  loss_dice: 2.188  loss_seg: 0.7154  loss_ce_0: 0  loss_mask_0: 0.7978  loss_dice_0: 2.231  loss_ce_1: 0  loss_mask_1: 0.7879  loss_dice_1: 2.208  loss_ce_2: 0  loss_mask_2: 0.7821  loss_dice_2: 2.189  loss_ce_3: 0  loss_mask_3: 0.7837  loss_dice_3: 2.179  loss_ce_4: 0  loss_mask_4: 0.7883  loss_dice_4: 2.178  loss_ce_5: 0  loss_mask_5: 0.7891  loss_dice_5: 2.178  loss_ce_6: 0  loss_mask_6: 0.7883  loss_dice_6: 2.18  loss_ce_7: 0  loss_mask_7: 0.7901  loss_dice_7: 2.183  loss_ce_8: 0  loss_mask_8: 0.7904  loss_dice_8: 2.187  time: 1.8699  data_time: 0.0374  lr: 6.0488e-05  max_mem: 6006M
[02/18 13:50:22] d2.utils.events INFO:  eta: 14:45:14  iter: 25699  total_loss: 29.77  loss_ce: 0  loss_mask: 0.7298  loss_dice: 2.108  loss_seg: 0.7581  loss_ce_0: 0  loss_mask_0: 0.7384  loss_dice_0: 2.166  loss_ce_1: 0  loss_mask_1: 0.7377  loss_dice_1: 2.125  loss_ce_2: 0  loss_mask_2: 0.7355  loss_dice_2: 2.112  loss_ce_3: 0  loss_mask_3: 0.7383  loss_dice_3: 2.099  loss_ce_4: 0  loss_mask_4: 0.7371  loss_dice_4: 2.1  loss_ce_5: 0  loss_mask_5: 0.7326  loss_dice_5: 2.1  loss_ce_6: 0  loss_mask_6: 0.7344  loss_dice_6: 2.101  loss_ce_7: 0  loss_mask_7: 0.7389  loss_dice_7: 2.095  loss_ce_8: 0  loss_mask_8: 0.7356  loss_dice_8: 2.102  time: 1.8697  data_time: 0.0335  lr: 6.0456e-05  max_mem: 6006M
[02/18 13:50:56] d2.utils.events INFO:  eta: 14:47:23  iter: 25719  total_loss: 29.71  loss_ce: 0  loss_mask: 0.7491  loss_dice: 2.119  loss_seg: 0.8126  loss_ce_0: 0  loss_mask_0: 0.7541  loss_dice_0: 2.212  loss_ce_1: 0  loss_mask_1: 0.7442  loss_dice_1: 2.142  loss_ce_2: 0  loss_mask_2: 0.7463  loss_dice_2: 2.117  loss_ce_3: 0  loss_mask_3: 0.7469  loss_dice_3: 2.109  loss_ce_4: 0  loss_mask_4: 0.7476  loss_dice_4: 2.107  loss_ce_5: 0  loss_mask_5: 0.7484  loss_dice_5: 2.11  loss_ce_6: 0  loss_mask_6: 0.7484  loss_dice_6: 2.107  loss_ce_7: 0  loss_mask_7: 0.7455  loss_dice_7: 2.104  loss_ce_8: 0  loss_mask_8: 0.7484  loss_dice_8: 2.106  time: 1.8696  data_time: 0.0278  lr: 6.0424e-05  max_mem: 6006M
[02/18 13:51:29] d2.utils.events INFO:  eta: 14:44:25  iter: 25739  total_loss: 28.6  loss_ce: 0  loss_mask: 0.7249  loss_dice: 2.062  loss_seg: 0.8665  loss_ce_0: 0  loss_mask_0: 0.7392  loss_dice_0: 2.131  loss_ce_1: 0  loss_mask_1: 0.7346  loss_dice_1: 2.074  loss_ce_2: 0  loss_mask_2: 0.7341  loss_dice_2: 2.069  loss_ce_3: 0  loss_mask_3: 0.7321  loss_dice_3: 2.054  loss_ce_4: 0  loss_mask_4: 0.7325  loss_dice_4: 2.055  loss_ce_5: 0  loss_mask_5: 0.7313  loss_dice_5: 2.051  loss_ce_6: 0  loss_mask_6: 0.7329  loss_dice_6: 2.052  loss_ce_7: 0  loss_mask_7: 0.7297  loss_dice_7: 2.052  loss_ce_8: 0  loss_mask_8: 0.7288  loss_dice_8: 2.052  time: 1.8694  data_time: 0.0293  lr: 6.0393e-05  max_mem: 6006M
[02/18 13:52:01] d2.utils.events INFO:  eta: 14:44:24  iter: 25759  total_loss: 29.31  loss_ce: 0  loss_mask: 0.7795  loss_dice: 2.077  loss_seg: 0.6635  loss_ce_0: 0  loss_mask_0: 0.7907  loss_dice_0: 2.121  loss_ce_1: 0  loss_mask_1: 0.7871  loss_dice_1: 2.083  loss_ce_2: 0  loss_mask_2: 0.7846  loss_dice_2: 2.075  loss_ce_3: 0  loss_mask_3: 0.7835  loss_dice_3: 2.073  loss_ce_4: 0  loss_mask_4: 0.7865  loss_dice_4: 2.071  loss_ce_5: 0  loss_mask_5: 0.7846  loss_dice_5: 2.071  loss_ce_6: 0  loss_mask_6: 0.7823  loss_dice_6: 2.064  loss_ce_7: 0  loss_mask_7: 0.7852  loss_dice_7: 2.069  loss_ce_8: 0  loss_mask_8: 0.783  loss_dice_8: 2.072  time: 1.8692  data_time: 0.0290  lr: 6.0361e-05  max_mem: 6006M
[02/18 13:52:36] d2.utils.events INFO:  eta: 14:48:53  iter: 25779  total_loss: 28.41  loss_ce: 0  loss_mask: 0.7537  loss_dice: 2.056  loss_seg: 0.6253  loss_ce_0: 0  loss_mask_0: 0.7683  loss_dice_0: 2.112  loss_ce_1: 0  loss_mask_1: 0.7532  loss_dice_1: 2.062  loss_ce_2: 0  loss_mask_2: 0.7544  loss_dice_2: 2.061  loss_ce_3: 0  loss_mask_3: 0.7563  loss_dice_3: 2.039  loss_ce_4: 0  loss_mask_4: 0.7574  loss_dice_4: 2.044  loss_ce_5: 0  loss_mask_5: 0.7548  loss_dice_5: 2.044  loss_ce_6: 0  loss_mask_6: 0.7579  loss_dice_6: 2.033  loss_ce_7: 0  loss_mask_7: 0.7542  loss_dice_7: 2.04  loss_ce_8: 0  loss_mask_8: 0.7552  loss_dice_8: 2.038  time: 1.8691  data_time: 0.0261  lr: 6.0329e-05  max_mem: 6006M
[02/18 13:53:08] d2.utils.events INFO:  eta: 14:48:47  iter: 25799  total_loss: 28.87  loss_ce: 0  loss_mask: 0.7689  loss_dice: 2.04  loss_seg: 0.5189  loss_ce_0: 0  loss_mask_0: 0.7787  loss_dice_0: 2.101  loss_ce_1: 0  loss_mask_1: 0.7761  loss_dice_1: 2.062  loss_ce_2: 0  loss_mask_2: 0.771  loss_dice_2: 2.041  loss_ce_3: 0  loss_mask_3: 0.772  loss_dice_3: 2.027  loss_ce_4: 0  loss_mask_4: 0.7769  loss_dice_4: 2.028  loss_ce_5: 0  loss_mask_5: 0.7766  loss_dice_5: 2.03  loss_ce_6: 0  loss_mask_6: 0.7746  loss_dice_6: 2.029  loss_ce_7: 0  loss_mask_7: 0.7738  loss_dice_7: 2.033  loss_ce_8: 0  loss_mask_8: 0.7786  loss_dice_8: 2.034  time: 1.8689  data_time: 0.0292  lr: 6.0297e-05  max_mem: 6006M
[02/18 13:53:35] d2.utils.events INFO:  eta: 14:43:09  iter: 25819  total_loss: 30.13  loss_ce: 0  loss_mask: 0.7789  loss_dice: 2.15  loss_seg: 0.9025  loss_ce_0: 0  loss_mask_0: 0.7941  loss_dice_0: 2.215  loss_ce_1: 0  loss_mask_1: 0.7751  loss_dice_1: 2.168  loss_ce_2: 0  loss_mask_2: 0.7774  loss_dice_2: 2.149  loss_ce_3: 0  loss_mask_3: 0.7836  loss_dice_3: 2.135  loss_ce_4: 0  loss_mask_4: 0.7824  loss_dice_4: 2.136  loss_ce_5: 0  loss_mask_5: 0.7877  loss_dice_5: 2.142  loss_ce_6: 0  loss_mask_6: 0.7868  loss_dice_6: 2.138  loss_ce_7: 0  loss_mask_7: 0.7839  loss_dice_7: 2.141  loss_ce_8: 0  loss_mask_8: 0.7855  loss_dice_8: 2.148  time: 1.8685  data_time: 0.0387  lr: 6.0266e-05  max_mem: 6006M
[02/18 13:54:09] d2.utils.events INFO:  eta: 14:47:20  iter: 25839  total_loss: 28.84  loss_ce: 0  loss_mask: 0.717  loss_dice: 2.005  loss_seg: 0.8034  loss_ce_0: 0  loss_mask_0: 0.7296  loss_dice_0: 2.104  loss_ce_1: 0  loss_mask_1: 0.7203  loss_dice_1: 2.024  loss_ce_2: 0  loss_mask_2: 0.7219  loss_dice_2: 2.006  loss_ce_3: 0  loss_mask_3: 0.7246  loss_dice_3: 1.993  loss_ce_4: 0  loss_mask_4: 0.7238  loss_dice_4: 1.996  loss_ce_5: 0  loss_mask_5: 0.7212  loss_dice_5: 1.998  loss_ce_6: 0  loss_mask_6: 0.7237  loss_dice_6: 1.997  loss_ce_7: 0  loss_mask_7: 0.7234  loss_dice_7: 1.999  loss_ce_8: 0  loss_mask_8: 0.7235  loss_dice_8: 1.995  time: 1.8684  data_time: 0.0322  lr: 6.0234e-05  max_mem: 6006M
[02/18 13:54:41] d2.utils.events INFO:  eta: 14:42:07  iter: 25859  total_loss: 27.87  loss_ce: 0  loss_mask: 0.7577  loss_dice: 1.959  loss_seg: 0.7049  loss_ce_0: 0  loss_mask_0: 0.7668  loss_dice_0: 2.032  loss_ce_1: 0  loss_mask_1: 0.7598  loss_dice_1: 1.965  loss_ce_2: 0  loss_mask_2: 0.7651  loss_dice_2: 1.951  loss_ce_3: 0  loss_mask_3: 0.7652  loss_dice_3: 1.945  loss_ce_4: 0  loss_mask_4: 0.7633  loss_dice_4: 1.94  loss_ce_5: 0  loss_mask_5: 0.7663  loss_dice_5: 1.941  loss_ce_6: 0  loss_mask_6: 0.7645  loss_dice_6: 1.938  loss_ce_7: 0  loss_mask_7: 0.7655  loss_dice_7: 1.934  loss_ce_8: 0  loss_mask_8: 0.7647  loss_dice_8: 1.938  time: 1.8682  data_time: 0.0304  lr: 6.0202e-05  max_mem: 6006M
[02/18 13:55:15] d2.utils.events INFO:  eta: 14:47:13  iter: 25879  total_loss: 29.51  loss_ce: 0  loss_mask: 0.7347  loss_dice: 2.053  loss_seg: 0.7738  loss_ce_0: 0  loss_mask_0: 0.7523  loss_dice_0: 2.131  loss_ce_1: 0  loss_mask_1: 0.7445  loss_dice_1: 2.072  loss_ce_2: 0  loss_mask_2: 0.7422  loss_dice_2: 2.054  loss_ce_3: 0  loss_mask_3: 0.7438  loss_dice_3: 2.046  loss_ce_4: 0  loss_mask_4: 0.7453  loss_dice_4: 2.042  loss_ce_5: 0  loss_mask_5: 0.7424  loss_dice_5: 2.043  loss_ce_6: 0  loss_mask_6: 0.7436  loss_dice_6: 2.042  loss_ce_7: 0  loss_mask_7: 0.7429  loss_dice_7: 2.041  loss_ce_8: 0  loss_mask_8: 0.7431  loss_dice_8: 2.045  time: 1.8680  data_time: 0.0312  lr: 6.017e-05  max_mem: 6006M
[02/18 13:55:46] d2.utils.events INFO:  eta: 14:40:17  iter: 25899  total_loss: 28.69  loss_ce: 0  loss_mask: 0.7341  loss_dice: 2.027  loss_seg: 0.7942  loss_ce_0: 0  loss_mask_0: 0.7511  loss_dice_0: 2.096  loss_ce_1: 0  loss_mask_1: 0.7389  loss_dice_1: 2.048  loss_ce_2: 0  loss_mask_2: 0.7379  loss_dice_2: 2.026  loss_ce_3: 0  loss_mask_3: 0.7429  loss_dice_3: 2.022  loss_ce_4: 0  loss_mask_4: 0.7428  loss_dice_4: 2.022  loss_ce_5: 0  loss_mask_5: 0.7408  loss_dice_5: 2.021  loss_ce_6: 0  loss_mask_6: 0.7381  loss_dice_6: 2.019  loss_ce_7: 0  loss_mask_7: 0.7383  loss_dice_7: 2.015  loss_ce_8: 0  loss_mask_8: 0.735  loss_dice_8: 2.015  time: 1.8678  data_time: 0.0258  lr: 6.0139e-05  max_mem: 6006M
[02/18 13:56:18] d2.utils.events INFO:  eta: 14:39:08  iter: 25919  total_loss: 31  loss_ce: 0  loss_mask: 0.7618  loss_dice: 2.159  loss_seg: 1.264  loss_ce_0: 0  loss_mask_0: 0.7702  loss_dice_0: 2.22  loss_ce_1: 0  loss_mask_1: 0.7641  loss_dice_1: 2.191  loss_ce_2: 0  loss_mask_2: 0.7612  loss_dice_2: 2.153  loss_ce_3: 0  loss_mask_3: 0.7631  loss_dice_3: 2.139  loss_ce_4: 0  loss_mask_4: 0.7614  loss_dice_4: 2.141  loss_ce_5: 0  loss_mask_5: 0.7604  loss_dice_5: 2.142  loss_ce_6: 0  loss_mask_6: 0.7644  loss_dice_6: 2.137  loss_ce_7: 0  loss_mask_7: 0.7632  loss_dice_7: 2.136  loss_ce_8: 0  loss_mask_8: 0.7631  loss_dice_8: 2.143  time: 1.8676  data_time: 0.0285  lr: 6.0107e-05  max_mem: 6006M
[02/18 13:56:50] d2.utils.events INFO:  eta: 14:38:37  iter: 25939  total_loss: 29.55  loss_ce: 0  loss_mask: 0.755  loss_dice: 2.051  loss_seg: 0.9628  loss_ce_0: 0  loss_mask_0: 0.7683  loss_dice_0: 2.104  loss_ce_1: 0  loss_mask_1: 0.7634  loss_dice_1: 2.06  loss_ce_2: 0  loss_mask_2: 0.7637  loss_dice_2: 2.043  loss_ce_3: 0  loss_mask_3: 0.766  loss_dice_3: 2.036  loss_ce_4: 0  loss_mask_4: 0.764  loss_dice_4: 2.038  loss_ce_5: 0  loss_mask_5: 0.7664  loss_dice_5: 2.045  loss_ce_6: 0  loss_mask_6: 0.7663  loss_dice_6: 2.043  loss_ce_7: 0  loss_mask_7: 0.7647  loss_dice_7: 2.041  loss_ce_8: 0  loss_mask_8: 0.7635  loss_dice_8: 2.043  time: 1.8674  data_time: 0.0280  lr: 6.0075e-05  max_mem: 6006M
[02/18 13:57:24] d2.utils.events INFO:  eta: 14:42:13  iter: 25959  total_loss: 28.64  loss_ce: 0  loss_mask: 0.7483  loss_dice: 2.047  loss_seg: 0.857  loss_ce_0: 0  loss_mask_0: 0.767  loss_dice_0: 2.106  loss_ce_1: 0  loss_mask_1: 0.7536  loss_dice_1: 2.05  loss_ce_2: 0  loss_mask_2: 0.7522  loss_dice_2: 2.04  loss_ce_3: 0  loss_mask_3: 0.7474  loss_dice_3: 2.037  loss_ce_4: 0  loss_mask_4: 0.7487  loss_dice_4: 2.042  loss_ce_5: 0  loss_mask_5: 0.7489  loss_dice_5: 2.037  loss_ce_6: 0  loss_mask_6: 0.7484  loss_dice_6: 2.036  loss_ce_7: 0  loss_mask_7: 0.7482  loss_dice_7: 2.041  loss_ce_8: 0  loss_mask_8: 0.7486  loss_dice_8: 2.038  time: 1.8672  data_time: 0.0260  lr: 6.0043e-05  max_mem: 6006M
[02/18 13:57:55] d2.utils.events INFO:  eta: 14:38:30  iter: 25979  total_loss: 29.23  loss_ce: 0  loss_mask: 0.7501  loss_dice: 2.085  loss_seg: 0.6631  loss_ce_0: 0  loss_mask_0: 0.7526  loss_dice_0: 2.155  loss_ce_1: 0  loss_mask_1: 0.7545  loss_dice_1: 2.108  loss_ce_2: 0  loss_mask_2: 0.7514  loss_dice_2: 2.084  loss_ce_3: 0  loss_mask_3: 0.7503  loss_dice_3: 2.079  loss_ce_4: 0  loss_mask_4: 0.7511  loss_dice_4: 2.077  loss_ce_5: 0  loss_mask_5: 0.7496  loss_dice_5: 2.081  loss_ce_6: 0  loss_mask_6: 0.7516  loss_dice_6: 2.078  loss_ce_7: 0  loss_mask_7: 0.7554  loss_dice_7: 2.08  loss_ce_8: 0  loss_mask_8: 0.7555  loss_dice_8: 2.076  time: 1.8670  data_time: 0.0267  lr: 6.0012e-05  max_mem: 6006M
[02/18 13:58:29] d2.utils.events INFO:  eta: 14:39:46  iter: 25999  total_loss: 29.46  loss_ce: 0  loss_mask: 0.7551  loss_dice: 2.081  loss_seg: 0.8217  loss_ce_0: 0  loss_mask_0: 0.7724  loss_dice_0: 2.158  loss_ce_1: 0  loss_mask_1: 0.7569  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7574  loss_dice_2: 2.08  loss_ce_3: 0  loss_mask_3: 0.7578  loss_dice_3: 2.078  loss_ce_4: 0  loss_mask_4: 0.7582  loss_dice_4: 2.074  loss_ce_5: 0  loss_mask_5: 0.7565  loss_dice_5: 2.077  loss_ce_6: 0  loss_mask_6: 0.7576  loss_dice_6: 2.079  loss_ce_7: 0  loss_mask_7: 0.7582  loss_dice_7: 2.075  loss_ce_8: 0  loss_mask_8: 0.7552  loss_dice_8: 2.084  time: 1.8669  data_time: 0.0321  lr: 5.998e-05  max_mem: 6006M
[02/18 13:59:01] d2.utils.events INFO:  eta: 14:45:54  iter: 26019  total_loss: 30.37  loss_ce: 0  loss_mask: 0.7768  loss_dice: 2.144  loss_seg: 0.6926  loss_ce_0: 0  loss_mask_0: 0.8058  loss_dice_0: 2.214  loss_ce_1: 0  loss_mask_1: 0.7831  loss_dice_1: 2.165  loss_ce_2: 0  loss_mask_2: 0.7845  loss_dice_2: 2.151  loss_ce_3: 0  loss_mask_3: 0.7853  loss_dice_3: 2.144  loss_ce_4: 0  loss_mask_4: 0.7842  loss_dice_4: 2.143  loss_ce_5: 0  loss_mask_5: 0.7836  loss_dice_5: 2.148  loss_ce_6: 0  loss_mask_6: 0.7834  loss_dice_6: 2.144  loss_ce_7: 0  loss_mask_7: 0.7824  loss_dice_7: 2.142  loss_ce_8: 0  loss_mask_8: 0.7815  loss_dice_8: 2.146  time: 1.8666  data_time: 0.0260  lr: 5.9948e-05  max_mem: 6006M
[02/18 13:59:36] d2.utils.events INFO:  eta: 14:51:07  iter: 26039  total_loss: 29.59  loss_ce: 0  loss_mask: 0.7778  loss_dice: 2.089  loss_seg: 0.8148  loss_ce_0: 0  loss_mask_0: 0.8036  loss_dice_0: 2.15  loss_ce_1: 0  loss_mask_1: 0.7765  loss_dice_1: 2.108  loss_ce_2: 0  loss_mask_2: 0.7785  loss_dice_2: 2.092  loss_ce_3: 0  loss_mask_3: 0.781  loss_dice_3: 2.073  loss_ce_4: 0  loss_mask_4: 0.7849  loss_dice_4: 2.078  loss_ce_5: 0  loss_mask_5: 0.7822  loss_dice_5: 2.077  loss_ce_6: 0  loss_mask_6: 0.7854  loss_dice_6: 2.076  loss_ce_7: 0  loss_mask_7: 0.7833  loss_dice_7: 2.074  loss_ce_8: 0  loss_mask_8: 0.7808  loss_dice_8: 2.071  time: 1.8666  data_time: 0.0233  lr: 5.9916e-05  max_mem: 6006M
[02/18 14:00:10] d2.utils.events INFO:  eta: 14:58:16  iter: 26059  total_loss: 29.72  loss_ce: 0  loss_mask: 0.7336  loss_dice: 2.085  loss_seg: 0.822  loss_ce_0: 0  loss_mask_0: 0.7367  loss_dice_0: 2.192  loss_ce_1: 0  loss_mask_1: 0.737  loss_dice_1: 2.108  loss_ce_2: 0  loss_mask_2: 0.7325  loss_dice_2: 2.093  loss_ce_3: 0  loss_mask_3: 0.732  loss_dice_3: 2.069  loss_ce_4: 0  loss_mask_4: 0.7346  loss_dice_4: 2.078  loss_ce_5: 0  loss_mask_5: 0.7344  loss_dice_5: 2.075  loss_ce_6: 0  loss_mask_6: 0.7333  loss_dice_6: 2.074  loss_ce_7: 0  loss_mask_7: 0.7368  loss_dice_7: 2.074  loss_ce_8: 0  loss_mask_8: 0.7388  loss_dice_8: 2.072  time: 1.8664  data_time: 0.0273  lr: 5.9885e-05  max_mem: 6006M
[02/18 14:00:39] d2.utils.events INFO:  eta: 14:59:11  iter: 26079  total_loss: 28.61  loss_ce: 0  loss_mask: 0.7265  loss_dice: 2.016  loss_seg: 0.7271  loss_ce_0: 0  loss_mask_0: 0.7346  loss_dice_0: 2.09  loss_ce_1: 0  loss_mask_1: 0.7277  loss_dice_1: 2.039  loss_ce_2: 0  loss_mask_2: 0.7285  loss_dice_2: 2.026  loss_ce_3: 0  loss_mask_3: 0.7246  loss_dice_3: 2.008  loss_ce_4: 0  loss_mask_4: 0.7238  loss_dice_4: 2.006  loss_ce_5: 0  loss_mask_5: 0.7239  loss_dice_5: 2.011  loss_ce_6: 0  loss_mask_6: 0.7234  loss_dice_6: 2.003  loss_ce_7: 0  loss_mask_7: 0.723  loss_dice_7: 2.006  loss_ce_8: 0  loss_mask_8: 0.7256  loss_dice_8: 2.011  time: 1.8661  data_time: 0.0275  lr: 5.9853e-05  max_mem: 6006M
[02/18 14:01:14] d2.utils.events INFO:  eta: 15:01:08  iter: 26099  total_loss: 29.64  loss_ce: 0  loss_mask: 0.7415  loss_dice: 2.08  loss_seg: 0.8256  loss_ce_0: 0  loss_mask_0: 0.763  loss_dice_0: 2.141  loss_ce_1: 0  loss_mask_1: 0.7436  loss_dice_1: 2.092  loss_ce_2: 0  loss_mask_2: 0.741  loss_dice_2: 2.081  loss_ce_3: 0  loss_mask_3: 0.7443  loss_dice_3: 2.072  loss_ce_4: 0  loss_mask_4: 0.7452  loss_dice_4: 2.07  loss_ce_5: 0  loss_mask_5: 0.7453  loss_dice_5: 2.069  loss_ce_6: 0  loss_mask_6: 0.7447  loss_dice_6: 2.068  loss_ce_7: 0  loss_mask_7: 0.7444  loss_dice_7: 2.068  loss_ce_8: 0  loss_mask_8: 0.7441  loss_dice_8: 2.064  time: 1.8660  data_time: 0.0261  lr: 5.9821e-05  max_mem: 6006M
[02/18 14:01:46] d2.utils.events INFO:  eta: 15:04:24  iter: 26119  total_loss: 27.53  loss_ce: 0  loss_mask: 0.7429  loss_dice: 1.991  loss_seg: 0.5643  loss_ce_0: 0  loss_mask_0: 0.7668  loss_dice_0: 2.043  loss_ce_1: 0  loss_mask_1: 0.755  loss_dice_1: 2.007  loss_ce_2: 0  loss_mask_2: 0.7465  loss_dice_2: 1.991  loss_ce_3: 0  loss_mask_3: 0.7464  loss_dice_3: 1.976  loss_ce_4: 0  loss_mask_4: 0.7409  loss_dice_4: 1.971  loss_ce_5: 0  loss_mask_5: 0.744  loss_dice_5: 1.976  loss_ce_6: 0  loss_mask_6: 0.7464  loss_dice_6: 1.978  loss_ce_7: 0  loss_mask_7: 0.7443  loss_dice_7: 1.977  loss_ce_8: 0  loss_mask_8: 0.7486  loss_dice_8: 1.973  time: 1.8658  data_time: 0.0301  lr: 5.9789e-05  max_mem: 6006M
[02/18 14:02:18] d2.utils.events INFO:  eta: 15:07:04  iter: 26139  total_loss: 27.68  loss_ce: 0  loss_mask: 0.7066  loss_dice: 1.981  loss_seg: 0.6778  loss_ce_0: 0  loss_mask_0: 0.7117  loss_dice_0: 2.051  loss_ce_1: 0  loss_mask_1: 0.7117  loss_dice_1: 1.996  loss_ce_2: 0  loss_mask_2: 0.7157  loss_dice_2: 1.988  loss_ce_3: 0  loss_mask_3: 0.7154  loss_dice_3: 1.967  loss_ce_4: 0  loss_mask_4: 0.7161  loss_dice_4: 1.971  loss_ce_5: 0  loss_mask_5: 0.7158  loss_dice_5: 1.963  loss_ce_6: 0  loss_mask_6: 0.7136  loss_dice_6: 1.964  loss_ce_7: 0  loss_mask_7: 0.714  loss_dice_7: 1.969  loss_ce_8: 0  loss_mask_8: 0.7136  loss_dice_8: 1.969  time: 1.8656  data_time: 0.0333  lr: 5.9758e-05  max_mem: 6006M
[02/18 14:02:57] d2.utils.events INFO:  eta: 15:10:04  iter: 26159  total_loss: 29.48  loss_ce: 0  loss_mask: 0.7756  loss_dice: 2.142  loss_seg: 0.6327  loss_ce_0: 0  loss_mask_0: 0.7748  loss_dice_0: 2.18  loss_ce_1: 0  loss_mask_1: 0.77  loss_dice_1: 2.146  loss_ce_2: 0  loss_mask_2: 0.7754  loss_dice_2: 2.138  loss_ce_3: 0  loss_mask_3: 0.7749  loss_dice_3: 2.139  loss_ce_4: 0  loss_mask_4: 0.7748  loss_dice_4: 2.135  loss_ce_5: 0  loss_mask_5: 0.7772  loss_dice_5: 2.127  loss_ce_6: 0  loss_mask_6: 0.7764  loss_dice_6: 2.128  loss_ce_7: 0  loss_mask_7: 0.7778  loss_dice_7: 2.126  loss_ce_8: 0  loss_mask_8: 0.7791  loss_dice_8: 2.12  time: 1.8657  data_time: 0.0354  lr: 5.9726e-05  max_mem: 6006M
[02/18 14:03:59] d2.utils.events INFO:  eta: 15:13:55  iter: 26179  total_loss: 29.99  loss_ce: 0  loss_mask: 0.7663  loss_dice: 2.114  loss_seg: 0.8549  loss_ce_0: 0  loss_mask_0: 0.7698  loss_dice_0: 2.166  loss_ce_1: 0  loss_mask_1: 0.7655  loss_dice_1: 2.125  loss_ce_2: 0  loss_mask_2: 0.7635  loss_dice_2: 2.112  loss_ce_3: 0  loss_mask_3: 0.7666  loss_dice_3: 2.108  loss_ce_4: 0  loss_mask_4: 0.7686  loss_dice_4: 2.111  loss_ce_5: 0  loss_mask_5: 0.7702  loss_dice_5: 2.111  loss_ce_6: 0  loss_mask_6: 0.7688  loss_dice_6: 2.109  loss_ce_7: 0  loss_mask_7: 0.7705  loss_dice_7: 2.107  loss_ce_8: 0  loss_mask_8: 0.7668  loss_dice_8: 2.111  time: 1.8666  data_time: 0.0334  lr: 5.9694e-05  max_mem: 6006M
[02/18 14:05:00] d2.utils.events INFO:  eta: 15:17:21  iter: 26199  total_loss: 28.9  loss_ce: 0  loss_mask: 0.7535  loss_dice: 2.046  loss_seg: 0.7785  loss_ce_0: 0  loss_mask_0: 0.7844  loss_dice_0: 2.112  loss_ce_1: 0  loss_mask_1: 0.7502  loss_dice_1: 2.068  loss_ce_2: 0  loss_mask_2: 0.7517  loss_dice_2: 2.049  loss_ce_3: 0  loss_mask_3: 0.7521  loss_dice_3: 2.044  loss_ce_4: 0  loss_mask_4: 0.751  loss_dice_4: 2.043  loss_ce_5: 0  loss_mask_5: 0.7483  loss_dice_5: 2.036  loss_ce_6: 0  loss_mask_6: 0.7519  loss_dice_6: 2.044  loss_ce_7: 0  loss_mask_7: 0.7552  loss_dice_7: 2.051  loss_ce_8: 0  loss_mask_8: 0.7561  loss_dice_8: 2.038  time: 1.8675  data_time: 0.0278  lr: 5.9662e-05  max_mem: 6006M
[02/18 14:06:03] d2.utils.events INFO:  eta: 15:20:40  iter: 26219  total_loss: 30.57  loss_ce: 0  loss_mask: 0.7867  loss_dice: 2.113  loss_seg: 0.7723  loss_ce_0: 0  loss_mask_0: 0.8045  loss_dice_0: 2.161  loss_ce_1: 0  loss_mask_1: 0.7864  loss_dice_1: 2.131  loss_ce_2: 0  loss_mask_2: 0.79  loss_dice_2: 2.112  loss_ce_3: 0  loss_mask_3: 0.7928  loss_dice_3: 2.102  loss_ce_4: 0  loss_mask_4: 0.7962  loss_dice_4: 2.098  loss_ce_5: 0  loss_mask_5: 0.7944  loss_dice_5: 2.102  loss_ce_6: 0  loss_mask_6: 0.7932  loss_dice_6: 2.104  loss_ce_7: 0  loss_mask_7: 0.7898  loss_dice_7: 2.105  loss_ce_8: 0  loss_mask_8: 0.7898  loss_dice_8: 2.104  time: 1.8685  data_time: 0.0304  lr: 5.9631e-05  max_mem: 6006M
[02/18 14:07:10] d2.utils.events INFO:  eta: 15:22:19  iter: 26239  total_loss: 28.72  loss_ce: 0  loss_mask: 0.7295  loss_dice: 2.054  loss_seg: 0.6584  loss_ce_0: 0  loss_mask_0: 0.7454  loss_dice_0: 2.117  loss_ce_1: 0  loss_mask_1: 0.735  loss_dice_1: 2.073  loss_ce_2: 0  loss_mask_2: 0.7367  loss_dice_2: 2.055  loss_ce_3: 0  loss_mask_3: 0.7389  loss_dice_3: 2.045  loss_ce_4: 0  loss_mask_4: 0.7428  loss_dice_4: 2.042  loss_ce_5: 0  loss_mask_5: 0.7408  loss_dice_5: 2.046  loss_ce_6: 0  loss_mask_6: 0.7399  loss_dice_6: 2.048  loss_ce_7: 0  loss_mask_7: 0.7373  loss_dice_7: 2.038  loss_ce_8: 0  loss_mask_8: 0.7373  loss_dice_8: 2.044  time: 1.8696  data_time: 0.0357  lr: 5.9599e-05  max_mem: 6006M
[02/18 14:08:16] d2.utils.events INFO:  eta: 15:25:23  iter: 26259  total_loss: 29.27  loss_ce: 0  loss_mask: 0.7677  loss_dice: 2.092  loss_seg: 0.9665  loss_ce_0: 0  loss_mask_0: 0.7603  loss_dice_0: 2.162  loss_ce_1: 0  loss_mask_1: 0.7622  loss_dice_1: 2.107  loss_ce_2: 0  loss_mask_2: 0.7678  loss_dice_2: 2.092  loss_ce_3: 0  loss_mask_3: 0.7669  loss_dice_3: 2.077  loss_ce_4: 0  loss_mask_4: 0.7666  loss_dice_4: 2.073  loss_ce_5: 0  loss_mask_5: 0.7648  loss_dice_5: 2.072  loss_ce_6: 0  loss_mask_6: 0.7693  loss_dice_6: 2.072  loss_ce_7: 0  loss_mask_7: 0.7729  loss_dice_7: 2.072  loss_ce_8: 0  loss_mask_8: 0.7733  loss_dice_8: 2.076  time: 1.8707  data_time: 0.0270  lr: 5.9567e-05  max_mem: 6006M
[02/18 14:09:21] d2.utils.events INFO:  eta: 15:29:01  iter: 26279  total_loss: 29.66  loss_ce: 0  loss_mask: 0.7415  loss_dice: 2.139  loss_seg: 0.9445  loss_ce_0: 0  loss_mask_0: 0.7388  loss_dice_0: 2.185  loss_ce_1: 0  loss_mask_1: 0.7388  loss_dice_1: 2.154  loss_ce_2: 0  loss_mask_2: 0.7427  loss_dice_2: 2.143  loss_ce_3: 0  loss_mask_3: 0.7507  loss_dice_3: 2.127  loss_ce_4: 0  loss_mask_4: 0.7509  loss_dice_4: 2.138  loss_ce_5: 0  loss_mask_5: 0.7495  loss_dice_5: 2.131  loss_ce_6: 0  loss_mask_6: 0.7499  loss_dice_6: 2.125  loss_ce_7: 0  loss_mask_7: 0.7483  loss_dice_7: 2.126  loss_ce_8: 0  loss_mask_8: 0.7478  loss_dice_8: 2.127  time: 1.8717  data_time: 0.0305  lr: 5.9535e-05  max_mem: 6006M
[02/18 14:10:28] d2.utils.events INFO:  eta: 15:34:30  iter: 26299  total_loss: 29.39  loss_ce: 0  loss_mask: 0.7597  loss_dice: 2.073  loss_seg: 0.6815  loss_ce_0: 0  loss_mask_0: 0.7727  loss_dice_0: 2.118  loss_ce_1: 0  loss_mask_1: 0.7568  loss_dice_1: 2.079  loss_ce_2: 0  loss_mask_2: 0.7675  loss_dice_2: 2.066  loss_ce_3: 0  loss_mask_3: 0.7674  loss_dice_3: 2.064  loss_ce_4: 0  loss_mask_4: 0.7674  loss_dice_4: 2.064  loss_ce_5: 0  loss_mask_5: 0.7661  loss_dice_5: 2.067  loss_ce_6: 0  loss_mask_6: 0.7672  loss_dice_6: 2.064  loss_ce_7: 0  loss_mask_7: 0.7635  loss_dice_7: 2.067  loss_ce_8: 0  loss_mask_8: 0.7657  loss_dice_8: 2.072  time: 1.8728  data_time: 0.0338  lr: 5.9503e-05  max_mem: 6006M
[02/18 14:11:32] d2.utils.events INFO:  eta: 15:40:02  iter: 26319  total_loss: 28.26  loss_ce: 0  loss_mask: 0.7311  loss_dice: 2.014  loss_seg: 0.6238  loss_ce_0: 0  loss_mask_0: 0.7362  loss_dice_0: 2.085  loss_ce_1: 0  loss_mask_1: 0.7233  loss_dice_1: 2.032  loss_ce_2: 0  loss_mask_2: 0.7313  loss_dice_2: 2.014  loss_ce_3: 0  loss_mask_3: 0.7298  loss_dice_3: 2.007  loss_ce_4: 0  loss_mask_4: 0.7301  loss_dice_4: 2.009  loss_ce_5: 0  loss_mask_5: 0.7284  loss_dice_5: 2.006  loss_ce_6: 0  loss_mask_6: 0.7316  loss_dice_6: 2.006  loss_ce_7: 0  loss_mask_7: 0.7302  loss_dice_7: 2.011  loss_ce_8: 0  loss_mask_8: 0.7295  loss_dice_8: 2.009  time: 1.8739  data_time: 0.0314  lr: 5.9472e-05  max_mem: 6006M
[02/18 14:12:42] d2.utils.events INFO:  eta: 15:45:07  iter: 26339  total_loss: 29.1  loss_ce: 0  loss_mask: 0.763  loss_dice: 2.096  loss_seg: 0.5512  loss_ce_0: 0  loss_mask_0: 0.7634  loss_dice_0: 2.16  loss_ce_1: 0  loss_mask_1: 0.7589  loss_dice_1: 2.104  loss_ce_2: 0  loss_mask_2: 0.7615  loss_dice_2: 2.092  loss_ce_3: 0  loss_mask_3: 0.7597  loss_dice_3: 2.083  loss_ce_4: 0  loss_mask_4: 0.7594  loss_dice_4: 2.088  loss_ce_5: 0  loss_mask_5: 0.7615  loss_dice_5: 2.087  loss_ce_6: 0  loss_mask_6: 0.7586  loss_dice_6: 2.083  loss_ce_7: 0  loss_mask_7: 0.7628  loss_dice_7: 2.087  loss_ce_8: 0  loss_mask_8: 0.767  loss_dice_8: 2.083  time: 1.8751  data_time: 0.0246  lr: 5.944e-05  max_mem: 6006M
[02/18 14:13:51] d2.utils.events INFO:  eta: 15:52:40  iter: 26359  total_loss: 28.51  loss_ce: 0  loss_mask: 0.7441  loss_dice: 2.017  loss_seg: 0.4989  loss_ce_0: 0  loss_mask_0: 0.7638  loss_dice_0: 2.085  loss_ce_1: 0  loss_mask_1: 0.7498  loss_dice_1: 2.028  loss_ce_2: 0  loss_mask_2: 0.7504  loss_dice_2: 2  loss_ce_3: 0  loss_mask_3: 0.7554  loss_dice_3: 1.997  loss_ce_4: 0  loss_mask_4: 0.7524  loss_dice_4: 1.996  loss_ce_5: 0  loss_mask_5: 0.7529  loss_dice_5: 1.992  loss_ce_6: 0  loss_mask_6: 0.754  loss_dice_6: 1.999  loss_ce_7: 0  loss_mask_7: 0.753  loss_dice_7: 2.002  loss_ce_8: 0  loss_mask_8: 0.7536  loss_dice_8: 1.991  time: 1.8763  data_time: 0.0298  lr: 5.9408e-05  max_mem: 6006M
[02/18 14:14:57] d2.utils.events INFO:  eta: 15:57:03  iter: 26379  total_loss: 29.54  loss_ce: 0  loss_mask: 0.7442  loss_dice: 2.111  loss_seg: 1.017  loss_ce_0: 0  loss_mask_0: 0.7667  loss_dice_0: 2.164  loss_ce_1: 0  loss_mask_1: 0.747  loss_dice_1: 2.121  loss_ce_2: 0  loss_mask_2: 0.7418  loss_dice_2: 2.104  loss_ce_3: 0  loss_mask_3: 0.7449  loss_dice_3: 2.105  loss_ce_4: 0  loss_mask_4: 0.7448  loss_dice_4: 2.102  loss_ce_5: 0  loss_mask_5: 0.7438  loss_dice_5: 2.103  loss_ce_6: 0  loss_mask_6: 0.7498  loss_dice_6: 2.1  loss_ce_7: 0  loss_mask_7: 0.7468  loss_dice_7: 2.107  loss_ce_8: 0  loss_mask_8: 0.7459  loss_dice_8: 2.105  time: 1.8773  data_time: 0.0474  lr: 5.9376e-05  max_mem: 6006M
[02/18 14:16:00] d2.utils.events INFO:  eta: 16:02:26  iter: 26399  total_loss: 28.94  loss_ce: 0  loss_mask: 0.7628  loss_dice: 2.082  loss_seg: 0.5264  loss_ce_0: 0  loss_mask_0: 0.7652  loss_dice_0: 2.149  loss_ce_1: 0  loss_mask_1: 0.7572  loss_dice_1: 2.103  loss_ce_2: 0  loss_mask_2: 0.7595  loss_dice_2: 2.088  loss_ce_3: 0  loss_mask_3: 0.7629  loss_dice_3: 2.071  loss_ce_4: 0  loss_mask_4: 0.7629  loss_dice_4: 2.079  loss_ce_5: 0  loss_mask_5: 0.7628  loss_dice_5: 2.071  loss_ce_6: 0  loss_mask_6: 0.7656  loss_dice_6: 2.073  loss_ce_7: 0  loss_mask_7: 0.7632  loss_dice_7: 2.069  loss_ce_8: 0  loss_mask_8: 0.7662  loss_dice_8: 2.074  time: 1.8783  data_time: 0.0390  lr: 5.9345e-05  max_mem: 6006M
[02/18 14:17:08] d2.utils.events INFO:  eta: 16:09:31  iter: 26419  total_loss: 29.68  loss_ce: 0  loss_mask: 0.7761  loss_dice: 2.076  loss_seg: 0.7041  loss_ce_0: 0  loss_mask_0: 0.7844  loss_dice_0: 2.138  loss_ce_1: 0  loss_mask_1: 0.7818  loss_dice_1: 2.088  loss_ce_2: 0  loss_mask_2: 0.7793  loss_dice_2: 2.074  loss_ce_3: 0  loss_mask_3: 0.7807  loss_dice_3: 2.072  loss_ce_4: 0  loss_mask_4: 0.7781  loss_dice_4: 2.064  loss_ce_5: 0  loss_mask_5: 0.7739  loss_dice_5: 2.063  loss_ce_6: 0  loss_mask_6: 0.7774  loss_dice_6: 2.069  loss_ce_7: 0  loss_mask_7: 0.775  loss_dice_7: 2.067  loss_ce_8: 0  loss_mask_8: 0.7755  loss_dice_8: 2.064  time: 1.8795  data_time: 0.0325  lr: 5.9313e-05  max_mem: 6006M
[02/18 14:18:16] d2.utils.events INFO:  eta: 16:15:21  iter: 26439  total_loss: 28.36  loss_ce: 0  loss_mask: 0.713  loss_dice: 2.033  loss_seg: 0.977  loss_ce_0: 0  loss_mask_0: 0.7542  loss_dice_0: 2.099  loss_ce_1: 0  loss_mask_1: 0.7158  loss_dice_1: 2.042  loss_ce_2: 0  loss_mask_2: 0.7162  loss_dice_2: 2.02  loss_ce_3: 0  loss_mask_3: 0.7099  loss_dice_3: 2.021  loss_ce_4: 0  loss_mask_4: 0.7089  loss_dice_4: 2.02  loss_ce_5: 0  loss_mask_5: 0.7097  loss_dice_5: 2.027  loss_ce_6: 0  loss_mask_6: 0.7118  loss_dice_6: 2.024  loss_ce_7: 0  loss_mask_7: 0.712  loss_dice_7: 2.021  loss_ce_8: 0  loss_mask_8: 0.7107  loss_dice_8: 2.025  time: 1.8806  data_time: 0.0292  lr: 5.9281e-05  max_mem: 6006M
[02/18 14:19:20] d2.utils.events INFO:  eta: 16:24:55  iter: 26459  total_loss: 29.15  loss_ce: 0  loss_mask: 0.7402  loss_dice: 2.042  loss_seg: 0.932  loss_ce_0: 0  loss_mask_0: 0.7489  loss_dice_0: 2.113  loss_ce_1: 0  loss_mask_1: 0.7387  loss_dice_1: 2.062  loss_ce_2: 0  loss_mask_2: 0.7417  loss_dice_2: 2.049  loss_ce_3: 0  loss_mask_3: 0.7444  loss_dice_3: 2.039  loss_ce_4: 0  loss_mask_4: 0.7492  loss_dice_4: 2.047  loss_ce_5: 0  loss_mask_5: 0.7457  loss_dice_5: 2.045  loss_ce_6: 0  loss_mask_6: 0.7473  loss_dice_6: 2.038  loss_ce_7: 0  loss_mask_7: 0.7516  loss_dice_7: 2.038  loss_ce_8: 0  loss_mask_8: 0.7487  loss_dice_8: 2.033  time: 1.8816  data_time: 0.0346  lr: 5.9249e-05  max_mem: 6006M
[02/18 14:20:25] d2.utils.events INFO:  eta: 16:41:16  iter: 26479  total_loss: 30.23  loss_ce: 0  loss_mask: 0.7818  loss_dice: 2.14  loss_seg: 0.5739  loss_ce_0: 0  loss_mask_0: 0.7884  loss_dice_0: 2.182  loss_ce_1: 0  loss_mask_1: 0.7806  loss_dice_1: 2.145  loss_ce_2: 0  loss_mask_2: 0.7775  loss_dice_2: 2.13  loss_ce_3: 0  loss_mask_3: 0.7799  loss_dice_3: 2.121  loss_ce_4: 0  loss_mask_4: 0.785  loss_dice_4: 2.122  loss_ce_5: 0  loss_mask_5: 0.7836  loss_dice_5: 2.118  loss_ce_6: 0  loss_mask_6: 0.783  loss_dice_6: 2.12  loss_ce_7: 0  loss_mask_7: 0.7867  loss_dice_7: 2.123  loss_ce_8: 0  loss_mask_8: 0.7836  loss_dice_8: 2.124  time: 1.8826  data_time: 0.0309  lr: 5.9217e-05  max_mem: 6006M
[02/18 14:21:31] d2.utils.events INFO:  eta: 16:56:50  iter: 26499  total_loss: 30.19  loss_ce: 0  loss_mask: 0.7694  loss_dice: 2.149  loss_seg: 0.8773  loss_ce_0: 0  loss_mask_0: 0.7749  loss_dice_0: 2.2  loss_ce_1: 0  loss_mask_1: 0.7707  loss_dice_1: 2.15  loss_ce_2: 0  loss_mask_2: 0.7747  loss_dice_2: 2.141  loss_ce_3: 0  loss_mask_3: 0.7702  loss_dice_3: 2.141  loss_ce_4: 0  loss_mask_4: 0.7693  loss_dice_4: 2.141  loss_ce_5: 0  loss_mask_5: 0.7697  loss_dice_5: 2.146  loss_ce_6: 0  loss_mask_6: 0.7709  loss_dice_6: 2.139  loss_ce_7: 0  loss_mask_7: 0.7711  loss_dice_7: 2.142  loss_ce_8: 0  loss_mask_8: 0.7676  loss_dice_8: 2.138  time: 1.8837  data_time: 0.0335  lr: 5.9186e-05  max_mem: 6006M
[02/18 14:22:39] d2.utils.events INFO:  eta: 17:12:32  iter: 26519  total_loss: 29.61  loss_ce: 0  loss_mask: 0.7525  loss_dice: 2.071  loss_seg: 0.85  loss_ce_0: 0  loss_mask_0: 0.7576  loss_dice_0: 2.127  loss_ce_1: 0  loss_mask_1: 0.7569  loss_dice_1: 2.075  loss_ce_2: 0  loss_mask_2: 0.7554  loss_dice_2: 2.07  loss_ce_3: 0  loss_mask_3: 0.7542  loss_dice_3: 2.068  loss_ce_4: 0  loss_mask_4: 0.7533  loss_dice_4: 2.069  loss_ce_5: 0  loss_mask_5: 0.753  loss_dice_5: 2.062  loss_ce_6: 0  loss_mask_6: 0.7545  loss_dice_6: 2.06  loss_ce_7: 0  loss_mask_7: 0.756  loss_dice_7: 2.061  loss_ce_8: 0  loss_mask_8: 0.7561  loss_dice_8: 2.059  time: 1.8848  data_time: 0.0274  lr: 5.9154e-05  max_mem: 6006M
[02/18 14:23:43] d2.utils.events INFO:  eta: 17:28:11  iter: 26539  total_loss: 28.21  loss_ce: 0  loss_mask: 0.7131  loss_dice: 2.021  loss_seg: 0.7792  loss_ce_0: 0  loss_mask_0: 0.7144  loss_dice_0: 2.101  loss_ce_1: 0  loss_mask_1: 0.7124  loss_dice_1: 2.045  loss_ce_2: 0  loss_mask_2: 0.7117  loss_dice_2: 2.028  loss_ce_3: 0  loss_mask_3: 0.7082  loss_dice_3: 2.014  loss_ce_4: 0  loss_mask_4: 0.7106  loss_dice_4: 2.014  loss_ce_5: 0  loss_mask_5: 0.7129  loss_dice_5: 2.01  loss_ce_6: 0  loss_mask_6: 0.712  loss_dice_6: 2.006  loss_ce_7: 0  loss_mask_7: 0.7151  loss_dice_7: 2.016  loss_ce_8: 0  loss_mask_8: 0.714  loss_dice_8: 2.011  time: 1.8858  data_time: 0.0355  lr: 5.9122e-05  max_mem: 6006M
[02/18 14:24:47] d2.utils.events INFO:  eta: 17:49:34  iter: 26559  total_loss: 29.28  loss_ce: 0  loss_mask: 0.7095  loss_dice: 2.111  loss_seg: 1.01  loss_ce_0: 0  loss_mask_0: 0.7068  loss_dice_0: 2.193  loss_ce_1: 0  loss_mask_1: 0.7141  loss_dice_1: 2.132  loss_ce_2: 0  loss_mask_2: 0.7122  loss_dice_2: 2.107  loss_ce_3: 0  loss_mask_3: 0.7141  loss_dice_3: 2.098  loss_ce_4: 0  loss_mask_4: 0.7111  loss_dice_4: 2.094  loss_ce_5: 0  loss_mask_5: 0.7129  loss_dice_5: 2.098  loss_ce_6: 0  loss_mask_6: 0.7124  loss_dice_6: 2.095  loss_ce_7: 0  loss_mask_7: 0.7099  loss_dice_7: 2.094  loss_ce_8: 0  loss_mask_8: 0.7118  loss_dice_8: 2.093  time: 1.8868  data_time: 0.0313  lr: 5.909e-05  max_mem: 6006M
[02/18 14:25:51] d2.utils.events INFO:  eta: 18:14:23  iter: 26579  total_loss: 30.07  loss_ce: 0  loss_mask: 0.775  loss_dice: 2.165  loss_seg: 0.7727  loss_ce_0: 0  loss_mask_0: 0.7847  loss_dice_0: 2.229  loss_ce_1: 0  loss_mask_1: 0.781  loss_dice_1: 2.181  loss_ce_2: 0  loss_mask_2: 0.7771  loss_dice_2: 2.167  loss_ce_3: 0  loss_mask_3: 0.7791  loss_dice_3: 2.158  loss_ce_4: 0  loss_mask_4: 0.7794  loss_dice_4: 2.157  loss_ce_5: 0  loss_mask_5: 0.7836  loss_dice_5: 2.159  loss_ce_6: 0  loss_mask_6: 0.7809  loss_dice_6: 2.157  loss_ce_7: 0  loss_mask_7: 0.7798  loss_dice_7: 2.158  loss_ce_8: 0  loss_mask_8: 0.781  loss_dice_8: 2.16  time: 1.8878  data_time: 0.0342  lr: 5.9058e-05  max_mem: 6006M
[02/18 14:26:52] d2.utils.events INFO:  eta: 18:39:37  iter: 26599  total_loss: 29.24  loss_ce: 0  loss_mask: 0.7303  loss_dice: 2.079  loss_seg: 0.6863  loss_ce_0: 0  loss_mask_0: 0.743  loss_dice_0: 2.133  loss_ce_1: 0  loss_mask_1: 0.7322  loss_dice_1: 2.087  loss_ce_2: 0  loss_mask_2: 0.7358  loss_dice_2: 2.076  loss_ce_3: 0  loss_mask_3: 0.7359  loss_dice_3: 2.07  loss_ce_4: 0  loss_mask_4: 0.7372  loss_dice_4: 2.068  loss_ce_5: 0  loss_mask_5: 0.7357  loss_dice_5: 2.066  loss_ce_6: 0  loss_mask_6: 0.7378  loss_dice_6: 2.059  loss_ce_7: 0  loss_mask_7: 0.7362  loss_dice_7: 2.064  loss_ce_8: 0  loss_mask_8: 0.7382  loss_dice_8: 2.065  time: 1.8887  data_time: 0.0331  lr: 5.9027e-05  max_mem: 6006M
[02/18 14:27:58] d2.utils.events INFO:  eta: 19:13:04  iter: 26619  total_loss: 27.7  loss_ce: 0  loss_mask: 0.7295  loss_dice: 1.962  loss_seg: 0.6022  loss_ce_0: 0  loss_mask_0: 0.7301  loss_dice_0: 2.028  loss_ce_1: 0  loss_mask_1: 0.7296  loss_dice_1: 1.97  loss_ce_2: 0  loss_mask_2: 0.7346  loss_dice_2: 1.952  loss_ce_3: 0  loss_mask_3: 0.7372  loss_dice_3: 1.942  loss_ce_4: 0  loss_mask_4: 0.7343  loss_dice_4: 1.94  loss_ce_5: 0  loss_mask_5: 0.7326  loss_dice_5: 1.948  loss_ce_6: 0  loss_mask_6: 0.7313  loss_dice_6: 1.951  loss_ce_7: 0  loss_mask_7: 0.7335  loss_dice_7: 1.942  loss_ce_8: 0  loss_mask_8: 0.7297  loss_dice_8: 1.952  time: 1.8897  data_time: 0.0305  lr: 5.8995e-05  max_mem: 6006M
[02/18 14:29:02] d2.utils.events INFO:  eta: 19:42:54  iter: 26639  total_loss: 27.93  loss_ce: 0  loss_mask: 0.7199  loss_dice: 2.022  loss_seg: 0.849  loss_ce_0: 0  loss_mask_0: 0.7301  loss_dice_0: 2.097  loss_ce_1: 0  loss_mask_1: 0.7247  loss_dice_1: 2.023  loss_ce_2: 0  loss_mask_2: 0.7276  loss_dice_2: 2.013  loss_ce_3: 0  loss_mask_3: 0.7285  loss_dice_3: 2.007  loss_ce_4: 0  loss_mask_4: 0.7252  loss_dice_4: 2.007  loss_ce_5: 0  loss_mask_5: 0.7258  loss_dice_5: 2.011  loss_ce_6: 0  loss_mask_6: 0.725  loss_dice_6: 2.003  loss_ce_7: 0  loss_mask_7: 0.7243  loss_dice_7: 2.003  loss_ce_8: 0  loss_mask_8: 0.7238  loss_dice_8: 2.006  time: 1.8907  data_time: 0.0288  lr: 5.8963e-05  max_mem: 6006M
[02/18 14:30:07] d2.utils.events INFO:  eta: 20:05:35  iter: 26659  total_loss: 28.73  loss_ce: 0  loss_mask: 0.7195  loss_dice: 2.014  loss_seg: 0.6334  loss_ce_0: 0  loss_mask_0: 0.7243  loss_dice_0: 2.076  loss_ce_1: 0  loss_mask_1: 0.7207  loss_dice_1: 2.033  loss_ce_2: 0  loss_mask_2: 0.7272  loss_dice_2: 2.012  loss_ce_3: 0  loss_mask_3: 0.7279  loss_dice_3: 2.01  loss_ce_4: 0  loss_mask_4: 0.725  loss_dice_4: 2.002  loss_ce_5: 0  loss_mask_5: 0.7275  loss_dice_5: 2.009  loss_ce_6: 0  loss_mask_6: 0.7253  loss_dice_6: 1.999  loss_ce_7: 0  loss_mask_7: 0.7232  loss_dice_7: 2.004  loss_ce_8: 0  loss_mask_8: 0.7287  loss_dice_8: 2.009  time: 1.8917  data_time: 0.0346  lr: 5.8931e-05  max_mem: 6006M
[02/18 14:31:14] d2.utils.events INFO:  eta: 20:48:35  iter: 26679  total_loss: 28.27  loss_ce: 0  loss_mask: 0.7092  loss_dice: 2.049  loss_seg: 0.8497  loss_ce_0: 0  loss_mask_0: 0.7154  loss_dice_0: 2.131  loss_ce_1: 0  loss_mask_1: 0.7098  loss_dice_1: 2.064  loss_ce_2: 0  loss_mask_2: 0.7111  loss_dice_2: 2.058  loss_ce_3: 0  loss_mask_3: 0.7089  loss_dice_3: 2.046  loss_ce_4: 0  loss_mask_4: 0.7097  loss_dice_4: 2.044  loss_ce_5: 0  loss_mask_5: 0.7094  loss_dice_5: 2.041  loss_ce_6: 0  loss_mask_6: 0.7067  loss_dice_6: 2.043  loss_ce_7: 0  loss_mask_7: 0.7119  loss_dice_7: 2.033  loss_ce_8: 0  loss_mask_8: 0.7127  loss_dice_8: 2.036  time: 1.8928  data_time: 0.0298  lr: 5.8899e-05  max_mem: 6006M
[02/18 14:32:20] d2.utils.events INFO:  eta: 21:49:10  iter: 26699  total_loss: 29.64  loss_ce: 0  loss_mask: 0.7436  loss_dice: 2.11  loss_seg: 0.7498  loss_ce_0: 0  loss_mask_0: 0.7568  loss_dice_0: 2.199  loss_ce_1: 0  loss_mask_1: 0.7544  loss_dice_1: 2.141  loss_ce_2: 0  loss_mask_2: 0.7483  loss_dice_2: 2.125  loss_ce_3: 0  loss_mask_3: 0.75  loss_dice_3: 2.104  loss_ce_4: 0  loss_mask_4: 0.7464  loss_dice_4: 2.11  loss_ce_5: 0  loss_mask_5: 0.7488  loss_dice_5: 2.109  loss_ce_6: 0  loss_mask_6: 0.7494  loss_dice_6: 2.108  loss_ce_7: 0  loss_mask_7: 0.75  loss_dice_7: 2.107  loss_ce_8: 0  loss_mask_8: 0.7483  loss_dice_8: 2.107  time: 1.8939  data_time: 0.0360  lr: 5.8867e-05  max_mem: 6006M
[02/18 14:32:58] d2.utils.events INFO:  eta: 21:49:11  iter: 26719  total_loss: 29.26  loss_ce: 0  loss_mask: 0.7524  loss_dice: 2.078  loss_seg: 0.5994  loss_ce_0: 0  loss_mask_0: 0.7503  loss_dice_0: 2.126  loss_ce_1: 0  loss_mask_1: 0.7563  loss_dice_1: 2.083  loss_ce_2: 0  loss_mask_2: 0.7562  loss_dice_2: 2.067  loss_ce_3: 0  loss_mask_3: 0.7535  loss_dice_3: 2.059  loss_ce_4: 0  loss_mask_4: 0.7526  loss_dice_4: 2.067  loss_ce_5: 0  loss_mask_5: 0.7535  loss_dice_5: 2.064  loss_ce_6: 0  loss_mask_6: 0.7508  loss_dice_6: 2.062  loss_ce_7: 0  loss_mask_7: 0.7522  loss_dice_7: 2.075  loss_ce_8: 0  loss_mask_8: 0.7526  loss_dice_8: 2.07  time: 1.8939  data_time: 0.0266  lr: 5.8836e-05  max_mem: 6006M
[02/18 14:33:30] d2.utils.events INFO:  eta: 21:48:23  iter: 26739  total_loss: 30.04  loss_ce: 0  loss_mask: 0.7239  loss_dice: 2.157  loss_seg: 0.8661  loss_ce_0: 0  loss_mask_0: 0.7505  loss_dice_0: 2.232  loss_ce_1: 0  loss_mask_1: 0.7278  loss_dice_1: 2.187  loss_ce_2: 0  loss_mask_2: 0.7288  loss_dice_2: 2.165  loss_ce_3: 0  loss_mask_3: 0.7263  loss_dice_3: 2.15  loss_ce_4: 0  loss_mask_4: 0.7273  loss_dice_4: 2.148  loss_ce_5: 0  loss_mask_5: 0.7242  loss_dice_5: 2.144  loss_ce_6: 0  loss_mask_6: 0.7275  loss_dice_6: 2.147  loss_ce_7: 0  loss_mask_7: 0.7244  loss_dice_7: 2.149  loss_ce_8: 0  loss_mask_8: 0.7255  loss_dice_8: 2.15  time: 1.8936  data_time: 0.0323  lr: 5.8804e-05  max_mem: 6006M
[02/18 14:34:04] d2.utils.events INFO:  eta: 21:47:36  iter: 26759  total_loss: 30.33  loss_ce: 0  loss_mask: 0.7231  loss_dice: 2.184  loss_seg: 0.9853  loss_ce_0: 0  loss_mask_0: 0.7277  loss_dice_0: 2.252  loss_ce_1: 0  loss_mask_1: 0.7223  loss_dice_1: 2.204  loss_ce_2: 0  loss_mask_2: 0.7239  loss_dice_2: 2.185  loss_ce_3: 0  loss_mask_3: 0.7212  loss_dice_3: 2.179  loss_ce_4: 0  loss_mask_4: 0.7235  loss_dice_4: 2.181  loss_ce_5: 0  loss_mask_5: 0.7263  loss_dice_5: 2.183  loss_ce_6: 0  loss_mask_6: 0.7246  loss_dice_6: 2.177  loss_ce_7: 0  loss_mask_7: 0.7252  loss_dice_7: 2.185  loss_ce_8: 0  loss_mask_8: 0.7269  loss_dice_8: 2.181  time: 1.8935  data_time: 0.0303  lr: 5.8772e-05  max_mem: 6006M
[02/18 14:34:37] d2.utils.events INFO:  eta: 21:46:49  iter: 26779  total_loss: 29.03  loss_ce: 0  loss_mask: 0.7188  loss_dice: 2.119  loss_seg: 0.6066  loss_ce_0: 0  loss_mask_0: 0.739  loss_dice_0: 2.177  loss_ce_1: 0  loss_mask_1: 0.7263  loss_dice_1: 2.131  loss_ce_2: 0  loss_mask_2: 0.7276  loss_dice_2: 2.128  loss_ce_3: 0  loss_mask_3: 0.7233  loss_dice_3: 2.123  loss_ce_4: 0  loss_mask_4: 0.7234  loss_dice_4: 2.116  loss_ce_5: 0  loss_mask_5: 0.7222  loss_dice_5: 2.114  loss_ce_6: 0  loss_mask_6: 0.7262  loss_dice_6: 2.116  loss_ce_7: 0  loss_mask_7: 0.7215  loss_dice_7: 2.115  loss_ce_8: 0  loss_mask_8: 0.7219  loss_dice_8: 2.113  time: 1.8933  data_time: 0.0253  lr: 5.874e-05  max_mem: 6006M
[02/18 14:35:09] d2.utils.events INFO:  eta: 21:46:02  iter: 26799  total_loss: 29.14  loss_ce: 0  loss_mask: 0.7375  loss_dice: 2.08  loss_seg: 0.7154  loss_ce_0: 0  loss_mask_0: 0.7535  loss_dice_0: 2.146  loss_ce_1: 0  loss_mask_1: 0.7416  loss_dice_1: 2.098  loss_ce_2: 0  loss_mask_2: 0.7429  loss_dice_2: 2.082  loss_ce_3: 0  loss_mask_3: 0.7442  loss_dice_3: 2.061  loss_ce_4: 0  loss_mask_4: 0.7454  loss_dice_4: 2.069  loss_ce_5: 0  loss_mask_5: 0.7469  loss_dice_5: 2.07  loss_ce_6: 0  loss_mask_6: 0.7463  loss_dice_6: 2.071  loss_ce_7: 0  loss_mask_7: 0.7444  loss_dice_7: 2.068  loss_ce_8: 0  loss_mask_8: 0.7445  loss_dice_8: 2.073  time: 1.8931  data_time: 0.0280  lr: 5.8708e-05  max_mem: 6006M
[02/18 14:35:44] d2.utils.events INFO:  eta: 21:48:58  iter: 26819  total_loss: 28.51  loss_ce: 0  loss_mask: 0.7224  loss_dice: 2.064  loss_seg: 0.729  loss_ce_0: 0  loss_mask_0: 0.7288  loss_dice_0: 2.129  loss_ce_1: 0  loss_mask_1: 0.7254  loss_dice_1: 2.08  loss_ce_2: 0  loss_mask_2: 0.728  loss_dice_2: 2.065  loss_ce_3: 0  loss_mask_3: 0.7295  loss_dice_3: 2.053  loss_ce_4: 0  loss_mask_4: 0.7258  loss_dice_4: 2.047  loss_ce_5: 0  loss_mask_5: 0.7268  loss_dice_5: 2.052  loss_ce_6: 0  loss_mask_6: 0.7241  loss_dice_6: 2.054  loss_ce_7: 0  loss_mask_7: 0.7275  loss_dice_7: 2.053  loss_ce_8: 0  loss_mask_8: 0.728  loss_dice_8: 2.049  time: 1.8930  data_time: 0.0381  lr: 5.8677e-05  max_mem: 6006M
[02/18 14:36:45] d2.utils.events INFO:  eta: 22:54:28  iter: 26839  total_loss: 29.12  loss_ce: 0  loss_mask: 0.7331  loss_dice: 2.113  loss_seg: 0.6702  loss_ce_0: 0  loss_mask_0: 0.7475  loss_dice_0: 2.187  loss_ce_1: 0  loss_mask_1: 0.7439  loss_dice_1: 2.133  loss_ce_2: 0  loss_mask_2: 0.7406  loss_dice_2: 2.115  loss_ce_3: 0  loss_mask_3: 0.744  loss_dice_3: 2.108  loss_ce_4: 0  loss_mask_4: 0.7467  loss_dice_4: 2.112  loss_ce_5: 0  loss_mask_5: 0.7453  loss_dice_5: 2.103  loss_ce_6: 0  loss_mask_6: 0.7436  loss_dice_6: 2.096  loss_ce_7: 0  loss_mask_7: 0.7437  loss_dice_7: 2.104  loss_ce_8: 0  loss_mask_8: 0.7444  loss_dice_8: 2.109  time: 1.8939  data_time: 0.0395  lr: 5.8645e-05  max_mem: 6006M
[02/18 14:37:53] d2.utils.events INFO:  eta: 23:43:52  iter: 26859  total_loss: 28.68  loss_ce: 0  loss_mask: 0.7004  loss_dice: 2.062  loss_seg: 0.6534  loss_ce_0: 0  loss_mask_0: 0.7119  loss_dice_0: 2.144  loss_ce_1: 0  loss_mask_1: 0.6967  loss_dice_1: 2.082  loss_ce_2: 0  loss_mask_2: 0.7005  loss_dice_2: 2.074  loss_ce_3: 0  loss_mask_3: 0.707  loss_dice_3: 2.047  loss_ce_4: 0  loss_mask_4: 0.707  loss_dice_4: 2.059  loss_ce_5: 0  loss_mask_5: 0.7073  loss_dice_5: 2.052  loss_ce_6: 0  loss_mask_6: 0.7085  loss_dice_6: 2.048  loss_ce_7: 0  loss_mask_7: 0.7087  loss_dice_7: 2.05  loss_ce_8: 0  loss_mask_8: 0.7063  loss_dice_8: 2.051  time: 1.8950  data_time: 0.0404  lr: 5.8613e-05  max_mem: 6006M
[02/18 14:38:59] d2.utils.events INFO:  eta: 1 day, 0:22:02  iter: 26879  total_loss: 29.24  loss_ce: 0  loss_mask: 0.7588  loss_dice: 2.045  loss_seg: 0.6865  loss_ce_0: 0  loss_mask_0: 0.7623  loss_dice_0: 2.123  loss_ce_1: 0  loss_mask_1: 0.7616  loss_dice_1: 2.072  loss_ce_2: 0  loss_mask_2: 0.7601  loss_dice_2: 2.045  loss_ce_3: 0  loss_mask_3: 0.7638  loss_dice_3: 2.031  loss_ce_4: 0  loss_mask_4: 0.7654  loss_dice_4: 2.038  loss_ce_5: 0  loss_mask_5: 0.764  loss_dice_5: 2.039  loss_ce_6: 0  loss_mask_6: 0.764  loss_dice_6: 2.04  loss_ce_7: 0  loss_mask_7: 0.7634  loss_dice_7: 2.04  loss_ce_8: 0  loss_mask_8: 0.7646  loss_dice_8: 2.037  time: 1.8960  data_time: 0.0489  lr: 5.8581e-05  max_mem: 6006M
[02/18 14:40:10] d2.utils.events INFO:  eta: 1 day, 1:17:33  iter: 26899  total_loss: 28.29  loss_ce: 0  loss_mask: 0.7013  loss_dice: 2.019  loss_seg: 0.7225  loss_ce_0: 0  loss_mask_0: 0.7094  loss_dice_0: 2.109  loss_ce_1: 0  loss_mask_1: 0.7076  loss_dice_1: 2.039  loss_ce_2: 0  loss_mask_2: 0.7039  loss_dice_2: 2.017  loss_ce_3: 0  loss_mask_3: 0.7048  loss_dice_3: 2.011  loss_ce_4: 0  loss_mask_4: 0.7046  loss_dice_4: 2.016  loss_ce_5: 0  loss_mask_5: 0.7028  loss_dice_5: 2.008  loss_ce_6: 0  loss_mask_6: 0.7022  loss_dice_6: 2.009  loss_ce_7: 0  loss_mask_7: 0.7067  loss_dice_7: 2.012  loss_ce_8: 0  loss_mask_8: 0.7057  loss_dice_8: 2.016  time: 1.8972  data_time: 0.0314  lr: 5.8549e-05  max_mem: 6006M
[02/18 14:40:49] d2.utils.events INFO:  eta: 1 day, 1:30:01  iter: 26919  total_loss: 29.6  loss_ce: 0  loss_mask: 0.7628  loss_dice: 2.146  loss_seg: 0.5095  loss_ce_0: 0  loss_mask_0: 0.7715  loss_dice_0: 2.204  loss_ce_1: 0  loss_mask_1: 0.7628  loss_dice_1: 2.161  loss_ce_2: 0  loss_mask_2: 0.7616  loss_dice_2: 2.147  loss_ce_3: 0  loss_mask_3: 0.7642  loss_dice_3: 2.132  loss_ce_4: 0  loss_mask_4: 0.7654  loss_dice_4: 2.129  loss_ce_5: 0  loss_mask_5: 0.7679  loss_dice_5: 2.133  loss_ce_6: 0  loss_mask_6: 0.767  loss_dice_6: 2.135  loss_ce_7: 0  loss_mask_7: 0.7689  loss_dice_7: 2.124  loss_ce_8: 0  loss_mask_8: 0.7666  loss_dice_8: 2.131  time: 1.8973  data_time: 0.0298  lr: 5.8517e-05  max_mem: 6006M
[02/18 14:41:04] d2.utils.events INFO:  eta: 1 day, 1:29:06  iter: 26939  total_loss: 28.77  loss_ce: 0  loss_mask: 0.7378  loss_dice: 1.96  loss_seg: 0.9969  loss_ce_0: 0  loss_mask_0: 0.7561  loss_dice_0: 2.036  loss_ce_1: 0  loss_mask_1: 0.7539  loss_dice_1: 1.973  loss_ce_2: 0  loss_mask_2: 0.749  loss_dice_2: 1.953  loss_ce_3: 0  loss_mask_3: 0.7456  loss_dice_3: 1.96  loss_ce_4: 0  loss_mask_4: 0.7468  loss_dice_4: 1.959  loss_ce_5: 0  loss_mask_5: 0.7467  loss_dice_5: 1.957  loss_ce_6: 0  loss_mask_6: 0.7445  loss_dice_6: 1.956  loss_ce_7: 0  loss_mask_7: 0.7446  loss_dice_7: 1.954  loss_ce_8: 0  loss_mask_8: 0.7403  loss_dice_8: 1.958  time: 1.8964  data_time: 0.0230  lr: 5.8486e-05  max_mem: 6006M
[02/18 14:41:17] d2.utils.events INFO:  eta: 1 day, 1:28:10  iter: 26959  total_loss: 29.65  loss_ce: 0  loss_mask: 0.7281  loss_dice: 2.132  loss_seg: 0.7067  loss_ce_0: 0  loss_mask_0: 0.743  loss_dice_0: 2.196  loss_ce_1: 0  loss_mask_1: 0.7284  loss_dice_1: 2.144  loss_ce_2: 0  loss_mask_2: 0.7303  loss_dice_2: 2.125  loss_ce_3: 0  loss_mask_3: 0.7247  loss_dice_3: 2.122  loss_ce_4: 0  loss_mask_4: 0.7287  loss_dice_4: 2.12  loss_ce_5: 0  loss_mask_5: 0.7299  loss_dice_5: 2.117  loss_ce_6: 0  loss_mask_6: 0.7274  loss_dice_6: 2.12  loss_ce_7: 0  loss_mask_7: 0.7272  loss_dice_7: 2.117  loss_ce_8: 0  loss_mask_8: 0.7299  loss_dice_8: 2.121  time: 1.8955  data_time: 0.0295  lr: 5.8454e-05  max_mem: 6006M
[02/18 14:41:30] d2.utils.events INFO:  eta: 1 day, 1:27:15  iter: 26979  total_loss: 27.29  loss_ce: 0  loss_mask: 0.7125  loss_dice: 1.965  loss_seg: 0.6012  loss_ce_0: 0  loss_mask_0: 0.7036  loss_dice_0: 2.051  loss_ce_1: 0  loss_mask_1: 0.7089  loss_dice_1: 1.986  loss_ce_2: 0  loss_mask_2: 0.717  loss_dice_2: 1.967  loss_ce_3: 0  loss_mask_3: 0.7182  loss_dice_3: 1.956  loss_ce_4: 0  loss_mask_4: 0.7212  loss_dice_4: 1.959  loss_ce_5: 0  loss_mask_5: 0.7177  loss_dice_5: 1.965  loss_ce_6: 0  loss_mask_6: 0.7196  loss_dice_6: 1.954  loss_ce_7: 0  loss_mask_7: 0.7195  loss_dice_7: 1.957  loss_ce_8: 0  loss_mask_8: 0.7196  loss_dice_8: 1.955  time: 1.8945  data_time: 0.0236  lr: 5.8422e-05  max_mem: 6006M
[02/18 14:41:44] d2.utils.events INFO:  eta: 1 day, 1:26:19  iter: 26999  total_loss: 28.13  loss_ce: 0  loss_mask: 0.7313  loss_dice: 1.987  loss_seg: 0.7361  loss_ce_0: 0  loss_mask_0: 0.7373  loss_dice_0: 2.055  loss_ce_1: 0  loss_mask_1: 0.7388  loss_dice_1: 1.996  loss_ce_2: 0  loss_mask_2: 0.7394  loss_dice_2: 1.979  loss_ce_3: 0  loss_mask_3: 0.7379  loss_dice_3: 1.976  loss_ce_4: 0  loss_mask_4: 0.7339  loss_dice_4: 1.975  loss_ce_5: 0  loss_mask_5: 0.7361  loss_dice_5: 1.98  loss_ce_6: 0  loss_mask_6: 0.7357  loss_dice_6: 1.979  loss_ce_7: 0  loss_mask_7: 0.7346  loss_dice_7: 1.975  loss_ce_8: 0  loss_mask_8: 0.7318  loss_dice_8: 1.983  time: 1.8937  data_time: 0.0346  lr: 5.839e-05  max_mem: 6006M
[02/18 14:42:05] d2.utils.events INFO:  eta: 1 day, 1:25:24  iter: 27019  total_loss: 27.94  loss_ce: 0  loss_mask: 0.7256  loss_dice: 2.026  loss_seg: 0.6753  loss_ce_0: 0  loss_mask_0: 0.7354  loss_dice_0: 2.082  loss_ce_1: 0  loss_mask_1: 0.7241  loss_dice_1: 2.032  loss_ce_2: 0  loss_mask_2: 0.7274  loss_dice_2: 2.023  loss_ce_3: 0  loss_mask_3: 0.7306  loss_dice_3: 2.003  loss_ce_4: 0  loss_mask_4: 0.7277  loss_dice_4: 2.008  loss_ce_5: 0  loss_mask_5: 0.7263  loss_dice_5: 2.009  loss_ce_6: 0  loss_mask_6: 0.729  loss_dice_6: 2.01  loss_ce_7: 0  loss_mask_7: 0.7314  loss_dice_7: 2.001  loss_ce_8: 0  loss_mask_8: 0.7312  loss_dice_8: 2.009  time: 1.8931  data_time: 0.0325  lr: 5.8358e-05  max_mem: 6006M
[02/18 14:42:58] d2.utils.events INFO:  eta: 1 day, 1:46:33  iter: 27039  total_loss: 28.63  loss_ce: 0  loss_mask: 0.7329  loss_dice: 2.065  loss_seg: 0.679  loss_ce_0: 0  loss_mask_0: 0.747  loss_dice_0: 2.141  loss_ce_1: 0  loss_mask_1: 0.7415  loss_dice_1: 2.081  loss_ce_2: 0  loss_mask_2: 0.7416  loss_dice_2: 2.06  loss_ce_3: 0  loss_mask_3: 0.7435  loss_dice_3: 2.053  loss_ce_4: 0  loss_mask_4: 0.743  loss_dice_4: 2.051  loss_ce_5: 0  loss_mask_5: 0.7405  loss_dice_5: 2.055  loss_ce_6: 0  loss_mask_6: 0.7432  loss_dice_6: 2.06  loss_ce_7: 0  loss_mask_7: 0.7432  loss_dice_7: 2.052  loss_ce_8: 0  loss_mask_8: 0.7421  loss_dice_8: 2.061  time: 1.8936  data_time: 0.0304  lr: 5.8326e-05  max_mem: 6006M
[02/18 14:44:03] d2.utils.events INFO:  eta: 1 day, 2:05:15  iter: 27059  total_loss: 28.45  loss_ce: 0  loss_mask: 0.6985  loss_dice: 2.023  loss_seg: 0.6693  loss_ce_0: 0  loss_mask_0: 0.7159  loss_dice_0: 2.101  loss_ce_1: 0  loss_mask_1: 0.6978  loss_dice_1: 2.04  loss_ce_2: 0  loss_mask_2: 0.6979  loss_dice_2: 2.029  loss_ce_3: 0  loss_mask_3: 0.6987  loss_dice_3: 2.028  loss_ce_4: 0  loss_mask_4: 0.7011  loss_dice_4: 2.023  loss_ce_5: 0  loss_mask_5: 0.6988  loss_dice_5: 2.021  loss_ce_6: 0  loss_mask_6: 0.7015  loss_dice_6: 2.024  loss_ce_7: 0  loss_mask_7: 0.7037  loss_dice_7: 2.021  loss_ce_8: 0  loss_mask_8: 0.7026  loss_dice_8: 2.022  time: 1.8946  data_time: 0.0342  lr: 5.8294e-05  max_mem: 6006M
[02/18 14:45:11] d2.utils.events INFO:  eta: 1 day, 2:30:11  iter: 27079  total_loss: 28.77  loss_ce: 0  loss_mask: 0.7489  loss_dice: 1.996  loss_seg: 0.8232  loss_ce_0: 0  loss_mask_0: 0.7545  loss_dice_0: 2.062  loss_ce_1: 0  loss_mask_1: 0.7612  loss_dice_1: 2.008  loss_ce_2: 0  loss_mask_2: 0.7588  loss_dice_2: 1.992  loss_ce_3: 0  loss_mask_3: 0.7538  loss_dice_3: 1.988  loss_ce_4: 0  loss_mask_4: 0.7539  loss_dice_4: 1.989  loss_ce_5: 0  loss_mask_5: 0.7539  loss_dice_5: 1.989  loss_ce_6: 0  loss_mask_6: 0.7504  loss_dice_6: 1.991  loss_ce_7: 0  loss_mask_7: 0.7535  loss_dice_7: 1.986  loss_ce_8: 0  loss_mask_8: 0.7541  loss_dice_8: 1.987  time: 1.8957  data_time: 0.0326  lr: 5.8263e-05  max_mem: 6006M
[02/18 14:46:20] d2.utils.events INFO:  eta: 1 day, 2:49:41  iter: 27099  total_loss: 29.68  loss_ce: 0  loss_mask: 0.743  loss_dice: 2.081  loss_seg: 0.8287  loss_ce_0: 0  loss_mask_0: 0.7433  loss_dice_0: 2.124  loss_ce_1: 0  loss_mask_1: 0.7434  loss_dice_1: 2.088  loss_ce_2: 0  loss_mask_2: 0.7493  loss_dice_2: 2.069  loss_ce_3: 0  loss_mask_3: 0.7549  loss_dice_3: 2.071  loss_ce_4: 0  loss_mask_4: 0.7481  loss_dice_4: 2.073  loss_ce_5: 0  loss_mask_5: 0.7533  loss_dice_5: 2.073  loss_ce_6: 0  loss_mask_6: 0.7566  loss_dice_6: 2.062  loss_ce_7: 0  loss_mask_7: 0.7531  loss_dice_7: 2.069  loss_ce_8: 0  loss_mask_8: 0.7509  loss_dice_8: 2.072  time: 1.8969  data_time: 0.0311  lr: 5.8231e-05  max_mem: 6006M
[02/18 14:47:04] d2.utils.events INFO:  eta: 1 day, 2:57:05  iter: 27119  total_loss: 28.87  loss_ce: 0  loss_mask: 0.7082  loss_dice: 2.047  loss_seg: 0.8302  loss_ce_0: 0  loss_mask_0: 0.725  loss_dice_0: 2.11  loss_ce_1: 0  loss_mask_1: 0.7135  loss_dice_1: 2.058  loss_ce_2: 0  loss_mask_2: 0.709  loss_dice_2: 2.047  loss_ce_3: 0  loss_mask_3: 0.7099  loss_dice_3: 2.037  loss_ce_4: 0  loss_mask_4: 0.707  loss_dice_4: 2.038  loss_ce_5: 0  loss_mask_5: 0.7061  loss_dice_5: 2.035  loss_ce_6: 0  loss_mask_6: 0.7104  loss_dice_6: 2.032  loss_ce_7: 0  loss_mask_7: 0.7114  loss_dice_7: 2.037  loss_ce_8: 0  loss_mask_8: 0.7141  loss_dice_8: 2.034  time: 1.8971  data_time: 0.0357  lr: 5.8199e-05  max_mem: 6006M
[02/18 14:47:36] d2.utils.events INFO:  eta: 1 day, 2:56:06  iter: 27139  total_loss: 27.61  loss_ce: 0  loss_mask: 0.6958  loss_dice: 1.921  loss_seg: 0.7597  loss_ce_0: 0  loss_mask_0: 0.7051  loss_dice_0: 1.979  loss_ce_1: 0  loss_mask_1: 0.7055  loss_dice_1: 1.936  loss_ce_2: 0  loss_mask_2: 0.7035  loss_dice_2: 1.919  loss_ce_3: 0  loss_mask_3: 0.7026  loss_dice_3: 1.915  loss_ce_4: 0  loss_mask_4: 0.7037  loss_dice_4: 1.908  loss_ce_5: 0  loss_mask_5: 0.7032  loss_dice_5: 1.912  loss_ce_6: 0  loss_mask_6: 0.7022  loss_dice_6: 1.912  loss_ce_7: 0  loss_mask_7: 0.7031  loss_dice_7: 1.918  loss_ce_8: 0  loss_mask_8: 0.6998  loss_dice_8: 1.918  time: 1.8968  data_time: 0.0383  lr: 5.8167e-05  max_mem: 6006M
[02/18 14:48:38] d2.utils.events INFO:  eta: 1 day, 3:07:28  iter: 27159  total_loss: 28.14  loss_ce: 0  loss_mask: 0.7377  loss_dice: 2.021  loss_seg: 0.7152  loss_ce_0: 0  loss_mask_0: 0.7408  loss_dice_0: 2.095  loss_ce_1: 0  loss_mask_1: 0.7408  loss_dice_1: 2.008  loss_ce_2: 0  loss_mask_2: 0.7452  loss_dice_2: 2.026  loss_ce_3: 0  loss_mask_3: 0.7411  loss_dice_3: 2.008  loss_ce_4: 0  loss_mask_4: 0.7434  loss_dice_4: 2.002  loss_ce_5: 0  loss_mask_5: 0.7458  loss_dice_5: 2  loss_ce_6: 0  loss_mask_6: 0.7471  loss_dice_6: 1.991  loss_ce_7: 0  loss_mask_7: 0.7461  loss_dice_7: 2.004  loss_ce_8: 0  loss_mask_8: 0.7424  loss_dice_8: 1.998  time: 1.8978  data_time: 0.0318  lr: 5.8135e-05  max_mem: 6006M
[02/18 14:49:45] d2.utils.events INFO:  eta: 1 day, 3:13:21  iter: 27179  total_loss: 28.16  loss_ce: 0  loss_mask: 0.6981  loss_dice: 1.993  loss_seg: 0.8187  loss_ce_0: 0  loss_mask_0: 0.7114  loss_dice_0: 2.036  loss_ce_1: 0  loss_mask_1: 0.7025  loss_dice_1: 2.001  loss_ce_2: 0  loss_mask_2: 0.7015  loss_dice_2: 1.993  loss_ce_3: 0  loss_mask_3: 0.7027  loss_dice_3: 1.988  loss_ce_4: 0  loss_mask_4: 0.7028  loss_dice_4: 1.99  loss_ce_5: 0  loss_mask_5: 0.7018  loss_dice_5: 1.99  loss_ce_6: 0  loss_mask_6: 0.703  loss_dice_6: 1.992  loss_ce_7: 0  loss_mask_7: 0.7074  loss_dice_7: 1.983  loss_ce_8: 0  loss_mask_8: 0.7043  loss_dice_8: 1.985  time: 1.8988  data_time: 0.0314  lr: 5.8103e-05  max_mem: 6006M
[02/18 14:50:57] d2.utils.events INFO:  eta: 1 day, 3:19:09  iter: 27199  total_loss: 29.47  loss_ce: 0  loss_mask: 0.7423  loss_dice: 2.126  loss_seg: 0.8258  loss_ce_0: 0  loss_mask_0: 0.745  loss_dice_0: 2.185  loss_ce_1: 0  loss_mask_1: 0.7432  loss_dice_1: 2.158  loss_ce_2: 0  loss_mask_2: 0.7461  loss_dice_2: 2.13  loss_ce_3: 0  loss_mask_3: 0.746  loss_dice_3: 2.119  loss_ce_4: 0  loss_mask_4: 0.7454  loss_dice_4: 2.119  loss_ce_5: 0  loss_mask_5: 0.7429  loss_dice_5: 2.125  loss_ce_6: 0  loss_mask_6: 0.7462  loss_dice_6: 2.12  loss_ce_7: 0  loss_mask_7: 0.7439  loss_dice_7: 2.114  loss_ce_8: 0  loss_mask_8: 0.7469  loss_dice_8: 2.127  time: 1.9000  data_time: 0.0246  lr: 5.8071e-05  max_mem: 6006M
[02/18 14:52:06] d2.utils.events INFO:  eta: 1 day, 3:21:44  iter: 27219  total_loss: 30.22  loss_ce: 0  loss_mask: 0.7708  loss_dice: 2.083  loss_seg: 1.048  loss_ce_0: 0  loss_mask_0: 0.7949  loss_dice_0: 2.14  loss_ce_1: 0  loss_mask_1: 0.7749  loss_dice_1: 2.103  loss_ce_2: 0  loss_mask_2: 0.7747  loss_dice_2: 2.081  loss_ce_3: 0  loss_mask_3: 0.7759  loss_dice_3: 2.072  loss_ce_4: 0  loss_mask_4: 0.7735  loss_dice_4: 2.071  loss_ce_5: 0  loss_mask_5: 0.7717  loss_dice_5: 2.079  loss_ce_6: 0  loss_mask_6: 0.7723  loss_dice_6: 2.074  loss_ce_7: 0  loss_mask_7: 0.7751  loss_dice_7: 2.074  loss_ce_8: 0  loss_mask_8: 0.7724  loss_dice_8: 2.072  time: 1.9012  data_time: 0.0287  lr: 5.804e-05  max_mem: 6006M
[02/18 14:53:12] d2.utils.events INFO:  eta: 1 day, 3:18:02  iter: 27239  total_loss: 29.51  loss_ce: 0  loss_mask: 0.7207  loss_dice: 2.094  loss_seg: 0.9391  loss_ce_0: 0  loss_mask_0: 0.746  loss_dice_0: 2.134  loss_ce_1: 0  loss_mask_1: 0.7312  loss_dice_1: 2.109  loss_ce_2: 0  loss_mask_2: 0.734  loss_dice_2: 2.09  loss_ce_3: 0  loss_mask_3: 0.7302  loss_dice_3: 2.085  loss_ce_4: 0  loss_mask_4: 0.7301  loss_dice_4: 2.083  loss_ce_5: 0  loss_mask_5: 0.7308  loss_dice_5: 2.084  loss_ce_6: 0  loss_mask_6: 0.7293  loss_dice_6: 2.086  loss_ce_7: 0  loss_mask_7: 0.7315  loss_dice_7: 2.083  loss_ce_8: 0  loss_mask_8: 0.73  loss_dice_8: 2.082  time: 1.9022  data_time: 0.0316  lr: 5.8008e-05  max_mem: 6006M
[02/18 14:54:09] d2.utils.events INFO:  eta: 1 day, 3:11:16  iter: 27259  total_loss: 28.4  loss_ce: 0  loss_mask: 0.7597  loss_dice: 2.005  loss_seg: 0.66  loss_ce_0: 0  loss_mask_0: 0.7846  loss_dice_0: 2.066  loss_ce_1: 0  loss_mask_1: 0.7704  loss_dice_1: 2.019  loss_ce_2: 0  loss_mask_2: 0.7735  loss_dice_2: 1.993  loss_ce_3: 0  loss_mask_3: 0.7677  loss_dice_3: 1.995  loss_ce_4: 0  loss_mask_4: 0.7655  loss_dice_4: 2  loss_ce_5: 0  loss_mask_5: 0.7686  loss_dice_5: 1.993  loss_ce_6: 0  loss_mask_6: 0.7666  loss_dice_6: 1.997  loss_ce_7: 0  loss_mask_7: 0.764  loss_dice_7: 1.999  loss_ce_8: 0  loss_mask_8: 0.7637  loss_dice_8: 2  time: 1.9029  data_time: 0.0286  lr: 5.7976e-05  max_mem: 6006M
[02/18 14:54:42] d2.utils.events INFO:  eta: 1 day, 2:56:10  iter: 27279  total_loss: 27.15  loss_ce: 0  loss_mask: 0.718  loss_dice: 1.937  loss_seg: 0.7026  loss_ce_0: 0  loss_mask_0: 0.7282  loss_dice_0: 1.985  loss_ce_1: 0  loss_mask_1: 0.7255  loss_dice_1: 1.952  loss_ce_2: 0  loss_mask_2: 0.7237  loss_dice_2: 1.941  loss_ce_3: 0  loss_mask_3: 0.722  loss_dice_3: 1.927  loss_ce_4: 0  loss_mask_4: 0.7203  loss_dice_4: 1.93  loss_ce_5: 0  loss_mask_5: 0.7208  loss_dice_5: 1.93  loss_ce_6: 0  loss_mask_6: 0.7209  loss_dice_6: 1.927  loss_ce_7: 0  loss_mask_7: 0.7237  loss_dice_7: 1.931  loss_ce_8: 0  loss_mask_8: 0.7211  loss_dice_8: 1.93  time: 1.9027  data_time: 0.0335  lr: 5.7944e-05  max_mem: 6006M
[02/18 14:55:17] d2.utils.events INFO:  eta: 1 day, 2:32:25  iter: 27299  total_loss: 30.04  loss_ce: 0  loss_mask: 0.7363  loss_dice: 2.165  loss_seg: 0.5861  loss_ce_0: 0  loss_mask_0: 0.7443  loss_dice_0: 2.209  loss_ce_1: 0  loss_mask_1: 0.738  loss_dice_1: 2.17  loss_ce_2: 0  loss_mask_2: 0.7389  loss_dice_2: 2.162  loss_ce_3: 0  loss_mask_3: 0.741  loss_dice_3: 2.159  loss_ce_4: 0  loss_mask_4: 0.7414  loss_dice_4: 2.163  loss_ce_5: 0  loss_mask_5: 0.7415  loss_dice_5: 2.157  loss_ce_6: 0  loss_mask_6: 0.7384  loss_dice_6: 2.159  loss_ce_7: 0  loss_mask_7: 0.7386  loss_dice_7: 2.16  loss_ce_8: 0  loss_mask_8: 0.741  loss_dice_8: 2.158  time: 1.9026  data_time: 0.0346  lr: 5.7912e-05  max_mem: 6006M
[02/18 14:56:21] d2.utils.events INFO:  eta: 1 day, 2:31:07  iter: 27319  total_loss: 27.76  loss_ce: 0  loss_mask: 0.7569  loss_dice: 1.971  loss_seg: 0.7031  loss_ce_0: 0  loss_mask_0: 0.7683  loss_dice_0: 2.035  loss_ce_1: 0  loss_mask_1: 0.7616  loss_dice_1: 1.99  loss_ce_2: 0  loss_mask_2: 0.7606  loss_dice_2: 1.969  loss_ce_3: 0  loss_mask_3: 0.7567  loss_dice_3: 1.967  loss_ce_4: 0  loss_mask_4: 0.7573  loss_dice_4: 1.959  loss_ce_5: 0  loss_mask_5: 0.7538  loss_dice_5: 1.966  loss_ce_6: 0  loss_mask_6: 0.7545  loss_dice_6: 1.956  loss_ce_7: 0  loss_mask_7: 0.7528  loss_dice_7: 1.956  loss_ce_8: 0  loss_mask_8: 0.7552  loss_dice_8: 1.963  time: 1.9035  data_time: 0.0301  lr: 5.788e-05  max_mem: 6006M
[02/18 14:57:24] d2.utils.events INFO:  eta: 1 day, 2:25:04  iter: 27339  total_loss: 28.35  loss_ce: 0  loss_mask: 0.7227  loss_dice: 1.98  loss_seg: 0.7811  loss_ce_0: 0  loss_mask_0: 0.7269  loss_dice_0: 2.055  loss_ce_1: 0  loss_mask_1: 0.7167  loss_dice_1: 2.01  loss_ce_2: 0  loss_mask_2: 0.7175  loss_dice_2: 1.988  loss_ce_3: 0  loss_mask_3: 0.7238  loss_dice_3: 1.975  loss_ce_4: 0  loss_mask_4: 0.7233  loss_dice_4: 1.978  loss_ce_5: 0  loss_mask_5: 0.7234  loss_dice_5: 1.975  loss_ce_6: 0  loss_mask_6: 0.7244  loss_dice_6: 1.973  loss_ce_7: 0  loss_mask_7: 0.7195  loss_dice_7: 1.974  loss_ce_8: 0  loss_mask_8: 0.7206  loss_dice_8: 1.973  time: 1.9044  data_time: 0.0285  lr: 5.7848e-05  max_mem: 6006M
[02/18 14:58:33] d2.utils.events INFO:  eta: 1 day, 2:24:05  iter: 27359  total_loss: 30.42  loss_ce: 0  loss_mask: 0.7574  loss_dice: 2.172  loss_seg: 0.818  loss_ce_0: 0  loss_mask_0: 0.7615  loss_dice_0: 2.251  loss_ce_1: 0  loss_mask_1: 0.766  loss_dice_1: 2.181  loss_ce_2: 0  loss_mask_2: 0.7678  loss_dice_2: 2.168  loss_ce_3: 0  loss_mask_3: 0.7671  loss_dice_3: 2.157  loss_ce_4: 0  loss_mask_4: 0.7684  loss_dice_4: 2.165  loss_ce_5: 0  loss_mask_5: 0.7692  loss_dice_5: 2.164  loss_ce_6: 0  loss_mask_6: 0.7647  loss_dice_6: 2.159  loss_ce_7: 0  loss_mask_7: 0.7655  loss_dice_7: 2.159  loss_ce_8: 0  loss_mask_8: 0.7641  loss_dice_8: 2.167  time: 1.9056  data_time: 0.0397  lr: 5.7816e-05  max_mem: 6006M
[02/18 14:59:43] d2.utils.events INFO:  eta: 1 day, 2:27:40  iter: 27379  total_loss: 27.86  loss_ce: 0  loss_mask: 0.739  loss_dice: 1.981  loss_seg: 0.5573  loss_ce_0: 0  loss_mask_0: 0.7371  loss_dice_0: 2.064  loss_ce_1: 0  loss_mask_1: 0.7429  loss_dice_1: 2.001  loss_ce_2: 0  loss_mask_2: 0.7352  loss_dice_2: 1.995  loss_ce_3: 0  loss_mask_3: 0.7379  loss_dice_3: 1.983  loss_ce_4: 0  loss_mask_4: 0.7364  loss_dice_4: 1.981  loss_ce_5: 0  loss_mask_5: 0.7354  loss_dice_5: 1.986  loss_ce_6: 0  loss_mask_6: 0.7348  loss_dice_6: 1.974  loss_ce_7: 0  loss_mask_7: 0.7365  loss_dice_7: 1.973  loss_ce_8: 0  loss_mask_8: 0.7367  loss_dice_8: 1.978  time: 1.9067  data_time: 0.0356  lr: 5.7785e-05  max_mem: 6006M
[02/18 15:00:50] d2.utils.events INFO:  eta: 1 day, 2:27:13  iter: 27399  total_loss: 28.76  loss_ce: 0  loss_mask: 0.7551  loss_dice: 1.994  loss_seg: 0.4826  loss_ce_0: 0  loss_mask_0: 0.7632  loss_dice_0: 2.091  loss_ce_1: 0  loss_mask_1: 0.7578  loss_dice_1: 2.019  loss_ce_2: 0  loss_mask_2: 0.7608  loss_dice_2: 2.002  loss_ce_3: 0  loss_mask_3: 0.7597  loss_dice_3: 1.988  loss_ce_4: 0  loss_mask_4: 0.7599  loss_dice_4: 1.983  loss_ce_5: 0  loss_mask_5: 0.7584  loss_dice_5: 1.984  loss_ce_6: 0  loss_mask_6: 0.7592  loss_dice_6: 1.985  loss_ce_7: 0  loss_mask_7: 0.7567  loss_dice_7: 1.982  loss_ce_8: 0  loss_mask_8: 0.7561  loss_dice_8: 1.99  time: 1.9078  data_time: 0.0469  lr: 5.7753e-05  max_mem: 6006M
[02/18 15:01:59] d2.utils.events INFO:  eta: 1 day, 2:26:50  iter: 27419  total_loss: 28.98  loss_ce: 0  loss_mask: 0.7158  loss_dice: 2.08  loss_seg: 0.6106  loss_ce_0: 0  loss_mask_0: 0.7283  loss_dice_0: 2.139  loss_ce_1: 0  loss_mask_1: 0.7224  loss_dice_1: 2.101  loss_ce_2: 0  loss_mask_2: 0.7191  loss_dice_2: 2.088  loss_ce_3: 0  loss_mask_3: 0.7201  loss_dice_3: 2.075  loss_ce_4: 0  loss_mask_4: 0.7219  loss_dice_4: 2.072  loss_ce_5: 0  loss_mask_5: 0.7207  loss_dice_5: 2.07  loss_ce_6: 0  loss_mask_6: 0.7203  loss_dice_6: 2.069  loss_ce_7: 0  loss_mask_7: 0.72  loss_dice_7: 2.066  loss_ce_8: 0  loss_mask_8: 0.7196  loss_dice_8: 2.067  time: 1.9089  data_time: 0.0374  lr: 5.7721e-05  max_mem: 6006M
[02/18 15:03:09] d2.utils.events INFO:  eta: 1 day, 2:27:14  iter: 27439  total_loss: 27.44  loss_ce: 0  loss_mask: 0.6748  loss_dice: 1.973  loss_seg: 0.7259  loss_ce_0: 0  loss_mask_0: 0.6944  loss_dice_0: 2.042  loss_ce_1: 0  loss_mask_1: 0.6839  loss_dice_1: 1.979  loss_ce_2: 0  loss_mask_2: 0.6774  loss_dice_2: 1.967  loss_ce_3: 0  loss_mask_3: 0.6783  loss_dice_3: 1.961  loss_ce_4: 0  loss_mask_4: 0.6781  loss_dice_4: 1.964  loss_ce_5: 0  loss_mask_5: 0.6795  loss_dice_5: 1.967  loss_ce_6: 0  loss_mask_6: 0.6818  loss_dice_6: 1.962  loss_ce_7: 0  loss_mask_7: 0.6833  loss_dice_7: 1.963  loss_ce_8: 0  loss_mask_8: 0.6823  loss_dice_8: 1.964  time: 1.9101  data_time: 0.0375  lr: 5.7689e-05  max_mem: 6006M
[02/18 15:04:15] d2.utils.events INFO:  eta: 1 day, 2:28:37  iter: 27459  total_loss: 28.66  loss_ce: 0  loss_mask: 0.7431  loss_dice: 2.01  loss_seg: 0.9053  loss_ce_0: 0  loss_mask_0: 0.7479  loss_dice_0: 2.07  loss_ce_1: 0  loss_mask_1: 0.7519  loss_dice_1: 2.016  loss_ce_2: 0  loss_mask_2: 0.7499  loss_dice_2: 2.006  loss_ce_3: 0  loss_mask_3: 0.75  loss_dice_3: 2.005  loss_ce_4: 0  loss_mask_4: 0.7436  loss_dice_4: 2  loss_ce_5: 0  loss_mask_5: 0.7448  loss_dice_5: 2.003  loss_ce_6: 0  loss_mask_6: 0.7472  loss_dice_6: 2.005  loss_ce_7: 0  loss_mask_7: 0.7464  loss_dice_7: 2  loss_ce_8: 0  loss_mask_8: 0.749  loss_dice_8: 1.999  time: 1.9111  data_time: 0.0352  lr: 5.7657e-05  max_mem: 6006M
[02/18 15:05:27] d2.utils.events INFO:  eta: 1 day, 2:42:59  iter: 27479  total_loss: 29.36  loss_ce: 0  loss_mask: 0.763  loss_dice: 2.056  loss_seg: 0.8298  loss_ce_0: 0  loss_mask_0: 0.767  loss_dice_0: 2.118  loss_ce_1: 0  loss_mask_1: 0.7578  loss_dice_1: 2.078  loss_ce_2: 0  loss_mask_2: 0.7591  loss_dice_2: 2.064  loss_ce_3: 0  loss_mask_3: 0.7648  loss_dice_3: 2.054  loss_ce_4: 0  loss_mask_4: 0.7635  loss_dice_4: 2.051  loss_ce_5: 0  loss_mask_5: 0.7635  loss_dice_5: 2.044  loss_ce_6: 0  loss_mask_6: 0.7614  loss_dice_6: 2.043  loss_ce_7: 0  loss_mask_7: 0.7665  loss_dice_7: 2.047  loss_ce_8: 0  loss_mask_8: 0.7658  loss_dice_8: 2.049  time: 1.9123  data_time: 0.0340  lr: 5.7625e-05  max_mem: 6006M
[02/18 15:06:28] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 15:06:29] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 15:06:29] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 15:06:45] mask2former INFO: Inference done 11/1093. Dataloading: 0.0030 s/iter. Inference: 0.3808 s/iter. Eval: 0.1060 s/iter. Total: 0.4898 s/iter. ETA=0:08:49
[02/18 15:06:50] mask2former INFO: Inference done 22/1093. Dataloading: 0.0044 s/iter. Inference: 0.3721 s/iter. Eval: 0.1124 s/iter. Total: 0.4891 s/iter. ETA=0:08:43
[02/18 15:06:56] mask2former INFO: Inference done 34/1093. Dataloading: 0.0047 s/iter. Inference: 0.3608 s/iter. Eval: 0.1081 s/iter. Total: 0.4736 s/iter. ETA=0:08:21
[02/18 15:07:01] mask2former INFO: Inference done 45/1093. Dataloading: 0.0046 s/iter. Inference: 0.3587 s/iter. Eval: 0.1121 s/iter. Total: 0.4755 s/iter. ETA=0:08:18
[02/18 15:07:06] mask2former INFO: Inference done 55/1093. Dataloading: 0.0047 s/iter. Inference: 0.3646 s/iter. Eval: 0.1177 s/iter. Total: 0.4872 s/iter. ETA=0:08:25
[02/18 15:07:11] mask2former INFO: Inference done 66/1093. Dataloading: 0.0048 s/iter. Inference: 0.3647 s/iter. Eval: 0.1162 s/iter. Total: 0.4858 s/iter. ETA=0:08:18
[02/18 15:07:17] mask2former INFO: Inference done 77/1093. Dataloading: 0.0050 s/iter. Inference: 0.3649 s/iter. Eval: 0.1153 s/iter. Total: 0.4853 s/iter. ETA=0:08:13
[02/18 15:07:22] mask2former INFO: Inference done 87/1093. Dataloading: 0.0051 s/iter. Inference: 0.3675 s/iter. Eval: 0.1159 s/iter. Total: 0.4886 s/iter. ETA=0:08:11
[02/18 15:07:27] mask2former INFO: Inference done 97/1093. Dataloading: 0.0052 s/iter. Inference: 0.3702 s/iter. Eval: 0.1160 s/iter. Total: 0.4914 s/iter. ETA=0:08:09
[02/18 15:07:32] mask2former INFO: Inference done 108/1093. Dataloading: 0.0051 s/iter. Inference: 0.3709 s/iter. Eval: 0.1160 s/iter. Total: 0.4921 s/iter. ETA=0:08:04
[02/18 15:07:38] mask2former INFO: Inference done 119/1093. Dataloading: 0.0051 s/iter. Inference: 0.3713 s/iter. Eval: 0.1154 s/iter. Total: 0.4919 s/iter. ETA=0:07:59
[02/18 15:07:43] mask2former INFO: Inference done 129/1093. Dataloading: 0.0051 s/iter. Inference: 0.3723 s/iter. Eval: 0.1170 s/iter. Total: 0.4945 s/iter. ETA=0:07:56
[02/18 15:07:48] mask2former INFO: Inference done 140/1093. Dataloading: 0.0050 s/iter. Inference: 0.3695 s/iter. Eval: 0.1175 s/iter. Total: 0.4921 s/iter. ETA=0:07:49
[02/18 15:07:54] mask2former INFO: Inference done 151/1093. Dataloading: 0.0050 s/iter. Inference: 0.3688 s/iter. Eval: 0.1172 s/iter. Total: 0.4912 s/iter. ETA=0:07:42
[02/18 15:07:59] mask2former INFO: Inference done 161/1093. Dataloading: 0.0051 s/iter. Inference: 0.3691 s/iter. Eval: 0.1184 s/iter. Total: 0.4927 s/iter. ETA=0:07:39
[02/18 15:08:04] mask2former INFO: Inference done 172/1093. Dataloading: 0.0051 s/iter. Inference: 0.3678 s/iter. Eval: 0.1178 s/iter. Total: 0.4908 s/iter. ETA=0:07:32
[02/18 15:08:09] mask2former INFO: Inference done 183/1093. Dataloading: 0.0051 s/iter. Inference: 0.3675 s/iter. Eval: 0.1178 s/iter. Total: 0.4904 s/iter. ETA=0:07:26
[02/18 15:08:14] mask2former INFO: Inference done 193/1093. Dataloading: 0.0051 s/iter. Inference: 0.3682 s/iter. Eval: 0.1176 s/iter. Total: 0.4910 s/iter. ETA=0:07:21
[02/18 15:08:20] mask2former INFO: Inference done 205/1093. Dataloading: 0.0051 s/iter. Inference: 0.3666 s/iter. Eval: 0.1171 s/iter. Total: 0.4889 s/iter. ETA=0:07:14
[02/18 15:08:25] mask2former INFO: Inference done 216/1093. Dataloading: 0.0050 s/iter. Inference: 0.3674 s/iter. Eval: 0.1165 s/iter. Total: 0.4891 s/iter. ETA=0:07:08
[02/18 15:08:30] mask2former INFO: Inference done 227/1093. Dataloading: 0.0051 s/iter. Inference: 0.3680 s/iter. Eval: 0.1159 s/iter. Total: 0.4890 s/iter. ETA=0:07:03
[02/18 15:08:36] mask2former INFO: Inference done 238/1093. Dataloading: 0.0050 s/iter. Inference: 0.3673 s/iter. Eval: 0.1158 s/iter. Total: 0.4882 s/iter. ETA=0:06:57
[02/18 15:08:41] mask2former INFO: Inference done 248/1093. Dataloading: 0.0063 s/iter. Inference: 0.3674 s/iter. Eval: 0.1155 s/iter. Total: 0.4893 s/iter. ETA=0:06:53
[02/18 15:08:46] mask2former INFO: Inference done 259/1093. Dataloading: 0.0063 s/iter. Inference: 0.3671 s/iter. Eval: 0.1161 s/iter. Total: 0.4896 s/iter. ETA=0:06:48
[02/18 15:08:51] mask2former INFO: Inference done 270/1093. Dataloading: 0.0062 s/iter. Inference: 0.3669 s/iter. Eval: 0.1159 s/iter. Total: 0.4891 s/iter. ETA=0:06:42
[02/18 15:08:57] mask2former INFO: Inference done 281/1093. Dataloading: 0.0062 s/iter. Inference: 0.3670 s/iter. Eval: 0.1159 s/iter. Total: 0.4892 s/iter. ETA=0:06:37
[02/18 15:09:02] mask2former INFO: Inference done 292/1093. Dataloading: 0.0062 s/iter. Inference: 0.3674 s/iter. Eval: 0.1153 s/iter. Total: 0.4889 s/iter. ETA=0:06:31
[02/18 15:09:08] mask2former INFO: Inference done 303/1093. Dataloading: 0.0061 s/iter. Inference: 0.3671 s/iter. Eval: 0.1157 s/iter. Total: 0.4891 s/iter. ETA=0:06:26
[02/18 15:09:13] mask2former INFO: Inference done 314/1093. Dataloading: 0.0061 s/iter. Inference: 0.3663 s/iter. Eval: 0.1155 s/iter. Total: 0.4880 s/iter. ETA=0:06:20
[02/18 15:09:18] mask2former INFO: Inference done 325/1093. Dataloading: 0.0060 s/iter. Inference: 0.3662 s/iter. Eval: 0.1154 s/iter. Total: 0.4878 s/iter. ETA=0:06:14
[02/18 15:09:23] mask2former INFO: Inference done 336/1093. Dataloading: 0.0060 s/iter. Inference: 0.3662 s/iter. Eval: 0.1154 s/iter. Total: 0.4876 s/iter. ETA=0:06:09
[02/18 15:09:28] mask2former INFO: Inference done 347/1093. Dataloading: 0.0060 s/iter. Inference: 0.3654 s/iter. Eval: 0.1152 s/iter. Total: 0.4867 s/iter. ETA=0:06:03
[02/18 15:09:34] mask2former INFO: Inference done 358/1093. Dataloading: 0.0060 s/iter. Inference: 0.3653 s/iter. Eval: 0.1151 s/iter. Total: 0.4865 s/iter. ETA=0:05:57
[02/18 15:09:39] mask2former INFO: Inference done 368/1093. Dataloading: 0.0060 s/iter. Inference: 0.3655 s/iter. Eval: 0.1156 s/iter. Total: 0.4872 s/iter. ETA=0:05:53
[02/18 15:09:44] mask2former INFO: Inference done 378/1093. Dataloading: 0.0060 s/iter. Inference: 0.3661 s/iter. Eval: 0.1153 s/iter. Total: 0.4875 s/iter. ETA=0:05:48
[02/18 15:09:49] mask2former INFO: Inference done 388/1093. Dataloading: 0.0059 s/iter. Inference: 0.3662 s/iter. Eval: 0.1158 s/iter. Total: 0.4881 s/iter. ETA=0:05:44
[02/18 15:09:54] mask2former INFO: Inference done 399/1093. Dataloading: 0.0059 s/iter. Inference: 0.3661 s/iter. Eval: 0.1157 s/iter. Total: 0.4878 s/iter. ETA=0:05:38
[02/18 15:09:59] mask2former INFO: Inference done 410/1093. Dataloading: 0.0059 s/iter. Inference: 0.3658 s/iter. Eval: 0.1155 s/iter. Total: 0.4873 s/iter. ETA=0:05:32
[02/18 15:10:05] mask2former INFO: Inference done 421/1093. Dataloading: 0.0059 s/iter. Inference: 0.3658 s/iter. Eval: 0.1155 s/iter. Total: 0.4873 s/iter. ETA=0:05:27
[02/18 15:10:10] mask2former INFO: Inference done 432/1093. Dataloading: 0.0058 s/iter. Inference: 0.3654 s/iter. Eval: 0.1157 s/iter. Total: 0.4870 s/iter. ETA=0:05:21
[02/18 15:10:15] mask2former INFO: Inference done 443/1093. Dataloading: 0.0058 s/iter. Inference: 0.3648 s/iter. Eval: 0.1161 s/iter. Total: 0.4869 s/iter. ETA=0:05:16
[02/18 15:10:21] mask2former INFO: Inference done 454/1093. Dataloading: 0.0058 s/iter. Inference: 0.3650 s/iter. Eval: 0.1162 s/iter. Total: 0.4871 s/iter. ETA=0:05:11
[02/18 15:10:26] mask2former INFO: Inference done 465/1093. Dataloading: 0.0058 s/iter. Inference: 0.3646 s/iter. Eval: 0.1160 s/iter. Total: 0.4864 s/iter. ETA=0:05:05
[02/18 15:10:31] mask2former INFO: Inference done 476/1093. Dataloading: 0.0058 s/iter. Inference: 0.3647 s/iter. Eval: 0.1160 s/iter. Total: 0.4866 s/iter. ETA=0:05:00
[02/18 15:10:36] mask2former INFO: Inference done 487/1093. Dataloading: 0.0057 s/iter. Inference: 0.3644 s/iter. Eval: 0.1158 s/iter. Total: 0.4861 s/iter. ETA=0:04:54
[02/18 15:10:41] mask2former INFO: Inference done 498/1093. Dataloading: 0.0057 s/iter. Inference: 0.3643 s/iter. Eval: 0.1159 s/iter. Total: 0.4860 s/iter. ETA=0:04:49
[02/18 15:10:47] mask2former INFO: Inference done 509/1093. Dataloading: 0.0057 s/iter. Inference: 0.3643 s/iter. Eval: 0.1160 s/iter. Total: 0.4862 s/iter. ETA=0:04:43
[02/18 15:10:52] mask2former INFO: Inference done 520/1093. Dataloading: 0.0057 s/iter. Inference: 0.3641 s/iter. Eval: 0.1159 s/iter. Total: 0.4858 s/iter. ETA=0:04:38
[02/18 15:10:57] mask2former INFO: Inference done 531/1093. Dataloading: 0.0057 s/iter. Inference: 0.3642 s/iter. Eval: 0.1157 s/iter. Total: 0.4857 s/iter. ETA=0:04:32
[02/18 15:11:03] mask2former INFO: Inference done 542/1093. Dataloading: 0.0057 s/iter. Inference: 0.3642 s/iter. Eval: 0.1157 s/iter. Total: 0.4856 s/iter. ETA=0:04:27
[02/18 15:11:08] mask2former INFO: Inference done 553/1093. Dataloading: 0.0056 s/iter. Inference: 0.3640 s/iter. Eval: 0.1156 s/iter. Total: 0.4854 s/iter. ETA=0:04:22
[02/18 15:11:13] mask2former INFO: Inference done 564/1093. Dataloading: 0.0057 s/iter. Inference: 0.3642 s/iter. Eval: 0.1157 s/iter. Total: 0.4857 s/iter. ETA=0:04:16
[02/18 15:11:18] mask2former INFO: Inference done 575/1093. Dataloading: 0.0056 s/iter. Inference: 0.3641 s/iter. Eval: 0.1156 s/iter. Total: 0.4854 s/iter. ETA=0:04:11
[02/18 15:11:24] mask2former INFO: Inference done 586/1093. Dataloading: 0.0056 s/iter. Inference: 0.3638 s/iter. Eval: 0.1159 s/iter. Total: 0.4854 s/iter. ETA=0:04:06
[02/18 15:11:29] mask2former INFO: Inference done 597/1093. Dataloading: 0.0056 s/iter. Inference: 0.3636 s/iter. Eval: 0.1157 s/iter. Total: 0.4850 s/iter. ETA=0:04:00
[02/18 15:11:34] mask2former INFO: Inference done 608/1093. Dataloading: 0.0056 s/iter. Inference: 0.3633 s/iter. Eval: 0.1158 s/iter. Total: 0.4848 s/iter. ETA=0:03:55
[02/18 15:11:39] mask2former INFO: Inference done 618/1093. Dataloading: 0.0056 s/iter. Inference: 0.3635 s/iter. Eval: 0.1159 s/iter. Total: 0.4851 s/iter. ETA=0:03:50
[02/18 15:11:45] mask2former INFO: Inference done 629/1093. Dataloading: 0.0056 s/iter. Inference: 0.3635 s/iter. Eval: 0.1161 s/iter. Total: 0.4853 s/iter. ETA=0:03:45
[02/18 15:11:50] mask2former INFO: Inference done 639/1093. Dataloading: 0.0056 s/iter. Inference: 0.3637 s/iter. Eval: 0.1161 s/iter. Total: 0.4855 s/iter. ETA=0:03:40
[02/18 15:11:55] mask2former INFO: Inference done 650/1093. Dataloading: 0.0056 s/iter. Inference: 0.3636 s/iter. Eval: 0.1160 s/iter. Total: 0.4853 s/iter. ETA=0:03:35
[02/18 15:12:00] mask2former INFO: Inference done 661/1093. Dataloading: 0.0056 s/iter. Inference: 0.3636 s/iter. Eval: 0.1160 s/iter. Total: 0.4853 s/iter. ETA=0:03:29
[02/18 15:12:05] mask2former INFO: Inference done 672/1093. Dataloading: 0.0056 s/iter. Inference: 0.3635 s/iter. Eval: 0.1158 s/iter. Total: 0.4849 s/iter. ETA=0:03:24
[02/18 15:12:11] mask2former INFO: Inference done 683/1093. Dataloading: 0.0056 s/iter. Inference: 0.3633 s/iter. Eval: 0.1160 s/iter. Total: 0.4851 s/iter. ETA=0:03:18
[02/18 15:12:16] mask2former INFO: Inference done 693/1093. Dataloading: 0.0056 s/iter. Inference: 0.3633 s/iter. Eval: 0.1163 s/iter. Total: 0.4854 s/iter. ETA=0:03:14
[02/18 15:12:21] mask2former INFO: Inference done 703/1093. Dataloading: 0.0056 s/iter. Inference: 0.3634 s/iter. Eval: 0.1165 s/iter. Total: 0.4857 s/iter. ETA=0:03:09
[02/18 15:12:26] mask2former INFO: Inference done 714/1093. Dataloading: 0.0057 s/iter. Inference: 0.3635 s/iter. Eval: 0.1165 s/iter. Total: 0.4858 s/iter. ETA=0:03:04
[02/18 15:12:31] mask2former INFO: Inference done 724/1093. Dataloading: 0.0057 s/iter. Inference: 0.3634 s/iter. Eval: 0.1169 s/iter. Total: 0.4860 s/iter. ETA=0:02:59
[02/18 15:12:37] mask2former INFO: Inference done 735/1093. Dataloading: 0.0057 s/iter. Inference: 0.3632 s/iter. Eval: 0.1170 s/iter. Total: 0.4859 s/iter. ETA=0:02:53
[02/18 15:12:42] mask2former INFO: Inference done 746/1093. Dataloading: 0.0057 s/iter. Inference: 0.3630 s/iter. Eval: 0.1168 s/iter. Total: 0.4855 s/iter. ETA=0:02:48
[02/18 15:12:47] mask2former INFO: Inference done 757/1093. Dataloading: 0.0057 s/iter. Inference: 0.3633 s/iter. Eval: 0.1166 s/iter. Total: 0.4857 s/iter. ETA=0:02:43
[02/18 15:12:52] mask2former INFO: Inference done 767/1093. Dataloading: 0.0056 s/iter. Inference: 0.3635 s/iter. Eval: 0.1167 s/iter. Total: 0.4860 s/iter. ETA=0:02:38
[02/18 15:12:57] mask2former INFO: Inference done 778/1093. Dataloading: 0.0056 s/iter. Inference: 0.3634 s/iter. Eval: 0.1166 s/iter. Total: 0.4857 s/iter. ETA=0:02:33
[02/18 15:13:03] mask2former INFO: Inference done 789/1093. Dataloading: 0.0056 s/iter. Inference: 0.3631 s/iter. Eval: 0.1168 s/iter. Total: 0.4856 s/iter. ETA=0:02:27
[02/18 15:13:08] mask2former INFO: Inference done 800/1093. Dataloading: 0.0056 s/iter. Inference: 0.3629 s/iter. Eval: 0.1168 s/iter. Total: 0.4854 s/iter. ETA=0:02:22
[02/18 15:13:13] mask2former INFO: Inference done 810/1093. Dataloading: 0.0057 s/iter. Inference: 0.3629 s/iter. Eval: 0.1169 s/iter. Total: 0.4856 s/iter. ETA=0:02:17
[02/18 15:13:18] mask2former INFO: Inference done 821/1093. Dataloading: 0.0057 s/iter. Inference: 0.3631 s/iter. Eval: 0.1170 s/iter. Total: 0.4859 s/iter. ETA=0:02:12
[02/18 15:13:23] mask2former INFO: Inference done 832/1093. Dataloading: 0.0057 s/iter. Inference: 0.3629 s/iter. Eval: 0.1170 s/iter. Total: 0.4857 s/iter. ETA=0:02:06
[02/18 15:13:29] mask2former INFO: Inference done 843/1093. Dataloading: 0.0056 s/iter. Inference: 0.3629 s/iter. Eval: 0.1170 s/iter. Total: 0.4856 s/iter. ETA=0:02:01
[02/18 15:13:34] mask2former INFO: Inference done 854/1093. Dataloading: 0.0056 s/iter. Inference: 0.3628 s/iter. Eval: 0.1172 s/iter. Total: 0.4856 s/iter. ETA=0:01:56
[02/18 15:13:39] mask2former INFO: Inference done 865/1093. Dataloading: 0.0056 s/iter. Inference: 0.3626 s/iter. Eval: 0.1171 s/iter. Total: 0.4855 s/iter. ETA=0:01:50
[02/18 15:13:44] mask2former INFO: Inference done 875/1093. Dataloading: 0.0056 s/iter. Inference: 0.3628 s/iter. Eval: 0.1171 s/iter. Total: 0.4856 s/iter. ETA=0:01:45
[02/18 15:13:50] mask2former INFO: Inference done 885/1093. Dataloading: 0.0056 s/iter. Inference: 0.3630 s/iter. Eval: 0.1174 s/iter. Total: 0.4860 s/iter. ETA=0:01:41
[02/18 15:13:55] mask2former INFO: Inference done 895/1093. Dataloading: 0.0056 s/iter. Inference: 0.3628 s/iter. Eval: 0.1177 s/iter. Total: 0.4863 s/iter. ETA=0:01:36
[02/18 15:14:00] mask2former INFO: Inference done 905/1093. Dataloading: 0.0056 s/iter. Inference: 0.3630 s/iter. Eval: 0.1178 s/iter. Total: 0.4865 s/iter. ETA=0:01:31
[02/18 15:14:05] mask2former INFO: Inference done 916/1093. Dataloading: 0.0056 s/iter. Inference: 0.3631 s/iter. Eval: 0.1177 s/iter. Total: 0.4865 s/iter. ETA=0:01:26
[02/18 15:14:10] mask2former INFO: Inference done 927/1093. Dataloading: 0.0056 s/iter. Inference: 0.3630 s/iter. Eval: 0.1178 s/iter. Total: 0.4865 s/iter. ETA=0:01:20
[02/18 15:14:16] mask2former INFO: Inference done 938/1093. Dataloading: 0.0056 s/iter. Inference: 0.3627 s/iter. Eval: 0.1179 s/iter. Total: 0.4863 s/iter. ETA=0:01:15
[02/18 15:14:21] mask2former INFO: Inference done 949/1093. Dataloading: 0.0056 s/iter. Inference: 0.3626 s/iter. Eval: 0.1178 s/iter. Total: 0.4861 s/iter. ETA=0:01:10
[02/18 15:14:26] mask2former INFO: Inference done 961/1093. Dataloading: 0.0056 s/iter. Inference: 0.3619 s/iter. Eval: 0.1178 s/iter. Total: 0.4854 s/iter. ETA=0:01:04
[02/18 15:14:31] mask2former INFO: Inference done 976/1093. Dataloading: 0.0056 s/iter. Inference: 0.3600 s/iter. Eval: 0.1176 s/iter. Total: 0.4833 s/iter. ETA=0:00:56
[02/18 15:14:36] mask2former INFO: Inference done 990/1093. Dataloading: 0.0056 s/iter. Inference: 0.3584 s/iter. Eval: 0.1176 s/iter. Total: 0.4816 s/iter. ETA=0:00:49
[02/18 15:14:41] mask2former INFO: Inference done 1004/1093. Dataloading: 0.0055 s/iter. Inference: 0.3567 s/iter. Eval: 0.1177 s/iter. Total: 0.4800 s/iter. ETA=0:00:42
[02/18 15:14:46] mask2former INFO: Inference done 1018/1093. Dataloading: 0.0055 s/iter. Inference: 0.3550 s/iter. Eval: 0.1177 s/iter. Total: 0.4784 s/iter. ETA=0:00:35
[02/18 15:14:52] mask2former INFO: Inference done 1033/1093. Dataloading: 0.0056 s/iter. Inference: 0.3533 s/iter. Eval: 0.1175 s/iter. Total: 0.4765 s/iter. ETA=0:00:28
[02/18 15:14:57] mask2former INFO: Inference done 1048/1093. Dataloading: 0.0056 s/iter. Inference: 0.3516 s/iter. Eval: 0.1175 s/iter. Total: 0.4748 s/iter. ETA=0:00:21
[02/18 15:15:02] mask2former INFO: Inference done 1062/1093. Dataloading: 0.0055 s/iter. Inference: 0.3501 s/iter. Eval: 0.1176 s/iter. Total: 0.4734 s/iter. ETA=0:00:14
[02/18 15:15:07] mask2former INFO: Inference done 1077/1093. Dataloading: 0.0056 s/iter. Inference: 0.3485 s/iter. Eval: 0.1175 s/iter. Total: 0.4717 s/iter. ETA=0:00:07
[02/18 15:15:13] mask2former INFO: Inference done 1092/1093. Dataloading: 0.0055 s/iter. Inference: 0.3470 s/iter. Eval: 0.1173 s/iter. Total: 0.4699 s/iter. ETA=0:00:00
[02/18 15:15:41] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.5570116181994447, 'error_1pix': 0.41763747477601004, 'error_3pix': 0.1979422945855574, 'mIoU': 19.755324708027374, 'fwIoU': 42.0189570443051, 'IoU-1': 94.28605942675065, 'IoU-2': 0.04579633565863844, 'IoU-3': 0.04617181850210462, 'IoU-4': 0.015306519022535261, 'IoU-5': 0.005196597383513217, 'IoU-6': 0.011828298474959654, 'IoU-7': 0.006412071793830518, 'IoU-8': 0.0027863623312887895, 'IoU-9': 0.7776625508512592, 'IoU-10': 9.979868151496422, 'IoU-11': 3.5357508469359726, 'IoU-12': 35.873939846760635, 'IoU-13': 21.3771819427491, 'IoU-14': 26.021544566208306, 'IoU-15': 24.882186353538156, 'IoU-16': 19.787202969134057, 'IoU-17': 21.029223042310953, 'IoU-18': 30.204756556620477, 'IoU-19': 36.248099024033586, 'IoU-20': 28.349678050922407, 'IoU-21': 8.997810085443732, 'IoU-22': 19.555647389174638, 'IoU-23': 25.103684446996816, 'IoU-24': 23.74390079249254, 'IoU-25': 31.85650223932711, 'IoU-26': 39.84399511910219, 'IoU-27': 30.873406848035955, 'IoU-28': 27.846198557165756, 'IoU-29': 28.559705871484436, 'IoU-30': 35.172448084176075, 'IoU-31': 30.820387477004356, 'IoU-32': 38.82388178643534, 'IoU-33': 22.55534283311931, 'IoU-34': 25.817013727253972, 'IoU-35': 32.271940950794914, 'IoU-36': 26.03324118296032, 'IoU-37': 5.187333195834172, 'IoU-38': 3.5475219852774917, 'IoU-39': 3.508173759910697, 'IoU-40': 3.804754743618771, 'IoU-41': 8.64790955424349, 'IoU-42': 22.472773942550887, 'IoU-43': 31.318684435430157, 'IoU-44': 18.83076302749609, 'IoU-45': 11.513110624563538, 'IoU-46': 13.729223636906845, 'IoU-47': 13.91041306961323, 'IoU-48': 11.423165287422313, 'mACC': 32.20318939754773, 'pACC': 51.22420606354551, 'ACC-1': 96.06035406473941, 'ACC-2': 0.04579641851544898, 'ACC-3': 0.052650943276537986, 'ACC-4': 0.01592043761302889, 'ACC-5': 0.005293588288230001, 'ACC-6': 0.01202366520845412, 'ACC-7': 0.006549169710817773, 'ACC-8': 0.002838612535559793, 'ACC-9': 53.05402372190004, 'ACC-10': 12.900262907333115, 'ACC-11': 3.9411378099063676, 'ACC-12': 86.49071600570892, 'ACC-13': 33.68942456664736, 'ACC-14': 40.09673568033673, 'ACC-15': 40.59888250473525, 'ACC-16': 30.499538181627763, 'ACC-17': 30.096914531255337, 'ACC-18': 40.68778698709416, 'ACC-19': 60.17139284055827, 'ACC-20': 58.9647076357788, 'ACC-21': 15.152917253407322, 'ACC-22': 30.091952904719637, 'ACC-23': 39.057072190836955, 'ACC-24': 34.80323508077645, 'ACC-25': 44.13294773001358, 'ACC-26': 64.51308605287271, 'ACC-27': 48.20489294335747, 'ACC-28': 40.522745260952966, 'ACC-29': 39.93154780909124, 'ACC-30': 53.570689845211874, 'ACC-31': 41.59006989846943, 'ACC-32': 72.64964839790721, 'ACC-33': 35.502568671635736, 'ACC-34': 37.717853410588496, 'ACC-35': 48.94888656393139, 'ACC-36': 60.42057065551195, 'ACC-37': 12.4495038644076, 'ACC-38': 7.140992541838107, 'ACC-39': 5.5885995362796095, 'ACC-40': 5.425090346677344, 'ACC-41': 11.808827012318243, 'ACC-42': 30.6665145836796, 'ACC-43': 57.694779254624926, 'ACC-44': 35.78501608663077, 'ACC-45': 19.575384104327348, 'ACC-46': 24.01161042098306, 'ACC-47': 23.1100702446626, 'ACC-48': 18.293068143807805})])
[02/18 15:15:41] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 15:15:41] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 15:15:41] d2.evaluation.testing INFO: copypaste: 2.5570,0.4176,0.1979,19.7553,42.0190,32.2032,51.2242
[02/18 15:15:41] d2.utils.events INFO:  eta: 1 day, 2:34:23  iter: 27499  total_loss: 28.43  loss_ce: 0  loss_mask: 0.7317  loss_dice: 1.977  loss_seg: 0.6698  loss_ce_0: 0  loss_mask_0: 0.7334  loss_dice_0: 2.064  loss_ce_1: 0  loss_mask_1: 0.7372  loss_dice_1: 1.992  loss_ce_2: 0  loss_mask_2: 0.7352  loss_dice_2: 1.978  loss_ce_3: 0  loss_mask_3: 0.7367  loss_dice_3: 1.972  loss_ce_4: 0  loss_mask_4: 0.7353  loss_dice_4: 1.968  loss_ce_5: 0  loss_mask_5: 0.7378  loss_dice_5: 1.964  loss_ce_6: 0  loss_mask_6: 0.7356  loss_dice_6: 1.971  loss_ce_7: 0  loss_mask_7: 0.7343  loss_dice_7: 1.969  loss_ce_8: 0  loss_mask_8: 0.7359  loss_dice_8: 1.977  time: 1.9131  data_time: 0.0420  lr: 5.7593e-05  max_mem: 6006M
[02/18 15:16:13] d2.utils.events INFO:  eta: 1 day, 2:10:07  iter: 27519  total_loss: 28.67  loss_ce: 0  loss_mask: 0.7395  loss_dice: 2.065  loss_seg: 0.6467  loss_ce_0: 0  loss_mask_0: 0.734  loss_dice_0: 2.134  loss_ce_1: 0  loss_mask_1: 0.7407  loss_dice_1: 2.075  loss_ce_2: 0  loss_mask_2: 0.7449  loss_dice_2: 2.066  loss_ce_3: 0  loss_mask_3: 0.7427  loss_dice_3: 2.051  loss_ce_4: 0  loss_mask_4: 0.7421  loss_dice_4: 2.049  loss_ce_5: 0  loss_mask_5: 0.7466  loss_dice_5: 2.055  loss_ce_6: 0  loss_mask_6: 0.7472  loss_dice_6: 2.051  loss_ce_7: 0  loss_mask_7: 0.7482  loss_dice_7: 2.05  loss_ce_8: 0  loss_mask_8: 0.7444  loss_dice_8: 2.049  time: 1.9129  data_time: 0.0338  lr: 5.7561e-05  max_mem: 6006M
[02/18 15:16:46] d2.utils.events INFO:  eta: 1 day, 1:54:13  iter: 27539  total_loss: 27.18  loss_ce: 0  loss_mask: 0.7178  loss_dice: 1.95  loss_seg: 0.517  loss_ce_0: 0  loss_mask_0: 0.7142  loss_dice_0: 2.043  loss_ce_1: 0  loss_mask_1: 0.7185  loss_dice_1: 1.982  loss_ce_2: 0  loss_mask_2: 0.7249  loss_dice_2: 1.948  loss_ce_3: 0  loss_mask_3: 0.7257  loss_dice_3: 1.933  loss_ce_4: 0  loss_mask_4: 0.7275  loss_dice_4: 1.928  loss_ce_5: 0  loss_mask_5: 0.7307  loss_dice_5: 1.931  loss_ce_6: 0  loss_mask_6: 0.7281  loss_dice_6: 1.936  loss_ce_7: 0  loss_mask_7: 0.7263  loss_dice_7: 1.938  loss_ce_8: 0  loss_mask_8: 0.7257  loss_dice_8: 1.938  time: 1.9127  data_time: 0.0284  lr: 5.7529e-05  max_mem: 6006M
[02/18 15:17:19] d2.utils.events INFO:  eta: 1 day, 1:31:35  iter: 27559  total_loss: 30.73  loss_ce: 0  loss_mask: 0.7527  loss_dice: 2.228  loss_seg: 0.8449  loss_ce_0: 0  loss_mask_0: 0.7765  loss_dice_0: 2.296  loss_ce_1: 0  loss_mask_1: 0.7564  loss_dice_1: 2.236  loss_ce_2: 0  loss_mask_2: 0.7596  loss_dice_2: 2.226  loss_ce_3: 0  loss_mask_3: 0.7564  loss_dice_3: 2.222  loss_ce_4: 0  loss_mask_4: 0.7567  loss_dice_4: 2.223  loss_ce_5: 0  loss_mask_5: 0.7567  loss_dice_5: 2.212  loss_ce_6: 0  loss_mask_6: 0.7563  loss_dice_6: 2.215  loss_ce_7: 0  loss_mask_7: 0.7567  loss_dice_7: 2.216  loss_ce_8: 0  loss_mask_8: 0.755  loss_dice_8: 2.219  time: 1.9125  data_time: 0.0267  lr: 5.7497e-05  max_mem: 6006M
[02/18 15:17:51] d2.utils.events INFO:  eta: 1 day, 0:35:35  iter: 27579  total_loss: 28.46  loss_ce: 0  loss_mask: 0.696  loss_dice: 1.966  loss_seg: 0.993  loss_ce_0: 0  loss_mask_0: 0.7094  loss_dice_0: 2.013  loss_ce_1: 0  loss_mask_1: 0.6987  loss_dice_1: 1.973  loss_ce_2: 0  loss_mask_2: 0.7019  loss_dice_2: 1.959  loss_ce_3: 0  loss_mask_3: 0.7045  loss_dice_3: 1.952  loss_ce_4: 0  loss_mask_4: 0.7056  loss_dice_4: 1.953  loss_ce_5: 0  loss_mask_5: 0.7036  loss_dice_5: 1.956  loss_ce_6: 0  loss_mask_6: 0.7049  loss_dice_6: 1.958  loss_ce_7: 0  loss_mask_7: 0.7049  loss_dice_7: 1.959  loss_ce_8: 0  loss_mask_8: 0.7066  loss_dice_8: 1.957  time: 1.9123  data_time: 0.0313  lr: 5.7466e-05  max_mem: 6006M
[02/18 15:18:23] d2.utils.events INFO:  eta: 23:50:15  iter: 27599  total_loss: 26.65  loss_ce: 0  loss_mask: 0.6896  loss_dice: 1.845  loss_seg: 0.8399  loss_ce_0: 0  loss_mask_0: 0.6967  loss_dice_0: 1.954  loss_ce_1: 0  loss_mask_1: 0.6897  loss_dice_1: 1.86  loss_ce_2: 0  loss_mask_2: 0.6934  loss_dice_2: 1.841  loss_ce_3: 0  loss_mask_3: 0.6949  loss_dice_3: 1.834  loss_ce_4: 0  loss_mask_4: 0.694  loss_dice_4: 1.832  loss_ce_5: 0  loss_mask_5: 0.6948  loss_dice_5: 1.833  loss_ce_6: 0  loss_mask_6: 0.6947  loss_dice_6: 1.833  loss_ce_7: 0  loss_mask_7: 0.6948  loss_dice_7: 1.83  loss_ce_8: 0  loss_mask_8: 0.6954  loss_dice_8: 1.832  time: 1.9121  data_time: 0.0256  lr: 5.7434e-05  max_mem: 6006M
[02/18 15:18:56] d2.utils.events INFO:  eta: 23:10:49  iter: 27619  total_loss: 28.58  loss_ce: 0  loss_mask: 0.7386  loss_dice: 2.015  loss_seg: 0.7431  loss_ce_0: 0  loss_mask_0: 0.745  loss_dice_0: 2.086  loss_ce_1: 0  loss_mask_1: 0.7379  loss_dice_1: 2.026  loss_ce_2: 0  loss_mask_2: 0.74  loss_dice_2: 2.012  loss_ce_3: 0  loss_mask_3: 0.741  loss_dice_3: 2.006  loss_ce_4: 0  loss_mask_4: 0.7386  loss_dice_4: 1.997  loss_ce_5: 0  loss_mask_5: 0.7408  loss_dice_5: 1.999  loss_ce_6: 0  loss_mask_6: 0.7422  loss_dice_6: 1.997  loss_ce_7: 0  loss_mask_7: 0.7387  loss_dice_7: 1.998  loss_ce_8: 0  loss_mask_8: 0.7416  loss_dice_8: 2.002  time: 1.9119  data_time: 0.0282  lr: 5.7402e-05  max_mem: 6006M
[02/18 15:19:30] d2.utils.events INFO:  eta: 21:58:46  iter: 27639  total_loss: 29.22  loss_ce: 0  loss_mask: 0.7596  loss_dice: 2.07  loss_seg: 0.771  loss_ce_0: 0  loss_mask_0: 0.7658  loss_dice_0: 2.146  loss_ce_1: 0  loss_mask_1: 0.7679  loss_dice_1: 2.076  loss_ce_2: 0  loss_mask_2: 0.7649  loss_dice_2: 2.068  loss_ce_3: 0  loss_mask_3: 0.7602  loss_dice_3: 2.057  loss_ce_4: 0  loss_mask_4: 0.7601  loss_dice_4: 2.06  loss_ce_5: 0  loss_mask_5: 0.7612  loss_dice_5: 2.065  loss_ce_6: 0  loss_mask_6: 0.7609  loss_dice_6: 2.055  loss_ce_7: 0  loss_mask_7: 0.7623  loss_dice_7: 2.056  loss_ce_8: 0  loss_mask_8: 0.7593  loss_dice_8: 2.056  time: 1.9117  data_time: 0.0296  lr: 5.737e-05  max_mem: 6006M
[02/18 15:20:01] d2.utils.events INFO:  eta: 20:40:56  iter: 27659  total_loss: 28.23  loss_ce: 0  loss_mask: 0.7421  loss_dice: 2.009  loss_seg: 0.7537  loss_ce_0: 0  loss_mask_0: 0.7563  loss_dice_0: 2.071  loss_ce_1: 0  loss_mask_1: 0.7415  loss_dice_1: 2.014  loss_ce_2: 0  loss_mask_2: 0.7412  loss_dice_2: 2.011  loss_ce_3: 0  loss_mask_3: 0.7453  loss_dice_3: 2  loss_ce_4: 0  loss_mask_4: 0.7444  loss_dice_4: 2.002  loss_ce_5: 0  loss_mask_5: 0.7423  loss_dice_5: 2  loss_ce_6: 0  loss_mask_6: 0.7496  loss_dice_6: 1.995  loss_ce_7: 0  loss_mask_7: 0.7497  loss_dice_7: 1.995  loss_ce_8: 0  loss_mask_8: 0.7507  loss_dice_8: 1.998  time: 1.9115  data_time: 0.0243  lr: 5.7338e-05  max_mem: 6006M
[02/18 15:20:35] d2.utils.events INFO:  eta: 19:28:51  iter: 27679  total_loss: 29.42  loss_ce: 0  loss_mask: 0.7312  loss_dice: 2.102  loss_seg: 0.6482  loss_ce_0: 0  loss_mask_0: 0.7438  loss_dice_0: 2.176  loss_ce_1: 0  loss_mask_1: 0.7367  loss_dice_1: 2.124  loss_ce_2: 0  loss_mask_2: 0.7354  loss_dice_2: 2.105  loss_ce_3: 0  loss_mask_3: 0.7358  loss_dice_3: 2.098  loss_ce_4: 0  loss_mask_4: 0.7333  loss_dice_4: 2.1  loss_ce_5: 0  loss_mask_5: 0.7336  loss_dice_5: 2.098  loss_ce_6: 0  loss_mask_6: 0.7365  loss_dice_6: 2.091  loss_ce_7: 0  loss_mask_7: 0.7337  loss_dice_7: 2.096  loss_ce_8: 0  loss_mask_8: 0.7353  loss_dice_8: 2.096  time: 1.9113  data_time: 0.0336  lr: 5.7306e-05  max_mem: 6006M
[02/18 15:21:09] d2.utils.events INFO:  eta: 18:16:10  iter: 27699  total_loss: 28.62  loss_ce: 0  loss_mask: 0.7538  loss_dice: 2.02  loss_seg: 0.8288  loss_ce_0: 0  loss_mask_0: 0.7643  loss_dice_0: 2.102  loss_ce_1: 0  loss_mask_1: 0.752  loss_dice_1: 2.035  loss_ce_2: 0  loss_mask_2: 0.7589  loss_dice_2: 2.014  loss_ce_3: 0  loss_mask_3: 0.7616  loss_dice_3: 2  loss_ce_4: 0  loss_mask_4: 0.7625  loss_dice_4: 2.002  loss_ce_5: 0  loss_mask_5: 0.7566  loss_dice_5: 2.004  loss_ce_6: 0  loss_mask_6: 0.7596  loss_dice_6: 2.006  loss_ce_7: 0  loss_mask_7: 0.7602  loss_dice_7: 2.006  loss_ce_8: 0  loss_mask_8: 0.7581  loss_dice_8: 2.004  time: 1.9111  data_time: 0.0315  lr: 5.7274e-05  max_mem: 6006M
[02/18 15:21:40] d2.utils.events INFO:  eta: 18:03:57  iter: 27719  total_loss: 29.58  loss_ce: 0  loss_mask: 0.7648  loss_dice: 2.103  loss_seg: 0.7031  loss_ce_0: 0  loss_mask_0: 0.7859  loss_dice_0: 2.155  loss_ce_1: 0  loss_mask_1: 0.7703  loss_dice_1: 2.117  loss_ce_2: 0  loss_mask_2: 0.7629  loss_dice_2: 2.093  loss_ce_3: 0  loss_mask_3: 0.7649  loss_dice_3: 2.088  loss_ce_4: 0  loss_mask_4: 0.7649  loss_dice_4: 2.088  loss_ce_5: 0  loss_mask_5: 0.7642  loss_dice_5: 2.089  loss_ce_6: 0  loss_mask_6: 0.7646  loss_dice_6: 2.083  loss_ce_7: 0  loss_mask_7: 0.7685  loss_dice_7: 2.089  loss_ce_8: 0  loss_mask_8: 0.7673  loss_dice_8: 2.086  time: 1.9109  data_time: 0.0362  lr: 5.7242e-05  max_mem: 6006M
[02/18 15:22:12] d2.utils.events INFO:  eta: 18:03:17  iter: 27739  total_loss: 28.37  loss_ce: 0  loss_mask: 0.7319  loss_dice: 1.96  loss_seg: 0.6546  loss_ce_0: 0  loss_mask_0: 0.7315  loss_dice_0: 2.061  loss_ce_1: 0  loss_mask_1: 0.7271  loss_dice_1: 1.964  loss_ce_2: 0  loss_mask_2: 0.7237  loss_dice_2: 1.965  loss_ce_3: 0  loss_mask_3: 0.7262  loss_dice_3: 1.949  loss_ce_4: 0  loss_mask_4: 0.7289  loss_dice_4: 1.946  loss_ce_5: 0  loss_mask_5: 0.729  loss_dice_5: 1.947  loss_ce_6: 0  loss_mask_6: 0.7299  loss_dice_6: 1.944  loss_ce_7: 0  loss_mask_7: 0.7304  loss_dice_7: 1.95  loss_ce_8: 0  loss_mask_8: 0.7307  loss_dice_8: 1.95  time: 1.9106  data_time: 0.0317  lr: 5.721e-05  max_mem: 6006M
[02/18 15:22:43] d2.utils.events INFO:  eta: 17:59:28  iter: 27759  total_loss: 26.7  loss_ce: 0  loss_mask: 0.6987  loss_dice: 1.872  loss_seg: 0.4625  loss_ce_0: 0  loss_mask_0: 0.7139  loss_dice_0: 1.967  loss_ce_1: 0  loss_mask_1: 0.7076  loss_dice_1: 1.885  loss_ce_2: 0  loss_mask_2: 0.7094  loss_dice_2: 1.873  loss_ce_3: 0  loss_mask_3: 0.7081  loss_dice_3: 1.878  loss_ce_4: 0  loss_mask_4: 0.7067  loss_dice_4: 1.876  loss_ce_5: 0  loss_mask_5: 0.7056  loss_dice_5: 1.876  loss_ce_6: 0  loss_mask_6: 0.7033  loss_dice_6: 1.874  loss_ce_7: 0  loss_mask_7: 0.7067  loss_dice_7: 1.87  loss_ce_8: 0  loss_mask_8: 0.7041  loss_dice_8: 1.865  time: 1.9104  data_time: 0.0316  lr: 5.7178e-05  max_mem: 6006M
[02/18 15:23:14] d2.utils.events INFO:  eta: 17:57:06  iter: 27779  total_loss: 29.06  loss_ce: 0  loss_mask: 0.7451  loss_dice: 2.078  loss_seg: 0.813  loss_ce_0: 0  loss_mask_0: 0.7626  loss_dice_0: 2.143  loss_ce_1: 0  loss_mask_1: 0.746  loss_dice_1: 2.084  loss_ce_2: 0  loss_mask_2: 0.7501  loss_dice_2: 2.07  loss_ce_3: 0  loss_mask_3: 0.7464  loss_dice_3: 2.064  loss_ce_4: 0  loss_mask_4: 0.749  loss_dice_4: 2.061  loss_ce_5: 0  loss_mask_5: 0.7464  loss_dice_5: 2.06  loss_ce_6: 0  loss_mask_6: 0.7457  loss_dice_6: 2.061  loss_ce_7: 0  loss_mask_7: 0.7468  loss_dice_7: 2.06  loss_ce_8: 0  loss_mask_8: 0.7473  loss_dice_8: 2.059  time: 1.9101  data_time: 0.0326  lr: 5.7146e-05  max_mem: 6006M
[02/18 15:23:45] d2.utils.events INFO:  eta: 17:53:09  iter: 27799  total_loss: 27.37  loss_ce: 0  loss_mask: 0.7305  loss_dice: 1.921  loss_seg: 0.6566  loss_ce_0: 0  loss_mask_0: 0.7376  loss_dice_0: 1.984  loss_ce_1: 0  loss_mask_1: 0.7419  loss_dice_1: 1.925  loss_ce_2: 0  loss_mask_2: 0.74  loss_dice_2: 1.906  loss_ce_3: 0  loss_mask_3: 0.7422  loss_dice_3: 1.901  loss_ce_4: 0  loss_mask_4: 0.7432  loss_dice_4: 1.902  loss_ce_5: 0  loss_mask_5: 0.7406  loss_dice_5: 1.9  loss_ce_6: 0  loss_mask_6: 0.7395  loss_dice_6: 1.906  loss_ce_7: 0  loss_mask_7: 0.7416  loss_dice_7: 1.903  loss_ce_8: 0  loss_mask_8: 0.7384  loss_dice_8: 1.909  time: 1.9099  data_time: 0.0293  lr: 5.7114e-05  max_mem: 6006M
[02/18 15:24:19] d2.utils.events INFO:  eta: 17:50:07  iter: 27819  total_loss: 27.87  loss_ce: 0  loss_mask: 0.6779  loss_dice: 1.954  loss_seg: 1  loss_ce_0: 0  loss_mask_0: 0.688  loss_dice_0: 2.014  loss_ce_1: 0  loss_mask_1: 0.6833  loss_dice_1: 1.971  loss_ce_2: 0  loss_mask_2: 0.6839  loss_dice_2: 1.952  loss_ce_3: 0  loss_mask_3: 0.6846  loss_dice_3: 1.946  loss_ce_4: 0  loss_mask_4: 0.6818  loss_dice_4: 1.946  loss_ce_5: 0  loss_mask_5: 0.6804  loss_dice_5: 1.951  loss_ce_6: 0  loss_mask_6: 0.6802  loss_dice_6: 1.95  loss_ce_7: 0  loss_mask_7: 0.6782  loss_dice_7: 1.952  loss_ce_8: 0  loss_mask_8: 0.6777  loss_dice_8: 1.944  time: 1.9097  data_time: 0.0312  lr: 5.7083e-05  max_mem: 6006M
[02/18 15:24:54] d2.utils.events INFO:  eta: 17:33:24  iter: 27839  total_loss: 28.07  loss_ce: 0  loss_mask: 0.7244  loss_dice: 1.957  loss_seg: 0.8638  loss_ce_0: 0  loss_mask_0: 0.7517  loss_dice_0: 2.029  loss_ce_1: 0  loss_mask_1: 0.7317  loss_dice_1: 1.978  loss_ce_2: 0  loss_mask_2: 0.7311  loss_dice_2: 1.963  loss_ce_3: 0  loss_mask_3: 0.7302  loss_dice_3: 1.953  loss_ce_4: 0  loss_mask_4: 0.7276  loss_dice_4: 1.951  loss_ce_5: 0  loss_mask_5: 0.7283  loss_dice_5: 1.955  loss_ce_6: 0  loss_mask_6: 0.725  loss_dice_6: 1.95  loss_ce_7: 0  loss_mask_7: 0.7261  loss_dice_7: 1.952  loss_ce_8: 0  loss_mask_8: 0.7277  loss_dice_8: 1.949  time: 1.9096  data_time: 0.0385  lr: 5.7051e-05  max_mem: 6006M
[02/18 15:25:28] d2.utils.events INFO:  eta: 17:04:10  iter: 27859  total_loss: 29.29  loss_ce: 0  loss_mask: 0.7583  loss_dice: 2.039  loss_seg: 0.6895  loss_ce_0: 0  loss_mask_0: 0.7513  loss_dice_0: 2.096  loss_ce_1: 0  loss_mask_1: 0.7588  loss_dice_1: 2.043  loss_ce_2: 0  loss_mask_2: 0.762  loss_dice_2: 2.03  loss_ce_3: 0  loss_mask_3: 0.7633  loss_dice_3: 2.019  loss_ce_4: 0  loss_mask_4: 0.7574  loss_dice_4: 2.022  loss_ce_5: 0  loss_mask_5: 0.7563  loss_dice_5: 2.022  loss_ce_6: 0  loss_mask_6: 0.7593  loss_dice_6: 2.026  loss_ce_7: 0  loss_mask_7: 0.7595  loss_dice_7: 2.029  loss_ce_8: 0  loss_mask_8: 0.7562  loss_dice_8: 2.031  time: 1.9094  data_time: 0.0266  lr: 5.7019e-05  max_mem: 6006M
[02/18 15:25:59] d2.utils.events INFO:  eta: 16:43:23  iter: 27879  total_loss: 28.9  loss_ce: 0  loss_mask: 0.7254  loss_dice: 2.04  loss_seg: 0.6769  loss_ce_0: 0  loss_mask_0: 0.7248  loss_dice_0: 2.095  loss_ce_1: 0  loss_mask_1: 0.7231  loss_dice_1: 2.039  loss_ce_2: 0  loss_mask_2: 0.7277  loss_dice_2: 2.038  loss_ce_3: 0  loss_mask_3: 0.726  loss_dice_3: 2.029  loss_ce_4: 0  loss_mask_4: 0.7298  loss_dice_4: 2.029  loss_ce_5: 0  loss_mask_5: 0.7308  loss_dice_5: 2.023  loss_ce_6: 0  loss_mask_6: 0.7316  loss_dice_6: 2.023  loss_ce_7: 0  loss_mask_7: 0.7308  loss_dice_7: 2.03  loss_ce_8: 0  loss_mask_8: 0.728  loss_dice_8: 2.028  time: 1.9092  data_time: 0.0377  lr: 5.6987e-05  max_mem: 6006M
[02/18 15:26:30] d2.utils.events INFO:  eta: 16:21:27  iter: 27899  total_loss: 28.79  loss_ce: 0  loss_mask: 0.7331  loss_dice: 2.037  loss_seg: 0.6135  loss_ce_0: 0  loss_mask_0: 0.7363  loss_dice_0: 2.106  loss_ce_1: 0  loss_mask_1: 0.7366  loss_dice_1: 2.052  loss_ce_2: 0  loss_mask_2: 0.733  loss_dice_2: 2.039  loss_ce_3: 0  loss_mask_3: 0.74  loss_dice_3: 2.035  loss_ce_4: 0  loss_mask_4: 0.7437  loss_dice_4: 2.033  loss_ce_5: 0  loss_mask_5: 0.7437  loss_dice_5: 2.032  loss_ce_6: 0  loss_mask_6: 0.7452  loss_dice_6: 2.028  loss_ce_7: 0  loss_mask_7: 0.7452  loss_dice_7: 2.03  loss_ce_8: 0  loss_mask_8: 0.7437  loss_dice_8: 2.027  time: 1.9089  data_time: 0.0371  lr: 5.6955e-05  max_mem: 6006M
[02/18 15:27:03] d2.utils.events INFO:  eta: 16:14:52  iter: 27919  total_loss: 29.44  loss_ce: 0  loss_mask: 0.7586  loss_dice: 2.123  loss_seg: 0.5669  loss_ce_0: 0  loss_mask_0: 0.7697  loss_dice_0: 2.217  loss_ce_1: 0  loss_mask_1: 0.7634  loss_dice_1: 2.149  loss_ce_2: 0  loss_mask_2: 0.7647  loss_dice_2: 2.132  loss_ce_3: 0  loss_mask_3: 0.76  loss_dice_3: 2.126  loss_ce_4: 0  loss_mask_4: 0.7615  loss_dice_4: 2.125  loss_ce_5: 0  loss_mask_5: 0.761  loss_dice_5: 2.122  loss_ce_6: 0  loss_mask_6: 0.7606  loss_dice_6: 2.118  loss_ce_7: 0  loss_mask_7: 0.7664  loss_dice_7: 2.123  loss_ce_8: 0  loss_mask_8: 0.7651  loss_dice_8: 2.12  time: 1.9087  data_time: 0.0368  lr: 5.6923e-05  max_mem: 6006M
[02/18 15:27:36] d2.utils.events INFO:  eta: 16:23:41  iter: 27939  total_loss: 29.1  loss_ce: 0  loss_mask: 0.7686  loss_dice: 2.079  loss_seg: 0.6365  loss_ce_0: 0  loss_mask_0: 0.7768  loss_dice_0: 2.128  loss_ce_1: 0  loss_mask_1: 0.7712  loss_dice_1: 2.096  loss_ce_2: 0  loss_mask_2: 0.7698  loss_dice_2: 2.078  loss_ce_3: 0  loss_mask_3: 0.776  loss_dice_3: 2.063  loss_ce_4: 0  loss_mask_4: 0.7745  loss_dice_4: 2.058  loss_ce_5: 0  loss_mask_5: 0.7723  loss_dice_5: 2.066  loss_ce_6: 0  loss_mask_6: 0.7751  loss_dice_6: 2.062  loss_ce_7: 0  loss_mask_7: 0.7729  loss_dice_7: 2.056  loss_ce_8: 0  loss_mask_8: 0.773  loss_dice_8: 2.065  time: 1.9086  data_time: 0.0346  lr: 5.6891e-05  max_mem: 6006M
[02/18 15:28:40] d2.utils.events INFO:  eta: 16:42:28  iter: 27959  total_loss: 26.61  loss_ce: 0  loss_mask: 0.6945  loss_dice: 1.891  loss_seg: 0.59  loss_ce_0: 0  loss_mask_0: 0.7106  loss_dice_0: 1.964  loss_ce_1: 0  loss_mask_1: 0.7055  loss_dice_1: 1.899  loss_ce_2: 0  loss_mask_2: 0.705  loss_dice_2: 1.882  loss_ce_3: 0  loss_mask_3: 0.7031  loss_dice_3: 1.881  loss_ce_4: 0  loss_mask_4: 0.7029  loss_dice_4: 1.877  loss_ce_5: 0  loss_mask_5: 0.7034  loss_dice_5: 1.882  loss_ce_6: 0  loss_mask_6: 0.6988  loss_dice_6: 1.884  loss_ce_7: 0  loss_mask_7: 0.6995  loss_dice_7: 1.879  loss_ce_8: 0  loss_mask_8: 0.6993  loss_dice_8: 1.881  time: 1.9095  data_time: 0.0368  lr: 5.6859e-05  max_mem: 6006M
[02/18 15:29:44] d2.utils.events INFO:  eta: 17:08:29  iter: 27979  total_loss: 28.79  loss_ce: 0  loss_mask: 0.7387  loss_dice: 2.012  loss_seg: 0.6027  loss_ce_0: 0  loss_mask_0: 0.7473  loss_dice_0: 2.078  loss_ce_1: 0  loss_mask_1: 0.7446  loss_dice_1: 2.03  loss_ce_2: 0  loss_mask_2: 0.744  loss_dice_2: 2.011  loss_ce_3: 0  loss_mask_3: 0.7413  loss_dice_3: 2.002  loss_ce_4: 0  loss_mask_4: 0.7435  loss_dice_4: 2.001  loss_ce_5: 0  loss_mask_5: 0.7436  loss_dice_5: 1.999  loss_ce_6: 0  loss_mask_6: 0.7417  loss_dice_6: 1.992  loss_ce_7: 0  loss_mask_7: 0.7431  loss_dice_7: 1.996  loss_ce_8: 0  loss_mask_8: 0.7388  loss_dice_8: 1.999  time: 1.9104  data_time: 0.0299  lr: 5.6827e-05  max_mem: 6006M
[02/18 15:30:52] d2.utils.events INFO:  eta: 17:34:26  iter: 27999  total_loss: 28.45  loss_ce: 0  loss_mask: 0.7253  loss_dice: 2.007  loss_seg: 0.8631  loss_ce_0: 0  loss_mask_0: 0.7337  loss_dice_0: 2.071  loss_ce_1: 0  loss_mask_1: 0.7247  loss_dice_1: 2.018  loss_ce_2: 0  loss_mask_2: 0.7254  loss_dice_2: 2.003  loss_ce_3: 0  loss_mask_3: 0.7276  loss_dice_3: 1.994  loss_ce_4: 0  loss_mask_4: 0.7299  loss_dice_4: 2.004  loss_ce_5: 0  loss_mask_5: 0.7308  loss_dice_5: 2  loss_ce_6: 0  loss_mask_6: 0.7278  loss_dice_6: 2  loss_ce_7: 0  loss_mask_7: 0.7263  loss_dice_7: 2.002  loss_ce_8: 0  loss_mask_8: 0.7314  loss_dice_8: 2.001  time: 1.9115  data_time: 0.0252  lr: 5.6795e-05  max_mem: 6006M
[02/18 15:32:03] d2.utils.events INFO:  eta: 17:57:32  iter: 28019  total_loss: 29.23  loss_ce: 0  loss_mask: 0.7658  loss_dice: 2.038  loss_seg: 0.635  loss_ce_0: 0  loss_mask_0: 0.7724  loss_dice_0: 2.099  loss_ce_1: 0  loss_mask_1: 0.7735  loss_dice_1: 2.049  loss_ce_2: 0  loss_mask_2: 0.7754  loss_dice_2: 2.043  loss_ce_3: 0  loss_mask_3: 0.7776  loss_dice_3: 2.039  loss_ce_4: 0  loss_mask_4: 0.7757  loss_dice_4: 2.035  loss_ce_5: 0  loss_mask_5: 0.7742  loss_dice_5: 2.034  loss_ce_6: 0  loss_mask_6: 0.775  loss_dice_6: 2.041  loss_ce_7: 0  loss_mask_7: 0.7735  loss_dice_7: 2.029  loss_ce_8: 0  loss_mask_8: 0.7748  loss_dice_8: 2.029  time: 1.9126  data_time: 0.0310  lr: 5.6763e-05  max_mem: 6006M
[02/18 15:33:05] d2.utils.events INFO:  eta: 18:05:39  iter: 28039  total_loss: 28.34  loss_ce: 0  loss_mask: 0.7388  loss_dice: 2.016  loss_seg: 0.6775  loss_ce_0: 0  loss_mask_0: 0.7456  loss_dice_0: 2.085  loss_ce_1: 0  loss_mask_1: 0.742  loss_dice_1: 2.029  loss_ce_2: 0  loss_mask_2: 0.7378  loss_dice_2: 2.018  loss_ce_3: 0  loss_mask_3: 0.7376  loss_dice_3: 2.003  loss_ce_4: 0  loss_mask_4: 0.7404  loss_dice_4: 2.003  loss_ce_5: 0  loss_mask_5: 0.7358  loss_dice_5: 2.009  loss_ce_6: 0  loss_mask_6: 0.7363  loss_dice_6: 2.006  loss_ce_7: 0  loss_mask_7: 0.7361  loss_dice_7: 2.014  loss_ce_8: 0  loss_mask_8: 0.7382  loss_dice_8: 2.008  time: 1.9135  data_time: 0.0349  lr: 5.6731e-05  max_mem: 6006M
[02/18 15:34:17] d2.utils.events INFO:  eta: 18:05:26  iter: 28059  total_loss: 29.31  loss_ce: 0  loss_mask: 0.7599  loss_dice: 2.062  loss_seg: 0.8367  loss_ce_0: 0  loss_mask_0: 0.7752  loss_dice_0: 2.111  loss_ce_1: 0  loss_mask_1: 0.7648  loss_dice_1: 2.084  loss_ce_2: 0  loss_mask_2: 0.762  loss_dice_2: 2.062  loss_ce_3: 0  loss_mask_3: 0.76  loss_dice_3: 2.054  loss_ce_4: 0  loss_mask_4: 0.7611  loss_dice_4: 2.063  loss_ce_5: 0  loss_mask_5: 0.758  loss_dice_5: 2.061  loss_ce_6: 0  loss_mask_6: 0.7591  loss_dice_6: 2.051  loss_ce_7: 0  loss_mask_7: 0.76  loss_dice_7: 2.05  loss_ce_8: 0  loss_mask_8: 0.7621  loss_dice_8: 2.053  time: 1.9147  data_time: 0.0313  lr: 5.6699e-05  max_mem: 6006M
[02/18 15:35:28] d2.utils.events INFO:  eta: 18:06:54  iter: 28079  total_loss: 29.13  loss_ce: 0  loss_mask: 0.7414  loss_dice: 2.012  loss_seg: 0.8225  loss_ce_0: 0  loss_mask_0: 0.7415  loss_dice_0: 2.076  loss_ce_1: 0  loss_mask_1: 0.7379  loss_dice_1: 2.026  loss_ce_2: 0  loss_mask_2: 0.7407  loss_dice_2: 2.007  loss_ce_3: 0  loss_mask_3: 0.7421  loss_dice_3: 1.994  loss_ce_4: 0  loss_mask_4: 0.7432  loss_dice_4: 2.002  loss_ce_5: 0  loss_mask_5: 0.7407  loss_dice_5: 2.007  loss_ce_6: 0  loss_mask_6: 0.7417  loss_dice_6: 2.009  loss_ce_7: 0  loss_mask_7: 0.7403  loss_dice_7: 2.002  loss_ce_8: 0  loss_mask_8: 0.7394  loss_dice_8: 2.002  time: 1.9158  data_time: 0.0323  lr: 5.6667e-05  max_mem: 6006M
[02/18 15:36:36] d2.utils.events INFO:  eta: 18:08:06  iter: 28099  total_loss: 29.36  loss_ce: 0  loss_mask: 0.7667  loss_dice: 2.082  loss_seg: 0.6166  loss_ce_0: 0  loss_mask_0: 0.7772  loss_dice_0: 2.139  loss_ce_1: 0  loss_mask_1: 0.7688  loss_dice_1: 2.101  loss_ce_2: 0  loss_mask_2: 0.7692  loss_dice_2: 2.089  loss_ce_3: 0  loss_mask_3: 0.7728  loss_dice_3: 2.071  loss_ce_4: 0  loss_mask_4: 0.773  loss_dice_4: 2.074  loss_ce_5: 0  loss_mask_5: 0.7688  loss_dice_5: 2.078  loss_ce_6: 0  loss_mask_6: 0.7699  loss_dice_6: 2.072  loss_ce_7: 0  loss_mask_7: 0.7714  loss_dice_7: 2.075  loss_ce_8: 0  loss_mask_8: 0.7684  loss_dice_8: 2.07  time: 1.9169  data_time: 0.0388  lr: 5.6635e-05  max_mem: 6006M
[02/18 15:37:31] d2.utils.events INFO:  eta: 18:17:18  iter: 28119  total_loss: 28.21  loss_ce: 0  loss_mask: 0.7506  loss_dice: 1.957  loss_seg: 0.6055  loss_ce_0: 0  loss_mask_0: 0.7594  loss_dice_0: 2.02  loss_ce_1: 0  loss_mask_1: 0.756  loss_dice_1: 1.971  loss_ce_2: 0  loss_mask_2: 0.7506  loss_dice_2: 1.956  loss_ce_3: 0  loss_mask_3: 0.7462  loss_dice_3: 1.951  loss_ce_4: 0  loss_mask_4: 0.7483  loss_dice_4: 1.953  loss_ce_5: 0  loss_mask_5: 0.7459  loss_dice_5: 1.953  loss_ce_6: 0  loss_mask_6: 0.7506  loss_dice_6: 1.952  loss_ce_7: 0  loss_mask_7: 0.7517  loss_dice_7: 1.958  loss_ce_8: 0  loss_mask_8: 0.7491  loss_dice_8: 1.957  time: 1.9174  data_time: 0.0291  lr: 5.6603e-05  max_mem: 6006M
[02/18 15:38:03] d2.utils.events INFO:  eta: 18:19:13  iter: 28139  total_loss: 27.7  loss_ce: 0  loss_mask: 0.7511  loss_dice: 1.958  loss_seg: 0.7462  loss_ce_0: 0  loss_mask_0: 0.7709  loss_dice_0: 2.029  loss_ce_1: 0  loss_mask_1: 0.7583  loss_dice_1: 1.981  loss_ce_2: 0  loss_mask_2: 0.7529  loss_dice_2: 1.96  loss_ce_3: 0  loss_mask_3: 0.7551  loss_dice_3: 1.955  loss_ce_4: 0  loss_mask_4: 0.7559  loss_dice_4: 1.956  loss_ce_5: 0  loss_mask_5: 0.7548  loss_dice_5: 1.952  loss_ce_6: 0  loss_mask_6: 0.7541  loss_dice_6: 1.951  loss_ce_7: 0  loss_mask_7: 0.7549  loss_dice_7: 1.952  loss_ce_8: 0  loss_mask_8: 0.7582  loss_dice_8: 1.95  time: 1.9172  data_time: 0.0315  lr: 5.6571e-05  max_mem: 6006M
[02/18 15:38:36] d2.utils.events INFO:  eta: 17:44:24  iter: 28159  total_loss: 28.66  loss_ce: 0  loss_mask: 0.7266  loss_dice: 2.073  loss_seg: 0.8109  loss_ce_0: 0  loss_mask_0: 0.7421  loss_dice_0: 2.125  loss_ce_1: 0  loss_mask_1: 0.7377  loss_dice_1: 2.083  loss_ce_2: 0  loss_mask_2: 0.7345  loss_dice_2: 2.067  loss_ce_3: 0  loss_mask_3: 0.7266  loss_dice_3: 2.064  loss_ce_4: 0  loss_mask_4: 0.7252  loss_dice_4: 2.065  loss_ce_5: 0  loss_mask_5: 0.7285  loss_dice_5: 2.065  loss_ce_6: 0  loss_mask_6: 0.7285  loss_dice_6: 2.058  loss_ce_7: 0  loss_mask_7: 0.7268  loss_dice_7: 2.062  loss_ce_8: 0  loss_mask_8: 0.728  loss_dice_8: 2.062  time: 1.9170  data_time: 0.0280  lr: 5.6539e-05  max_mem: 6006M
[02/18 15:39:21] d2.utils.events INFO:  eta: 17:30:07  iter: 28179  total_loss: 27.05  loss_ce: 0  loss_mask: 0.7138  loss_dice: 1.91  loss_seg: 0.6601  loss_ce_0: 0  loss_mask_0: 0.7271  loss_dice_0: 1.984  loss_ce_1: 0  loss_mask_1: 0.7226  loss_dice_1: 1.91  loss_ce_2: 0  loss_mask_2: 0.7233  loss_dice_2: 1.904  loss_ce_3: 0  loss_mask_3: 0.7181  loss_dice_3: 1.898  loss_ce_4: 0  loss_mask_4: 0.7202  loss_dice_4: 1.894  loss_ce_5: 0  loss_mask_5: 0.7205  loss_dice_5: 1.895  loss_ce_6: 0  loss_mask_6: 0.7178  loss_dice_6: 1.9  loss_ce_7: 0  loss_mask_7: 0.7213  loss_dice_7: 1.894  loss_ce_8: 0  loss_mask_8: 0.7192  loss_dice_8: 1.9  time: 1.9173  data_time: 0.0402  lr: 5.6508e-05  max_mem: 6006M
[02/18 15:40:28] d2.utils.events INFO:  eta: 17:29:28  iter: 28199  total_loss: 27.39  loss_ce: 0  loss_mask: 0.6946  loss_dice: 1.935  loss_seg: 0.5546  loss_ce_0: 0  loss_mask_0: 0.711  loss_dice_0: 2.008  loss_ce_1: 0  loss_mask_1: 0.7043  loss_dice_1: 1.949  loss_ce_2: 0  loss_mask_2: 0.7002  loss_dice_2: 1.947  loss_ce_3: 0  loss_mask_3: 0.6985  loss_dice_3: 1.926  loss_ce_4: 0  loss_mask_4: 0.698  loss_dice_4: 1.927  loss_ce_5: 0  loss_mask_5: 0.6963  loss_dice_5: 1.922  loss_ce_6: 0  loss_mask_6: 0.6997  loss_dice_6: 1.92  loss_ce_7: 0  loss_mask_7: 0.7001  loss_dice_7: 1.924  loss_ce_8: 0  loss_mask_8: 0.6997  loss_dice_8: 1.923  time: 1.9183  data_time: 0.0382  lr: 5.6476e-05  max_mem: 6006M
[02/18 15:41:34] d2.utils.events INFO:  eta: 17:28:29  iter: 28219  total_loss: 29.86  loss_ce: 0  loss_mask: 0.7172  loss_dice: 2.087  loss_seg: 1.08  loss_ce_0: 0  loss_mask_0: 0.7264  loss_dice_0: 2.156  loss_ce_1: 0  loss_mask_1: 0.7223  loss_dice_1: 2.105  loss_ce_2: 0  loss_mask_2: 0.7217  loss_dice_2: 2.093  loss_ce_3: 0  loss_mask_3: 0.7233  loss_dice_3: 2.086  loss_ce_4: 0  loss_mask_4: 0.7243  loss_dice_4: 2.081  loss_ce_5: 0  loss_mask_5: 0.7246  loss_dice_5: 2.087  loss_ce_6: 0  loss_mask_6: 0.7226  loss_dice_6: 2.084  loss_ce_7: 0  loss_mask_7: 0.7202  loss_dice_7: 2.076  loss_ce_8: 0  loss_mask_8: 0.7234  loss_dice_8: 2.086  time: 1.9193  data_time: 0.0387  lr: 5.6444e-05  max_mem: 6006M
[02/18 15:42:40] d2.utils.events INFO:  eta: 17:27:49  iter: 28239  total_loss: 27.96  loss_ce: 0  loss_mask: 0.7447  loss_dice: 1.972  loss_seg: 0.6702  loss_ce_0: 0  loss_mask_0: 0.7569  loss_dice_0: 2.037  loss_ce_1: 0  loss_mask_1: 0.7463  loss_dice_1: 1.976  loss_ce_2: 0  loss_mask_2: 0.7506  loss_dice_2: 1.976  loss_ce_3: 0  loss_mask_3: 0.7476  loss_dice_3: 1.965  loss_ce_4: 0  loss_mask_4: 0.7465  loss_dice_4: 1.965  loss_ce_5: 0  loss_mask_5: 0.7464  loss_dice_5: 1.964  loss_ce_6: 0  loss_mask_6: 0.7484  loss_dice_6: 1.961  loss_ce_7: 0  loss_mask_7: 0.75  loss_dice_7: 1.965  loss_ce_8: 0  loss_mask_8: 0.7491  loss_dice_8: 1.968  time: 1.9203  data_time: 0.0317  lr: 5.6412e-05  max_mem: 6006M
[02/18 15:43:50] d2.utils.events INFO:  eta: 17:30:08  iter: 28259  total_loss: 26.16  loss_ce: 0  loss_mask: 0.7165  loss_dice: 1.839  loss_seg: 0.5597  loss_ce_0: 0  loss_mask_0: 0.724  loss_dice_0: 1.922  loss_ce_1: 0  loss_mask_1: 0.7196  loss_dice_1: 1.857  loss_ce_2: 0  loss_mask_2: 0.7182  loss_dice_2: 1.838  loss_ce_3: 0  loss_mask_3: 0.7231  loss_dice_3: 1.824  loss_ce_4: 0  loss_mask_4: 0.7184  loss_dice_4: 1.825  loss_ce_5: 0  loss_mask_5: 0.7195  loss_dice_5: 1.83  loss_ce_6: 0  loss_mask_6: 0.7199  loss_dice_6: 1.822  loss_ce_7: 0  loss_mask_7: 0.7208  loss_dice_7: 1.829  loss_ce_8: 0  loss_mask_8: 0.7199  loss_dice_8: 1.828  time: 1.9214  data_time: 0.0320  lr: 5.638e-05  max_mem: 6006M
[02/18 15:45:01] d2.utils.events INFO:  eta: 18:00:05  iter: 28279  total_loss: 28.89  loss_ce: 0  loss_mask: 0.7181  loss_dice: 2.027  loss_seg: 0.7587  loss_ce_0: 0  loss_mask_0: 0.7064  loss_dice_0: 2.12  loss_ce_1: 0  loss_mask_1: 0.7128  loss_dice_1: 2.052  loss_ce_2: 0  loss_mask_2: 0.7179  loss_dice_2: 2.034  loss_ce_3: 0  loss_mask_3: 0.7195  loss_dice_3: 2.02  loss_ce_4: 0  loss_mask_4: 0.7214  loss_dice_4: 2.017  loss_ce_5: 0  loss_mask_5: 0.7216  loss_dice_5: 2.018  loss_ce_6: 0  loss_mask_6: 0.7238  loss_dice_6: 2.013  loss_ce_7: 0  loss_mask_7: 0.724  loss_dice_7: 2.019  loss_ce_8: 0  loss_mask_8: 0.7218  loss_dice_8: 2.016  time: 1.9225  data_time: 0.0327  lr: 5.6348e-05  max_mem: 6006M
[02/18 15:46:10] d2.utils.events INFO:  eta: 19:01:00  iter: 28299  total_loss: 29.17  loss_ce: 0  loss_mask: 0.7316  loss_dice: 2.024  loss_seg: 0.6878  loss_ce_0: 0  loss_mask_0: 0.739  loss_dice_0: 2.093  loss_ce_1: 0  loss_mask_1: 0.7364  loss_dice_1: 2.036  loss_ce_2: 0  loss_mask_2: 0.7384  loss_dice_2: 2.017  loss_ce_3: 0  loss_mask_3: 0.7367  loss_dice_3: 2.013  loss_ce_4: 0  loss_mask_4: 0.7336  loss_dice_4: 2.012  loss_ce_5: 0  loss_mask_5: 0.7354  loss_dice_5: 2.009  loss_ce_6: 0  loss_mask_6: 0.7372  loss_dice_6: 2.01  loss_ce_7: 0  loss_mask_7: 0.7355  loss_dice_7: 2.008  loss_ce_8: 0  loss_mask_8: 0.7353  loss_dice_8: 2.012  time: 1.9236  data_time: 0.0262  lr: 5.6316e-05  max_mem: 6006M
[02/18 15:47:14] d2.utils.events INFO:  eta: 19:02:28  iter: 28319  total_loss: 27.84  loss_ce: 0  loss_mask: 0.7296  loss_dice: 1.964  loss_seg: 0.4228  loss_ce_0: 0  loss_mask_0: 0.7302  loss_dice_0: 2.02  loss_ce_1: 0  loss_mask_1: 0.7363  loss_dice_1: 1.978  loss_ce_2: 0  loss_mask_2: 0.7351  loss_dice_2: 1.962  loss_ce_3: 0  loss_mask_3: 0.7331  loss_dice_3: 1.959  loss_ce_4: 0  loss_mask_4: 0.7279  loss_dice_4: 1.965  loss_ce_5: 0  loss_mask_5: 0.728  loss_dice_5: 1.963  loss_ce_6: 0  loss_mask_6: 0.7301  loss_dice_6: 1.954  loss_ce_7: 0  loss_mask_7: 0.7304  loss_dice_7: 1.951  loss_ce_8: 0  loss_mask_8: 0.7281  loss_dice_8: 1.957  time: 1.9245  data_time: 0.0311  lr: 5.6284e-05  max_mem: 6006M
[02/18 15:48:26] d2.utils.events INFO:  eta: 18:59:34  iter: 28339  total_loss: 28.81  loss_ce: 0  loss_mask: 0.7351  loss_dice: 2.007  loss_seg: 0.706  loss_ce_0: 0  loss_mask_0: 0.7441  loss_dice_0: 2.072  loss_ce_1: 0  loss_mask_1: 0.7404  loss_dice_1: 2.019  loss_ce_2: 0  loss_mask_2: 0.7387  loss_dice_2: 2  loss_ce_3: 0  loss_mask_3: 0.7364  loss_dice_3: 1.993  loss_ce_4: 0  loss_mask_4: 0.7398  loss_dice_4: 1.992  loss_ce_5: 0  loss_mask_5: 0.7369  loss_dice_5: 1.997  loss_ce_6: 0  loss_mask_6: 0.7389  loss_dice_6: 1.995  loss_ce_7: 0  loss_mask_7: 0.7412  loss_dice_7: 1.995  loss_ce_8: 0  loss_mask_8: 0.7379  loss_dice_8: 2.001  time: 1.9257  data_time: 0.0273  lr: 5.6252e-05  max_mem: 6006M
[02/18 15:49:32] d2.utils.events INFO:  eta: 18:55:42  iter: 28359  total_loss: 26.86  loss_ce: 0  loss_mask: 0.7033  loss_dice: 1.888  loss_seg: 0.6191  loss_ce_0: 0  loss_mask_0: 0.7047  loss_dice_0: 1.977  loss_ce_1: 0  loss_mask_1: 0.7017  loss_dice_1: 1.892  loss_ce_2: 0  loss_mask_2: 0.7014  loss_dice_2: 1.885  loss_ce_3: 0  loss_mask_3: 0.7038  loss_dice_3: 1.868  loss_ce_4: 0  loss_mask_4: 0.7059  loss_dice_4: 1.878  loss_ce_5: 0  loss_mask_5: 0.7056  loss_dice_5: 1.877  loss_ce_6: 0  loss_mask_6: 0.7039  loss_dice_6: 1.872  loss_ce_7: 0  loss_mask_7: 0.7026  loss_dice_7: 1.865  loss_ce_8: 0  loss_mask_8: 0.7047  loss_dice_8: 1.865  time: 1.9266  data_time: 0.0281  lr: 5.622e-05  max_mem: 6006M
[02/18 15:50:35] d2.utils.events INFO:  eta: 18:48:50  iter: 28379  total_loss: 27.15  loss_ce: 0  loss_mask: 0.6877  loss_dice: 1.983  loss_seg: 0.8789  loss_ce_0: 0  loss_mask_0: 0.6947  loss_dice_0: 2.059  loss_ce_1: 0  loss_mask_1: 0.686  loss_dice_1: 1.996  loss_ce_2: 0  loss_mask_2: 0.6899  loss_dice_2: 1.976  loss_ce_3: 0  loss_mask_3: 0.6895  loss_dice_3: 1.963  loss_ce_4: 0  loss_mask_4: 0.6891  loss_dice_4: 1.97  loss_ce_5: 0  loss_mask_5: 0.6927  loss_dice_5: 1.968  loss_ce_6: 0  loss_mask_6: 0.6946  loss_dice_6: 1.957  loss_ce_7: 0  loss_mask_7: 0.6939  loss_dice_7: 1.974  loss_ce_8: 0  loss_mask_8: 0.6929  loss_dice_8: 1.972  time: 1.9275  data_time: 0.0328  lr: 5.6188e-05  max_mem: 6006M
[02/18 15:51:45] d2.utils.events INFO:  eta: 18:51:30  iter: 28399  total_loss: 28.02  loss_ce: 0  loss_mask: 0.7346  loss_dice: 2.011  loss_seg: 0.7693  loss_ce_0: 0  loss_mask_0: 0.7397  loss_dice_0: 2.081  loss_ce_1: 0  loss_mask_1: 0.7337  loss_dice_1: 2.023  loss_ce_2: 0  loss_mask_2: 0.734  loss_dice_2: 2.013  loss_ce_3: 0  loss_mask_3: 0.7355  loss_dice_3: 2.004  loss_ce_4: 0  loss_mask_4: 0.7336  loss_dice_4: 2.006  loss_ce_5: 0  loss_mask_5: 0.7352  loss_dice_5: 2.005  loss_ce_6: 0  loss_mask_6: 0.7348  loss_dice_6: 2.004  loss_ce_7: 0  loss_mask_7: 0.7349  loss_dice_7: 2.005  loss_ce_8: 0  loss_mask_8: 0.7349  loss_dice_8: 2.01  time: 1.9286  data_time: 0.0385  lr: 5.6156e-05  max_mem: 6006M
[02/18 15:52:54] d2.utils.events INFO:  eta: 18:47:25  iter: 28419  total_loss: 27.84  loss_ce: 0  loss_mask: 0.7364  loss_dice: 1.94  loss_seg: 0.5948  loss_ce_0: 0  loss_mask_0: 0.7516  loss_dice_0: 2.032  loss_ce_1: 0  loss_mask_1: 0.7402  loss_dice_1: 1.97  loss_ce_2: 0  loss_mask_2: 0.7407  loss_dice_2: 1.947  loss_ce_3: 0  loss_mask_3: 0.7408  loss_dice_3: 1.938  loss_ce_4: 0  loss_mask_4: 0.7405  loss_dice_4: 1.942  loss_ce_5: 0  loss_mask_5: 0.7404  loss_dice_5: 1.939  loss_ce_6: 0  loss_mask_6: 0.7409  loss_dice_6: 1.938  loss_ce_7: 0  loss_mask_7: 0.7412  loss_dice_7: 1.942  loss_ce_8: 0  loss_mask_8: 0.7416  loss_dice_8: 1.941  time: 1.9297  data_time: 0.0297  lr: 5.6124e-05  max_mem: 6006M
[02/18 15:54:03] d2.utils.events INFO:  eta: 18:46:42  iter: 28439  total_loss: 27.7  loss_ce: 0  loss_mask: 0.7181  loss_dice: 1.977  loss_seg: 0.6944  loss_ce_0: 0  loss_mask_0: 0.7212  loss_dice_0: 2.056  loss_ce_1: 0  loss_mask_1: 0.718  loss_dice_1: 1.99  loss_ce_2: 0  loss_mask_2: 0.7194  loss_dice_2: 1.976  loss_ce_3: 0  loss_mask_3: 0.7202  loss_dice_3: 1.967  loss_ce_4: 0  loss_mask_4: 0.7194  loss_dice_4: 1.968  loss_ce_5: 0  loss_mask_5: 0.7222  loss_dice_5: 1.973  loss_ce_6: 0  loss_mask_6: 0.7216  loss_dice_6: 1.968  loss_ce_7: 0  loss_mask_7: 0.7211  loss_dice_7: 1.967  loss_ce_8: 0  loss_mask_8: 0.7192  loss_dice_8: 1.967  time: 1.9307  data_time: 0.0319  lr: 5.6092e-05  max_mem: 6006M
[02/18 15:55:14] d2.utils.events INFO:  eta: 18:45:59  iter: 28459  total_loss: 28.57  loss_ce: 0  loss_mask: 0.7489  loss_dice: 1.925  loss_seg: 0.9632  loss_ce_0: 0  loss_mask_0: 0.7626  loss_dice_0: 1.989  loss_ce_1: 0  loss_mask_1: 0.7524  loss_dice_1: 1.931  loss_ce_2: 0  loss_mask_2: 0.749  loss_dice_2: 1.923  loss_ce_3: 0  loss_mask_3: 0.7469  loss_dice_3: 1.926  loss_ce_4: 0  loss_mask_4: 0.7486  loss_dice_4: 1.924  loss_ce_5: 0  loss_mask_5: 0.7526  loss_dice_5: 1.925  loss_ce_6: 0  loss_mask_6: 0.7501  loss_dice_6: 1.923  loss_ce_7: 0  loss_mask_7: 0.7494  loss_dice_7: 1.911  loss_ce_8: 0  loss_mask_8: 0.7503  loss_dice_8: 1.919  time: 1.9319  data_time: 0.0366  lr: 5.606e-05  max_mem: 6006M
[02/18 15:56:19] d2.utils.events INFO:  eta: 18:45:16  iter: 28479  total_loss: 26.94  loss_ce: 0  loss_mask: 0.7317  loss_dice: 1.893  loss_seg: 0.68  loss_ce_0: 0  loss_mask_0: 0.7409  loss_dice_0: 1.969  loss_ce_1: 0  loss_mask_1: 0.7369  loss_dice_1: 1.914  loss_ce_2: 0  loss_mask_2: 0.7375  loss_dice_2: 1.9  loss_ce_3: 0  loss_mask_3: 0.7369  loss_dice_3: 1.887  loss_ce_4: 0  loss_mask_4: 0.7357  loss_dice_4: 1.885  loss_ce_5: 0  loss_mask_5: 0.7366  loss_dice_5: 1.883  loss_ce_6: 0  loss_mask_6: 0.7373  loss_dice_6: 1.886  loss_ce_7: 0  loss_mask_7: 0.7376  loss_dice_7: 1.88  loss_ce_8: 0  loss_mask_8: 0.7417  loss_dice_8: 1.88  time: 1.9328  data_time: 0.0297  lr: 5.6028e-05  max_mem: 6006M
[02/18 15:57:29] d2.utils.events INFO:  eta: 19:00:37  iter: 28499  total_loss: 28.07  loss_ce: 0  loss_mask: 0.7313  loss_dice: 1.958  loss_seg: 0.6506  loss_ce_0: 0  loss_mask_0: 0.7404  loss_dice_0: 2.023  loss_ce_1: 0  loss_mask_1: 0.7326  loss_dice_1: 1.968  loss_ce_2: 0  loss_mask_2: 0.7315  loss_dice_2: 1.956  loss_ce_3: 0  loss_mask_3: 0.7341  loss_dice_3: 1.948  loss_ce_4: 0  loss_mask_4: 0.7356  loss_dice_4: 1.95  loss_ce_5: 0  loss_mask_5: 0.7328  loss_dice_5: 1.947  loss_ce_6: 0  loss_mask_6: 0.7358  loss_dice_6: 1.948  loss_ce_7: 0  loss_mask_7: 0.7362  loss_dice_7: 1.949  loss_ce_8: 0  loss_mask_8: 0.7354  loss_dice_8: 1.942  time: 1.9339  data_time: 0.0259  lr: 5.5996e-05  max_mem: 6006M
[02/18 15:58:38] d2.utils.events INFO:  eta: 20:02:33  iter: 28519  total_loss: 28.52  loss_ce: 0  loss_mask: 0.7415  loss_dice: 2.029  loss_seg: 0.5064  loss_ce_0: 0  loss_mask_0: 0.7406  loss_dice_0: 2.082  loss_ce_1: 0  loss_mask_1: 0.7443  loss_dice_1: 2.038  loss_ce_2: 0  loss_mask_2: 0.7501  loss_dice_2: 2.02  loss_ce_3: 0  loss_mask_3: 0.7475  loss_dice_3: 2.008  loss_ce_4: 0  loss_mask_4: 0.7495  loss_dice_4: 2.006  loss_ce_5: 0  loss_mask_5: 0.75  loss_dice_5: 2.008  loss_ce_6: 0  loss_mask_6: 0.7491  loss_dice_6: 2.006  loss_ce_7: 0  loss_mask_7: 0.7504  loss_dice_7: 2.008  loss_ce_8: 0  loss_mask_8: 0.7496  loss_dice_8: 2.015  time: 1.9349  data_time: 0.0297  lr: 5.5964e-05  max_mem: 6006M
[02/18 15:59:47] d2.utils.events INFO:  eta: 21:13:21  iter: 28539  total_loss: 27.17  loss_ce: 0  loss_mask: 0.7171  loss_dice: 1.925  loss_seg: 0.7846  loss_ce_0: 0  loss_mask_0: 0.7271  loss_dice_0: 2.001  loss_ce_1: 0  loss_mask_1: 0.7235  loss_dice_1: 1.932  loss_ce_2: 0  loss_mask_2: 0.7218  loss_dice_2: 1.926  loss_ce_3: 0  loss_mask_3: 0.7176  loss_dice_3: 1.912  loss_ce_4: 0  loss_mask_4: 0.714  loss_dice_4: 1.913  loss_ce_5: 0  loss_mask_5: 0.7129  loss_dice_5: 1.916  loss_ce_6: 0  loss_mask_6: 0.7135  loss_dice_6: 1.916  loss_ce_7: 0  loss_mask_7: 0.7133  loss_dice_7: 1.92  loss_ce_8: 0  loss_mask_8: 0.7163  loss_dice_8: 1.916  time: 1.9360  data_time: 0.0277  lr: 5.5932e-05  max_mem: 6006M
[02/18 16:00:56] d2.utils.events INFO:  eta: 22:19:47  iter: 28559  total_loss: 27.51  loss_ce: 0  loss_mask: 0.7295  loss_dice: 1.984  loss_seg: 0.6523  loss_ce_0: 0  loss_mask_0: 0.7224  loss_dice_0: 2.014  loss_ce_1: 0  loss_mask_1: 0.7372  loss_dice_1: 2  loss_ce_2: 0  loss_mask_2: 0.7376  loss_dice_2: 1.982  loss_ce_3: 0  loss_mask_3: 0.7384  loss_dice_3: 1.97  loss_ce_4: 0  loss_mask_4: 0.7405  loss_dice_4: 1.97  loss_ce_5: 0  loss_mask_5: 0.7396  loss_dice_5: 1.969  loss_ce_6: 0  loss_mask_6: 0.7358  loss_dice_6: 1.966  loss_ce_7: 0  loss_mask_7: 0.7389  loss_dice_7: 1.974  loss_ce_8: 0  loss_mask_8: 0.7374  loss_dice_8: 1.977  time: 1.9370  data_time: 0.0306  lr: 5.59e-05  max_mem: 6006M
[02/18 16:02:06] d2.utils.events INFO:  eta: 23:08:03  iter: 28579  total_loss: 28.4  loss_ce: 0  loss_mask: 0.7456  loss_dice: 2.02  loss_seg: 0.5949  loss_ce_0: 0  loss_mask_0: 0.767  loss_dice_0: 2.071  loss_ce_1: 0  loss_mask_1: 0.7489  loss_dice_1: 2.021  loss_ce_2: 0  loss_mask_2: 0.7491  loss_dice_2: 2.019  loss_ce_3: 0  loss_mask_3: 0.752  loss_dice_3: 2.008  loss_ce_4: 0  loss_mask_4: 0.7493  loss_dice_4: 2.011  loss_ce_5: 0  loss_mask_5: 0.7493  loss_dice_5: 2.011  loss_ce_6: 0  loss_mask_6: 0.7508  loss_dice_6: 2.009  loss_ce_7: 0  loss_mask_7: 0.7514  loss_dice_7: 2.002  loss_ce_8: 0  loss_mask_8: 0.7522  loss_dice_8: 2.011  time: 1.9381  data_time: 0.0331  lr: 5.5868e-05  max_mem: 6006M
[02/18 16:03:18] d2.utils.events INFO:  eta: 23:44:58  iter: 28599  total_loss: 28.17  loss_ce: 0  loss_mask: 0.7065  loss_dice: 1.993  loss_seg: 0.8694  loss_ce_0: 0  loss_mask_0: 0.7164  loss_dice_0: 2.047  loss_ce_1: 0  loss_mask_1: 0.7133  loss_dice_1: 2.01  loss_ce_2: 0  loss_mask_2: 0.7123  loss_dice_2: 1.989  loss_ce_3: 0  loss_mask_3: 0.7123  loss_dice_3: 1.987  loss_ce_4: 0  loss_mask_4: 0.7115  loss_dice_4: 1.982  loss_ce_5: 0  loss_mask_5: 0.7079  loss_dice_5: 1.99  loss_ce_6: 0  loss_mask_6: 0.7084  loss_dice_6: 1.986  loss_ce_7: 0  loss_mask_7: 0.7106  loss_dice_7: 1.989  loss_ce_8: 0  loss_mask_8: 0.7068  loss_dice_8: 1.992  time: 1.9393  data_time: 0.0323  lr: 5.5836e-05  max_mem: 6006M
[02/18 16:04:22] d2.utils.events INFO:  eta: 1 day, 0:02:58  iter: 28619  total_loss: 28.93  loss_ce: 0  loss_mask: 0.7047  loss_dice: 2.041  loss_seg: 0.9536  loss_ce_0: 0  loss_mask_0: 0.7142  loss_dice_0: 2.129  loss_ce_1: 0  loss_mask_1: 0.7033  loss_dice_1: 2.064  loss_ce_2: 0  loss_mask_2: 0.7043  loss_dice_2: 2.046  loss_ce_3: 0  loss_mask_3: 0.7039  loss_dice_3: 2.042  loss_ce_4: 0  loss_mask_4: 0.7017  loss_dice_4: 2.04  loss_ce_5: 0  loss_mask_5: 0.7049  loss_dice_5: 2.044  loss_ce_6: 0  loss_mask_6: 0.706  loss_dice_6: 2.04  loss_ce_7: 0  loss_mask_7: 0.7073  loss_dice_7: 2.042  loss_ce_8: 0  loss_mask_8: 0.7052  loss_dice_8: 2.042  time: 1.9402  data_time: 0.0320  lr: 5.5804e-05  max_mem: 6006M
[02/18 16:05:34] d2.utils.events INFO:  eta: 1 day, 0:41:00  iter: 28639  total_loss: 28.19  loss_ce: 0  loss_mask: 0.7356  loss_dice: 1.987  loss_seg: 0.5138  loss_ce_0: 0  loss_mask_0: 0.7541  loss_dice_0: 2.059  loss_ce_1: 0  loss_mask_1: 0.7393  loss_dice_1: 2.001  loss_ce_2: 0  loss_mask_2: 0.7374  loss_dice_2: 1.986  loss_ce_3: 0  loss_mask_3: 0.7401  loss_dice_3: 1.98  loss_ce_4: 0  loss_mask_4: 0.7396  loss_dice_4: 1.982  loss_ce_5: 0  loss_mask_5: 0.7418  loss_dice_5: 1.977  loss_ce_6: 0  loss_mask_6: 0.7395  loss_dice_6: 1.975  loss_ce_7: 0  loss_mask_7: 0.7391  loss_dice_7: 1.972  loss_ce_8: 0  loss_mask_8: 0.7412  loss_dice_8: 1.974  time: 1.9414  data_time: 0.0308  lr: 5.5772e-05  max_mem: 6006M
[02/18 16:06:45] d2.utils.events INFO:  eta: 1 day, 1:23:33  iter: 28659  total_loss: 28.67  loss_ce: 0  loss_mask: 0.7269  loss_dice: 2.009  loss_seg: 0.649  loss_ce_0: 0  loss_mask_0: 0.7374  loss_dice_0: 2.089  loss_ce_1: 0  loss_mask_1: 0.7354  loss_dice_1: 2.034  loss_ce_2: 0  loss_mask_2: 0.7317  loss_dice_2: 2.014  loss_ce_3: 0  loss_mask_3: 0.726  loss_dice_3: 2  loss_ce_4: 0  loss_mask_4: 0.7265  loss_dice_4: 2.008  loss_ce_5: 0  loss_mask_5: 0.7262  loss_dice_5: 2.012  loss_ce_6: 0  loss_mask_6: 0.724  loss_dice_6: 2.005  loss_ce_7: 0  loss_mask_7: 0.7262  loss_dice_7: 2.001  loss_ce_8: 0  loss_mask_8: 0.7287  loss_dice_8: 1.999  time: 1.9425  data_time: 0.0306  lr: 5.574e-05  max_mem: 6006M
[02/18 16:07:53] d2.utils.events INFO:  eta: 1 day, 1:40:26  iter: 28679  total_loss: 29.25  loss_ce: 0  loss_mask: 0.7328  loss_dice: 1.999  loss_seg: 0.6933  loss_ce_0: 0  loss_mask_0: 0.7595  loss_dice_0: 2.059  loss_ce_1: 0  loss_mask_1: 0.7373  loss_dice_1: 2.015  loss_ce_2: 0  loss_mask_2: 0.7411  loss_dice_2: 2.005  loss_ce_3: 0  loss_mask_3: 0.7385  loss_dice_3: 1.991  loss_ce_4: 0  loss_mask_4: 0.7382  loss_dice_4: 1.982  loss_ce_5: 0  loss_mask_5: 0.7407  loss_dice_5: 1.988  loss_ce_6: 0  loss_mask_6: 0.7364  loss_dice_6: 1.985  loss_ce_7: 0  loss_mask_7: 0.7388  loss_dice_7: 1.992  loss_ce_8: 0  loss_mask_8: 0.7389  loss_dice_8: 1.984  time: 1.9435  data_time: 0.0307  lr: 5.5708e-05  max_mem: 6006M
[02/18 16:09:02] d2.utils.events INFO:  eta: 1 day, 2:03:34  iter: 28699  total_loss: 28.2  loss_ce: 0  loss_mask: 0.7144  loss_dice: 1.902  loss_seg: 0.6425  loss_ce_0: 0  loss_mask_0: 0.7059  loss_dice_0: 1.947  loss_ce_1: 0  loss_mask_1: 0.714  loss_dice_1: 1.918  loss_ce_2: 0  loss_mask_2: 0.7169  loss_dice_2: 1.907  loss_ce_3: 0  loss_mask_3: 0.7249  loss_dice_3: 1.899  loss_ce_4: 0  loss_mask_4: 0.7229  loss_dice_4: 1.899  loss_ce_5: 0  loss_mask_5: 0.7219  loss_dice_5: 1.902  loss_ce_6: 0  loss_mask_6: 0.7191  loss_dice_6: 1.898  loss_ce_7: 0  loss_mask_7: 0.7193  loss_dice_7: 1.898  loss_ce_8: 0  loss_mask_8: 0.7162  loss_dice_8: 1.896  time: 1.9445  data_time: 0.0294  lr: 5.5676e-05  max_mem: 6006M
[02/18 16:10:10] d2.utils.events INFO:  eta: 1 day, 2:18:17  iter: 28719  total_loss: 29.81  loss_ce: 0  loss_mask: 0.7292  loss_dice: 2.115  loss_seg: 0.5526  loss_ce_0: 0  loss_mask_0: 0.7513  loss_dice_0: 2.16  loss_ce_1: 0  loss_mask_1: 0.742  loss_dice_1: 2.123  loss_ce_2: 0  loss_mask_2: 0.7347  loss_dice_2: 2.102  loss_ce_3: 0  loss_mask_3: 0.7333  loss_dice_3: 2.101  loss_ce_4: 0  loss_mask_4: 0.733  loss_dice_4: 2.098  loss_ce_5: 0  loss_mask_5: 0.735  loss_dice_5: 2.099  loss_ce_6: 0  loss_mask_6: 0.7315  loss_dice_6: 2.095  loss_ce_7: 0  loss_mask_7: 0.7334  loss_dice_7: 2.098  loss_ce_8: 0  loss_mask_8: 0.7318  loss_dice_8: 2.099  time: 1.9455  data_time: 0.0419  lr: 5.5644e-05  max_mem: 6006M
[02/18 16:11:18] d2.utils.events INFO:  eta: 1 day, 2:38:00  iter: 28739  total_loss: 27.9  loss_ce: 0  loss_mask: 0.7168  loss_dice: 2.017  loss_seg: 0.7213  loss_ce_0: 0  loss_mask_0: 0.7333  loss_dice_0: 2.088  loss_ce_1: 0  loss_mask_1: 0.7174  loss_dice_1: 2.033  loss_ce_2: 0  loss_mask_2: 0.7187  loss_dice_2: 2.019  loss_ce_3: 0  loss_mask_3: 0.7247  loss_dice_3: 2.008  loss_ce_4: 0  loss_mask_4: 0.725  loss_dice_4: 2.009  loss_ce_5: 0  loss_mask_5: 0.7249  loss_dice_5: 2.005  loss_ce_6: 0  loss_mask_6: 0.7268  loss_dice_6: 2.004  loss_ce_7: 0  loss_mask_7: 0.7296  loss_dice_7: 2.006  loss_ce_8: 0  loss_mask_8: 0.728  loss_dice_8: 2.009  time: 1.9466  data_time: 0.0300  lr: 5.5612e-05  max_mem: 6006M
[02/18 16:12:31] d2.utils.events INFO:  eta: 1 day, 2:56:27  iter: 28759  total_loss: 27.67  loss_ce: 0  loss_mask: 0.7528  loss_dice: 1.925  loss_seg: 0.4598  loss_ce_0: 0  loss_mask_0: 0.7674  loss_dice_0: 1.978  loss_ce_1: 0  loss_mask_1: 0.7507  loss_dice_1: 1.933  loss_ce_2: 0  loss_mask_2: 0.7548  loss_dice_2: 1.919  loss_ce_3: 0  loss_mask_3: 0.7539  loss_dice_3: 1.917  loss_ce_4: 0  loss_mask_4: 0.7523  loss_dice_4: 1.914  loss_ce_5: 0  loss_mask_5: 0.7544  loss_dice_5: 1.917  loss_ce_6: 0  loss_mask_6: 0.7544  loss_dice_6: 1.915  loss_ce_7: 0  loss_mask_7: 0.7526  loss_dice_7: 1.919  loss_ce_8: 0  loss_mask_8: 0.7526  loss_dice_8: 1.918  time: 1.9477  data_time: 0.0310  lr: 5.558e-05  max_mem: 6006M
[02/18 16:13:41] d2.utils.events INFO:  eta: 1 day, 3:17:32  iter: 28779  total_loss: 28.46  loss_ce: 0  loss_mask: 0.7336  loss_dice: 1.985  loss_seg: 0.7148  loss_ce_0: 0  loss_mask_0: 0.7313  loss_dice_0: 2.072  loss_ce_1: 0  loss_mask_1: 0.7332  loss_dice_1: 2.004  loss_ce_2: 0  loss_mask_2: 0.7316  loss_dice_2: 1.991  loss_ce_3: 0  loss_mask_3: 0.7339  loss_dice_3: 1.988  loss_ce_4: 0  loss_mask_4: 0.736  loss_dice_4: 1.982  loss_ce_5: 0  loss_mask_5: 0.7343  loss_dice_5: 1.987  loss_ce_6: 0  loss_mask_6: 0.7362  loss_dice_6: 1.986  loss_ce_7: 0  loss_mask_7: 0.7381  loss_dice_7: 1.978  loss_ce_8: 0  loss_mask_8: 0.7389  loss_dice_8: 1.977  time: 1.9488  data_time: 0.0307  lr: 5.5548e-05  max_mem: 6006M
[02/18 16:14:49] d2.utils.events INFO:  eta: 1 day, 3:28:40  iter: 28799  total_loss: 27.28  loss_ce: 0  loss_mask: 0.6932  loss_dice: 1.962  loss_seg: 0.696  loss_ce_0: 0  loss_mask_0: 0.7065  loss_dice_0: 2.016  loss_ce_1: 0  loss_mask_1: 0.6965  loss_dice_1: 1.981  loss_ce_2: 0  loss_mask_2: 0.694  loss_dice_2: 1.955  loss_ce_3: 0  loss_mask_3: 0.6948  loss_dice_3: 1.943  loss_ce_4: 0  loss_mask_4: 0.698  loss_dice_4: 1.938  loss_ce_5: 0  loss_mask_5: 0.6967  loss_dice_5: 1.946  loss_ce_6: 0  loss_mask_6: 0.6964  loss_dice_6: 1.946  loss_ce_7: 0  loss_mask_7: 0.6972  loss_dice_7: 1.943  loss_ce_8: 0  loss_mask_8: 0.6939  loss_dice_8: 1.947  time: 1.9498  data_time: 0.0312  lr: 5.5516e-05  max_mem: 6006M
[02/18 16:15:57] d2.utils.events INFO:  eta: 1 day, 3:52:13  iter: 28819  total_loss: 27.66  loss_ce: 0  loss_mask: 0.7289  loss_dice: 1.999  loss_seg: 0.8559  loss_ce_0: 0  loss_mask_0: 0.7218  loss_dice_0: 2.069  loss_ce_1: 0  loss_mask_1: 0.7249  loss_dice_1: 2.012  loss_ce_2: 0  loss_mask_2: 0.727  loss_dice_2: 1.996  loss_ce_3: 0  loss_mask_3: 0.7272  loss_dice_3: 1.985  loss_ce_4: 0  loss_mask_4: 0.7279  loss_dice_4: 1.984  loss_ce_5: 0  loss_mask_5: 0.727  loss_dice_5: 1.982  loss_ce_6: 0  loss_mask_6: 0.7289  loss_dice_6: 1.99  loss_ce_7: 0  loss_mask_7: 0.7279  loss_dice_7: 1.987  loss_ce_8: 0  loss_mask_8: 0.7263  loss_dice_8: 1.986  time: 1.9508  data_time: 0.0394  lr: 5.5484e-05  max_mem: 6006M
[02/18 16:17:05] d2.utils.events INFO:  eta: 1 day, 4:04:33  iter: 28839  total_loss: 29.24  loss_ce: 0  loss_mask: 0.7385  loss_dice: 2.059  loss_seg: 0.9272  loss_ce_0: 0  loss_mask_0: 0.7578  loss_dice_0: 2.113  loss_ce_1: 0  loss_mask_1: 0.7435  loss_dice_1: 2.062  loss_ce_2: 0  loss_mask_2: 0.7438  loss_dice_2: 2.054  loss_ce_3: 0  loss_mask_3: 0.7453  loss_dice_3: 2.045  loss_ce_4: 0  loss_mask_4: 0.7397  loss_dice_4: 2.044  loss_ce_5: 0  loss_mask_5: 0.7408  loss_dice_5: 2.049  loss_ce_6: 0  loss_mask_6: 0.7385  loss_dice_6: 2.048  loss_ce_7: 0  loss_mask_7: 0.7414  loss_dice_7: 2.049  loss_ce_8: 0  loss_mask_8: 0.7391  loss_dice_8: 2.048  time: 1.9518  data_time: 0.0315  lr: 5.5452e-05  max_mem: 6006M
[02/18 16:18:10] d2.utils.events INFO:  eta: 1 day, 4:32:57  iter: 28859  total_loss: 29.23  loss_ce: 0  loss_mask: 0.7637  loss_dice: 2.086  loss_seg: 0.6958  loss_ce_0: 0  loss_mask_0: 0.7695  loss_dice_0: 2.143  loss_ce_1: 0  loss_mask_1: 0.7616  loss_dice_1: 2.082  loss_ce_2: 0  loss_mask_2: 0.7648  loss_dice_2: 2.075  loss_ce_3: 0  loss_mask_3: 0.7635  loss_dice_3: 2.069  loss_ce_4: 0  loss_mask_4: 0.7637  loss_dice_4: 2.062  loss_ce_5: 0  loss_mask_5: 0.7654  loss_dice_5: 2.072  loss_ce_6: 0  loss_mask_6: 0.7654  loss_dice_6: 2.068  loss_ce_7: 0  loss_mask_7: 0.765  loss_dice_7: 2.064  loss_ce_8: 0  loss_mask_8: 0.7661  loss_dice_8: 2.072  time: 1.9527  data_time: 0.0316  lr: 5.542e-05  max_mem: 6006M
[02/18 16:19:19] d2.utils.events INFO:  eta: 1 day, 4:41:17  iter: 28879  total_loss: 28.19  loss_ce: 0  loss_mask: 0.7068  loss_dice: 1.997  loss_seg: 0.6882  loss_ce_0: 0  loss_mask_0: 0.7202  loss_dice_0: 2.043  loss_ce_1: 0  loss_mask_1: 0.7184  loss_dice_1: 1.994  loss_ce_2: 0  loss_mask_2: 0.7137  loss_dice_2: 1.99  loss_ce_3: 0  loss_mask_3: 0.7077  loss_dice_3: 1.986  loss_ce_4: 0  loss_mask_4: 0.7107  loss_dice_4: 1.983  loss_ce_5: 0  loss_mask_5: 0.7111  loss_dice_5: 1.988  loss_ce_6: 0  loss_mask_6: 0.7074  loss_dice_6: 1.98  loss_ce_7: 0  loss_mask_7: 0.7098  loss_dice_7: 1.985  loss_ce_8: 0  loss_mask_8: 0.7101  loss_dice_8: 1.983  time: 1.9538  data_time: 0.0322  lr: 5.5388e-05  max_mem: 6006M
[02/18 16:20:29] d2.utils.events INFO:  eta: 1 day, 4:54:38  iter: 28899  total_loss: 28.88  loss_ce: 0  loss_mask: 0.7071  loss_dice: 2.046  loss_seg: 0.6857  loss_ce_0: 0  loss_mask_0: 0.7092  loss_dice_0: 2.119  loss_ce_1: 0  loss_mask_1: 0.7101  loss_dice_1: 2.054  loss_ce_2: 0  loss_mask_2: 0.7121  loss_dice_2: 2.035  loss_ce_3: 0  loss_mask_3: 0.7166  loss_dice_3: 2.031  loss_ce_4: 0  loss_mask_4: 0.7154  loss_dice_4: 2.028  loss_ce_5: 0  loss_mask_5: 0.7177  loss_dice_5: 2.028  loss_ce_6: 0  loss_mask_6: 0.7151  loss_dice_6: 2.026  loss_ce_7: 0  loss_mask_7: 0.7169  loss_dice_7: 2.029  loss_ce_8: 0  loss_mask_8: 0.7124  loss_dice_8: 2.032  time: 1.9548  data_time: 0.0275  lr: 5.5356e-05  max_mem: 6006M
[02/18 16:21:37] d2.utils.events INFO:  eta: 1 day, 5:09:05  iter: 28919  total_loss: 30.34  loss_ce: 0  loss_mask: 0.7341  loss_dice: 2.169  loss_seg: 0.815  loss_ce_0: 0  loss_mask_0: 0.7473  loss_dice_0: 2.241  loss_ce_1: 0  loss_mask_1: 0.7334  loss_dice_1: 2.188  loss_ce_2: 0  loss_mask_2: 0.7304  loss_dice_2: 2.174  loss_ce_3: 0  loss_mask_3: 0.7351  loss_dice_3: 2.161  loss_ce_4: 0  loss_mask_4: 0.7351  loss_dice_4: 2.164  loss_ce_5: 0  loss_mask_5: 0.736  loss_dice_5: 2.16  loss_ce_6: 0  loss_mask_6: 0.7359  loss_dice_6: 2.161  loss_ce_7: 0  loss_mask_7: 0.7346  loss_dice_7: 2.164  loss_ce_8: 0  loss_mask_8: 0.7351  loss_dice_8: 2.166  time: 1.9558  data_time: 0.0291  lr: 5.5323e-05  max_mem: 6006M
[02/18 16:22:44] d2.utils.events INFO:  eta: 1 day, 5:13:50  iter: 28939  total_loss: 28.72  loss_ce: 0  loss_mask: 0.7244  loss_dice: 2.031  loss_seg: 1.09  loss_ce_0: 0  loss_mask_0: 0.7365  loss_dice_0: 2.116  loss_ce_1: 0  loss_mask_1: 0.7251  loss_dice_1: 2.047  loss_ce_2: 0  loss_mask_2: 0.7254  loss_dice_2: 2.029  loss_ce_3: 0  loss_mask_3: 0.7238  loss_dice_3: 2.021  loss_ce_4: 0  loss_mask_4: 0.7218  loss_dice_4: 2.017  loss_ce_5: 0  loss_mask_5: 0.7234  loss_dice_5: 2.018  loss_ce_6: 0  loss_mask_6: 0.7234  loss_dice_6: 2.014  loss_ce_7: 0  loss_mask_7: 0.7244  loss_dice_7: 2.017  loss_ce_8: 0  loss_mask_8: 0.7216  loss_dice_8: 2.019  time: 1.9568  data_time: 0.0299  lr: 5.5291e-05  max_mem: 6006M
[02/18 16:23:51] d2.utils.events INFO:  eta: 1 day, 5:14:41  iter: 28959  total_loss: 28.03  loss_ce: 0  loss_mask: 0.7254  loss_dice: 1.983  loss_seg: 0.6094  loss_ce_0: 0  loss_mask_0: 0.7293  loss_dice_0: 2.056  loss_ce_1: 0  loss_mask_1: 0.7262  loss_dice_1: 2.008  loss_ce_2: 0  loss_mask_2: 0.7299  loss_dice_2: 1.985  loss_ce_3: 0  loss_mask_3: 0.7312  loss_dice_3: 1.979  loss_ce_4: 0  loss_mask_4: 0.7332  loss_dice_4: 1.979  loss_ce_5: 0  loss_mask_5: 0.7316  loss_dice_5: 1.977  loss_ce_6: 0  loss_mask_6: 0.7365  loss_dice_6: 1.967  loss_ce_7: 0  loss_mask_7: 0.7359  loss_dice_7: 1.976  loss_ce_8: 0  loss_mask_8: 0.7341  loss_dice_8: 1.976  time: 1.9577  data_time: 0.0337  lr: 5.5259e-05  max_mem: 6006M
[02/18 16:25:02] d2.utils.events INFO:  eta: 1 day, 5:20:43  iter: 28979  total_loss: 27.12  loss_ce: 0  loss_mask: 0.6918  loss_dice: 1.909  loss_seg: 0.5544  loss_ce_0: 0  loss_mask_0: 0.6975  loss_dice_0: 1.958  loss_ce_1: 0  loss_mask_1: 0.698  loss_dice_1: 1.916  loss_ce_2: 0  loss_mask_2: 0.7003  loss_dice_2: 1.904  loss_ce_3: 0  loss_mask_3: 0.6992  loss_dice_3: 1.898  loss_ce_4: 0  loss_mask_4: 0.7011  loss_dice_4: 1.901  loss_ce_5: 0  loss_mask_5: 0.704  loss_dice_5: 1.901  loss_ce_6: 0  loss_mask_6: 0.7013  loss_dice_6: 1.9  loss_ce_7: 0  loss_mask_7: 0.701  loss_dice_7: 1.901  loss_ce_8: 0  loss_mask_8: 0.6995  loss_dice_8: 1.904  time: 1.9588  data_time: 0.0321  lr: 5.5227e-05  max_mem: 6006M
[02/18 16:26:11] d2.utils.events INFO:  eta: 1 day, 5:17:33  iter: 28999  total_loss: 27.88  loss_ce: 0  loss_mask: 0.6905  loss_dice: 1.959  loss_seg: 0.7624  loss_ce_0: 0  loss_mask_0: 0.6992  loss_dice_0: 2.003  loss_ce_1: 0  loss_mask_1: 0.693  loss_dice_1: 1.959  loss_ce_2: 0  loss_mask_2: 0.6938  loss_dice_2: 1.956  loss_ce_3: 0  loss_mask_3: 0.6948  loss_dice_3: 1.943  loss_ce_4: 0  loss_mask_4: 0.6988  loss_dice_4: 1.945  loss_ce_5: 0  loss_mask_5: 0.6934  loss_dice_5: 1.95  loss_ce_6: 0  loss_mask_6: 0.6978  loss_dice_6: 1.957  loss_ce_7: 0  loss_mask_7: 0.6984  loss_dice_7: 1.952  loss_ce_8: 0  loss_mask_8: 0.7005  loss_dice_8: 1.953  time: 1.9599  data_time: 0.0275  lr: 5.5195e-05  max_mem: 6006M
[02/18 16:27:22] d2.utils.events INFO:  eta: 1 day, 5:14:06  iter: 29019  total_loss: 27.41  loss_ce: 0  loss_mask: 0.7111  loss_dice: 1.919  loss_seg: 0.8188  loss_ce_0: 0  loss_mask_0: 0.7148  loss_dice_0: 1.977  loss_ce_1: 0  loss_mask_1: 0.7136  loss_dice_1: 1.918  loss_ce_2: 0  loss_mask_2: 0.7122  loss_dice_2: 1.908  loss_ce_3: 0  loss_mask_3: 0.7147  loss_dice_3: 1.906  loss_ce_4: 0  loss_mask_4: 0.7136  loss_dice_4: 1.903  loss_ce_5: 0  loss_mask_5: 0.7156  loss_dice_5: 1.906  loss_ce_6: 0  loss_mask_6: 0.7144  loss_dice_6: 1.911  loss_ce_7: 0  loss_mask_7: 0.7161  loss_dice_7: 1.91  loss_ce_8: 0  loss_mask_8: 0.7157  loss_dice_8: 1.911  time: 1.9609  data_time: 0.0306  lr: 5.5163e-05  max_mem: 6006M
[02/18 16:28:31] d2.utils.events INFO:  eta: 1 day, 5:17:18  iter: 29039  total_loss: 29.29  loss_ce: 0  loss_mask: 0.7414  loss_dice: 2.054  loss_seg: 0.7947  loss_ce_0: 0  loss_mask_0: 0.7428  loss_dice_0: 2.131  loss_ce_1: 0  loss_mask_1: 0.748  loss_dice_1: 2.067  loss_ce_2: 0  loss_mask_2: 0.7487  loss_dice_2: 2.053  loss_ce_3: 0  loss_mask_3: 0.7448  loss_dice_3: 2.052  loss_ce_4: 0  loss_mask_4: 0.7428  loss_dice_4: 2.054  loss_ce_5: 0  loss_mask_5: 0.7402  loss_dice_5: 2.048  loss_ce_6: 0  loss_mask_6: 0.7436  loss_dice_6: 2.049  loss_ce_7: 0  loss_mask_7: 0.7419  loss_dice_7: 2.047  loss_ce_8: 0  loss_mask_8: 0.7426  loss_dice_8: 2.051  time: 1.9620  data_time: 0.0282  lr: 5.5131e-05  max_mem: 6006M
[02/18 16:29:37] d2.utils.events INFO:  eta: 1 day, 5:15:34  iter: 29059  total_loss: 25.97  loss_ce: 0  loss_mask: 0.6778  loss_dice: 1.837  loss_seg: 0.7611  loss_ce_0: 0  loss_mask_0: 0.6757  loss_dice_0: 1.907  loss_ce_1: 0  loss_mask_1: 0.6733  loss_dice_1: 1.859  loss_ce_2: 0  loss_mask_2: 0.678  loss_dice_2: 1.833  loss_ce_3: 0  loss_mask_3: 0.6795  loss_dice_3: 1.828  loss_ce_4: 0  loss_mask_4: 0.6771  loss_dice_4: 1.828  loss_ce_5: 0  loss_mask_5: 0.6781  loss_dice_5: 1.829  loss_ce_6: 0  loss_mask_6: 0.6785  loss_dice_6: 1.828  loss_ce_7: 0  loss_mask_7: 0.6796  loss_dice_7: 1.83  loss_ce_8: 0  loss_mask_8: 0.6781  loss_dice_8: 1.834  time: 1.9629  data_time: 0.0254  lr: 5.5099e-05  max_mem: 6006M
[02/18 16:30:46] d2.utils.events INFO:  eta: 1 day, 5:17:00  iter: 29079  total_loss: 27.99  loss_ce: 0  loss_mask: 0.7062  loss_dice: 2.067  loss_seg: 0.6599  loss_ce_0: 0  loss_mask_0: 0.7214  loss_dice_0: 2.108  loss_ce_1: 0  loss_mask_1: 0.7103  loss_dice_1: 2.079  loss_ce_2: 0  loss_mask_2: 0.7095  loss_dice_2: 2.066  loss_ce_3: 0  loss_mask_3: 0.7109  loss_dice_3: 2.05  loss_ce_4: 0  loss_mask_4: 0.7106  loss_dice_4: 2.052  loss_ce_5: 0  loss_mask_5: 0.7087  loss_dice_5: 2.056  loss_ce_6: 0  loss_mask_6: 0.7133  loss_dice_6: 2.048  loss_ce_7: 0  loss_mask_7: 0.7103  loss_dice_7: 2.052  loss_ce_8: 0  loss_mask_8: 0.7108  loss_dice_8: 2.048  time: 1.9639  data_time: 0.0349  lr: 5.5067e-05  max_mem: 6006M
[02/18 16:31:56] d2.utils.events INFO:  eta: 1 day, 5:15:52  iter: 29099  total_loss: 27.48  loss_ce: 0  loss_mask: 0.7319  loss_dice: 1.99  loss_seg: 0.6764  loss_ce_0: 0  loss_mask_0: 0.751  loss_dice_0: 2.012  loss_ce_1: 0  loss_mask_1: 0.7396  loss_dice_1: 1.98  loss_ce_2: 0  loss_mask_2: 0.7383  loss_dice_2: 1.976  loss_ce_3: 0  loss_mask_3: 0.7339  loss_dice_3: 1.965  loss_ce_4: 0  loss_mask_4: 0.7349  loss_dice_4: 1.969  loss_ce_5: 0  loss_mask_5: 0.7341  loss_dice_5: 1.968  loss_ce_6: 0  loss_mask_6: 0.7303  loss_dice_6: 1.963  loss_ce_7: 0  loss_mask_7: 0.7311  loss_dice_7: 1.969  loss_ce_8: 0  loss_mask_8: 0.7304  loss_dice_8: 1.976  time: 1.9650  data_time: 0.0347  lr: 5.5035e-05  max_mem: 6006M
[02/18 16:33:05] d2.utils.events INFO:  eta: 1 day, 5:15:36  iter: 29119  total_loss: 27.91  loss_ce: 0  loss_mask: 0.7377  loss_dice: 1.973  loss_seg: 0.9593  loss_ce_0: 0  loss_mask_0: 0.7348  loss_dice_0: 2.064  loss_ce_1: 0  loss_mask_1: 0.7451  loss_dice_1: 1.991  loss_ce_2: 0  loss_mask_2: 0.7418  loss_dice_2: 1.982  loss_ce_3: 0  loss_mask_3: 0.7392  loss_dice_3: 1.968  loss_ce_4: 0  loss_mask_4: 0.7409  loss_dice_4: 1.965  loss_ce_5: 0  loss_mask_5: 0.7413  loss_dice_5: 1.968  loss_ce_6: 0  loss_mask_6: 0.743  loss_dice_6: 1.968  loss_ce_7: 0  loss_mask_7: 0.7445  loss_dice_7: 1.961  loss_ce_8: 0  loss_mask_8: 0.7408  loss_dice_8: 1.966  time: 1.9660  data_time: 0.0315  lr: 5.5003e-05  max_mem: 6006M
[02/18 16:34:13] d2.utils.events INFO:  eta: 1 day, 5:22:11  iter: 29139  total_loss: 27.94  loss_ce: 0  loss_mask: 0.7323  loss_dice: 1.94  loss_seg: 0.7446  loss_ce_0: 0  loss_mask_0: 0.7548  loss_dice_0: 1.97  loss_ce_1: 0  loss_mask_1: 0.738  loss_dice_1: 1.943  loss_ce_2: 0  loss_mask_2: 0.7341  loss_dice_2: 1.938  loss_ce_3: 0  loss_mask_3: 0.7347  loss_dice_3: 1.925  loss_ce_4: 0  loss_mask_4: 0.7364  loss_dice_4: 1.921  loss_ce_5: 0  loss_mask_5: 0.7336  loss_dice_5: 1.925  loss_ce_6: 0  loss_mask_6: 0.7335  loss_dice_6: 1.927  loss_ce_7: 0  loss_mask_7: 0.7355  loss_dice_7: 1.927  loss_ce_8: 0  loss_mask_8: 0.7322  loss_dice_8: 1.929  time: 1.9670  data_time: 0.0344  lr: 5.4971e-05  max_mem: 6006M
[02/18 16:35:23] d2.utils.events INFO:  eta: 1 day, 5:31:25  iter: 29159  total_loss: 28.51  loss_ce: 0  loss_mask: 0.721  loss_dice: 1.978  loss_seg: 0.6752  loss_ce_0: 0  loss_mask_0: 0.7281  loss_dice_0: 2.044  loss_ce_1: 0  loss_mask_1: 0.7299  loss_dice_1: 1.98  loss_ce_2: 0  loss_mask_2: 0.7289  loss_dice_2: 1.972  loss_ce_3: 0  loss_mask_3: 0.73  loss_dice_3: 1.964  loss_ce_4: 0  loss_mask_4: 0.7314  loss_dice_4: 1.963  loss_ce_5: 0  loss_mask_5: 0.7291  loss_dice_5: 1.964  loss_ce_6: 0  loss_mask_6: 0.7296  loss_dice_6: 1.968  loss_ce_7: 0  loss_mask_7: 0.7315  loss_dice_7: 1.961  loss_ce_8: 0  loss_mask_8: 0.7305  loss_dice_8: 1.97  time: 1.9680  data_time: 0.0298  lr: 5.4939e-05  max_mem: 6006M
[02/18 16:36:36] d2.utils.events INFO:  eta: 1 day, 5:49:46  iter: 29179  total_loss: 27.35  loss_ce: 0  loss_mask: 0.6892  loss_dice: 1.911  loss_seg: 0.7029  loss_ce_0: 0  loss_mask_0: 0.711  loss_dice_0: 1.979  loss_ce_1: 0  loss_mask_1: 0.698  loss_dice_1: 1.922  loss_ce_2: 0  loss_mask_2: 0.6934  loss_dice_2: 1.908  loss_ce_3: 0  loss_mask_3: 0.697  loss_dice_3: 1.893  loss_ce_4: 0  loss_mask_4: 0.6997  loss_dice_4: 1.898  loss_ce_5: 0  loss_mask_5: 0.6942  loss_dice_5: 1.895  loss_ce_6: 0  loss_mask_6: 0.6917  loss_dice_6: 1.894  loss_ce_7: 0  loss_mask_7: 0.6955  loss_dice_7: 1.897  loss_ce_8: 0  loss_mask_8: 0.6924  loss_dice_8: 1.894  time: 1.9692  data_time: 0.0303  lr: 5.4907e-05  max_mem: 6006M
[02/18 16:37:39] d2.utils.events INFO:  eta: 1 day, 5:42:12  iter: 29199  total_loss: 29.89  loss_ce: 0  loss_mask: 0.7445  loss_dice: 2.042  loss_seg: 0.9818  loss_ce_0: 0  loss_mask_0: 0.7461  loss_dice_0: 2.099  loss_ce_1: 0  loss_mask_1: 0.741  loss_dice_1: 2.056  loss_ce_2: 0  loss_mask_2: 0.7458  loss_dice_2: 2.036  loss_ce_3: 0  loss_mask_3: 0.7491  loss_dice_3: 2.027  loss_ce_4: 0  loss_mask_4: 0.7449  loss_dice_4: 2.024  loss_ce_5: 0  loss_mask_5: 0.7479  loss_dice_5: 2.026  loss_ce_6: 0  loss_mask_6: 0.7492  loss_dice_6: 2.029  loss_ce_7: 0  loss_mask_7: 0.75  loss_dice_7: 2.026  loss_ce_8: 0  loss_mask_8: 0.7488  loss_dice_8: 2.023  time: 1.9700  data_time: 0.0310  lr: 5.4875e-05  max_mem: 6006M
[02/18 16:38:47] d2.utils.events INFO:  eta: 1 day, 5:47:26  iter: 29219  total_loss: 28.8  loss_ce: 0  loss_mask: 0.7075  loss_dice: 2.028  loss_seg: 0.5491  loss_ce_0: 0  loss_mask_0: 0.7073  loss_dice_0: 2.09  loss_ce_1: 0  loss_mask_1: 0.7118  loss_dice_1: 2.043  loss_ce_2: 0  loss_mask_2: 0.7096  loss_dice_2: 2.03  loss_ce_3: 0  loss_mask_3: 0.7106  loss_dice_3: 2.021  loss_ce_4: 0  loss_mask_4: 0.7108  loss_dice_4: 2.024  loss_ce_5: 0  loss_mask_5: 0.7091  loss_dice_5: 2.025  loss_ce_6: 0  loss_mask_6: 0.7148  loss_dice_6: 2.023  loss_ce_7: 0  loss_mask_7: 0.7121  loss_dice_7: 2.027  loss_ce_8: 0  loss_mask_8: 0.7116  loss_dice_8: 2.025  time: 1.9709  data_time: 0.0300  lr: 5.4843e-05  max_mem: 6006M
[02/18 16:39:57] d2.utils.events INFO:  eta: 1 day, 5:47:08  iter: 29239  total_loss: 27.51  loss_ce: 0  loss_mask: 0.7197  loss_dice: 1.984  loss_seg: 0.6669  loss_ce_0: 0  loss_mask_0: 0.7305  loss_dice_0: 2.045  loss_ce_1: 0  loss_mask_1: 0.7235  loss_dice_1: 1.989  loss_ce_2: 0  loss_mask_2: 0.7233  loss_dice_2: 1.982  loss_ce_3: 0  loss_mask_3: 0.7207  loss_dice_3: 1.973  loss_ce_4: 0  loss_mask_4: 0.7171  loss_dice_4: 1.975  loss_ce_5: 0  loss_mask_5: 0.7187  loss_dice_5: 1.981  loss_ce_6: 0  loss_mask_6: 0.7212  loss_dice_6: 1.972  loss_ce_7: 0  loss_mask_7: 0.722  loss_dice_7: 1.971  loss_ce_8: 0  loss_mask_8: 0.7205  loss_dice_8: 1.975  time: 1.9720  data_time: 0.0318  lr: 5.4811e-05  max_mem: 6006M
[02/18 16:41:03] d2.utils.events INFO:  eta: 1 day, 5:43:29  iter: 29259  total_loss: 28.17  loss_ce: 0  loss_mask: 0.7209  loss_dice: 1.99  loss_seg: 0.7665  loss_ce_0: 0  loss_mask_0: 0.7414  loss_dice_0: 2.052  loss_ce_1: 0  loss_mask_1: 0.7203  loss_dice_1: 2  loss_ce_2: 0  loss_mask_2: 0.7185  loss_dice_2: 1.994  loss_ce_3: 0  loss_mask_3: 0.7234  loss_dice_3: 1.98  loss_ce_4: 0  loss_mask_4: 0.7204  loss_dice_4: 1.983  loss_ce_5: 0  loss_mask_5: 0.7201  loss_dice_5: 1.982  loss_ce_6: 0  loss_mask_6: 0.7233  loss_dice_6: 1.982  loss_ce_7: 0  loss_mask_7: 0.7202  loss_dice_7: 1.979  loss_ce_8: 0  loss_mask_8: 0.7181  loss_dice_8: 1.983  time: 1.9729  data_time: 0.0458  lr: 5.4778e-05  max_mem: 6006M
[02/18 16:42:12] d2.utils.events INFO:  eta: 1 day, 5:42:20  iter: 29279  total_loss: 28.19  loss_ce: 0  loss_mask: 0.7316  loss_dice: 2.003  loss_seg: 0.7077  loss_ce_0: 0  loss_mask_0: 0.7267  loss_dice_0: 2.076  loss_ce_1: 0  loss_mask_1: 0.7364  loss_dice_1: 2.025  loss_ce_2: 0  loss_mask_2: 0.7344  loss_dice_2: 2.007  loss_ce_3: 0  loss_mask_3: 0.733  loss_dice_3: 2.002  loss_ce_4: 0  loss_mask_4: 0.7359  loss_dice_4: 1.999  loss_ce_5: 0  loss_mask_5: 0.734  loss_dice_5: 2  loss_ce_6: 0  loss_mask_6: 0.7355  loss_dice_6: 1.993  loss_ce_7: 0  loss_mask_7: 0.7368  loss_dice_7: 1.999  loss_ce_8: 0  loss_mask_8: 0.7364  loss_dice_8: 2.004  time: 1.9739  data_time: 0.0291  lr: 5.4746e-05  max_mem: 6006M
[02/18 16:43:23] d2.utils.events INFO:  eta: 1 day, 5:43:20  iter: 29299  total_loss: 29.55  loss_ce: 0  loss_mask: 0.7355  loss_dice: 2.166  loss_seg: 0.8754  loss_ce_0: 0  loss_mask_0: 0.7585  loss_dice_0: 2.242  loss_ce_1: 0  loss_mask_1: 0.7406  loss_dice_1: 2.183  loss_ce_2: 0  loss_mask_2: 0.7389  loss_dice_2: 2.168  loss_ce_3: 0  loss_mask_3: 0.7355  loss_dice_3: 2.163  loss_ce_4: 0  loss_mask_4: 0.7411  loss_dice_4: 2.152  loss_ce_5: 0  loss_mask_5: 0.7392  loss_dice_5: 2.162  loss_ce_6: 0  loss_mask_6: 0.7378  loss_dice_6: 2.152  loss_ce_7: 0  loss_mask_7: 0.7392  loss_dice_7: 2.155  loss_ce_8: 0  loss_mask_8: 0.7393  loss_dice_8: 2.149  time: 1.9750  data_time: 0.0321  lr: 5.4714e-05  max_mem: 6006M
[02/18 16:44:30] d2.utils.events INFO:  eta: 1 day, 5:42:45  iter: 29319  total_loss: 29.1  loss_ce: 0  loss_mask: 0.7078  loss_dice: 2.123  loss_seg: 0.6607  loss_ce_0: 0  loss_mask_0: 0.7224  loss_dice_0: 2.185  loss_ce_1: 0  loss_mask_1: 0.7156  loss_dice_1: 2.133  loss_ce_2: 0  loss_mask_2: 0.7177  loss_dice_2: 2.119  loss_ce_3: 0  loss_mask_3: 0.7133  loss_dice_3: 2.107  loss_ce_4: 0  loss_mask_4: 0.7114  loss_dice_4: 2.105  loss_ce_5: 0  loss_mask_5: 0.7129  loss_dice_5: 2.11  loss_ce_6: 0  loss_mask_6: 0.7147  loss_dice_6: 2.108  loss_ce_7: 0  loss_mask_7: 0.7129  loss_dice_7: 2.109  loss_ce_8: 0  loss_mask_8: 0.7116  loss_dice_8: 2.111  time: 1.9759  data_time: 0.0327  lr: 5.4682e-05  max_mem: 6006M
[02/18 16:45:38] d2.utils.events INFO:  eta: 1 day, 5:41:19  iter: 29339  total_loss: 28.2  loss_ce: 0  loss_mask: 0.7141  loss_dice: 1.98  loss_seg: 0.7433  loss_ce_0: 0  loss_mask_0: 0.7369  loss_dice_0: 2.053  loss_ce_1: 0  loss_mask_1: 0.7188  loss_dice_1: 1.997  loss_ce_2: 0  loss_mask_2: 0.7192  loss_dice_2: 1.982  loss_ce_3: 0  loss_mask_3: 0.719  loss_dice_3: 1.969  loss_ce_4: 0  loss_mask_4: 0.7183  loss_dice_4: 1.971  loss_ce_5: 0  loss_mask_5: 0.719  loss_dice_5: 1.975  loss_ce_6: 0  loss_mask_6: 0.7231  loss_dice_6: 1.967  loss_ce_7: 0  loss_mask_7: 0.7222  loss_dice_7: 1.966  loss_ce_8: 0  loss_mask_8: 0.7221  loss_dice_8: 1.973  time: 1.9769  data_time: 0.0345  lr: 5.465e-05  max_mem: 6006M
[02/18 16:46:44] d2.utils.events INFO:  eta: 1 day, 5:40:10  iter: 29359  total_loss: 28.54  loss_ce: 0  loss_mask: 0.7068  loss_dice: 2.004  loss_seg: 0.7025  loss_ce_0: 0  loss_mask_0: 0.7149  loss_dice_0: 2.046  loss_ce_1: 0  loss_mask_1: 0.7084  loss_dice_1: 2.018  loss_ce_2: 0  loss_mask_2: 0.7056  loss_dice_2: 2.011  loss_ce_3: 0  loss_mask_3: 0.7083  loss_dice_3: 2.001  loss_ce_4: 0  loss_mask_4: 0.7074  loss_dice_4: 2.003  loss_ce_5: 0  loss_mask_5: 0.7074  loss_dice_5: 2.001  loss_ce_6: 0  loss_mask_6: 0.7112  loss_dice_6: 1.998  loss_ce_7: 0  loss_mask_7: 0.7135  loss_dice_7: 1.994  loss_ce_8: 0  loss_mask_8: 0.7115  loss_dice_8: 1.998  time: 1.9778  data_time: 0.0350  lr: 5.4618e-05  max_mem: 6006M
[02/18 16:47:52] d2.utils.events INFO:  eta: 1 day, 5:41:58  iter: 29379  total_loss: 29.95  loss_ce: 0  loss_mask: 0.782  loss_dice: 2.118  loss_seg: 0.9863  loss_ce_0: 0  loss_mask_0: 0.7971  loss_dice_0: 2.169  loss_ce_1: 0  loss_mask_1: 0.7881  loss_dice_1: 2.128  loss_ce_2: 0  loss_mask_2: 0.7836  loss_dice_2: 2.115  loss_ce_3: 0  loss_mask_3: 0.792  loss_dice_3: 2.108  loss_ce_4: 0  loss_mask_4: 0.7882  loss_dice_4: 2.111  loss_ce_5: 0  loss_mask_5: 0.7901  loss_dice_5: 2.113  loss_ce_6: 0  loss_mask_6: 0.7927  loss_dice_6: 2.114  loss_ce_7: 0  loss_mask_7: 0.7911  loss_dice_7: 2.11  loss_ce_8: 0  loss_mask_8: 0.7882  loss_dice_8: 2.115  time: 1.9787  data_time: 0.0261  lr: 5.4586e-05  max_mem: 6006M
[02/18 16:48:58] d2.utils.events INFO:  eta: 1 day, 5:38:39  iter: 29399  total_loss: 27.02  loss_ce: 0  loss_mask: 0.7025  loss_dice: 1.909  loss_seg: 0.6977  loss_ce_0: 0  loss_mask_0: 0.7091  loss_dice_0: 1.985  loss_ce_1: 0  loss_mask_1: 0.7027  loss_dice_1: 1.926  loss_ce_2: 0  loss_mask_2: 0.7045  loss_dice_2: 1.906  loss_ce_3: 0  loss_mask_3: 0.7019  loss_dice_3: 1.899  loss_ce_4: 0  loss_mask_4: 0.7043  loss_dice_4: 1.897  loss_ce_5: 0  loss_mask_5: 0.6998  loss_dice_5: 1.899  loss_ce_6: 0  loss_mask_6: 0.7011  loss_dice_6: 1.897  loss_ce_7: 0  loss_mask_7: 0.6997  loss_dice_7: 1.893  loss_ce_8: 0  loss_mask_8: 0.7  loss_dice_8: 1.898  time: 1.9796  data_time: 0.0330  lr: 5.4554e-05  max_mem: 6006M
[02/18 16:50:04] d2.utils.events INFO:  eta: 1 day, 5:36:41  iter: 29419  total_loss: 28.87  loss_ce: 0  loss_mask: 0.7325  loss_dice: 2.034  loss_seg: 0.6541  loss_ce_0: 0  loss_mask_0: 0.7422  loss_dice_0: 2.09  loss_ce_1: 0  loss_mask_1: 0.7472  loss_dice_1: 2.046  loss_ce_2: 0  loss_mask_2: 0.7493  loss_dice_2: 2.033  loss_ce_3: 0  loss_mask_3: 0.7433  loss_dice_3: 2.03  loss_ce_4: 0  loss_mask_4: 0.7399  loss_dice_4: 2.025  loss_ce_5: 0  loss_mask_5: 0.742  loss_dice_5: 2.022  loss_ce_6: 0  loss_mask_6: 0.7412  loss_dice_6: 2.026  loss_ce_7: 0  loss_mask_7: 0.7417  loss_dice_7: 2.028  loss_ce_8: 0  loss_mask_8: 0.7407  loss_dice_8: 2.032  time: 1.9805  data_time: 0.0261  lr: 5.4522e-05  max_mem: 6006M
[02/18 16:51:10] d2.utils.events INFO:  eta: 1 day, 5:35:31  iter: 29439  total_loss: 28.01  loss_ce: 0  loss_mask: 0.73  loss_dice: 1.978  loss_seg: 0.8451  loss_ce_0: 0  loss_mask_0: 0.73  loss_dice_0: 2.033  loss_ce_1: 0  loss_mask_1: 0.728  loss_dice_1: 1.997  loss_ce_2: 0  loss_mask_2: 0.7307  loss_dice_2: 1.984  loss_ce_3: 0  loss_mask_3: 0.7323  loss_dice_3: 1.977  loss_ce_4: 0  loss_mask_4: 0.7345  loss_dice_4: 1.975  loss_ce_5: 0  loss_mask_5: 0.7379  loss_dice_5: 1.976  loss_ce_6: 0  loss_mask_6: 0.738  loss_dice_6: 1.97  loss_ce_7: 0  loss_mask_7: 0.7373  loss_dice_7: 1.977  loss_ce_8: 0  loss_mask_8: 0.7334  loss_dice_8: 1.973  time: 1.9814  data_time: 0.0336  lr: 5.449e-05  max_mem: 6006M
[02/18 16:52:23] d2.utils.events INFO:  eta: 1 day, 5:34:21  iter: 29459  total_loss: 28.25  loss_ce: 0  loss_mask: 0.7444  loss_dice: 1.969  loss_seg: 0.8344  loss_ce_0: 0  loss_mask_0: 0.7556  loss_dice_0: 2.065  loss_ce_1: 0  loss_mask_1: 0.7439  loss_dice_1: 1.994  loss_ce_2: 0  loss_mask_2: 0.7494  loss_dice_2: 1.976  loss_ce_3: 0  loss_mask_3: 0.7478  loss_dice_3: 1.963  loss_ce_4: 0  loss_mask_4: 0.7466  loss_dice_4: 1.961  loss_ce_5: 0  loss_mask_5: 0.749  loss_dice_5: 1.96  loss_ce_6: 0  loss_mask_6: 0.7474  loss_dice_6: 1.965  loss_ce_7: 0  loss_mask_7: 0.7466  loss_dice_7: 1.968  loss_ce_8: 0  loss_mask_8: 0.7449  loss_dice_8: 1.963  time: 1.9825  data_time: 0.0285  lr: 5.4458e-05  max_mem: 6006M
[02/18 16:53:30] d2.utils.events INFO:  eta: 1 day, 5:33:27  iter: 29479  total_loss: 27.55  loss_ce: 0  loss_mask: 0.6556  loss_dice: 1.918  loss_seg: 0.6925  loss_ce_0: 0  loss_mask_0: 0.6714  loss_dice_0: 1.984  loss_ce_1: 0  loss_mask_1: 0.6655  loss_dice_1: 1.923  loss_ce_2: 0  loss_mask_2: 0.6627  loss_dice_2: 1.912  loss_ce_3: 0  loss_mask_3: 0.663  loss_dice_3: 1.902  loss_ce_4: 0  loss_mask_4: 0.661  loss_dice_4: 1.902  loss_ce_5: 0  loss_mask_5: 0.6603  loss_dice_5: 1.906  loss_ce_6: 0  loss_mask_6: 0.6572  loss_dice_6: 1.902  loss_ce_7: 0  loss_mask_7: 0.6593  loss_dice_7: 1.905  loss_ce_8: 0  loss_mask_8: 0.6599  loss_dice_8: 1.908  time: 1.9835  data_time: 0.0285  lr: 5.4426e-05  max_mem: 6006M
[02/18 16:54:39] d2.utils.events INFO:  eta: 1 day, 5:31:57  iter: 29499  total_loss: 28.94  loss_ce: 0  loss_mask: 0.7256  loss_dice: 2.096  loss_seg: 0.7388  loss_ce_0: 0  loss_mask_0: 0.7233  loss_dice_0: 2.182  loss_ce_1: 0  loss_mask_1: 0.7264  loss_dice_1: 2.12  loss_ce_2: 0  loss_mask_2: 0.7311  loss_dice_2: 2.1  loss_ce_3: 0  loss_mask_3: 0.7291  loss_dice_3: 2.086  loss_ce_4: 0  loss_mask_4: 0.7312  loss_dice_4: 2.088  loss_ce_5: 0  loss_mask_5: 0.7265  loss_dice_5: 2.093  loss_ce_6: 0  loss_mask_6: 0.729  loss_dice_6: 2.092  loss_ce_7: 0  loss_mask_7: 0.727  loss_dice_7: 2.093  loss_ce_8: 0  loss_mask_8: 0.7279  loss_dice_8: 2.091  time: 1.9845  data_time: 0.0391  lr: 5.4393e-05  max_mem: 6006M
[02/18 16:55:45] d2.utils.events INFO:  eta: 1 day, 5:30:49  iter: 29519  total_loss: 27.15  loss_ce: 0  loss_mask: 0.6805  loss_dice: 1.979  loss_seg: 0.8485  loss_ce_0: 0  loss_mask_0: 0.6794  loss_dice_0: 2.056  loss_ce_1: 0  loss_mask_1: 0.6843  loss_dice_1: 2.003  loss_ce_2: 0  loss_mask_2: 0.6839  loss_dice_2: 1.988  loss_ce_3: 0  loss_mask_3: 0.6833  loss_dice_3: 1.973  loss_ce_4: 0  loss_mask_4: 0.682  loss_dice_4: 1.974  loss_ce_5: 0  loss_mask_5: 0.6816  loss_dice_5: 1.971  loss_ce_6: 0  loss_mask_6: 0.6831  loss_dice_6: 1.969  loss_ce_7: 0  loss_mask_7: 0.6841  loss_dice_7: 1.967  loss_ce_8: 0  loss_mask_8: 0.6831  loss_dice_8: 1.97  time: 1.9853  data_time: 0.0364  lr: 5.4361e-05  max_mem: 6006M
[02/18 16:56:52] d2.utils.events INFO:  eta: 1 day, 5:28:51  iter: 29539  total_loss: 29.09  loss_ce: 0  loss_mask: 0.7457  loss_dice: 2.056  loss_seg: 0.8871  loss_ce_0: 0  loss_mask_0: 0.772  loss_dice_0: 2.121  loss_ce_1: 0  loss_mask_1: 0.745  loss_dice_1: 2.077  loss_ce_2: 0  loss_mask_2: 0.7489  loss_dice_2: 2.062  loss_ce_3: 0  loss_mask_3: 0.7509  loss_dice_3: 2.054  loss_ce_4: 0  loss_mask_4: 0.7497  loss_dice_4: 2.052  loss_ce_5: 0  loss_mask_5: 0.7496  loss_dice_5: 2.056  loss_ce_6: 0  loss_mask_6: 0.7545  loss_dice_6: 2.055  loss_ce_7: 0  loss_mask_7: 0.7511  loss_dice_7: 2.05  loss_ce_8: 0  loss_mask_8: 0.753  loss_dice_8: 2.048  time: 1.9863  data_time: 0.0331  lr: 5.4329e-05  max_mem: 6006M
[02/18 16:57:58] d2.utils.events INFO:  eta: 1 day, 5:24:35  iter: 29559  total_loss: 28.61  loss_ce: 0  loss_mask: 0.7488  loss_dice: 2.04  loss_seg: 0.7263  loss_ce_0: 0  loss_mask_0: 0.7409  loss_dice_0: 2.091  loss_ce_1: 0  loss_mask_1: 0.7456  loss_dice_1: 2.053  loss_ce_2: 0  loss_mask_2: 0.747  loss_dice_2: 2.045  loss_ce_3: 0  loss_mask_3: 0.7483  loss_dice_3: 2.037  loss_ce_4: 0  loss_mask_4: 0.7494  loss_dice_4: 2.036  loss_ce_5: 0  loss_mask_5: 0.7504  loss_dice_5: 2.039  loss_ce_6: 0  loss_mask_6: 0.7509  loss_dice_6: 2.037  loss_ce_7: 0  loss_mask_7: 0.7525  loss_dice_7: 2.037  loss_ce_8: 0  loss_mask_8: 0.7519  loss_dice_8: 2.036  time: 1.9872  data_time: 0.0366  lr: 5.4297e-05  max_mem: 6006M
[02/18 16:59:09] d2.utils.events INFO:  eta: 1 day, 5:22:03  iter: 29579  total_loss: 27.28  loss_ce: 0  loss_mask: 0.7552  loss_dice: 1.916  loss_seg: 0.5939  loss_ce_0: 0  loss_mask_0: 0.7621  loss_dice_0: 1.971  loss_ce_1: 0  loss_mask_1: 0.7562  loss_dice_1: 1.929  loss_ce_2: 0  loss_mask_2: 0.7569  loss_dice_2: 1.92  loss_ce_3: 0  loss_mask_3: 0.7582  loss_dice_3: 1.914  loss_ce_4: 0  loss_mask_4: 0.7624  loss_dice_4: 1.912  loss_ce_5: 0  loss_mask_5: 0.7579  loss_dice_5: 1.91  loss_ce_6: 0  loss_mask_6: 0.7552  loss_dice_6: 1.912  loss_ce_7: 0  loss_mask_7: 0.7574  loss_dice_7: 1.917  loss_ce_8: 0  loss_mask_8: 0.7618  loss_dice_8: 1.914  time: 1.9882  data_time: 0.0341  lr: 5.4265e-05  max_mem: 6006M
[02/18 17:00:20] d2.utils.events INFO:  eta: 1 day, 5:20:53  iter: 29599  total_loss: 27.81  loss_ce: 0  loss_mask: 0.7113  loss_dice: 2.018  loss_seg: 0.7592  loss_ce_0: 0  loss_mask_0: 0.7189  loss_dice_0: 2.107  loss_ce_1: 0  loss_mask_1: 0.7174  loss_dice_1: 2.032  loss_ce_2: 0  loss_mask_2: 0.7155  loss_dice_2: 2.016  loss_ce_3: 0  loss_mask_3: 0.7146  loss_dice_3: 2.019  loss_ce_4: 0  loss_mask_4: 0.7144  loss_dice_4: 2.011  loss_ce_5: 0  loss_mask_5: 0.7171  loss_dice_5: 2.009  loss_ce_6: 0  loss_mask_6: 0.7162  loss_dice_6: 2.005  loss_ce_7: 0  loss_mask_7: 0.7161  loss_dice_7: 2.005  loss_ce_8: 0  loss_mask_8: 0.7163  loss_dice_8: 2.003  time: 1.9893  data_time: 0.0349  lr: 5.4233e-05  max_mem: 6006M
[02/18 17:01:28] d2.utils.events INFO:  eta: 1 day, 5:21:20  iter: 29619  total_loss: 28.97  loss_ce: 0  loss_mask: 0.7454  loss_dice: 2.04  loss_seg: 0.6551  loss_ce_0: 0  loss_mask_0: 0.7674  loss_dice_0: 2.118  loss_ce_1: 0  loss_mask_1: 0.747  loss_dice_1: 2.073  loss_ce_2: 0  loss_mask_2: 0.7462  loss_dice_2: 2.045  loss_ce_3: 0  loss_mask_3: 0.7484  loss_dice_3: 2.036  loss_ce_4: 0  loss_mask_4: 0.7447  loss_dice_4: 2.038  loss_ce_5: 0  loss_mask_5: 0.747  loss_dice_5: 2.046  loss_ce_6: 0  loss_mask_6: 0.7479  loss_dice_6: 2.042  loss_ce_7: 0  loss_mask_7: 0.7488  loss_dice_7: 2.042  loss_ce_8: 0  loss_mask_8: 0.7468  loss_dice_8: 2.04  time: 1.9902  data_time: 0.0291  lr: 5.4201e-05  max_mem: 6006M
[02/18 17:02:34] d2.utils.events INFO:  eta: 1 day, 5:15:33  iter: 29639  total_loss: 27.52  loss_ce: 0  loss_mask: 0.6979  loss_dice: 1.951  loss_seg: 0.6579  loss_ce_0: 0  loss_mask_0: 0.7151  loss_dice_0: 2.016  loss_ce_1: 0  loss_mask_1: 0.7089  loss_dice_1: 1.949  loss_ce_2: 0  loss_mask_2: 0.7124  loss_dice_2: 1.945  loss_ce_3: 0  loss_mask_3: 0.7099  loss_dice_3: 1.938  loss_ce_4: 0  loss_mask_4: 0.7119  loss_dice_4: 1.94  loss_ce_5: 0  loss_mask_5: 0.7131  loss_dice_5: 1.94  loss_ce_6: 0  loss_mask_6: 0.711  loss_dice_6: 1.94  loss_ce_7: 0  loss_mask_7: 0.7076  loss_dice_7: 1.934  loss_ce_8: 0  loss_mask_8: 0.7072  loss_dice_8: 1.94  time: 1.9911  data_time: 0.0254  lr: 5.4169e-05  max_mem: 6006M
[02/18 17:03:43] d2.utils.events INFO:  eta: 1 day, 5:10:52  iter: 29659  total_loss: 28.42  loss_ce: 0  loss_mask: 0.7288  loss_dice: 1.963  loss_seg: 0.652  loss_ce_0: 0  loss_mask_0: 0.7348  loss_dice_0: 2.037  loss_ce_1: 0  loss_mask_1: 0.7285  loss_dice_1: 1.991  loss_ce_2: 0  loss_mask_2: 0.7331  loss_dice_2: 1.968  loss_ce_3: 0  loss_mask_3: 0.7322  loss_dice_3: 1.961  loss_ce_4: 0  loss_mask_4: 0.7341  loss_dice_4: 1.958  loss_ce_5: 0  loss_mask_5: 0.7329  loss_dice_5: 1.959  loss_ce_6: 0  loss_mask_6: 0.7358  loss_dice_6: 1.954  loss_ce_7: 0  loss_mask_7: 0.7339  loss_dice_7: 1.961  loss_ce_8: 0  loss_mask_8: 0.7349  loss_dice_8: 1.957  time: 1.9921  data_time: 0.0314  lr: 5.4137e-05  max_mem: 6006M
[02/18 17:04:54] d2.utils.events INFO:  eta: 1 day, 5:11:48  iter: 29679  total_loss: 28.84  loss_ce: 0  loss_mask: 0.7488  loss_dice: 2.11  loss_seg: 0.6082  loss_ce_0: 0  loss_mask_0: 0.7486  loss_dice_0: 2.169  loss_ce_1: 0  loss_mask_1: 0.7515  loss_dice_1: 2.134  loss_ce_2: 0  loss_mask_2: 0.7455  loss_dice_2: 2.123  loss_ce_3: 0  loss_mask_3: 0.7486  loss_dice_3: 2.104  loss_ce_4: 0  loss_mask_4: 0.7457  loss_dice_4: 2.099  loss_ce_5: 0  loss_mask_5: 0.7483  loss_dice_5: 2.101  loss_ce_6: 0  loss_mask_6: 0.7486  loss_dice_6: 2.1  loss_ce_7: 0  loss_mask_7: 0.7492  loss_dice_7: 2.098  loss_ce_8: 0  loss_mask_8: 0.7527  loss_dice_8: 2.095  time: 1.9931  data_time: 0.0318  lr: 5.4104e-05  max_mem: 6006M
[02/18 17:05:58] d2.utils.events INFO:  eta: 1 day, 5:05:05  iter: 29699  total_loss: 28.95  loss_ce: 0  loss_mask: 0.7304  loss_dice: 2.073  loss_seg: 0.5714  loss_ce_0: 0  loss_mask_0: 0.7509  loss_dice_0: 2.123  loss_ce_1: 0  loss_mask_1: 0.7302  loss_dice_1: 2.088  loss_ce_2: 0  loss_mask_2: 0.7339  loss_dice_2: 2.072  loss_ce_3: 0  loss_mask_3: 0.7396  loss_dice_3: 2.056  loss_ce_4: 0  loss_mask_4: 0.7376  loss_dice_4: 2.061  loss_ce_5: 0  loss_mask_5: 0.7349  loss_dice_5: 2.064  loss_ce_6: 0  loss_mask_6: 0.7355  loss_dice_6: 2.066  loss_ce_7: 0  loss_mask_7: 0.7327  loss_dice_7: 2.063  loss_ce_8: 0  loss_mask_8: 0.732  loss_dice_8: 2.064  time: 1.9939  data_time: 0.0324  lr: 5.4072e-05  max_mem: 6006M
[02/18 17:07:05] d2.utils.events INFO:  eta: 1 day, 5:00:26  iter: 29719  total_loss: 30.04  loss_ce: 0  loss_mask: 0.7621  loss_dice: 2.113  loss_seg: 0.6029  loss_ce_0: 0  loss_mask_0: 0.773  loss_dice_0: 2.205  loss_ce_1: 0  loss_mask_1: 0.7635  loss_dice_1: 2.142  loss_ce_2: 0  loss_mask_2: 0.7681  loss_dice_2: 2.132  loss_ce_3: 0  loss_mask_3: 0.7648  loss_dice_3: 2.114  loss_ce_4: 0  loss_mask_4: 0.7632  loss_dice_4: 2.117  loss_ce_5: 0  loss_mask_5: 0.7671  loss_dice_5: 2.117  loss_ce_6: 0  loss_mask_6: 0.7678  loss_dice_6: 2.108  loss_ce_7: 0  loss_mask_7: 0.7671  loss_dice_7: 2.113  loss_ce_8: 0  loss_mask_8: 0.7684  loss_dice_8: 2.107  time: 1.9949  data_time: 0.0293  lr: 5.404e-05  max_mem: 6006M
[02/18 17:08:15] d2.utils.events INFO:  eta: 1 day, 5:04:35  iter: 29739  total_loss: 29.9  loss_ce: 0  loss_mask: 0.7733  loss_dice: 2.13  loss_seg: 0.6484  loss_ce_0: 0  loss_mask_0: 0.7936  loss_dice_0: 2.188  loss_ce_1: 0  loss_mask_1: 0.7747  loss_dice_1: 2.148  loss_ce_2: 0  loss_mask_2: 0.7715  loss_dice_2: 2.135  loss_ce_3: 0  loss_mask_3: 0.7779  loss_dice_3: 2.129  loss_ce_4: 0  loss_mask_4: 0.7793  loss_dice_4: 2.124  loss_ce_5: 0  loss_mask_5: 0.7791  loss_dice_5: 2.13  loss_ce_6: 0  loss_mask_6: 0.782  loss_dice_6: 2.125  loss_ce_7: 0  loss_mask_7: 0.781  loss_dice_7: 2.123  loss_ce_8: 0  loss_mask_8: 0.7797  loss_dice_8: 2.128  time: 1.9959  data_time: 0.0307  lr: 5.4008e-05  max_mem: 6006M
[02/18 17:09:20] d2.utils.events INFO:  eta: 1 day, 4:54:28  iter: 29759  total_loss: 29.58  loss_ce: 0  loss_mask: 0.745  loss_dice: 2.092  loss_seg: 0.6232  loss_ce_0: 0  loss_mask_0: 0.7624  loss_dice_0: 2.171  loss_ce_1: 0  loss_mask_1: 0.7523  loss_dice_1: 2.11  loss_ce_2: 0  loss_mask_2: 0.7476  loss_dice_2: 2.097  loss_ce_3: 0  loss_mask_3: 0.7478  loss_dice_3: 2.082  loss_ce_4: 0  loss_mask_4: 0.7478  loss_dice_4: 2.086  loss_ce_5: 0  loss_mask_5: 0.749  loss_dice_5: 2.076  loss_ce_6: 0  loss_mask_6: 0.7505  loss_dice_6: 2.082  loss_ce_7: 0  loss_mask_7: 0.7524  loss_dice_7: 2.078  loss_ce_8: 0  loss_mask_8: 0.7501  loss_dice_8: 2.075  time: 1.9967  data_time: 0.0308  lr: 5.3976e-05  max_mem: 6006M
[02/18 17:10:25] d2.utils.events INFO:  eta: 1 day, 4:50:28  iter: 29779  total_loss: 28.58  loss_ce: 0  loss_mask: 0.7099  loss_dice: 2.039  loss_seg: 0.8369  loss_ce_0: 0  loss_mask_0: 0.7217  loss_dice_0: 2.093  loss_ce_1: 0  loss_mask_1: 0.7219  loss_dice_1: 2.044  loss_ce_2: 0  loss_mask_2: 0.7197  loss_dice_2: 2.028  loss_ce_3: 0  loss_mask_3: 0.7152  loss_dice_3: 2.026  loss_ce_4: 0  loss_mask_4: 0.7144  loss_dice_4: 2.02  loss_ce_5: 0  loss_mask_5: 0.7172  loss_dice_5: 2.022  loss_ce_6: 0  loss_mask_6: 0.7136  loss_dice_6: 2.023  loss_ce_7: 0  loss_mask_7: 0.7115  loss_dice_7: 2.026  loss_ce_8: 0  loss_mask_8: 0.7118  loss_dice_8: 2.027  time: 1.9975  data_time: 0.0335  lr: 5.3944e-05  max_mem: 6006M
[02/18 17:11:28] d2.utils.events INFO:  eta: 1 day, 4:47:24  iter: 29799  total_loss: 28.17  loss_ce: 0  loss_mask: 0.7091  loss_dice: 1.974  loss_seg: 0.7641  loss_ce_0: 0  loss_mask_0: 0.7153  loss_dice_0: 2.057  loss_ce_1: 0  loss_mask_1: 0.7154  loss_dice_1: 2.001  loss_ce_2: 0  loss_mask_2: 0.7137  loss_dice_2: 1.98  loss_ce_3: 0  loss_mask_3: 0.7092  loss_dice_3: 1.975  loss_ce_4: 0  loss_mask_4: 0.7101  loss_dice_4: 1.98  loss_ce_5: 0  loss_mask_5: 0.7108  loss_dice_5: 1.979  loss_ce_6: 0  loss_mask_6: 0.708  loss_dice_6: 1.971  loss_ce_7: 0  loss_mask_7: 0.7105  loss_dice_7: 1.968  loss_ce_8: 0  loss_mask_8: 0.7105  loss_dice_8: 1.973  time: 1.9983  data_time: 0.0316  lr: 5.3912e-05  max_mem: 6006M
[02/18 17:12:37] d2.utils.events INFO:  eta: 1 day, 4:46:47  iter: 29819  total_loss: 28.03  loss_ce: 0  loss_mask: 0.7534  loss_dice: 2.025  loss_seg: 0.6488  loss_ce_0: 0  loss_mask_0: 0.7619  loss_dice_0: 2.085  loss_ce_1: 0  loss_mask_1: 0.7605  loss_dice_1: 2.04  loss_ce_2: 0  loss_mask_2: 0.764  loss_dice_2: 2.024  loss_ce_3: 0  loss_mask_3: 0.7545  loss_dice_3: 2.009  loss_ce_4: 0  loss_mask_4: 0.7569  loss_dice_4: 2.012  loss_ce_5: 0  loss_mask_5: 0.7585  loss_dice_5: 2.016  loss_ce_6: 0  loss_mask_6: 0.7533  loss_dice_6: 2.011  loss_ce_7: 0  loss_mask_7: 0.7593  loss_dice_7: 2.019  loss_ce_8: 0  loss_mask_8: 0.7548  loss_dice_8: 2.018  time: 1.9993  data_time: 0.0260  lr: 5.388e-05  max_mem: 6006M
[02/18 17:13:46] d2.utils.events INFO:  eta: 1 day, 4:48:21  iter: 29839  total_loss: 29.27  loss_ce: 0  loss_mask: 0.7548  loss_dice: 2.088  loss_seg: 0.6632  loss_ce_0: 0  loss_mask_0: 0.764  loss_dice_0: 2.114  loss_ce_1: 0  loss_mask_1: 0.7505  loss_dice_1: 2.091  loss_ce_2: 0  loss_mask_2: 0.749  loss_dice_2: 2.088  loss_ce_3: 0  loss_mask_3: 0.7552  loss_dice_3: 2.079  loss_ce_4: 0  loss_mask_4: 0.7566  loss_dice_4: 2.087  loss_ce_5: 0  loss_mask_5: 0.7579  loss_dice_5: 2.082  loss_ce_6: 0  loss_mask_6: 0.7593  loss_dice_6: 2.083  loss_ce_7: 0  loss_mask_7: 0.7599  loss_dice_7: 2.082  loss_ce_8: 0  loss_mask_8: 0.7591  loss_dice_8: 2.081  time: 2.0002  data_time: 0.0329  lr: 5.3847e-05  max_mem: 6006M
[02/18 17:14:56] d2.utils.events INFO:  eta: 1 day, 4:50:35  iter: 29859  total_loss: 26.9  loss_ce: 0  loss_mask: 0.7006  loss_dice: 1.889  loss_seg: 0.8252  loss_ce_0: 0  loss_mask_0: 0.7186  loss_dice_0: 1.96  loss_ce_1: 0  loss_mask_1: 0.7048  loss_dice_1: 1.908  loss_ce_2: 0  loss_mask_2: 0.7067  loss_dice_2: 1.904  loss_ce_3: 0  loss_mask_3: 0.7082  loss_dice_3: 1.883  loss_ce_4: 0  loss_mask_4: 0.7086  loss_dice_4: 1.883  loss_ce_5: 0  loss_mask_5: 0.7104  loss_dice_5: 1.881  loss_ce_6: 0  loss_mask_6: 0.7109  loss_dice_6: 1.87  loss_ce_7: 0  loss_mask_7: 0.7089  loss_dice_7: 1.873  loss_ce_8: 0  loss_mask_8: 0.708  loss_dice_8: 1.881  time: 2.0012  data_time: 0.0288  lr: 5.3815e-05  max_mem: 6006M
[02/18 17:16:05] d2.utils.events INFO:  eta: 1 day, 4:48:59  iter: 29879  total_loss: 28.22  loss_ce: 0  loss_mask: 0.7028  loss_dice: 2.015  loss_seg: 0.8046  loss_ce_0: 0  loss_mask_0: 0.7244  loss_dice_0: 2.097  loss_ce_1: 0  loss_mask_1: 0.7144  loss_dice_1: 2.022  loss_ce_2: 0  loss_mask_2: 0.708  loss_dice_2: 2.012  loss_ce_3: 0  loss_mask_3: 0.7056  loss_dice_3: 2.006  loss_ce_4: 0  loss_mask_4: 0.705  loss_dice_4: 2.004  loss_ce_5: 0  loss_mask_5: 0.7053  loss_dice_5: 2.007  loss_ce_6: 0  loss_mask_6: 0.7033  loss_dice_6: 2.011  loss_ce_7: 0  loss_mask_7: 0.7036  loss_dice_7: 2.013  loss_ce_8: 0  loss_mask_8: 0.7057  loss_dice_8: 2.009  time: 2.0022  data_time: 0.0355  lr: 5.3783e-05  max_mem: 6006M
[02/18 17:17:13] d2.utils.events INFO:  eta: 1 day, 4:45:59  iter: 29899  total_loss: 29.12  loss_ce: 0  loss_mask: 0.7111  loss_dice: 2.073  loss_seg: 0.8764  loss_ce_0: 0  loss_mask_0: 0.7096  loss_dice_0: 2.14  loss_ce_1: 0  loss_mask_1: 0.7064  loss_dice_1: 2.082  loss_ce_2: 0  loss_mask_2: 0.7055  loss_dice_2: 2.069  loss_ce_3: 0  loss_mask_3: 0.7048  loss_dice_3: 2.062  loss_ce_4: 0  loss_mask_4: 0.7098  loss_dice_4: 2.064  loss_ce_5: 0  loss_mask_5: 0.7091  loss_dice_5: 2.068  loss_ce_6: 0  loss_mask_6: 0.7103  loss_dice_6: 2.063  loss_ce_7: 0  loss_mask_7: 0.7102  loss_dice_7: 2.058  loss_ce_8: 0  loss_mask_8: 0.708  loss_dice_8: 2.061  time: 2.0032  data_time: 0.0308  lr: 5.3751e-05  max_mem: 6006M
[02/18 17:18:20] d2.utils.events INFO:  eta: 1 day, 4:41:04  iter: 29919  total_loss: 28  loss_ce: 0  loss_mask: 0.7331  loss_dice: 2.004  loss_seg: 0.6017  loss_ce_0: 0  loss_mask_0: 0.7629  loss_dice_0: 2.065  loss_ce_1: 0  loss_mask_1: 0.7445  loss_dice_1: 2.02  loss_ce_2: 0  loss_mask_2: 0.7395  loss_dice_2: 2.005  loss_ce_3: 0  loss_mask_3: 0.7369  loss_dice_3: 1.996  loss_ce_4: 0  loss_mask_4: 0.7394  loss_dice_4: 1.997  loss_ce_5: 0  loss_mask_5: 0.7391  loss_dice_5: 1.997  loss_ce_6: 0  loss_mask_6: 0.735  loss_dice_6: 1.998  loss_ce_7: 0  loss_mask_7: 0.7369  loss_dice_7: 1.993  loss_ce_8: 0  loss_mask_8: 0.7352  loss_dice_8: 1.998  time: 2.0040  data_time: 0.0362  lr: 5.3719e-05  max_mem: 6006M
[02/18 17:19:31] d2.utils.events INFO:  eta: 1 day, 4:42:21  iter: 29939  total_loss: 28.4  loss_ce: 0  loss_mask: 0.7067  loss_dice: 2.068  loss_seg: 0.6542  loss_ce_0: 0  loss_mask_0: 0.7167  loss_dice_0: 2.158  loss_ce_1: 0  loss_mask_1: 0.7089  loss_dice_1: 2.094  loss_ce_2: 0  loss_mask_2: 0.7052  loss_dice_2: 2.069  loss_ce_3: 0  loss_mask_3: 0.7056  loss_dice_3: 2.06  loss_ce_4: 0  loss_mask_4: 0.7073  loss_dice_4: 2.054  loss_ce_5: 0  loss_mask_5: 0.7059  loss_dice_5: 2.065  loss_ce_6: 0  loss_mask_6: 0.7075  loss_dice_6: 2.056  loss_ce_7: 0  loss_mask_7: 0.7113  loss_dice_7: 2.058  loss_ce_8: 0  loss_mask_8: 0.7079  loss_dice_8: 2.059  time: 2.0051  data_time: 0.0332  lr: 5.3687e-05  max_mem: 6006M
[02/18 17:20:37] d2.utils.events INFO:  eta: 1 day, 4:41:12  iter: 29959  total_loss: 29.12  loss_ce: 0  loss_mask: 0.7267  loss_dice: 2.071  loss_seg: 0.984  loss_ce_0: 0  loss_mask_0: 0.7353  loss_dice_0: 2.157  loss_ce_1: 0  loss_mask_1: 0.734  loss_dice_1: 2.095  loss_ce_2: 0  loss_mask_2: 0.732  loss_dice_2: 2.072  loss_ce_3: 0  loss_mask_3: 0.7302  loss_dice_3: 2.059  loss_ce_4: 0  loss_mask_4: 0.7303  loss_dice_4: 2.07  loss_ce_5: 0  loss_mask_5: 0.7272  loss_dice_5: 2.062  loss_ce_6: 0  loss_mask_6: 0.7304  loss_dice_6: 2.064  loss_ce_7: 0  loss_mask_7: 0.7296  loss_dice_7: 2.061  loss_ce_8: 0  loss_mask_8: 0.7279  loss_dice_8: 2.06  time: 2.0059  data_time: 0.0286  lr: 5.3655e-05  max_mem: 6006M
[02/18 17:21:49] d2.utils.events INFO:  eta: 1 day, 4:42:27  iter: 29979  total_loss: 26.9  loss_ce: 0  loss_mask: 0.6929  loss_dice: 1.845  loss_seg: 0.7972  loss_ce_0: 0  loss_mask_0: 0.6961  loss_dice_0: 1.921  loss_ce_1: 0  loss_mask_1: 0.7036  loss_dice_1: 1.856  loss_ce_2: 0  loss_mask_2: 0.6979  loss_dice_2: 1.848  loss_ce_3: 0  loss_mask_3: 0.6986  loss_dice_3: 1.835  loss_ce_4: 0  loss_mask_4: 0.6967  loss_dice_4: 1.832  loss_ce_5: 0  loss_mask_5: 0.6956  loss_dice_5: 1.837  loss_ce_6: 0  loss_mask_6: 0.6958  loss_dice_6: 1.834  loss_ce_7: 0  loss_mask_7: 0.6944  loss_dice_7: 1.837  loss_ce_8: 0  loss_mask_8: 0.6922  loss_dice_8: 1.836  time: 2.0070  data_time: 0.0343  lr: 5.3622e-05  max_mem: 6006M
[02/18 17:22:57] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_upsampleconv_segweight0p1/model_0029999.pth
[02/18 17:22:58] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/18 17:22:59] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/18 17:22:59] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/18 17:23:15] mask2former INFO: Inference done 11/1093. Dataloading: 0.0056 s/iter. Inference: 0.3849 s/iter. Eval: 0.1191 s/iter. Total: 0.5097 s/iter. ETA=0:09:11
[02/18 17:23:20] mask2former INFO: Inference done 21/1093. Dataloading: 0.0050 s/iter. Inference: 0.3663 s/iter. Eval: 0.1326 s/iter. Total: 0.5040 s/iter. ETA=0:09:00
[02/18 17:23:25] mask2former INFO: Inference done 32/1093. Dataloading: 0.0056 s/iter. Inference: 0.3658 s/iter. Eval: 0.1291 s/iter. Total: 0.5006 s/iter. ETA=0:08:51
[02/18 17:23:30] mask2former INFO: Inference done 42/1093. Dataloading: 0.0057 s/iter. Inference: 0.3690 s/iter. Eval: 0.1277 s/iter. Total: 0.5025 s/iter. ETA=0:08:48
[02/18 17:23:36] mask2former INFO: Inference done 53/1093. Dataloading: 0.0054 s/iter. Inference: 0.3682 s/iter. Eval: 0.1258 s/iter. Total: 0.4995 s/iter. ETA=0:08:39
[02/18 17:23:41] mask2former INFO: Inference done 64/1093. Dataloading: 0.0053 s/iter. Inference: 0.3674 s/iter. Eval: 0.1255 s/iter. Total: 0.4983 s/iter. ETA=0:08:32
[02/18 17:23:46] mask2former INFO: Inference done 75/1093. Dataloading: 0.0053 s/iter. Inference: 0.3687 s/iter. Eval: 0.1231 s/iter. Total: 0.4972 s/iter. ETA=0:08:26
[02/18 17:23:51] mask2former INFO: Inference done 85/1093. Dataloading: 0.0052 s/iter. Inference: 0.3689 s/iter. Eval: 0.1236 s/iter. Total: 0.4977 s/iter. ETA=0:08:21
[02/18 17:23:57] mask2former INFO: Inference done 97/1093. Dataloading: 0.0051 s/iter. Inference: 0.3639 s/iter. Eval: 0.1224 s/iter. Total: 0.4915 s/iter. ETA=0:08:09
[02/18 17:24:02] mask2former INFO: Inference done 108/1093. Dataloading: 0.0050 s/iter. Inference: 0.3633 s/iter. Eval: 0.1231 s/iter. Total: 0.4915 s/iter. ETA=0:08:04
[02/18 17:24:07] mask2former INFO: Inference done 119/1093. Dataloading: 0.0050 s/iter. Inference: 0.3632 s/iter. Eval: 0.1215 s/iter. Total: 0.4898 s/iter. ETA=0:07:57
[02/18 17:24:13] mask2former INFO: Inference done 130/1093. Dataloading: 0.0049 s/iter. Inference: 0.3618 s/iter. Eval: 0.1212 s/iter. Total: 0.4880 s/iter. ETA=0:07:49
[02/18 17:24:18] mask2former INFO: Inference done 140/1093. Dataloading: 0.0053 s/iter. Inference: 0.3620 s/iter. Eval: 0.1216 s/iter. Total: 0.4890 s/iter. ETA=0:07:46
[02/18 17:24:23] mask2former INFO: Inference done 151/1093. Dataloading: 0.0052 s/iter. Inference: 0.3611 s/iter. Eval: 0.1208 s/iter. Total: 0.4872 s/iter. ETA=0:07:38
[02/18 17:24:28] mask2former INFO: Inference done 162/1093. Dataloading: 0.0051 s/iter. Inference: 0.3615 s/iter. Eval: 0.1213 s/iter. Total: 0.4881 s/iter. ETA=0:07:34
[02/18 17:24:34] mask2former INFO: Inference done 173/1093. Dataloading: 0.0051 s/iter. Inference: 0.3609 s/iter. Eval: 0.1219 s/iter. Total: 0.4880 s/iter. ETA=0:07:28
[02/18 17:24:39] mask2former INFO: Inference done 184/1093. Dataloading: 0.0052 s/iter. Inference: 0.3613 s/iter. Eval: 0.1216 s/iter. Total: 0.4882 s/iter. ETA=0:07:23
[02/18 17:24:44] mask2former INFO: Inference done 195/1093. Dataloading: 0.0051 s/iter. Inference: 0.3613 s/iter. Eval: 0.1205 s/iter. Total: 0.4871 s/iter. ETA=0:07:17
[02/18 17:24:49] mask2former INFO: Inference done 206/1093. Dataloading: 0.0053 s/iter. Inference: 0.3608 s/iter. Eval: 0.1206 s/iter. Total: 0.4869 s/iter. ETA=0:07:11
[02/18 17:24:55] mask2former INFO: Inference done 217/1093. Dataloading: 0.0053 s/iter. Inference: 0.3613 s/iter. Eval: 0.1201 s/iter. Total: 0.4868 s/iter. ETA=0:07:06
[02/18 17:25:00] mask2former INFO: Inference done 228/1093. Dataloading: 0.0053 s/iter. Inference: 0.3611 s/iter. Eval: 0.1197 s/iter. Total: 0.4862 s/iter. ETA=0:07:00
[02/18 17:25:05] mask2former INFO: Inference done 239/1093. Dataloading: 0.0052 s/iter. Inference: 0.3612 s/iter. Eval: 0.1195 s/iter. Total: 0.4860 s/iter. ETA=0:06:55
[02/18 17:25:10] mask2former INFO: Inference done 250/1093. Dataloading: 0.0052 s/iter. Inference: 0.3605 s/iter. Eval: 0.1189 s/iter. Total: 0.4847 s/iter. ETA=0:06:48
[02/18 17:25:15] mask2former INFO: Inference done 260/1093. Dataloading: 0.0052 s/iter. Inference: 0.3612 s/iter. Eval: 0.1190 s/iter. Total: 0.4854 s/iter. ETA=0:06:44
[02/18 17:25:21] mask2former INFO: Inference done 271/1093. Dataloading: 0.0052 s/iter. Inference: 0.3610 s/iter. Eval: 0.1188 s/iter. Total: 0.4850 s/iter. ETA=0:06:38
[02/18 17:25:26] mask2former INFO: Inference done 282/1093. Dataloading: 0.0052 s/iter. Inference: 0.3604 s/iter. Eval: 0.1186 s/iter. Total: 0.4843 s/iter. ETA=0:06:32
[02/18 17:25:31] mask2former INFO: Inference done 293/1093. Dataloading: 0.0052 s/iter. Inference: 0.3606 s/iter. Eval: 0.1188 s/iter. Total: 0.4847 s/iter. ETA=0:06:27
[02/18 17:25:36] mask2former INFO: Inference done 303/1093. Dataloading: 0.0052 s/iter. Inference: 0.3607 s/iter. Eval: 0.1192 s/iter. Total: 0.4852 s/iter. ETA=0:06:23
[02/18 17:25:42] mask2former INFO: Inference done 314/1093. Dataloading: 0.0052 s/iter. Inference: 0.3605 s/iter. Eval: 0.1196 s/iter. Total: 0.4854 s/iter. ETA=0:06:18
[02/18 17:25:47] mask2former INFO: Inference done 324/1093. Dataloading: 0.0053 s/iter. Inference: 0.3616 s/iter. Eval: 0.1198 s/iter. Total: 0.4868 s/iter. ETA=0:06:14
[02/18 17:25:52] mask2former INFO: Inference done 335/1093. Dataloading: 0.0053 s/iter. Inference: 0.3620 s/iter. Eval: 0.1193 s/iter. Total: 0.4866 s/iter. ETA=0:06:08
[02/18 17:25:57] mask2former INFO: Inference done 346/1093. Dataloading: 0.0052 s/iter. Inference: 0.3621 s/iter. Eval: 0.1190 s/iter. Total: 0.4864 s/iter. ETA=0:06:03
[02/18 17:26:03] mask2former INFO: Inference done 357/1093. Dataloading: 0.0052 s/iter. Inference: 0.3618 s/iter. Eval: 0.1190 s/iter. Total: 0.4861 s/iter. ETA=0:05:57
[02/18 17:26:08] mask2former INFO: Inference done 368/1093. Dataloading: 0.0052 s/iter. Inference: 0.3614 s/iter. Eval: 0.1192 s/iter. Total: 0.4859 s/iter. ETA=0:05:52
[02/18 17:26:13] mask2former INFO: Inference done 379/1093. Dataloading: 0.0052 s/iter. Inference: 0.3610 s/iter. Eval: 0.1189 s/iter. Total: 0.4851 s/iter. ETA=0:05:46
[02/18 17:26:18] mask2former INFO: Inference done 390/1093. Dataloading: 0.0052 s/iter. Inference: 0.3611 s/iter. Eval: 0.1190 s/iter. Total: 0.4854 s/iter. ETA=0:05:41
[02/18 17:26:24] mask2former INFO: Inference done 401/1093. Dataloading: 0.0052 s/iter. Inference: 0.3611 s/iter. Eval: 0.1188 s/iter. Total: 0.4851 s/iter. ETA=0:05:35
[02/18 17:26:29] mask2former INFO: Inference done 411/1093. Dataloading: 0.0051 s/iter. Inference: 0.3620 s/iter. Eval: 0.1189 s/iter. Total: 0.4861 s/iter. ETA=0:05:31
[02/18 17:26:34] mask2former INFO: Inference done 422/1093. Dataloading: 0.0051 s/iter. Inference: 0.3625 s/iter. Eval: 0.1187 s/iter. Total: 0.4865 s/iter. ETA=0:05:26
[02/18 17:26:40] mask2former INFO: Inference done 433/1093. Dataloading: 0.0051 s/iter. Inference: 0.3626 s/iter. Eval: 0.1186 s/iter. Total: 0.4865 s/iter. ETA=0:05:21
[02/18 17:26:45] mask2former INFO: Inference done 444/1093. Dataloading: 0.0051 s/iter. Inference: 0.3621 s/iter. Eval: 0.1192 s/iter. Total: 0.4866 s/iter. ETA=0:05:15
[02/18 17:26:50] mask2former INFO: Inference done 455/1093. Dataloading: 0.0052 s/iter. Inference: 0.3622 s/iter. Eval: 0.1188 s/iter. Total: 0.4863 s/iter. ETA=0:05:10
[02/18 17:26:55] mask2former INFO: Inference done 466/1093. Dataloading: 0.0052 s/iter. Inference: 0.3620 s/iter. Eval: 0.1185 s/iter. Total: 0.4858 s/iter. ETA=0:05:04
[02/18 17:27:01] mask2former INFO: Inference done 477/1093. Dataloading: 0.0053 s/iter. Inference: 0.3621 s/iter. Eval: 0.1180 s/iter. Total: 0.4855 s/iter. ETA=0:04:59
[02/18 17:27:06] mask2former INFO: Inference done 488/1093. Dataloading: 0.0052 s/iter. Inference: 0.3622 s/iter. Eval: 0.1178 s/iter. Total: 0.4853 s/iter. ETA=0:04:53
[02/18 17:27:11] mask2former INFO: Inference done 499/1093. Dataloading: 0.0052 s/iter. Inference: 0.3622 s/iter. Eval: 0.1178 s/iter. Total: 0.4854 s/iter. ETA=0:04:48
[02/18 17:27:17] mask2former INFO: Inference done 510/1093. Dataloading: 0.0053 s/iter. Inference: 0.3624 s/iter. Eval: 0.1178 s/iter. Total: 0.4855 s/iter. ETA=0:04:43
[02/18 17:27:22] mask2former INFO: Inference done 521/1093. Dataloading: 0.0053 s/iter. Inference: 0.3629 s/iter. Eval: 0.1179 s/iter. Total: 0.4862 s/iter. ETA=0:04:38
[02/18 17:27:28] mask2former INFO: Inference done 532/1093. Dataloading: 0.0053 s/iter. Inference: 0.3629 s/iter. Eval: 0.1175 s/iter. Total: 0.4858 s/iter. ETA=0:04:32
[02/18 17:27:33] mask2former INFO: Inference done 543/1093. Dataloading: 0.0052 s/iter. Inference: 0.3626 s/iter. Eval: 0.1175 s/iter. Total: 0.4855 s/iter. ETA=0:04:27
[02/18 17:27:38] mask2former INFO: Inference done 553/1093. Dataloading: 0.0052 s/iter. Inference: 0.3624 s/iter. Eval: 0.1183 s/iter. Total: 0.4860 s/iter. ETA=0:04:22
[02/18 17:27:43] mask2former INFO: Inference done 563/1093. Dataloading: 0.0053 s/iter. Inference: 0.3625 s/iter. Eval: 0.1188 s/iter. Total: 0.4867 s/iter. ETA=0:04:17
[02/18 17:27:48] mask2former INFO: Inference done 574/1093. Dataloading: 0.0053 s/iter. Inference: 0.3625 s/iter. Eval: 0.1188 s/iter. Total: 0.4867 s/iter. ETA=0:04:12
[02/18 17:27:54] mask2former INFO: Inference done 585/1093. Dataloading: 0.0053 s/iter. Inference: 0.3624 s/iter. Eval: 0.1185 s/iter. Total: 0.4863 s/iter. ETA=0:04:07
[02/18 17:27:59] mask2former INFO: Inference done 596/1093. Dataloading: 0.0053 s/iter. Inference: 0.3623 s/iter. Eval: 0.1185 s/iter. Total: 0.4862 s/iter. ETA=0:04:01
[02/18 17:28:04] mask2former INFO: Inference done 607/1093. Dataloading: 0.0053 s/iter. Inference: 0.3620 s/iter. Eval: 0.1186 s/iter. Total: 0.4861 s/iter. ETA=0:03:56
[02/18 17:28:09] mask2former INFO: Inference done 618/1093. Dataloading: 0.0053 s/iter. Inference: 0.3618 s/iter. Eval: 0.1188 s/iter. Total: 0.4860 s/iter. ETA=0:03:50
[02/18 17:28:15] mask2former INFO: Inference done 629/1093. Dataloading: 0.0053 s/iter. Inference: 0.3619 s/iter. Eval: 0.1187 s/iter. Total: 0.4860 s/iter. ETA=0:03:45
[02/18 17:28:20] mask2former INFO: Inference done 640/1093. Dataloading: 0.0053 s/iter. Inference: 0.3619 s/iter. Eval: 0.1187 s/iter. Total: 0.4860 s/iter. ETA=0:03:40
[02/18 17:28:25] mask2former INFO: Inference done 651/1093. Dataloading: 0.0053 s/iter. Inference: 0.3616 s/iter. Eval: 0.1187 s/iter. Total: 0.4857 s/iter. ETA=0:03:34
[02/18 17:28:31] mask2former INFO: Inference done 662/1093. Dataloading: 0.0053 s/iter. Inference: 0.3617 s/iter. Eval: 0.1187 s/iter. Total: 0.4857 s/iter. ETA=0:03:29
[02/18 17:28:36] mask2former INFO: Inference done 673/1093. Dataloading: 0.0053 s/iter. Inference: 0.3618 s/iter. Eval: 0.1183 s/iter. Total: 0.4856 s/iter. ETA=0:03:23
[02/18 17:28:41] mask2former INFO: Inference done 684/1093. Dataloading: 0.0053 s/iter. Inference: 0.3620 s/iter. Eval: 0.1183 s/iter. Total: 0.4856 s/iter. ETA=0:03:18
[02/18 17:28:47] mask2former INFO: Inference done 695/1093. Dataloading: 0.0053 s/iter. Inference: 0.3620 s/iter. Eval: 0.1182 s/iter. Total: 0.4856 s/iter. ETA=0:03:13
[02/18 17:28:52] mask2former INFO: Inference done 706/1093. Dataloading: 0.0053 s/iter. Inference: 0.3621 s/iter. Eval: 0.1181 s/iter. Total: 0.4855 s/iter. ETA=0:03:07
[02/18 17:28:57] mask2former INFO: Inference done 717/1093. Dataloading: 0.0053 s/iter. Inference: 0.3620 s/iter. Eval: 0.1180 s/iter. Total: 0.4854 s/iter. ETA=0:03:02
[02/18 17:29:03] mask2former INFO: Inference done 728/1093. Dataloading: 0.0053 s/iter. Inference: 0.3620 s/iter. Eval: 0.1182 s/iter. Total: 0.4856 s/iter. ETA=0:02:57
[02/18 17:29:08] mask2former INFO: Inference done 739/1093. Dataloading: 0.0053 s/iter. Inference: 0.3618 s/iter. Eval: 0.1184 s/iter. Total: 0.4856 s/iter. ETA=0:02:51
[02/18 17:29:13] mask2former INFO: Inference done 750/1093. Dataloading: 0.0053 s/iter. Inference: 0.3617 s/iter. Eval: 0.1183 s/iter. Total: 0.4854 s/iter. ETA=0:02:46
[02/18 17:29:18] mask2former INFO: Inference done 760/1093. Dataloading: 0.0053 s/iter. Inference: 0.3620 s/iter. Eval: 0.1186 s/iter. Total: 0.4860 s/iter. ETA=0:02:41
[02/18 17:29:24] mask2former INFO: Inference done 771/1093. Dataloading: 0.0052 s/iter. Inference: 0.3619 s/iter. Eval: 0.1185 s/iter. Total: 0.4858 s/iter. ETA=0:02:36
[02/18 17:29:29] mask2former INFO: Inference done 783/1093. Dataloading: 0.0052 s/iter. Inference: 0.3614 s/iter. Eval: 0.1183 s/iter. Total: 0.4851 s/iter. ETA=0:02:30
[02/18 17:29:34] mask2former INFO: Inference done 794/1093. Dataloading: 0.0052 s/iter. Inference: 0.3612 s/iter. Eval: 0.1183 s/iter. Total: 0.4848 s/iter. ETA=0:02:24
[02/18 17:29:39] mask2former INFO: Inference done 805/1093. Dataloading: 0.0052 s/iter. Inference: 0.3611 s/iter. Eval: 0.1183 s/iter. Total: 0.4848 s/iter. ETA=0:02:19
[02/18 17:29:45] mask2former INFO: Inference done 813/1093. Dataloading: 0.0053 s/iter. Inference: 0.3621 s/iter. Eval: 0.1197 s/iter. Total: 0.4872 s/iter. ETA=0:02:16
[02/18 17:29:50] mask2former INFO: Inference done 818/1093. Dataloading: 0.0054 s/iter. Inference: 0.3639 s/iter. Eval: 0.1212 s/iter. Total: 0.4907 s/iter. ETA=0:02:14
[02/18 17:29:56] mask2former INFO: Inference done 824/1093. Dataloading: 0.0055 s/iter. Inference: 0.3658 s/iter. Eval: 0.1221 s/iter. Total: 0.4935 s/iter. ETA=0:02:12
[02/18 17:30:01] mask2former INFO: Inference done 835/1093. Dataloading: 0.0055 s/iter. Inference: 0.3658 s/iter. Eval: 0.1221 s/iter. Total: 0.4935 s/iter. ETA=0:02:07
[02/18 17:30:06] mask2former INFO: Inference done 842/1093. Dataloading: 0.0056 s/iter. Inference: 0.3668 s/iter. Eval: 0.1230 s/iter. Total: 0.4954 s/iter. ETA=0:02:04
[02/18 17:30:11] mask2former INFO: Inference done 852/1093. Dataloading: 0.0056 s/iter. Inference: 0.3667 s/iter. Eval: 0.1233 s/iter. Total: 0.4957 s/iter. ETA=0:01:59
[02/18 17:30:17] mask2former INFO: Inference done 863/1093. Dataloading: 0.0056 s/iter. Inference: 0.3667 s/iter. Eval: 0.1231 s/iter. Total: 0.4955 s/iter. ETA=0:01:53
[02/18 17:30:22] mask2former INFO: Inference done 874/1093. Dataloading: 0.0055 s/iter. Inference: 0.3667 s/iter. Eval: 0.1232 s/iter. Total: 0.4956 s/iter. ETA=0:01:48
[02/18 17:30:27] mask2former INFO: Inference done 884/1093. Dataloading: 0.0055 s/iter. Inference: 0.3667 s/iter. Eval: 0.1234 s/iter. Total: 0.4958 s/iter. ETA=0:01:43
[02/18 17:30:33] mask2former INFO: Inference done 895/1093. Dataloading: 0.0056 s/iter. Inference: 0.3666 s/iter. Eval: 0.1234 s/iter. Total: 0.4957 s/iter. ETA=0:01:38
[02/18 17:30:38] mask2former INFO: Inference done 905/1093. Dataloading: 0.0056 s/iter. Inference: 0.3667 s/iter. Eval: 0.1234 s/iter. Total: 0.4958 s/iter. ETA=0:01:33
[02/18 17:30:43] mask2former INFO: Inference done 915/1093. Dataloading: 0.0056 s/iter. Inference: 0.3670 s/iter. Eval: 0.1234 s/iter. Total: 0.4961 s/iter. ETA=0:01:28
[02/18 17:30:48] mask2former INFO: Inference done 926/1093. Dataloading: 0.0056 s/iter. Inference: 0.3669 s/iter. Eval: 0.1232 s/iter. Total: 0.4958 s/iter. ETA=0:01:22
[02/18 17:30:53] mask2former INFO: Inference done 937/1093. Dataloading: 0.0056 s/iter. Inference: 0.3668 s/iter. Eval: 0.1231 s/iter. Total: 0.4956 s/iter. ETA=0:01:17
[02/18 17:30:59] mask2former INFO: Inference done 948/1093. Dataloading: 0.0056 s/iter. Inference: 0.3668 s/iter. Eval: 0.1231 s/iter. Total: 0.4956 s/iter. ETA=0:01:11
[02/18 17:31:04] mask2former INFO: Inference done 959/1093. Dataloading: 0.0056 s/iter. Inference: 0.3668 s/iter. Eval: 0.1229 s/iter. Total: 0.4954 s/iter. ETA=0:01:06
[02/18 17:31:10] mask2former INFO: Inference done 970/1093. Dataloading: 0.0056 s/iter. Inference: 0.3666 s/iter. Eval: 0.1232 s/iter. Total: 0.4955 s/iter. ETA=0:01:00
[02/18 17:31:15] mask2former INFO: Inference done 980/1093. Dataloading: 0.0056 s/iter. Inference: 0.3666 s/iter. Eval: 0.1233 s/iter. Total: 0.4957 s/iter. ETA=0:00:56
[02/18 17:31:20] mask2former INFO: Inference done 991/1093. Dataloading: 0.0056 s/iter. Inference: 0.3666 s/iter. Eval: 0.1234 s/iter. Total: 0.4957 s/iter. ETA=0:00:50
[02/18 17:31:26] mask2former INFO: Inference done 1002/1093. Dataloading: 0.0056 s/iter. Inference: 0.3663 s/iter. Eval: 0.1234 s/iter. Total: 0.4955 s/iter. ETA=0:00:45
[02/18 17:31:31] mask2former INFO: Inference done 1012/1093. Dataloading: 0.0056 s/iter. Inference: 0.3664 s/iter. Eval: 0.1236 s/iter. Total: 0.4956 s/iter. ETA=0:00:40
[02/18 17:31:36] mask2former INFO: Inference done 1023/1093. Dataloading: 0.0056 s/iter. Inference: 0.3665 s/iter. Eval: 0.1235 s/iter. Total: 0.4957 s/iter. ETA=0:00:34
[02/18 17:31:42] mask2former INFO: Inference done 1034/1093. Dataloading: 0.0056 s/iter. Inference: 0.3667 s/iter. Eval: 0.1232 s/iter. Total: 0.4956 s/iter. ETA=0:00:29
[02/18 17:31:47] mask2former INFO: Inference done 1045/1093. Dataloading: 0.0056 s/iter. Inference: 0.3665 s/iter. Eval: 0.1231 s/iter. Total: 0.4954 s/iter. ETA=0:00:23
[02/18 17:31:52] mask2former INFO: Inference done 1056/1093. Dataloading: 0.0056 s/iter. Inference: 0.3665 s/iter. Eval: 0.1231 s/iter. Total: 0.4954 s/iter. ETA=0:00:18
[02/18 17:31:58] mask2former INFO: Inference done 1067/1093. Dataloading: 0.0056 s/iter. Inference: 0.3664 s/iter. Eval: 0.1232 s/iter. Total: 0.4953 s/iter. ETA=0:00:12
[02/18 17:32:03] mask2former INFO: Inference done 1077/1093. Dataloading: 0.0056 s/iter. Inference: 0.3666 s/iter. Eval: 0.1232 s/iter. Total: 0.4955 s/iter. ETA=0:00:07
[02/18 17:32:08] mask2former INFO: Inference done 1088/1093. Dataloading: 0.0056 s/iter. Inference: 0.3665 s/iter. Eval: 0.1231 s/iter. Total: 0.4953 s/iter. ETA=0:00:02
[02/18 17:32:42] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.277898490072411, 'error_1pix': 0.2983697489430841, 'error_3pix': 0.18805352809383952, 'mIoU': 24.693003587460364, 'fwIoU': 45.85684379114861, 'IoU-1': 94.66451636071085, 'IoU-2': 0.03803478866976289, 'IoU-3': 0.04840934720135211, 'IoU-4': 0.02472772877585911, 'IoU-5': 0.017218929437965606, 'IoU-6': 0.020593677097578634, 'IoU-7': 0.018125116613801742, 'IoU-8': 0.010675297482934687, 'IoU-9': 0.9272343119316154, 'IoU-10': 8.611540594367534, 'IoU-11': 2.4653733285857222, 'IoU-12': 37.62051745284868, 'IoU-13': 28.970826056688548, 'IoU-14': 31.940317147983826, 'IoU-15': 30.209746253174718, 'IoU-16': 29.2498257113133, 'IoU-17': 28.29975291046507, 'IoU-18': 28.427323829353263, 'IoU-19': 30.434289899824552, 'IoU-20': 38.96902386503962, 'IoU-21': 25.312398999666613, 'IoU-22': 30.936613367958284, 'IoU-23': 30.352076392691412, 'IoU-24': 28.452722695281214, 'IoU-25': 32.67887575931272, 'IoU-26': 42.465914610933694, 'IoU-27': 34.41950302444014, 'IoU-28': 30.923171292275757, 'IoU-29': 27.37449659451062, 'IoU-30': 29.67622447758168, 'IoU-31': 30.810488423183468, 'IoU-32': 42.26870661349436, 'IoU-33': 30.25453224941274, 'IoU-34': 28.72055365822865, 'IoU-35': 29.126414109879388, 'IoU-36': 39.23344814122219, 'IoU-37': 32.601872562324985, 'IoU-38': 25.305906707845633, 'IoU-39': 22.484323603309463, 'IoU-40': 25.515331734405372, 'IoU-41': 24.06058236895758, 'IoU-42': 21.447319592498673, 'IoU-43': 33.434783826917865, 'IoU-44': 30.638174931295897, 'IoU-45': 20.559894001209035, 'IoU-46': 19.05809264083945, 'IoU-47': 15.44003682670547, 'IoU-48': 10.743640384148517, 'mACC': 39.18499981106473, 'pACC': 56.29602513200598, 'ACC-1': 96.55621466201157, 'ACC-2': 0.03803485522389161, 'ACC-3': 0.05487273015621283, 'ACC-4': 0.025996900273900357, 'ACC-5': 0.017793175655406477, 'ACC-6': 0.02108276467516895, 'ACC-7': 0.018556689777629, 'ACC-8': 0.0108614620515327, 'ACC-9': 63.25102691937291, 'ACC-10': 10.91221640033211, 'ACC-11': 2.7087176429639515, 'ACC-12': 81.09577214193003, 'ACC-13': 40.13590343224991, 'ACC-14': 41.6802530934174, 'ACC-15': 44.82531573505544, 'ACC-16': 46.20249404687114, 'ACC-17': 45.009214889927314, 'ACC-18': 41.14658910884316, 'ACC-19': 48.29925077108979, 'ACC-20': 76.65396028063921, 'ACC-21': 38.424170600907104, 'ACC-22': 44.754423323863826, 'ACC-23': 46.890658147392756, 'ACC-24': 40.769000787934345, 'ACC-25': 44.625312479657495, 'ACC-26': 70.37878375643317, 'ACC-27': 51.340943739984844, 'ACC-28': 43.20952611574224, 'ACC-29': 37.70396041783812, 'ACC-30': 46.96606583656729, 'ACC-31': 46.485391866181665, 'ACC-32': 74.81645145314234, 'ACC-33': 42.41814559965581, 'ACC-34': 37.94558280190811, 'ACC-35': 42.30478624459641, 'ACC-36': 68.69341131952433, 'ACC-37': 48.04600731263975, 'ACC-38': 35.80241506883039, 'ACC-39': 35.24892573186463, 'ACC-40': 43.11538628864473, 'ACC-41': 36.77276654089573, 'ACC-42': 32.901059523789236, 'ACC-43': 63.866524162704806, 'ACC-44': 55.509542037655734, 'ACC-45': 33.99234792990375, 'ACC-46': 35.54843358382618, 'ACC-47': 26.718216980693192, 'ACC-48': 16.967623575811533})])
[02/18 17:32:42] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/18 17:32:42] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/18 17:32:42] d2.evaluation.testing INFO: copypaste: 2.2779,0.2984,0.1881,24.6930,45.8568,39.1850,56.2960
[02/18 17:32:42] d2.utils.events INFO:  eta: 1 day, 4:43:09  iter: 29999  total_loss: 27.02  loss_ce: 0  loss_mask: 0.6493  loss_dice: 1.879  loss_seg: 0.6717  loss_ce_0: 0  loss_mask_0: 0.6612  loss_dice_0: 1.937  loss_ce_1: 0  loss_mask_1: 0.6551  loss_dice_1: 1.899  loss_ce_2: 0  loss_mask_2: 0.6517  loss_dice_2: 1.891  loss_ce_3: 0  loss_mask_3: 0.6533  loss_dice_3: 1.877  loss_ce_4: 0  loss_mask_4: 0.6543  loss_dice_4: 1.868  loss_ce_5: 0  loss_mask_5: 0.6522  loss_dice_5: 1.865  loss_ce_6: 0  loss_mask_6: 0.6537  loss_dice_6: 1.861  loss_ce_7: 0  loss_mask_7: 0.6523  loss_dice_7: 1.869  loss_ce_8: 0  loss_mask_8: 0.6526  loss_dice_8: 1.88  time: 2.0079  data_time: 0.0362  lr: 5.359e-05  max_mem: 6006M
[02/18 17:32:51] d2.engine.hooks INFO: Overall training speed: 30000 iterations in 16:44:03 (2.0081 s / it)
[02/18 17:32:51] d2.engine.hooks INFO: Total training time: 18:27:05 (1:43:01 on hooks)
[02/18 17:32:51] d2.utils.events INFO:  eta: 1 day, 4:41:55  iter: 30002  total_loss: 27.02  loss_ce: 0  loss_mask: 0.6493  loss_dice: 1.889  loss_seg: 0.764  loss_ce_0: 0  loss_mask_0: 0.6612  loss_dice_0: 1.985  loss_ce_1: 0  loss_mask_1: 0.6551  loss_dice_1: 1.925  loss_ce_2: 0  loss_mask_2: 0.6525  loss_dice_2: 1.915  loss_ce_3: 0  loss_mask_3: 0.6533  loss_dice_3: 1.894  loss_ce_4: 0  loss_mask_4: 0.6543  loss_dice_4: 1.895  loss_ce_5: 0  loss_mask_5: 0.6535  loss_dice_5: 1.893  loss_ce_6: 0  loss_mask_6: 0.6543  loss_dice_6: 1.892  loss_ce_7: 0  loss_mask_7: 0.6523  loss_dice_7: 1.888  loss_ce_8: 0  loss_mask_8: 0.6535  loss_dice_8: 1.893  time: 2.0080  data_time: 0.0371  lr: 5.3587e-05  max_mem: 6006M
